{"pr_number": 1660, "pr_title": "GG-31094: cluster wide collection", "pr_createdAt": "2020-12-16T14:10:59Z", "pr_url": "https://github.com/gridgain/gridgain/pull/1660", "merge_commit": "baf94dd2b9a49d96b7043541aa6268320cdb908f", "timeline": [{"oid": "c377675f4b2c1e0fe9c21750f3891a4b6ec3efc7", "url": "https://github.com/gridgain/gridgain/commit/c377675f4b2c1e0fe9c21750f3891a4b6ec3efc7", "message": "GG-31027: Statistics storage implementation", "committedDate": "2020-11-23T13:55:33Z", "type": "commit"}, {"oid": "fdd5a74c4ee6c1509a5f2115fef9af91801580ce", "url": "https://github.com/gridgain/gridgain/commit/fdd5a74c4ee6c1509a5f2115fef9af91801580ce", "message": "Merge remote-tracking branch 'gridgain-ce/master' into gg-31027", "committedDate": "2020-11-23T16:17:37Z", "type": "commit"}, {"oid": "652ab10b366070d91d2396b14dfc2cfad786f99f", "url": "https://github.com/gridgain/gridgain/commit/652ab10b366070d91d2396b14dfc2cfad786f99f", "message": "GG-31027: minor autotests fixes", "committedDate": "2020-11-24T10:56:39Z", "type": "commit"}, {"oid": "9d2c6da3e88e433b45d16a8df9e6c6e9393de01a", "url": "https://github.com/gridgain/gridgain/commit/9d2c6da3e88e433b45d16a8df9e6c6e9393de01a", "message": "GG-31094: add messages to collect and clear statistics cluster wide.", "committedDate": "2020-12-07T13:56:53Z", "type": "commit"}, {"oid": "593ddab1a7c8c9eb84af8c04e252381a5edae79b", "url": "https://github.com/gridgain/gridgain/commit/593ddab1a7c8c9eb84af8c04e252381a5edae79b", "message": "GG-31094: cluster wide statistics collection routine", "committedDate": "2020-12-16T14:05:25Z", "type": "commit"}, {"oid": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "url": "https://github.com/gridgain/gridgain/commit/3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "message": "GG-31094: small fixes", "committedDate": "2020-12-16T14:20:44Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTM3MTg1Mw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545371853", "body": "FYI: You can try IntMap instead of HashMap for per-partition stats. It can be a bit more efficient.", "bodyText": "FYI: You can try IntMap instead of HashMap for per-partition stats. It can be a bit more efficient.", "bodyHTML": "<p dir=\"auto\">FYI: You can try IntMap instead of HashMap for per-partition stats. It can be a bit more efficient.</p>", "author": "AMashenkov", "createdAt": "2020-12-17T20:08:57Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsInMemoryStoreImpl.java", "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteLogger;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Sql statistics storage in metastore.\n+ * Will store all statistics related objects with prefix \"stats.\"\n+ * Store only partition level statistics.\n+ */\n+public class IgniteStatisticsInMemoryStoreImpl implements IgniteStatisticsStore {\n+    /** Table -> Partition -> Partition Statistics map, populated only on server nodes without persistence enabled. */\n+    private final Map<StatsKey, Map<Integer, ObjectPartitionStatisticsImpl>> partsStats = new ConcurrentHashMap<>();\n+", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTY4NzM3MQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545687371", "bodyText": "Ok, fixed.", "author": "Berkof", "createdAt": "2020-12-18T09:08:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTM3MTg1Mw=="}], "type": "inlineReview", "revised_code": {"commit": "d8c6c6bb46b36bf8d36a0578e7c1813e04bfabfe", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsInMemoryStoreImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsInMemoryStoreImpl.java\nindex b38221d6051..8c3ddbefa60 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsInMemoryStoreImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsInMemoryStoreImpl.java\n", "chunk": "@@ -34,7 +37,7 @@ import java.util.stream.Collectors;\n  */\n public class IgniteStatisticsInMemoryStoreImpl implements IgniteStatisticsStore {\n     /** Table -> Partition -> Partition Statistics map, populated only on server nodes without persistence enabled. */\n-    private final Map<StatsKey, Map<Integer, ObjectPartitionStatisticsImpl>> partsStats = new ConcurrentHashMap<>();\n+    private final Map<StatsKey, IntMap<ObjectPartitionStatisticsImpl>> partsStats = new ConcurrentHashMap<>();\n \n     /** Logger. */\n     private final IgniteLogger log;\n", "next_change": {"commit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsInMemoryStoreImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsInMemoryStoreImpl.java\nindex 8c3ddbefa60..ec72f041551 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsInMemoryStoreImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsInMemoryStoreImpl.java\n", "chunk": "@@ -37,7 +33,7 @@ import java.util.stream.Collectors;\n  */\n public class IgniteStatisticsInMemoryStoreImpl implements IgniteStatisticsStore {\n     /** Table -> Partition -> Partition Statistics map, populated only on server nodes without persistence enabled. */\n-    private final Map<StatsKey, IntMap<ObjectPartitionStatisticsImpl>> partsStats = new ConcurrentHashMap<>();\n+    private final Map<StatisticsKey, IntMap<ObjectPartitionStatisticsImpl>> partsStats = new ConcurrentHashMap<>();\n \n     /** Logger. */\n     private final IgniteLogger log;\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTM3Nzg5NQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545377895", "body": "Let's move this method to the listener object, like it is done for nodeLeft event.", "bodyText": "Let's move this method to the listener object, like it is done for nodeLeft event.", "bodyHTML": "<p dir=\"auto\">Let's move this method to the listener object, like it is done for nodeLeft event.</p>", "author": "AMashenkov", "createdAt": "2020-12-17T20:19:21Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -278,4 +739,349 @@ private ObjectStatisticsImpl aggregateLocalStatistics(\n \n         return tblStats;\n     }\n+\n+    /**\n+     * Receive and handle statistics propagation message with partitions statistics.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receivePartitionsStatistics(UUID nodeId, StatsPropagationMessage msg) throws IgniteCheckedException {\n+        UUID locNode = ctx.discovery().localNode().id();\n+        for (StatsObjectData partData : msg.data()) {\n+            StatsKey key = new StatsKey(partData.key().schema(), partData.key().obj());\n+\n+            assert partData.type() == StatsType.PARTITION : \"Got non partition level statistics by \" + key\n+                    + \" without request\";\n+\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d from node %s\", key.schema(),\n+                        key.obj(), partData.partId(), nodeId));\n+\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(locNode, partData.partId());\n+            if (partState != OWNING) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+\n+            ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n+\n+            statsRepos.saveLocalPartitionStatistics(key, opStat);\n+        }\n+    }\n+\n+    /**\n+     * Receive and handle statistics propagation message as response for collection request.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receiveLocalStatistics(UUID nodeId, StatsCollectionResponse msg) {\n+        assert msg.data().keySet().stream().noneMatch(pd -> pd.type() == StatsType.PARTITION)\n+                : \"Got partition statistics by request \" + msg.reqId();\n+\n+        /**currCollections.compute(msg.reqId(), (k, v) -> {\n+            if (v == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring outdated local statistics collection response from node %s to req %s\",\n+                            nodeId, msg.reqId()));\n+\n+                return null;\n+            }\n+\n+            assert msg.reqId().equals(v.reqId);\n+\n+            boolean rmv = v.remainingNodes.remove(nodeId);\n+            if (!rmv) {\n+                log.warning(String.format(\"Ignoring statistics propagation message from unexpected node %s by request %s.\",\n+                        nodeId, v.reqId));\n+\n+                return v;\n+            }\n+\n+            v.locStatistics.add(msg);\n+\n+            if (v.remainingNodes.isEmpty()) {\n+                aggregateCollected(v);\n+\n+                return null;\n+            }\n+\n+            return v;\n+        });**/\n+    }\n+\n+    /**\n+     * Send statistics by request.\n+     *\n+     * @param nodeId Node to send statistics to.\n+     * @param msg Statistics request to process.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void supplyStatistics(UUID nodeId, StatsGetRequest msg) throws IgniteCheckedException {\n+        List<StatsObjectData> data = new ArrayList<>(msg.keys().size());\n+        for (StatsKeyMessage keyMsg : msg.keys()) {\n+            StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+            ObjectStatisticsImpl objStats = statsRepos.getGlobalStatistics(key);\n+\n+            if (objStats != null)\n+                data.add(StatisticsUtils.toObjectData(keyMsg, StatsType.GLOBAL, objStats));\n+        }\n+        StatsPropagationMessage res = new StatsPropagationMessage(data);\n+        ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n+\n+        /**List<StatsObjectData> data = new ArrayList<>();\n+        for (StatsKeyMessage key : msg.keys()) {\n+            StatsKey statsKey = new StatsKey(key.schema(), key.obj());\n+            ObjectStatisticsImpl objStats = statsRepos.getGlobalStatistics(statsKey);\n+\n+            if (objStats != null)\n+                data.add(StatisticsUtils.toMessage(statsKey, StatsType.GLOBAL, objStats));\n+        }\n+\n+        StatsPropagationMessage res = new StatsPropagationMessage(msg.reqId(), data);\n+        ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);**/\n+    }\n+\n+    private void cancelStatisticsCollection(UUID nodeId, CancelStatsCollectionRequest msg) {\n+        currCollections.updateCollection(msg.colId(), stat -> {\n+            stat.doneFut().cancel();\n+            return null;\n+        });\n+        /*StatCollectionStatus currState = currCollections.remove(msg.reqId());\n+        if (currState != null) {\n+            if (log.isDebugEnabled())\n+                log.debug(String.format(\"Cancelling statistics collection by reqId = %s from node %s\", msg.reqId(),\n+                        nodeId));\n+\n+            currState.doneFut().cancel();\n+        } else\n+        if (log.isDebugEnabled())\n+            log.debug(String.format(\"Unable to cancel staitstics collection by req = %s from node %s\", msg.reqId(),\n+                    nodeId));*/\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void onMessage(UUID nodeId, Object msg, byte plc) {", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTY4OTIxNw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545689217", "bodyText": "Why? It handle a lot of messages not related with topology change: cancel request, collect request, stas propagation and so on.", "author": "Berkof", "createdAt": "2020-12-18T09:10:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTM3Nzg5NQ=="}], "type": "inlineReview", "revised_code": {"commit": "ec4a9ef0e7691b605225c12527d496d07d573b42", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex ca50e8e339b..aa95be0231f 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -856,22 +949,30 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n         ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);**/\n     }\n \n+    /**\n+     * Cacel local statistics collection task.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Cancel request.\n+     */\n     private void cancelStatisticsCollection(UUID nodeId, CancelStatsCollectionRequest msg) {\n         currCollections.updateCollection(msg.colId(), stat -> {\n+            if (stat == null) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Unable to cancel statistics collection %s by req %s from node %s\",\n+                            msg.colId(), msg.reqId(), nodeId));\n+\n+                return null;\n+            }\n+\n             stat.doneFut().cancel();\n-            return null;\n-        });\n-        /*StatCollectionStatus currState = currCollections.remove(msg.reqId());\n-        if (currState != null) {\n+\n             if (log.isDebugEnabled())\n                 log.debug(String.format(\"Cancelling statistics collection by reqId = %s from node %s\", msg.reqId(),\n                         nodeId));\n \n-            currState.doneFut().cancel();\n-        } else\n-        if (log.isDebugEnabled())\n-            log.debug(String.format(\"Unable to cancel staitstics collection by req = %s from node %s\", msg.reqId(),\n-                    nodeId));*/\n+            return null;\n+        });\n     }\n \n     /** {@inheritDoc} */\n", "next_change": {"commit": "b69634fd8544d7b27bd76f84bdee9a1e4f0ac470", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex aa95be0231f..e0108f8302d 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -956,23 +967,25 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n      * @param msg Cancel request.\n      */\n     private void cancelStatisticsCollection(UUID nodeId, CancelStatsCollectionRequest msg) {\n-        currCollections.updateCollection(msg.colId(), stat -> {\n-            if (stat == null) {\n-                if (log.isDebugEnabled())\n-                    log.debug(String.format(\"Unable to cancel statistics collection %s by req %s from node %s\",\n-                            msg.colId(), msg.reqId(), nodeId));\n+        for (UUID reqId : msg.reqIds()) {\n+            currCollections.updateCollection(reqId, stat -> {\n+                if (stat == null) {\n+                    if (log.isDebugEnabled())\n+                        log.debug(String.format(\"Unable to cancel statistics collection %s by req %s from node %s\",\n+                                msg.colId(), reqId, nodeId));\n \n-                return null;\n-            }\n+                    return null;\n+                }\n \n-            stat.doneFut().cancel();\n+                stat.doneFut().cancel();\n \n-            if (log.isDebugEnabled())\n-                log.debug(String.format(\"Cancelling statistics collection by reqId = %s from node %s\", msg.reqId(),\n-                        nodeId));\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Cancelling statistics collection by colId = %s, reqId = %s from node %s\",\n+                            msg.colId(), reqId, nodeId));\n \n-            return null;\n-        });\n+                return null;\n+            });\n+        }\n     }\n \n     /** {@inheritDoc} */\n", "next_change": {"commit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex e0108f8302d..f208a744d01 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -922,108 +440,35 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n                 continue;\n             }\n             ObjectStatisticsImpl globalStat = aggregateLocalStatistics(keyMsg, keyStats.getValue());\n-            StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+            StatisticsKey key = new StatisticsKey(keyMsg.schema(), keyMsg.obj());\n             res.put(key, statsRepos.mergeGlobalStatistics(key, globalStat));\n         }\n         return res;\n     }\n \n     /**\n-     * Send statistics by request.\n-     *\n-     * @param nodeId Node to send statistics to.\n-     * @param msg Statistics request to process.\n-     * @throws IgniteCheckedException In case of errors.\n-     */\n-    private void supplyStatistics(UUID nodeId, StatsGetRequest msg) throws IgniteCheckedException {\n-        List<StatsObjectData> data = new ArrayList<>(msg.keys().size());\n-        for (StatsKeyMessage keyMsg : msg.keys()) {\n-            StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n-            ObjectStatisticsImpl objStats = statsRepos.getGlobalStatistics(key);\n-\n-            if (objStats != null)\n-                data.add(StatisticsUtils.toObjectData(keyMsg, StatsType.GLOBAL, objStats));\n-        }\n-        StatsPropagationMessage res = new StatsPropagationMessage(data);\n-        ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n-\n-        /**List<StatsObjectData> data = new ArrayList<>();\n-        for (StatsKeyMessage key : msg.keys()) {\n-            StatsKey statsKey = new StatsKey(key.schema(), key.obj());\n-            ObjectStatisticsImpl objStats = statsRepos.getGlobalStatistics(statsKey);\n-\n-            if (objStats != null)\n-                data.add(StatisticsUtils.toMessage(statsKey, StatsType.GLOBAL, objStats));\n-        }\n-\n-        StatsPropagationMessage res = new StatsPropagationMessage(msg.reqId(), data);\n-        ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);**/\n-    }\n-\n-    /**\n-     * Cacel local statistics collection task.\n+     * Get global statistics by key.\n      *\n-     * @param nodeId Sender node id.\n-     * @param msg Cancel request.\n+     * @param key Key to get statistics by.\n+     * @return Global statistics or {@code null} if there are no statistics for specified key.\n      */\n-    private void cancelStatisticsCollection(UUID nodeId, CancelStatsCollectionRequest msg) {\n-        for (UUID reqId : msg.reqIds()) {\n-            currCollections.updateCollection(reqId, stat -> {\n-                if (stat == null) {\n-                    if (log.isDebugEnabled())\n-                        log.debug(String.format(\"Unable to cancel statistics collection %s by req %s from node %s\",\n-                                msg.colId(), reqId, nodeId));\n-\n-                    return null;\n-                }\n+   public ObjectStatisticsImpl getGlobalStatistics(StatisticsKeyMessage key) {\n+        ObjectStatisticsImpl stat = statsRepos.getGlobalStatistics(new StatisticsKey(key.schema(), key.obj()));\n+        if (stat != null && !F.isEmpty(key.colNames()))\n+            stat = IgniteStatisticsHelper.filterColumns(stat, key.colNames());\n \n-                stat.doneFut().cancel();\n-\n-                if (log.isDebugEnabled())\n-                    log.debug(String.format(\"Cancelling statistics collection by colId = %s, reqId = %s from node %s\",\n-                            msg.colId(), reqId, nodeId));\n-\n-                return null;\n-            });\n-        }\n-    }\n-\n-    /** {@inheritDoc} */\n-    @Override public void onMessage(UUID nodeId, Object msg, byte plc) {\n-        try {\n-            if (msg instanceof StatsPropagationMessage)\n-                receivePartitionsStatistics(nodeId, (StatsPropagationMessage) msg);\n-            else if (msg instanceof StatsCollectionResponse)\n-                receiveLocalStatistics(nodeId, (StatsCollectionResponse) msg);\n-            else if (msg instanceof StatsGetRequest)\n-                supplyStatistics(nodeId, (StatsGetRequest) msg);\n-            else if (msg instanceof StatsCollectionRequest)\n-                handleCollectionRequest(nodeId, (StatsCollectionRequest)msg);\n-            else if (msg instanceof CancelStatsCollectionRequest)\n-                cancelStatisticsCollection(nodeId, (CancelStatsCollectionRequest) msg);\n-            else if (msg instanceof StatsClearRequest)\n-                clearObjectStatistics(nodeId, (StatsClearRequest)msg);\n-            else\n-                log.warning(\"Unknown msg \" + msg +  \" in statistics topic \" + TOPIC + \" from node \" + nodeId);\n-        } catch (IgniteCheckedException e) {\n-            log.warning(\"Statistic msg from node \" + nodeId + \" processing failed\", e);\n-        }\n-    }\n+        return stat;\n+   }\n \n     /**\n-     * Handle statistics clear request.\n+     * Clear object statistics by specified keys.\n      *\n-     * @param nodeId UUID of request sender node.\n-     * @param msg Clear request message.\n+     * @param keys Collection of keys to clean statistics by.\n      */\n-    private void clearObjectStatistics(UUID nodeId, StatsClearRequest msg) {\n-        for (StatsKeyMessage key : msg.keys()) {\n-            if (log.isTraceEnabled())\n-                log.trace(String.format(\"Clearing statistics by request %s from node %s by key %s.%s\", msg.reqId(),\n-                        nodeId, key.schema(), key.obj()));\n-            statMgmtPool.submit(() -> clearObjectStatisticsLocal(key));\n-        }\n-    }\n+   public void clearObjectStatisticsLocal(Collection<StatisticsKeyMessage> keys) {\n+       for (StatisticsKeyMessage key : keys)\n+           clearObjectStatisticsLocal(key);\n+   }\n \n     /**\n      * Collect local object statistics by specified request (possibly for a few objects) and send result back to origin\n", "next_change": {"commit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex f208a744d01..1f98ad5ca73 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -476,7 +514,7 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n      *\n      * @param req request to collect statistics by.\n      */\n-    private void processLocal(UUID nodeId, StatisticsGatheringRequest req) {\n+    /*private void processLocal(UUID nodeId, StatisticsGatheringRequest req) {\n         UUID locNode = ctx.localNodeId();\n \n         StatisticsGatheringContext stat = (nodeId.equals(locNode)) ? helper.getCollection(req.gatId()) :\n", "next_change": {"commit": "e54c934091d0917505fbe4bd919fd766a492897e", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 1f98ad5ca73..c989b5605e7 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -507,59 +487,4 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n        for (StatisticsKeyMessage key : keys)\n            clearObjectStatisticsLocal(key);\n    }\n-\n-    /**\n-     * Collect local object statistics by specified request (possibly for a few objects) and send result back to origin\n-     * node specified. If local node id specified - process result without sending it throw the communication.\n-     *\n-     * @param req request to collect statistics by.\n-     */\n-    /*private void processLocal(UUID nodeId, StatisticsGatheringRequest req) {\n-        UUID locNode = ctx.localNodeId();\n-\n-        StatisticsGatheringContext stat = (nodeId.equals(locNode)) ? helper.getCollection(req.gatId()) :\n-            helper.getCollection(req.reqId());\n-\n-        if (stat == null)\n-            return;\n-\n-        Map<StatisticsObjectData, int[]> collected = new HashMap<>(req.keys().size());\n-        for (Map.Entry<StatisticsKeyMessage, int[]> keyEntry : req.keys().entrySet()) {\n-            try {\n-                StatisticsKeyMessage key = keyEntry.getKey();\n-                IgniteBiTuple <ObjectStatisticsImpl, int[]> loStat = gatherLocalObjectStatisticsAsync(key,\n-                        keyEntry.getValue(), () -> stat.doneFut().isCancelled());\n-                StatisticsKey statsKey = new StatisticsKey(key.schema(), key.obj());\n-\n-                // TODO?\n-                statsRepos.mergeLocalStatistics(statsKey, loStat.getKey());\n-\n-                StatisticsObjectData objData = StatisticsUtils.toObjectData(key, StatisticsType.LOCAL, loStat.getKey());\n-                collected.put(objData, loStat.getValue());\n-            }\n-            catch (IgniteCheckedException e) {\n-                log.warning(String.format(\"Unable to complete request %s due to error %s\", req.reqId(), e.getMessage()));\n-                // TODO: send cancel to originator node\n-            }\n-        }\n-\n-        StatisticsGatheringResponse res = new StatisticsGatheringResponse(req.gatId(), req.reqId(), collected);\n-\n-        if (locNode.equals(nodeId))\n-            receiveLocalStatistics(nodeId, res);\n-        else {\n-            try {\n-                ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n-            }\n-            catch (IgniteCheckedException e) {\n-                if (log.isDebugEnabled())\n-                    log.debug(String.format(\n-                            \"Unable to send statistics collection result to node %s in response to colId %s, reqId %s\",\n-                        nodeId, req.gatId(), req.reqId()));\n-            }\n-\n-            // Not local collection - remove by its reqId.\n-            helper.updateCollection(req.reqId(), s -> null);\n-        }\n-    }*/\n }\n", "next_change": {"commit": "33170812024f6c4d321f85287fea0b6c3abdb9e5", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex c989b5605e7..5011b1a87a5 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -478,13 +458,20 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n         return stat;\n    }\n \n+    /** {@inheritDoc} */\n+    @Override public ObjectStatistics getGlobalStatistics(String schemaName, String objName) {\n+        return statsRepos.getGlobalStatistics(new StatisticsKey(schemaName, objName));\n+    }\n+\n     /**\n-     * Clear object statistics by specified keys.\n+     * Check that all server nodes in the cluster support STATISTICS_COLLECTION features.\n      *\n-     * @param keys Collection of keys to clean statistics by.\n+     * @param op Operation name.\n      */\n-   public void clearObjectStatisticsLocal(Collection<StatisticsKeyMessage> keys) {\n-       for (StatisticsKeyMessage key : keys)\n-           clearObjectStatisticsLocal(key);\n+   private void checkSupport(String op) throws IgniteCheckedException {\n+       if (!IgniteFeatures.allNodesSupport(ctx, IgniteFeatures.STATISTICS_COLLECTION, IgniteDiscoverySpi.SRV_NODES)) {\n+           throw new IgniteCheckedException(String.format(\n+               \"Unable to perform %s due to not all server nodes supports STATISTICS_COLLECTION feature.\", op));\n+       }\n    }\n }\n", "next_change": {"commit": "f5aafee54b1036c09d4944ca9bf0254f8bfd2b1e", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 5011b1a87a5..4df3ed6f1e0 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -464,11 +485,13 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n     }\n \n     /**\n-     * Check that all server nodes in the cluster support STATISTICS_COLLECTION features.\n+     * Check that all server nodes in the cluster support STATISTICS_COLLECTION feature. Throws IgniteCheckedException\n+     * in not.\n      *\n      * @param op Operation name.\n+     * @throws IgniteCheckedException If at least one server node doesn't support feature.\n      */\n-   private void checkSupport(String op) throws IgniteCheckedException {\n+   private void checkStatisticsSupport(String op) throws IgniteCheckedException {\n        if (!IgniteFeatures.allNodesSupport(ctx, IgniteFeatures.STATISTICS_COLLECTION, IgniteDiscoverySpi.SRV_NODES)) {\n            throw new IgniteCheckedException(String.format(\n                \"Unable to perform %s due to not all server nodes supports STATISTICS_COLLECTION feature.\", op));\n", "next_change": {"commit": "65caf2d646409c3be32c4d00f762fcdc7ec4ceb0", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 4df3ed6f1e0..47277987f34 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -492,9 +492,18 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n      * @throws IgniteCheckedException If at least one server node doesn't support feature.\n      */\n    private void checkStatisticsSupport(String op) throws IgniteCheckedException {\n-       if (!IgniteFeatures.allNodesSupport(ctx, IgniteFeatures.STATISTICS_COLLECTION, IgniteDiscoverySpi.SRV_NODES)) {\n+       if (!isStatisticsSupport()) {\n            throw new IgniteCheckedException(String.format(\n                \"Unable to perform %s due to not all server nodes supports STATISTICS_COLLECTION feature.\", op));\n        }\n    }\n+\n+    /**\n+     * Test is statistics collection feature are supported by each server node in cluster.\n+     *\n+     * @return {@code true} if all server nodes support STATISTICS_COLLECTION feature, {@code false} - otherwise.\n+     */\n+   private boolean isStatisticsSupport() {\n+       return IgniteFeatures.allNodesSupport(ctx, IgniteFeatures.STATISTICS_COLLECTION, IgniteDiscoverySpi.SRV_NODES);\n+   }\n }\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQyNzMzOA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545427338", "body": "Why is colNames a part of StatsKeyMessage, but not a part of StatsKey?\r\n", "bodyText": "Why is colNames a part of StatsKeyMessage, but not a part of StatsKey?", "bodyHTML": "<p dir=\"auto\">Why is colNames a part of StatsKeyMessage, but not a part of StatsKey?</p>", "author": "AMashenkov", "createdAt": "2020-12-17T21:53:03Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -89,86 +157,468 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+\n+        UUID reqId = UUID.randomUUID();\n+        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        Map<UUID, List<Integer>> requestNodes = null;\n+        /*try {\n+            requestNodes = nodePartitions(extractGroups(Collections.singletonList(keyMsg)), null);\n+        } catch (IgniteCheckedException e) {\n+            // TODO: handle & remove task\n+        }\n+\n+        StatsClearRequest req = new StatsClearRequest(reqId, false, Collections.singletonList(keyMsg));\n+\n+        sendLocalRequests(reqId, req, requestNodes);*/\n+\n+        clearObjectStatisticsLocal(keyMsg);\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatsKeyMessage keyMsg) {\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTY5MDQwOQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545690409", "bodyText": "Because we store statistics by object, aquire statistics by whole object, but we can send request to collect statistics by only some of the tables columns.", "author": "Berkof", "createdAt": "2020-12-18T09:11:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQyNzMzOA=="}], "type": "inlineReview", "revised_code": {"commit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex ca50e8e339b..f208a744d01 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -186,8 +195,8 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n      *\n      * @param keyMsg Key to clear statistics by.\n      */\n-    private void clearObjectStatisticsLocal(StatsKeyMessage keyMsg) {\n-        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+    private void clearObjectStatisticsLocal(StatisticsKeyMessage keyMsg) {\n+        StatisticsKey key = new StatisticsKey(keyMsg.schema(), keyMsg.obj());\n         String[] colNames = keyMsg.colNames().toArray(new String[0]);\n \n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQzNDcwNw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545434707", "body": "Statistic is collected by a 'key' not by a 'message', right?", "bodyText": "Statistic is collected by a 'key' not by a 'message', right?", "bodyHTML": "<p dir=\"auto\">Statistic is collected by a 'key' not by a 'message', right?</p>", "author": "AMashenkov", "createdAt": "2020-12-17T22:07:47Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -89,86 +157,468 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+\n+        UUID reqId = UUID.randomUUID();\n+        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        Map<UUID, List<Integer>> requestNodes = null;\n+        /*try {\n+            requestNodes = nodePartitions(extractGroups(Collections.singletonList(keyMsg)), null);\n+        } catch (IgniteCheckedException e) {\n+            // TODO: handle & remove task\n+        }\n+\n+        StatsClearRequest req = new StatsClearRequest(reqId, false, Collections.singletonList(keyMsg));\n+\n+        sendLocalRequests(reqId, req, requestNodes);*/\n+\n+        clearObjectStatisticsLocal(keyMsg);\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatsKeyMessage keyMsg) {\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n+    // TODO\n+    /**\n+     * Collect local object statistics by primary partitions of specified object.\n+     *\n+     * @param keyMsg Statistic key message to collect statistics by.", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTY5MjA1Mg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545692052", "bodyText": "No, we just store and aquire statistics by whole object (by StatsKey), but we can collect and clear it with column granularity (by StatsKeyMessage).", "author": "Berkof", "createdAt": "2020-12-18T09:13:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQzNDcwNw=="}], "type": "inlineReview", "revised_code": {"commit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex ca50e8e339b..f208a744d01 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -195,182 +204,16 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n-    // TODO\n-    /**\n-     * Collect local object statistics by primary partitions of specified object.\n-     *\n-     * @param keyMsg Statistic key message to collect statistics by.\n-     * @param partIds Set of partition ids to collect statistics by.\n-     * @param cancelled Supplier to check if operation was cancelled.\n-     * @return Tuple of Collected local statistics with array of successfully collected partitions.\n-     * @throws IgniteCheckedException\n-     */\n-    private IgniteBiTuple<ObjectStatisticsImpl, int[]> collectLocalObjectStatistics(\n-            StatsKeyMessage keyMsg,\n-            int[] partIds,\n-            Supplier<Boolean> cancelled\n-    ) throws IgniteCheckedException {\n-        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n-        if (tbl == null)\n-            throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", keyMsg.schema(), keyMsg.obj()));\n-\n-        Column[] selectedCols = filterColumns(tbl.getColumns(), keyMsg.colNames());\n-\n-        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, partIds, selectedCols,\n-                cancelled);\n-        if (partsStats == null) {\n-            assert cancelled.get() : \"Error collecting partition level statistics.\";\n-\n-            return null;\n-        }\n-\n-        sendPartStatsToBU(tbl, partsStats);\n-\n-        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n-        statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n-\n-        ObjectStatisticsImpl tblStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n-        statsRepos.mergeLocalStatistics(key, tblStats);\n-\n-        return new IgniteBiTuple(tblStats, partsStats.stream().map(ObjectPartitionStatisticsImpl::partId).toArray());\n-    }\n-\n     /**\n-     * Send statistics propagation messages with partition statistics to all backups node.\n+     * Collect object statistics prepared status.\n      *\n-     * @param tbl Table to which statistics should be send.\n-     * @param objStats Collection of partition statistics to send.\n+     * @param status Collection status to collect statistics by.\n      * @throws IgniteCheckedException In case of errors.\n      */\n-    private void sendPartStatsToBU(\n-            GridH2Table tbl,\n-            Collection<ObjectPartitionStatisticsImpl> objStats\n-    ) throws IgniteCheckedException {\n-        UUID locNode = ctx.discovery().localNode().id();\n-        StatsKeyMessage keyMsg = new StatsKeyMessage(tbl.identifier().schema(), tbl.identifier().table(), null);\n-        GridDhtPartitionTopology topology = tbl.cacheContext().topology();\n-        Map<UUID, List<StatsObjectData>> statsByNodes = new HashMap<>();\n-        for (ObjectPartitionStatisticsImpl stat : objStats) {\n-            StatsObjectData statData = StatisticsUtils.toObjectData(keyMsg, StatsType.PARTITION, stat);\n-            for (ClusterNode partNode : topology.nodes(stat.partId(), topology.readyTopologyVersion())) {\n-                if (locNode.equals(partNode.id()))\n-                    continue;\n-\n-                statsByNodes.compute(partNode.id(), (k, v) -> {\n-                    if (v == null)\n-                        v = new ArrayList<>();\n-\n-                    v.add(statData);\n-\n-                    return v;\n-                });\n-            }\n-        }\n-\n-        for (Map.Entry <UUID, List<StatsObjectData>> statToNode : statsByNodes.entrySet()) {\n-            //StatsPropagationMessage nodeMsg = StatisticsUtils.toMessage(null, statToNode.getValue());\n-\n-            //ctx.io().sendToCustomTopic(statToNode.getKey(), TOPIC, nodeMsg, GridIoPolicy.QUERY_POOL);\n-        }\n-    }\n-\n-    /**\n-     * Group local statistics by table and columns.\n-     *\n-     * @param status statistics collection status with all necessary local statistics.\n-     * @return map of tables to columns to list of local column statistics.\n-     */\n-    private Map<GridH2Table, Map<String, List<ColumnStatistics>>> groupColumnStatistics(StatCollectionStatus status) {\n-        /*Map<GridH2Table, Map<String, List<ColumnStatistics>>> result = new HashMap<>();\n-        for (StatsPropagationMessage msg : status.locStatistics) {\n-            for (StatsObjectData msgData : msg.data()) {\n-                GridH2Table dataTable = schemaMgr.dataTable(msgData.key().schema(), msgData.key().obj());\n-                if (dataTable == null) {\n-                    log.warning(String.format(\"Can't find table for received statistics: %s %s\", msgData.key().schema(),\n-                            msgData.key().obj()));\n-\n-                    continue;\n-                }\n-\n-                result.compute(dataTable, (table, columns) -> {\n-                    if (columns == null)\n-                        columns = new HashMap<>();\n-\n-                    for (Map.Entry<String, StatsColumnData> colData : msgData.data().entrySet())\n-                        columns.compute(colData.getKey(), (colName, colStatistics) -> {\n-                            if (colStatistics == null)\n-                                colStatistics = new ArrayList<>();\n-\n-                            ColumnStatistics colStat;\n-                            try {\n-                                colStat = StatisticsUtils.toColumnStatistics(ctx, colData.getValue());\n-                                colStatistics.add(colStat);\n-                            }\n-                            catch (IgniteCheckedException e) {\n-                                log.warning(String. format(\"Error while converting column statistics %s.%s - %s\",\n-                                        msgData.key().schema(), msgData.key().obj(), colName));\n-                            }\n-                            return colStatistics;\n-                        });\n-                    return columns;\n-                });\n-            }\n-        }\n-        return result;\n-        */\n-        return null;\n-    }\n-\n-    /**\n-     * Will aggregate all received local statistics and save it.\n-     *\n-     * @param request aggregation request with id only.\n-     */\n-    private void aggregateCollected(StatCollectionStatus status) {\n-        /*// Table -> Column -> List of local column stats\n-        Map<GridH2Table, Map<String, List<ColumnStatistics>>> tablesData = groupColumnStatistics(status);\n-\n-        Map<ClusterNode, List<StatsObjectData>> dataByNodes = new HashMap<>();\n-        for (Map.Entry<GridH2Table, Map<String, List<ColumnStatistics>>> tableStats : tablesData.entrySet()) {\n-            GridH2Table table = tableStats.getKey();\n-            long rowCount = 0L;\n-            Map<String, ColumnStatistics> columnStatistics = new HashMap<>();\n-            for (Map.Entry<String, List<ColumnStatistics>> columnStats : tableStats.getValue().entrySet()) {\n-                ColumnStatistics globalStatistics = ColumnStatisticsCollector\n-                        .aggregate(table::compareValues, columnStats.getValue());\n-                if (rowCount < globalStatistics.total())\n-                    rowCount = globalStatistics.total();\n-                columnStatistics.put(columnStats.getKey(), globalStatistics);\n-            }\n-\n-            ObjectStatisticsImpl objectStatistics = new ObjectStatisticsImpl(rowCount, columnStatistics);\n-            statsRepos.saveGlobalStatistics(new StatsKey(table.identifier().schema(), table.identifier().table()),\n-                    objectStatistics);\n-        }\n-        status.doneFut.onDone();\n-        */\n-\n-    }\n-\n-    /**\n-     * Filter columns by specified names.\n-     *\n-     * @param cols Columns to filter.\n-     * @param colNames Column names.\n-     * @return Column with specified names.\n-     */\n-    private Column[] filterColumns(Column[] cols, @Nullable Collection<String> colNames) {\n-        if (F.isEmpty(colNames))\n-            return cols;\n-\n-        Set<String> colNamesSet = new HashSet(Arrays.asList(colNames));\n-        List<Column> resList = new ArrayList<>(colNames.size());\n+    private void collectObjectStatistics(StatisticsGatheringContext status) throws IgniteCheckedException {\n \n-        for (Column col : cols)\n-            if (colNamesSet.contains(col.getName()))\n-                resList.add(col);\n+        statRouter.sendGatheringRequestsAsync(status.gatId(), status.keys());\n \n-        return resList.toArray(new Column[resList.size()]);\n     }\n \n     /** {@inheritDoc} */\n", "next_change": {"commit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex f208a744d01..1f98ad5ca73 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -211,9 +235,25 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n      * @throws IgniteCheckedException In case of errors.\n      */\n     private void collectObjectStatistics(StatisticsGatheringContext status) throws IgniteCheckedException {\n+        statCrawler.sendGatheringRequestsAsync(status.gatId(), status.keys());\n+    }\n \n-        statRouter.sendGatheringRequestsAsync(status.gatId(), status.keys());\n+    /**\n+     * Calculate total partitions count for all keys in gathering task.\n+     *\n+     * @param keys Collection of keys to calculate partitions by.\n+     * @return Total number of partitions in all tasks keys.\n+     */\n+    private Integer calculatePartitions(Collection<StatisticsKeyMessage> keys) {\n+        int res = 0;\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                return null;\n \n+            res += tbl.cacheContext().topology().partitions();\n+        }\n+        return res;\n     }\n \n     /** {@inheritDoc} */\n", "next_change": {"commit": "7ef165002105dd10417170217e86d65771c524bb", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 1f98ad5ca73..4e5949c6399 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -262,9 +261,15 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n             String objName,\n             String... colNames\n     ) throws IgniteCheckedException {\n+\n         StatisticsKeyMessage keyMsg = new StatisticsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n-        StatisticsGatheringContext status = new StatisticsGatheringContext(Collections.singleton(keyMsg));\n+        CacheGroupContext grpCtx = helper.getGroupContext(keyMsg);\n+\n+        StatisticsGatheringContext status = new StatisticsGatheringContext(UUID.randomUUID(),\n+            Collections.singleton(keyMsg), grpCtx.topology().partitions());\n+\n         currColls.put(status.gatId(), status);\n+\n         collectObjectStatistics(status);\n \n         status.doneFut().get();\n", "next_change": {"commit": "33170812024f6c4d321f85287fea0b6c3abdb9e5", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 4e5949c6399..5011b1a87a5 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -234,45 +219,25 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n      * @throws IgniteCheckedException In case of errors.\n      */\n     private void collectObjectStatistics(StatisticsGatheringContext status) throws IgniteCheckedException {\n-        statCrawler.sendGatheringRequestsAsync(status.gatId(), status.keys(), null);\n-    }\n-\n-    /**\n-     * Calculate total partitions count for all keys in gathering task.\n-     *\n-     * @param keys Collection of keys to calculate partitions by.\n-     * @return Total number of partitions in all tasks keys.\n-     */\n-    private Integer calculatePartitions(Collection<StatisticsKeyMessage> keys) {\n-        int res = 0;\n-        for (StatisticsKeyMessage key : keys) {\n-            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n-            if (tbl == null)\n-                return null;\n-\n-            res += tbl.cacheContext().topology().partitions();\n-        }\n-        return res;\n+        statCrawler.sendGatheringRequestsAsync(status.gatheringId(), status.keys(), null);\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void collectObjectStatistics(\n-            String schemaName,\n-            String objName,\n-            String... colNames\n-    ) throws IgniteCheckedException {\n+    @Override public void gatherObjectStatistics(StatisticsTarget target) throws IgniteCheckedException {\n+        checkSupport(\"collect statistics\");\n \n-        StatisticsKeyMessage keyMsg = new StatisticsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        StatisticsKeyMessage keyMsg = new StatisticsKeyMessage(target.schema(), target.obj(),\n+            Arrays.asList(target.columns()));\n         CacheGroupContext grpCtx = helper.getGroupContext(keyMsg);\n \n         StatisticsGatheringContext status = new StatisticsGatheringContext(UUID.randomUUID(),\n             Collections.singleton(keyMsg), grpCtx.topology().partitions());\n \n-        currColls.put(status.gatId(), status);\n+        currColls.put(status.gatheringId(), status);\n \n         collectObjectStatistics(status);\n \n-        status.doneFut().get();\n+        status.doneFuture().get();\n     }\n \n     /**\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQzNTQzOA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545435438", "body": "Why do we need to pass a Cancel supplier as it look like method is executed synchronously? ", "bodyText": "Why do we need to pass a Cancel supplier as it look like method is executed synchronously?", "bodyHTML": "<p dir=\"auto\">Why do we need to pass a Cancel supplier as it look like method is executed synchronously?</p>", "author": "AMashenkov", "createdAt": "2020-12-17T22:09:18Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -89,86 +157,468 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+\n+        UUID reqId = UUID.randomUUID();\n+        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        Map<UUID, List<Integer>> requestNodes = null;\n+        /*try {\n+            requestNodes = nodePartitions(extractGroups(Collections.singletonList(keyMsg)), null);\n+        } catch (IgniteCheckedException e) {\n+            // TODO: handle & remove task\n+        }\n+\n+        StatsClearRequest req = new StatsClearRequest(reqId, false, Collections.singletonList(keyMsg));\n+\n+        sendLocalRequests(reqId, req, requestNodes);*/\n+\n+        clearObjectStatisticsLocal(keyMsg);\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatsKeyMessage keyMsg) {\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n+    // TODO\n+    /**\n+     * Collect local object statistics by primary partitions of specified object.\n+     *\n+     * @param keyMsg Statistic key message to collect statistics by.\n+     * @param partIds Set of partition ids to collect statistics by.\n+     * @param cancelled Supplier to check if operation was cancelled.\n+     * @return Tuple of Collected local statistics with array of successfully collected partitions.\n+     * @throws IgniteCheckedException\n+     */\n+    private IgniteBiTuple<ObjectStatisticsImpl, int[]> collectLocalObjectStatistics(\n+            StatsKeyMessage keyMsg,\n+            int[] partIds,\n+            Supplier<Boolean> cancelled\n+    ) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", keyMsg.schema(), keyMsg.obj()));\n+\n+        Column[] selectedCols = filterColumns(tbl.getColumns(), keyMsg.colNames());\n+\n+        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, partIds, selectedCols,\n+                cancelled);", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQzNjA0OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545436048", "bodyText": "Can statistic be calculated for partitions in parallel?", "author": "AMashenkov", "createdAt": "2020-12-17T22:10:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQzNTQzOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTY5NjQ5MQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545696491", "bodyText": "We pass cancelled to allow to cancel such collection while it works. It'll happen when CancelStatisticsCollectionRequest received. Here cancelled - is just wrapper around statistics collection status doneFuture. So to cancel collection we'll just get status from current collection map and mark it's future as cancelled (and remove status from current map so worker won't event find it there and stop request processing).", "author": "Berkof", "createdAt": "2020-12-18T09:18:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQzNTQzOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTY5OTM0MA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545699340", "bodyText": "For now - no, all collection made by single thread from IgniteStatisticsManagerImpl.statMgmtPool. Only cancel and reschedule operation can be conducted in parallel (but not for single object during synchronization). But in general - it should be possible to collect statistics in parallel.", "author": "Berkof", "createdAt": "2020-12-18T09:20:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQzNTQzOA=="}], "type": "inlineReview", "revised_code": {"commit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex ca50e8e339b..f208a744d01 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -195,182 +204,16 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n-    // TODO\n-    /**\n-     * Collect local object statistics by primary partitions of specified object.\n-     *\n-     * @param keyMsg Statistic key message to collect statistics by.\n-     * @param partIds Set of partition ids to collect statistics by.\n-     * @param cancelled Supplier to check if operation was cancelled.\n-     * @return Tuple of Collected local statistics with array of successfully collected partitions.\n-     * @throws IgniteCheckedException\n-     */\n-    private IgniteBiTuple<ObjectStatisticsImpl, int[]> collectLocalObjectStatistics(\n-            StatsKeyMessage keyMsg,\n-            int[] partIds,\n-            Supplier<Boolean> cancelled\n-    ) throws IgniteCheckedException {\n-        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n-        if (tbl == null)\n-            throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", keyMsg.schema(), keyMsg.obj()));\n-\n-        Column[] selectedCols = filterColumns(tbl.getColumns(), keyMsg.colNames());\n-\n-        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, partIds, selectedCols,\n-                cancelled);\n-        if (partsStats == null) {\n-            assert cancelled.get() : \"Error collecting partition level statistics.\";\n-\n-            return null;\n-        }\n-\n-        sendPartStatsToBU(tbl, partsStats);\n-\n-        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n-        statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n-\n-        ObjectStatisticsImpl tblStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n-        statsRepos.mergeLocalStatistics(key, tblStats);\n-\n-        return new IgniteBiTuple(tblStats, partsStats.stream().map(ObjectPartitionStatisticsImpl::partId).toArray());\n-    }\n-\n     /**\n-     * Send statistics propagation messages with partition statistics to all backups node.\n+     * Collect object statistics prepared status.\n      *\n-     * @param tbl Table to which statistics should be send.\n-     * @param objStats Collection of partition statistics to send.\n+     * @param status Collection status to collect statistics by.\n      * @throws IgniteCheckedException In case of errors.\n      */\n-    private void sendPartStatsToBU(\n-            GridH2Table tbl,\n-            Collection<ObjectPartitionStatisticsImpl> objStats\n-    ) throws IgniteCheckedException {\n-        UUID locNode = ctx.discovery().localNode().id();\n-        StatsKeyMessage keyMsg = new StatsKeyMessage(tbl.identifier().schema(), tbl.identifier().table(), null);\n-        GridDhtPartitionTopology topology = tbl.cacheContext().topology();\n-        Map<UUID, List<StatsObjectData>> statsByNodes = new HashMap<>();\n-        for (ObjectPartitionStatisticsImpl stat : objStats) {\n-            StatsObjectData statData = StatisticsUtils.toObjectData(keyMsg, StatsType.PARTITION, stat);\n-            for (ClusterNode partNode : topology.nodes(stat.partId(), topology.readyTopologyVersion())) {\n-                if (locNode.equals(partNode.id()))\n-                    continue;\n-\n-                statsByNodes.compute(partNode.id(), (k, v) -> {\n-                    if (v == null)\n-                        v = new ArrayList<>();\n-\n-                    v.add(statData);\n-\n-                    return v;\n-                });\n-            }\n-        }\n-\n-        for (Map.Entry <UUID, List<StatsObjectData>> statToNode : statsByNodes.entrySet()) {\n-            //StatsPropagationMessage nodeMsg = StatisticsUtils.toMessage(null, statToNode.getValue());\n-\n-            //ctx.io().sendToCustomTopic(statToNode.getKey(), TOPIC, nodeMsg, GridIoPolicy.QUERY_POOL);\n-        }\n-    }\n-\n-    /**\n-     * Group local statistics by table and columns.\n-     *\n-     * @param status statistics collection status with all necessary local statistics.\n-     * @return map of tables to columns to list of local column statistics.\n-     */\n-    private Map<GridH2Table, Map<String, List<ColumnStatistics>>> groupColumnStatistics(StatCollectionStatus status) {\n-        /*Map<GridH2Table, Map<String, List<ColumnStatistics>>> result = new HashMap<>();\n-        for (StatsPropagationMessage msg : status.locStatistics) {\n-            for (StatsObjectData msgData : msg.data()) {\n-                GridH2Table dataTable = schemaMgr.dataTable(msgData.key().schema(), msgData.key().obj());\n-                if (dataTable == null) {\n-                    log.warning(String.format(\"Can't find table for received statistics: %s %s\", msgData.key().schema(),\n-                            msgData.key().obj()));\n-\n-                    continue;\n-                }\n-\n-                result.compute(dataTable, (table, columns) -> {\n-                    if (columns == null)\n-                        columns = new HashMap<>();\n-\n-                    for (Map.Entry<String, StatsColumnData> colData : msgData.data().entrySet())\n-                        columns.compute(colData.getKey(), (colName, colStatistics) -> {\n-                            if (colStatistics == null)\n-                                colStatistics = new ArrayList<>();\n-\n-                            ColumnStatistics colStat;\n-                            try {\n-                                colStat = StatisticsUtils.toColumnStatistics(ctx, colData.getValue());\n-                                colStatistics.add(colStat);\n-                            }\n-                            catch (IgniteCheckedException e) {\n-                                log.warning(String. format(\"Error while converting column statistics %s.%s - %s\",\n-                                        msgData.key().schema(), msgData.key().obj(), colName));\n-                            }\n-                            return colStatistics;\n-                        });\n-                    return columns;\n-                });\n-            }\n-        }\n-        return result;\n-        */\n-        return null;\n-    }\n-\n-    /**\n-     * Will aggregate all received local statistics and save it.\n-     *\n-     * @param request aggregation request with id only.\n-     */\n-    private void aggregateCollected(StatCollectionStatus status) {\n-        /*// Table -> Column -> List of local column stats\n-        Map<GridH2Table, Map<String, List<ColumnStatistics>>> tablesData = groupColumnStatistics(status);\n-\n-        Map<ClusterNode, List<StatsObjectData>> dataByNodes = new HashMap<>();\n-        for (Map.Entry<GridH2Table, Map<String, List<ColumnStatistics>>> tableStats : tablesData.entrySet()) {\n-            GridH2Table table = tableStats.getKey();\n-            long rowCount = 0L;\n-            Map<String, ColumnStatistics> columnStatistics = new HashMap<>();\n-            for (Map.Entry<String, List<ColumnStatistics>> columnStats : tableStats.getValue().entrySet()) {\n-                ColumnStatistics globalStatistics = ColumnStatisticsCollector\n-                        .aggregate(table::compareValues, columnStats.getValue());\n-                if (rowCount < globalStatistics.total())\n-                    rowCount = globalStatistics.total();\n-                columnStatistics.put(columnStats.getKey(), globalStatistics);\n-            }\n-\n-            ObjectStatisticsImpl objectStatistics = new ObjectStatisticsImpl(rowCount, columnStatistics);\n-            statsRepos.saveGlobalStatistics(new StatsKey(table.identifier().schema(), table.identifier().table()),\n-                    objectStatistics);\n-        }\n-        status.doneFut.onDone();\n-        */\n-\n-    }\n-\n-    /**\n-     * Filter columns by specified names.\n-     *\n-     * @param cols Columns to filter.\n-     * @param colNames Column names.\n-     * @return Column with specified names.\n-     */\n-    private Column[] filterColumns(Column[] cols, @Nullable Collection<String> colNames) {\n-        if (F.isEmpty(colNames))\n-            return cols;\n-\n-        Set<String> colNamesSet = new HashSet(Arrays.asList(colNames));\n-        List<Column> resList = new ArrayList<>(colNames.size());\n+    private void collectObjectStatistics(StatisticsGatheringContext status) throws IgniteCheckedException {\n \n-        for (Column col : cols)\n-            if (colNamesSet.contains(col.getName()))\n-                resList.add(col);\n+        statRouter.sendGatheringRequestsAsync(status.gatId(), status.keys());\n \n-        return resList.toArray(new Column[resList.size()]);\n     }\n \n     /** {@inheritDoc} */\n", "next_change": {"commit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex f208a744d01..1f98ad5ca73 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -211,9 +235,25 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n      * @throws IgniteCheckedException In case of errors.\n      */\n     private void collectObjectStatistics(StatisticsGatheringContext status) throws IgniteCheckedException {\n+        statCrawler.sendGatheringRequestsAsync(status.gatId(), status.keys());\n+    }\n \n-        statRouter.sendGatheringRequestsAsync(status.gatId(), status.keys());\n+    /**\n+     * Calculate total partitions count for all keys in gathering task.\n+     *\n+     * @param keys Collection of keys to calculate partitions by.\n+     * @return Total number of partitions in all tasks keys.\n+     */\n+    private Integer calculatePartitions(Collection<StatisticsKeyMessage> keys) {\n+        int res = 0;\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                return null;\n \n+            res += tbl.cacheContext().topology().partitions();\n+        }\n+        return res;\n     }\n \n     /** {@inheritDoc} */\n", "next_change": {"commit": "7ef165002105dd10417170217e86d65771c524bb", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 1f98ad5ca73..4e5949c6399 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -262,9 +261,15 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n             String objName,\n             String... colNames\n     ) throws IgniteCheckedException {\n+\n         StatisticsKeyMessage keyMsg = new StatisticsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n-        StatisticsGatheringContext status = new StatisticsGatheringContext(Collections.singleton(keyMsg));\n+        CacheGroupContext grpCtx = helper.getGroupContext(keyMsg);\n+\n+        StatisticsGatheringContext status = new StatisticsGatheringContext(UUID.randomUUID(),\n+            Collections.singleton(keyMsg), grpCtx.topology().partitions());\n+\n         currColls.put(status.gatId(), status);\n+\n         collectObjectStatistics(status);\n \n         status.doneFut().get();\n", "next_change": {"commit": "33170812024f6c4d321f85287fea0b6c3abdb9e5", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 4e5949c6399..5011b1a87a5 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -234,45 +219,25 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n      * @throws IgniteCheckedException In case of errors.\n      */\n     private void collectObjectStatistics(StatisticsGatheringContext status) throws IgniteCheckedException {\n-        statCrawler.sendGatheringRequestsAsync(status.gatId(), status.keys(), null);\n-    }\n-\n-    /**\n-     * Calculate total partitions count for all keys in gathering task.\n-     *\n-     * @param keys Collection of keys to calculate partitions by.\n-     * @return Total number of partitions in all tasks keys.\n-     */\n-    private Integer calculatePartitions(Collection<StatisticsKeyMessage> keys) {\n-        int res = 0;\n-        for (StatisticsKeyMessage key : keys) {\n-            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n-            if (tbl == null)\n-                return null;\n-\n-            res += tbl.cacheContext().topology().partitions();\n-        }\n-        return res;\n+        statCrawler.sendGatheringRequestsAsync(status.gatheringId(), status.keys(), null);\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void collectObjectStatistics(\n-            String schemaName,\n-            String objName,\n-            String... colNames\n-    ) throws IgniteCheckedException {\n+    @Override public void gatherObjectStatistics(StatisticsTarget target) throws IgniteCheckedException {\n+        checkSupport(\"collect statistics\");\n \n-        StatisticsKeyMessage keyMsg = new StatisticsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        StatisticsKeyMessage keyMsg = new StatisticsKeyMessage(target.schema(), target.obj(),\n+            Arrays.asList(target.columns()));\n         CacheGroupContext grpCtx = helper.getGroupContext(keyMsg);\n \n         StatisticsGatheringContext status = new StatisticsGatheringContext(UUID.randomUUID(),\n             Collections.singleton(keyMsg), grpCtx.topology().partitions());\n \n-        currColls.put(status.gatId(), status);\n+        currColls.put(status.gatheringId(), status);\n \n         collectObjectStatistics(status);\n \n-        status.doneFut().get();\n+        status.doneFuture().get();\n     }\n \n     /**\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQzOTM4OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545439388", "body": "Is aggregated statistics can be updated only after all partitions were processed only?\r\n\r\nWhat if we got updates from primary? Will we update aggregates instantly?\r\nIf so, why we can't update aggregates after every single local partition is processed?", "bodyText": "Is aggregated statistics can be updated only after all partitions were processed only?\nWhat if we got updates from primary? Will we update aggregates instantly?\nIf so, why we can't update aggregates after every single local partition is processed?", "bodyHTML": "<p dir=\"auto\">Is aggregated statistics can be updated only after all partitions were processed only?</p>\n<p dir=\"auto\">What if we got updates from primary? Will we update aggregates instantly?<br>\nIf so, why we can't update aggregates after every single local partition is processed?</p>", "author": "AMashenkov", "createdAt": "2020-12-17T22:17:00Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -89,86 +157,468 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+\n+        UUID reqId = UUID.randomUUID();\n+        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        Map<UUID, List<Integer>> requestNodes = null;\n+        /*try {\n+            requestNodes = nodePartitions(extractGroups(Collections.singletonList(keyMsg)), null);\n+        } catch (IgniteCheckedException e) {\n+            // TODO: handle & remove task\n+        }\n+\n+        StatsClearRequest req = new StatsClearRequest(reqId, false, Collections.singletonList(keyMsg));\n+\n+        sendLocalRequests(reqId, req, requestNodes);*/\n+\n+        clearObjectStatisticsLocal(keyMsg);\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatsKeyMessage keyMsg) {\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n+    // TODO\n+    /**\n+     * Collect local object statistics by primary partitions of specified object.\n+     *\n+     * @param keyMsg Statistic key message to collect statistics by.\n+     * @param partIds Set of partition ids to collect statistics by.\n+     * @param cancelled Supplier to check if operation was cancelled.\n+     * @return Tuple of Collected local statistics with array of successfully collected partitions.\n+     * @throws IgniteCheckedException\n+     */\n+    private IgniteBiTuple<ObjectStatisticsImpl, int[]> collectLocalObjectStatistics(\n+            StatsKeyMessage keyMsg,\n+            int[] partIds,\n+            Supplier<Boolean> cancelled\n+    ) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", keyMsg.schema(), keyMsg.obj()));\n+\n+        Column[] selectedCols = filterColumns(tbl.getColumns(), keyMsg.colNames());\n+\n+        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, partIds, selectedCols,\n+                cancelled);\n+        if (partsStats == null) {\n+            assert cancelled.get() : \"Error collecting partition level statistics.\";\n+\n+            return null;\n+        }\n+\n+        sendPartStatsToBU(tbl, partsStats);\n+\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n+\n+        ObjectStatisticsImpl tblStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n+        statsRepos.mergeLocalStatistics(key, tblStats);", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTcwNDU1NA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545704554", "bodyText": "\"Is aggregated statistics can be updated only after all partitions were processed only?\"\nYes and no. Yes, because aggregated statistics  should only contains specified in collection request partitions (to allow correctly aggregate global statistics). And no, because as local statistics it can became outdated (if some partition left current node during collection). I don't cover such scenario.\n\"What if we got updates from primary?\"\nLocal level statistics contains statistics only from primary partitions. So if node will receive any partition propagation from another nodes - it won't affect local statistics at all.", "author": "Berkof", "createdAt": "2020-12-18T09:26:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQzOTM4OA=="}], "type": "inlineReview", "revised_code": {"commit": "d8c6c6bb46b36bf8d36a0578e7c1813e04bfabfe", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex ca50e8e339b..0f88eff3479 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -224,7 +224,7 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n             return null;\n         }\n \n-        sendPartStatsToBU(tbl, partsStats);\n+        sendPartitionStatisticsToBackupNodes(tbl, partsStats);\n \n         StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n         statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n", "next_change": {"commit": "b595e90b5b480aaf80a9256558b1841334df97de", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 0f88eff3479..7fab3588e96 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -232,7 +247,8 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n         ObjectStatisticsImpl tblStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n         statsRepos.mergeLocalStatistics(key, tblStats);\n \n-        return new IgniteBiTuple(tblStats, partsStats.stream().map(ObjectPartitionStatisticsImpl::partId).toArray());\n+        return new IgniteBiTuple(tblStats, partsStats.stream().map(ObjectPartitionStatisticsImpl::partId)\n+                .mapToInt(Integer::intValue).toArray());\n     }\n \n     /**\n", "next_change": {"commit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 7fab3588e96..f208a744d01 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -210,148 +204,16 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n-    // TODO\n-    /**\n-     * Collect local object statistics by primary partitions of specified object.\n-     *\n-     * @param keyMsg Statistic key message to collect statistics by.\n-     * @param partIds Set of partition ids to collect statistics by.\n-     * @param cancelled Supplier to check if operation was cancelled.\n-     * @return Tuple of Collected local statistics with array of successfully collected partitions.\n-     * @throws IgniteCheckedException\n-     */\n-    private IgniteBiTuple<ObjectStatisticsImpl, int[]> collectLocalObjectStatistics(\n-            StatsKeyMessage keyMsg,\n-            int[] partIds,\n-            Supplier<Boolean> cancelled\n-    ) throws IgniteCheckedException {\n-        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n-        if (tbl == null)\n-            throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", keyMsg.schema(), keyMsg.obj()));\n-\n-        Column[] selectedCols = filterColumns(tbl.getColumns(), keyMsg.colNames());\n-\n-        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, partIds, selectedCols,\n-                cancelled);\n-        if (partsStats == null) {\n-            assert cancelled.get() : \"Error collecting partition level statistics.\";\n-\n-            return null;\n-        }\n-\n-        sendPartitionStatisticsToBackupNodes(tbl, partsStats);\n-\n-        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n-        statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n-\n-        ObjectStatisticsImpl tblStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n-        statsRepos.mergeLocalStatistics(key, tblStats);\n-\n-        return new IgniteBiTuple(tblStats, partsStats.stream().map(ObjectPartitionStatisticsImpl::partId)\n-                .mapToInt(Integer::intValue).toArray());\n-    }\n-\n-    /**\n-     * Send statistics propagation messages with partition statistics to all backups node.\n-     *\n-     * @param tbl Table to which statistics should be send.\n-     * @param objStats Collection of partition statistics to send.\n-     * @throws IgniteCheckedException In case of errors.\n-     */\n-    private void sendPartitionStatisticsToBackupNodes(\n-            GridH2Table tbl,\n-            Collection<ObjectPartitionStatisticsImpl> objStats\n-    ) throws IgniteCheckedException {\n-        UUID locNode = ctx.localNodeId();\n-        StatsKeyMessage keyMsg = new StatsKeyMessage(tbl.identifier().schema(), tbl.identifier().table(), null);\n-        GridDhtPartitionTopology topology = tbl.cacheContext().topology();\n-        Map<UUID, List<StatsObjectData>> statsByNodes = new HashMap<>();\n-        for (ObjectPartitionStatisticsImpl stat : objStats) {\n-            StatsObjectData statData = StatisticsUtils.toObjectData(keyMsg, StatsType.PARTITION, stat);\n-            for (ClusterNode partNode : topology.nodes(stat.partId(), topology.readyTopologyVersion())) {\n-                if (locNode.equals(partNode.id()))\n-                    continue;\n-\n-                statsByNodes.compute(partNode.id(), (k, v) -> {\n-                    if (v == null)\n-                        v = new ArrayList<>();\n-\n-                    v.add(statData);\n-\n-                    return v;\n-                });\n-            }\n-        }\n-\n-        for (Map.Entry <UUID, List<StatsObjectData>> statToNode : statsByNodes.entrySet()) {\n-            //StatsPropagationMessage nodeMsg = StatisticsUtils.toMessage(null, statToNode.getValue());\n-\n-            //ctx.io().sendToCustomTopic(statToNode.getKey(), TOPIC, nodeMsg, GridIoPolicy.QUERY_POOL);\n-        }\n-    }\n-\n-    /**\n-     * Filter columns by specified names.\n-     *\n-     * @param cols Columns to filter.\n-     * @param colNames Column names.\n-     * @return Column with specified names.\n-     */\n-    private Column[] filterColumns(Column[] cols, @Nullable Collection<String> colNames) {\n-        if (F.isEmpty(colNames))\n-            return cols;\n-\n-        Set<String> colNamesSet = new HashSet(Arrays.asList(colNames));\n-\n-        return Arrays.stream(cols).filter(c -> colNamesSet.contains(c.getName())).toArray(Column[]::new);\n-    }\n-\n     /**\n      * Collect object statistics prepared status.\n      *\n      * @param status Collection status to collect statistics by.\n      * @throws IgniteCheckedException In case of errors.\n      */\n-    private void collectObjectStatistics(StatCollectionStatus status) throws IgniteCheckedException {\n-        synchronized (status) {\n-            currCollections.updateCollection(status.colId(), s -> status);\n-            Map<StatsKeyMessage, int[]> failedPartitions = null;\n-            int cnt = 0;\n-            do {\n-                Collection<StatsAddrRequest<StatsCollectionRequest>> reqs = currCollections\n-                        .generateCollectionRequests(status.colId(), status.keys(), failedPartitions);\n-\n-                Collection<StatsAddrRequest<StatsCollectionRequest>> failedMsgs = sendRequests(reqs);\n-                Map<UUID, StatsAddrRequest<StatsCollectionRequest>> sendedMsgs;\n-                if (F.isEmpty(failedMsgs)) {\n-                    sendedMsgs = reqs.stream().collect(Collectors.toMap(r -> r.req().reqId(), r -> r));\n-                    failedPartitions = null;\n-                }\n-                else {\n-                    Set<UUID> failedIds = failedMsgs.stream().map(r -> r.req().reqId()).collect(Collectors.toSet());\n-                    sendedMsgs = reqs.stream().filter(r -> !failedIds.contains(r.req().reqId()))\n-                            .collect(Collectors.toMap(r -> r.req().reqId(), r -> r));\n-                    failedPartitions = currCollections.extractFailed(failedMsgs.stream().map(StatsAddrRequest::req)\n-                            .toArray(StatsCollectionRequest[]::new));\n-                }\n-                status.remainingCollectionReqs().putAll(sendedMsgs);\n-\n-                if (cnt++ > 10) {\n-                    StatsKeyMessage key = status.keys().iterator().next();\n-\n-                    throw new IgniteCheckedException(String.format(\n-                            \"Unable to send all messages to collect statistics by key %s.%s and the others %d\",\n-                            key.schema(), key.obj(), status.keys().size() - 1));\n-                }\n-            }\n-            while (failedPartitions != null);\n-        }\n+    private void collectObjectStatistics(StatisticsGatheringContext status) throws IgniteCheckedException {\n+\n+        statRouter.sendGatheringRequestsAsync(status.gatId(), status.keys());\n \n-        UUID locNode = ctx.localNodeId();\n-        StatsAddrRequest<StatsCollectionRequest> locReq = status.remainingCollectionReqs().values().stream()\n-                .filter(r -> locNode.equals(r.nodeId())).findAny().orElse(null);\n-        if (locReq != null)\n-            statMgmtPool.submit(() -> processLocal(locNode, locReq.req()));\n     }\n \n     /** {@inheritDoc} */\n", "next_change": {"commit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex f208a744d01..1f98ad5ca73 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -211,9 +235,25 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n      * @throws IgniteCheckedException In case of errors.\n      */\n     private void collectObjectStatistics(StatisticsGatheringContext status) throws IgniteCheckedException {\n+        statCrawler.sendGatheringRequestsAsync(status.gatId(), status.keys());\n+    }\n \n-        statRouter.sendGatheringRequestsAsync(status.gatId(), status.keys());\n+    /**\n+     * Calculate total partitions count for all keys in gathering task.\n+     *\n+     * @param keys Collection of keys to calculate partitions by.\n+     * @return Total number of partitions in all tasks keys.\n+     */\n+    private Integer calculatePartitions(Collection<StatisticsKeyMessage> keys) {\n+        int res = 0;\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                return null;\n \n+            res += tbl.cacheContext().topology().partitions();\n+        }\n+        return res;\n     }\n \n     /** {@inheritDoc} */\n", "next_change": {"commit": "7ef165002105dd10417170217e86d65771c524bb", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 1f98ad5ca73..4e5949c6399 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -262,9 +261,15 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n             String objName,\n             String... colNames\n     ) throws IgniteCheckedException {\n+\n         StatisticsKeyMessage keyMsg = new StatisticsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n-        StatisticsGatheringContext status = new StatisticsGatheringContext(Collections.singleton(keyMsg));\n+        CacheGroupContext grpCtx = helper.getGroupContext(keyMsg);\n+\n+        StatisticsGatheringContext status = new StatisticsGatheringContext(UUID.randomUUID(),\n+            Collections.singleton(keyMsg), grpCtx.topology().partitions());\n+\n         currColls.put(status.gatId(), status);\n+\n         collectObjectStatistics(status);\n \n         status.doneFut().get();\n", "next_change": {"commit": "33170812024f6c4d321f85287fea0b6c3abdb9e5", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 4e5949c6399..5011b1a87a5 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -234,45 +219,25 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n      * @throws IgniteCheckedException In case of errors.\n      */\n     private void collectObjectStatistics(StatisticsGatheringContext status) throws IgniteCheckedException {\n-        statCrawler.sendGatheringRequestsAsync(status.gatId(), status.keys(), null);\n-    }\n-\n-    /**\n-     * Calculate total partitions count for all keys in gathering task.\n-     *\n-     * @param keys Collection of keys to calculate partitions by.\n-     * @return Total number of partitions in all tasks keys.\n-     */\n-    private Integer calculatePartitions(Collection<StatisticsKeyMessage> keys) {\n-        int res = 0;\n-        for (StatisticsKeyMessage key : keys) {\n-            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n-            if (tbl == null)\n-                return null;\n-\n-            res += tbl.cacheContext().topology().partitions();\n-        }\n-        return res;\n+        statCrawler.sendGatheringRequestsAsync(status.gatheringId(), status.keys(), null);\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void collectObjectStatistics(\n-            String schemaName,\n-            String objName,\n-            String... colNames\n-    ) throws IgniteCheckedException {\n+    @Override public void gatherObjectStatistics(StatisticsTarget target) throws IgniteCheckedException {\n+        checkSupport(\"collect statistics\");\n \n-        StatisticsKeyMessage keyMsg = new StatisticsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        StatisticsKeyMessage keyMsg = new StatisticsKeyMessage(target.schema(), target.obj(),\n+            Arrays.asList(target.columns()));\n         CacheGroupContext grpCtx = helper.getGroupContext(keyMsg);\n \n         StatisticsGatheringContext status = new StatisticsGatheringContext(UUID.randomUUID(),\n             Collections.singleton(keyMsg), grpCtx.topology().partitions());\n \n-        currColls.put(status.gatId(), status);\n+        currColls.put(status.gatheringId(), status);\n \n         collectObjectStatistics(status);\n \n-        status.doneFut().get();\n+        status.doneFuture().get();\n     }\n \n     /**\n", "next_change": null}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ0MjgyNQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545442825", "body": "Method 'sendPartitionStatisticsToBackupNodes' name would look more expressive.\r\nI believe method name should has exact meaning, in opposite to variable, that can be short as variable exists in much narrower scope.", "bodyText": "Method 'sendPartitionStatisticsToBackupNodes' name would look more expressive.\nI believe method name should has exact meaning, in opposite to variable, that can be short as variable exists in much narrower scope.", "bodyHTML": "<p dir=\"auto\">Method 'sendPartitionStatisticsToBackupNodes' name would look more expressive.<br>\nI believe method name should has exact meaning, in opposite to variable, that can be short as variable exists in much narrower scope.</p>", "author": "AMashenkov", "createdAt": "2020-12-17T22:24:05Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -89,86 +157,468 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+\n+        UUID reqId = UUID.randomUUID();\n+        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        Map<UUID, List<Integer>> requestNodes = null;\n+        /*try {\n+            requestNodes = nodePartitions(extractGroups(Collections.singletonList(keyMsg)), null);\n+        } catch (IgniteCheckedException e) {\n+            // TODO: handle & remove task\n+        }\n+\n+        StatsClearRequest req = new StatsClearRequest(reqId, false, Collections.singletonList(keyMsg));\n+\n+        sendLocalRequests(reqId, req, requestNodes);*/\n+\n+        clearObjectStatisticsLocal(keyMsg);\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatsKeyMessage keyMsg) {\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n+    // TODO\n+    /**\n+     * Collect local object statistics by primary partitions of specified object.\n+     *\n+     * @param keyMsg Statistic key message to collect statistics by.\n+     * @param partIds Set of partition ids to collect statistics by.\n+     * @param cancelled Supplier to check if operation was cancelled.\n+     * @return Tuple of Collected local statistics with array of successfully collected partitions.\n+     * @throws IgniteCheckedException\n+     */\n+    private IgniteBiTuple<ObjectStatisticsImpl, int[]> collectLocalObjectStatistics(\n+            StatsKeyMessage keyMsg,\n+            int[] partIds,\n+            Supplier<Boolean> cancelled\n+    ) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", keyMsg.schema(), keyMsg.obj()));\n+\n+        Column[] selectedCols = filterColumns(tbl.getColumns(), keyMsg.colNames());\n+\n+        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, partIds, selectedCols,\n+                cancelled);\n+        if (partsStats == null) {\n+            assert cancelled.get() : \"Error collecting partition level statistics.\";\n+\n+            return null;\n+        }\n+\n+        sendPartStatsToBU(tbl, partsStats);\n+\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n+\n+        ObjectStatisticsImpl tblStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n+        statsRepos.mergeLocalStatistics(key, tblStats);\n+\n+        return new IgniteBiTuple(tblStats, partsStats.stream().map(ObjectPartitionStatisticsImpl::partId).toArray());\n+    }\n+\n+    /**\n+     * Send statistics propagation messages with partition statistics to all backups node.\n+     *\n+     * @param tbl Table to which statistics should be send.\n+     * @param objStats Collection of partition statistics to send.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void sendPartStatsToBU(", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTcwNTQ2OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545705468", "bodyText": "OK", "author": "Berkof", "createdAt": "2020-12-18T09:27:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ0MjgyNQ=="}], "type": "inlineReview", "revised_code": {"commit": "d8c6c6bb46b36bf8d36a0578e7c1813e04bfabfe", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex ca50e8e339b..0f88eff3479 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -242,11 +242,11 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n      * @param objStats Collection of partition statistics to send.\n      * @throws IgniteCheckedException In case of errors.\n      */\n-    private void sendPartStatsToBU(\n+    private void sendPartitionStatisticsToBackupNodes(\n             GridH2Table tbl,\n             Collection<ObjectPartitionStatisticsImpl> objStats\n     ) throws IgniteCheckedException {\n-        UUID locNode = ctx.discovery().localNode().id();\n+        UUID locNode = ctx.localNodeId();\n         StatsKeyMessage keyMsg = new StatsKeyMessage(tbl.identifier().schema(), tbl.identifier().table(), null);\n         GridDhtPartitionTopology topology = tbl.cacheContext().topology();\n         Map<UUID, List<StatsObjectData>> statsByNodes = new HashMap<>();\n", "next_change": {"commit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 0f88eff3479..f208a744d01 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -195,150 +204,16 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n-    // TODO\n-    /**\n-     * Collect local object statistics by primary partitions of specified object.\n-     *\n-     * @param keyMsg Statistic key message to collect statistics by.\n-     * @param partIds Set of partition ids to collect statistics by.\n-     * @param cancelled Supplier to check if operation was cancelled.\n-     * @return Tuple of Collected local statistics with array of successfully collected partitions.\n-     * @throws IgniteCheckedException\n-     */\n-    private IgniteBiTuple<ObjectStatisticsImpl, int[]> collectLocalObjectStatistics(\n-            StatsKeyMessage keyMsg,\n-            int[] partIds,\n-            Supplier<Boolean> cancelled\n-    ) throws IgniteCheckedException {\n-        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n-        if (tbl == null)\n-            throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", keyMsg.schema(), keyMsg.obj()));\n-\n-        Column[] selectedCols = filterColumns(tbl.getColumns(), keyMsg.colNames());\n-\n-        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, partIds, selectedCols,\n-                cancelled);\n-        if (partsStats == null) {\n-            assert cancelled.get() : \"Error collecting partition level statistics.\";\n-\n-            return null;\n-        }\n-\n-        sendPartitionStatisticsToBackupNodes(tbl, partsStats);\n-\n-        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n-        statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n-\n-        ObjectStatisticsImpl tblStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n-        statsRepos.mergeLocalStatistics(key, tblStats);\n-\n-        return new IgniteBiTuple(tblStats, partsStats.stream().map(ObjectPartitionStatisticsImpl::partId).toArray());\n-    }\n-\n-    /**\n-     * Send statistics propagation messages with partition statistics to all backups node.\n-     *\n-     * @param tbl Table to which statistics should be send.\n-     * @param objStats Collection of partition statistics to send.\n-     * @throws IgniteCheckedException In case of errors.\n-     */\n-    private void sendPartitionStatisticsToBackupNodes(\n-            GridH2Table tbl,\n-            Collection<ObjectPartitionStatisticsImpl> objStats\n-    ) throws IgniteCheckedException {\n-        UUID locNode = ctx.localNodeId();\n-        StatsKeyMessage keyMsg = new StatsKeyMessage(tbl.identifier().schema(), tbl.identifier().table(), null);\n-        GridDhtPartitionTopology topology = tbl.cacheContext().topology();\n-        Map<UUID, List<StatsObjectData>> statsByNodes = new HashMap<>();\n-        for (ObjectPartitionStatisticsImpl stat : objStats) {\n-            StatsObjectData statData = StatisticsUtils.toObjectData(keyMsg, StatsType.PARTITION, stat);\n-            for (ClusterNode partNode : topology.nodes(stat.partId(), topology.readyTopologyVersion())) {\n-                if (locNode.equals(partNode.id()))\n-                    continue;\n-\n-                statsByNodes.compute(partNode.id(), (k, v) -> {\n-                    if (v == null)\n-                        v = new ArrayList<>();\n-\n-                    v.add(statData);\n-\n-                    return v;\n-                });\n-            }\n-        }\n-\n-        for (Map.Entry <UUID, List<StatsObjectData>> statToNode : statsByNodes.entrySet()) {\n-            //StatsPropagationMessage nodeMsg = StatisticsUtils.toMessage(null, statToNode.getValue());\n-\n-            //ctx.io().sendToCustomTopic(statToNode.getKey(), TOPIC, nodeMsg, GridIoPolicy.QUERY_POOL);\n-        }\n-    }\n-\n-    /**\n-     * Filter columns by specified names.\n-     *\n-     * @param cols Columns to filter.\n-     * @param colNames Column names.\n-     * @return Column with specified names.\n-     */\n-    private Column[] filterColumns(Column[] cols, @Nullable Collection<String> colNames) {\n-        if (F.isEmpty(colNames))\n-            return cols;\n-\n-        Set<String> colNamesSet = new HashSet(Arrays.asList(colNames));\n-\n-        return Arrays.stream(cols).filter(c -> colNamesSet.contains(c.getName())).toArray(Column[]::new);\n-    }\n-\n     /**\n      * Collect object statistics prepared status.\n      *\n      * @param status Collection status to collect statistics by.\n      * @throws IgniteCheckedException In case of errors.\n      */\n-    private void collectObjectStatistics(StatCollectionStatus status) throws IgniteCheckedException {\n-        synchronized (status) {\n-            currCollections.updateCollection(status.colId(), s -> status);\n-            Map<StatsKeyMessage, int[]> failedPartitions = null;\n-            int cnt = 0;\n-            do {\n-                Collection<StatsAddrRequest<StatsCollectionRequest>> reqs = currCollections\n-                        .generateCollectionRequests(status.colId(), status.keys(), failedPartitions);\n-\n-                //Map<UUID, StatsCollectionRequest> msgs = reqs.stream().collect(Collectors.toMap(\n-                //    StatsAddrRequest::nodeId, StatsAddrRequest::req));\n-\n-                Collection<StatsAddrRequest<StatsCollectionRequest>> failedMsgs = sendRequests(reqs);\n-                Map<UUID, StatsAddrRequest<StatsCollectionRequest>> sendedMsgs;\n-                if (failedMsgs == null) {\n-                    sendedMsgs = reqs.stream().collect(Collectors.toMap(r -> r.req().reqId(), r -> r));\n-                    failedPartitions = null;\n-                }\n-                else {\n-                    Set<UUID> failedIds = failedMsgs.stream().map(r -> r.req().reqId()).collect(Collectors.toSet());\n-                    sendedMsgs = reqs.stream().filter(r -> !failedIds.contains(r.req().reqId()))\n-                            .collect(Collectors.toMap(r -> r.req().reqId(), r -> r));\n-                    failedPartitions = currCollections.extractFailed(failedMsgs.stream().map(StatsAddrRequest::req)\n-                            .toArray(StatsCollectionRequest[]::new));\n-                }\n-                status.remainingCollectionReqs().putAll(sendedMsgs);\n-\n-                if (cnt++ > 10) {\n-                    StatsKeyMessage key = status.keys().iterator().next();\n-\n-                    throw new IgniteCheckedException(String.format(\n-                            \"Unable to send all messages to collect statistics by key %s.%s and the others %d\",\n-                            key.schema(), key.obj(), status.keys().size() - 1));\n-                }\n-            }\n-            while (failedPartitions != null);\n-        }\n+    private void collectObjectStatistics(StatisticsGatheringContext status) throws IgniteCheckedException {\n+\n+        statRouter.sendGatheringRequestsAsync(status.gatId(), status.keys());\n \n-        UUID locNode = ctx.localNodeId();\n-        StatsAddrRequest<StatsCollectionRequest> locReq = status.remainingCollectionReqs().values().stream()\n-                .filter(r -> locNode.equals(r.nodeId())).findAny().orElse(null);\n-        if (locReq != null)\n-            statMgmtPool.submit(() -> processLocal(locNode, locReq.req()));\n     }\n \n     /** {@inheritDoc} */\n", "next_change": {"commit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex f208a744d01..1f98ad5ca73 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -211,9 +235,25 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n      * @throws IgniteCheckedException In case of errors.\n      */\n     private void collectObjectStatistics(StatisticsGatheringContext status) throws IgniteCheckedException {\n+        statCrawler.sendGatheringRequestsAsync(status.gatId(), status.keys());\n+    }\n \n-        statRouter.sendGatheringRequestsAsync(status.gatId(), status.keys());\n+    /**\n+     * Calculate total partitions count for all keys in gathering task.\n+     *\n+     * @param keys Collection of keys to calculate partitions by.\n+     * @return Total number of partitions in all tasks keys.\n+     */\n+    private Integer calculatePartitions(Collection<StatisticsKeyMessage> keys) {\n+        int res = 0;\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                return null;\n \n+            res += tbl.cacheContext().topology().partitions();\n+        }\n+        return res;\n     }\n \n     /** {@inheritDoc} */\n", "next_change": {"commit": "7ef165002105dd10417170217e86d65771c524bb", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 1f98ad5ca73..4e5949c6399 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -262,9 +261,15 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n             String objName,\n             String... colNames\n     ) throws IgniteCheckedException {\n+\n         StatisticsKeyMessage keyMsg = new StatisticsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n-        StatisticsGatheringContext status = new StatisticsGatheringContext(Collections.singleton(keyMsg));\n+        CacheGroupContext grpCtx = helper.getGroupContext(keyMsg);\n+\n+        StatisticsGatheringContext status = new StatisticsGatheringContext(UUID.randomUUID(),\n+            Collections.singleton(keyMsg), grpCtx.topology().partitions());\n+\n         currColls.put(status.gatId(), status);\n+\n         collectObjectStatistics(status);\n \n         status.doneFut().get();\n", "next_change": {"commit": "33170812024f6c4d321f85287fea0b6c3abdb9e5", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 4e5949c6399..5011b1a87a5 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -234,45 +219,25 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n      * @throws IgniteCheckedException In case of errors.\n      */\n     private void collectObjectStatistics(StatisticsGatheringContext status) throws IgniteCheckedException {\n-        statCrawler.sendGatheringRequestsAsync(status.gatId(), status.keys(), null);\n-    }\n-\n-    /**\n-     * Calculate total partitions count for all keys in gathering task.\n-     *\n-     * @param keys Collection of keys to calculate partitions by.\n-     * @return Total number of partitions in all tasks keys.\n-     */\n-    private Integer calculatePartitions(Collection<StatisticsKeyMessage> keys) {\n-        int res = 0;\n-        for (StatisticsKeyMessage key : keys) {\n-            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n-            if (tbl == null)\n-                return null;\n-\n-            res += tbl.cacheContext().topology().partitions();\n-        }\n-        return res;\n+        statCrawler.sendGatheringRequestsAsync(status.gatheringId(), status.keys(), null);\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void collectObjectStatistics(\n-            String schemaName,\n-            String objName,\n-            String... colNames\n-    ) throws IgniteCheckedException {\n+    @Override public void gatherObjectStatistics(StatisticsTarget target) throws IgniteCheckedException {\n+        checkSupport(\"collect statistics\");\n \n-        StatisticsKeyMessage keyMsg = new StatisticsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        StatisticsKeyMessage keyMsg = new StatisticsKeyMessage(target.schema(), target.obj(),\n+            Arrays.asList(target.columns()));\n         CacheGroupContext grpCtx = helper.getGroupContext(keyMsg);\n \n         StatisticsGatheringContext status = new StatisticsGatheringContext(UUID.randomUUID(),\n             Collections.singleton(keyMsg), grpCtx.topology().partitions());\n \n-        currColls.put(status.gatId(), status);\n+        currColls.put(status.gatheringId(), status);\n \n         collectObjectStatistics(status);\n \n-        status.doneFut().get();\n+        status.doneFuture().get();\n     }\n \n     /**\n", "next_change": null}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ1MDk3MA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545450970", "body": "return Arrays.stream(cols).filter(colNamesSet::contains).toArray()", "bodyText": "return Arrays.stream(cols).filter(colNamesSet::contains).toArray()", "bodyHTML": "<p dir=\"auto\">return Arrays.stream(cols).filter(colNamesSet::contains).toArray()</p>", "author": "AMashenkov", "createdAt": "2020-12-17T22:41:40Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -89,86 +157,468 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+\n+        UUID reqId = UUID.randomUUID();\n+        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        Map<UUID, List<Integer>> requestNodes = null;\n+        /*try {\n+            requestNodes = nodePartitions(extractGroups(Collections.singletonList(keyMsg)), null);\n+        } catch (IgniteCheckedException e) {\n+            // TODO: handle & remove task\n+        }\n+\n+        StatsClearRequest req = new StatsClearRequest(reqId, false, Collections.singletonList(keyMsg));\n+\n+        sendLocalRequests(reqId, req, requestNodes);*/\n+\n+        clearObjectStatisticsLocal(keyMsg);\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatsKeyMessage keyMsg) {\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n+    // TODO\n+    /**\n+     * Collect local object statistics by primary partitions of specified object.\n+     *\n+     * @param keyMsg Statistic key message to collect statistics by.\n+     * @param partIds Set of partition ids to collect statistics by.\n+     * @param cancelled Supplier to check if operation was cancelled.\n+     * @return Tuple of Collected local statistics with array of successfully collected partitions.\n+     * @throws IgniteCheckedException\n+     */\n+    private IgniteBiTuple<ObjectStatisticsImpl, int[]> collectLocalObjectStatistics(\n+            StatsKeyMessage keyMsg,\n+            int[] partIds,\n+            Supplier<Boolean> cancelled\n+    ) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", keyMsg.schema(), keyMsg.obj()));\n+\n+        Column[] selectedCols = filterColumns(tbl.getColumns(), keyMsg.colNames());\n+\n+        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, partIds, selectedCols,\n+                cancelled);\n+        if (partsStats == null) {\n+            assert cancelled.get() : \"Error collecting partition level statistics.\";\n+\n+            return null;\n+        }\n+\n+        sendPartStatsToBU(tbl, partsStats);\n+\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n+\n+        ObjectStatisticsImpl tblStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n+        statsRepos.mergeLocalStatistics(key, tblStats);\n+\n+        return new IgniteBiTuple(tblStats, partsStats.stream().map(ObjectPartitionStatisticsImpl::partId).toArray());\n+    }\n+\n+    /**\n+     * Send statistics propagation messages with partition statistics to all backups node.\n+     *\n+     * @param tbl Table to which statistics should be send.\n+     * @param objStats Collection of partition statistics to send.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void sendPartStatsToBU(\n+            GridH2Table tbl,\n+            Collection<ObjectPartitionStatisticsImpl> objStats\n+    ) throws IgniteCheckedException {\n+        UUID locNode = ctx.discovery().localNode().id();\n+        StatsKeyMessage keyMsg = new StatsKeyMessage(tbl.identifier().schema(), tbl.identifier().table(), null);\n+        GridDhtPartitionTopology topology = tbl.cacheContext().topology();\n+        Map<UUID, List<StatsObjectData>> statsByNodes = new HashMap<>();\n+        for (ObjectPartitionStatisticsImpl stat : objStats) {\n+            StatsObjectData statData = StatisticsUtils.toObjectData(keyMsg, StatsType.PARTITION, stat);\n+            for (ClusterNode partNode : topology.nodes(stat.partId(), topology.readyTopologyVersion())) {\n+                if (locNode.equals(partNode.id()))\n+                    continue;\n+\n+                statsByNodes.compute(partNode.id(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+\n+                    v.add(statData);\n+\n+                    return v;\n+                });\n+            }\n+        }\n+\n+        for (Map.Entry <UUID, List<StatsObjectData>> statToNode : statsByNodes.entrySet()) {\n+            //StatsPropagationMessage nodeMsg = StatisticsUtils.toMessage(null, statToNode.getValue());\n+\n+            //ctx.io().sendToCustomTopic(statToNode.getKey(), TOPIC, nodeMsg, GridIoPolicy.QUERY_POOL);\n+        }\n+    }\n+\n+    /**\n+     * Group local statistics by table and columns.\n+     *\n+     * @param status statistics collection status with all necessary local statistics.\n+     * @return map of tables to columns to list of local column statistics.\n+     */\n+    private Map<GridH2Table, Map<String, List<ColumnStatistics>>> groupColumnStatistics(StatCollectionStatus status) {\n+        /*Map<GridH2Table, Map<String, List<ColumnStatistics>>> result = new HashMap<>();\n+        for (StatsPropagationMessage msg : status.locStatistics) {\n+            for (StatsObjectData msgData : msg.data()) {\n+                GridH2Table dataTable = schemaMgr.dataTable(msgData.key().schema(), msgData.key().obj());\n+                if (dataTable == null) {\n+                    log.warning(String.format(\"Can't find table for received statistics: %s %s\", msgData.key().schema(),\n+                            msgData.key().obj()));\n+\n+                    continue;\n+                }\n+\n+                result.compute(dataTable, (table, columns) -> {\n+                    if (columns == null)\n+                        columns = new HashMap<>();\n+\n+                    for (Map.Entry<String, StatsColumnData> colData : msgData.data().entrySet())\n+                        columns.compute(colData.getKey(), (colName, colStatistics) -> {\n+                            if (colStatistics == null)\n+                                colStatistics = new ArrayList<>();\n+\n+                            ColumnStatistics colStat;\n+                            try {\n+                                colStat = StatisticsUtils.toColumnStatistics(ctx, colData.getValue());\n+                                colStatistics.add(colStat);\n+                            }\n+                            catch (IgniteCheckedException e) {\n+                                log.warning(String. format(\"Error while converting column statistics %s.%s - %s\",\n+                                        msgData.key().schema(), msgData.key().obj(), colName));\n+                            }\n+                            return colStatistics;\n+                        });\n+                    return columns;\n+                });\n+            }\n+        }\n+        return result;\n+        */\n+        return null;\n+    }\n+\n+    /**\n+     * Will aggregate all received local statistics and save it.\n+     *\n+     * @param request aggregation request with id only.\n+     */\n+    private void aggregateCollected(StatCollectionStatus status) {\n+        /*// Table -> Column -> List of local column stats\n+        Map<GridH2Table, Map<String, List<ColumnStatistics>>> tablesData = groupColumnStatistics(status);\n+\n+        Map<ClusterNode, List<StatsObjectData>> dataByNodes = new HashMap<>();\n+        for (Map.Entry<GridH2Table, Map<String, List<ColumnStatistics>>> tableStats : tablesData.entrySet()) {\n+            GridH2Table table = tableStats.getKey();\n+            long rowCount = 0L;\n+            Map<String, ColumnStatistics> columnStatistics = new HashMap<>();\n+            for (Map.Entry<String, List<ColumnStatistics>> columnStats : tableStats.getValue().entrySet()) {\n+                ColumnStatistics globalStatistics = ColumnStatisticsCollector\n+                        .aggregate(table::compareValues, columnStats.getValue());\n+                if (rowCount < globalStatistics.total())\n+                    rowCount = globalStatistics.total();\n+                columnStatistics.put(columnStats.getKey(), globalStatistics);\n+            }\n+\n+            ObjectStatisticsImpl objectStatistics = new ObjectStatisticsImpl(rowCount, columnStatistics);\n+            statsRepos.saveGlobalStatistics(new StatsKey(table.identifier().schema(), table.identifier().table()),\n+                    objectStatistics);\n+        }\n+        status.doneFut.onDone();\n+        */\n+\n+    }\n+\n     /**\n      * Filter columns by specified names.\n      *\n-     * @param columns Columns to filter.\n+     * @param cols Columns to filter.\n      * @param colNames Column names.\n      * @return Column with specified names.\n      */\n-    private Column[] filterColumns(Column[] columns, String... colNames) {\n+    private Column[] filterColumns(Column[] cols, @Nullable Collection<String> colNames) {\n         if (F.isEmpty(colNames))\n-            return columns;\n+            return cols;\n \n         Set<String> colNamesSet = new HashSet(Arrays.asList(colNames));\n-        List<Column> resultList = new ArrayList<>(colNames.length);\n+        List<Column> resList = new ArrayList<>(colNames.size());\n \n-        for (Column col : columns)\n+        for (Column col : cols)\n             if (colNamesSet.contains(col.getName()))\n-                resultList.add(col);\n+                resList.add(col);\n \n-        return resultList.toArray(new Column[resultList.size()]);\n+        return resList.toArray(new Column[resList.size()]);", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTczNjY3OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545736678", "bodyText": "OK", "author": "Berkof", "createdAt": "2020-12-18T10:20:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ1MDk3MA=="}], "type": "inlineReview", "revised_code": {"commit": "ec4a9ef0e7691b605225c12527d496d07d573b42", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex ca50e8e339b..aa95be0231f 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -373,117 +373,120 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n         return resList.toArray(new Column[resList.size()]);\n     }\n \n-    /** {@inheritDoc} */\n-    @Override public void collectObjectStatistics(\n-            String schemaName,\n-            String objName,\n-            String... colNames\n-    ) throws IgniteCheckedException {\n-        StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n-        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n-        UUID colId = UUID.randomUUID();\n-        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.singletonList(keyMsg),\n-            Collections.emptyMap(), doneFut);\n+    /**\n+     * Collect object statistics prepared status.\n+     *\n+     * @param status Collection status to collect statistics by.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void collectObjectStatistics(StatCollectionStatus status) throws IgniteCheckedException {\n         synchronized (status) {\n-            currCollections.updateCollection(colId, s -> status);\n+            currCollections.updateCollection(status.colId(), s -> status);\n             Map<StatsKeyMessage, int[]> failedPartitions = null;\n             int cnt = 0;\n             do {\n-                Collection<StatsCollectionAddrRequest> reqs = currCollections.generateCollectionRequests(colId,\n-                    Collections.singletonList(keyMsg), failedPartitions);\n-                Map<UUID, StatsCollectionRequest> msgs = reqs.stream().collect(Collectors.toMap(\n-                    StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req));\n-\n-                Map<UUID, StatsCollectionRequest> failedMsgs = sendLocalRequests(msgs);\n-                failedPartitions = currCollections.extractFailed(failedMsgs.values()\n-                    .toArray(new StatsCollectionRequest[0]));\n-                if (cnt++ > 10)\n+                Collection<StatsAddrRequest<StatsCollectionRequest>> reqs = currCollections\n+                        .generateCollectionRequests(status.colId(), status.keys(), failedPartitions);\n+\n+                //Map<UUID, StatsCollectionRequest> msgs = reqs.stream().collect(Collectors.toMap(\n+                //    StatsAddrRequest::nodeId, StatsAddrRequest::req));\n+\n+                Collection<StatsAddrRequest<StatsCollectionRequest>> failedMsgs = sendLocalRequests(reqs);\n+                Map<UUID, StatsAddrRequest<StatsCollectionRequest>> sendedMsgs;\n+                if (failedMsgs == null) {\n+                    sendedMsgs = reqs.stream().collect(Collectors.toMap(r -> r.req().reqId(), r -> r));\n+                    failedPartitions = null;\n+                }\n+                else {\n+                    Set<UUID> failedIds = failedMsgs.stream().map(r -> r.req().reqId()).collect(Collectors.toSet());\n+                    sendedMsgs = reqs.stream().filter(r -> !failedIds.contains(r.req().reqId()))\n+                            .collect(Collectors.toMap(r -> r.req().reqId(), r -> r));\n+                    failedPartitions = currCollections.extractFailed(failedMsgs.stream().map(StatsAddrRequest::req)\n+                            .toArray(StatsCollectionRequest[]::new));\n+                }\n+                status.remainingCollectionReqs().putAll(sendedMsgs);\n+\n+                if (cnt++ > 10) {\n+                    StatsKeyMessage key = status.keys().iterator().next();\n+\n                     throw new IgniteCheckedException(String.format(\n-                            \"Unable to send all messages to collect statistics by key %s.%s\", schemaName, objName));\n+                            \"Unable to send all messages to collect statistics by key %s.%s and the others %d\",\n+                            key.schema(), key.obj(), status.keys().size() - 1));\n+                }\n             }\n-            while (!failedPartitions.isEmpty());\n+            while (failedPartitions != null);\n         }\n+\n         UUID locNode = ctx.discovery().localNode().id();\n-        StatsCollectionAddrRequest locReq = status.remainingCollectionReqs().get(locNode);\n-        statMgmtPool.submit(() -> processLocal(ctx.discovery().localNode().id(), locReq.req()));\n-        /*final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+        StatsAddrRequest<StatsCollectionRequest> locReq = status.remainingCollectionReqs().values().stream()\n+                .filter(r -> locNode.equals(r.nodeId())).findAny().orElse(null);\n+        if (locReq != null)\n+            statMgmtPool.submit(() -> processLocal(ctx.discovery().localNode().id(), locReq.req()));\n+    }\n \n+    /** {@inheritDoc} */\n+    @Override public void collectObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        UUID colId = UUID.randomUUID();\n+        StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter(colId);\n         StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.singletonList(keyMsg),\n+            Collections.emptyMap(), doneFut);\n+\n+        collectObjectStatistics(status);\n+\n+        doneFut.get();\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public StatsCollectionFuture<Map<GridTuple3<String, String, String[]>, ObjectStatistics>>\n+    collectObjectStatisticsAsync(\n+        GridTuple3<String, String, String[]>... keys\n+    ) throws IgniteCheckedException {\n         UUID colId = UUID.randomUUID();\n-        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.emptyMap(), doneFut);\n+        StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter(colId);\n+        Collection<StatsKeyMessage> keysMsg = Arrays.stream(keys).map(\n+                k -> new StatsKeyMessage(k.get1(), k.get2(), Arrays.asList(k.get3()))).collect(Collectors.toList());\n \n-        synchronized (status) {\n-            currCollections.put(colId, status);\n-            if (!doRequests(status, Collections.singletonList(keyMsg))) {\n-                status.doneFut().cancel();\n-                currCollections.remove(colId);\n-                throw new IgniteCheckedException(\"Unable to send statistics collection messages to all necessary nodes\");\n+        StatCollectionStatus status = new StatCollectionStatus(colId, keysMsg, Collections.emptyMap(), doneFut);\n+\n+        collectObjectStatistics(status);\n+\n+        return status.doneFut();\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public boolean cancelObjectStatisticsCollection(UUID colId) {\n+        boolean[] res = new boolean[]{true};\n+\n+        currCollections.updateCollection(colId, s -> {\n+            if (s == null) {\n+                res[0] = false;\n+\n+                return null;\n             }\n-        }\n-        UUID locNode = ctx.discovery().localNode().id();\n-        StatsCollectionAddrRequest locReq = status.remainingCollectionReqs().get(locNode);\n-        if (locReq != null)\n-            statMgmtPool.submit(() -> processLocal(locNode, locReq.req()));\n \n-        doneFut.get();\n-        */\n+            s.doneFut().cancel();\n+\n+            Collection<StatsAddrRequest<CancelStatsCollectionRequest>> cancelReqs = s.remainingCollectionReqs()\n+                .values().stream().map(r ->\n+                    new StatsAddrRequest<CancelStatsCollectionRequest>(\n+                            new CancelStatsCollectionRequest(colId, UUID.randomUUID()), r.nodeId()))\n+                    .collect(Collectors.toList());\n+\n+            Collection<StatsAddrRequest<CancelStatsCollectionRequest>> failed = sendLocalRequests(cancelReqs);\n+            if (failed != null)\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Unable to cancel all statistics collections requests (%d failed) by colId %s\",\n+                            failed.size(), colId));\n+\n+            return null;\n+        });\n \n-//\n-//        StatsKey key = new StatsKey(schemaName, objName);\n-//\n-//        List<CacheGroupContext> grpContexts = extractGroups(Collections.singletonList(key));\n-//\n-//        assert grpContexts.size() == 1;\n-//\n-//        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n-//        Map<UUID, List<Integer>> reqNodes = nodePartitions(grpContexts.get(0), null);\n-//        Map<UUID, StatsCollectionAddrRequest> reqs = prepareRequests(colId, keyMsg, reqNodes);\n-//\n-//        synchronized (status) {\n-//            currCollections.put(colId, status);\n-//\n-//            Map<UUID, StatsCollectionRequest> failedReqs = sendLocalRequests(reqs.values().stream().collect(\n-//                    Collectors.toMap(StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req)));\n-//\n-//            if (failedReqs != null) {\n-//                for (UUID failedReqId : failedReqs.keySet())\n-//                    status.remainingCollectionReqs().remove(failedReqId);\n-//\n-//                Map<StatsKeyMessage,List<Integer>> failedPartIds = extractFailed(failedReqs.values());\n-//\n-//                assert failedPartIds.size() == 1;\n-//\n-//                List<Integer> newPartIds = failedPartIds.get(keyMsg);\n-//\n-//                assert newPartIds != null;\n-//\n-//                Map<UUID, List<Integer>> newReqNodes = nodePartitions(grpContexts.get(0), newPartIds);\n-//                Map<UUID, StatsCollectionAddrRequest> newReqs = prepareRequests(colId, keyMsg, newReqNodes);\n-//                Map<UUID, StatsCollectionRequest> newFailedReqs = sendLocalRequests(newReqs.values().stream().collect(\n-//                        Collectors.toMap(StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req)));\n-//                if (newFailedReqs != null) {\n-//                    doneFut.cancel();\n-//\n-//                    // TODO: is it safe?\n-//                    currCollections.remove(colId);\n-//\n-//                    throw new IgniteCheckedException(String.format(\n-//                            \"Unable to send statistics collection request to %d nodes. Cancelling collection %s\",\n-//                            newFailedReqs.size(), colId));\n-//                }\n-//                status.remainingCollectionReqs().putAll(newReqs);\n-//\n-//                failedReqs.values().stream().forEach(req -> req.keys().values().forEach(failedPartIds.addAll()));\n-//                rescheduleFailedPartitions(colId, Collections.singletonMap(keyMsg, ));\n-//            }\n-//            UUID locNode = ctx.discovery().localNode().id();\n-//            StatsCollectionAddrRequest locReq = reqs.get(locNode);\n-//            if (locReq != null)\n-//                statMgmtPool.submit(() -> processLocal(locNode, locReq.req()));\n-//\n-//        }\n-//\n-//        doneFut.get();\n+        return res[0];\n     }\n \n     /**\n", "next_change": {"commit": "b595e90b5b480aaf80a9256558b1841334df97de", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex aa95be0231f..7fab3588e96 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -490,98 +429,7 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n     }\n \n     /**\n-     * Generate and try to send all request for particular status. Should be called inside status lock after putting it\n-     * into currCollections map. REMOVE!!!!\n-     *\n-     * @param status Status to process.\n-     * @param keys Collection of object keys to collect statistics by.\n-     * @return {@code true} if all request was successfully sended, {@code false} - otherwise (one should remove\n-     * status from cullCollections.\n-     */\n-    protected boolean doRequests(StatCollectionStatus status, List<StatsKeyMessage> keys) throws IgniteCheckedException {\n-        /*Map<CacheGroupContext, Collection<StatsKeyMessage>> grpContexts = extractGroups(keys);\n-        List<Map<UUID, StatsCollectionAddrRequest>> reqsByGrps = new ArrayList<>(grpContexts.size());\n-        for (Map.Entry<CacheGroupContext, Collection<StatsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n-            Map<UUID, List<Integer>> reqNodes = nodePartitions(grpEntry.getKey(), null);\n-            for(StatsKeyMessage keyMsg : grpEntry.getValue())\n-                reqsByGrps.add(prepareRequests(status.colId(), keyMsg, reqNodes));\n-\n-        }\n-        Map<UUID, StatsCollectionAddrRequest> reqs = compressRequests(reqsByGrps);\n-\n-        status.remainingCollectionReqs().putAll(reqs);\n-\n-        Map<UUID, StatsCollectionRequest> failedReqs = sendLocalRequests(reqs.values().stream().collect(\n-                Collectors.toMap(StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req)));\n-        // TODO: cycle replanning and sending\n-        return failedReqs.isEmpty();\n-\n-         */\n-        return false;\n-    }\n-\n-    /**\n-     * Group request by target node id. REMOVE!!!!\n-     *\n-     * @param reqsByGrps Requests to compress, map.\n-     * @return Grouped requests.\n-     */\n-    protected Map<UUID, StatsAddrRequest<StatsCollectionRequest>> compressRequests(\n-        List<Map<UUID, StatsAddrRequest<StatsCollectionRequest>>> reqsByGrps) {\n-        // NodeId to base request map\n-        Map<UUID, StatsAddrRequest<StatsCollectionRequest>> reqByNode = new HashMap<>();\n-        for (Map<UUID, StatsAddrRequest<StatsCollectionRequest>> grpReqs : reqsByGrps)\n-            for (StatsAddrRequest<StatsCollectionRequest> addReq : grpReqs.values())\n-                reqByNode.compute(addReq.nodeId(), (k, v) -> (v == null) ? addReq : addKey(v, addReq));\n-\n-        return reqByNode.entrySet().stream().collect(Collectors.toMap(e -> e.getValue().req().reqId(),\n-            Map.Entry::getValue));\n-    }\n-\n-    /**\n-     * Add keys from add request to the base one and return it.\n-     *\n-     * @param base Base request to add to.\n-     * @param add Add request to add.\n-     * @return Request with all keys from both specified.\n-     */\n-    protected StatsAddrRequest<StatsCollectionRequest> addKey(\n-        StatsAddrRequest<StatsCollectionRequest> base,\n-        StatsAddrRequest<StatsCollectionRequest> add\n-    ) {\n-        assert base.nodeId().equals(add.nodeId());\n-\n-        base.req().keys().putAll(add.req().keys());\n-        return base;\n-    }\n-\n-\n-    /**\n-     * Prepare statistics collection request for each nodes. MOVED!!!!\n-     *\n-     * @param colId Collection id.\n-     * @param keyMsg Key to collect statistics by.\n-     * @param reqNodes Map of node id to array of partition ids to be collected on that node.\n-     * @return Map: request id to statistics collection addressed request.\n-     */\n-    protected Map<UUID, StatsAddrRequest<StatsCollectionRequest>> _____prepareRequests(\n-            UUID colId,\n-            StatsKeyMessage keyMsg,\n-            Map<UUID, List<Integer>> reqNodes\n-    ) {\n-        Map<UUID, StatsAddrRequest<StatsCollectionRequest>> res = new HashMap<>(reqNodes.size());\n-        for (Map.Entry<UUID, List<Integer>> reqNode : reqNodes.entrySet()) {\n-            UUID reqId = UUID.randomUUID();\n-            StatsCollectionRequest colReq = new StatsCollectionRequest(colId, reqId, Collections.singletonMap(keyMsg,\n-                    reqNode.getValue().stream().mapToInt(Integer::intValue).toArray()));\n-            StatsAddrRequest<StatsCollectionRequest> addrReq = new StatsAddrRequest(colReq, reqNode.getKey());\n-            res.put(reqId, addrReq);\n-        }\n-        return res;\n-    }\n-\n-    /**\n-     * TODO\n+     * Stop statistics manager.\n      */\n     public void stop() {\n         if (statMgmtPool != null) {\n", "next_change": {"commit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 7fab3588e96..1f98ad5ca73 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -360,334 +262,199 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n             String objName,\n             String... colNames\n     ) throws IgniteCheckedException {\n-        UUID colId = UUID.randomUUID();\n-        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n-        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.singletonList(keyMsg),\n-            Collections.emptyMap());\n-\n+        StatisticsKeyMessage keyMsg = new StatisticsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        StatisticsGatheringContext status = new StatisticsGatheringContext(Collections.singleton(keyMsg));\n+        currColls.put(status.gatId(), status);\n         collectObjectStatistics(status);\n \n         status.doneFut().get();\n     }\n \n+    /**\n+     * Ensure that local gathering context exists and schedule local statistics gathering.\n+     *\n+     * @param nodeId Initiator node id.\n+     * @param gatId Gathering id.\n+     * @param reqId Request id.\n+     * @param keys Keys to collect statistics by.\n+     */\n+    public void gatherLocalObjectStatisticsAsync(UUID gatId, UUID reqId, Map<StatisticsKeyMessage, int[]> keys) {\n+        int parts = keys.values().stream().mapToInt(arr -> arr.length).sum();\n+\n+        StatisticsGatheringContext[] ctxs = new StatisticsGatheringContext[1];\n+        currColls.compute(gatId, (k, v) -> {\n+            if (v == null)\n+                v = new StatisticsGatheringContext(gatId, keys.keySet(), parts);\n+\n+            ctxs[0] = v;\n+\n+            return v;\n+        });\n+\n+        statGathering.collectLocalObjectsStatisticsAsync(reqId, keys, () -> ctxs[0].doneFut().isCancelled());\n+    }\n+\n     /** {@inheritDoc} */\n     @Override public StatsCollectionFuture<Map<GridTuple3<String, String, String[]>, ObjectStatistics>>\n     collectObjectStatisticsAsync(\n         GridTuple3<String, String, String[]>... keys\n     ) throws IgniteCheckedException {\n-        UUID colId = UUID.randomUUID();\n-        Collection<StatsKeyMessage> keysMsg = Arrays.stream(keys).map(\n-                k -> new StatsKeyMessage(k.get1(), k.get2(), Arrays.asList(k.get3()))).collect(Collectors.toList());\n+        Set<StatisticsKeyMessage> keysMsg = Arrays.stream(keys).map(\n+                k -> new StatisticsKeyMessage(k.get1(), k.get2(), Arrays.asList(k.get3()))).collect(Collectors.toSet());\n \n-        StatCollectionStatus status = new StatCollectionStatus(colId, keysMsg, Collections.emptyMap());\n+        StatisticsGatheringContext status = new StatisticsGatheringContext(keysMsg);\n \n         collectObjectStatistics(status);\n \n         return status.doneFut();\n     }\n \n-    /** {@inheritDoc} */\n-    @Override public boolean cancelObjectStatisticsCollection(UUID colId) {\n-        boolean[] res = new boolean[]{true};\n-\n-        currCollections.updateCollection(colId, s -> {\n-            if (s == null) {\n-                res[0] = false;\n-\n-                return null;\n-            }\n-\n-            s.doneFut().cancel();\n-\n-            Map<UUID, List<UUID>> nodeRequests = new HashMap<>();\n-            for (StatsAddrRequest<StatsCollectionRequest> req : s.remainingCollectionReqs().values()) {\n-                nodeRequests.compute(req.nodeId(), (k, v) -> {\n-                   if (v == null)\n-                       v = new ArrayList<>();\n-                   v.add(req.req().reqId());\n-\n-                   return v;\n-                });\n-            }\n-\n-            Collection<StatsAddrRequest<CancelStatsCollectionRequest>> cancelReqs = nodeRequests.entrySet().stream().map(\n-                        targetNode -> new StatsAddrRequest<>(\n-                            new CancelStatsCollectionRequest(colId, targetNode.getValue().toArray(new UUID[0])),\n-                            targetNode.getKey()))\n-                    .collect(Collectors.toList());\n-\n-            Collection<StatsAddrRequest<CancelStatsCollectionRequest>> failed = sendRequests(cancelReqs);\n-            if (!F.isEmpty(failed))\n-                if (log.isDebugEnabled())\n-                    log.debug(String.format(\"Unable to cancel all statistics collections requests (%d failed) by colId %s\",\n-                            failed.size(), colId));\n-\n-            return null;\n-        });\n-\n-        return res[0];\n-    }\n-\n     /**\n-     * Stop statistics manager.\n+     * Cancel specified statistics gathering process.\n+     *\n+     * @param gatId Gathering id to cancel.\n      */\n-    public void stop() {\n-        if (statMgmtPool != null) {\n-            List<Runnable> unfinishedTasks = statMgmtPool.shutdownNow();\n-            if (!unfinishedTasks.isEmpty())\n-                log.warning(String.format(\"%d statistics collection request cancelled.\", unfinishedTasks.size()));\n+    public void cancelLocalStatisticsGathering(UUID gatId){\n+       StatisticsGatheringContext stCtx = currColls.remove(gatId);\n+       if (stCtx != null)\n+           stCtx.doneFut().cancel();\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public boolean cancelObjectStatisticsGathering(UUID gatId) {\n+        boolean res = false;\n+        StatisticsGatheringContext stCtx = currColls.remove(gatId);\n+        if (stCtx != null) {\n+\n+            res = stCtx.doneFut().cancel();\n+            if (res)\n+                statCrawler.sendCancelGatheringAsync(gatId);\n         }\n+        return res;\n     }\n \n     /**\n-     * Collect partition level statistics.\n+     * Receive and store partition statistics object data for locals backup partition.\n      *\n-     * @param tbl Table to collect statistics by.\n-     * @param partIds Array of partition ids to collect statistics by.\n-     * @param selectedCols Columns to collect statistics by.\n-     * @param cancelled Supplier to check if collection was cancelled.\n-     * @return Collection of partition level statistics by local primary partitions.\n-     * @throws IgniteCheckedException in case of error.\n+     * @param data Collection of partition level statistics of local bacup partitions.\n      */\n-    private Collection<ObjectPartitionStatisticsImpl> collectPartitionStatistics(\n-            GridH2Table tbl,\n-            int[] partIds,\n-            Column[] selectedCols,\n-            Supplier<Boolean> cancelled\n-    ) {\n-        List<ObjectPartitionStatisticsImpl> tblPartStats = new ArrayList<>();\n-        GridH2RowDescriptor desc = tbl.rowDescriptor();\n-        String tblName = tbl.getName();\n-        GridDhtPartitionTopology top = tbl.cacheContext().topology();\n-        AffinityTopologyVersion topVer = top.readyTopologyVersion();\n-\n-        for (int partId : partIds) {\n-            GridDhtLocalPartition locPart = top.localPartition(partId, topVer, false);\n-            if (locPart == null)\n-                continue;\n+    public void receivePartitionsStatistics(Collection<StatisticsObjectData> data) {\n+        for (StatisticsObjectData partData : data) {\n+            StatisticsKey key = new StatisticsKey(partData.key().schema(), partData.key().obj());\n+\n+            assert partData.type() == StatisticsType.PARTITION : \"Got non partition level statistics by \" + key\n+                    + \" without request\";\n \n-            if (cancelled.get()) {\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d\", key.schema(), key.obj(),\n+                    partData.partId()));\n+\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null) {\n                 if (log.isInfoEnabled())\n-                    log.info(String.format(\"Canceled collection of object %s.%s statistics.\", tbl.identifier().schema(),\n-                            tbl.identifier().table()));\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d\", key.schema(), key.obj(),\n+                        partData.partId()));\n \n-                return null;\n+                continue;\n             }\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(ctx.localNodeId(), partData.partId());\n+            if (partState != OWNING) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d\",\n+                            key.schema(), key.obj(), partData.partId()));\n \n-            final boolean reserved = locPart.reserve();\n+                continue;\n+            }\n \n             try {\n-                if (!reserved || (locPart.state() != OWNING) || !locPart.primary(ctx.discovery().topologyVersionEx()))\n-                    continue;\n-\n-                long rowsCnt = 0;\n-\n-                List<ColumnStatisticsCollector> colStatsCollectors = new ArrayList<>(selectedCols.length);\n-\n-                for (Column col : selectedCols)\n-                    colStatsCollectors.add(new ColumnStatisticsCollector(col, tbl::compareValues));\n-\n-                for (CacheDataRow row : tbl.cacheContext().offheap().cachePartitionIterator(tbl.cacheId(), locPart.id(),\n-                        null, true)) {\n-                    GridQueryTypeDescriptor typeDesc = ctx.query().typeByValue(tbl.cacheName(),\n-                        tbl.cacheContext().cacheObjectContext(), row.key(), row.value(), false);\n-                    if (!tblName.equals(typeDesc.tableName()))\n-                        continue;\n-\n-                    rowsCnt++;\n-\n-                    H2Row row0 = desc.createRow(row);\n-\n-                    for (ColumnStatisticsCollector colStat : colStatsCollectors)\n-                        colStat.add(row0.getValue(colStat.col().getColumnId()));\n-\n-                }\n-\n-                Map<String, ColumnStatistics> colStats = colStatsCollectors.stream().collect(Collectors.toMap(\n-                    csc -> csc.col().getName(), ColumnStatisticsCollector::finish));\n+                ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n \n-                tblPartStats.add(new ObjectPartitionStatisticsImpl(locPart.id(), true, rowsCnt,\n-                        locPart.updateCounter(), colStats));\n-\n-                if (log.isTraceEnabled())\n-                    log.trace(String.format(\"Finished statistics collection on %s.%s:%d\",\n-                        tbl.identifier().schema(), tbl.identifier().table(), locPart.id()));\n+                statsRepos.saveLocalPartitionStatistics(key, opStat);\n             }\n             catch (IgniteCheckedException e) {\n-                if (log.isDebugEnabled())\n-                    log.debug(String.format(\"Unable to collect statistics by %s.%s:%d due to error %s\",\n-                        tbl.identifier().schema(), tbl.identifier().table(), partId, e.getMessage()));\n-            }\n-            finally {\n-                if (reserved)\n-                    locPart.release();\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Unable to parse partition statistics for %s.%s:%d because of: %s\",\n+                        key.schema(), key.obj(), partData.partId(), e.getMessage()));\n             }\n         }\n-\n-        return tblPartStats;\n     }\n \n     /**\n-     * Aggregate specified partition level statistics to local level statistics.\n+     * Aggregate specified gathered statistics, remove it form local and complete its future.\n      *\n-     * @param keyMsg Aggregation key.\n-     * @param stats Collection of all local partition level or local level statistics by specified key to aggregate.\n-     * @return Local level aggregated statistics.\n+     * @param stCtx Gathering to complete.\n      */\n-    public ObjectStatisticsImpl aggregateLocalStatistics(\n-            StatsKeyMessage keyMsg,\n-            Collection<? extends ObjectStatisticsImpl> stats\n-    ) {\n-        // For now there can be only tables\n-        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n-\n-        if (tbl == null) {\n-            // remove all loaded statistics.\n-            if (log.isDebugEnabled())\n-                log.debug(String.format(\"Removing statistics for object %s.%s cause table doesn't exists.\",\n-                        keyMsg.schema(), keyMsg.obj()));\n-\n-            // Just to double check\n-            statsRepos.clearLocalPartitionsStatistics(new StatsKey(keyMsg.schema(), keyMsg.obj()));\n+    public void finishStatisticsCollection(StatisticsGatheringContext stCtx) {\n+        currColls.remove(stCtx.gatId());\n+\n+        Map<StatisticsKeyMessage, ObjectStatisticsImpl> keysGlobalStats = new HashMap<>();\n+        for (Map.Entry<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : stCtx.collectedStatistics()\n+                .entrySet()) {\n+            ObjectStatisticsImpl globalCollectedStat = statGathering.aggregateLocalStatistics(keyStats.getKey(),\n+                keyStats.getValue());\n+            StatisticsKey statsKey = new StatisticsKey(keyStats.getKey().schema(), keyStats.getKey().obj());\n+            ObjectStatisticsImpl globalStat = statsRepos.mergeGlobalStatistics(statsKey, globalCollectedStat);\n+            keysGlobalStats.put(keyStats.getKey(), globalStat);\n         }\n \n-        return aggregateLocalStatistics(tbl, filterColumns(tbl.getColumns(), keyMsg.colNames()), stats);\n+        statCrawler.sendGlobalStat(keysGlobalStats);\n     }\n \n     /**\n-     * Aggregate partition level statistics to local level one.\n+     * Cache global statistics.\n      *\n-     * @param tbl Table to aggregate statistics by.\n-     * @param selectedCols Columns to aggregate statistics by.\n-     * @param stats Collection of partition level or local level statistics to aggregate.\n-     * @return Local level statistics.\n+     * @param data Global statistics to cache.\n      */\n-    private ObjectStatisticsImpl aggregateLocalStatistics(\n-            GridH2Table tbl,\n-            Column[] selectedCols,\n-            Collection<? extends ObjectStatisticsImpl> stats\n-    ) {\n-        Map<Column, List<ColumnStatistics>> colPartStats = new HashMap<>(selectedCols.length);\n-        long rowCnt = 0;\n-        for (Column col : selectedCols)\n-            colPartStats.put(col, new ArrayList<>());\n-\n-        for (ObjectStatisticsImpl partStat : stats) {\n-            for (Column col : selectedCols) {\n-                ColumnStatistics colPartStat = partStat.columnStatistics(col.getName());\n-                if (colPartStat != null) {\n-                    colPartStats.computeIfPresent(col, (k, v) -> {\n-                        v.add(colPartStat);\n-\n-                        return v;\n-                    });\n-                }\n-            }\n-            rowCnt += partStat.rowCount();\n-        }\n-\n-        Map<String, ColumnStatistics> colStats = new HashMap<>(selectedCols.length);\n-        for (Column col : selectedCols) {\n-            ColumnStatistics stat = ColumnStatisticsCollector.aggregate(tbl::compareValues, colPartStats.get(col));\n-            colStats.put(col.getName(), stat);\n-        }\n-\n-        ObjectStatisticsImpl tblStats = new ObjectStatisticsImpl(rowCnt, colStats);\n-\n-        return tblStats;\n-    }\n-\n-    /**\n-     * Receive and handle statistics propagation message with partitions statistics.\n-     *\n-     * @param nodeId Sender node id.\n-     * @param msg Statistics propagation message with partitions statistics to handle.\n-     * @throws IgniteCheckedException In case of errors.\n-     */\n-    private void receivePartitionsStatistics(UUID nodeId, StatsPropagationMessage msg) throws IgniteCheckedException {\n-        UUID locNode = ctx.localNodeId();\n-        for (StatsObjectData partData : msg.data()) {\n-            StatsKey key = new StatsKey(partData.key().schema(), partData.key().obj());\n-\n-            assert partData.type() == StatsType.PARTITION : \"Got non partition level statistics by \" + key\n-                    + \" without request\";\n-\n-            if (log.isTraceEnabled())\n-                log.trace(String.format(\"Received partition statistics %s.%s:%d from node %s\", key.schema(),\n-                        key.obj(), partData.partId(), nodeId));\n-\n-            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n-            if (tbl == null) {\n-                if (log.isInfoEnabled())\n-                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d from node %s\",\n-                            key.schema(), key.obj(), partData.partId(), nodeId));\n+    public void saveGlobalStatistics(Collection<StatisticsObjectData> data) {\n+        data.forEach(objData -> {\n+            try {\n+                ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(this.ctx, objData);\n \n-                continue;\n+                statsRepos.saveGlobalStatistics(new StatisticsKey(objData.key().schema(), objData.key().obj()), objStat);\n             }\n-            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(locNode, partData.partId());\n-            if (partState != OWNING) {\n-                if (log.isInfoEnabled())\n-                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d from node %s\",\n-                            key.schema(), key.obj(), partData.partId(), nodeId));\n-\n-                continue;\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Cannot read global statistics %s\", objData.key()));\n             }\n-\n-            ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n-\n-            statsRepos.saveLocalPartitionStatistics(key, opStat);\n-        }\n+        });\n     }\n \n     /**\n-     * Receive and handle statistics propagation message as response for collection request.\n+     * Register\n      *\n-     * @param nodeId Sender node id.\n-     * @param msg Statistics propagation message with partitions statistics to handle.\n-     * @throws IgniteCheckedException In case of errors.\n+     * @param gatId Gathering id.\n+     * @param data Collected statistics.\n      */\n-    private void receiveLocalStatistics(UUID nodeId, StatsCollectionResponse msg) {\n-        assert msg.data().keySet().stream().noneMatch(pd -> pd.type() == StatsType.PARTITION)\n-                : \"Got partition statistics by request \" + msg.reqId();\n-\n-        currCollections.updateCollection(msg.colId(), stat -> {\n-            if (stat == null) {\n-                if (log.isDebugEnabled())\n-                    log.debug(String.format(\n-                        \"Ignoring outdated local statistics collection response from node %s to col %s req %s\",\n-                            nodeId, msg.colId(), msg.reqId()));\n-\n-                return stat;\n-            }\n+    public void registerLocalResult(UUID gatId, Map<StatisticsObjectData, int[]> data) {\n+        StatisticsGatheringContext stCtx = currColls.get(gatId);\n+        if (stCtx == null) {\n+            if (log.isDebugEnabled())\n+                log.debug(String.format(\"Unable to register outdated statistics collection result %s\", gatId));\n \n-            assert stat.colId().equals(msg.colId());\n+            return;\n+        }\n+        Map<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats = new HashMap<>();\n+        for (StatisticsObjectData objData : data.keySet()) {\n+            keyStats.compute(objData.key(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n \n-            // Need syncronization here to avoid races between removing remaining reqs and adding new ones.\n-            synchronized (stat) {\n-                StatsAddrRequest<StatsCollectionRequest> req = stat.remainingCollectionReqs().remove(msg.reqId());\n+                try {\n+                    ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n \n-                if (req == null) {\n+                    v.add(objStat);\n+                }\n+                catch (IgniteCheckedException e) {\n                     if (log.isDebugEnabled())\n-                        log.debug(String.format(\n-                                \"Ignoring unknown local statistics collection response from node %s to col %s req %s\",\n-                                nodeId, msg.colId(), msg.reqId()));\n-\n-                    return stat;\n+                        log.debug(String.format(\"Cannot read local statistics %s by gathering task %s\", objData.key(),\n+                            gatId));\n                 }\n \n-                stat.localStatistics().add(msg);\n-                // TODO: reschedule if not all partition collected.\n-\n-                if (stat.remainingCollectionReqs().isEmpty()) {\n-                    Map<StatsKey, ObjectStatisticsImpl> mergedGlobal = finishStatCollection(stat);\n-\n-                    stat.doneFut().onDone(null);\n-\n-                    return null;\n-                }\n-            }\n-            return stat;\n-        });\n+                return v;\n+            });\n+        }\n+        if (stCtx.registerCollected(keyStats, data.values().stream().mapToInt(a -> a.length).sum()))\n+            finishStatisticsCollection(stCtx);\n     }\n \n     /**\n", "next_change": {"commit": "7ef165002105dd10417170217e86d65771c524bb", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 1f98ad5ca73..4e5949c6399 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -453,35 +461,9 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n                 return v;\n             });\n         }\n-        if (stCtx.registerCollected(keyStats, data.values().stream().mapToInt(a -> a.length).sum()))\n-            finishStatisticsCollection(stCtx);\n-    }\n \n-    /**\n-     * Aggregate local statistics to global one.\n-     *\n-     * @param stat Statistics collection status to aggregate.\n-     * @return Map stats key to merged global statistics.\n-     */\n-    private Map<StatisticsKey, ObjectStatisticsImpl> finishStatCollection(StatisticsGatheringContext stat) {\n-        Map<StatisticsKey, ObjectStatisticsImpl> res = new HashMap<>();\n-        for (Map.Entry<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : stat.collectedStatistics()\n-                .entrySet()) {\n-            StatisticsKeyMessage keyMsg = keyStats.getKey();\n-            GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n-            if (tbl == null) {\n-                if (log.isInfoEnabled())\n-                    log.info(String.format(\"Unable to find object %s.%s to save collected statistics by.\",\n-                            keyMsg.schema(), keyMsg.obj()));\n-\n-                continue;\n-            }\n-\n-            ObjectStatisticsImpl globalStat = statGathering.aggregateLocalStatistics(keyMsg, keyStats.getValue());\n-            StatisticsKey key = new StatisticsKey(keyMsg.schema(), keyMsg.obj());\n-            res.put(key, statsRepos.mergeGlobalStatistics(key, globalStat));\n-        }\n-        return res;\n+        if (stCtx.registerCollected(keyStats, partsCount))\n+            finishStatisticsCollection(stCtx);\n     }\n \n     /**\n", "next_change": {"commit": "05b732cd7e8840c429c48f5561e7c98e0289bcf6", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 4e5949c6399..ab2c41eca80 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -443,23 +447,17 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n         }\n         Map<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats = new HashMap<>();\n         for (StatisticsObjectData objData : data) {\n-            keyStats.compute(objData.key(), (k, v) -> {\n-                if (v == null)\n-                    v = new ArrayList<>();\n-\n-                try {\n-                    ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n-\n-                    v.add(objStat);\n-                }\n-                catch (IgniteCheckedException e) {\n-                    if (log.isDebugEnabled())\n-                        log.debug(String.format(\"Cannot read local statistics %s by gathering task %s\", objData.key(),\n-                            gatId));\n-                }\n-\n-                return v;\n-            });\n+            Collection<ObjectStatisticsImpl> keyObjStats = keyStats.computeIfAbsent(objData.key(), k -> new ArrayList<>());\n+            try {\n+                ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n+\n+                keyObjStats.add(objStat);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Cannot read local statistics %s by gathering task %s\", objData.key(),\n+                        gatId));\n+            }\n         }\n \n         if (stCtx.registerCollected(keyStats, partsCount))\n", "next_change": null}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ1Mjg2OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545452868", "body": "What is 'doneFut' future purpose? Why we pass a future to status object constructor from outside?", "bodyText": "What is 'doneFut' future purpose? Why we pass a future to status object constructor from outside?", "bodyHTML": "<p dir=\"auto\">What is 'doneFut' future purpose? Why we pass a future to status object constructor from outside?</p>", "author": "AMashenkov", "createdAt": "2020-12-17T22:45:40Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -89,86 +157,468 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+\n+        UUID reqId = UUID.randomUUID();\n+        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        Map<UUID, List<Integer>> requestNodes = null;\n+        /*try {\n+            requestNodes = nodePartitions(extractGroups(Collections.singletonList(keyMsg)), null);\n+        } catch (IgniteCheckedException e) {\n+            // TODO: handle & remove task\n+        }\n+\n+        StatsClearRequest req = new StatsClearRequest(reqId, false, Collections.singletonList(keyMsg));\n+\n+        sendLocalRequests(reqId, req, requestNodes);*/\n+\n+        clearObjectStatisticsLocal(keyMsg);\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatsKeyMessage keyMsg) {\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n+    // TODO\n+    /**\n+     * Collect local object statistics by primary partitions of specified object.\n+     *\n+     * @param keyMsg Statistic key message to collect statistics by.\n+     * @param partIds Set of partition ids to collect statistics by.\n+     * @param cancelled Supplier to check if operation was cancelled.\n+     * @return Tuple of Collected local statistics with array of successfully collected partitions.\n+     * @throws IgniteCheckedException\n+     */\n+    private IgniteBiTuple<ObjectStatisticsImpl, int[]> collectLocalObjectStatistics(\n+            StatsKeyMessage keyMsg,\n+            int[] partIds,\n+            Supplier<Boolean> cancelled\n+    ) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", keyMsg.schema(), keyMsg.obj()));\n+\n+        Column[] selectedCols = filterColumns(tbl.getColumns(), keyMsg.colNames());\n+\n+        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, partIds, selectedCols,\n+                cancelled);\n+        if (partsStats == null) {\n+            assert cancelled.get() : \"Error collecting partition level statistics.\";\n+\n+            return null;\n+        }\n+\n+        sendPartStatsToBU(tbl, partsStats);\n+\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n+\n+        ObjectStatisticsImpl tblStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n+        statsRepos.mergeLocalStatistics(key, tblStats);\n+\n+        return new IgniteBiTuple(tblStats, partsStats.stream().map(ObjectPartitionStatisticsImpl::partId).toArray());\n+    }\n+\n+    /**\n+     * Send statistics propagation messages with partition statistics to all backups node.\n+     *\n+     * @param tbl Table to which statistics should be send.\n+     * @param objStats Collection of partition statistics to send.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void sendPartStatsToBU(\n+            GridH2Table tbl,\n+            Collection<ObjectPartitionStatisticsImpl> objStats\n+    ) throws IgniteCheckedException {\n+        UUID locNode = ctx.discovery().localNode().id();\n+        StatsKeyMessage keyMsg = new StatsKeyMessage(tbl.identifier().schema(), tbl.identifier().table(), null);\n+        GridDhtPartitionTopology topology = tbl.cacheContext().topology();\n+        Map<UUID, List<StatsObjectData>> statsByNodes = new HashMap<>();\n+        for (ObjectPartitionStatisticsImpl stat : objStats) {\n+            StatsObjectData statData = StatisticsUtils.toObjectData(keyMsg, StatsType.PARTITION, stat);\n+            for (ClusterNode partNode : topology.nodes(stat.partId(), topology.readyTopologyVersion())) {\n+                if (locNode.equals(partNode.id()))\n+                    continue;\n+\n+                statsByNodes.compute(partNode.id(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+\n+                    v.add(statData);\n+\n+                    return v;\n+                });\n+            }\n+        }\n+\n+        for (Map.Entry <UUID, List<StatsObjectData>> statToNode : statsByNodes.entrySet()) {\n+            //StatsPropagationMessage nodeMsg = StatisticsUtils.toMessage(null, statToNode.getValue());\n+\n+            //ctx.io().sendToCustomTopic(statToNode.getKey(), TOPIC, nodeMsg, GridIoPolicy.QUERY_POOL);\n+        }\n+    }\n+\n+    /**\n+     * Group local statistics by table and columns.\n+     *\n+     * @param status statistics collection status with all necessary local statistics.\n+     * @return map of tables to columns to list of local column statistics.\n+     */\n+    private Map<GridH2Table, Map<String, List<ColumnStatistics>>> groupColumnStatistics(StatCollectionStatus status) {\n+        /*Map<GridH2Table, Map<String, List<ColumnStatistics>>> result = new HashMap<>();\n+        for (StatsPropagationMessage msg : status.locStatistics) {\n+            for (StatsObjectData msgData : msg.data()) {\n+                GridH2Table dataTable = schemaMgr.dataTable(msgData.key().schema(), msgData.key().obj());\n+                if (dataTable == null) {\n+                    log.warning(String.format(\"Can't find table for received statistics: %s %s\", msgData.key().schema(),\n+                            msgData.key().obj()));\n+\n+                    continue;\n+                }\n+\n+                result.compute(dataTable, (table, columns) -> {\n+                    if (columns == null)\n+                        columns = new HashMap<>();\n+\n+                    for (Map.Entry<String, StatsColumnData> colData : msgData.data().entrySet())\n+                        columns.compute(colData.getKey(), (colName, colStatistics) -> {\n+                            if (colStatistics == null)\n+                                colStatistics = new ArrayList<>();\n+\n+                            ColumnStatistics colStat;\n+                            try {\n+                                colStat = StatisticsUtils.toColumnStatistics(ctx, colData.getValue());\n+                                colStatistics.add(colStat);\n+                            }\n+                            catch (IgniteCheckedException e) {\n+                                log.warning(String. format(\"Error while converting column statistics %s.%s - %s\",\n+                                        msgData.key().schema(), msgData.key().obj(), colName));\n+                            }\n+                            return colStatistics;\n+                        });\n+                    return columns;\n+                });\n+            }\n+        }\n+        return result;\n+        */\n+        return null;\n+    }\n+\n+    /**\n+     * Will aggregate all received local statistics and save it.\n+     *\n+     * @param request aggregation request with id only.\n+     */\n+    private void aggregateCollected(StatCollectionStatus status) {\n+        /*// Table -> Column -> List of local column stats\n+        Map<GridH2Table, Map<String, List<ColumnStatistics>>> tablesData = groupColumnStatistics(status);\n+\n+        Map<ClusterNode, List<StatsObjectData>> dataByNodes = new HashMap<>();\n+        for (Map.Entry<GridH2Table, Map<String, List<ColumnStatistics>>> tableStats : tablesData.entrySet()) {\n+            GridH2Table table = tableStats.getKey();\n+            long rowCount = 0L;\n+            Map<String, ColumnStatistics> columnStatistics = new HashMap<>();\n+            for (Map.Entry<String, List<ColumnStatistics>> columnStats : tableStats.getValue().entrySet()) {\n+                ColumnStatistics globalStatistics = ColumnStatisticsCollector\n+                        .aggregate(table::compareValues, columnStats.getValue());\n+                if (rowCount < globalStatistics.total())\n+                    rowCount = globalStatistics.total();\n+                columnStatistics.put(columnStats.getKey(), globalStatistics);\n+            }\n+\n+            ObjectStatisticsImpl objectStatistics = new ObjectStatisticsImpl(rowCount, columnStatistics);\n+            statsRepos.saveGlobalStatistics(new StatsKey(table.identifier().schema(), table.identifier().table()),\n+                    objectStatistics);\n+        }\n+        status.doneFut.onDone();\n+        */\n+\n+    }\n+\n     /**\n      * Filter columns by specified names.\n      *\n-     * @param columns Columns to filter.\n+     * @param cols Columns to filter.\n      * @param colNames Column names.\n      * @return Column with specified names.\n      */\n-    private Column[] filterColumns(Column[] columns, String... colNames) {\n+    private Column[] filterColumns(Column[] cols, @Nullable Collection<String> colNames) {\n         if (F.isEmpty(colNames))\n-            return columns;\n+            return cols;\n \n         Set<String> colNamesSet = new HashSet(Arrays.asList(colNames));\n-        List<Column> resultList = new ArrayList<>(colNames.length);\n+        List<Column> resList = new ArrayList<>(colNames.size());\n \n-        for (Column col : columns)\n+        for (Column col : cols)\n             if (colNamesSet.contains(col.getName()))\n-                resultList.add(col);\n+                resList.add(col);\n \n-        return resultList.toArray(new Column[resultList.size()]);\n+        return resList.toArray(new Column[resList.size()]);\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void collectObjectStatistics(String schemaName, String objName, String... colNames)\n-            throws IgniteCheckedException {\n-        GridH2Table tbl = schemaMgr.dataTable(schemaName, objName);\n-        if (tbl == null)\n-            throw new IllegalArgumentException(String.format(\"Can't find table %s.%s\", schemaName, objName));\n+    @Override public void collectObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        UUID colId = UUID.randomUUID();\n+        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.singletonList(keyMsg),\n+            Collections.emptyMap(), doneFut);", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTczODM2Nw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545738367", "bodyText": "It need to async collection and to cancel started collection. But yes, no reason to pass it from the outside. Fixed.", "author": "Berkof", "createdAt": "2020-12-18T10:23:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ1Mjg2OA=="}], "type": "inlineReview", "revised_code": {"commit": "ec4a9ef0e7691b605225c12527d496d07d573b42", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex ca50e8e339b..aa95be0231f 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -373,117 +373,120 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n         return resList.toArray(new Column[resList.size()]);\n     }\n \n-    /** {@inheritDoc} */\n-    @Override public void collectObjectStatistics(\n-            String schemaName,\n-            String objName,\n-            String... colNames\n-    ) throws IgniteCheckedException {\n-        StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n-        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n-        UUID colId = UUID.randomUUID();\n-        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.singletonList(keyMsg),\n-            Collections.emptyMap(), doneFut);\n+    /**\n+     * Collect object statistics prepared status.\n+     *\n+     * @param status Collection status to collect statistics by.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void collectObjectStatistics(StatCollectionStatus status) throws IgniteCheckedException {\n         synchronized (status) {\n-            currCollections.updateCollection(colId, s -> status);\n+            currCollections.updateCollection(status.colId(), s -> status);\n             Map<StatsKeyMessage, int[]> failedPartitions = null;\n             int cnt = 0;\n             do {\n-                Collection<StatsCollectionAddrRequest> reqs = currCollections.generateCollectionRequests(colId,\n-                    Collections.singletonList(keyMsg), failedPartitions);\n-                Map<UUID, StatsCollectionRequest> msgs = reqs.stream().collect(Collectors.toMap(\n-                    StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req));\n-\n-                Map<UUID, StatsCollectionRequest> failedMsgs = sendLocalRequests(msgs);\n-                failedPartitions = currCollections.extractFailed(failedMsgs.values()\n-                    .toArray(new StatsCollectionRequest[0]));\n-                if (cnt++ > 10)\n+                Collection<StatsAddrRequest<StatsCollectionRequest>> reqs = currCollections\n+                        .generateCollectionRequests(status.colId(), status.keys(), failedPartitions);\n+\n+                //Map<UUID, StatsCollectionRequest> msgs = reqs.stream().collect(Collectors.toMap(\n+                //    StatsAddrRequest::nodeId, StatsAddrRequest::req));\n+\n+                Collection<StatsAddrRequest<StatsCollectionRequest>> failedMsgs = sendLocalRequests(reqs);\n+                Map<UUID, StatsAddrRequest<StatsCollectionRequest>> sendedMsgs;\n+                if (failedMsgs == null) {\n+                    sendedMsgs = reqs.stream().collect(Collectors.toMap(r -> r.req().reqId(), r -> r));\n+                    failedPartitions = null;\n+                }\n+                else {\n+                    Set<UUID> failedIds = failedMsgs.stream().map(r -> r.req().reqId()).collect(Collectors.toSet());\n+                    sendedMsgs = reqs.stream().filter(r -> !failedIds.contains(r.req().reqId()))\n+                            .collect(Collectors.toMap(r -> r.req().reqId(), r -> r));\n+                    failedPartitions = currCollections.extractFailed(failedMsgs.stream().map(StatsAddrRequest::req)\n+                            .toArray(StatsCollectionRequest[]::new));\n+                }\n+                status.remainingCollectionReqs().putAll(sendedMsgs);\n+\n+                if (cnt++ > 10) {\n+                    StatsKeyMessage key = status.keys().iterator().next();\n+\n                     throw new IgniteCheckedException(String.format(\n-                            \"Unable to send all messages to collect statistics by key %s.%s\", schemaName, objName));\n+                            \"Unable to send all messages to collect statistics by key %s.%s and the others %d\",\n+                            key.schema(), key.obj(), status.keys().size() - 1));\n+                }\n             }\n-            while (!failedPartitions.isEmpty());\n+            while (failedPartitions != null);\n         }\n+\n         UUID locNode = ctx.discovery().localNode().id();\n-        StatsCollectionAddrRequest locReq = status.remainingCollectionReqs().get(locNode);\n-        statMgmtPool.submit(() -> processLocal(ctx.discovery().localNode().id(), locReq.req()));\n-        /*final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+        StatsAddrRequest<StatsCollectionRequest> locReq = status.remainingCollectionReqs().values().stream()\n+                .filter(r -> locNode.equals(r.nodeId())).findAny().orElse(null);\n+        if (locReq != null)\n+            statMgmtPool.submit(() -> processLocal(ctx.discovery().localNode().id(), locReq.req()));\n+    }\n \n+    /** {@inheritDoc} */\n+    @Override public void collectObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        UUID colId = UUID.randomUUID();\n+        StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter(colId);\n         StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.singletonList(keyMsg),\n+            Collections.emptyMap(), doneFut);\n+\n+        collectObjectStatistics(status);\n+\n+        doneFut.get();\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public StatsCollectionFuture<Map<GridTuple3<String, String, String[]>, ObjectStatistics>>\n+    collectObjectStatisticsAsync(\n+        GridTuple3<String, String, String[]>... keys\n+    ) throws IgniteCheckedException {\n         UUID colId = UUID.randomUUID();\n-        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.emptyMap(), doneFut);\n+        StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter(colId);\n+        Collection<StatsKeyMessage> keysMsg = Arrays.stream(keys).map(\n+                k -> new StatsKeyMessage(k.get1(), k.get2(), Arrays.asList(k.get3()))).collect(Collectors.toList());\n \n-        synchronized (status) {\n-            currCollections.put(colId, status);\n-            if (!doRequests(status, Collections.singletonList(keyMsg))) {\n-                status.doneFut().cancel();\n-                currCollections.remove(colId);\n-                throw new IgniteCheckedException(\"Unable to send statistics collection messages to all necessary nodes\");\n+        StatCollectionStatus status = new StatCollectionStatus(colId, keysMsg, Collections.emptyMap(), doneFut);\n+\n+        collectObjectStatistics(status);\n+\n+        return status.doneFut();\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public boolean cancelObjectStatisticsCollection(UUID colId) {\n+        boolean[] res = new boolean[]{true};\n+\n+        currCollections.updateCollection(colId, s -> {\n+            if (s == null) {\n+                res[0] = false;\n+\n+                return null;\n             }\n-        }\n-        UUID locNode = ctx.discovery().localNode().id();\n-        StatsCollectionAddrRequest locReq = status.remainingCollectionReqs().get(locNode);\n-        if (locReq != null)\n-            statMgmtPool.submit(() -> processLocal(locNode, locReq.req()));\n \n-        doneFut.get();\n-        */\n+            s.doneFut().cancel();\n+\n+            Collection<StatsAddrRequest<CancelStatsCollectionRequest>> cancelReqs = s.remainingCollectionReqs()\n+                .values().stream().map(r ->\n+                    new StatsAddrRequest<CancelStatsCollectionRequest>(\n+                            new CancelStatsCollectionRequest(colId, UUID.randomUUID()), r.nodeId()))\n+                    .collect(Collectors.toList());\n+\n+            Collection<StatsAddrRequest<CancelStatsCollectionRequest>> failed = sendLocalRequests(cancelReqs);\n+            if (failed != null)\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Unable to cancel all statistics collections requests (%d failed) by colId %s\",\n+                            failed.size(), colId));\n+\n+            return null;\n+        });\n \n-//\n-//        StatsKey key = new StatsKey(schemaName, objName);\n-//\n-//        List<CacheGroupContext> grpContexts = extractGroups(Collections.singletonList(key));\n-//\n-//        assert grpContexts.size() == 1;\n-//\n-//        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n-//        Map<UUID, List<Integer>> reqNodes = nodePartitions(grpContexts.get(0), null);\n-//        Map<UUID, StatsCollectionAddrRequest> reqs = prepareRequests(colId, keyMsg, reqNodes);\n-//\n-//        synchronized (status) {\n-//            currCollections.put(colId, status);\n-//\n-//            Map<UUID, StatsCollectionRequest> failedReqs = sendLocalRequests(reqs.values().stream().collect(\n-//                    Collectors.toMap(StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req)));\n-//\n-//            if (failedReqs != null) {\n-//                for (UUID failedReqId : failedReqs.keySet())\n-//                    status.remainingCollectionReqs().remove(failedReqId);\n-//\n-//                Map<StatsKeyMessage,List<Integer>> failedPartIds = extractFailed(failedReqs.values());\n-//\n-//                assert failedPartIds.size() == 1;\n-//\n-//                List<Integer> newPartIds = failedPartIds.get(keyMsg);\n-//\n-//                assert newPartIds != null;\n-//\n-//                Map<UUID, List<Integer>> newReqNodes = nodePartitions(grpContexts.get(0), newPartIds);\n-//                Map<UUID, StatsCollectionAddrRequest> newReqs = prepareRequests(colId, keyMsg, newReqNodes);\n-//                Map<UUID, StatsCollectionRequest> newFailedReqs = sendLocalRequests(newReqs.values().stream().collect(\n-//                        Collectors.toMap(StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req)));\n-//                if (newFailedReqs != null) {\n-//                    doneFut.cancel();\n-//\n-//                    // TODO: is it safe?\n-//                    currCollections.remove(colId);\n-//\n-//                    throw new IgniteCheckedException(String.format(\n-//                            \"Unable to send statistics collection request to %d nodes. Cancelling collection %s\",\n-//                            newFailedReqs.size(), colId));\n-//                }\n-//                status.remainingCollectionReqs().putAll(newReqs);\n-//\n-//                failedReqs.values().stream().forEach(req -> req.keys().values().forEach(failedPartIds.addAll()));\n-//                rescheduleFailedPartitions(colId, Collections.singletonMap(keyMsg, ));\n-//            }\n-//            UUID locNode = ctx.discovery().localNode().id();\n-//            StatsCollectionAddrRequest locReq = reqs.get(locNode);\n-//            if (locReq != null)\n-//                statMgmtPool.submit(() -> processLocal(locNode, locReq.req()));\n-//\n-//        }\n-//\n-//        doneFut.get();\n+        return res[0];\n     }\n \n     /**\n", "next_change": {"commit": "b595e90b5b480aaf80a9256558b1841334df97de", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex aa95be0231f..7fab3588e96 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -490,98 +429,7 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n     }\n \n     /**\n-     * Generate and try to send all request for particular status. Should be called inside status lock after putting it\n-     * into currCollections map. REMOVE!!!!\n-     *\n-     * @param status Status to process.\n-     * @param keys Collection of object keys to collect statistics by.\n-     * @return {@code true} if all request was successfully sended, {@code false} - otherwise (one should remove\n-     * status from cullCollections.\n-     */\n-    protected boolean doRequests(StatCollectionStatus status, List<StatsKeyMessage> keys) throws IgniteCheckedException {\n-        /*Map<CacheGroupContext, Collection<StatsKeyMessage>> grpContexts = extractGroups(keys);\n-        List<Map<UUID, StatsCollectionAddrRequest>> reqsByGrps = new ArrayList<>(grpContexts.size());\n-        for (Map.Entry<CacheGroupContext, Collection<StatsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n-            Map<UUID, List<Integer>> reqNodes = nodePartitions(grpEntry.getKey(), null);\n-            for(StatsKeyMessage keyMsg : grpEntry.getValue())\n-                reqsByGrps.add(prepareRequests(status.colId(), keyMsg, reqNodes));\n-\n-        }\n-        Map<UUID, StatsCollectionAddrRequest> reqs = compressRequests(reqsByGrps);\n-\n-        status.remainingCollectionReqs().putAll(reqs);\n-\n-        Map<UUID, StatsCollectionRequest> failedReqs = sendLocalRequests(reqs.values().stream().collect(\n-                Collectors.toMap(StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req)));\n-        // TODO: cycle replanning and sending\n-        return failedReqs.isEmpty();\n-\n-         */\n-        return false;\n-    }\n-\n-    /**\n-     * Group request by target node id. REMOVE!!!!\n-     *\n-     * @param reqsByGrps Requests to compress, map.\n-     * @return Grouped requests.\n-     */\n-    protected Map<UUID, StatsAddrRequest<StatsCollectionRequest>> compressRequests(\n-        List<Map<UUID, StatsAddrRequest<StatsCollectionRequest>>> reqsByGrps) {\n-        // NodeId to base request map\n-        Map<UUID, StatsAddrRequest<StatsCollectionRequest>> reqByNode = new HashMap<>();\n-        for (Map<UUID, StatsAddrRequest<StatsCollectionRequest>> grpReqs : reqsByGrps)\n-            for (StatsAddrRequest<StatsCollectionRequest> addReq : grpReqs.values())\n-                reqByNode.compute(addReq.nodeId(), (k, v) -> (v == null) ? addReq : addKey(v, addReq));\n-\n-        return reqByNode.entrySet().stream().collect(Collectors.toMap(e -> e.getValue().req().reqId(),\n-            Map.Entry::getValue));\n-    }\n-\n-    /**\n-     * Add keys from add request to the base one and return it.\n-     *\n-     * @param base Base request to add to.\n-     * @param add Add request to add.\n-     * @return Request with all keys from both specified.\n-     */\n-    protected StatsAddrRequest<StatsCollectionRequest> addKey(\n-        StatsAddrRequest<StatsCollectionRequest> base,\n-        StatsAddrRequest<StatsCollectionRequest> add\n-    ) {\n-        assert base.nodeId().equals(add.nodeId());\n-\n-        base.req().keys().putAll(add.req().keys());\n-        return base;\n-    }\n-\n-\n-    /**\n-     * Prepare statistics collection request for each nodes. MOVED!!!!\n-     *\n-     * @param colId Collection id.\n-     * @param keyMsg Key to collect statistics by.\n-     * @param reqNodes Map of node id to array of partition ids to be collected on that node.\n-     * @return Map: request id to statistics collection addressed request.\n-     */\n-    protected Map<UUID, StatsAddrRequest<StatsCollectionRequest>> _____prepareRequests(\n-            UUID colId,\n-            StatsKeyMessage keyMsg,\n-            Map<UUID, List<Integer>> reqNodes\n-    ) {\n-        Map<UUID, StatsAddrRequest<StatsCollectionRequest>> res = new HashMap<>(reqNodes.size());\n-        for (Map.Entry<UUID, List<Integer>> reqNode : reqNodes.entrySet()) {\n-            UUID reqId = UUID.randomUUID();\n-            StatsCollectionRequest colReq = new StatsCollectionRequest(colId, reqId, Collections.singletonMap(keyMsg,\n-                    reqNode.getValue().stream().mapToInt(Integer::intValue).toArray()));\n-            StatsAddrRequest<StatsCollectionRequest> addrReq = new StatsAddrRequest(colReq, reqNode.getKey());\n-            res.put(reqId, addrReq);\n-        }\n-        return res;\n-    }\n-\n-    /**\n-     * TODO\n+     * Stop statistics manager.\n      */\n     public void stop() {\n         if (statMgmtPool != null) {\n", "next_change": {"commit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 7fab3588e96..1f98ad5ca73 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -360,334 +262,199 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n             String objName,\n             String... colNames\n     ) throws IgniteCheckedException {\n-        UUID colId = UUID.randomUUID();\n-        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n-        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.singletonList(keyMsg),\n-            Collections.emptyMap());\n-\n+        StatisticsKeyMessage keyMsg = new StatisticsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        StatisticsGatheringContext status = new StatisticsGatheringContext(Collections.singleton(keyMsg));\n+        currColls.put(status.gatId(), status);\n         collectObjectStatistics(status);\n \n         status.doneFut().get();\n     }\n \n+    /**\n+     * Ensure that local gathering context exists and schedule local statistics gathering.\n+     *\n+     * @param nodeId Initiator node id.\n+     * @param gatId Gathering id.\n+     * @param reqId Request id.\n+     * @param keys Keys to collect statistics by.\n+     */\n+    public void gatherLocalObjectStatisticsAsync(UUID gatId, UUID reqId, Map<StatisticsKeyMessage, int[]> keys) {\n+        int parts = keys.values().stream().mapToInt(arr -> arr.length).sum();\n+\n+        StatisticsGatheringContext[] ctxs = new StatisticsGatheringContext[1];\n+        currColls.compute(gatId, (k, v) -> {\n+            if (v == null)\n+                v = new StatisticsGatheringContext(gatId, keys.keySet(), parts);\n+\n+            ctxs[0] = v;\n+\n+            return v;\n+        });\n+\n+        statGathering.collectLocalObjectsStatisticsAsync(reqId, keys, () -> ctxs[0].doneFut().isCancelled());\n+    }\n+\n     /** {@inheritDoc} */\n     @Override public StatsCollectionFuture<Map<GridTuple3<String, String, String[]>, ObjectStatistics>>\n     collectObjectStatisticsAsync(\n         GridTuple3<String, String, String[]>... keys\n     ) throws IgniteCheckedException {\n-        UUID colId = UUID.randomUUID();\n-        Collection<StatsKeyMessage> keysMsg = Arrays.stream(keys).map(\n-                k -> new StatsKeyMessage(k.get1(), k.get2(), Arrays.asList(k.get3()))).collect(Collectors.toList());\n+        Set<StatisticsKeyMessage> keysMsg = Arrays.stream(keys).map(\n+                k -> new StatisticsKeyMessage(k.get1(), k.get2(), Arrays.asList(k.get3()))).collect(Collectors.toSet());\n \n-        StatCollectionStatus status = new StatCollectionStatus(colId, keysMsg, Collections.emptyMap());\n+        StatisticsGatheringContext status = new StatisticsGatheringContext(keysMsg);\n \n         collectObjectStatistics(status);\n \n         return status.doneFut();\n     }\n \n-    /** {@inheritDoc} */\n-    @Override public boolean cancelObjectStatisticsCollection(UUID colId) {\n-        boolean[] res = new boolean[]{true};\n-\n-        currCollections.updateCollection(colId, s -> {\n-            if (s == null) {\n-                res[0] = false;\n-\n-                return null;\n-            }\n-\n-            s.doneFut().cancel();\n-\n-            Map<UUID, List<UUID>> nodeRequests = new HashMap<>();\n-            for (StatsAddrRequest<StatsCollectionRequest> req : s.remainingCollectionReqs().values()) {\n-                nodeRequests.compute(req.nodeId(), (k, v) -> {\n-                   if (v == null)\n-                       v = new ArrayList<>();\n-                   v.add(req.req().reqId());\n-\n-                   return v;\n-                });\n-            }\n-\n-            Collection<StatsAddrRequest<CancelStatsCollectionRequest>> cancelReqs = nodeRequests.entrySet().stream().map(\n-                        targetNode -> new StatsAddrRequest<>(\n-                            new CancelStatsCollectionRequest(colId, targetNode.getValue().toArray(new UUID[0])),\n-                            targetNode.getKey()))\n-                    .collect(Collectors.toList());\n-\n-            Collection<StatsAddrRequest<CancelStatsCollectionRequest>> failed = sendRequests(cancelReqs);\n-            if (!F.isEmpty(failed))\n-                if (log.isDebugEnabled())\n-                    log.debug(String.format(\"Unable to cancel all statistics collections requests (%d failed) by colId %s\",\n-                            failed.size(), colId));\n-\n-            return null;\n-        });\n-\n-        return res[0];\n-    }\n-\n     /**\n-     * Stop statistics manager.\n+     * Cancel specified statistics gathering process.\n+     *\n+     * @param gatId Gathering id to cancel.\n      */\n-    public void stop() {\n-        if (statMgmtPool != null) {\n-            List<Runnable> unfinishedTasks = statMgmtPool.shutdownNow();\n-            if (!unfinishedTasks.isEmpty())\n-                log.warning(String.format(\"%d statistics collection request cancelled.\", unfinishedTasks.size()));\n+    public void cancelLocalStatisticsGathering(UUID gatId){\n+       StatisticsGatheringContext stCtx = currColls.remove(gatId);\n+       if (stCtx != null)\n+           stCtx.doneFut().cancel();\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public boolean cancelObjectStatisticsGathering(UUID gatId) {\n+        boolean res = false;\n+        StatisticsGatheringContext stCtx = currColls.remove(gatId);\n+        if (stCtx != null) {\n+\n+            res = stCtx.doneFut().cancel();\n+            if (res)\n+                statCrawler.sendCancelGatheringAsync(gatId);\n         }\n+        return res;\n     }\n \n     /**\n-     * Collect partition level statistics.\n+     * Receive and store partition statistics object data for locals backup partition.\n      *\n-     * @param tbl Table to collect statistics by.\n-     * @param partIds Array of partition ids to collect statistics by.\n-     * @param selectedCols Columns to collect statistics by.\n-     * @param cancelled Supplier to check if collection was cancelled.\n-     * @return Collection of partition level statistics by local primary partitions.\n-     * @throws IgniteCheckedException in case of error.\n+     * @param data Collection of partition level statistics of local bacup partitions.\n      */\n-    private Collection<ObjectPartitionStatisticsImpl> collectPartitionStatistics(\n-            GridH2Table tbl,\n-            int[] partIds,\n-            Column[] selectedCols,\n-            Supplier<Boolean> cancelled\n-    ) {\n-        List<ObjectPartitionStatisticsImpl> tblPartStats = new ArrayList<>();\n-        GridH2RowDescriptor desc = tbl.rowDescriptor();\n-        String tblName = tbl.getName();\n-        GridDhtPartitionTopology top = tbl.cacheContext().topology();\n-        AffinityTopologyVersion topVer = top.readyTopologyVersion();\n-\n-        for (int partId : partIds) {\n-            GridDhtLocalPartition locPart = top.localPartition(partId, topVer, false);\n-            if (locPart == null)\n-                continue;\n+    public void receivePartitionsStatistics(Collection<StatisticsObjectData> data) {\n+        for (StatisticsObjectData partData : data) {\n+            StatisticsKey key = new StatisticsKey(partData.key().schema(), partData.key().obj());\n+\n+            assert partData.type() == StatisticsType.PARTITION : \"Got non partition level statistics by \" + key\n+                    + \" without request\";\n \n-            if (cancelled.get()) {\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d\", key.schema(), key.obj(),\n+                    partData.partId()));\n+\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null) {\n                 if (log.isInfoEnabled())\n-                    log.info(String.format(\"Canceled collection of object %s.%s statistics.\", tbl.identifier().schema(),\n-                            tbl.identifier().table()));\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d\", key.schema(), key.obj(),\n+                        partData.partId()));\n \n-                return null;\n+                continue;\n             }\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(ctx.localNodeId(), partData.partId());\n+            if (partState != OWNING) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d\",\n+                            key.schema(), key.obj(), partData.partId()));\n \n-            final boolean reserved = locPart.reserve();\n+                continue;\n+            }\n \n             try {\n-                if (!reserved || (locPart.state() != OWNING) || !locPart.primary(ctx.discovery().topologyVersionEx()))\n-                    continue;\n-\n-                long rowsCnt = 0;\n-\n-                List<ColumnStatisticsCollector> colStatsCollectors = new ArrayList<>(selectedCols.length);\n-\n-                for (Column col : selectedCols)\n-                    colStatsCollectors.add(new ColumnStatisticsCollector(col, tbl::compareValues));\n-\n-                for (CacheDataRow row : tbl.cacheContext().offheap().cachePartitionIterator(tbl.cacheId(), locPart.id(),\n-                        null, true)) {\n-                    GridQueryTypeDescriptor typeDesc = ctx.query().typeByValue(tbl.cacheName(),\n-                        tbl.cacheContext().cacheObjectContext(), row.key(), row.value(), false);\n-                    if (!tblName.equals(typeDesc.tableName()))\n-                        continue;\n-\n-                    rowsCnt++;\n-\n-                    H2Row row0 = desc.createRow(row);\n-\n-                    for (ColumnStatisticsCollector colStat : colStatsCollectors)\n-                        colStat.add(row0.getValue(colStat.col().getColumnId()));\n-\n-                }\n-\n-                Map<String, ColumnStatistics> colStats = colStatsCollectors.stream().collect(Collectors.toMap(\n-                    csc -> csc.col().getName(), ColumnStatisticsCollector::finish));\n+                ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n \n-                tblPartStats.add(new ObjectPartitionStatisticsImpl(locPart.id(), true, rowsCnt,\n-                        locPart.updateCounter(), colStats));\n-\n-                if (log.isTraceEnabled())\n-                    log.trace(String.format(\"Finished statistics collection on %s.%s:%d\",\n-                        tbl.identifier().schema(), tbl.identifier().table(), locPart.id()));\n+                statsRepos.saveLocalPartitionStatistics(key, opStat);\n             }\n             catch (IgniteCheckedException e) {\n-                if (log.isDebugEnabled())\n-                    log.debug(String.format(\"Unable to collect statistics by %s.%s:%d due to error %s\",\n-                        tbl.identifier().schema(), tbl.identifier().table(), partId, e.getMessage()));\n-            }\n-            finally {\n-                if (reserved)\n-                    locPart.release();\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Unable to parse partition statistics for %s.%s:%d because of: %s\",\n+                        key.schema(), key.obj(), partData.partId(), e.getMessage()));\n             }\n         }\n-\n-        return tblPartStats;\n     }\n \n     /**\n-     * Aggregate specified partition level statistics to local level statistics.\n+     * Aggregate specified gathered statistics, remove it form local and complete its future.\n      *\n-     * @param keyMsg Aggregation key.\n-     * @param stats Collection of all local partition level or local level statistics by specified key to aggregate.\n-     * @return Local level aggregated statistics.\n+     * @param stCtx Gathering to complete.\n      */\n-    public ObjectStatisticsImpl aggregateLocalStatistics(\n-            StatsKeyMessage keyMsg,\n-            Collection<? extends ObjectStatisticsImpl> stats\n-    ) {\n-        // For now there can be only tables\n-        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n-\n-        if (tbl == null) {\n-            // remove all loaded statistics.\n-            if (log.isDebugEnabled())\n-                log.debug(String.format(\"Removing statistics for object %s.%s cause table doesn't exists.\",\n-                        keyMsg.schema(), keyMsg.obj()));\n-\n-            // Just to double check\n-            statsRepos.clearLocalPartitionsStatistics(new StatsKey(keyMsg.schema(), keyMsg.obj()));\n+    public void finishStatisticsCollection(StatisticsGatheringContext stCtx) {\n+        currColls.remove(stCtx.gatId());\n+\n+        Map<StatisticsKeyMessage, ObjectStatisticsImpl> keysGlobalStats = new HashMap<>();\n+        for (Map.Entry<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : stCtx.collectedStatistics()\n+                .entrySet()) {\n+            ObjectStatisticsImpl globalCollectedStat = statGathering.aggregateLocalStatistics(keyStats.getKey(),\n+                keyStats.getValue());\n+            StatisticsKey statsKey = new StatisticsKey(keyStats.getKey().schema(), keyStats.getKey().obj());\n+            ObjectStatisticsImpl globalStat = statsRepos.mergeGlobalStatistics(statsKey, globalCollectedStat);\n+            keysGlobalStats.put(keyStats.getKey(), globalStat);\n         }\n \n-        return aggregateLocalStatistics(tbl, filterColumns(tbl.getColumns(), keyMsg.colNames()), stats);\n+        statCrawler.sendGlobalStat(keysGlobalStats);\n     }\n \n     /**\n-     * Aggregate partition level statistics to local level one.\n+     * Cache global statistics.\n      *\n-     * @param tbl Table to aggregate statistics by.\n-     * @param selectedCols Columns to aggregate statistics by.\n-     * @param stats Collection of partition level or local level statistics to aggregate.\n-     * @return Local level statistics.\n+     * @param data Global statistics to cache.\n      */\n-    private ObjectStatisticsImpl aggregateLocalStatistics(\n-            GridH2Table tbl,\n-            Column[] selectedCols,\n-            Collection<? extends ObjectStatisticsImpl> stats\n-    ) {\n-        Map<Column, List<ColumnStatistics>> colPartStats = new HashMap<>(selectedCols.length);\n-        long rowCnt = 0;\n-        for (Column col : selectedCols)\n-            colPartStats.put(col, new ArrayList<>());\n-\n-        for (ObjectStatisticsImpl partStat : stats) {\n-            for (Column col : selectedCols) {\n-                ColumnStatistics colPartStat = partStat.columnStatistics(col.getName());\n-                if (colPartStat != null) {\n-                    colPartStats.computeIfPresent(col, (k, v) -> {\n-                        v.add(colPartStat);\n-\n-                        return v;\n-                    });\n-                }\n-            }\n-            rowCnt += partStat.rowCount();\n-        }\n-\n-        Map<String, ColumnStatistics> colStats = new HashMap<>(selectedCols.length);\n-        for (Column col : selectedCols) {\n-            ColumnStatistics stat = ColumnStatisticsCollector.aggregate(tbl::compareValues, colPartStats.get(col));\n-            colStats.put(col.getName(), stat);\n-        }\n-\n-        ObjectStatisticsImpl tblStats = new ObjectStatisticsImpl(rowCnt, colStats);\n-\n-        return tblStats;\n-    }\n-\n-    /**\n-     * Receive and handle statistics propagation message with partitions statistics.\n-     *\n-     * @param nodeId Sender node id.\n-     * @param msg Statistics propagation message with partitions statistics to handle.\n-     * @throws IgniteCheckedException In case of errors.\n-     */\n-    private void receivePartitionsStatistics(UUID nodeId, StatsPropagationMessage msg) throws IgniteCheckedException {\n-        UUID locNode = ctx.localNodeId();\n-        for (StatsObjectData partData : msg.data()) {\n-            StatsKey key = new StatsKey(partData.key().schema(), partData.key().obj());\n-\n-            assert partData.type() == StatsType.PARTITION : \"Got non partition level statistics by \" + key\n-                    + \" without request\";\n-\n-            if (log.isTraceEnabled())\n-                log.trace(String.format(\"Received partition statistics %s.%s:%d from node %s\", key.schema(),\n-                        key.obj(), partData.partId(), nodeId));\n-\n-            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n-            if (tbl == null) {\n-                if (log.isInfoEnabled())\n-                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d from node %s\",\n-                            key.schema(), key.obj(), partData.partId(), nodeId));\n+    public void saveGlobalStatistics(Collection<StatisticsObjectData> data) {\n+        data.forEach(objData -> {\n+            try {\n+                ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(this.ctx, objData);\n \n-                continue;\n+                statsRepos.saveGlobalStatistics(new StatisticsKey(objData.key().schema(), objData.key().obj()), objStat);\n             }\n-            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(locNode, partData.partId());\n-            if (partState != OWNING) {\n-                if (log.isInfoEnabled())\n-                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d from node %s\",\n-                            key.schema(), key.obj(), partData.partId(), nodeId));\n-\n-                continue;\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Cannot read global statistics %s\", objData.key()));\n             }\n-\n-            ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n-\n-            statsRepos.saveLocalPartitionStatistics(key, opStat);\n-        }\n+        });\n     }\n \n     /**\n-     * Receive and handle statistics propagation message as response for collection request.\n+     * Register\n      *\n-     * @param nodeId Sender node id.\n-     * @param msg Statistics propagation message with partitions statistics to handle.\n-     * @throws IgniteCheckedException In case of errors.\n+     * @param gatId Gathering id.\n+     * @param data Collected statistics.\n      */\n-    private void receiveLocalStatistics(UUID nodeId, StatsCollectionResponse msg) {\n-        assert msg.data().keySet().stream().noneMatch(pd -> pd.type() == StatsType.PARTITION)\n-                : \"Got partition statistics by request \" + msg.reqId();\n-\n-        currCollections.updateCollection(msg.colId(), stat -> {\n-            if (stat == null) {\n-                if (log.isDebugEnabled())\n-                    log.debug(String.format(\n-                        \"Ignoring outdated local statistics collection response from node %s to col %s req %s\",\n-                            nodeId, msg.colId(), msg.reqId()));\n-\n-                return stat;\n-            }\n+    public void registerLocalResult(UUID gatId, Map<StatisticsObjectData, int[]> data) {\n+        StatisticsGatheringContext stCtx = currColls.get(gatId);\n+        if (stCtx == null) {\n+            if (log.isDebugEnabled())\n+                log.debug(String.format(\"Unable to register outdated statistics collection result %s\", gatId));\n \n-            assert stat.colId().equals(msg.colId());\n+            return;\n+        }\n+        Map<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats = new HashMap<>();\n+        for (StatisticsObjectData objData : data.keySet()) {\n+            keyStats.compute(objData.key(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n \n-            // Need syncronization here to avoid races between removing remaining reqs and adding new ones.\n-            synchronized (stat) {\n-                StatsAddrRequest<StatsCollectionRequest> req = stat.remainingCollectionReqs().remove(msg.reqId());\n+                try {\n+                    ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n \n-                if (req == null) {\n+                    v.add(objStat);\n+                }\n+                catch (IgniteCheckedException e) {\n                     if (log.isDebugEnabled())\n-                        log.debug(String.format(\n-                                \"Ignoring unknown local statistics collection response from node %s to col %s req %s\",\n-                                nodeId, msg.colId(), msg.reqId()));\n-\n-                    return stat;\n+                        log.debug(String.format(\"Cannot read local statistics %s by gathering task %s\", objData.key(),\n+                            gatId));\n                 }\n \n-                stat.localStatistics().add(msg);\n-                // TODO: reschedule if not all partition collected.\n-\n-                if (stat.remainingCollectionReqs().isEmpty()) {\n-                    Map<StatsKey, ObjectStatisticsImpl> mergedGlobal = finishStatCollection(stat);\n-\n-                    stat.doneFut().onDone(null);\n-\n-                    return null;\n-                }\n-            }\n-            return stat;\n-        });\n+                return v;\n+            });\n+        }\n+        if (stCtx.registerCollected(keyStats, data.values().stream().mapToInt(a -> a.length).sum()))\n+            finishStatisticsCollection(stCtx);\n     }\n \n     /**\n", "next_change": {"commit": "7ef165002105dd10417170217e86d65771c524bb", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 1f98ad5ca73..4e5949c6399 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -453,35 +461,9 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n                 return v;\n             });\n         }\n-        if (stCtx.registerCollected(keyStats, data.values().stream().mapToInt(a -> a.length).sum()))\n-            finishStatisticsCollection(stCtx);\n-    }\n \n-    /**\n-     * Aggregate local statistics to global one.\n-     *\n-     * @param stat Statistics collection status to aggregate.\n-     * @return Map stats key to merged global statistics.\n-     */\n-    private Map<StatisticsKey, ObjectStatisticsImpl> finishStatCollection(StatisticsGatheringContext stat) {\n-        Map<StatisticsKey, ObjectStatisticsImpl> res = new HashMap<>();\n-        for (Map.Entry<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : stat.collectedStatistics()\n-                .entrySet()) {\n-            StatisticsKeyMessage keyMsg = keyStats.getKey();\n-            GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n-            if (tbl == null) {\n-                if (log.isInfoEnabled())\n-                    log.info(String.format(\"Unable to find object %s.%s to save collected statistics by.\",\n-                            keyMsg.schema(), keyMsg.obj()));\n-\n-                continue;\n-            }\n-\n-            ObjectStatisticsImpl globalStat = statGathering.aggregateLocalStatistics(keyMsg, keyStats.getValue());\n-            StatisticsKey key = new StatisticsKey(keyMsg.schema(), keyMsg.obj());\n-            res.put(key, statsRepos.mergeGlobalStatistics(key, globalStat));\n-        }\n-        return res;\n+        if (stCtx.registerCollected(keyStats, partsCount))\n+            finishStatisticsCollection(stCtx);\n     }\n \n     /**\n", "next_change": {"commit": "05b732cd7e8840c429c48f5561e7c98e0289bcf6", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 4e5949c6399..ab2c41eca80 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -443,23 +447,17 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n         }\n         Map<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats = new HashMap<>();\n         for (StatisticsObjectData objData : data) {\n-            keyStats.compute(objData.key(), (k, v) -> {\n-                if (v == null)\n-                    v = new ArrayList<>();\n-\n-                try {\n-                    ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n-\n-                    v.add(objStat);\n-                }\n-                catch (IgniteCheckedException e) {\n-                    if (log.isDebugEnabled())\n-                        log.debug(String.format(\"Cannot read local statistics %s by gathering task %s\", objData.key(),\n-                            gatId));\n-                }\n-\n-                return v;\n-            });\n+            Collection<ObjectStatisticsImpl> keyObjStats = keyStats.computeIfAbsent(objData.key(), k -> new ArrayList<>());\n+            try {\n+                ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n+\n+                keyObjStats.add(objStat);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Cannot read local statistics %s by gathering task %s\", objData.key(),\n+                        gatId));\n+            }\n         }\n \n         if (stCtx.registerCollected(keyStats, partsCount))\n", "next_change": null}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ1MzczOQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545453739", "body": "Does \"colId\" mean \"collectionId\" or mean \"columnId\", like a \"colNames\" means column names?", "bodyText": "Does \"colId\" mean \"collectionId\" or mean \"columnId\", like a \"colNames\" means column names?", "bodyHTML": "<p dir=\"auto\">Does \"colId\" mean \"collectionId\" or mean \"columnId\", like a \"colNames\" means column names?</p>", "author": "AMashenkov", "createdAt": "2020-12-17T22:47:40Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -89,86 +157,468 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+\n+        UUID reqId = UUID.randomUUID();\n+        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        Map<UUID, List<Integer>> requestNodes = null;\n+        /*try {\n+            requestNodes = nodePartitions(extractGroups(Collections.singletonList(keyMsg)), null);\n+        } catch (IgniteCheckedException e) {\n+            // TODO: handle & remove task\n+        }\n+\n+        StatsClearRequest req = new StatsClearRequest(reqId, false, Collections.singletonList(keyMsg));\n+\n+        sendLocalRequests(reqId, req, requestNodes);*/\n+\n+        clearObjectStatisticsLocal(keyMsg);\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatsKeyMessage keyMsg) {\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n+    // TODO\n+    /**\n+     * Collect local object statistics by primary partitions of specified object.\n+     *\n+     * @param keyMsg Statistic key message to collect statistics by.\n+     * @param partIds Set of partition ids to collect statistics by.\n+     * @param cancelled Supplier to check if operation was cancelled.\n+     * @return Tuple of Collected local statistics with array of successfully collected partitions.\n+     * @throws IgniteCheckedException\n+     */\n+    private IgniteBiTuple<ObjectStatisticsImpl, int[]> collectLocalObjectStatistics(\n+            StatsKeyMessage keyMsg,\n+            int[] partIds,\n+            Supplier<Boolean> cancelled\n+    ) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", keyMsg.schema(), keyMsg.obj()));\n+\n+        Column[] selectedCols = filterColumns(tbl.getColumns(), keyMsg.colNames());\n+\n+        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, partIds, selectedCols,\n+                cancelled);\n+        if (partsStats == null) {\n+            assert cancelled.get() : \"Error collecting partition level statistics.\";\n+\n+            return null;\n+        }\n+\n+        sendPartStatsToBU(tbl, partsStats);\n+\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n+\n+        ObjectStatisticsImpl tblStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n+        statsRepos.mergeLocalStatistics(key, tblStats);\n+\n+        return new IgniteBiTuple(tblStats, partsStats.stream().map(ObjectPartitionStatisticsImpl::partId).toArray());\n+    }\n+\n+    /**\n+     * Send statistics propagation messages with partition statistics to all backups node.\n+     *\n+     * @param tbl Table to which statistics should be send.\n+     * @param objStats Collection of partition statistics to send.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void sendPartStatsToBU(\n+            GridH2Table tbl,\n+            Collection<ObjectPartitionStatisticsImpl> objStats\n+    ) throws IgniteCheckedException {\n+        UUID locNode = ctx.discovery().localNode().id();\n+        StatsKeyMessage keyMsg = new StatsKeyMessage(tbl.identifier().schema(), tbl.identifier().table(), null);\n+        GridDhtPartitionTopology topology = tbl.cacheContext().topology();\n+        Map<UUID, List<StatsObjectData>> statsByNodes = new HashMap<>();\n+        for (ObjectPartitionStatisticsImpl stat : objStats) {\n+            StatsObjectData statData = StatisticsUtils.toObjectData(keyMsg, StatsType.PARTITION, stat);\n+            for (ClusterNode partNode : topology.nodes(stat.partId(), topology.readyTopologyVersion())) {\n+                if (locNode.equals(partNode.id()))\n+                    continue;\n+\n+                statsByNodes.compute(partNode.id(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+\n+                    v.add(statData);\n+\n+                    return v;\n+                });\n+            }\n+        }\n+\n+        for (Map.Entry <UUID, List<StatsObjectData>> statToNode : statsByNodes.entrySet()) {\n+            //StatsPropagationMessage nodeMsg = StatisticsUtils.toMessage(null, statToNode.getValue());\n+\n+            //ctx.io().sendToCustomTopic(statToNode.getKey(), TOPIC, nodeMsg, GridIoPolicy.QUERY_POOL);\n+        }\n+    }\n+\n+    /**\n+     * Group local statistics by table and columns.\n+     *\n+     * @param status statistics collection status with all necessary local statistics.\n+     * @return map of tables to columns to list of local column statistics.\n+     */\n+    private Map<GridH2Table, Map<String, List<ColumnStatistics>>> groupColumnStatistics(StatCollectionStatus status) {\n+        /*Map<GridH2Table, Map<String, List<ColumnStatistics>>> result = new HashMap<>();\n+        for (StatsPropagationMessage msg : status.locStatistics) {\n+            for (StatsObjectData msgData : msg.data()) {\n+                GridH2Table dataTable = schemaMgr.dataTable(msgData.key().schema(), msgData.key().obj());\n+                if (dataTable == null) {\n+                    log.warning(String.format(\"Can't find table for received statistics: %s %s\", msgData.key().schema(),\n+                            msgData.key().obj()));\n+\n+                    continue;\n+                }\n+\n+                result.compute(dataTable, (table, columns) -> {\n+                    if (columns == null)\n+                        columns = new HashMap<>();\n+\n+                    for (Map.Entry<String, StatsColumnData> colData : msgData.data().entrySet())\n+                        columns.compute(colData.getKey(), (colName, colStatistics) -> {\n+                            if (colStatistics == null)\n+                                colStatistics = new ArrayList<>();\n+\n+                            ColumnStatistics colStat;\n+                            try {\n+                                colStat = StatisticsUtils.toColumnStatistics(ctx, colData.getValue());\n+                                colStatistics.add(colStat);\n+                            }\n+                            catch (IgniteCheckedException e) {\n+                                log.warning(String. format(\"Error while converting column statistics %s.%s - %s\",\n+                                        msgData.key().schema(), msgData.key().obj(), colName));\n+                            }\n+                            return colStatistics;\n+                        });\n+                    return columns;\n+                });\n+            }\n+        }\n+        return result;\n+        */\n+        return null;\n+    }\n+\n+    /**\n+     * Will aggregate all received local statistics and save it.\n+     *\n+     * @param request aggregation request with id only.\n+     */\n+    private void aggregateCollected(StatCollectionStatus status) {\n+        /*// Table -> Column -> List of local column stats\n+        Map<GridH2Table, Map<String, List<ColumnStatistics>>> tablesData = groupColumnStatistics(status);\n+\n+        Map<ClusterNode, List<StatsObjectData>> dataByNodes = new HashMap<>();\n+        for (Map.Entry<GridH2Table, Map<String, List<ColumnStatistics>>> tableStats : tablesData.entrySet()) {\n+            GridH2Table table = tableStats.getKey();\n+            long rowCount = 0L;\n+            Map<String, ColumnStatistics> columnStatistics = new HashMap<>();\n+            for (Map.Entry<String, List<ColumnStatistics>> columnStats : tableStats.getValue().entrySet()) {\n+                ColumnStatistics globalStatistics = ColumnStatisticsCollector\n+                        .aggregate(table::compareValues, columnStats.getValue());\n+                if (rowCount < globalStatistics.total())\n+                    rowCount = globalStatistics.total();\n+                columnStatistics.put(columnStats.getKey(), globalStatistics);\n+            }\n+\n+            ObjectStatisticsImpl objectStatistics = new ObjectStatisticsImpl(rowCount, columnStatistics);\n+            statsRepos.saveGlobalStatistics(new StatsKey(table.identifier().schema(), table.identifier().table()),\n+                    objectStatistics);\n+        }\n+        status.doneFut.onDone();\n+        */\n+\n+    }\n+\n     /**\n      * Filter columns by specified names.\n      *\n-     * @param columns Columns to filter.\n+     * @param cols Columns to filter.\n      * @param colNames Column names.\n      * @return Column with specified names.\n      */\n-    private Column[] filterColumns(Column[] columns, String... colNames) {\n+    private Column[] filterColumns(Column[] cols, @Nullable Collection<String> colNames) {\n         if (F.isEmpty(colNames))\n-            return columns;\n+            return cols;\n \n         Set<String> colNamesSet = new HashSet(Arrays.asList(colNames));\n-        List<Column> resultList = new ArrayList<>(colNames.length);\n+        List<Column> resList = new ArrayList<>(colNames.size());\n \n-        for (Column col : columns)\n+        for (Column col : cols)\n             if (colNamesSet.contains(col.getName()))\n-                resultList.add(col);\n+                resList.add(col);\n \n-        return resultList.toArray(new Column[resultList.size()]);\n+        return resList.toArray(new Column[resList.size()]);\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void collectObjectStatistics(String schemaName, String objName, String... colNames)\n-            throws IgniteCheckedException {\n-        GridH2Table tbl = schemaMgr.dataTable(schemaName, objName);\n-        if (tbl == null)\n-            throw new IllegalArgumentException(String.format(\"Can't find table %s.%s\", schemaName, objName));\n+    @Override public void collectObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        UUID colId = UUID.randomUUID();", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTAxMDI3MQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555010271", "bodyText": "each colId was renamed to gatId (gathering id) to prevent such misunderstandings.", "author": "Berkof", "createdAt": "2021-01-11T12:23:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ1MzczOQ=="}], "type": "inlineReview", "revised_code": {"commit": "ec4a9ef0e7691b605225c12527d496d07d573b42", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex ca50e8e339b..aa95be0231f 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -373,117 +373,120 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n         return resList.toArray(new Column[resList.size()]);\n     }\n \n-    /** {@inheritDoc} */\n-    @Override public void collectObjectStatistics(\n-            String schemaName,\n-            String objName,\n-            String... colNames\n-    ) throws IgniteCheckedException {\n-        StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n-        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n-        UUID colId = UUID.randomUUID();\n-        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.singletonList(keyMsg),\n-            Collections.emptyMap(), doneFut);\n+    /**\n+     * Collect object statistics prepared status.\n+     *\n+     * @param status Collection status to collect statistics by.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void collectObjectStatistics(StatCollectionStatus status) throws IgniteCheckedException {\n         synchronized (status) {\n-            currCollections.updateCollection(colId, s -> status);\n+            currCollections.updateCollection(status.colId(), s -> status);\n             Map<StatsKeyMessage, int[]> failedPartitions = null;\n             int cnt = 0;\n             do {\n-                Collection<StatsCollectionAddrRequest> reqs = currCollections.generateCollectionRequests(colId,\n-                    Collections.singletonList(keyMsg), failedPartitions);\n-                Map<UUID, StatsCollectionRequest> msgs = reqs.stream().collect(Collectors.toMap(\n-                    StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req));\n-\n-                Map<UUID, StatsCollectionRequest> failedMsgs = sendLocalRequests(msgs);\n-                failedPartitions = currCollections.extractFailed(failedMsgs.values()\n-                    .toArray(new StatsCollectionRequest[0]));\n-                if (cnt++ > 10)\n+                Collection<StatsAddrRequest<StatsCollectionRequest>> reqs = currCollections\n+                        .generateCollectionRequests(status.colId(), status.keys(), failedPartitions);\n+\n+                //Map<UUID, StatsCollectionRequest> msgs = reqs.stream().collect(Collectors.toMap(\n+                //    StatsAddrRequest::nodeId, StatsAddrRequest::req));\n+\n+                Collection<StatsAddrRequest<StatsCollectionRequest>> failedMsgs = sendLocalRequests(reqs);\n+                Map<UUID, StatsAddrRequest<StatsCollectionRequest>> sendedMsgs;\n+                if (failedMsgs == null) {\n+                    sendedMsgs = reqs.stream().collect(Collectors.toMap(r -> r.req().reqId(), r -> r));\n+                    failedPartitions = null;\n+                }\n+                else {\n+                    Set<UUID> failedIds = failedMsgs.stream().map(r -> r.req().reqId()).collect(Collectors.toSet());\n+                    sendedMsgs = reqs.stream().filter(r -> !failedIds.contains(r.req().reqId()))\n+                            .collect(Collectors.toMap(r -> r.req().reqId(), r -> r));\n+                    failedPartitions = currCollections.extractFailed(failedMsgs.stream().map(StatsAddrRequest::req)\n+                            .toArray(StatsCollectionRequest[]::new));\n+                }\n+                status.remainingCollectionReqs().putAll(sendedMsgs);\n+\n+                if (cnt++ > 10) {\n+                    StatsKeyMessage key = status.keys().iterator().next();\n+\n                     throw new IgniteCheckedException(String.format(\n-                            \"Unable to send all messages to collect statistics by key %s.%s\", schemaName, objName));\n+                            \"Unable to send all messages to collect statistics by key %s.%s and the others %d\",\n+                            key.schema(), key.obj(), status.keys().size() - 1));\n+                }\n             }\n-            while (!failedPartitions.isEmpty());\n+            while (failedPartitions != null);\n         }\n+\n         UUID locNode = ctx.discovery().localNode().id();\n-        StatsCollectionAddrRequest locReq = status.remainingCollectionReqs().get(locNode);\n-        statMgmtPool.submit(() -> processLocal(ctx.discovery().localNode().id(), locReq.req()));\n-        /*final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+        StatsAddrRequest<StatsCollectionRequest> locReq = status.remainingCollectionReqs().values().stream()\n+                .filter(r -> locNode.equals(r.nodeId())).findAny().orElse(null);\n+        if (locReq != null)\n+            statMgmtPool.submit(() -> processLocal(ctx.discovery().localNode().id(), locReq.req()));\n+    }\n \n+    /** {@inheritDoc} */\n+    @Override public void collectObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        UUID colId = UUID.randomUUID();\n+        StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter(colId);\n         StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.singletonList(keyMsg),\n+            Collections.emptyMap(), doneFut);\n+\n+        collectObjectStatistics(status);\n+\n+        doneFut.get();\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public StatsCollectionFuture<Map<GridTuple3<String, String, String[]>, ObjectStatistics>>\n+    collectObjectStatisticsAsync(\n+        GridTuple3<String, String, String[]>... keys\n+    ) throws IgniteCheckedException {\n         UUID colId = UUID.randomUUID();\n-        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.emptyMap(), doneFut);\n+        StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter(colId);\n+        Collection<StatsKeyMessage> keysMsg = Arrays.stream(keys).map(\n+                k -> new StatsKeyMessage(k.get1(), k.get2(), Arrays.asList(k.get3()))).collect(Collectors.toList());\n \n-        synchronized (status) {\n-            currCollections.put(colId, status);\n-            if (!doRequests(status, Collections.singletonList(keyMsg))) {\n-                status.doneFut().cancel();\n-                currCollections.remove(colId);\n-                throw new IgniteCheckedException(\"Unable to send statistics collection messages to all necessary nodes\");\n+        StatCollectionStatus status = new StatCollectionStatus(colId, keysMsg, Collections.emptyMap(), doneFut);\n+\n+        collectObjectStatistics(status);\n+\n+        return status.doneFut();\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public boolean cancelObjectStatisticsCollection(UUID colId) {\n+        boolean[] res = new boolean[]{true};\n+\n+        currCollections.updateCollection(colId, s -> {\n+            if (s == null) {\n+                res[0] = false;\n+\n+                return null;\n             }\n-        }\n-        UUID locNode = ctx.discovery().localNode().id();\n-        StatsCollectionAddrRequest locReq = status.remainingCollectionReqs().get(locNode);\n-        if (locReq != null)\n-            statMgmtPool.submit(() -> processLocal(locNode, locReq.req()));\n \n-        doneFut.get();\n-        */\n+            s.doneFut().cancel();\n+\n+            Collection<StatsAddrRequest<CancelStatsCollectionRequest>> cancelReqs = s.remainingCollectionReqs()\n+                .values().stream().map(r ->\n+                    new StatsAddrRequest<CancelStatsCollectionRequest>(\n+                            new CancelStatsCollectionRequest(colId, UUID.randomUUID()), r.nodeId()))\n+                    .collect(Collectors.toList());\n+\n+            Collection<StatsAddrRequest<CancelStatsCollectionRequest>> failed = sendLocalRequests(cancelReqs);\n+            if (failed != null)\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Unable to cancel all statistics collections requests (%d failed) by colId %s\",\n+                            failed.size(), colId));\n+\n+            return null;\n+        });\n \n-//\n-//        StatsKey key = new StatsKey(schemaName, objName);\n-//\n-//        List<CacheGroupContext> grpContexts = extractGroups(Collections.singletonList(key));\n-//\n-//        assert grpContexts.size() == 1;\n-//\n-//        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n-//        Map<UUID, List<Integer>> reqNodes = nodePartitions(grpContexts.get(0), null);\n-//        Map<UUID, StatsCollectionAddrRequest> reqs = prepareRequests(colId, keyMsg, reqNodes);\n-//\n-//        synchronized (status) {\n-//            currCollections.put(colId, status);\n-//\n-//            Map<UUID, StatsCollectionRequest> failedReqs = sendLocalRequests(reqs.values().stream().collect(\n-//                    Collectors.toMap(StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req)));\n-//\n-//            if (failedReqs != null) {\n-//                for (UUID failedReqId : failedReqs.keySet())\n-//                    status.remainingCollectionReqs().remove(failedReqId);\n-//\n-//                Map<StatsKeyMessage,List<Integer>> failedPartIds = extractFailed(failedReqs.values());\n-//\n-//                assert failedPartIds.size() == 1;\n-//\n-//                List<Integer> newPartIds = failedPartIds.get(keyMsg);\n-//\n-//                assert newPartIds != null;\n-//\n-//                Map<UUID, List<Integer>> newReqNodes = nodePartitions(grpContexts.get(0), newPartIds);\n-//                Map<UUID, StatsCollectionAddrRequest> newReqs = prepareRequests(colId, keyMsg, newReqNodes);\n-//                Map<UUID, StatsCollectionRequest> newFailedReqs = sendLocalRequests(newReqs.values().stream().collect(\n-//                        Collectors.toMap(StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req)));\n-//                if (newFailedReqs != null) {\n-//                    doneFut.cancel();\n-//\n-//                    // TODO: is it safe?\n-//                    currCollections.remove(colId);\n-//\n-//                    throw new IgniteCheckedException(String.format(\n-//                            \"Unable to send statistics collection request to %d nodes. Cancelling collection %s\",\n-//                            newFailedReqs.size(), colId));\n-//                }\n-//                status.remainingCollectionReqs().putAll(newReqs);\n-//\n-//                failedReqs.values().stream().forEach(req -> req.keys().values().forEach(failedPartIds.addAll()));\n-//                rescheduleFailedPartitions(colId, Collections.singletonMap(keyMsg, ));\n-//            }\n-//            UUID locNode = ctx.discovery().localNode().id();\n-//            StatsCollectionAddrRequest locReq = reqs.get(locNode);\n-//            if (locReq != null)\n-//                statMgmtPool.submit(() -> processLocal(locNode, locReq.req()));\n-//\n-//        }\n-//\n-//        doneFut.get();\n+        return res[0];\n     }\n \n     /**\n", "next_change": {"commit": "b595e90b5b480aaf80a9256558b1841334df97de", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex aa95be0231f..7fab3588e96 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -490,98 +429,7 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n     }\n \n     /**\n-     * Generate and try to send all request for particular status. Should be called inside status lock after putting it\n-     * into currCollections map. REMOVE!!!!\n-     *\n-     * @param status Status to process.\n-     * @param keys Collection of object keys to collect statistics by.\n-     * @return {@code true} if all request was successfully sended, {@code false} - otherwise (one should remove\n-     * status from cullCollections.\n-     */\n-    protected boolean doRequests(StatCollectionStatus status, List<StatsKeyMessage> keys) throws IgniteCheckedException {\n-        /*Map<CacheGroupContext, Collection<StatsKeyMessage>> grpContexts = extractGroups(keys);\n-        List<Map<UUID, StatsCollectionAddrRequest>> reqsByGrps = new ArrayList<>(grpContexts.size());\n-        for (Map.Entry<CacheGroupContext, Collection<StatsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n-            Map<UUID, List<Integer>> reqNodes = nodePartitions(grpEntry.getKey(), null);\n-            for(StatsKeyMessage keyMsg : grpEntry.getValue())\n-                reqsByGrps.add(prepareRequests(status.colId(), keyMsg, reqNodes));\n-\n-        }\n-        Map<UUID, StatsCollectionAddrRequest> reqs = compressRequests(reqsByGrps);\n-\n-        status.remainingCollectionReqs().putAll(reqs);\n-\n-        Map<UUID, StatsCollectionRequest> failedReqs = sendLocalRequests(reqs.values().stream().collect(\n-                Collectors.toMap(StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req)));\n-        // TODO: cycle replanning and sending\n-        return failedReqs.isEmpty();\n-\n-         */\n-        return false;\n-    }\n-\n-    /**\n-     * Group request by target node id. REMOVE!!!!\n-     *\n-     * @param reqsByGrps Requests to compress, map.\n-     * @return Grouped requests.\n-     */\n-    protected Map<UUID, StatsAddrRequest<StatsCollectionRequest>> compressRequests(\n-        List<Map<UUID, StatsAddrRequest<StatsCollectionRequest>>> reqsByGrps) {\n-        // NodeId to base request map\n-        Map<UUID, StatsAddrRequest<StatsCollectionRequest>> reqByNode = new HashMap<>();\n-        for (Map<UUID, StatsAddrRequest<StatsCollectionRequest>> grpReqs : reqsByGrps)\n-            for (StatsAddrRequest<StatsCollectionRequest> addReq : grpReqs.values())\n-                reqByNode.compute(addReq.nodeId(), (k, v) -> (v == null) ? addReq : addKey(v, addReq));\n-\n-        return reqByNode.entrySet().stream().collect(Collectors.toMap(e -> e.getValue().req().reqId(),\n-            Map.Entry::getValue));\n-    }\n-\n-    /**\n-     * Add keys from add request to the base one and return it.\n-     *\n-     * @param base Base request to add to.\n-     * @param add Add request to add.\n-     * @return Request with all keys from both specified.\n-     */\n-    protected StatsAddrRequest<StatsCollectionRequest> addKey(\n-        StatsAddrRequest<StatsCollectionRequest> base,\n-        StatsAddrRequest<StatsCollectionRequest> add\n-    ) {\n-        assert base.nodeId().equals(add.nodeId());\n-\n-        base.req().keys().putAll(add.req().keys());\n-        return base;\n-    }\n-\n-\n-    /**\n-     * Prepare statistics collection request for each nodes. MOVED!!!!\n-     *\n-     * @param colId Collection id.\n-     * @param keyMsg Key to collect statistics by.\n-     * @param reqNodes Map of node id to array of partition ids to be collected on that node.\n-     * @return Map: request id to statistics collection addressed request.\n-     */\n-    protected Map<UUID, StatsAddrRequest<StatsCollectionRequest>> _____prepareRequests(\n-            UUID colId,\n-            StatsKeyMessage keyMsg,\n-            Map<UUID, List<Integer>> reqNodes\n-    ) {\n-        Map<UUID, StatsAddrRequest<StatsCollectionRequest>> res = new HashMap<>(reqNodes.size());\n-        for (Map.Entry<UUID, List<Integer>> reqNode : reqNodes.entrySet()) {\n-            UUID reqId = UUID.randomUUID();\n-            StatsCollectionRequest colReq = new StatsCollectionRequest(colId, reqId, Collections.singletonMap(keyMsg,\n-                    reqNode.getValue().stream().mapToInt(Integer::intValue).toArray()));\n-            StatsAddrRequest<StatsCollectionRequest> addrReq = new StatsAddrRequest(colReq, reqNode.getKey());\n-            res.put(reqId, addrReq);\n-        }\n-        return res;\n-    }\n-\n-    /**\n-     * TODO\n+     * Stop statistics manager.\n      */\n     public void stop() {\n         if (statMgmtPool != null) {\n", "next_change": {"commit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 7fab3588e96..1f98ad5ca73 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -360,334 +262,199 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n             String objName,\n             String... colNames\n     ) throws IgniteCheckedException {\n-        UUID colId = UUID.randomUUID();\n-        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n-        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.singletonList(keyMsg),\n-            Collections.emptyMap());\n-\n+        StatisticsKeyMessage keyMsg = new StatisticsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        StatisticsGatheringContext status = new StatisticsGatheringContext(Collections.singleton(keyMsg));\n+        currColls.put(status.gatId(), status);\n         collectObjectStatistics(status);\n \n         status.doneFut().get();\n     }\n \n+    /**\n+     * Ensure that local gathering context exists and schedule local statistics gathering.\n+     *\n+     * @param nodeId Initiator node id.\n+     * @param gatId Gathering id.\n+     * @param reqId Request id.\n+     * @param keys Keys to collect statistics by.\n+     */\n+    public void gatherLocalObjectStatisticsAsync(UUID gatId, UUID reqId, Map<StatisticsKeyMessage, int[]> keys) {\n+        int parts = keys.values().stream().mapToInt(arr -> arr.length).sum();\n+\n+        StatisticsGatheringContext[] ctxs = new StatisticsGatheringContext[1];\n+        currColls.compute(gatId, (k, v) -> {\n+            if (v == null)\n+                v = new StatisticsGatheringContext(gatId, keys.keySet(), parts);\n+\n+            ctxs[0] = v;\n+\n+            return v;\n+        });\n+\n+        statGathering.collectLocalObjectsStatisticsAsync(reqId, keys, () -> ctxs[0].doneFut().isCancelled());\n+    }\n+\n     /** {@inheritDoc} */\n     @Override public StatsCollectionFuture<Map<GridTuple3<String, String, String[]>, ObjectStatistics>>\n     collectObjectStatisticsAsync(\n         GridTuple3<String, String, String[]>... keys\n     ) throws IgniteCheckedException {\n-        UUID colId = UUID.randomUUID();\n-        Collection<StatsKeyMessage> keysMsg = Arrays.stream(keys).map(\n-                k -> new StatsKeyMessage(k.get1(), k.get2(), Arrays.asList(k.get3()))).collect(Collectors.toList());\n+        Set<StatisticsKeyMessage> keysMsg = Arrays.stream(keys).map(\n+                k -> new StatisticsKeyMessage(k.get1(), k.get2(), Arrays.asList(k.get3()))).collect(Collectors.toSet());\n \n-        StatCollectionStatus status = new StatCollectionStatus(colId, keysMsg, Collections.emptyMap());\n+        StatisticsGatheringContext status = new StatisticsGatheringContext(keysMsg);\n \n         collectObjectStatistics(status);\n \n         return status.doneFut();\n     }\n \n-    /** {@inheritDoc} */\n-    @Override public boolean cancelObjectStatisticsCollection(UUID colId) {\n-        boolean[] res = new boolean[]{true};\n-\n-        currCollections.updateCollection(colId, s -> {\n-            if (s == null) {\n-                res[0] = false;\n-\n-                return null;\n-            }\n-\n-            s.doneFut().cancel();\n-\n-            Map<UUID, List<UUID>> nodeRequests = new HashMap<>();\n-            for (StatsAddrRequest<StatsCollectionRequest> req : s.remainingCollectionReqs().values()) {\n-                nodeRequests.compute(req.nodeId(), (k, v) -> {\n-                   if (v == null)\n-                       v = new ArrayList<>();\n-                   v.add(req.req().reqId());\n-\n-                   return v;\n-                });\n-            }\n-\n-            Collection<StatsAddrRequest<CancelStatsCollectionRequest>> cancelReqs = nodeRequests.entrySet().stream().map(\n-                        targetNode -> new StatsAddrRequest<>(\n-                            new CancelStatsCollectionRequest(colId, targetNode.getValue().toArray(new UUID[0])),\n-                            targetNode.getKey()))\n-                    .collect(Collectors.toList());\n-\n-            Collection<StatsAddrRequest<CancelStatsCollectionRequest>> failed = sendRequests(cancelReqs);\n-            if (!F.isEmpty(failed))\n-                if (log.isDebugEnabled())\n-                    log.debug(String.format(\"Unable to cancel all statistics collections requests (%d failed) by colId %s\",\n-                            failed.size(), colId));\n-\n-            return null;\n-        });\n-\n-        return res[0];\n-    }\n-\n     /**\n-     * Stop statistics manager.\n+     * Cancel specified statistics gathering process.\n+     *\n+     * @param gatId Gathering id to cancel.\n      */\n-    public void stop() {\n-        if (statMgmtPool != null) {\n-            List<Runnable> unfinishedTasks = statMgmtPool.shutdownNow();\n-            if (!unfinishedTasks.isEmpty())\n-                log.warning(String.format(\"%d statistics collection request cancelled.\", unfinishedTasks.size()));\n+    public void cancelLocalStatisticsGathering(UUID gatId){\n+       StatisticsGatheringContext stCtx = currColls.remove(gatId);\n+       if (stCtx != null)\n+           stCtx.doneFut().cancel();\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public boolean cancelObjectStatisticsGathering(UUID gatId) {\n+        boolean res = false;\n+        StatisticsGatheringContext stCtx = currColls.remove(gatId);\n+        if (stCtx != null) {\n+\n+            res = stCtx.doneFut().cancel();\n+            if (res)\n+                statCrawler.sendCancelGatheringAsync(gatId);\n         }\n+        return res;\n     }\n \n     /**\n-     * Collect partition level statistics.\n+     * Receive and store partition statistics object data for locals backup partition.\n      *\n-     * @param tbl Table to collect statistics by.\n-     * @param partIds Array of partition ids to collect statistics by.\n-     * @param selectedCols Columns to collect statistics by.\n-     * @param cancelled Supplier to check if collection was cancelled.\n-     * @return Collection of partition level statistics by local primary partitions.\n-     * @throws IgniteCheckedException in case of error.\n+     * @param data Collection of partition level statistics of local bacup partitions.\n      */\n-    private Collection<ObjectPartitionStatisticsImpl> collectPartitionStatistics(\n-            GridH2Table tbl,\n-            int[] partIds,\n-            Column[] selectedCols,\n-            Supplier<Boolean> cancelled\n-    ) {\n-        List<ObjectPartitionStatisticsImpl> tblPartStats = new ArrayList<>();\n-        GridH2RowDescriptor desc = tbl.rowDescriptor();\n-        String tblName = tbl.getName();\n-        GridDhtPartitionTopology top = tbl.cacheContext().topology();\n-        AffinityTopologyVersion topVer = top.readyTopologyVersion();\n-\n-        for (int partId : partIds) {\n-            GridDhtLocalPartition locPart = top.localPartition(partId, topVer, false);\n-            if (locPart == null)\n-                continue;\n+    public void receivePartitionsStatistics(Collection<StatisticsObjectData> data) {\n+        for (StatisticsObjectData partData : data) {\n+            StatisticsKey key = new StatisticsKey(partData.key().schema(), partData.key().obj());\n+\n+            assert partData.type() == StatisticsType.PARTITION : \"Got non partition level statistics by \" + key\n+                    + \" without request\";\n \n-            if (cancelled.get()) {\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d\", key.schema(), key.obj(),\n+                    partData.partId()));\n+\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null) {\n                 if (log.isInfoEnabled())\n-                    log.info(String.format(\"Canceled collection of object %s.%s statistics.\", tbl.identifier().schema(),\n-                            tbl.identifier().table()));\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d\", key.schema(), key.obj(),\n+                        partData.partId()));\n \n-                return null;\n+                continue;\n             }\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(ctx.localNodeId(), partData.partId());\n+            if (partState != OWNING) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d\",\n+                            key.schema(), key.obj(), partData.partId()));\n \n-            final boolean reserved = locPart.reserve();\n+                continue;\n+            }\n \n             try {\n-                if (!reserved || (locPart.state() != OWNING) || !locPart.primary(ctx.discovery().topologyVersionEx()))\n-                    continue;\n-\n-                long rowsCnt = 0;\n-\n-                List<ColumnStatisticsCollector> colStatsCollectors = new ArrayList<>(selectedCols.length);\n-\n-                for (Column col : selectedCols)\n-                    colStatsCollectors.add(new ColumnStatisticsCollector(col, tbl::compareValues));\n-\n-                for (CacheDataRow row : tbl.cacheContext().offheap().cachePartitionIterator(tbl.cacheId(), locPart.id(),\n-                        null, true)) {\n-                    GridQueryTypeDescriptor typeDesc = ctx.query().typeByValue(tbl.cacheName(),\n-                        tbl.cacheContext().cacheObjectContext(), row.key(), row.value(), false);\n-                    if (!tblName.equals(typeDesc.tableName()))\n-                        continue;\n-\n-                    rowsCnt++;\n-\n-                    H2Row row0 = desc.createRow(row);\n-\n-                    for (ColumnStatisticsCollector colStat : colStatsCollectors)\n-                        colStat.add(row0.getValue(colStat.col().getColumnId()));\n-\n-                }\n-\n-                Map<String, ColumnStatistics> colStats = colStatsCollectors.stream().collect(Collectors.toMap(\n-                    csc -> csc.col().getName(), ColumnStatisticsCollector::finish));\n+                ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n \n-                tblPartStats.add(new ObjectPartitionStatisticsImpl(locPart.id(), true, rowsCnt,\n-                        locPart.updateCounter(), colStats));\n-\n-                if (log.isTraceEnabled())\n-                    log.trace(String.format(\"Finished statistics collection on %s.%s:%d\",\n-                        tbl.identifier().schema(), tbl.identifier().table(), locPart.id()));\n+                statsRepos.saveLocalPartitionStatistics(key, opStat);\n             }\n             catch (IgniteCheckedException e) {\n-                if (log.isDebugEnabled())\n-                    log.debug(String.format(\"Unable to collect statistics by %s.%s:%d due to error %s\",\n-                        tbl.identifier().schema(), tbl.identifier().table(), partId, e.getMessage()));\n-            }\n-            finally {\n-                if (reserved)\n-                    locPart.release();\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Unable to parse partition statistics for %s.%s:%d because of: %s\",\n+                        key.schema(), key.obj(), partData.partId(), e.getMessage()));\n             }\n         }\n-\n-        return tblPartStats;\n     }\n \n     /**\n-     * Aggregate specified partition level statistics to local level statistics.\n+     * Aggregate specified gathered statistics, remove it form local and complete its future.\n      *\n-     * @param keyMsg Aggregation key.\n-     * @param stats Collection of all local partition level or local level statistics by specified key to aggregate.\n-     * @return Local level aggregated statistics.\n+     * @param stCtx Gathering to complete.\n      */\n-    public ObjectStatisticsImpl aggregateLocalStatistics(\n-            StatsKeyMessage keyMsg,\n-            Collection<? extends ObjectStatisticsImpl> stats\n-    ) {\n-        // For now there can be only tables\n-        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n-\n-        if (tbl == null) {\n-            // remove all loaded statistics.\n-            if (log.isDebugEnabled())\n-                log.debug(String.format(\"Removing statistics for object %s.%s cause table doesn't exists.\",\n-                        keyMsg.schema(), keyMsg.obj()));\n-\n-            // Just to double check\n-            statsRepos.clearLocalPartitionsStatistics(new StatsKey(keyMsg.schema(), keyMsg.obj()));\n+    public void finishStatisticsCollection(StatisticsGatheringContext stCtx) {\n+        currColls.remove(stCtx.gatId());\n+\n+        Map<StatisticsKeyMessage, ObjectStatisticsImpl> keysGlobalStats = new HashMap<>();\n+        for (Map.Entry<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : stCtx.collectedStatistics()\n+                .entrySet()) {\n+            ObjectStatisticsImpl globalCollectedStat = statGathering.aggregateLocalStatistics(keyStats.getKey(),\n+                keyStats.getValue());\n+            StatisticsKey statsKey = new StatisticsKey(keyStats.getKey().schema(), keyStats.getKey().obj());\n+            ObjectStatisticsImpl globalStat = statsRepos.mergeGlobalStatistics(statsKey, globalCollectedStat);\n+            keysGlobalStats.put(keyStats.getKey(), globalStat);\n         }\n \n-        return aggregateLocalStatistics(tbl, filterColumns(tbl.getColumns(), keyMsg.colNames()), stats);\n+        statCrawler.sendGlobalStat(keysGlobalStats);\n     }\n \n     /**\n-     * Aggregate partition level statistics to local level one.\n+     * Cache global statistics.\n      *\n-     * @param tbl Table to aggregate statistics by.\n-     * @param selectedCols Columns to aggregate statistics by.\n-     * @param stats Collection of partition level or local level statistics to aggregate.\n-     * @return Local level statistics.\n+     * @param data Global statistics to cache.\n      */\n-    private ObjectStatisticsImpl aggregateLocalStatistics(\n-            GridH2Table tbl,\n-            Column[] selectedCols,\n-            Collection<? extends ObjectStatisticsImpl> stats\n-    ) {\n-        Map<Column, List<ColumnStatistics>> colPartStats = new HashMap<>(selectedCols.length);\n-        long rowCnt = 0;\n-        for (Column col : selectedCols)\n-            colPartStats.put(col, new ArrayList<>());\n-\n-        for (ObjectStatisticsImpl partStat : stats) {\n-            for (Column col : selectedCols) {\n-                ColumnStatistics colPartStat = partStat.columnStatistics(col.getName());\n-                if (colPartStat != null) {\n-                    colPartStats.computeIfPresent(col, (k, v) -> {\n-                        v.add(colPartStat);\n-\n-                        return v;\n-                    });\n-                }\n-            }\n-            rowCnt += partStat.rowCount();\n-        }\n-\n-        Map<String, ColumnStatistics> colStats = new HashMap<>(selectedCols.length);\n-        for (Column col : selectedCols) {\n-            ColumnStatistics stat = ColumnStatisticsCollector.aggregate(tbl::compareValues, colPartStats.get(col));\n-            colStats.put(col.getName(), stat);\n-        }\n-\n-        ObjectStatisticsImpl tblStats = new ObjectStatisticsImpl(rowCnt, colStats);\n-\n-        return tblStats;\n-    }\n-\n-    /**\n-     * Receive and handle statistics propagation message with partitions statistics.\n-     *\n-     * @param nodeId Sender node id.\n-     * @param msg Statistics propagation message with partitions statistics to handle.\n-     * @throws IgniteCheckedException In case of errors.\n-     */\n-    private void receivePartitionsStatistics(UUID nodeId, StatsPropagationMessage msg) throws IgniteCheckedException {\n-        UUID locNode = ctx.localNodeId();\n-        for (StatsObjectData partData : msg.data()) {\n-            StatsKey key = new StatsKey(partData.key().schema(), partData.key().obj());\n-\n-            assert partData.type() == StatsType.PARTITION : \"Got non partition level statistics by \" + key\n-                    + \" without request\";\n-\n-            if (log.isTraceEnabled())\n-                log.trace(String.format(\"Received partition statistics %s.%s:%d from node %s\", key.schema(),\n-                        key.obj(), partData.partId(), nodeId));\n-\n-            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n-            if (tbl == null) {\n-                if (log.isInfoEnabled())\n-                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d from node %s\",\n-                            key.schema(), key.obj(), partData.partId(), nodeId));\n+    public void saveGlobalStatistics(Collection<StatisticsObjectData> data) {\n+        data.forEach(objData -> {\n+            try {\n+                ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(this.ctx, objData);\n \n-                continue;\n+                statsRepos.saveGlobalStatistics(new StatisticsKey(objData.key().schema(), objData.key().obj()), objStat);\n             }\n-            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(locNode, partData.partId());\n-            if (partState != OWNING) {\n-                if (log.isInfoEnabled())\n-                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d from node %s\",\n-                            key.schema(), key.obj(), partData.partId(), nodeId));\n-\n-                continue;\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Cannot read global statistics %s\", objData.key()));\n             }\n-\n-            ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n-\n-            statsRepos.saveLocalPartitionStatistics(key, opStat);\n-        }\n+        });\n     }\n \n     /**\n-     * Receive and handle statistics propagation message as response for collection request.\n+     * Register\n      *\n-     * @param nodeId Sender node id.\n-     * @param msg Statistics propagation message with partitions statistics to handle.\n-     * @throws IgniteCheckedException In case of errors.\n+     * @param gatId Gathering id.\n+     * @param data Collected statistics.\n      */\n-    private void receiveLocalStatistics(UUID nodeId, StatsCollectionResponse msg) {\n-        assert msg.data().keySet().stream().noneMatch(pd -> pd.type() == StatsType.PARTITION)\n-                : \"Got partition statistics by request \" + msg.reqId();\n-\n-        currCollections.updateCollection(msg.colId(), stat -> {\n-            if (stat == null) {\n-                if (log.isDebugEnabled())\n-                    log.debug(String.format(\n-                        \"Ignoring outdated local statistics collection response from node %s to col %s req %s\",\n-                            nodeId, msg.colId(), msg.reqId()));\n-\n-                return stat;\n-            }\n+    public void registerLocalResult(UUID gatId, Map<StatisticsObjectData, int[]> data) {\n+        StatisticsGatheringContext stCtx = currColls.get(gatId);\n+        if (stCtx == null) {\n+            if (log.isDebugEnabled())\n+                log.debug(String.format(\"Unable to register outdated statistics collection result %s\", gatId));\n \n-            assert stat.colId().equals(msg.colId());\n+            return;\n+        }\n+        Map<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats = new HashMap<>();\n+        for (StatisticsObjectData objData : data.keySet()) {\n+            keyStats.compute(objData.key(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n \n-            // Need syncronization here to avoid races between removing remaining reqs and adding new ones.\n-            synchronized (stat) {\n-                StatsAddrRequest<StatsCollectionRequest> req = stat.remainingCollectionReqs().remove(msg.reqId());\n+                try {\n+                    ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n \n-                if (req == null) {\n+                    v.add(objStat);\n+                }\n+                catch (IgniteCheckedException e) {\n                     if (log.isDebugEnabled())\n-                        log.debug(String.format(\n-                                \"Ignoring unknown local statistics collection response from node %s to col %s req %s\",\n-                                nodeId, msg.colId(), msg.reqId()));\n-\n-                    return stat;\n+                        log.debug(String.format(\"Cannot read local statistics %s by gathering task %s\", objData.key(),\n+                            gatId));\n                 }\n \n-                stat.localStatistics().add(msg);\n-                // TODO: reschedule if not all partition collected.\n-\n-                if (stat.remainingCollectionReqs().isEmpty()) {\n-                    Map<StatsKey, ObjectStatisticsImpl> mergedGlobal = finishStatCollection(stat);\n-\n-                    stat.doneFut().onDone(null);\n-\n-                    return null;\n-                }\n-            }\n-            return stat;\n-        });\n+                return v;\n+            });\n+        }\n+        if (stCtx.registerCollected(keyStats, data.values().stream().mapToInt(a -> a.length).sum()))\n+            finishStatisticsCollection(stCtx);\n     }\n \n     /**\n", "next_change": {"commit": "7ef165002105dd10417170217e86d65771c524bb", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 1f98ad5ca73..4e5949c6399 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -453,35 +461,9 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n                 return v;\n             });\n         }\n-        if (stCtx.registerCollected(keyStats, data.values().stream().mapToInt(a -> a.length).sum()))\n-            finishStatisticsCollection(stCtx);\n-    }\n \n-    /**\n-     * Aggregate local statistics to global one.\n-     *\n-     * @param stat Statistics collection status to aggregate.\n-     * @return Map stats key to merged global statistics.\n-     */\n-    private Map<StatisticsKey, ObjectStatisticsImpl> finishStatCollection(StatisticsGatheringContext stat) {\n-        Map<StatisticsKey, ObjectStatisticsImpl> res = new HashMap<>();\n-        for (Map.Entry<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : stat.collectedStatistics()\n-                .entrySet()) {\n-            StatisticsKeyMessage keyMsg = keyStats.getKey();\n-            GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n-            if (tbl == null) {\n-                if (log.isInfoEnabled())\n-                    log.info(String.format(\"Unable to find object %s.%s to save collected statistics by.\",\n-                            keyMsg.schema(), keyMsg.obj()));\n-\n-                continue;\n-            }\n-\n-            ObjectStatisticsImpl globalStat = statGathering.aggregateLocalStatistics(keyMsg, keyStats.getValue());\n-            StatisticsKey key = new StatisticsKey(keyMsg.schema(), keyMsg.obj());\n-            res.put(key, statsRepos.mergeGlobalStatistics(key, globalStat));\n-        }\n-        return res;\n+        if (stCtx.registerCollected(keyStats, partsCount))\n+            finishStatisticsCollection(stCtx);\n     }\n \n     /**\n", "next_change": {"commit": "05b732cd7e8840c429c48f5561e7c98e0289bcf6", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 4e5949c6399..ab2c41eca80 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -443,23 +447,17 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n         }\n         Map<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats = new HashMap<>();\n         for (StatisticsObjectData objData : data) {\n-            keyStats.compute(objData.key(), (k, v) -> {\n-                if (v == null)\n-                    v = new ArrayList<>();\n-\n-                try {\n-                    ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n-\n-                    v.add(objStat);\n-                }\n-                catch (IgniteCheckedException e) {\n-                    if (log.isDebugEnabled())\n-                        log.debug(String.format(\"Cannot read local statistics %s by gathering task %s\", objData.key(),\n-                            gatId));\n-                }\n-\n-                return v;\n-            });\n+            Collection<ObjectStatisticsImpl> keyObjStats = keyStats.computeIfAbsent(objData.key(), k -> new ArrayList<>());\n+            try {\n+                ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n+\n+                keyObjStats.add(objStat);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Cannot read local statistics %s by gathering task %s\", objData.key(),\n+                        gatId));\n+            }\n         }\n \n         if (stCtx.registerCollected(keyStats, partsCount))\n", "next_change": null}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ1NjIxMw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545456213", "body": "What does 'sendLocalRequests' mean? Why 'local'?", "bodyText": "What does 'sendLocalRequests' mean? Why 'local'?", "bodyHTML": "<p dir=\"auto\">What does 'sendLocalRequests' mean? Why 'local'?</p>", "author": "AMashenkov", "createdAt": "2020-12-17T22:52:55Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -89,86 +157,468 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+\n+        UUID reqId = UUID.randomUUID();\n+        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        Map<UUID, List<Integer>> requestNodes = null;\n+        /*try {\n+            requestNodes = nodePartitions(extractGroups(Collections.singletonList(keyMsg)), null);\n+        } catch (IgniteCheckedException e) {\n+            // TODO: handle & remove task\n+        }\n+\n+        StatsClearRequest req = new StatsClearRequest(reqId, false, Collections.singletonList(keyMsg));\n+\n+        sendLocalRequests(reqId, req, requestNodes);*/\n+\n+        clearObjectStatisticsLocal(keyMsg);\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatsKeyMessage keyMsg) {\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n+    // TODO\n+    /**\n+     * Collect local object statistics by primary partitions of specified object.\n+     *\n+     * @param keyMsg Statistic key message to collect statistics by.\n+     * @param partIds Set of partition ids to collect statistics by.\n+     * @param cancelled Supplier to check if operation was cancelled.\n+     * @return Tuple of Collected local statistics with array of successfully collected partitions.\n+     * @throws IgniteCheckedException\n+     */\n+    private IgniteBiTuple<ObjectStatisticsImpl, int[]> collectLocalObjectStatistics(\n+            StatsKeyMessage keyMsg,\n+            int[] partIds,\n+            Supplier<Boolean> cancelled\n+    ) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", keyMsg.schema(), keyMsg.obj()));\n+\n+        Column[] selectedCols = filterColumns(tbl.getColumns(), keyMsg.colNames());\n+\n+        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, partIds, selectedCols,\n+                cancelled);\n+        if (partsStats == null) {\n+            assert cancelled.get() : \"Error collecting partition level statistics.\";\n+\n+            return null;\n+        }\n+\n+        sendPartStatsToBU(tbl, partsStats);\n+\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n+\n+        ObjectStatisticsImpl tblStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n+        statsRepos.mergeLocalStatistics(key, tblStats);\n+\n+        return new IgniteBiTuple(tblStats, partsStats.stream().map(ObjectPartitionStatisticsImpl::partId).toArray());\n+    }\n+\n+    /**\n+     * Send statistics propagation messages with partition statistics to all backups node.\n+     *\n+     * @param tbl Table to which statistics should be send.\n+     * @param objStats Collection of partition statistics to send.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void sendPartStatsToBU(\n+            GridH2Table tbl,\n+            Collection<ObjectPartitionStatisticsImpl> objStats\n+    ) throws IgniteCheckedException {\n+        UUID locNode = ctx.discovery().localNode().id();\n+        StatsKeyMessage keyMsg = new StatsKeyMessage(tbl.identifier().schema(), tbl.identifier().table(), null);\n+        GridDhtPartitionTopology topology = tbl.cacheContext().topology();\n+        Map<UUID, List<StatsObjectData>> statsByNodes = new HashMap<>();\n+        for (ObjectPartitionStatisticsImpl stat : objStats) {\n+            StatsObjectData statData = StatisticsUtils.toObjectData(keyMsg, StatsType.PARTITION, stat);\n+            for (ClusterNode partNode : topology.nodes(stat.partId(), topology.readyTopologyVersion())) {\n+                if (locNode.equals(partNode.id()))\n+                    continue;\n+\n+                statsByNodes.compute(partNode.id(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+\n+                    v.add(statData);\n+\n+                    return v;\n+                });\n+            }\n+        }\n+\n+        for (Map.Entry <UUID, List<StatsObjectData>> statToNode : statsByNodes.entrySet()) {\n+            //StatsPropagationMessage nodeMsg = StatisticsUtils.toMessage(null, statToNode.getValue());\n+\n+            //ctx.io().sendToCustomTopic(statToNode.getKey(), TOPIC, nodeMsg, GridIoPolicy.QUERY_POOL);\n+        }\n+    }\n+\n+    /**\n+     * Group local statistics by table and columns.\n+     *\n+     * @param status statistics collection status with all necessary local statistics.\n+     * @return map of tables to columns to list of local column statistics.\n+     */\n+    private Map<GridH2Table, Map<String, List<ColumnStatistics>>> groupColumnStatistics(StatCollectionStatus status) {\n+        /*Map<GridH2Table, Map<String, List<ColumnStatistics>>> result = new HashMap<>();\n+        for (StatsPropagationMessage msg : status.locStatistics) {\n+            for (StatsObjectData msgData : msg.data()) {\n+                GridH2Table dataTable = schemaMgr.dataTable(msgData.key().schema(), msgData.key().obj());\n+                if (dataTable == null) {\n+                    log.warning(String.format(\"Can't find table for received statistics: %s %s\", msgData.key().schema(),\n+                            msgData.key().obj()));\n+\n+                    continue;\n+                }\n+\n+                result.compute(dataTable, (table, columns) -> {\n+                    if (columns == null)\n+                        columns = new HashMap<>();\n+\n+                    for (Map.Entry<String, StatsColumnData> colData : msgData.data().entrySet())\n+                        columns.compute(colData.getKey(), (colName, colStatistics) -> {\n+                            if (colStatistics == null)\n+                                colStatistics = new ArrayList<>();\n+\n+                            ColumnStatistics colStat;\n+                            try {\n+                                colStat = StatisticsUtils.toColumnStatistics(ctx, colData.getValue());\n+                                colStatistics.add(colStat);\n+                            }\n+                            catch (IgniteCheckedException e) {\n+                                log.warning(String. format(\"Error while converting column statistics %s.%s - %s\",\n+                                        msgData.key().schema(), msgData.key().obj(), colName));\n+                            }\n+                            return colStatistics;\n+                        });\n+                    return columns;\n+                });\n+            }\n+        }\n+        return result;\n+        */\n+        return null;\n+    }\n+\n+    /**\n+     * Will aggregate all received local statistics and save it.\n+     *\n+     * @param request aggregation request with id only.\n+     */\n+    private void aggregateCollected(StatCollectionStatus status) {\n+        /*// Table -> Column -> List of local column stats\n+        Map<GridH2Table, Map<String, List<ColumnStatistics>>> tablesData = groupColumnStatistics(status);\n+\n+        Map<ClusterNode, List<StatsObjectData>> dataByNodes = new HashMap<>();\n+        for (Map.Entry<GridH2Table, Map<String, List<ColumnStatistics>>> tableStats : tablesData.entrySet()) {\n+            GridH2Table table = tableStats.getKey();\n+            long rowCount = 0L;\n+            Map<String, ColumnStatistics> columnStatistics = new HashMap<>();\n+            for (Map.Entry<String, List<ColumnStatistics>> columnStats : tableStats.getValue().entrySet()) {\n+                ColumnStatistics globalStatistics = ColumnStatisticsCollector\n+                        .aggregate(table::compareValues, columnStats.getValue());\n+                if (rowCount < globalStatistics.total())\n+                    rowCount = globalStatistics.total();\n+                columnStatistics.put(columnStats.getKey(), globalStatistics);\n+            }\n+\n+            ObjectStatisticsImpl objectStatistics = new ObjectStatisticsImpl(rowCount, columnStatistics);\n+            statsRepos.saveGlobalStatistics(new StatsKey(table.identifier().schema(), table.identifier().table()),\n+                    objectStatistics);\n+        }\n+        status.doneFut.onDone();\n+        */\n+\n+    }\n+\n     /**\n      * Filter columns by specified names.\n      *\n-     * @param columns Columns to filter.\n+     * @param cols Columns to filter.\n      * @param colNames Column names.\n      * @return Column with specified names.\n      */\n-    private Column[] filterColumns(Column[] columns, String... colNames) {\n+    private Column[] filterColumns(Column[] cols, @Nullable Collection<String> colNames) {\n         if (F.isEmpty(colNames))\n-            return columns;\n+            return cols;\n \n         Set<String> colNamesSet = new HashSet(Arrays.asList(colNames));\n-        List<Column> resultList = new ArrayList<>(colNames.length);\n+        List<Column> resList = new ArrayList<>(colNames.size());\n \n-        for (Column col : columns)\n+        for (Column col : cols)\n             if (colNamesSet.contains(col.getName()))\n-                resultList.add(col);\n+                resList.add(col);\n \n-        return resultList.toArray(new Column[resultList.size()]);\n+        return resList.toArray(new Column[resList.size()]);\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void collectObjectStatistics(String schemaName, String objName, String... colNames)\n-            throws IgniteCheckedException {\n-        GridH2Table tbl = schemaMgr.dataTable(schemaName, objName);\n-        if (tbl == null)\n-            throw new IllegalArgumentException(String.format(\"Can't find table %s.%s\", schemaName, objName));\n+    @Override public void collectObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        UUID colId = UUID.randomUUID();\n+        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.singletonList(keyMsg),\n+            Collections.emptyMap(), doneFut);\n+        synchronized (status) {\n+            currCollections.updateCollection(colId, s -> status);\n+            Map<StatsKeyMessage, int[]> failedPartitions = null;\n+            int cnt = 0;\n+            do {\n+                Collection<StatsCollectionAddrRequest> reqs = currCollections.generateCollectionRequests(colId,\n+                    Collections.singletonList(keyMsg), failedPartitions);\n+                Map<UUID, StatsCollectionRequest> msgs = reqs.stream().collect(Collectors.toMap(\n+                    StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req));\n \n-        if (log.isDebugEnabled())\n-            log.debug(String.format(\"Starting statistics collection by %s.%s object\", schemaName, objName));\n+                Map<UUID, StatsCollectionRequest> failedMsgs = sendLocalRequests(msgs);", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTc0MTQ0NQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545741445", "bodyText": "I thought about locallity of requests. All of them should either collect or cancel local operations. But let it be just sendRequests.", "author": "Berkof", "createdAt": "2020-12-18T10:28:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ1NjIxMw=="}], "type": "inlineReview", "revised_code": {"commit": "ec4a9ef0e7691b605225c12527d496d07d573b42", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex ca50e8e339b..aa95be0231f 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -373,117 +373,120 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n         return resList.toArray(new Column[resList.size()]);\n     }\n \n-    /** {@inheritDoc} */\n-    @Override public void collectObjectStatistics(\n-            String schemaName,\n-            String objName,\n-            String... colNames\n-    ) throws IgniteCheckedException {\n-        StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n-        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n-        UUID colId = UUID.randomUUID();\n-        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.singletonList(keyMsg),\n-            Collections.emptyMap(), doneFut);\n+    /**\n+     * Collect object statistics prepared status.\n+     *\n+     * @param status Collection status to collect statistics by.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void collectObjectStatistics(StatCollectionStatus status) throws IgniteCheckedException {\n         synchronized (status) {\n-            currCollections.updateCollection(colId, s -> status);\n+            currCollections.updateCollection(status.colId(), s -> status);\n             Map<StatsKeyMessage, int[]> failedPartitions = null;\n             int cnt = 0;\n             do {\n-                Collection<StatsCollectionAddrRequest> reqs = currCollections.generateCollectionRequests(colId,\n-                    Collections.singletonList(keyMsg), failedPartitions);\n-                Map<UUID, StatsCollectionRequest> msgs = reqs.stream().collect(Collectors.toMap(\n-                    StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req));\n-\n-                Map<UUID, StatsCollectionRequest> failedMsgs = sendLocalRequests(msgs);\n-                failedPartitions = currCollections.extractFailed(failedMsgs.values()\n-                    .toArray(new StatsCollectionRequest[0]));\n-                if (cnt++ > 10)\n+                Collection<StatsAddrRequest<StatsCollectionRequest>> reqs = currCollections\n+                        .generateCollectionRequests(status.colId(), status.keys(), failedPartitions);\n+\n+                //Map<UUID, StatsCollectionRequest> msgs = reqs.stream().collect(Collectors.toMap(\n+                //    StatsAddrRequest::nodeId, StatsAddrRequest::req));\n+\n+                Collection<StatsAddrRequest<StatsCollectionRequest>> failedMsgs = sendLocalRequests(reqs);\n+                Map<UUID, StatsAddrRequest<StatsCollectionRequest>> sendedMsgs;\n+                if (failedMsgs == null) {\n+                    sendedMsgs = reqs.stream().collect(Collectors.toMap(r -> r.req().reqId(), r -> r));\n+                    failedPartitions = null;\n+                }\n+                else {\n+                    Set<UUID> failedIds = failedMsgs.stream().map(r -> r.req().reqId()).collect(Collectors.toSet());\n+                    sendedMsgs = reqs.stream().filter(r -> !failedIds.contains(r.req().reqId()))\n+                            .collect(Collectors.toMap(r -> r.req().reqId(), r -> r));\n+                    failedPartitions = currCollections.extractFailed(failedMsgs.stream().map(StatsAddrRequest::req)\n+                            .toArray(StatsCollectionRequest[]::new));\n+                }\n+                status.remainingCollectionReqs().putAll(sendedMsgs);\n+\n+                if (cnt++ > 10) {\n+                    StatsKeyMessage key = status.keys().iterator().next();\n+\n                     throw new IgniteCheckedException(String.format(\n-                            \"Unable to send all messages to collect statistics by key %s.%s\", schemaName, objName));\n+                            \"Unable to send all messages to collect statistics by key %s.%s and the others %d\",\n+                            key.schema(), key.obj(), status.keys().size() - 1));\n+                }\n             }\n-            while (!failedPartitions.isEmpty());\n+            while (failedPartitions != null);\n         }\n+\n         UUID locNode = ctx.discovery().localNode().id();\n-        StatsCollectionAddrRequest locReq = status.remainingCollectionReqs().get(locNode);\n-        statMgmtPool.submit(() -> processLocal(ctx.discovery().localNode().id(), locReq.req()));\n-        /*final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+        StatsAddrRequest<StatsCollectionRequest> locReq = status.remainingCollectionReqs().values().stream()\n+                .filter(r -> locNode.equals(r.nodeId())).findAny().orElse(null);\n+        if (locReq != null)\n+            statMgmtPool.submit(() -> processLocal(ctx.discovery().localNode().id(), locReq.req()));\n+    }\n \n+    /** {@inheritDoc} */\n+    @Override public void collectObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        UUID colId = UUID.randomUUID();\n+        StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter(colId);\n         StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.singletonList(keyMsg),\n+            Collections.emptyMap(), doneFut);\n+\n+        collectObjectStatistics(status);\n+\n+        doneFut.get();\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public StatsCollectionFuture<Map<GridTuple3<String, String, String[]>, ObjectStatistics>>\n+    collectObjectStatisticsAsync(\n+        GridTuple3<String, String, String[]>... keys\n+    ) throws IgniteCheckedException {\n         UUID colId = UUID.randomUUID();\n-        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.emptyMap(), doneFut);\n+        StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter(colId);\n+        Collection<StatsKeyMessage> keysMsg = Arrays.stream(keys).map(\n+                k -> new StatsKeyMessage(k.get1(), k.get2(), Arrays.asList(k.get3()))).collect(Collectors.toList());\n \n-        synchronized (status) {\n-            currCollections.put(colId, status);\n-            if (!doRequests(status, Collections.singletonList(keyMsg))) {\n-                status.doneFut().cancel();\n-                currCollections.remove(colId);\n-                throw new IgniteCheckedException(\"Unable to send statistics collection messages to all necessary nodes\");\n+        StatCollectionStatus status = new StatCollectionStatus(colId, keysMsg, Collections.emptyMap(), doneFut);\n+\n+        collectObjectStatistics(status);\n+\n+        return status.doneFut();\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public boolean cancelObjectStatisticsCollection(UUID colId) {\n+        boolean[] res = new boolean[]{true};\n+\n+        currCollections.updateCollection(colId, s -> {\n+            if (s == null) {\n+                res[0] = false;\n+\n+                return null;\n             }\n-        }\n-        UUID locNode = ctx.discovery().localNode().id();\n-        StatsCollectionAddrRequest locReq = status.remainingCollectionReqs().get(locNode);\n-        if (locReq != null)\n-            statMgmtPool.submit(() -> processLocal(locNode, locReq.req()));\n \n-        doneFut.get();\n-        */\n+            s.doneFut().cancel();\n+\n+            Collection<StatsAddrRequest<CancelStatsCollectionRequest>> cancelReqs = s.remainingCollectionReqs()\n+                .values().stream().map(r ->\n+                    new StatsAddrRequest<CancelStatsCollectionRequest>(\n+                            new CancelStatsCollectionRequest(colId, UUID.randomUUID()), r.nodeId()))\n+                    .collect(Collectors.toList());\n+\n+            Collection<StatsAddrRequest<CancelStatsCollectionRequest>> failed = sendLocalRequests(cancelReqs);\n+            if (failed != null)\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Unable to cancel all statistics collections requests (%d failed) by colId %s\",\n+                            failed.size(), colId));\n+\n+            return null;\n+        });\n \n-//\n-//        StatsKey key = new StatsKey(schemaName, objName);\n-//\n-//        List<CacheGroupContext> grpContexts = extractGroups(Collections.singletonList(key));\n-//\n-//        assert grpContexts.size() == 1;\n-//\n-//        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n-//        Map<UUID, List<Integer>> reqNodes = nodePartitions(grpContexts.get(0), null);\n-//        Map<UUID, StatsCollectionAddrRequest> reqs = prepareRequests(colId, keyMsg, reqNodes);\n-//\n-//        synchronized (status) {\n-//            currCollections.put(colId, status);\n-//\n-//            Map<UUID, StatsCollectionRequest> failedReqs = sendLocalRequests(reqs.values().stream().collect(\n-//                    Collectors.toMap(StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req)));\n-//\n-//            if (failedReqs != null) {\n-//                for (UUID failedReqId : failedReqs.keySet())\n-//                    status.remainingCollectionReqs().remove(failedReqId);\n-//\n-//                Map<StatsKeyMessage,List<Integer>> failedPartIds = extractFailed(failedReqs.values());\n-//\n-//                assert failedPartIds.size() == 1;\n-//\n-//                List<Integer> newPartIds = failedPartIds.get(keyMsg);\n-//\n-//                assert newPartIds != null;\n-//\n-//                Map<UUID, List<Integer>> newReqNodes = nodePartitions(grpContexts.get(0), newPartIds);\n-//                Map<UUID, StatsCollectionAddrRequest> newReqs = prepareRequests(colId, keyMsg, newReqNodes);\n-//                Map<UUID, StatsCollectionRequest> newFailedReqs = sendLocalRequests(newReqs.values().stream().collect(\n-//                        Collectors.toMap(StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req)));\n-//                if (newFailedReqs != null) {\n-//                    doneFut.cancel();\n-//\n-//                    // TODO: is it safe?\n-//                    currCollections.remove(colId);\n-//\n-//                    throw new IgniteCheckedException(String.format(\n-//                            \"Unable to send statistics collection request to %d nodes. Cancelling collection %s\",\n-//                            newFailedReqs.size(), colId));\n-//                }\n-//                status.remainingCollectionReqs().putAll(newReqs);\n-//\n-//                failedReqs.values().stream().forEach(req -> req.keys().values().forEach(failedPartIds.addAll()));\n-//                rescheduleFailedPartitions(colId, Collections.singletonMap(keyMsg, ));\n-//            }\n-//            UUID locNode = ctx.discovery().localNode().id();\n-//            StatsCollectionAddrRequest locReq = reqs.get(locNode);\n-//            if (locReq != null)\n-//                statMgmtPool.submit(() -> processLocal(locNode, locReq.req()));\n-//\n-//        }\n-//\n-//        doneFut.get();\n+        return res[0];\n     }\n \n     /**\n", "next_change": {"commit": "b595e90b5b480aaf80a9256558b1841334df97de", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex aa95be0231f..7fab3588e96 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -490,98 +429,7 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n     }\n \n     /**\n-     * Generate and try to send all request for particular status. Should be called inside status lock after putting it\n-     * into currCollections map. REMOVE!!!!\n-     *\n-     * @param status Status to process.\n-     * @param keys Collection of object keys to collect statistics by.\n-     * @return {@code true} if all request was successfully sended, {@code false} - otherwise (one should remove\n-     * status from cullCollections.\n-     */\n-    protected boolean doRequests(StatCollectionStatus status, List<StatsKeyMessage> keys) throws IgniteCheckedException {\n-        /*Map<CacheGroupContext, Collection<StatsKeyMessage>> grpContexts = extractGroups(keys);\n-        List<Map<UUID, StatsCollectionAddrRequest>> reqsByGrps = new ArrayList<>(grpContexts.size());\n-        for (Map.Entry<CacheGroupContext, Collection<StatsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n-            Map<UUID, List<Integer>> reqNodes = nodePartitions(grpEntry.getKey(), null);\n-            for(StatsKeyMessage keyMsg : grpEntry.getValue())\n-                reqsByGrps.add(prepareRequests(status.colId(), keyMsg, reqNodes));\n-\n-        }\n-        Map<UUID, StatsCollectionAddrRequest> reqs = compressRequests(reqsByGrps);\n-\n-        status.remainingCollectionReqs().putAll(reqs);\n-\n-        Map<UUID, StatsCollectionRequest> failedReqs = sendLocalRequests(reqs.values().stream().collect(\n-                Collectors.toMap(StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req)));\n-        // TODO: cycle replanning and sending\n-        return failedReqs.isEmpty();\n-\n-         */\n-        return false;\n-    }\n-\n-    /**\n-     * Group request by target node id. REMOVE!!!!\n-     *\n-     * @param reqsByGrps Requests to compress, map.\n-     * @return Grouped requests.\n-     */\n-    protected Map<UUID, StatsAddrRequest<StatsCollectionRequest>> compressRequests(\n-        List<Map<UUID, StatsAddrRequest<StatsCollectionRequest>>> reqsByGrps) {\n-        // NodeId to base request map\n-        Map<UUID, StatsAddrRequest<StatsCollectionRequest>> reqByNode = new HashMap<>();\n-        for (Map<UUID, StatsAddrRequest<StatsCollectionRequest>> grpReqs : reqsByGrps)\n-            for (StatsAddrRequest<StatsCollectionRequest> addReq : grpReqs.values())\n-                reqByNode.compute(addReq.nodeId(), (k, v) -> (v == null) ? addReq : addKey(v, addReq));\n-\n-        return reqByNode.entrySet().stream().collect(Collectors.toMap(e -> e.getValue().req().reqId(),\n-            Map.Entry::getValue));\n-    }\n-\n-    /**\n-     * Add keys from add request to the base one and return it.\n-     *\n-     * @param base Base request to add to.\n-     * @param add Add request to add.\n-     * @return Request with all keys from both specified.\n-     */\n-    protected StatsAddrRequest<StatsCollectionRequest> addKey(\n-        StatsAddrRequest<StatsCollectionRequest> base,\n-        StatsAddrRequest<StatsCollectionRequest> add\n-    ) {\n-        assert base.nodeId().equals(add.nodeId());\n-\n-        base.req().keys().putAll(add.req().keys());\n-        return base;\n-    }\n-\n-\n-    /**\n-     * Prepare statistics collection request for each nodes. MOVED!!!!\n-     *\n-     * @param colId Collection id.\n-     * @param keyMsg Key to collect statistics by.\n-     * @param reqNodes Map of node id to array of partition ids to be collected on that node.\n-     * @return Map: request id to statistics collection addressed request.\n-     */\n-    protected Map<UUID, StatsAddrRequest<StatsCollectionRequest>> _____prepareRequests(\n-            UUID colId,\n-            StatsKeyMessage keyMsg,\n-            Map<UUID, List<Integer>> reqNodes\n-    ) {\n-        Map<UUID, StatsAddrRequest<StatsCollectionRequest>> res = new HashMap<>(reqNodes.size());\n-        for (Map.Entry<UUID, List<Integer>> reqNode : reqNodes.entrySet()) {\n-            UUID reqId = UUID.randomUUID();\n-            StatsCollectionRequest colReq = new StatsCollectionRequest(colId, reqId, Collections.singletonMap(keyMsg,\n-                    reqNode.getValue().stream().mapToInt(Integer::intValue).toArray()));\n-            StatsAddrRequest<StatsCollectionRequest> addrReq = new StatsAddrRequest(colReq, reqNode.getKey());\n-            res.put(reqId, addrReq);\n-        }\n-        return res;\n-    }\n-\n-    /**\n-     * TODO\n+     * Stop statistics manager.\n      */\n     public void stop() {\n         if (statMgmtPool != null) {\n", "next_change": {"commit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 7fab3588e96..1f98ad5ca73 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -360,334 +262,199 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n             String objName,\n             String... colNames\n     ) throws IgniteCheckedException {\n-        UUID colId = UUID.randomUUID();\n-        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n-        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.singletonList(keyMsg),\n-            Collections.emptyMap());\n-\n+        StatisticsKeyMessage keyMsg = new StatisticsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        StatisticsGatheringContext status = new StatisticsGatheringContext(Collections.singleton(keyMsg));\n+        currColls.put(status.gatId(), status);\n         collectObjectStatistics(status);\n \n         status.doneFut().get();\n     }\n \n+    /**\n+     * Ensure that local gathering context exists and schedule local statistics gathering.\n+     *\n+     * @param nodeId Initiator node id.\n+     * @param gatId Gathering id.\n+     * @param reqId Request id.\n+     * @param keys Keys to collect statistics by.\n+     */\n+    public void gatherLocalObjectStatisticsAsync(UUID gatId, UUID reqId, Map<StatisticsKeyMessage, int[]> keys) {\n+        int parts = keys.values().stream().mapToInt(arr -> arr.length).sum();\n+\n+        StatisticsGatheringContext[] ctxs = new StatisticsGatheringContext[1];\n+        currColls.compute(gatId, (k, v) -> {\n+            if (v == null)\n+                v = new StatisticsGatheringContext(gatId, keys.keySet(), parts);\n+\n+            ctxs[0] = v;\n+\n+            return v;\n+        });\n+\n+        statGathering.collectLocalObjectsStatisticsAsync(reqId, keys, () -> ctxs[0].doneFut().isCancelled());\n+    }\n+\n     /** {@inheritDoc} */\n     @Override public StatsCollectionFuture<Map<GridTuple3<String, String, String[]>, ObjectStatistics>>\n     collectObjectStatisticsAsync(\n         GridTuple3<String, String, String[]>... keys\n     ) throws IgniteCheckedException {\n-        UUID colId = UUID.randomUUID();\n-        Collection<StatsKeyMessage> keysMsg = Arrays.stream(keys).map(\n-                k -> new StatsKeyMessage(k.get1(), k.get2(), Arrays.asList(k.get3()))).collect(Collectors.toList());\n+        Set<StatisticsKeyMessage> keysMsg = Arrays.stream(keys).map(\n+                k -> new StatisticsKeyMessage(k.get1(), k.get2(), Arrays.asList(k.get3()))).collect(Collectors.toSet());\n \n-        StatCollectionStatus status = new StatCollectionStatus(colId, keysMsg, Collections.emptyMap());\n+        StatisticsGatheringContext status = new StatisticsGatheringContext(keysMsg);\n \n         collectObjectStatistics(status);\n \n         return status.doneFut();\n     }\n \n-    /** {@inheritDoc} */\n-    @Override public boolean cancelObjectStatisticsCollection(UUID colId) {\n-        boolean[] res = new boolean[]{true};\n-\n-        currCollections.updateCollection(colId, s -> {\n-            if (s == null) {\n-                res[0] = false;\n-\n-                return null;\n-            }\n-\n-            s.doneFut().cancel();\n-\n-            Map<UUID, List<UUID>> nodeRequests = new HashMap<>();\n-            for (StatsAddrRequest<StatsCollectionRequest> req : s.remainingCollectionReqs().values()) {\n-                nodeRequests.compute(req.nodeId(), (k, v) -> {\n-                   if (v == null)\n-                       v = new ArrayList<>();\n-                   v.add(req.req().reqId());\n-\n-                   return v;\n-                });\n-            }\n-\n-            Collection<StatsAddrRequest<CancelStatsCollectionRequest>> cancelReqs = nodeRequests.entrySet().stream().map(\n-                        targetNode -> new StatsAddrRequest<>(\n-                            new CancelStatsCollectionRequest(colId, targetNode.getValue().toArray(new UUID[0])),\n-                            targetNode.getKey()))\n-                    .collect(Collectors.toList());\n-\n-            Collection<StatsAddrRequest<CancelStatsCollectionRequest>> failed = sendRequests(cancelReqs);\n-            if (!F.isEmpty(failed))\n-                if (log.isDebugEnabled())\n-                    log.debug(String.format(\"Unable to cancel all statistics collections requests (%d failed) by colId %s\",\n-                            failed.size(), colId));\n-\n-            return null;\n-        });\n-\n-        return res[0];\n-    }\n-\n     /**\n-     * Stop statistics manager.\n+     * Cancel specified statistics gathering process.\n+     *\n+     * @param gatId Gathering id to cancel.\n      */\n-    public void stop() {\n-        if (statMgmtPool != null) {\n-            List<Runnable> unfinishedTasks = statMgmtPool.shutdownNow();\n-            if (!unfinishedTasks.isEmpty())\n-                log.warning(String.format(\"%d statistics collection request cancelled.\", unfinishedTasks.size()));\n+    public void cancelLocalStatisticsGathering(UUID gatId){\n+       StatisticsGatheringContext stCtx = currColls.remove(gatId);\n+       if (stCtx != null)\n+           stCtx.doneFut().cancel();\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public boolean cancelObjectStatisticsGathering(UUID gatId) {\n+        boolean res = false;\n+        StatisticsGatheringContext stCtx = currColls.remove(gatId);\n+        if (stCtx != null) {\n+\n+            res = stCtx.doneFut().cancel();\n+            if (res)\n+                statCrawler.sendCancelGatheringAsync(gatId);\n         }\n+        return res;\n     }\n \n     /**\n-     * Collect partition level statistics.\n+     * Receive and store partition statistics object data for locals backup partition.\n      *\n-     * @param tbl Table to collect statistics by.\n-     * @param partIds Array of partition ids to collect statistics by.\n-     * @param selectedCols Columns to collect statistics by.\n-     * @param cancelled Supplier to check if collection was cancelled.\n-     * @return Collection of partition level statistics by local primary partitions.\n-     * @throws IgniteCheckedException in case of error.\n+     * @param data Collection of partition level statistics of local bacup partitions.\n      */\n-    private Collection<ObjectPartitionStatisticsImpl> collectPartitionStatistics(\n-            GridH2Table tbl,\n-            int[] partIds,\n-            Column[] selectedCols,\n-            Supplier<Boolean> cancelled\n-    ) {\n-        List<ObjectPartitionStatisticsImpl> tblPartStats = new ArrayList<>();\n-        GridH2RowDescriptor desc = tbl.rowDescriptor();\n-        String tblName = tbl.getName();\n-        GridDhtPartitionTopology top = tbl.cacheContext().topology();\n-        AffinityTopologyVersion topVer = top.readyTopologyVersion();\n-\n-        for (int partId : partIds) {\n-            GridDhtLocalPartition locPart = top.localPartition(partId, topVer, false);\n-            if (locPart == null)\n-                continue;\n+    public void receivePartitionsStatistics(Collection<StatisticsObjectData> data) {\n+        for (StatisticsObjectData partData : data) {\n+            StatisticsKey key = new StatisticsKey(partData.key().schema(), partData.key().obj());\n+\n+            assert partData.type() == StatisticsType.PARTITION : \"Got non partition level statistics by \" + key\n+                    + \" without request\";\n \n-            if (cancelled.get()) {\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d\", key.schema(), key.obj(),\n+                    partData.partId()));\n+\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null) {\n                 if (log.isInfoEnabled())\n-                    log.info(String.format(\"Canceled collection of object %s.%s statistics.\", tbl.identifier().schema(),\n-                            tbl.identifier().table()));\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d\", key.schema(), key.obj(),\n+                        partData.partId()));\n \n-                return null;\n+                continue;\n             }\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(ctx.localNodeId(), partData.partId());\n+            if (partState != OWNING) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d\",\n+                            key.schema(), key.obj(), partData.partId()));\n \n-            final boolean reserved = locPart.reserve();\n+                continue;\n+            }\n \n             try {\n-                if (!reserved || (locPart.state() != OWNING) || !locPart.primary(ctx.discovery().topologyVersionEx()))\n-                    continue;\n-\n-                long rowsCnt = 0;\n-\n-                List<ColumnStatisticsCollector> colStatsCollectors = new ArrayList<>(selectedCols.length);\n-\n-                for (Column col : selectedCols)\n-                    colStatsCollectors.add(new ColumnStatisticsCollector(col, tbl::compareValues));\n-\n-                for (CacheDataRow row : tbl.cacheContext().offheap().cachePartitionIterator(tbl.cacheId(), locPart.id(),\n-                        null, true)) {\n-                    GridQueryTypeDescriptor typeDesc = ctx.query().typeByValue(tbl.cacheName(),\n-                        tbl.cacheContext().cacheObjectContext(), row.key(), row.value(), false);\n-                    if (!tblName.equals(typeDesc.tableName()))\n-                        continue;\n-\n-                    rowsCnt++;\n-\n-                    H2Row row0 = desc.createRow(row);\n-\n-                    for (ColumnStatisticsCollector colStat : colStatsCollectors)\n-                        colStat.add(row0.getValue(colStat.col().getColumnId()));\n-\n-                }\n-\n-                Map<String, ColumnStatistics> colStats = colStatsCollectors.stream().collect(Collectors.toMap(\n-                    csc -> csc.col().getName(), ColumnStatisticsCollector::finish));\n+                ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n \n-                tblPartStats.add(new ObjectPartitionStatisticsImpl(locPart.id(), true, rowsCnt,\n-                        locPart.updateCounter(), colStats));\n-\n-                if (log.isTraceEnabled())\n-                    log.trace(String.format(\"Finished statistics collection on %s.%s:%d\",\n-                        tbl.identifier().schema(), tbl.identifier().table(), locPart.id()));\n+                statsRepos.saveLocalPartitionStatistics(key, opStat);\n             }\n             catch (IgniteCheckedException e) {\n-                if (log.isDebugEnabled())\n-                    log.debug(String.format(\"Unable to collect statistics by %s.%s:%d due to error %s\",\n-                        tbl.identifier().schema(), tbl.identifier().table(), partId, e.getMessage()));\n-            }\n-            finally {\n-                if (reserved)\n-                    locPart.release();\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Unable to parse partition statistics for %s.%s:%d because of: %s\",\n+                        key.schema(), key.obj(), partData.partId(), e.getMessage()));\n             }\n         }\n-\n-        return tblPartStats;\n     }\n \n     /**\n-     * Aggregate specified partition level statistics to local level statistics.\n+     * Aggregate specified gathered statistics, remove it form local and complete its future.\n      *\n-     * @param keyMsg Aggregation key.\n-     * @param stats Collection of all local partition level or local level statistics by specified key to aggregate.\n-     * @return Local level aggregated statistics.\n+     * @param stCtx Gathering to complete.\n      */\n-    public ObjectStatisticsImpl aggregateLocalStatistics(\n-            StatsKeyMessage keyMsg,\n-            Collection<? extends ObjectStatisticsImpl> stats\n-    ) {\n-        // For now there can be only tables\n-        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n-\n-        if (tbl == null) {\n-            // remove all loaded statistics.\n-            if (log.isDebugEnabled())\n-                log.debug(String.format(\"Removing statistics for object %s.%s cause table doesn't exists.\",\n-                        keyMsg.schema(), keyMsg.obj()));\n-\n-            // Just to double check\n-            statsRepos.clearLocalPartitionsStatistics(new StatsKey(keyMsg.schema(), keyMsg.obj()));\n+    public void finishStatisticsCollection(StatisticsGatheringContext stCtx) {\n+        currColls.remove(stCtx.gatId());\n+\n+        Map<StatisticsKeyMessage, ObjectStatisticsImpl> keysGlobalStats = new HashMap<>();\n+        for (Map.Entry<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : stCtx.collectedStatistics()\n+                .entrySet()) {\n+            ObjectStatisticsImpl globalCollectedStat = statGathering.aggregateLocalStatistics(keyStats.getKey(),\n+                keyStats.getValue());\n+            StatisticsKey statsKey = new StatisticsKey(keyStats.getKey().schema(), keyStats.getKey().obj());\n+            ObjectStatisticsImpl globalStat = statsRepos.mergeGlobalStatistics(statsKey, globalCollectedStat);\n+            keysGlobalStats.put(keyStats.getKey(), globalStat);\n         }\n \n-        return aggregateLocalStatistics(tbl, filterColumns(tbl.getColumns(), keyMsg.colNames()), stats);\n+        statCrawler.sendGlobalStat(keysGlobalStats);\n     }\n \n     /**\n-     * Aggregate partition level statistics to local level one.\n+     * Cache global statistics.\n      *\n-     * @param tbl Table to aggregate statistics by.\n-     * @param selectedCols Columns to aggregate statistics by.\n-     * @param stats Collection of partition level or local level statistics to aggregate.\n-     * @return Local level statistics.\n+     * @param data Global statistics to cache.\n      */\n-    private ObjectStatisticsImpl aggregateLocalStatistics(\n-            GridH2Table tbl,\n-            Column[] selectedCols,\n-            Collection<? extends ObjectStatisticsImpl> stats\n-    ) {\n-        Map<Column, List<ColumnStatistics>> colPartStats = new HashMap<>(selectedCols.length);\n-        long rowCnt = 0;\n-        for (Column col : selectedCols)\n-            colPartStats.put(col, new ArrayList<>());\n-\n-        for (ObjectStatisticsImpl partStat : stats) {\n-            for (Column col : selectedCols) {\n-                ColumnStatistics colPartStat = partStat.columnStatistics(col.getName());\n-                if (colPartStat != null) {\n-                    colPartStats.computeIfPresent(col, (k, v) -> {\n-                        v.add(colPartStat);\n-\n-                        return v;\n-                    });\n-                }\n-            }\n-            rowCnt += partStat.rowCount();\n-        }\n-\n-        Map<String, ColumnStatistics> colStats = new HashMap<>(selectedCols.length);\n-        for (Column col : selectedCols) {\n-            ColumnStatistics stat = ColumnStatisticsCollector.aggregate(tbl::compareValues, colPartStats.get(col));\n-            colStats.put(col.getName(), stat);\n-        }\n-\n-        ObjectStatisticsImpl tblStats = new ObjectStatisticsImpl(rowCnt, colStats);\n-\n-        return tblStats;\n-    }\n-\n-    /**\n-     * Receive and handle statistics propagation message with partitions statistics.\n-     *\n-     * @param nodeId Sender node id.\n-     * @param msg Statistics propagation message with partitions statistics to handle.\n-     * @throws IgniteCheckedException In case of errors.\n-     */\n-    private void receivePartitionsStatistics(UUID nodeId, StatsPropagationMessage msg) throws IgniteCheckedException {\n-        UUID locNode = ctx.localNodeId();\n-        for (StatsObjectData partData : msg.data()) {\n-            StatsKey key = new StatsKey(partData.key().schema(), partData.key().obj());\n-\n-            assert partData.type() == StatsType.PARTITION : \"Got non partition level statistics by \" + key\n-                    + \" without request\";\n-\n-            if (log.isTraceEnabled())\n-                log.trace(String.format(\"Received partition statistics %s.%s:%d from node %s\", key.schema(),\n-                        key.obj(), partData.partId(), nodeId));\n-\n-            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n-            if (tbl == null) {\n-                if (log.isInfoEnabled())\n-                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d from node %s\",\n-                            key.schema(), key.obj(), partData.partId(), nodeId));\n+    public void saveGlobalStatistics(Collection<StatisticsObjectData> data) {\n+        data.forEach(objData -> {\n+            try {\n+                ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(this.ctx, objData);\n \n-                continue;\n+                statsRepos.saveGlobalStatistics(new StatisticsKey(objData.key().schema(), objData.key().obj()), objStat);\n             }\n-            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(locNode, partData.partId());\n-            if (partState != OWNING) {\n-                if (log.isInfoEnabled())\n-                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d from node %s\",\n-                            key.schema(), key.obj(), partData.partId(), nodeId));\n-\n-                continue;\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Cannot read global statistics %s\", objData.key()));\n             }\n-\n-            ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n-\n-            statsRepos.saveLocalPartitionStatistics(key, opStat);\n-        }\n+        });\n     }\n \n     /**\n-     * Receive and handle statistics propagation message as response for collection request.\n+     * Register\n      *\n-     * @param nodeId Sender node id.\n-     * @param msg Statistics propagation message with partitions statistics to handle.\n-     * @throws IgniteCheckedException In case of errors.\n+     * @param gatId Gathering id.\n+     * @param data Collected statistics.\n      */\n-    private void receiveLocalStatistics(UUID nodeId, StatsCollectionResponse msg) {\n-        assert msg.data().keySet().stream().noneMatch(pd -> pd.type() == StatsType.PARTITION)\n-                : \"Got partition statistics by request \" + msg.reqId();\n-\n-        currCollections.updateCollection(msg.colId(), stat -> {\n-            if (stat == null) {\n-                if (log.isDebugEnabled())\n-                    log.debug(String.format(\n-                        \"Ignoring outdated local statistics collection response from node %s to col %s req %s\",\n-                            nodeId, msg.colId(), msg.reqId()));\n-\n-                return stat;\n-            }\n+    public void registerLocalResult(UUID gatId, Map<StatisticsObjectData, int[]> data) {\n+        StatisticsGatheringContext stCtx = currColls.get(gatId);\n+        if (stCtx == null) {\n+            if (log.isDebugEnabled())\n+                log.debug(String.format(\"Unable to register outdated statistics collection result %s\", gatId));\n \n-            assert stat.colId().equals(msg.colId());\n+            return;\n+        }\n+        Map<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats = new HashMap<>();\n+        for (StatisticsObjectData objData : data.keySet()) {\n+            keyStats.compute(objData.key(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n \n-            // Need syncronization here to avoid races between removing remaining reqs and adding new ones.\n-            synchronized (stat) {\n-                StatsAddrRequest<StatsCollectionRequest> req = stat.remainingCollectionReqs().remove(msg.reqId());\n+                try {\n+                    ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n \n-                if (req == null) {\n+                    v.add(objStat);\n+                }\n+                catch (IgniteCheckedException e) {\n                     if (log.isDebugEnabled())\n-                        log.debug(String.format(\n-                                \"Ignoring unknown local statistics collection response from node %s to col %s req %s\",\n-                                nodeId, msg.colId(), msg.reqId()));\n-\n-                    return stat;\n+                        log.debug(String.format(\"Cannot read local statistics %s by gathering task %s\", objData.key(),\n+                            gatId));\n                 }\n \n-                stat.localStatistics().add(msg);\n-                // TODO: reschedule if not all partition collected.\n-\n-                if (stat.remainingCollectionReqs().isEmpty()) {\n-                    Map<StatsKey, ObjectStatisticsImpl> mergedGlobal = finishStatCollection(stat);\n-\n-                    stat.doneFut().onDone(null);\n-\n-                    return null;\n-                }\n-            }\n-            return stat;\n-        });\n+                return v;\n+            });\n+        }\n+        if (stCtx.registerCollected(keyStats, data.values().stream().mapToInt(a -> a.length).sum()))\n+            finishStatisticsCollection(stCtx);\n     }\n \n     /**\n", "next_change": {"commit": "7ef165002105dd10417170217e86d65771c524bb", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 1f98ad5ca73..4e5949c6399 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -453,35 +461,9 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n                 return v;\n             });\n         }\n-        if (stCtx.registerCollected(keyStats, data.values().stream().mapToInt(a -> a.length).sum()))\n-            finishStatisticsCollection(stCtx);\n-    }\n \n-    /**\n-     * Aggregate local statistics to global one.\n-     *\n-     * @param stat Statistics collection status to aggregate.\n-     * @return Map stats key to merged global statistics.\n-     */\n-    private Map<StatisticsKey, ObjectStatisticsImpl> finishStatCollection(StatisticsGatheringContext stat) {\n-        Map<StatisticsKey, ObjectStatisticsImpl> res = new HashMap<>();\n-        for (Map.Entry<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : stat.collectedStatistics()\n-                .entrySet()) {\n-            StatisticsKeyMessage keyMsg = keyStats.getKey();\n-            GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n-            if (tbl == null) {\n-                if (log.isInfoEnabled())\n-                    log.info(String.format(\"Unable to find object %s.%s to save collected statistics by.\",\n-                            keyMsg.schema(), keyMsg.obj()));\n-\n-                continue;\n-            }\n-\n-            ObjectStatisticsImpl globalStat = statGathering.aggregateLocalStatistics(keyMsg, keyStats.getValue());\n-            StatisticsKey key = new StatisticsKey(keyMsg.schema(), keyMsg.obj());\n-            res.put(key, statsRepos.mergeGlobalStatistics(key, globalStat));\n-        }\n-        return res;\n+        if (stCtx.registerCollected(keyStats, partsCount))\n+            finishStatisticsCollection(stCtx);\n     }\n \n     /**\n", "next_change": {"commit": "05b732cd7e8840c429c48f5561e7c98e0289bcf6", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 4e5949c6399..ab2c41eca80 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -443,23 +447,17 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n         }\n         Map<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats = new HashMap<>();\n         for (StatisticsObjectData objData : data) {\n-            keyStats.compute(objData.key(), (k, v) -> {\n-                if (v == null)\n-                    v = new ArrayList<>();\n-\n-                try {\n-                    ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n-\n-                    v.add(objStat);\n-                }\n-                catch (IgniteCheckedException e) {\n-                    if (log.isDebugEnabled())\n-                        log.debug(String.format(\"Cannot read local statistics %s by gathering task %s\", objData.key(),\n-                            gatId));\n-                }\n-\n-                return v;\n-            });\n+            Collection<ObjectStatisticsImpl> keyObjStats = keyStats.computeIfAbsent(objData.key(), k -> new ArrayList<>());\n+            try {\n+                ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n+\n+                keyObjStats.add(objStat);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Cannot read local statistics %s by gathering task %s\", objData.key(),\n+                        gatId));\n+            }\n         }\n \n         if (stCtx.registerCollected(keyStats, partsCount))\n", "next_change": null}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ1NzI1NQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545457255", "body": "'status' doesn't reflect it's role here. \r\nIt is actually a context of current task\\operation.", "bodyText": "'status' doesn't reflect it's role here.\nIt is actually a context of current task\\operation.", "bodyHTML": "<p dir=\"auto\">'status' doesn't reflect it's role here.<br>\nIt is actually a context of current task\\operation.</p>", "author": "AMashenkov", "createdAt": "2020-12-17T22:54:58Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -89,86 +157,468 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+\n+        UUID reqId = UUID.randomUUID();\n+        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        Map<UUID, List<Integer>> requestNodes = null;\n+        /*try {\n+            requestNodes = nodePartitions(extractGroups(Collections.singletonList(keyMsg)), null);\n+        } catch (IgniteCheckedException e) {\n+            // TODO: handle & remove task\n+        }\n+\n+        StatsClearRequest req = new StatsClearRequest(reqId, false, Collections.singletonList(keyMsg));\n+\n+        sendLocalRequests(reqId, req, requestNodes);*/\n+\n+        clearObjectStatisticsLocal(keyMsg);\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatsKeyMessage keyMsg) {\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n+    // TODO\n+    /**\n+     * Collect local object statistics by primary partitions of specified object.\n+     *\n+     * @param keyMsg Statistic key message to collect statistics by.\n+     * @param partIds Set of partition ids to collect statistics by.\n+     * @param cancelled Supplier to check if operation was cancelled.\n+     * @return Tuple of Collected local statistics with array of successfully collected partitions.\n+     * @throws IgniteCheckedException\n+     */\n+    private IgniteBiTuple<ObjectStatisticsImpl, int[]> collectLocalObjectStatistics(\n+            StatsKeyMessage keyMsg,\n+            int[] partIds,\n+            Supplier<Boolean> cancelled\n+    ) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", keyMsg.schema(), keyMsg.obj()));\n+\n+        Column[] selectedCols = filterColumns(tbl.getColumns(), keyMsg.colNames());\n+\n+        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, partIds, selectedCols,\n+                cancelled);\n+        if (partsStats == null) {\n+            assert cancelled.get() : \"Error collecting partition level statistics.\";\n+\n+            return null;\n+        }\n+\n+        sendPartStatsToBU(tbl, partsStats);\n+\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n+\n+        ObjectStatisticsImpl tblStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n+        statsRepos.mergeLocalStatistics(key, tblStats);\n+\n+        return new IgniteBiTuple(tblStats, partsStats.stream().map(ObjectPartitionStatisticsImpl::partId).toArray());\n+    }\n+\n+    /**\n+     * Send statistics propagation messages with partition statistics to all backups node.\n+     *\n+     * @param tbl Table to which statistics should be send.\n+     * @param objStats Collection of partition statistics to send.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void sendPartStatsToBU(\n+            GridH2Table tbl,\n+            Collection<ObjectPartitionStatisticsImpl> objStats\n+    ) throws IgniteCheckedException {\n+        UUID locNode = ctx.discovery().localNode().id();\n+        StatsKeyMessage keyMsg = new StatsKeyMessage(tbl.identifier().schema(), tbl.identifier().table(), null);\n+        GridDhtPartitionTopology topology = tbl.cacheContext().topology();\n+        Map<UUID, List<StatsObjectData>> statsByNodes = new HashMap<>();\n+        for (ObjectPartitionStatisticsImpl stat : objStats) {\n+            StatsObjectData statData = StatisticsUtils.toObjectData(keyMsg, StatsType.PARTITION, stat);\n+            for (ClusterNode partNode : topology.nodes(stat.partId(), topology.readyTopologyVersion())) {\n+                if (locNode.equals(partNode.id()))\n+                    continue;\n+\n+                statsByNodes.compute(partNode.id(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+\n+                    v.add(statData);\n+\n+                    return v;\n+                });\n+            }\n+        }\n+\n+        for (Map.Entry <UUID, List<StatsObjectData>> statToNode : statsByNodes.entrySet()) {\n+            //StatsPropagationMessage nodeMsg = StatisticsUtils.toMessage(null, statToNode.getValue());\n+\n+            //ctx.io().sendToCustomTopic(statToNode.getKey(), TOPIC, nodeMsg, GridIoPolicy.QUERY_POOL);\n+        }\n+    }\n+\n+    /**\n+     * Group local statistics by table and columns.\n+     *\n+     * @param status statistics collection status with all necessary local statistics.\n+     * @return map of tables to columns to list of local column statistics.\n+     */\n+    private Map<GridH2Table, Map<String, List<ColumnStatistics>>> groupColumnStatistics(StatCollectionStatus status) {\n+        /*Map<GridH2Table, Map<String, List<ColumnStatistics>>> result = new HashMap<>();\n+        for (StatsPropagationMessage msg : status.locStatistics) {\n+            for (StatsObjectData msgData : msg.data()) {\n+                GridH2Table dataTable = schemaMgr.dataTable(msgData.key().schema(), msgData.key().obj());\n+                if (dataTable == null) {\n+                    log.warning(String.format(\"Can't find table for received statistics: %s %s\", msgData.key().schema(),\n+                            msgData.key().obj()));\n+\n+                    continue;\n+                }\n+\n+                result.compute(dataTable, (table, columns) -> {\n+                    if (columns == null)\n+                        columns = new HashMap<>();\n+\n+                    for (Map.Entry<String, StatsColumnData> colData : msgData.data().entrySet())\n+                        columns.compute(colData.getKey(), (colName, colStatistics) -> {\n+                            if (colStatistics == null)\n+                                colStatistics = new ArrayList<>();\n+\n+                            ColumnStatistics colStat;\n+                            try {\n+                                colStat = StatisticsUtils.toColumnStatistics(ctx, colData.getValue());\n+                                colStatistics.add(colStat);\n+                            }\n+                            catch (IgniteCheckedException e) {\n+                                log.warning(String. format(\"Error while converting column statistics %s.%s - %s\",\n+                                        msgData.key().schema(), msgData.key().obj(), colName));\n+                            }\n+                            return colStatistics;\n+                        });\n+                    return columns;\n+                });\n+            }\n+        }\n+        return result;\n+        */\n+        return null;\n+    }\n+\n+    /**\n+     * Will aggregate all received local statistics and save it.\n+     *\n+     * @param request aggregation request with id only.\n+     */\n+    private void aggregateCollected(StatCollectionStatus status) {\n+        /*// Table -> Column -> List of local column stats\n+        Map<GridH2Table, Map<String, List<ColumnStatistics>>> tablesData = groupColumnStatistics(status);\n+\n+        Map<ClusterNode, List<StatsObjectData>> dataByNodes = new HashMap<>();\n+        for (Map.Entry<GridH2Table, Map<String, List<ColumnStatistics>>> tableStats : tablesData.entrySet()) {\n+            GridH2Table table = tableStats.getKey();\n+            long rowCount = 0L;\n+            Map<String, ColumnStatistics> columnStatistics = new HashMap<>();\n+            for (Map.Entry<String, List<ColumnStatistics>> columnStats : tableStats.getValue().entrySet()) {\n+                ColumnStatistics globalStatistics = ColumnStatisticsCollector\n+                        .aggregate(table::compareValues, columnStats.getValue());\n+                if (rowCount < globalStatistics.total())\n+                    rowCount = globalStatistics.total();\n+                columnStatistics.put(columnStats.getKey(), globalStatistics);\n+            }\n+\n+            ObjectStatisticsImpl objectStatistics = new ObjectStatisticsImpl(rowCount, columnStatistics);\n+            statsRepos.saveGlobalStatistics(new StatsKey(table.identifier().schema(), table.identifier().table()),\n+                    objectStatistics);\n+        }\n+        status.doneFut.onDone();\n+        */\n+\n+    }\n+\n     /**\n      * Filter columns by specified names.\n      *\n-     * @param columns Columns to filter.\n+     * @param cols Columns to filter.\n      * @param colNames Column names.\n      * @return Column with specified names.\n      */\n-    private Column[] filterColumns(Column[] columns, String... colNames) {\n+    private Column[] filterColumns(Column[] cols, @Nullable Collection<String> colNames) {\n         if (F.isEmpty(colNames))\n-            return columns;\n+            return cols;\n \n         Set<String> colNamesSet = new HashSet(Arrays.asList(colNames));\n-        List<Column> resultList = new ArrayList<>(colNames.length);\n+        List<Column> resList = new ArrayList<>(colNames.size());\n \n-        for (Column col : columns)\n+        for (Column col : cols)\n             if (colNamesSet.contains(col.getName()))\n-                resultList.add(col);\n+                resList.add(col);\n \n-        return resultList.toArray(new Column[resultList.size()]);\n+        return resList.toArray(new Column[resList.size()]);\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void collectObjectStatistics(String schemaName, String objName, String... colNames)\n-            throws IgniteCheckedException {\n-        GridH2Table tbl = schemaMgr.dataTable(schemaName, objName);\n-        if (tbl == null)\n-            throw new IllegalArgumentException(String.format(\"Can't find table %s.%s\", schemaName, objName));\n+    @Override public void collectObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        UUID colId = UUID.randomUUID();\n+        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.singletonList(keyMsg),\n+            Collections.emptyMap(), doneFut);\n+        synchronized (status) {\n+            currCollections.updateCollection(colId, s -> status);\n+            Map<StatsKeyMessage, int[]> failedPartitions = null;\n+            int cnt = 0;\n+            do {\n+                Collection<StatsCollectionAddrRequest> reqs = currCollections.generateCollectionRequests(colId,\n+                    Collections.singletonList(keyMsg), failedPartitions);\n+                Map<UUID, StatsCollectionRequest> msgs = reqs.stream().collect(Collectors.toMap(\n+                    StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req));\n \n-        if (log.isDebugEnabled())\n-            log.debug(String.format(\"Starting statistics collection by %s.%s object\", schemaName, objName));\n+                Map<UUID, StatsCollectionRequest> failedMsgs = sendLocalRequests(msgs);\n+                failedPartitions = currCollections.extractFailed(failedMsgs.values()\n+                    .toArray(new StatsCollectionRequest[0]));\n+                if (cnt++ > 10)\n+                    throw new IgniteCheckedException(String.format(\n+                            \"Unable to send all messages to collect statistics by key %s.%s\", schemaName, objName));\n+            }\n+            while (!failedPartitions.isEmpty());\n+        }\n+        UUID locNode = ctx.discovery().localNode().id();\n+        StatsCollectionAddrRequest locReq = status.remainingCollectionReqs().get(locNode);", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ1ODU5OQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545458599", "bodyText": "I would think we just created requests to 'reqs' map. but why we looking for local-node-request in status.remaining().\nI can't figure out how we get there.", "author": "AMashenkov", "createdAt": "2020-12-17T22:57:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ1NzI1NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTc0NzUxNw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545747517", "bodyText": "Why 'status' doesn't fit here? Main purpouse of these function is just to send requests by specified status and update status with sended requests. So it's both status (in general it still represent the state of collection operation) and context (collectObjectStatistics update it with sended requests).\nYour comment a little bit outdated in second part, but I'll describe current situation:\n\nreqs  = currCollections.generateCollectionRequests(...   - we generate requests which should be sended ideally.\nfailedMsgs = sendRequests(reqs)    - we try to send as many requests as possible and return failed ones. BUT we didn't even try to send request to the local node. So it's no way to fail it.\nsendedMsgs = reqs minus failed. - If local node should participate in collection - the request will be in sendedMsg\nstatsu.remainingCollectReqs().putAll(sendedMsgs) - will add local collection request with others to status, so we may get it from here.", "author": "Berkof", "createdAt": "2020-12-18T10:40:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ1NzI1NQ=="}], "type": "inlineReview", "revised_code": {"commit": "ec4a9ef0e7691b605225c12527d496d07d573b42", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex ca50e8e339b..aa95be0231f 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -373,117 +373,120 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n         return resList.toArray(new Column[resList.size()]);\n     }\n \n-    /** {@inheritDoc} */\n-    @Override public void collectObjectStatistics(\n-            String schemaName,\n-            String objName,\n-            String... colNames\n-    ) throws IgniteCheckedException {\n-        StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n-        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n-        UUID colId = UUID.randomUUID();\n-        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.singletonList(keyMsg),\n-            Collections.emptyMap(), doneFut);\n+    /**\n+     * Collect object statistics prepared status.\n+     *\n+     * @param status Collection status to collect statistics by.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void collectObjectStatistics(StatCollectionStatus status) throws IgniteCheckedException {\n         synchronized (status) {\n-            currCollections.updateCollection(colId, s -> status);\n+            currCollections.updateCollection(status.colId(), s -> status);\n             Map<StatsKeyMessage, int[]> failedPartitions = null;\n             int cnt = 0;\n             do {\n-                Collection<StatsCollectionAddrRequest> reqs = currCollections.generateCollectionRequests(colId,\n-                    Collections.singletonList(keyMsg), failedPartitions);\n-                Map<UUID, StatsCollectionRequest> msgs = reqs.stream().collect(Collectors.toMap(\n-                    StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req));\n-\n-                Map<UUID, StatsCollectionRequest> failedMsgs = sendLocalRequests(msgs);\n-                failedPartitions = currCollections.extractFailed(failedMsgs.values()\n-                    .toArray(new StatsCollectionRequest[0]));\n-                if (cnt++ > 10)\n+                Collection<StatsAddrRequest<StatsCollectionRequest>> reqs = currCollections\n+                        .generateCollectionRequests(status.colId(), status.keys(), failedPartitions);\n+\n+                //Map<UUID, StatsCollectionRequest> msgs = reqs.stream().collect(Collectors.toMap(\n+                //    StatsAddrRequest::nodeId, StatsAddrRequest::req));\n+\n+                Collection<StatsAddrRequest<StatsCollectionRequest>> failedMsgs = sendLocalRequests(reqs);\n+                Map<UUID, StatsAddrRequest<StatsCollectionRequest>> sendedMsgs;\n+                if (failedMsgs == null) {\n+                    sendedMsgs = reqs.stream().collect(Collectors.toMap(r -> r.req().reqId(), r -> r));\n+                    failedPartitions = null;\n+                }\n+                else {\n+                    Set<UUID> failedIds = failedMsgs.stream().map(r -> r.req().reqId()).collect(Collectors.toSet());\n+                    sendedMsgs = reqs.stream().filter(r -> !failedIds.contains(r.req().reqId()))\n+                            .collect(Collectors.toMap(r -> r.req().reqId(), r -> r));\n+                    failedPartitions = currCollections.extractFailed(failedMsgs.stream().map(StatsAddrRequest::req)\n+                            .toArray(StatsCollectionRequest[]::new));\n+                }\n+                status.remainingCollectionReqs().putAll(sendedMsgs);\n+\n+                if (cnt++ > 10) {\n+                    StatsKeyMessage key = status.keys().iterator().next();\n+\n                     throw new IgniteCheckedException(String.format(\n-                            \"Unable to send all messages to collect statistics by key %s.%s\", schemaName, objName));\n+                            \"Unable to send all messages to collect statistics by key %s.%s and the others %d\",\n+                            key.schema(), key.obj(), status.keys().size() - 1));\n+                }\n             }\n-            while (!failedPartitions.isEmpty());\n+            while (failedPartitions != null);\n         }\n+\n         UUID locNode = ctx.discovery().localNode().id();\n-        StatsCollectionAddrRequest locReq = status.remainingCollectionReqs().get(locNode);\n-        statMgmtPool.submit(() -> processLocal(ctx.discovery().localNode().id(), locReq.req()));\n-        /*final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+        StatsAddrRequest<StatsCollectionRequest> locReq = status.remainingCollectionReqs().values().stream()\n+                .filter(r -> locNode.equals(r.nodeId())).findAny().orElse(null);\n+        if (locReq != null)\n+            statMgmtPool.submit(() -> processLocal(ctx.discovery().localNode().id(), locReq.req()));\n+    }\n \n+    /** {@inheritDoc} */\n+    @Override public void collectObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        UUID colId = UUID.randomUUID();\n+        StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter(colId);\n         StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.singletonList(keyMsg),\n+            Collections.emptyMap(), doneFut);\n+\n+        collectObjectStatistics(status);\n+\n+        doneFut.get();\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public StatsCollectionFuture<Map<GridTuple3<String, String, String[]>, ObjectStatistics>>\n+    collectObjectStatisticsAsync(\n+        GridTuple3<String, String, String[]>... keys\n+    ) throws IgniteCheckedException {\n         UUID colId = UUID.randomUUID();\n-        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.emptyMap(), doneFut);\n+        StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter(colId);\n+        Collection<StatsKeyMessage> keysMsg = Arrays.stream(keys).map(\n+                k -> new StatsKeyMessage(k.get1(), k.get2(), Arrays.asList(k.get3()))).collect(Collectors.toList());\n \n-        synchronized (status) {\n-            currCollections.put(colId, status);\n-            if (!doRequests(status, Collections.singletonList(keyMsg))) {\n-                status.doneFut().cancel();\n-                currCollections.remove(colId);\n-                throw new IgniteCheckedException(\"Unable to send statistics collection messages to all necessary nodes\");\n+        StatCollectionStatus status = new StatCollectionStatus(colId, keysMsg, Collections.emptyMap(), doneFut);\n+\n+        collectObjectStatistics(status);\n+\n+        return status.doneFut();\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public boolean cancelObjectStatisticsCollection(UUID colId) {\n+        boolean[] res = new boolean[]{true};\n+\n+        currCollections.updateCollection(colId, s -> {\n+            if (s == null) {\n+                res[0] = false;\n+\n+                return null;\n             }\n-        }\n-        UUID locNode = ctx.discovery().localNode().id();\n-        StatsCollectionAddrRequest locReq = status.remainingCollectionReqs().get(locNode);\n-        if (locReq != null)\n-            statMgmtPool.submit(() -> processLocal(locNode, locReq.req()));\n \n-        doneFut.get();\n-        */\n+            s.doneFut().cancel();\n+\n+            Collection<StatsAddrRequest<CancelStatsCollectionRequest>> cancelReqs = s.remainingCollectionReqs()\n+                .values().stream().map(r ->\n+                    new StatsAddrRequest<CancelStatsCollectionRequest>(\n+                            new CancelStatsCollectionRequest(colId, UUID.randomUUID()), r.nodeId()))\n+                    .collect(Collectors.toList());\n+\n+            Collection<StatsAddrRequest<CancelStatsCollectionRequest>> failed = sendLocalRequests(cancelReqs);\n+            if (failed != null)\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Unable to cancel all statistics collections requests (%d failed) by colId %s\",\n+                            failed.size(), colId));\n+\n+            return null;\n+        });\n \n-//\n-//        StatsKey key = new StatsKey(schemaName, objName);\n-//\n-//        List<CacheGroupContext> grpContexts = extractGroups(Collections.singletonList(key));\n-//\n-//        assert grpContexts.size() == 1;\n-//\n-//        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n-//        Map<UUID, List<Integer>> reqNodes = nodePartitions(grpContexts.get(0), null);\n-//        Map<UUID, StatsCollectionAddrRequest> reqs = prepareRequests(colId, keyMsg, reqNodes);\n-//\n-//        synchronized (status) {\n-//            currCollections.put(colId, status);\n-//\n-//            Map<UUID, StatsCollectionRequest> failedReqs = sendLocalRequests(reqs.values().stream().collect(\n-//                    Collectors.toMap(StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req)));\n-//\n-//            if (failedReqs != null) {\n-//                for (UUID failedReqId : failedReqs.keySet())\n-//                    status.remainingCollectionReqs().remove(failedReqId);\n-//\n-//                Map<StatsKeyMessage,List<Integer>> failedPartIds = extractFailed(failedReqs.values());\n-//\n-//                assert failedPartIds.size() == 1;\n-//\n-//                List<Integer> newPartIds = failedPartIds.get(keyMsg);\n-//\n-//                assert newPartIds != null;\n-//\n-//                Map<UUID, List<Integer>> newReqNodes = nodePartitions(grpContexts.get(0), newPartIds);\n-//                Map<UUID, StatsCollectionAddrRequest> newReqs = prepareRequests(colId, keyMsg, newReqNodes);\n-//                Map<UUID, StatsCollectionRequest> newFailedReqs = sendLocalRequests(newReqs.values().stream().collect(\n-//                        Collectors.toMap(StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req)));\n-//                if (newFailedReqs != null) {\n-//                    doneFut.cancel();\n-//\n-//                    // TODO: is it safe?\n-//                    currCollections.remove(colId);\n-//\n-//                    throw new IgniteCheckedException(String.format(\n-//                            \"Unable to send statistics collection request to %d nodes. Cancelling collection %s\",\n-//                            newFailedReqs.size(), colId));\n-//                }\n-//                status.remainingCollectionReqs().putAll(newReqs);\n-//\n-//                failedReqs.values().stream().forEach(req -> req.keys().values().forEach(failedPartIds.addAll()));\n-//                rescheduleFailedPartitions(colId, Collections.singletonMap(keyMsg, ));\n-//            }\n-//            UUID locNode = ctx.discovery().localNode().id();\n-//            StatsCollectionAddrRequest locReq = reqs.get(locNode);\n-//            if (locReq != null)\n-//                statMgmtPool.submit(() -> processLocal(locNode, locReq.req()));\n-//\n-//        }\n-//\n-//        doneFut.get();\n+        return res[0];\n     }\n \n     /**\n", "next_change": {"commit": "b595e90b5b480aaf80a9256558b1841334df97de", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex aa95be0231f..7fab3588e96 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -490,98 +429,7 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n     }\n \n     /**\n-     * Generate and try to send all request for particular status. Should be called inside status lock after putting it\n-     * into currCollections map. REMOVE!!!!\n-     *\n-     * @param status Status to process.\n-     * @param keys Collection of object keys to collect statistics by.\n-     * @return {@code true} if all request was successfully sended, {@code false} - otherwise (one should remove\n-     * status from cullCollections.\n-     */\n-    protected boolean doRequests(StatCollectionStatus status, List<StatsKeyMessage> keys) throws IgniteCheckedException {\n-        /*Map<CacheGroupContext, Collection<StatsKeyMessage>> grpContexts = extractGroups(keys);\n-        List<Map<UUID, StatsCollectionAddrRequest>> reqsByGrps = new ArrayList<>(grpContexts.size());\n-        for (Map.Entry<CacheGroupContext, Collection<StatsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n-            Map<UUID, List<Integer>> reqNodes = nodePartitions(grpEntry.getKey(), null);\n-            for(StatsKeyMessage keyMsg : grpEntry.getValue())\n-                reqsByGrps.add(prepareRequests(status.colId(), keyMsg, reqNodes));\n-\n-        }\n-        Map<UUID, StatsCollectionAddrRequest> reqs = compressRequests(reqsByGrps);\n-\n-        status.remainingCollectionReqs().putAll(reqs);\n-\n-        Map<UUID, StatsCollectionRequest> failedReqs = sendLocalRequests(reqs.values().stream().collect(\n-                Collectors.toMap(StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req)));\n-        // TODO: cycle replanning and sending\n-        return failedReqs.isEmpty();\n-\n-         */\n-        return false;\n-    }\n-\n-    /**\n-     * Group request by target node id. REMOVE!!!!\n-     *\n-     * @param reqsByGrps Requests to compress, map.\n-     * @return Grouped requests.\n-     */\n-    protected Map<UUID, StatsAddrRequest<StatsCollectionRequest>> compressRequests(\n-        List<Map<UUID, StatsAddrRequest<StatsCollectionRequest>>> reqsByGrps) {\n-        // NodeId to base request map\n-        Map<UUID, StatsAddrRequest<StatsCollectionRequest>> reqByNode = new HashMap<>();\n-        for (Map<UUID, StatsAddrRequest<StatsCollectionRequest>> grpReqs : reqsByGrps)\n-            for (StatsAddrRequest<StatsCollectionRequest> addReq : grpReqs.values())\n-                reqByNode.compute(addReq.nodeId(), (k, v) -> (v == null) ? addReq : addKey(v, addReq));\n-\n-        return reqByNode.entrySet().stream().collect(Collectors.toMap(e -> e.getValue().req().reqId(),\n-            Map.Entry::getValue));\n-    }\n-\n-    /**\n-     * Add keys from add request to the base one and return it.\n-     *\n-     * @param base Base request to add to.\n-     * @param add Add request to add.\n-     * @return Request with all keys from both specified.\n-     */\n-    protected StatsAddrRequest<StatsCollectionRequest> addKey(\n-        StatsAddrRequest<StatsCollectionRequest> base,\n-        StatsAddrRequest<StatsCollectionRequest> add\n-    ) {\n-        assert base.nodeId().equals(add.nodeId());\n-\n-        base.req().keys().putAll(add.req().keys());\n-        return base;\n-    }\n-\n-\n-    /**\n-     * Prepare statistics collection request for each nodes. MOVED!!!!\n-     *\n-     * @param colId Collection id.\n-     * @param keyMsg Key to collect statistics by.\n-     * @param reqNodes Map of node id to array of partition ids to be collected on that node.\n-     * @return Map: request id to statistics collection addressed request.\n-     */\n-    protected Map<UUID, StatsAddrRequest<StatsCollectionRequest>> _____prepareRequests(\n-            UUID colId,\n-            StatsKeyMessage keyMsg,\n-            Map<UUID, List<Integer>> reqNodes\n-    ) {\n-        Map<UUID, StatsAddrRequest<StatsCollectionRequest>> res = new HashMap<>(reqNodes.size());\n-        for (Map.Entry<UUID, List<Integer>> reqNode : reqNodes.entrySet()) {\n-            UUID reqId = UUID.randomUUID();\n-            StatsCollectionRequest colReq = new StatsCollectionRequest(colId, reqId, Collections.singletonMap(keyMsg,\n-                    reqNode.getValue().stream().mapToInt(Integer::intValue).toArray()));\n-            StatsAddrRequest<StatsCollectionRequest> addrReq = new StatsAddrRequest(colReq, reqNode.getKey());\n-            res.put(reqId, addrReq);\n-        }\n-        return res;\n-    }\n-\n-    /**\n-     * TODO\n+     * Stop statistics manager.\n      */\n     public void stop() {\n         if (statMgmtPool != null) {\n", "next_change": {"commit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 7fab3588e96..1f98ad5ca73 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -360,334 +262,199 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n             String objName,\n             String... colNames\n     ) throws IgniteCheckedException {\n-        UUID colId = UUID.randomUUID();\n-        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n-        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.singletonList(keyMsg),\n-            Collections.emptyMap());\n-\n+        StatisticsKeyMessage keyMsg = new StatisticsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        StatisticsGatheringContext status = new StatisticsGatheringContext(Collections.singleton(keyMsg));\n+        currColls.put(status.gatId(), status);\n         collectObjectStatistics(status);\n \n         status.doneFut().get();\n     }\n \n+    /**\n+     * Ensure that local gathering context exists and schedule local statistics gathering.\n+     *\n+     * @param nodeId Initiator node id.\n+     * @param gatId Gathering id.\n+     * @param reqId Request id.\n+     * @param keys Keys to collect statistics by.\n+     */\n+    public void gatherLocalObjectStatisticsAsync(UUID gatId, UUID reqId, Map<StatisticsKeyMessage, int[]> keys) {\n+        int parts = keys.values().stream().mapToInt(arr -> arr.length).sum();\n+\n+        StatisticsGatheringContext[] ctxs = new StatisticsGatheringContext[1];\n+        currColls.compute(gatId, (k, v) -> {\n+            if (v == null)\n+                v = new StatisticsGatheringContext(gatId, keys.keySet(), parts);\n+\n+            ctxs[0] = v;\n+\n+            return v;\n+        });\n+\n+        statGathering.collectLocalObjectsStatisticsAsync(reqId, keys, () -> ctxs[0].doneFut().isCancelled());\n+    }\n+\n     /** {@inheritDoc} */\n     @Override public StatsCollectionFuture<Map<GridTuple3<String, String, String[]>, ObjectStatistics>>\n     collectObjectStatisticsAsync(\n         GridTuple3<String, String, String[]>... keys\n     ) throws IgniteCheckedException {\n-        UUID colId = UUID.randomUUID();\n-        Collection<StatsKeyMessage> keysMsg = Arrays.stream(keys).map(\n-                k -> new StatsKeyMessage(k.get1(), k.get2(), Arrays.asList(k.get3()))).collect(Collectors.toList());\n+        Set<StatisticsKeyMessage> keysMsg = Arrays.stream(keys).map(\n+                k -> new StatisticsKeyMessage(k.get1(), k.get2(), Arrays.asList(k.get3()))).collect(Collectors.toSet());\n \n-        StatCollectionStatus status = new StatCollectionStatus(colId, keysMsg, Collections.emptyMap());\n+        StatisticsGatheringContext status = new StatisticsGatheringContext(keysMsg);\n \n         collectObjectStatistics(status);\n \n         return status.doneFut();\n     }\n \n-    /** {@inheritDoc} */\n-    @Override public boolean cancelObjectStatisticsCollection(UUID colId) {\n-        boolean[] res = new boolean[]{true};\n-\n-        currCollections.updateCollection(colId, s -> {\n-            if (s == null) {\n-                res[0] = false;\n-\n-                return null;\n-            }\n-\n-            s.doneFut().cancel();\n-\n-            Map<UUID, List<UUID>> nodeRequests = new HashMap<>();\n-            for (StatsAddrRequest<StatsCollectionRequest> req : s.remainingCollectionReqs().values()) {\n-                nodeRequests.compute(req.nodeId(), (k, v) -> {\n-                   if (v == null)\n-                       v = new ArrayList<>();\n-                   v.add(req.req().reqId());\n-\n-                   return v;\n-                });\n-            }\n-\n-            Collection<StatsAddrRequest<CancelStatsCollectionRequest>> cancelReqs = nodeRequests.entrySet().stream().map(\n-                        targetNode -> new StatsAddrRequest<>(\n-                            new CancelStatsCollectionRequest(colId, targetNode.getValue().toArray(new UUID[0])),\n-                            targetNode.getKey()))\n-                    .collect(Collectors.toList());\n-\n-            Collection<StatsAddrRequest<CancelStatsCollectionRequest>> failed = sendRequests(cancelReqs);\n-            if (!F.isEmpty(failed))\n-                if (log.isDebugEnabled())\n-                    log.debug(String.format(\"Unable to cancel all statistics collections requests (%d failed) by colId %s\",\n-                            failed.size(), colId));\n-\n-            return null;\n-        });\n-\n-        return res[0];\n-    }\n-\n     /**\n-     * Stop statistics manager.\n+     * Cancel specified statistics gathering process.\n+     *\n+     * @param gatId Gathering id to cancel.\n      */\n-    public void stop() {\n-        if (statMgmtPool != null) {\n-            List<Runnable> unfinishedTasks = statMgmtPool.shutdownNow();\n-            if (!unfinishedTasks.isEmpty())\n-                log.warning(String.format(\"%d statistics collection request cancelled.\", unfinishedTasks.size()));\n+    public void cancelLocalStatisticsGathering(UUID gatId){\n+       StatisticsGatheringContext stCtx = currColls.remove(gatId);\n+       if (stCtx != null)\n+           stCtx.doneFut().cancel();\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public boolean cancelObjectStatisticsGathering(UUID gatId) {\n+        boolean res = false;\n+        StatisticsGatheringContext stCtx = currColls.remove(gatId);\n+        if (stCtx != null) {\n+\n+            res = stCtx.doneFut().cancel();\n+            if (res)\n+                statCrawler.sendCancelGatheringAsync(gatId);\n         }\n+        return res;\n     }\n \n     /**\n-     * Collect partition level statistics.\n+     * Receive and store partition statistics object data for locals backup partition.\n      *\n-     * @param tbl Table to collect statistics by.\n-     * @param partIds Array of partition ids to collect statistics by.\n-     * @param selectedCols Columns to collect statistics by.\n-     * @param cancelled Supplier to check if collection was cancelled.\n-     * @return Collection of partition level statistics by local primary partitions.\n-     * @throws IgniteCheckedException in case of error.\n+     * @param data Collection of partition level statistics of local bacup partitions.\n      */\n-    private Collection<ObjectPartitionStatisticsImpl> collectPartitionStatistics(\n-            GridH2Table tbl,\n-            int[] partIds,\n-            Column[] selectedCols,\n-            Supplier<Boolean> cancelled\n-    ) {\n-        List<ObjectPartitionStatisticsImpl> tblPartStats = new ArrayList<>();\n-        GridH2RowDescriptor desc = tbl.rowDescriptor();\n-        String tblName = tbl.getName();\n-        GridDhtPartitionTopology top = tbl.cacheContext().topology();\n-        AffinityTopologyVersion topVer = top.readyTopologyVersion();\n-\n-        for (int partId : partIds) {\n-            GridDhtLocalPartition locPart = top.localPartition(partId, topVer, false);\n-            if (locPart == null)\n-                continue;\n+    public void receivePartitionsStatistics(Collection<StatisticsObjectData> data) {\n+        for (StatisticsObjectData partData : data) {\n+            StatisticsKey key = new StatisticsKey(partData.key().schema(), partData.key().obj());\n+\n+            assert partData.type() == StatisticsType.PARTITION : \"Got non partition level statistics by \" + key\n+                    + \" without request\";\n \n-            if (cancelled.get()) {\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d\", key.schema(), key.obj(),\n+                    partData.partId()));\n+\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null) {\n                 if (log.isInfoEnabled())\n-                    log.info(String.format(\"Canceled collection of object %s.%s statistics.\", tbl.identifier().schema(),\n-                            tbl.identifier().table()));\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d\", key.schema(), key.obj(),\n+                        partData.partId()));\n \n-                return null;\n+                continue;\n             }\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(ctx.localNodeId(), partData.partId());\n+            if (partState != OWNING) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d\",\n+                            key.schema(), key.obj(), partData.partId()));\n \n-            final boolean reserved = locPart.reserve();\n+                continue;\n+            }\n \n             try {\n-                if (!reserved || (locPart.state() != OWNING) || !locPart.primary(ctx.discovery().topologyVersionEx()))\n-                    continue;\n-\n-                long rowsCnt = 0;\n-\n-                List<ColumnStatisticsCollector> colStatsCollectors = new ArrayList<>(selectedCols.length);\n-\n-                for (Column col : selectedCols)\n-                    colStatsCollectors.add(new ColumnStatisticsCollector(col, tbl::compareValues));\n-\n-                for (CacheDataRow row : tbl.cacheContext().offheap().cachePartitionIterator(tbl.cacheId(), locPart.id(),\n-                        null, true)) {\n-                    GridQueryTypeDescriptor typeDesc = ctx.query().typeByValue(tbl.cacheName(),\n-                        tbl.cacheContext().cacheObjectContext(), row.key(), row.value(), false);\n-                    if (!tblName.equals(typeDesc.tableName()))\n-                        continue;\n-\n-                    rowsCnt++;\n-\n-                    H2Row row0 = desc.createRow(row);\n-\n-                    for (ColumnStatisticsCollector colStat : colStatsCollectors)\n-                        colStat.add(row0.getValue(colStat.col().getColumnId()));\n-\n-                }\n-\n-                Map<String, ColumnStatistics> colStats = colStatsCollectors.stream().collect(Collectors.toMap(\n-                    csc -> csc.col().getName(), ColumnStatisticsCollector::finish));\n+                ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n \n-                tblPartStats.add(new ObjectPartitionStatisticsImpl(locPart.id(), true, rowsCnt,\n-                        locPart.updateCounter(), colStats));\n-\n-                if (log.isTraceEnabled())\n-                    log.trace(String.format(\"Finished statistics collection on %s.%s:%d\",\n-                        tbl.identifier().schema(), tbl.identifier().table(), locPart.id()));\n+                statsRepos.saveLocalPartitionStatistics(key, opStat);\n             }\n             catch (IgniteCheckedException e) {\n-                if (log.isDebugEnabled())\n-                    log.debug(String.format(\"Unable to collect statistics by %s.%s:%d due to error %s\",\n-                        tbl.identifier().schema(), tbl.identifier().table(), partId, e.getMessage()));\n-            }\n-            finally {\n-                if (reserved)\n-                    locPart.release();\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Unable to parse partition statistics for %s.%s:%d because of: %s\",\n+                        key.schema(), key.obj(), partData.partId(), e.getMessage()));\n             }\n         }\n-\n-        return tblPartStats;\n     }\n \n     /**\n-     * Aggregate specified partition level statistics to local level statistics.\n+     * Aggregate specified gathered statistics, remove it form local and complete its future.\n      *\n-     * @param keyMsg Aggregation key.\n-     * @param stats Collection of all local partition level or local level statistics by specified key to aggregate.\n-     * @return Local level aggregated statistics.\n+     * @param stCtx Gathering to complete.\n      */\n-    public ObjectStatisticsImpl aggregateLocalStatistics(\n-            StatsKeyMessage keyMsg,\n-            Collection<? extends ObjectStatisticsImpl> stats\n-    ) {\n-        // For now there can be only tables\n-        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n-\n-        if (tbl == null) {\n-            // remove all loaded statistics.\n-            if (log.isDebugEnabled())\n-                log.debug(String.format(\"Removing statistics for object %s.%s cause table doesn't exists.\",\n-                        keyMsg.schema(), keyMsg.obj()));\n-\n-            // Just to double check\n-            statsRepos.clearLocalPartitionsStatistics(new StatsKey(keyMsg.schema(), keyMsg.obj()));\n+    public void finishStatisticsCollection(StatisticsGatheringContext stCtx) {\n+        currColls.remove(stCtx.gatId());\n+\n+        Map<StatisticsKeyMessage, ObjectStatisticsImpl> keysGlobalStats = new HashMap<>();\n+        for (Map.Entry<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : stCtx.collectedStatistics()\n+                .entrySet()) {\n+            ObjectStatisticsImpl globalCollectedStat = statGathering.aggregateLocalStatistics(keyStats.getKey(),\n+                keyStats.getValue());\n+            StatisticsKey statsKey = new StatisticsKey(keyStats.getKey().schema(), keyStats.getKey().obj());\n+            ObjectStatisticsImpl globalStat = statsRepos.mergeGlobalStatistics(statsKey, globalCollectedStat);\n+            keysGlobalStats.put(keyStats.getKey(), globalStat);\n         }\n \n-        return aggregateLocalStatistics(tbl, filterColumns(tbl.getColumns(), keyMsg.colNames()), stats);\n+        statCrawler.sendGlobalStat(keysGlobalStats);\n     }\n \n     /**\n-     * Aggregate partition level statistics to local level one.\n+     * Cache global statistics.\n      *\n-     * @param tbl Table to aggregate statistics by.\n-     * @param selectedCols Columns to aggregate statistics by.\n-     * @param stats Collection of partition level or local level statistics to aggregate.\n-     * @return Local level statistics.\n+     * @param data Global statistics to cache.\n      */\n-    private ObjectStatisticsImpl aggregateLocalStatistics(\n-            GridH2Table tbl,\n-            Column[] selectedCols,\n-            Collection<? extends ObjectStatisticsImpl> stats\n-    ) {\n-        Map<Column, List<ColumnStatistics>> colPartStats = new HashMap<>(selectedCols.length);\n-        long rowCnt = 0;\n-        for (Column col : selectedCols)\n-            colPartStats.put(col, new ArrayList<>());\n-\n-        for (ObjectStatisticsImpl partStat : stats) {\n-            for (Column col : selectedCols) {\n-                ColumnStatistics colPartStat = partStat.columnStatistics(col.getName());\n-                if (colPartStat != null) {\n-                    colPartStats.computeIfPresent(col, (k, v) -> {\n-                        v.add(colPartStat);\n-\n-                        return v;\n-                    });\n-                }\n-            }\n-            rowCnt += partStat.rowCount();\n-        }\n-\n-        Map<String, ColumnStatistics> colStats = new HashMap<>(selectedCols.length);\n-        for (Column col : selectedCols) {\n-            ColumnStatistics stat = ColumnStatisticsCollector.aggregate(tbl::compareValues, colPartStats.get(col));\n-            colStats.put(col.getName(), stat);\n-        }\n-\n-        ObjectStatisticsImpl tblStats = new ObjectStatisticsImpl(rowCnt, colStats);\n-\n-        return tblStats;\n-    }\n-\n-    /**\n-     * Receive and handle statistics propagation message with partitions statistics.\n-     *\n-     * @param nodeId Sender node id.\n-     * @param msg Statistics propagation message with partitions statistics to handle.\n-     * @throws IgniteCheckedException In case of errors.\n-     */\n-    private void receivePartitionsStatistics(UUID nodeId, StatsPropagationMessage msg) throws IgniteCheckedException {\n-        UUID locNode = ctx.localNodeId();\n-        for (StatsObjectData partData : msg.data()) {\n-            StatsKey key = new StatsKey(partData.key().schema(), partData.key().obj());\n-\n-            assert partData.type() == StatsType.PARTITION : \"Got non partition level statistics by \" + key\n-                    + \" without request\";\n-\n-            if (log.isTraceEnabled())\n-                log.trace(String.format(\"Received partition statistics %s.%s:%d from node %s\", key.schema(),\n-                        key.obj(), partData.partId(), nodeId));\n-\n-            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n-            if (tbl == null) {\n-                if (log.isInfoEnabled())\n-                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d from node %s\",\n-                            key.schema(), key.obj(), partData.partId(), nodeId));\n+    public void saveGlobalStatistics(Collection<StatisticsObjectData> data) {\n+        data.forEach(objData -> {\n+            try {\n+                ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(this.ctx, objData);\n \n-                continue;\n+                statsRepos.saveGlobalStatistics(new StatisticsKey(objData.key().schema(), objData.key().obj()), objStat);\n             }\n-            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(locNode, partData.partId());\n-            if (partState != OWNING) {\n-                if (log.isInfoEnabled())\n-                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d from node %s\",\n-                            key.schema(), key.obj(), partData.partId(), nodeId));\n-\n-                continue;\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Cannot read global statistics %s\", objData.key()));\n             }\n-\n-            ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n-\n-            statsRepos.saveLocalPartitionStatistics(key, opStat);\n-        }\n+        });\n     }\n \n     /**\n-     * Receive and handle statistics propagation message as response for collection request.\n+     * Register\n      *\n-     * @param nodeId Sender node id.\n-     * @param msg Statistics propagation message with partitions statistics to handle.\n-     * @throws IgniteCheckedException In case of errors.\n+     * @param gatId Gathering id.\n+     * @param data Collected statistics.\n      */\n-    private void receiveLocalStatistics(UUID nodeId, StatsCollectionResponse msg) {\n-        assert msg.data().keySet().stream().noneMatch(pd -> pd.type() == StatsType.PARTITION)\n-                : \"Got partition statistics by request \" + msg.reqId();\n-\n-        currCollections.updateCollection(msg.colId(), stat -> {\n-            if (stat == null) {\n-                if (log.isDebugEnabled())\n-                    log.debug(String.format(\n-                        \"Ignoring outdated local statistics collection response from node %s to col %s req %s\",\n-                            nodeId, msg.colId(), msg.reqId()));\n-\n-                return stat;\n-            }\n+    public void registerLocalResult(UUID gatId, Map<StatisticsObjectData, int[]> data) {\n+        StatisticsGatheringContext stCtx = currColls.get(gatId);\n+        if (stCtx == null) {\n+            if (log.isDebugEnabled())\n+                log.debug(String.format(\"Unable to register outdated statistics collection result %s\", gatId));\n \n-            assert stat.colId().equals(msg.colId());\n+            return;\n+        }\n+        Map<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats = new HashMap<>();\n+        for (StatisticsObjectData objData : data.keySet()) {\n+            keyStats.compute(objData.key(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n \n-            // Need syncronization here to avoid races between removing remaining reqs and adding new ones.\n-            synchronized (stat) {\n-                StatsAddrRequest<StatsCollectionRequest> req = stat.remainingCollectionReqs().remove(msg.reqId());\n+                try {\n+                    ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n \n-                if (req == null) {\n+                    v.add(objStat);\n+                }\n+                catch (IgniteCheckedException e) {\n                     if (log.isDebugEnabled())\n-                        log.debug(String.format(\n-                                \"Ignoring unknown local statistics collection response from node %s to col %s req %s\",\n-                                nodeId, msg.colId(), msg.reqId()));\n-\n-                    return stat;\n+                        log.debug(String.format(\"Cannot read local statistics %s by gathering task %s\", objData.key(),\n+                            gatId));\n                 }\n \n-                stat.localStatistics().add(msg);\n-                // TODO: reschedule if not all partition collected.\n-\n-                if (stat.remainingCollectionReqs().isEmpty()) {\n-                    Map<StatsKey, ObjectStatisticsImpl> mergedGlobal = finishStatCollection(stat);\n-\n-                    stat.doneFut().onDone(null);\n-\n-                    return null;\n-                }\n-            }\n-            return stat;\n-        });\n+                return v;\n+            });\n+        }\n+        if (stCtx.registerCollected(keyStats, data.values().stream().mapToInt(a -> a.length).sum()))\n+            finishStatisticsCollection(stCtx);\n     }\n \n     /**\n", "next_change": {"commit": "7ef165002105dd10417170217e86d65771c524bb", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 1f98ad5ca73..4e5949c6399 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -453,35 +461,9 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n                 return v;\n             });\n         }\n-        if (stCtx.registerCollected(keyStats, data.values().stream().mapToInt(a -> a.length).sum()))\n-            finishStatisticsCollection(stCtx);\n-    }\n \n-    /**\n-     * Aggregate local statistics to global one.\n-     *\n-     * @param stat Statistics collection status to aggregate.\n-     * @return Map stats key to merged global statistics.\n-     */\n-    private Map<StatisticsKey, ObjectStatisticsImpl> finishStatCollection(StatisticsGatheringContext stat) {\n-        Map<StatisticsKey, ObjectStatisticsImpl> res = new HashMap<>();\n-        for (Map.Entry<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : stat.collectedStatistics()\n-                .entrySet()) {\n-            StatisticsKeyMessage keyMsg = keyStats.getKey();\n-            GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n-            if (tbl == null) {\n-                if (log.isInfoEnabled())\n-                    log.info(String.format(\"Unable to find object %s.%s to save collected statistics by.\",\n-                            keyMsg.schema(), keyMsg.obj()));\n-\n-                continue;\n-            }\n-\n-            ObjectStatisticsImpl globalStat = statGathering.aggregateLocalStatistics(keyMsg, keyStats.getValue());\n-            StatisticsKey key = new StatisticsKey(keyMsg.schema(), keyMsg.obj());\n-            res.put(key, statsRepos.mergeGlobalStatistics(key, globalStat));\n-        }\n-        return res;\n+        if (stCtx.registerCollected(keyStats, partsCount))\n+            finishStatisticsCollection(stCtx);\n     }\n \n     /**\n", "next_change": {"commit": "05b732cd7e8840c429c48f5561e7c98e0289bcf6", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 4e5949c6399..ab2c41eca80 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -443,23 +447,17 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n         }\n         Map<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats = new HashMap<>();\n         for (StatisticsObjectData objData : data) {\n-            keyStats.compute(objData.key(), (k, v) -> {\n-                if (v == null)\n-                    v = new ArrayList<>();\n-\n-                try {\n-                    ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n-\n-                    v.add(objStat);\n-                }\n-                catch (IgniteCheckedException e) {\n-                    if (log.isDebugEnabled())\n-                        log.debug(String.format(\"Cannot read local statistics %s by gathering task %s\", objData.key(),\n-                            gatId));\n-                }\n-\n-                return v;\n-            });\n+            Collection<ObjectStatisticsImpl> keyObjStats = keyStats.computeIfAbsent(objData.key(), k -> new ArrayList<>());\n+            try {\n+                ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n+\n+                keyObjStats.add(objStat);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Cannot read local statistics %s by gathering task %s\", objData.key(),\n+                        gatId));\n+            }\n         }\n \n         if (stCtx.registerCollected(keyStats, partsCount))\n", "next_change": null}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ1OTEzNg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545459136", "body": "localNodeId is available via KernalConext.localNodeId().", "bodyText": "localNodeId is available via KernalConext.localNodeId().", "bodyHTML": "<p dir=\"auto\">localNodeId is available via KernalConext.localNodeId().</p>", "author": "AMashenkov", "createdAt": "2020-12-17T22:59:07Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -89,86 +157,468 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+\n+        UUID reqId = UUID.randomUUID();\n+        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        Map<UUID, List<Integer>> requestNodes = null;\n+        /*try {\n+            requestNodes = nodePartitions(extractGroups(Collections.singletonList(keyMsg)), null);\n+        } catch (IgniteCheckedException e) {\n+            // TODO: handle & remove task\n+        }\n+\n+        StatsClearRequest req = new StatsClearRequest(reqId, false, Collections.singletonList(keyMsg));\n+\n+        sendLocalRequests(reqId, req, requestNodes);*/\n+\n+        clearObjectStatisticsLocal(keyMsg);\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatsKeyMessage keyMsg) {\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n+    // TODO\n+    /**\n+     * Collect local object statistics by primary partitions of specified object.\n+     *\n+     * @param keyMsg Statistic key message to collect statistics by.\n+     * @param partIds Set of partition ids to collect statistics by.\n+     * @param cancelled Supplier to check if operation was cancelled.\n+     * @return Tuple of Collected local statistics with array of successfully collected partitions.\n+     * @throws IgniteCheckedException\n+     */\n+    private IgniteBiTuple<ObjectStatisticsImpl, int[]> collectLocalObjectStatistics(\n+            StatsKeyMessage keyMsg,\n+            int[] partIds,\n+            Supplier<Boolean> cancelled\n+    ) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", keyMsg.schema(), keyMsg.obj()));\n+\n+        Column[] selectedCols = filterColumns(tbl.getColumns(), keyMsg.colNames());\n+\n+        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, partIds, selectedCols,\n+                cancelled);\n+        if (partsStats == null) {\n+            assert cancelled.get() : \"Error collecting partition level statistics.\";\n+\n+            return null;\n+        }\n+\n+        sendPartStatsToBU(tbl, partsStats);\n+\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n+\n+        ObjectStatisticsImpl tblStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n+        statsRepos.mergeLocalStatistics(key, tblStats);\n+\n+        return new IgniteBiTuple(tblStats, partsStats.stream().map(ObjectPartitionStatisticsImpl::partId).toArray());\n+    }\n+\n+    /**\n+     * Send statistics propagation messages with partition statistics to all backups node.\n+     *\n+     * @param tbl Table to which statistics should be send.\n+     * @param objStats Collection of partition statistics to send.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void sendPartStatsToBU(\n+            GridH2Table tbl,\n+            Collection<ObjectPartitionStatisticsImpl> objStats\n+    ) throws IgniteCheckedException {\n+        UUID locNode = ctx.discovery().localNode().id();\n+        StatsKeyMessage keyMsg = new StatsKeyMessage(tbl.identifier().schema(), tbl.identifier().table(), null);\n+        GridDhtPartitionTopology topology = tbl.cacheContext().topology();\n+        Map<UUID, List<StatsObjectData>> statsByNodes = new HashMap<>();\n+        for (ObjectPartitionStatisticsImpl stat : objStats) {\n+            StatsObjectData statData = StatisticsUtils.toObjectData(keyMsg, StatsType.PARTITION, stat);\n+            for (ClusterNode partNode : topology.nodes(stat.partId(), topology.readyTopologyVersion())) {\n+                if (locNode.equals(partNode.id()))\n+                    continue;\n+\n+                statsByNodes.compute(partNode.id(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+\n+                    v.add(statData);\n+\n+                    return v;\n+                });\n+            }\n+        }\n+\n+        for (Map.Entry <UUID, List<StatsObjectData>> statToNode : statsByNodes.entrySet()) {\n+            //StatsPropagationMessage nodeMsg = StatisticsUtils.toMessage(null, statToNode.getValue());\n+\n+            //ctx.io().sendToCustomTopic(statToNode.getKey(), TOPIC, nodeMsg, GridIoPolicy.QUERY_POOL);\n+        }\n+    }\n+\n+    /**\n+     * Group local statistics by table and columns.\n+     *\n+     * @param status statistics collection status with all necessary local statistics.\n+     * @return map of tables to columns to list of local column statistics.\n+     */\n+    private Map<GridH2Table, Map<String, List<ColumnStatistics>>> groupColumnStatistics(StatCollectionStatus status) {\n+        /*Map<GridH2Table, Map<String, List<ColumnStatistics>>> result = new HashMap<>();\n+        for (StatsPropagationMessage msg : status.locStatistics) {\n+            for (StatsObjectData msgData : msg.data()) {\n+                GridH2Table dataTable = schemaMgr.dataTable(msgData.key().schema(), msgData.key().obj());\n+                if (dataTable == null) {\n+                    log.warning(String.format(\"Can't find table for received statistics: %s %s\", msgData.key().schema(),\n+                            msgData.key().obj()));\n+\n+                    continue;\n+                }\n+\n+                result.compute(dataTable, (table, columns) -> {\n+                    if (columns == null)\n+                        columns = new HashMap<>();\n+\n+                    for (Map.Entry<String, StatsColumnData> colData : msgData.data().entrySet())\n+                        columns.compute(colData.getKey(), (colName, colStatistics) -> {\n+                            if (colStatistics == null)\n+                                colStatistics = new ArrayList<>();\n+\n+                            ColumnStatistics colStat;\n+                            try {\n+                                colStat = StatisticsUtils.toColumnStatistics(ctx, colData.getValue());\n+                                colStatistics.add(colStat);\n+                            }\n+                            catch (IgniteCheckedException e) {\n+                                log.warning(String. format(\"Error while converting column statistics %s.%s - %s\",\n+                                        msgData.key().schema(), msgData.key().obj(), colName));\n+                            }\n+                            return colStatistics;\n+                        });\n+                    return columns;\n+                });\n+            }\n+        }\n+        return result;\n+        */\n+        return null;\n+    }\n+\n+    /**\n+     * Will aggregate all received local statistics and save it.\n+     *\n+     * @param request aggregation request with id only.\n+     */\n+    private void aggregateCollected(StatCollectionStatus status) {\n+        /*// Table -> Column -> List of local column stats\n+        Map<GridH2Table, Map<String, List<ColumnStatistics>>> tablesData = groupColumnStatistics(status);\n+\n+        Map<ClusterNode, List<StatsObjectData>> dataByNodes = new HashMap<>();\n+        for (Map.Entry<GridH2Table, Map<String, List<ColumnStatistics>>> tableStats : tablesData.entrySet()) {\n+            GridH2Table table = tableStats.getKey();\n+            long rowCount = 0L;\n+            Map<String, ColumnStatistics> columnStatistics = new HashMap<>();\n+            for (Map.Entry<String, List<ColumnStatistics>> columnStats : tableStats.getValue().entrySet()) {\n+                ColumnStatistics globalStatistics = ColumnStatisticsCollector\n+                        .aggregate(table::compareValues, columnStats.getValue());\n+                if (rowCount < globalStatistics.total())\n+                    rowCount = globalStatistics.total();\n+                columnStatistics.put(columnStats.getKey(), globalStatistics);\n+            }\n+\n+            ObjectStatisticsImpl objectStatistics = new ObjectStatisticsImpl(rowCount, columnStatistics);\n+            statsRepos.saveGlobalStatistics(new StatsKey(table.identifier().schema(), table.identifier().table()),\n+                    objectStatistics);\n+        }\n+        status.doneFut.onDone();\n+        */\n+\n+    }\n+\n     /**\n      * Filter columns by specified names.\n      *\n-     * @param columns Columns to filter.\n+     * @param cols Columns to filter.\n      * @param colNames Column names.\n      * @return Column with specified names.\n      */\n-    private Column[] filterColumns(Column[] columns, String... colNames) {\n+    private Column[] filterColumns(Column[] cols, @Nullable Collection<String> colNames) {\n         if (F.isEmpty(colNames))\n-            return columns;\n+            return cols;\n \n         Set<String> colNamesSet = new HashSet(Arrays.asList(colNames));\n-        List<Column> resultList = new ArrayList<>(colNames.length);\n+        List<Column> resList = new ArrayList<>(colNames.size());\n \n-        for (Column col : columns)\n+        for (Column col : cols)\n             if (colNamesSet.contains(col.getName()))\n-                resultList.add(col);\n+                resList.add(col);\n \n-        return resultList.toArray(new Column[resultList.size()]);\n+        return resList.toArray(new Column[resList.size()]);\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void collectObjectStatistics(String schemaName, String objName, String... colNames)\n-            throws IgniteCheckedException {\n-        GridH2Table tbl = schemaMgr.dataTable(schemaName, objName);\n-        if (tbl == null)\n-            throw new IllegalArgumentException(String.format(\"Can't find table %s.%s\", schemaName, objName));\n+    @Override public void collectObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        UUID colId = UUID.randomUUID();\n+        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.singletonList(keyMsg),\n+            Collections.emptyMap(), doneFut);\n+        synchronized (status) {\n+            currCollections.updateCollection(colId, s -> status);\n+            Map<StatsKeyMessage, int[]> failedPartitions = null;\n+            int cnt = 0;\n+            do {\n+                Collection<StatsCollectionAddrRequest> reqs = currCollections.generateCollectionRequests(colId,\n+                    Collections.singletonList(keyMsg), failedPartitions);\n+                Map<UUID, StatsCollectionRequest> msgs = reqs.stream().collect(Collectors.toMap(\n+                    StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req));\n \n-        if (log.isDebugEnabled())\n-            log.debug(String.format(\"Starting statistics collection by %s.%s object\", schemaName, objName));\n+                Map<UUID, StatsCollectionRequest> failedMsgs = sendLocalRequests(msgs);\n+                failedPartitions = currCollections.extractFailed(failedMsgs.values()\n+                    .toArray(new StatsCollectionRequest[0]));\n+                if (cnt++ > 10)\n+                    throw new IgniteCheckedException(String.format(\n+                            \"Unable to send all messages to collect statistics by key %s.%s\", schemaName, objName));\n+            }\n+            while (!failedPartitions.isEmpty());\n+        }\n+        UUID locNode = ctx.discovery().localNode().id();\n+        StatsCollectionAddrRequest locReq = status.remainingCollectionReqs().get(locNode);\n+        statMgmtPool.submit(() -> processLocal(ctx.discovery().localNode().id(), locReq.req()));", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTc0ODIxMw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545748213", "bodyText": "Cool, I'll use it. Fixed", "author": "Berkof", "createdAt": "2020-12-18T10:41:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ1OTEzNg=="}], "type": "inlineReview", "revised_code": {"commit": "ec4a9ef0e7691b605225c12527d496d07d573b42", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex ca50e8e339b..aa95be0231f 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -373,117 +373,120 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n         return resList.toArray(new Column[resList.size()]);\n     }\n \n-    /** {@inheritDoc} */\n-    @Override public void collectObjectStatistics(\n-            String schemaName,\n-            String objName,\n-            String... colNames\n-    ) throws IgniteCheckedException {\n-        StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n-        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n-        UUID colId = UUID.randomUUID();\n-        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.singletonList(keyMsg),\n-            Collections.emptyMap(), doneFut);\n+    /**\n+     * Collect object statistics prepared status.\n+     *\n+     * @param status Collection status to collect statistics by.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void collectObjectStatistics(StatCollectionStatus status) throws IgniteCheckedException {\n         synchronized (status) {\n-            currCollections.updateCollection(colId, s -> status);\n+            currCollections.updateCollection(status.colId(), s -> status);\n             Map<StatsKeyMessage, int[]> failedPartitions = null;\n             int cnt = 0;\n             do {\n-                Collection<StatsCollectionAddrRequest> reqs = currCollections.generateCollectionRequests(colId,\n-                    Collections.singletonList(keyMsg), failedPartitions);\n-                Map<UUID, StatsCollectionRequest> msgs = reqs.stream().collect(Collectors.toMap(\n-                    StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req));\n-\n-                Map<UUID, StatsCollectionRequest> failedMsgs = sendLocalRequests(msgs);\n-                failedPartitions = currCollections.extractFailed(failedMsgs.values()\n-                    .toArray(new StatsCollectionRequest[0]));\n-                if (cnt++ > 10)\n+                Collection<StatsAddrRequest<StatsCollectionRequest>> reqs = currCollections\n+                        .generateCollectionRequests(status.colId(), status.keys(), failedPartitions);\n+\n+                //Map<UUID, StatsCollectionRequest> msgs = reqs.stream().collect(Collectors.toMap(\n+                //    StatsAddrRequest::nodeId, StatsAddrRequest::req));\n+\n+                Collection<StatsAddrRequest<StatsCollectionRequest>> failedMsgs = sendLocalRequests(reqs);\n+                Map<UUID, StatsAddrRequest<StatsCollectionRequest>> sendedMsgs;\n+                if (failedMsgs == null) {\n+                    sendedMsgs = reqs.stream().collect(Collectors.toMap(r -> r.req().reqId(), r -> r));\n+                    failedPartitions = null;\n+                }\n+                else {\n+                    Set<UUID> failedIds = failedMsgs.stream().map(r -> r.req().reqId()).collect(Collectors.toSet());\n+                    sendedMsgs = reqs.stream().filter(r -> !failedIds.contains(r.req().reqId()))\n+                            .collect(Collectors.toMap(r -> r.req().reqId(), r -> r));\n+                    failedPartitions = currCollections.extractFailed(failedMsgs.stream().map(StatsAddrRequest::req)\n+                            .toArray(StatsCollectionRequest[]::new));\n+                }\n+                status.remainingCollectionReqs().putAll(sendedMsgs);\n+\n+                if (cnt++ > 10) {\n+                    StatsKeyMessage key = status.keys().iterator().next();\n+\n                     throw new IgniteCheckedException(String.format(\n-                            \"Unable to send all messages to collect statistics by key %s.%s\", schemaName, objName));\n+                            \"Unable to send all messages to collect statistics by key %s.%s and the others %d\",\n+                            key.schema(), key.obj(), status.keys().size() - 1));\n+                }\n             }\n-            while (!failedPartitions.isEmpty());\n+            while (failedPartitions != null);\n         }\n+\n         UUID locNode = ctx.discovery().localNode().id();\n-        StatsCollectionAddrRequest locReq = status.remainingCollectionReqs().get(locNode);\n-        statMgmtPool.submit(() -> processLocal(ctx.discovery().localNode().id(), locReq.req()));\n-        /*final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+        StatsAddrRequest<StatsCollectionRequest> locReq = status.remainingCollectionReqs().values().stream()\n+                .filter(r -> locNode.equals(r.nodeId())).findAny().orElse(null);\n+        if (locReq != null)\n+            statMgmtPool.submit(() -> processLocal(ctx.discovery().localNode().id(), locReq.req()));\n+    }\n \n+    /** {@inheritDoc} */\n+    @Override public void collectObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        UUID colId = UUID.randomUUID();\n+        StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter(colId);\n         StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.singletonList(keyMsg),\n+            Collections.emptyMap(), doneFut);\n+\n+        collectObjectStatistics(status);\n+\n+        doneFut.get();\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public StatsCollectionFuture<Map<GridTuple3<String, String, String[]>, ObjectStatistics>>\n+    collectObjectStatisticsAsync(\n+        GridTuple3<String, String, String[]>... keys\n+    ) throws IgniteCheckedException {\n         UUID colId = UUID.randomUUID();\n-        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.emptyMap(), doneFut);\n+        StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter(colId);\n+        Collection<StatsKeyMessage> keysMsg = Arrays.stream(keys).map(\n+                k -> new StatsKeyMessage(k.get1(), k.get2(), Arrays.asList(k.get3()))).collect(Collectors.toList());\n \n-        synchronized (status) {\n-            currCollections.put(colId, status);\n-            if (!doRequests(status, Collections.singletonList(keyMsg))) {\n-                status.doneFut().cancel();\n-                currCollections.remove(colId);\n-                throw new IgniteCheckedException(\"Unable to send statistics collection messages to all necessary nodes\");\n+        StatCollectionStatus status = new StatCollectionStatus(colId, keysMsg, Collections.emptyMap(), doneFut);\n+\n+        collectObjectStatistics(status);\n+\n+        return status.doneFut();\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public boolean cancelObjectStatisticsCollection(UUID colId) {\n+        boolean[] res = new boolean[]{true};\n+\n+        currCollections.updateCollection(colId, s -> {\n+            if (s == null) {\n+                res[0] = false;\n+\n+                return null;\n             }\n-        }\n-        UUID locNode = ctx.discovery().localNode().id();\n-        StatsCollectionAddrRequest locReq = status.remainingCollectionReqs().get(locNode);\n-        if (locReq != null)\n-            statMgmtPool.submit(() -> processLocal(locNode, locReq.req()));\n \n-        doneFut.get();\n-        */\n+            s.doneFut().cancel();\n+\n+            Collection<StatsAddrRequest<CancelStatsCollectionRequest>> cancelReqs = s.remainingCollectionReqs()\n+                .values().stream().map(r ->\n+                    new StatsAddrRequest<CancelStatsCollectionRequest>(\n+                            new CancelStatsCollectionRequest(colId, UUID.randomUUID()), r.nodeId()))\n+                    .collect(Collectors.toList());\n+\n+            Collection<StatsAddrRequest<CancelStatsCollectionRequest>> failed = sendLocalRequests(cancelReqs);\n+            if (failed != null)\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Unable to cancel all statistics collections requests (%d failed) by colId %s\",\n+                            failed.size(), colId));\n+\n+            return null;\n+        });\n \n-//\n-//        StatsKey key = new StatsKey(schemaName, objName);\n-//\n-//        List<CacheGroupContext> grpContexts = extractGroups(Collections.singletonList(key));\n-//\n-//        assert grpContexts.size() == 1;\n-//\n-//        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n-//        Map<UUID, List<Integer>> reqNodes = nodePartitions(grpContexts.get(0), null);\n-//        Map<UUID, StatsCollectionAddrRequest> reqs = prepareRequests(colId, keyMsg, reqNodes);\n-//\n-//        synchronized (status) {\n-//            currCollections.put(colId, status);\n-//\n-//            Map<UUID, StatsCollectionRequest> failedReqs = sendLocalRequests(reqs.values().stream().collect(\n-//                    Collectors.toMap(StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req)));\n-//\n-//            if (failedReqs != null) {\n-//                for (UUID failedReqId : failedReqs.keySet())\n-//                    status.remainingCollectionReqs().remove(failedReqId);\n-//\n-//                Map<StatsKeyMessage,List<Integer>> failedPartIds = extractFailed(failedReqs.values());\n-//\n-//                assert failedPartIds.size() == 1;\n-//\n-//                List<Integer> newPartIds = failedPartIds.get(keyMsg);\n-//\n-//                assert newPartIds != null;\n-//\n-//                Map<UUID, List<Integer>> newReqNodes = nodePartitions(grpContexts.get(0), newPartIds);\n-//                Map<UUID, StatsCollectionAddrRequest> newReqs = prepareRequests(colId, keyMsg, newReqNodes);\n-//                Map<UUID, StatsCollectionRequest> newFailedReqs = sendLocalRequests(newReqs.values().stream().collect(\n-//                        Collectors.toMap(StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req)));\n-//                if (newFailedReqs != null) {\n-//                    doneFut.cancel();\n-//\n-//                    // TODO: is it safe?\n-//                    currCollections.remove(colId);\n-//\n-//                    throw new IgniteCheckedException(String.format(\n-//                            \"Unable to send statistics collection request to %d nodes. Cancelling collection %s\",\n-//                            newFailedReqs.size(), colId));\n-//                }\n-//                status.remainingCollectionReqs().putAll(newReqs);\n-//\n-//                failedReqs.values().stream().forEach(req -> req.keys().values().forEach(failedPartIds.addAll()));\n-//                rescheduleFailedPartitions(colId, Collections.singletonMap(keyMsg, ));\n-//            }\n-//            UUID locNode = ctx.discovery().localNode().id();\n-//            StatsCollectionAddrRequest locReq = reqs.get(locNode);\n-//            if (locReq != null)\n-//                statMgmtPool.submit(() -> processLocal(locNode, locReq.req()));\n-//\n-//        }\n-//\n-//        doneFut.get();\n+        return res[0];\n     }\n \n     /**\n", "next_change": {"commit": "b595e90b5b480aaf80a9256558b1841334df97de", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex aa95be0231f..7fab3588e96 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -490,98 +429,7 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n     }\n \n     /**\n-     * Generate and try to send all request for particular status. Should be called inside status lock after putting it\n-     * into currCollections map. REMOVE!!!!\n-     *\n-     * @param status Status to process.\n-     * @param keys Collection of object keys to collect statistics by.\n-     * @return {@code true} if all request was successfully sended, {@code false} - otherwise (one should remove\n-     * status from cullCollections.\n-     */\n-    protected boolean doRequests(StatCollectionStatus status, List<StatsKeyMessage> keys) throws IgniteCheckedException {\n-        /*Map<CacheGroupContext, Collection<StatsKeyMessage>> grpContexts = extractGroups(keys);\n-        List<Map<UUID, StatsCollectionAddrRequest>> reqsByGrps = new ArrayList<>(grpContexts.size());\n-        for (Map.Entry<CacheGroupContext, Collection<StatsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n-            Map<UUID, List<Integer>> reqNodes = nodePartitions(grpEntry.getKey(), null);\n-            for(StatsKeyMessage keyMsg : grpEntry.getValue())\n-                reqsByGrps.add(prepareRequests(status.colId(), keyMsg, reqNodes));\n-\n-        }\n-        Map<UUID, StatsCollectionAddrRequest> reqs = compressRequests(reqsByGrps);\n-\n-        status.remainingCollectionReqs().putAll(reqs);\n-\n-        Map<UUID, StatsCollectionRequest> failedReqs = sendLocalRequests(reqs.values().stream().collect(\n-                Collectors.toMap(StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req)));\n-        // TODO: cycle replanning and sending\n-        return failedReqs.isEmpty();\n-\n-         */\n-        return false;\n-    }\n-\n-    /**\n-     * Group request by target node id. REMOVE!!!!\n-     *\n-     * @param reqsByGrps Requests to compress, map.\n-     * @return Grouped requests.\n-     */\n-    protected Map<UUID, StatsAddrRequest<StatsCollectionRequest>> compressRequests(\n-        List<Map<UUID, StatsAddrRequest<StatsCollectionRequest>>> reqsByGrps) {\n-        // NodeId to base request map\n-        Map<UUID, StatsAddrRequest<StatsCollectionRequest>> reqByNode = new HashMap<>();\n-        for (Map<UUID, StatsAddrRequest<StatsCollectionRequest>> grpReqs : reqsByGrps)\n-            for (StatsAddrRequest<StatsCollectionRequest> addReq : grpReqs.values())\n-                reqByNode.compute(addReq.nodeId(), (k, v) -> (v == null) ? addReq : addKey(v, addReq));\n-\n-        return reqByNode.entrySet().stream().collect(Collectors.toMap(e -> e.getValue().req().reqId(),\n-            Map.Entry::getValue));\n-    }\n-\n-    /**\n-     * Add keys from add request to the base one and return it.\n-     *\n-     * @param base Base request to add to.\n-     * @param add Add request to add.\n-     * @return Request with all keys from both specified.\n-     */\n-    protected StatsAddrRequest<StatsCollectionRequest> addKey(\n-        StatsAddrRequest<StatsCollectionRequest> base,\n-        StatsAddrRequest<StatsCollectionRequest> add\n-    ) {\n-        assert base.nodeId().equals(add.nodeId());\n-\n-        base.req().keys().putAll(add.req().keys());\n-        return base;\n-    }\n-\n-\n-    /**\n-     * Prepare statistics collection request for each nodes. MOVED!!!!\n-     *\n-     * @param colId Collection id.\n-     * @param keyMsg Key to collect statistics by.\n-     * @param reqNodes Map of node id to array of partition ids to be collected on that node.\n-     * @return Map: request id to statistics collection addressed request.\n-     */\n-    protected Map<UUID, StatsAddrRequest<StatsCollectionRequest>> _____prepareRequests(\n-            UUID colId,\n-            StatsKeyMessage keyMsg,\n-            Map<UUID, List<Integer>> reqNodes\n-    ) {\n-        Map<UUID, StatsAddrRequest<StatsCollectionRequest>> res = new HashMap<>(reqNodes.size());\n-        for (Map.Entry<UUID, List<Integer>> reqNode : reqNodes.entrySet()) {\n-            UUID reqId = UUID.randomUUID();\n-            StatsCollectionRequest colReq = new StatsCollectionRequest(colId, reqId, Collections.singletonMap(keyMsg,\n-                    reqNode.getValue().stream().mapToInt(Integer::intValue).toArray()));\n-            StatsAddrRequest<StatsCollectionRequest> addrReq = new StatsAddrRequest(colReq, reqNode.getKey());\n-            res.put(reqId, addrReq);\n-        }\n-        return res;\n-    }\n-\n-    /**\n-     * TODO\n+     * Stop statistics manager.\n      */\n     public void stop() {\n         if (statMgmtPool != null) {\n", "next_change": {"commit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 7fab3588e96..1f98ad5ca73 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -360,334 +262,199 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n             String objName,\n             String... colNames\n     ) throws IgniteCheckedException {\n-        UUID colId = UUID.randomUUID();\n-        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n-        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.singletonList(keyMsg),\n-            Collections.emptyMap());\n-\n+        StatisticsKeyMessage keyMsg = new StatisticsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        StatisticsGatheringContext status = new StatisticsGatheringContext(Collections.singleton(keyMsg));\n+        currColls.put(status.gatId(), status);\n         collectObjectStatistics(status);\n \n         status.doneFut().get();\n     }\n \n+    /**\n+     * Ensure that local gathering context exists and schedule local statistics gathering.\n+     *\n+     * @param nodeId Initiator node id.\n+     * @param gatId Gathering id.\n+     * @param reqId Request id.\n+     * @param keys Keys to collect statistics by.\n+     */\n+    public void gatherLocalObjectStatisticsAsync(UUID gatId, UUID reqId, Map<StatisticsKeyMessage, int[]> keys) {\n+        int parts = keys.values().stream().mapToInt(arr -> arr.length).sum();\n+\n+        StatisticsGatheringContext[] ctxs = new StatisticsGatheringContext[1];\n+        currColls.compute(gatId, (k, v) -> {\n+            if (v == null)\n+                v = new StatisticsGatheringContext(gatId, keys.keySet(), parts);\n+\n+            ctxs[0] = v;\n+\n+            return v;\n+        });\n+\n+        statGathering.collectLocalObjectsStatisticsAsync(reqId, keys, () -> ctxs[0].doneFut().isCancelled());\n+    }\n+\n     /** {@inheritDoc} */\n     @Override public StatsCollectionFuture<Map<GridTuple3<String, String, String[]>, ObjectStatistics>>\n     collectObjectStatisticsAsync(\n         GridTuple3<String, String, String[]>... keys\n     ) throws IgniteCheckedException {\n-        UUID colId = UUID.randomUUID();\n-        Collection<StatsKeyMessage> keysMsg = Arrays.stream(keys).map(\n-                k -> new StatsKeyMessage(k.get1(), k.get2(), Arrays.asList(k.get3()))).collect(Collectors.toList());\n+        Set<StatisticsKeyMessage> keysMsg = Arrays.stream(keys).map(\n+                k -> new StatisticsKeyMessage(k.get1(), k.get2(), Arrays.asList(k.get3()))).collect(Collectors.toSet());\n \n-        StatCollectionStatus status = new StatCollectionStatus(colId, keysMsg, Collections.emptyMap());\n+        StatisticsGatheringContext status = new StatisticsGatheringContext(keysMsg);\n \n         collectObjectStatistics(status);\n \n         return status.doneFut();\n     }\n \n-    /** {@inheritDoc} */\n-    @Override public boolean cancelObjectStatisticsCollection(UUID colId) {\n-        boolean[] res = new boolean[]{true};\n-\n-        currCollections.updateCollection(colId, s -> {\n-            if (s == null) {\n-                res[0] = false;\n-\n-                return null;\n-            }\n-\n-            s.doneFut().cancel();\n-\n-            Map<UUID, List<UUID>> nodeRequests = new HashMap<>();\n-            for (StatsAddrRequest<StatsCollectionRequest> req : s.remainingCollectionReqs().values()) {\n-                nodeRequests.compute(req.nodeId(), (k, v) -> {\n-                   if (v == null)\n-                       v = new ArrayList<>();\n-                   v.add(req.req().reqId());\n-\n-                   return v;\n-                });\n-            }\n-\n-            Collection<StatsAddrRequest<CancelStatsCollectionRequest>> cancelReqs = nodeRequests.entrySet().stream().map(\n-                        targetNode -> new StatsAddrRequest<>(\n-                            new CancelStatsCollectionRequest(colId, targetNode.getValue().toArray(new UUID[0])),\n-                            targetNode.getKey()))\n-                    .collect(Collectors.toList());\n-\n-            Collection<StatsAddrRequest<CancelStatsCollectionRequest>> failed = sendRequests(cancelReqs);\n-            if (!F.isEmpty(failed))\n-                if (log.isDebugEnabled())\n-                    log.debug(String.format(\"Unable to cancel all statistics collections requests (%d failed) by colId %s\",\n-                            failed.size(), colId));\n-\n-            return null;\n-        });\n-\n-        return res[0];\n-    }\n-\n     /**\n-     * Stop statistics manager.\n+     * Cancel specified statistics gathering process.\n+     *\n+     * @param gatId Gathering id to cancel.\n      */\n-    public void stop() {\n-        if (statMgmtPool != null) {\n-            List<Runnable> unfinishedTasks = statMgmtPool.shutdownNow();\n-            if (!unfinishedTasks.isEmpty())\n-                log.warning(String.format(\"%d statistics collection request cancelled.\", unfinishedTasks.size()));\n+    public void cancelLocalStatisticsGathering(UUID gatId){\n+       StatisticsGatheringContext stCtx = currColls.remove(gatId);\n+       if (stCtx != null)\n+           stCtx.doneFut().cancel();\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public boolean cancelObjectStatisticsGathering(UUID gatId) {\n+        boolean res = false;\n+        StatisticsGatheringContext stCtx = currColls.remove(gatId);\n+        if (stCtx != null) {\n+\n+            res = stCtx.doneFut().cancel();\n+            if (res)\n+                statCrawler.sendCancelGatheringAsync(gatId);\n         }\n+        return res;\n     }\n \n     /**\n-     * Collect partition level statistics.\n+     * Receive and store partition statistics object data for locals backup partition.\n      *\n-     * @param tbl Table to collect statistics by.\n-     * @param partIds Array of partition ids to collect statistics by.\n-     * @param selectedCols Columns to collect statistics by.\n-     * @param cancelled Supplier to check if collection was cancelled.\n-     * @return Collection of partition level statistics by local primary partitions.\n-     * @throws IgniteCheckedException in case of error.\n+     * @param data Collection of partition level statistics of local bacup partitions.\n      */\n-    private Collection<ObjectPartitionStatisticsImpl> collectPartitionStatistics(\n-            GridH2Table tbl,\n-            int[] partIds,\n-            Column[] selectedCols,\n-            Supplier<Boolean> cancelled\n-    ) {\n-        List<ObjectPartitionStatisticsImpl> tblPartStats = new ArrayList<>();\n-        GridH2RowDescriptor desc = tbl.rowDescriptor();\n-        String tblName = tbl.getName();\n-        GridDhtPartitionTopology top = tbl.cacheContext().topology();\n-        AffinityTopologyVersion topVer = top.readyTopologyVersion();\n-\n-        for (int partId : partIds) {\n-            GridDhtLocalPartition locPart = top.localPartition(partId, topVer, false);\n-            if (locPart == null)\n-                continue;\n+    public void receivePartitionsStatistics(Collection<StatisticsObjectData> data) {\n+        for (StatisticsObjectData partData : data) {\n+            StatisticsKey key = new StatisticsKey(partData.key().schema(), partData.key().obj());\n+\n+            assert partData.type() == StatisticsType.PARTITION : \"Got non partition level statistics by \" + key\n+                    + \" without request\";\n \n-            if (cancelled.get()) {\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d\", key.schema(), key.obj(),\n+                    partData.partId()));\n+\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null) {\n                 if (log.isInfoEnabled())\n-                    log.info(String.format(\"Canceled collection of object %s.%s statistics.\", tbl.identifier().schema(),\n-                            tbl.identifier().table()));\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d\", key.schema(), key.obj(),\n+                        partData.partId()));\n \n-                return null;\n+                continue;\n             }\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(ctx.localNodeId(), partData.partId());\n+            if (partState != OWNING) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d\",\n+                            key.schema(), key.obj(), partData.partId()));\n \n-            final boolean reserved = locPart.reserve();\n+                continue;\n+            }\n \n             try {\n-                if (!reserved || (locPart.state() != OWNING) || !locPart.primary(ctx.discovery().topologyVersionEx()))\n-                    continue;\n-\n-                long rowsCnt = 0;\n-\n-                List<ColumnStatisticsCollector> colStatsCollectors = new ArrayList<>(selectedCols.length);\n-\n-                for (Column col : selectedCols)\n-                    colStatsCollectors.add(new ColumnStatisticsCollector(col, tbl::compareValues));\n-\n-                for (CacheDataRow row : tbl.cacheContext().offheap().cachePartitionIterator(tbl.cacheId(), locPart.id(),\n-                        null, true)) {\n-                    GridQueryTypeDescriptor typeDesc = ctx.query().typeByValue(tbl.cacheName(),\n-                        tbl.cacheContext().cacheObjectContext(), row.key(), row.value(), false);\n-                    if (!tblName.equals(typeDesc.tableName()))\n-                        continue;\n-\n-                    rowsCnt++;\n-\n-                    H2Row row0 = desc.createRow(row);\n-\n-                    for (ColumnStatisticsCollector colStat : colStatsCollectors)\n-                        colStat.add(row0.getValue(colStat.col().getColumnId()));\n-\n-                }\n-\n-                Map<String, ColumnStatistics> colStats = colStatsCollectors.stream().collect(Collectors.toMap(\n-                    csc -> csc.col().getName(), ColumnStatisticsCollector::finish));\n+                ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n \n-                tblPartStats.add(new ObjectPartitionStatisticsImpl(locPart.id(), true, rowsCnt,\n-                        locPart.updateCounter(), colStats));\n-\n-                if (log.isTraceEnabled())\n-                    log.trace(String.format(\"Finished statistics collection on %s.%s:%d\",\n-                        tbl.identifier().schema(), tbl.identifier().table(), locPart.id()));\n+                statsRepos.saveLocalPartitionStatistics(key, opStat);\n             }\n             catch (IgniteCheckedException e) {\n-                if (log.isDebugEnabled())\n-                    log.debug(String.format(\"Unable to collect statistics by %s.%s:%d due to error %s\",\n-                        tbl.identifier().schema(), tbl.identifier().table(), partId, e.getMessage()));\n-            }\n-            finally {\n-                if (reserved)\n-                    locPart.release();\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Unable to parse partition statistics for %s.%s:%d because of: %s\",\n+                        key.schema(), key.obj(), partData.partId(), e.getMessage()));\n             }\n         }\n-\n-        return tblPartStats;\n     }\n \n     /**\n-     * Aggregate specified partition level statistics to local level statistics.\n+     * Aggregate specified gathered statistics, remove it form local and complete its future.\n      *\n-     * @param keyMsg Aggregation key.\n-     * @param stats Collection of all local partition level or local level statistics by specified key to aggregate.\n-     * @return Local level aggregated statistics.\n+     * @param stCtx Gathering to complete.\n      */\n-    public ObjectStatisticsImpl aggregateLocalStatistics(\n-            StatsKeyMessage keyMsg,\n-            Collection<? extends ObjectStatisticsImpl> stats\n-    ) {\n-        // For now there can be only tables\n-        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n-\n-        if (tbl == null) {\n-            // remove all loaded statistics.\n-            if (log.isDebugEnabled())\n-                log.debug(String.format(\"Removing statistics for object %s.%s cause table doesn't exists.\",\n-                        keyMsg.schema(), keyMsg.obj()));\n-\n-            // Just to double check\n-            statsRepos.clearLocalPartitionsStatistics(new StatsKey(keyMsg.schema(), keyMsg.obj()));\n+    public void finishStatisticsCollection(StatisticsGatheringContext stCtx) {\n+        currColls.remove(stCtx.gatId());\n+\n+        Map<StatisticsKeyMessage, ObjectStatisticsImpl> keysGlobalStats = new HashMap<>();\n+        for (Map.Entry<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : stCtx.collectedStatistics()\n+                .entrySet()) {\n+            ObjectStatisticsImpl globalCollectedStat = statGathering.aggregateLocalStatistics(keyStats.getKey(),\n+                keyStats.getValue());\n+            StatisticsKey statsKey = new StatisticsKey(keyStats.getKey().schema(), keyStats.getKey().obj());\n+            ObjectStatisticsImpl globalStat = statsRepos.mergeGlobalStatistics(statsKey, globalCollectedStat);\n+            keysGlobalStats.put(keyStats.getKey(), globalStat);\n         }\n \n-        return aggregateLocalStatistics(tbl, filterColumns(tbl.getColumns(), keyMsg.colNames()), stats);\n+        statCrawler.sendGlobalStat(keysGlobalStats);\n     }\n \n     /**\n-     * Aggregate partition level statistics to local level one.\n+     * Cache global statistics.\n      *\n-     * @param tbl Table to aggregate statistics by.\n-     * @param selectedCols Columns to aggregate statistics by.\n-     * @param stats Collection of partition level or local level statistics to aggregate.\n-     * @return Local level statistics.\n+     * @param data Global statistics to cache.\n      */\n-    private ObjectStatisticsImpl aggregateLocalStatistics(\n-            GridH2Table tbl,\n-            Column[] selectedCols,\n-            Collection<? extends ObjectStatisticsImpl> stats\n-    ) {\n-        Map<Column, List<ColumnStatistics>> colPartStats = new HashMap<>(selectedCols.length);\n-        long rowCnt = 0;\n-        for (Column col : selectedCols)\n-            colPartStats.put(col, new ArrayList<>());\n-\n-        for (ObjectStatisticsImpl partStat : stats) {\n-            for (Column col : selectedCols) {\n-                ColumnStatistics colPartStat = partStat.columnStatistics(col.getName());\n-                if (colPartStat != null) {\n-                    colPartStats.computeIfPresent(col, (k, v) -> {\n-                        v.add(colPartStat);\n-\n-                        return v;\n-                    });\n-                }\n-            }\n-            rowCnt += partStat.rowCount();\n-        }\n-\n-        Map<String, ColumnStatistics> colStats = new HashMap<>(selectedCols.length);\n-        for (Column col : selectedCols) {\n-            ColumnStatistics stat = ColumnStatisticsCollector.aggregate(tbl::compareValues, colPartStats.get(col));\n-            colStats.put(col.getName(), stat);\n-        }\n-\n-        ObjectStatisticsImpl tblStats = new ObjectStatisticsImpl(rowCnt, colStats);\n-\n-        return tblStats;\n-    }\n-\n-    /**\n-     * Receive and handle statistics propagation message with partitions statistics.\n-     *\n-     * @param nodeId Sender node id.\n-     * @param msg Statistics propagation message with partitions statistics to handle.\n-     * @throws IgniteCheckedException In case of errors.\n-     */\n-    private void receivePartitionsStatistics(UUID nodeId, StatsPropagationMessage msg) throws IgniteCheckedException {\n-        UUID locNode = ctx.localNodeId();\n-        for (StatsObjectData partData : msg.data()) {\n-            StatsKey key = new StatsKey(partData.key().schema(), partData.key().obj());\n-\n-            assert partData.type() == StatsType.PARTITION : \"Got non partition level statistics by \" + key\n-                    + \" without request\";\n-\n-            if (log.isTraceEnabled())\n-                log.trace(String.format(\"Received partition statistics %s.%s:%d from node %s\", key.schema(),\n-                        key.obj(), partData.partId(), nodeId));\n-\n-            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n-            if (tbl == null) {\n-                if (log.isInfoEnabled())\n-                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d from node %s\",\n-                            key.schema(), key.obj(), partData.partId(), nodeId));\n+    public void saveGlobalStatistics(Collection<StatisticsObjectData> data) {\n+        data.forEach(objData -> {\n+            try {\n+                ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(this.ctx, objData);\n \n-                continue;\n+                statsRepos.saveGlobalStatistics(new StatisticsKey(objData.key().schema(), objData.key().obj()), objStat);\n             }\n-            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(locNode, partData.partId());\n-            if (partState != OWNING) {\n-                if (log.isInfoEnabled())\n-                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d from node %s\",\n-                            key.schema(), key.obj(), partData.partId(), nodeId));\n-\n-                continue;\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Cannot read global statistics %s\", objData.key()));\n             }\n-\n-            ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n-\n-            statsRepos.saveLocalPartitionStatistics(key, opStat);\n-        }\n+        });\n     }\n \n     /**\n-     * Receive and handle statistics propagation message as response for collection request.\n+     * Register\n      *\n-     * @param nodeId Sender node id.\n-     * @param msg Statistics propagation message with partitions statistics to handle.\n-     * @throws IgniteCheckedException In case of errors.\n+     * @param gatId Gathering id.\n+     * @param data Collected statistics.\n      */\n-    private void receiveLocalStatistics(UUID nodeId, StatsCollectionResponse msg) {\n-        assert msg.data().keySet().stream().noneMatch(pd -> pd.type() == StatsType.PARTITION)\n-                : \"Got partition statistics by request \" + msg.reqId();\n-\n-        currCollections.updateCollection(msg.colId(), stat -> {\n-            if (stat == null) {\n-                if (log.isDebugEnabled())\n-                    log.debug(String.format(\n-                        \"Ignoring outdated local statistics collection response from node %s to col %s req %s\",\n-                            nodeId, msg.colId(), msg.reqId()));\n-\n-                return stat;\n-            }\n+    public void registerLocalResult(UUID gatId, Map<StatisticsObjectData, int[]> data) {\n+        StatisticsGatheringContext stCtx = currColls.get(gatId);\n+        if (stCtx == null) {\n+            if (log.isDebugEnabled())\n+                log.debug(String.format(\"Unable to register outdated statistics collection result %s\", gatId));\n \n-            assert stat.colId().equals(msg.colId());\n+            return;\n+        }\n+        Map<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats = new HashMap<>();\n+        for (StatisticsObjectData objData : data.keySet()) {\n+            keyStats.compute(objData.key(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n \n-            // Need syncronization here to avoid races between removing remaining reqs and adding new ones.\n-            synchronized (stat) {\n-                StatsAddrRequest<StatsCollectionRequest> req = stat.remainingCollectionReqs().remove(msg.reqId());\n+                try {\n+                    ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n \n-                if (req == null) {\n+                    v.add(objStat);\n+                }\n+                catch (IgniteCheckedException e) {\n                     if (log.isDebugEnabled())\n-                        log.debug(String.format(\n-                                \"Ignoring unknown local statistics collection response from node %s to col %s req %s\",\n-                                nodeId, msg.colId(), msg.reqId()));\n-\n-                    return stat;\n+                        log.debug(String.format(\"Cannot read local statistics %s by gathering task %s\", objData.key(),\n+                            gatId));\n                 }\n \n-                stat.localStatistics().add(msg);\n-                // TODO: reschedule if not all partition collected.\n-\n-                if (stat.remainingCollectionReqs().isEmpty()) {\n-                    Map<StatsKey, ObjectStatisticsImpl> mergedGlobal = finishStatCollection(stat);\n-\n-                    stat.doneFut().onDone(null);\n-\n-                    return null;\n-                }\n-            }\n-            return stat;\n-        });\n+                return v;\n+            });\n+        }\n+        if (stCtx.registerCollected(keyStats, data.values().stream().mapToInt(a -> a.length).sum()))\n+            finishStatisticsCollection(stCtx);\n     }\n \n     /**\n", "next_change": {"commit": "7ef165002105dd10417170217e86d65771c524bb", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 1f98ad5ca73..4e5949c6399 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -453,35 +461,9 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n                 return v;\n             });\n         }\n-        if (stCtx.registerCollected(keyStats, data.values().stream().mapToInt(a -> a.length).sum()))\n-            finishStatisticsCollection(stCtx);\n-    }\n \n-    /**\n-     * Aggregate local statistics to global one.\n-     *\n-     * @param stat Statistics collection status to aggregate.\n-     * @return Map stats key to merged global statistics.\n-     */\n-    private Map<StatisticsKey, ObjectStatisticsImpl> finishStatCollection(StatisticsGatheringContext stat) {\n-        Map<StatisticsKey, ObjectStatisticsImpl> res = new HashMap<>();\n-        for (Map.Entry<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : stat.collectedStatistics()\n-                .entrySet()) {\n-            StatisticsKeyMessage keyMsg = keyStats.getKey();\n-            GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n-            if (tbl == null) {\n-                if (log.isInfoEnabled())\n-                    log.info(String.format(\"Unable to find object %s.%s to save collected statistics by.\",\n-                            keyMsg.schema(), keyMsg.obj()));\n-\n-                continue;\n-            }\n-\n-            ObjectStatisticsImpl globalStat = statGathering.aggregateLocalStatistics(keyMsg, keyStats.getValue());\n-            StatisticsKey key = new StatisticsKey(keyMsg.schema(), keyMsg.obj());\n-            res.put(key, statsRepos.mergeGlobalStatistics(key, globalStat));\n-        }\n-        return res;\n+        if (stCtx.registerCollected(keyStats, partsCount))\n+            finishStatisticsCollection(stCtx);\n     }\n \n     /**\n", "next_change": {"commit": "05b732cd7e8840c429c48f5561e7c98e0289bcf6", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 4e5949c6399..ab2c41eca80 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -443,23 +447,17 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n         }\n         Map<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats = new HashMap<>();\n         for (StatisticsObjectData objData : data) {\n-            keyStats.compute(objData.key(), (k, v) -> {\n-                if (v == null)\n-                    v = new ArrayList<>();\n-\n-                try {\n-                    ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n-\n-                    v.add(objStat);\n-                }\n-                catch (IgniteCheckedException e) {\n-                    if (log.isDebugEnabled())\n-                        log.debug(String.format(\"Cannot read local statistics %s by gathering task %s\", objData.key(),\n-                            gatId));\n-                }\n-\n-                return v;\n-            });\n+            Collection<ObjectStatisticsImpl> keyObjStats = keyStats.computeIfAbsent(objData.key(), k -> new ArrayList<>());\n+            try {\n+                ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n+\n+                keyObjStats.add(objStat);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Cannot read local statistics %s by gathering task %s\", objData.key(),\n+                        gatId));\n+            }\n         }\n \n         if (stCtx.registerCollected(keyStats, partsCount))\n", "next_change": null}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ2NDQ3OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545464478", "body": "I think MOVING partitions can be safely skipped here.\r\nThere is no need to wait for preloader synchronously, you can subscribe to the future and reschedule statistic gathering once it's done.", "bodyText": "I think MOVING partitions can be safely skipped here.\nThere is no need to wait for preloader synchronously, you can subscribe to the future and reschedule statistic gathering once it's done.", "bodyHTML": "<p dir=\"auto\">I think MOVING partitions can be safely skipped here.<br>\nThere is no need to wait for preloader synchronously, you can subscribe to the future and reschedule statistic gathering once it's done.</p>", "author": "AMashenkov", "createdAt": "2020-12-17T23:09:16Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -89,86 +157,468 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+\n+        UUID reqId = UUID.randomUUID();\n+        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        Map<UUID, List<Integer>> requestNodes = null;\n+        /*try {\n+            requestNodes = nodePartitions(extractGroups(Collections.singletonList(keyMsg)), null);\n+        } catch (IgniteCheckedException e) {\n+            // TODO: handle & remove task\n+        }\n+\n+        StatsClearRequest req = new StatsClearRequest(reqId, false, Collections.singletonList(keyMsg));\n+\n+        sendLocalRequests(reqId, req, requestNodes);*/\n+\n+        clearObjectStatisticsLocal(keyMsg);\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatsKeyMessage keyMsg) {\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n+    // TODO\n+    /**\n+     * Collect local object statistics by primary partitions of specified object.\n+     *\n+     * @param keyMsg Statistic key message to collect statistics by.\n+     * @param partIds Set of partition ids to collect statistics by.\n+     * @param cancelled Supplier to check if operation was cancelled.\n+     * @return Tuple of Collected local statistics with array of successfully collected partitions.\n+     * @throws IgniteCheckedException\n+     */\n+    private IgniteBiTuple<ObjectStatisticsImpl, int[]> collectLocalObjectStatistics(\n+            StatsKeyMessage keyMsg,\n+            int[] partIds,\n+            Supplier<Boolean> cancelled\n+    ) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", keyMsg.schema(), keyMsg.obj()));\n+\n+        Column[] selectedCols = filterColumns(tbl.getColumns(), keyMsg.colNames());\n+\n+        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, partIds, selectedCols,\n+                cancelled);\n+        if (partsStats == null) {\n+            assert cancelled.get() : \"Error collecting partition level statistics.\";\n+\n+            return null;\n+        }\n+\n+        sendPartStatsToBU(tbl, partsStats);\n+\n+        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+        statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n+\n+        ObjectStatisticsImpl tblStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n+        statsRepos.mergeLocalStatistics(key, tblStats);\n+\n+        return new IgniteBiTuple(tblStats, partsStats.stream().map(ObjectPartitionStatisticsImpl::partId).toArray());\n+    }\n+\n+    /**\n+     * Send statistics propagation messages with partition statistics to all backups node.\n+     *\n+     * @param tbl Table to which statistics should be send.\n+     * @param objStats Collection of partition statistics to send.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void sendPartStatsToBU(\n+            GridH2Table tbl,\n+            Collection<ObjectPartitionStatisticsImpl> objStats\n+    ) throws IgniteCheckedException {\n+        UUID locNode = ctx.discovery().localNode().id();\n+        StatsKeyMessage keyMsg = new StatsKeyMessage(tbl.identifier().schema(), tbl.identifier().table(), null);\n+        GridDhtPartitionTopology topology = tbl.cacheContext().topology();\n+        Map<UUID, List<StatsObjectData>> statsByNodes = new HashMap<>();\n+        for (ObjectPartitionStatisticsImpl stat : objStats) {\n+            StatsObjectData statData = StatisticsUtils.toObjectData(keyMsg, StatsType.PARTITION, stat);\n+            for (ClusterNode partNode : topology.nodes(stat.partId(), topology.readyTopologyVersion())) {\n+                if (locNode.equals(partNode.id()))\n+                    continue;\n+\n+                statsByNodes.compute(partNode.id(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+\n+                    v.add(statData);\n+\n+                    return v;\n+                });\n+            }\n+        }\n+\n+        for (Map.Entry <UUID, List<StatsObjectData>> statToNode : statsByNodes.entrySet()) {\n+            //StatsPropagationMessage nodeMsg = StatisticsUtils.toMessage(null, statToNode.getValue());\n+\n+            //ctx.io().sendToCustomTopic(statToNode.getKey(), TOPIC, nodeMsg, GridIoPolicy.QUERY_POOL);\n+        }\n+    }\n+\n+    /**\n+     * Group local statistics by table and columns.\n+     *\n+     * @param status statistics collection status with all necessary local statistics.\n+     * @return map of tables to columns to list of local column statistics.\n+     */\n+    private Map<GridH2Table, Map<String, List<ColumnStatistics>>> groupColumnStatistics(StatCollectionStatus status) {\n+        /*Map<GridH2Table, Map<String, List<ColumnStatistics>>> result = new HashMap<>();\n+        for (StatsPropagationMessage msg : status.locStatistics) {\n+            for (StatsObjectData msgData : msg.data()) {\n+                GridH2Table dataTable = schemaMgr.dataTable(msgData.key().schema(), msgData.key().obj());\n+                if (dataTable == null) {\n+                    log.warning(String.format(\"Can't find table for received statistics: %s %s\", msgData.key().schema(),\n+                            msgData.key().obj()));\n+\n+                    continue;\n+                }\n+\n+                result.compute(dataTable, (table, columns) -> {\n+                    if (columns == null)\n+                        columns = new HashMap<>();\n+\n+                    for (Map.Entry<String, StatsColumnData> colData : msgData.data().entrySet())\n+                        columns.compute(colData.getKey(), (colName, colStatistics) -> {\n+                            if (colStatistics == null)\n+                                colStatistics = new ArrayList<>();\n+\n+                            ColumnStatistics colStat;\n+                            try {\n+                                colStat = StatisticsUtils.toColumnStatistics(ctx, colData.getValue());\n+                                colStatistics.add(colStat);\n+                            }\n+                            catch (IgniteCheckedException e) {\n+                                log.warning(String. format(\"Error while converting column statistics %s.%s - %s\",\n+                                        msgData.key().schema(), msgData.key().obj(), colName));\n+                            }\n+                            return colStatistics;\n+                        });\n+                    return columns;\n+                });\n+            }\n+        }\n+        return result;\n+        */\n+        return null;\n+    }\n+\n+    /**\n+     * Will aggregate all received local statistics and save it.\n+     *\n+     * @param request aggregation request with id only.\n+     */\n+    private void aggregateCollected(StatCollectionStatus status) {\n+        /*// Table -> Column -> List of local column stats\n+        Map<GridH2Table, Map<String, List<ColumnStatistics>>> tablesData = groupColumnStatistics(status);\n+\n+        Map<ClusterNode, List<StatsObjectData>> dataByNodes = new HashMap<>();\n+        for (Map.Entry<GridH2Table, Map<String, List<ColumnStatistics>>> tableStats : tablesData.entrySet()) {\n+            GridH2Table table = tableStats.getKey();\n+            long rowCount = 0L;\n+            Map<String, ColumnStatistics> columnStatistics = new HashMap<>();\n+            for (Map.Entry<String, List<ColumnStatistics>> columnStats : tableStats.getValue().entrySet()) {\n+                ColumnStatistics globalStatistics = ColumnStatisticsCollector\n+                        .aggregate(table::compareValues, columnStats.getValue());\n+                if (rowCount < globalStatistics.total())\n+                    rowCount = globalStatistics.total();\n+                columnStatistics.put(columnStats.getKey(), globalStatistics);\n+            }\n+\n+            ObjectStatisticsImpl objectStatistics = new ObjectStatisticsImpl(rowCount, columnStatistics);\n+            statsRepos.saveGlobalStatistics(new StatsKey(table.identifier().schema(), table.identifier().table()),\n+                    objectStatistics);\n+        }\n+        status.doneFut.onDone();\n+        */\n+\n+    }\n+\n     /**\n      * Filter columns by specified names.\n      *\n-     * @param columns Columns to filter.\n+     * @param cols Columns to filter.\n      * @param colNames Column names.\n      * @return Column with specified names.\n      */\n-    private Column[] filterColumns(Column[] columns, String... colNames) {\n+    private Column[] filterColumns(Column[] cols, @Nullable Collection<String> colNames) {\n         if (F.isEmpty(colNames))\n-            return columns;\n+            return cols;\n \n         Set<String> colNamesSet = new HashSet(Arrays.asList(colNames));\n-        List<Column> resultList = new ArrayList<>(colNames.length);\n+        List<Column> resList = new ArrayList<>(colNames.size());\n \n-        for (Column col : columns)\n+        for (Column col : cols)\n             if (colNamesSet.contains(col.getName()))\n-                resultList.add(col);\n+                resList.add(col);\n \n-        return resultList.toArray(new Column[resultList.size()]);\n+        return resList.toArray(new Column[resList.size()]);\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void collectObjectStatistics(String schemaName, String objName, String... colNames)\n-            throws IgniteCheckedException {\n-        GridH2Table tbl = schemaMgr.dataTable(schemaName, objName);\n-        if (tbl == null)\n-            throw new IllegalArgumentException(String.format(\"Can't find table %s.%s\", schemaName, objName));\n+    @Override public void collectObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        UUID colId = UUID.randomUUID();\n+        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.singletonList(keyMsg),\n+            Collections.emptyMap(), doneFut);\n+        synchronized (status) {\n+            currCollections.updateCollection(colId, s -> status);\n+            Map<StatsKeyMessage, int[]> failedPartitions = null;\n+            int cnt = 0;\n+            do {\n+                Collection<StatsCollectionAddrRequest> reqs = currCollections.generateCollectionRequests(colId,\n+                    Collections.singletonList(keyMsg), failedPartitions);\n+                Map<UUID, StatsCollectionRequest> msgs = reqs.stream().collect(Collectors.toMap(\n+                    StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req));\n \n-        if (log.isDebugEnabled())\n-            log.debug(String.format(\"Starting statistics collection by %s.%s object\", schemaName, objName));\n+                Map<UUID, StatsCollectionRequest> failedMsgs = sendLocalRequests(msgs);\n+                failedPartitions = currCollections.extractFailed(failedMsgs.values()\n+                    .toArray(new StatsCollectionRequest[0]));\n+                if (cnt++ > 10)\n+                    throw new IgniteCheckedException(String.format(\n+                            \"Unable to send all messages to collect statistics by key %s.%s\", schemaName, objName));\n+            }\n+            while (!failedPartitions.isEmpty());\n+        }\n+        UUID locNode = ctx.discovery().localNode().id();\n+        StatsCollectionAddrRequest locReq = status.remainingCollectionReqs().get(locNode);\n+        statMgmtPool.submit(() -> processLocal(ctx.discovery().localNode().id(), locReq.req()));\n+        /*final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n+\n+        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        UUID colId = UUID.randomUUID();\n+        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.emptyMap(), doneFut);\n \n-        Column[] selectedColumns;\n-        boolean fullStat;\n-        if (F.isEmpty(colNames)) {\n-            fullStat = true;\n-            selectedColumns = tbl.getColumns();\n+        synchronized (status) {\n+            currCollections.put(colId, status);\n+            if (!doRequests(status, Collections.singletonList(keyMsg))) {\n+                status.doneFut().cancel();\n+                currCollections.remove(colId);\n+                throw new IgniteCheckedException(\"Unable to send statistics collection messages to all necessary nodes\");\n+            }\n         }\n-        else {\n-            fullStat = false;\n-            selectedColumns = filterColumns(tbl.getColumns(), colNames);\n+        UUID locNode = ctx.discovery().localNode().id();\n+        StatsCollectionAddrRequest locReq = status.remainingCollectionReqs().get(locNode);\n+        if (locReq != null)\n+            statMgmtPool.submit(() -> processLocal(locNode, locReq.req()));\n+\n+        doneFut.get();\n+        */\n+\n+//\n+//        StatsKey key = new StatsKey(schemaName, objName);\n+//\n+//        List<CacheGroupContext> grpContexts = extractGroups(Collections.singletonList(key));\n+//\n+//        assert grpContexts.size() == 1;\n+//\n+//        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+//        Map<UUID, List<Integer>> reqNodes = nodePartitions(grpContexts.get(0), null);\n+//        Map<UUID, StatsCollectionAddrRequest> reqs = prepareRequests(colId, keyMsg, reqNodes);\n+//\n+//        synchronized (status) {\n+//            currCollections.put(colId, status);\n+//\n+//            Map<UUID, StatsCollectionRequest> failedReqs = sendLocalRequests(reqs.values().stream().collect(\n+//                    Collectors.toMap(StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req)));\n+//\n+//            if (failedReqs != null) {\n+//                for (UUID failedReqId : failedReqs.keySet())\n+//                    status.remainingCollectionReqs().remove(failedReqId);\n+//\n+//                Map<StatsKeyMessage,List<Integer>> failedPartIds = extractFailed(failedReqs.values());\n+//\n+//                assert failedPartIds.size() == 1;\n+//\n+//                List<Integer> newPartIds = failedPartIds.get(keyMsg);\n+//\n+//                assert newPartIds != null;\n+//\n+//                Map<UUID, List<Integer>> newReqNodes = nodePartitions(grpContexts.get(0), newPartIds);\n+//                Map<UUID, StatsCollectionAddrRequest> newReqs = prepareRequests(colId, keyMsg, newReqNodes);\n+//                Map<UUID, StatsCollectionRequest> newFailedReqs = sendLocalRequests(newReqs.values().stream().collect(\n+//                        Collectors.toMap(StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req)));\n+//                if (newFailedReqs != null) {\n+//                    doneFut.cancel();\n+//\n+//                    // TODO: is it safe?\n+//                    currCollections.remove(colId);\n+//\n+//                    throw new IgniteCheckedException(String.format(\n+//                            \"Unable to send statistics collection request to %d nodes. Cancelling collection %s\",\n+//                            newFailedReqs.size(), colId));\n+//                }\n+//                status.remainingCollectionReqs().putAll(newReqs);\n+//\n+//                failedReqs.values().stream().forEach(req -> req.keys().values().forEach(failedPartIds.addAll()));\n+//                rescheduleFailedPartitions(colId, Collections.singletonMap(keyMsg, ));\n+//            }\n+//            UUID locNode = ctx.discovery().localNode().id();\n+//            StatsCollectionAddrRequest locReq = reqs.get(locNode);\n+//            if (locReq != null)\n+//                statMgmtPool.submit(() -> processLocal(locNode, locReq.req()));\n+//\n+//        }\n+//\n+//        doneFut.get();\n+    }\n+\n+    /**\n+     * Generate and try to send all request for particular status. Should be called inside status lock after putting it\n+     * into currCollections map. REMOVE!!!!\n+     *\n+     * @param status Status to process.\n+     * @param keys Collection of object keys to collect statistics by.\n+     * @return {@code true} if all request was successfully sended, {@code false} - otherwise (one should remove\n+     * status from cullCollections.\n+     */\n+    protected boolean doRequests(StatCollectionStatus status, List<StatsKeyMessage> keys) throws IgniteCheckedException {\n+        /*Map<CacheGroupContext, Collection<StatsKeyMessage>> grpContexts = extractGroups(keys);\n+        List<Map<UUID, StatsCollectionAddrRequest>> reqsByGrps = new ArrayList<>(grpContexts.size());\n+        for (Map.Entry<CacheGroupContext, Collection<StatsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n+            Map<UUID, List<Integer>> reqNodes = nodePartitions(grpEntry.getKey(), null);\n+            for(StatsKeyMessage keyMsg : grpEntry.getValue())\n+                reqsByGrps.add(prepareRequests(status.colId(), keyMsg, reqNodes));\n+\n         }\n+        Map<UUID, StatsCollectionAddrRequest> reqs = compressRequests(reqsByGrps);\n \n-        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, selectedColumns);\n-        StatsKey key = new StatsKey(tbl.identifier().schema(), tbl.identifier().table());\n-        if (fullStat)\n-            statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n-        else\n-            statsRepos.mergeLocalPartitionsStatistics(key, partsStats);\n-\n-        ObjectStatisticsImpl objStats = aggregateLocalStatistics(tbl, selectedColumns, partsStats);\n-        if (fullStat)\n-            statsRepos.saveLocalStatistics(key, objStats);\n-        else\n-            statsRepos.mergeLocalStatistics(key, objStats);\n-        if (log.isDebugEnabled())\n-            log.debug(String.format(\"Statistics collection by %s.%s object is finished.\", schemaName, objName));\n+        status.remainingCollectionReqs().putAll(reqs);\n+\n+        Map<UUID, StatsCollectionRequest> failedReqs = sendLocalRequests(reqs.values().stream().collect(\n+                Collectors.toMap(StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req)));\n+        // TODO: cycle replanning and sending\n+        return failedReqs.isEmpty();\n+\n+         */\n+        return false;\n+    }\n+\n+    /**\n+     * Group request by target node id. REMOVE!!!!\n+     *\n+     * @param reqsByGrps Requests to compress, map.\n+     * @return Grouped requests.\n+     */\n+    protected Map<UUID, StatsCollectionAddrRequest> compressRequests(List<Map<UUID, StatsCollectionAddrRequest>> reqsByGrps) {\n+        // NodeId to base request map\n+        Map<UUID, StatsCollectionAddrRequest> reqByNode = new HashMap<>();\n+        for (Map<UUID, StatsCollectionAddrRequest> grpReqs : reqsByGrps)\n+            for (StatsCollectionAddrRequest addReq : grpReqs.values())\n+                reqByNode.compute(addReq.nodeId(), (k, v) -> (v == null) ? addReq : addKey(v, addReq));\n+\n+        return reqByNode.entrySet().stream().collect(Collectors.toMap(e -> e.getValue().req().reqId(),\n+            Map.Entry::getValue));\n+    }\n+\n+    /**\n+     * Add keys from add request to the base one and return it.\n+     *\n+     * @param base Base request to add to.\n+     * @param add Add request to add.\n+     * @return Request with all keys from both specified.\n+     */\n+    protected StatsCollectionAddrRequest addKey(StatsCollectionAddrRequest base, StatsCollectionAddrRequest add) {\n+        assert base.nodeId().equals(add.nodeId());\n+\n+        base.req().keys().putAll(add.req().keys());\n+        return base;\n+    }\n+\n+\n+    /**\n+     * Prepare statistics collection request for each nodes. MOVED!!!!\n+     *\n+     * @param colId Collection id.\n+     * @param keyMsg Key to collect statistics by.\n+     * @param reqNodes Map of node id to array of partition ids to be collected on that node.\n+     * @return Map: request id to statistics collection addressed request.\n+     */\n+    protected Map<UUID, StatsCollectionAddrRequest> _____prepareRequests(\n+            UUID colId,\n+            StatsKeyMessage keyMsg,\n+            Map<UUID, List<Integer>> reqNodes\n+    ) {\n+        Map<UUID, StatsCollectionAddrRequest> res = new HashMap<>(reqNodes.size());\n+        for (Map.Entry<UUID, List<Integer>> reqNode : reqNodes.entrySet()) {\n+            UUID reqId = UUID.randomUUID();\n+            StatsCollectionRequest colReq = new StatsCollectionRequest(colId, reqId, Collections.singletonMap(keyMsg,\n+                    reqNode.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+            StatsCollectionAddrRequest addrReq = new StatsCollectionAddrRequest(colReq, reqNode.getKey());\n+            res.put(reqId, addrReq);\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * TODO\n+     */\n+    public void stop() {\n+        if (statMgmtPool != null) {\n+            List<Runnable> unfinishedTasks = statMgmtPool.shutdownNow();\n+            if (!unfinishedTasks.isEmpty())\n+                log.warning(String.format(\"%d statistics collection request cancelled.\", unfinishedTasks.size()));\n+        }\n     }\n \n     /**\n      * Collect partition level statistics.\n      *\n      * @param tbl Table to collect statistics by.\n-     * @param selectedColumns Columns to collect statistics by.\n+     * @param partIds Array of partition ids to collect statistics by.\n+     * @param selectedCols Columns to collect statistics by.\n+     * @param cancelled Supplier to check if collection was cancelled.\n      * @return Collection of partition level statistics by local primary partitions.\n      * @throws IgniteCheckedException in case of error.\n      */\n-    private Collection<ObjectPartitionStatisticsImpl> collectPartitionStatistics(GridH2Table tbl, Column[] selectedColumns)\n-            throws IgniteCheckedException {\n+    private Collection<ObjectPartitionStatisticsImpl> collectPartitionStatistics(\n+            GridH2Table tbl,\n+            int[] partIds,\n+            Column[] selectedCols,\n+            Supplier<Boolean> cancelled\n+    ) throws IgniteCheckedException {\n         List<ObjectPartitionStatisticsImpl> tblPartStats = new ArrayList<>();\n         GridH2RowDescriptor desc = tbl.rowDescriptor();\n         String tblName = tbl.getName();\n+        GridDhtPartitionTopology topology = tbl.cacheContext().topology();\n+        AffinityTopologyVersion topologyVersion = topology.readyTopologyVersion();\n+\n+        for (int partId : partIds) {\n+            GridDhtLocalPartition locPart = topology.localPartition(partId, topologyVersion, false);\n+            if (locPart == null)\n+                continue;\n+\n+            if (cancelled.get()) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Canceled collection of object %s.%s statistics.\", tbl.identifier().schema(),\n+                            tbl.identifier().table()));\n+\n+                return null;\n+            }\n \n-        for (GridDhtLocalPartition locPart : tbl.cacheContext().topology().localPartitions()) {\n             final boolean reserved = locPart.reserve();\n \n             try {", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzA2ODUxMA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r557068510", "bodyText": "skipped", "author": "Berkof", "createdAt": "2021-01-14T06:26:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ2NDQ3OA=="}], "type": "inlineReview", "revised_code": {"commit": "b595e90b5b480aaf80a9256558b1841334df97de", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex ca50e8e339b..7fab3588e96 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -622,13 +477,9 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n             final boolean reserved = locPart.reserve();\n \n             try {\n-                if (!reserved || (locPart.state() != OWNING && locPart.state() != MOVING)\n-                        || !locPart.primary(ctx.discovery().topologyVersionEx()))\n+                if (!reserved || (locPart.state() != OWNING) || !locPart.primary(ctx.discovery().topologyVersionEx()))\n                     continue;\n \n-                if (locPart.state() == MOVING)\n-                    tbl.cacheContext().preloader().syncFuture().get();\n-\n                 long rowsCnt = 0;\n \n                 List<ColumnStatisticsCollector> colStatsCollectors = new ArrayList<>(selectedCols.length);\n", "next_change": {"commit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 7fab3588e96..f208a744d01 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -440,254 +332,72 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n     }\n \n     /**\n-     * Collect partition level statistics.\n+     * Receive and store partition statistics object data for locals backup partition.\n      *\n-     * @param tbl Table to collect statistics by.\n-     * @param partIds Array of partition ids to collect statistics by.\n-     * @param selectedCols Columns to collect statistics by.\n-     * @param cancelled Supplier to check if collection was cancelled.\n-     * @return Collection of partition level statistics by local primary partitions.\n-     * @throws IgniteCheckedException in case of error.\n+     * @param data Collection of partition level statistics of local bacup partitions.\n      */\n-    private Collection<ObjectPartitionStatisticsImpl> collectPartitionStatistics(\n-            GridH2Table tbl,\n-            int[] partIds,\n-            Column[] selectedCols,\n-            Supplier<Boolean> cancelled\n-    ) {\n-        List<ObjectPartitionStatisticsImpl> tblPartStats = new ArrayList<>();\n-        GridH2RowDescriptor desc = tbl.rowDescriptor();\n-        String tblName = tbl.getName();\n-        GridDhtPartitionTopology top = tbl.cacheContext().topology();\n-        AffinityTopologyVersion topVer = top.readyTopologyVersion();\n-\n-        for (int partId : partIds) {\n-            GridDhtLocalPartition locPart = top.localPartition(partId, topVer, false);\n-            if (locPart == null)\n-                continue;\n-\n-            if (cancelled.get()) {\n-                if (log.isInfoEnabled())\n-                    log.info(String.format(\"Canceled collection of object %s.%s statistics.\", tbl.identifier().schema(),\n-                            tbl.identifier().table()));\n+    public void receivePartitionsStatistics(Collection<StatisticsObjectData> data) {\n+        for (StatisticsObjectData partData : data) {\n+            StatisticsKey key = new StatisticsKey(partData.key().schema(), partData.key().obj());\n \n-                return null;\n-            }\n-\n-            final boolean reserved = locPart.reserve();\n-\n-            try {\n-                if (!reserved || (locPart.state() != OWNING) || !locPart.primary(ctx.discovery().topologyVersionEx()))\n-                    continue;\n-\n-                long rowsCnt = 0;\n-\n-                List<ColumnStatisticsCollector> colStatsCollectors = new ArrayList<>(selectedCols.length);\n-\n-                for (Column col : selectedCols)\n-                    colStatsCollectors.add(new ColumnStatisticsCollector(col, tbl::compareValues));\n-\n-                for (CacheDataRow row : tbl.cacheContext().offheap().cachePartitionIterator(tbl.cacheId(), locPart.id(),\n-                        null, true)) {\n-                    GridQueryTypeDescriptor typeDesc = ctx.query().typeByValue(tbl.cacheName(),\n-                        tbl.cacheContext().cacheObjectContext(), row.key(), row.value(), false);\n-                    if (!tblName.equals(typeDesc.tableName()))\n-                        continue;\n-\n-                    rowsCnt++;\n-\n-                    H2Row row0 = desc.createRow(row);\n-\n-                    for (ColumnStatisticsCollector colStat : colStatsCollectors)\n-                        colStat.add(row0.getValue(colStat.col().getColumnId()));\n-\n-                }\n-\n-                Map<String, ColumnStatistics> colStats = colStatsCollectors.stream().collect(Collectors.toMap(\n-                    csc -> csc.col().getName(), ColumnStatisticsCollector::finish));\n-\n-                tblPartStats.add(new ObjectPartitionStatisticsImpl(locPart.id(), true, rowsCnt,\n-                        locPart.updateCounter(), colStats));\n-\n-                if (log.isTraceEnabled())\n-                    log.trace(String.format(\"Finished statistics collection on %s.%s:%d\",\n-                        tbl.identifier().schema(), tbl.identifier().table(), locPart.id()));\n-            }\n-            catch (IgniteCheckedException e) {\n-                if (log.isDebugEnabled())\n-                    log.debug(String.format(\"Unable to collect statistics by %s.%s:%d due to error %s\",\n-                        tbl.identifier().schema(), tbl.identifier().table(), partId, e.getMessage()));\n-            }\n-            finally {\n-                if (reserved)\n-                    locPart.release();\n-            }\n-        }\n-\n-        return tblPartStats;\n-    }\n-\n-    /**\n-     * Aggregate specified partition level statistics to local level statistics.\n-     *\n-     * @param keyMsg Aggregation key.\n-     * @param stats Collection of all local partition level or local level statistics by specified key to aggregate.\n-     * @return Local level aggregated statistics.\n-     */\n-    public ObjectStatisticsImpl aggregateLocalStatistics(\n-            StatsKeyMessage keyMsg,\n-            Collection<? extends ObjectStatisticsImpl> stats\n-    ) {\n-        // For now there can be only tables\n-        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n-\n-        if (tbl == null) {\n-            // remove all loaded statistics.\n-            if (log.isDebugEnabled())\n-                log.debug(String.format(\"Removing statistics for object %s.%s cause table doesn't exists.\",\n-                        keyMsg.schema(), keyMsg.obj()));\n-\n-            // Just to double check\n-            statsRepos.clearLocalPartitionsStatistics(new StatsKey(keyMsg.schema(), keyMsg.obj()));\n-        }\n-\n-        return aggregateLocalStatistics(tbl, filterColumns(tbl.getColumns(), keyMsg.colNames()), stats);\n-    }\n-\n-    /**\n-     * Aggregate partition level statistics to local level one.\n-     *\n-     * @param tbl Table to aggregate statistics by.\n-     * @param selectedCols Columns to aggregate statistics by.\n-     * @param stats Collection of partition level or local level statistics to aggregate.\n-     * @return Local level statistics.\n-     */\n-    private ObjectStatisticsImpl aggregateLocalStatistics(\n-            GridH2Table tbl,\n-            Column[] selectedCols,\n-            Collection<? extends ObjectStatisticsImpl> stats\n-    ) {\n-        Map<Column, List<ColumnStatistics>> colPartStats = new HashMap<>(selectedCols.length);\n-        long rowCnt = 0;\n-        for (Column col : selectedCols)\n-            colPartStats.put(col, new ArrayList<>());\n-\n-        for (ObjectStatisticsImpl partStat : stats) {\n-            for (Column col : selectedCols) {\n-                ColumnStatistics colPartStat = partStat.columnStatistics(col.getName());\n-                if (colPartStat != null) {\n-                    colPartStats.computeIfPresent(col, (k, v) -> {\n-                        v.add(colPartStat);\n-\n-                        return v;\n-                    });\n-                }\n-            }\n-            rowCnt += partStat.rowCount();\n-        }\n-\n-        Map<String, ColumnStatistics> colStats = new HashMap<>(selectedCols.length);\n-        for (Column col : selectedCols) {\n-            ColumnStatistics stat = ColumnStatisticsCollector.aggregate(tbl::compareValues, colPartStats.get(col));\n-            colStats.put(col.getName(), stat);\n-        }\n-\n-        ObjectStatisticsImpl tblStats = new ObjectStatisticsImpl(rowCnt, colStats);\n-\n-        return tblStats;\n-    }\n-\n-    /**\n-     * Receive and handle statistics propagation message with partitions statistics.\n-     *\n-     * @param nodeId Sender node id.\n-     * @param msg Statistics propagation message with partitions statistics to handle.\n-     * @throws IgniteCheckedException In case of errors.\n-     */\n-    private void receivePartitionsStatistics(UUID nodeId, StatsPropagationMessage msg) throws IgniteCheckedException {\n-        UUID locNode = ctx.localNodeId();\n-        for (StatsObjectData partData : msg.data()) {\n-            StatsKey key = new StatsKey(partData.key().schema(), partData.key().obj());\n-\n-            assert partData.type() == StatsType.PARTITION : \"Got non partition level statistics by \" + key\n+            assert partData.type() == StatisticsType.PARTITION : \"Got non partition level statistics by \" + key\n                     + \" without request\";\n \n             if (log.isTraceEnabled())\n-                log.trace(String.format(\"Received partition statistics %s.%s:%d from node %s\", key.schema(),\n-                        key.obj(), partData.partId(), nodeId));\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d\", key.schema(), key.obj(),\n+                    partData.partId()));\n \n             GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n             if (tbl == null) {\n                 if (log.isInfoEnabled())\n-                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d from node %s\",\n-                            key.schema(), key.obj(), partData.partId(), nodeId));\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d\", key.schema(), key.obj(),\n+                        partData.partId()));\n \n                 continue;\n             }\n-            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(locNode, partData.partId());\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(ctx.localNodeId(), partData.partId());\n             if (partState != OWNING) {\n                 if (log.isInfoEnabled())\n-                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d from node %s\",\n-                            key.schema(), key.obj(), partData.partId(), nodeId));\n+                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d\",\n+                            key.schema(), key.obj(), partData.partId()));\n \n                 continue;\n             }\n \n-            ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n+            try {\n+                ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n \n-            statsRepos.saveLocalPartitionStatistics(key, opStat);\n+                statsRepos.saveLocalPartitionStatistics(key, opStat);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Unable to parse partition statistics for %s.%s:%d because of: %s\",\n+                        key.schema(), key.obj(), partData.partId(), e.getMessage()));\n+            }\n         }\n     }\n \n     /**\n-     * Receive and handle statistics propagation message as response for collection request.\n-     *\n-     * @param nodeId Sender node id.\n-     * @param msg Statistics propagation message with partitions statistics to handle.\n-     * @throws IgniteCheckedException In case of errors.\n+     * Aggregate specified gathered statistics, remove it form local and complete its future.\n+     * @param gatId Gathering to complete.\n      */\n-    private void receiveLocalStatistics(UUID nodeId, StatsCollectionResponse msg) {\n-        assert msg.data().keySet().stream().noneMatch(pd -> pd.type() == StatsType.PARTITION)\n-                : \"Got partition statistics by request \" + msg.reqId();\n-\n-        currCollections.updateCollection(msg.colId(), stat -> {\n-            if (stat == null) {\n-                if (log.isDebugEnabled())\n-                    log.debug(String.format(\n-                        \"Ignoring outdated local statistics collection response from node %s to col %s req %s\",\n-                            nodeId, msg.colId(), msg.reqId()));\n-\n-                return stat;\n-            }\n-\n-            assert stat.colId().equals(msg.colId());\n-\n-            // Need syncronization here to avoid races between removing remaining reqs and adding new ones.\n-            synchronized (stat) {\n-                StatsAddrRequest<StatsCollectionRequest> req = stat.remainingCollectionReqs().remove(msg.reqId());\n-\n-                if (req == null) {\n-                    if (log.isDebugEnabled())\n-                        log.debug(String.format(\n-                                \"Ignoring unknown local statistics collection response from node %s to col %s req %s\",\n-                                nodeId, msg.colId(), msg.reqId()));\n-\n-                    return stat;\n-                }\n-\n-                stat.localStatistics().add(msg);\n-                // TODO: reschedule if not all partition collected.\n+    public void finishStatisticsCollection(UUID gatId) {\n+        StatisticsGatheringContext ctx = currColls.remove(gatId);\n+        if (ctx == null)\n+            return;\n \n-                if (stat.remainingCollectionReqs().isEmpty()) {\n-                    Map<StatsKey, ObjectStatisticsImpl> mergedGlobal = finishStatCollection(stat);\n+        Map<StatisticsKeyMessage, ObjectStatisticsImpl> keysStats = new HashMap<>();\n+        for(Map.Entry<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : ctx.localStatistics().e\n \n-                    stat.doneFut().onDone(null);\n+    }\n \n-                    return null;\n-                }\n-            }\n-            return stat;\n-        });\n+    public void registerLocalResult(UUID gatId, Collection<StatisticsObjectData> data) {\n+        StatisticsGatheringContext ctx = currColls.get(gatId);\n+        if (ctx == null) {\n+            // TODO: log\n+            return;\n+        }\n+        ctx.registerCollected(data);\n     }\n \n     /**\n", "next_change": {"commit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex f208a744d01..1f98ad5ca73 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -379,25 +381,80 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n \n     /**\n      * Aggregate specified gathered statistics, remove it form local and complete its future.\n-     * @param gatId Gathering to complete.\n+     *\n+     * @param stCtx Gathering to complete.\n      */\n-    public void finishStatisticsCollection(UUID gatId) {\n-        StatisticsGatheringContext ctx = currColls.remove(gatId);\n-        if (ctx == null)\n-            return;\n+    public void finishStatisticsCollection(StatisticsGatheringContext stCtx) {\n+        currColls.remove(stCtx.gatId());\n+\n+        Map<StatisticsKeyMessage, ObjectStatisticsImpl> keysGlobalStats = new HashMap<>();\n+        for (Map.Entry<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : stCtx.collectedStatistics()\n+                .entrySet()) {\n+            ObjectStatisticsImpl globalCollectedStat = statGathering.aggregateLocalStatistics(keyStats.getKey(),\n+                keyStats.getValue());\n+            StatisticsKey statsKey = new StatisticsKey(keyStats.getKey().schema(), keyStats.getKey().obj());\n+            ObjectStatisticsImpl globalStat = statsRepos.mergeGlobalStatistics(statsKey, globalCollectedStat);\n+            keysGlobalStats.put(keyStats.getKey(), globalStat);\n+        }\n \n-        Map<StatisticsKeyMessage, ObjectStatisticsImpl> keysStats = new HashMap<>();\n-        for(Map.Entry<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : ctx.localStatistics().e\n+        statCrawler.sendGlobalStat(keysGlobalStats);\n+    }\n \n+    /**\n+     * Cache global statistics.\n+     *\n+     * @param data Global statistics to cache.\n+     */\n+    public void saveGlobalStatistics(Collection<StatisticsObjectData> data) {\n+        data.forEach(objData -> {\n+            try {\n+                ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(this.ctx, objData);\n+\n+                statsRepos.saveGlobalStatistics(new StatisticsKey(objData.key().schema(), objData.key().obj()), objStat);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Cannot read global statistics %s\", objData.key()));\n+            }\n+        });\n     }\n \n-    public void registerLocalResult(UUID gatId, Collection<StatisticsObjectData> data) {\n-        StatisticsGatheringContext ctx = currColls.get(gatId);\n-        if (ctx == null) {\n-            // TODO: log\n+    /**\n+     * Register\n+     *\n+     * @param gatId Gathering id.\n+     * @param data Collected statistics.\n+     */\n+    public void registerLocalResult(UUID gatId, Map<StatisticsObjectData, int[]> data) {\n+        StatisticsGatheringContext stCtx = currColls.get(gatId);\n+        if (stCtx == null) {\n+            if (log.isDebugEnabled())\n+                log.debug(String.format(\"Unable to register outdated statistics collection result %s\", gatId));\n+\n             return;\n         }\n-        ctx.registerCollected(data);\n+        Map<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats = new HashMap<>();\n+        for (StatisticsObjectData objData : data.keySet()) {\n+            keyStats.compute(objData.key(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                try {\n+                    ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n+\n+                    v.add(objStat);\n+                }\n+                catch (IgniteCheckedException e) {\n+                    if (log.isDebugEnabled())\n+                        log.debug(String.format(\"Cannot read local statistics %s by gathering task %s\", objData.key(),\n+                            gatId));\n+                }\n+\n+                return v;\n+            });\n+        }\n+        if (stCtx.registerCollected(keyStats, data.values().stream().mapToInt(a -> a.length).sum()))\n+            finishStatisticsCollection(stCtx);\n     }\n \n     /**\n", "next_change": {"commit": "7ef165002105dd10417170217e86d65771c524bb", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 1f98ad5ca73..4e5949c6399 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -453,35 +461,9 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n                 return v;\n             });\n         }\n-        if (stCtx.registerCollected(keyStats, data.values().stream().mapToInt(a -> a.length).sum()))\n-            finishStatisticsCollection(stCtx);\n-    }\n \n-    /**\n-     * Aggregate local statistics to global one.\n-     *\n-     * @param stat Statistics collection status to aggregate.\n-     * @return Map stats key to merged global statistics.\n-     */\n-    private Map<StatisticsKey, ObjectStatisticsImpl> finishStatCollection(StatisticsGatheringContext stat) {\n-        Map<StatisticsKey, ObjectStatisticsImpl> res = new HashMap<>();\n-        for (Map.Entry<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : stat.collectedStatistics()\n-                .entrySet()) {\n-            StatisticsKeyMessage keyMsg = keyStats.getKey();\n-            GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n-            if (tbl == null) {\n-                if (log.isInfoEnabled())\n-                    log.info(String.format(\"Unable to find object %s.%s to save collected statistics by.\",\n-                            keyMsg.schema(), keyMsg.obj()));\n-\n-                continue;\n-            }\n-\n-            ObjectStatisticsImpl globalStat = statGathering.aggregateLocalStatistics(keyMsg, keyStats.getValue());\n-            StatisticsKey key = new StatisticsKey(keyMsg.schema(), keyMsg.obj());\n-            res.put(key, statsRepos.mergeGlobalStatistics(key, globalStat));\n-        }\n-        return res;\n+        if (stCtx.registerCollected(keyStats, partsCount))\n+            finishStatisticsCollection(stCtx);\n     }\n \n     /**\n", "next_change": {"commit": "05b732cd7e8840c429c48f5561e7c98e0289bcf6", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 4e5949c6399..ab2c41eca80 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -443,23 +447,17 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n         }\n         Map<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats = new HashMap<>();\n         for (StatisticsObjectData objData : data) {\n-            keyStats.compute(objData.key(), (k, v) -> {\n-                if (v == null)\n-                    v = new ArrayList<>();\n-\n-                try {\n-                    ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n-\n-                    v.add(objStat);\n-                }\n-                catch (IgniteCheckedException e) {\n-                    if (log.isDebugEnabled())\n-                        log.debug(String.format(\"Cannot read local statistics %s by gathering task %s\", objData.key(),\n-                            gatId));\n-                }\n-\n-                return v;\n-            });\n+            Collection<ObjectStatisticsImpl> keyObjStats = keyStats.computeIfAbsent(objData.key(), k -> new ArrayList<>());\n+            try {\n+                ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n+\n+                keyObjStats.add(objStat);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Cannot read local statistics %s by gathering task %s\", objData.key(),\n+                        gatId));\n+            }\n         }\n \n         if (stCtx.registerCollected(keyStats, partsCount))\n", "next_change": null}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ2NTI4Nw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545465287", "body": "Let's remove redundant method.", "bodyText": "Let's remove redundant method.", "bodyHTML": "<p dir=\"auto\">Let's remove redundant method.</p>", "author": "AMashenkov", "createdAt": "2020-12-17T23:11:05Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -225,51 +679,58 @@ public IgniteStatisticsRepository statisticsRepository() {\n      * @param tblPartStats Collection of all local partition level statistics by specified key.\n      * @return Local level aggregated statistics.\n      */\n-    public ObjectStatisticsImpl aggregateLocalStatistics(StatsKey key, Collection<ObjectPartitionStatisticsImpl> tblPartStats) {\n+    public ObjectStatisticsImpl aggregateLocalStatistics(\n+            StatsKey key,\n+            Collection<ObjectPartitionStatisticsImpl> tblPartStats\n+    ) {\n         // For now there can be only tables\n-        GridH2Table table = schemaMgr.dataTable(key.schema(), key.obj());\n+        GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n \n-        if (table == null) {\n+        if (tbl == null) {\n             // remove all loaded statistics.\n-            log.info(\"Removing statistics for object \" + key + \" cause table doesn't exists.\");\n+            if (log.isDebugEnabled())\n+                log.debug(String.format(\"Removing statistics for object %s.%s cause table doesn't exists.\",\n+                        key.schema(), key.obj()));\n+\n             statsRepos.clearLocalPartitionsStatistics(key);\n         }\n-        return aggregateLocalStatistics(table, table.getColumns(), tblPartStats);\n+        return aggregateLocalStatistics(tbl, tbl.getColumns(), tblPartStats);\n     }\n \n     /**\n      * Aggregate partition level statistics to local level one.\n      *\n      * @param tbl Table to aggregate statistics by.\n-     * @param selectedColumns Columns to aggregate statistics by.\n+     * @param selectedCols Columns to aggregate statistics by.\n      * @param tblPartStats Collection of partition level statistics.\n      * @return Local level statistics.\n      */\n     private ObjectStatisticsImpl aggregateLocalStatistics(\n             GridH2Table tbl,\n-            Column[] selectedColumns,\n+            Column[] selectedCols,\n             Collection<ObjectPartitionStatisticsImpl> tblPartStats\n     ) {", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTc2NjczMA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545766730", "bodyText": "Sure, I'll clean the class. But this particular method isn't redundant as fas as I see.", "author": "Berkof", "createdAt": "2020-12-18T11:17:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ2NTI4Nw=="}], "type": "inlineReview", "revised_code": {"commit": "ec4a9ef0e7691b605225c12527d496d07d573b42", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex ca50e8e339b..aa95be0231f 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -702,20 +711,20 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n      *\n      * @param tbl Table to aggregate statistics by.\n      * @param selectedCols Columns to aggregate statistics by.\n-     * @param tblPartStats Collection of partition level statistics.\n+     * @param stats Collection of partition level or local level statistics to aggregate.\n      * @return Local level statistics.\n      */\n     private ObjectStatisticsImpl aggregateLocalStatistics(\n             GridH2Table tbl,\n             Column[] selectedCols,\n-            Collection<ObjectPartitionStatisticsImpl> tblPartStats\n+            Collection<? extends ObjectStatisticsImpl> stats\n     ) {\n         Map<Column, List<ColumnStatistics>> colPartStats = new HashMap<>(selectedCols.length);\n         long rowCnt = 0;\n         for (Column col : selectedCols)\n             colPartStats.put(col, new ArrayList<>());\n \n-        for (ObjectPartitionStatisticsImpl partStat : tblPartStats) {\n+        for (ObjectStatisticsImpl partStat : stats) {\n             for (Column col : selectedCols) {\n                 ColumnStatistics colPartStat = partStat.columnStatistics(col.getName());\n                 if (colPartStat != null) {\n", "next_change": {"commit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex aa95be0231f..f208a744d01 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -592,283 +332,72 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n     }\n \n     /**\n-     * Collect partition level statistics.\n+     * Receive and store partition statistics object data for locals backup partition.\n      *\n-     * @param tbl Table to collect statistics by.\n-     * @param partIds Array of partition ids to collect statistics by.\n-     * @param selectedCols Columns to collect statistics by.\n-     * @param cancelled Supplier to check if collection was cancelled.\n-     * @return Collection of partition level statistics by local primary partitions.\n-     * @throws IgniteCheckedException in case of error.\n+     * @param data Collection of partition level statistics of local bacup partitions.\n      */\n-    private Collection<ObjectPartitionStatisticsImpl> collectPartitionStatistics(\n-            GridH2Table tbl,\n-            int[] partIds,\n-            Column[] selectedCols,\n-            Supplier<Boolean> cancelled\n-    ) throws IgniteCheckedException {\n-        List<ObjectPartitionStatisticsImpl> tblPartStats = new ArrayList<>();\n-        GridH2RowDescriptor desc = tbl.rowDescriptor();\n-        String tblName = tbl.getName();\n-        GridDhtPartitionTopology topology = tbl.cacheContext().topology();\n-        AffinityTopologyVersion topologyVersion = topology.readyTopologyVersion();\n-\n-        for (int partId : partIds) {\n-            GridDhtLocalPartition locPart = topology.localPartition(partId, topologyVersion, false);\n-            if (locPart == null)\n-                continue;\n-\n-            if (cancelled.get()) {\n-                if (log.isInfoEnabled())\n-                    log.info(String.format(\"Canceled collection of object %s.%s statistics.\", tbl.identifier().schema(),\n-                            tbl.identifier().table()));\n-\n-                return null;\n-            }\n-\n-            final boolean reserved = locPart.reserve();\n-\n-            try {\n-                if (!reserved || (locPart.state() != OWNING && locPart.state() != MOVING)\n-                        || !locPart.primary(ctx.discovery().topologyVersionEx()))\n-                    continue;\n-\n-                if (locPart.state() == MOVING)\n-                    tbl.cacheContext().preloader().syncFuture().get();\n-\n-                long rowsCnt = 0;\n+    public void receivePartitionsStatistics(Collection<StatisticsObjectData> data) {\n+        for (StatisticsObjectData partData : data) {\n+            StatisticsKey key = new StatisticsKey(partData.key().schema(), partData.key().obj());\n \n-                List<ColumnStatisticsCollector> colStatsCollectors = new ArrayList<>(selectedCols.length);\n-\n-                for (Column col : selectedCols)\n-                    colStatsCollectors.add(new ColumnStatisticsCollector(col, tbl::compareValues));\n-\n-                for (CacheDataRow row : tbl.cacheContext().offheap().cachePartitionIterator(tbl.cacheId(), locPart.id(),\n-                        null, true)) {\n-                    GridQueryTypeDescriptor typeDesc = ctx.query().typeByValue(tbl.cacheName(),\n-                            tbl.cacheContext().cacheObjectContext(), row.key(), row.value(), false);\n-                    if (!tblName.equals(typeDesc.tableName()))\n-                        continue;\n-\n-                    rowsCnt++;\n-\n-                    H2Row row0 = desc.createRow(row);\n-\n-                    for (ColumnStatisticsCollector colStat : colStatsCollectors)\n-                        colStat.add(row0.getValue(colStat.col().getColumnId()));\n-\n-                }\n-\n-                Map<String, ColumnStatistics> colStats = colStatsCollectors.stream().collect(Collectors.toMap(\n-                        csc -> csc.col().getName(), csc -> csc.finish()\n-                ));\n-\n-                tblPartStats.add(new ObjectPartitionStatisticsImpl(locPart.id(), true, rowsCnt,\n-                        locPart.updateCounter(), colStats));\n-\n-                if (log.isTraceEnabled())\n-                    log.trace(String.format(\"Finished statistics collection on %s.%s:%d\",\n-                            tbl.identifier().schema(), tbl.identifier().table(), locPart.id()));\n-            }\n-            finally {\n-                if (reserved)\n-                    locPart.release();\n-            }\n-        }\n-\n-        return tblPartStats;\n-    }\n-\n-    /**\n-     * Aggregate specified partition level statistics to local level statistics.\n-     *\n-     * @param keyMsg Aggregation key.\n-     * @param stats Collection of all local partition level or local level statistics by specified key to aggregate.\n-     * @return Local level aggregated statistics.\n-     */\n-    public ObjectStatisticsImpl aggregateLocalStatistics(\n-            StatsKeyMessage keyMsg,\n-            Collection<? extends ObjectStatisticsImpl> stats\n-    ) {\n-        // For now there can be only tables\n-        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n-\n-        if (tbl == null) {\n-            // remove all loaded statistics.\n-            if (log.isDebugEnabled())\n-                log.debug(String.format(\"Removing statistics for object %s.%s cause table doesn't exists.\",\n-                        keyMsg.schema(), keyMsg.obj()));\n-\n-            // Just to double check\n-            statsRepos.clearLocalPartitionsStatistics(new StatsKey(keyMsg.schema(), keyMsg.obj()));\n-        }\n-\n-        return aggregateLocalStatistics(tbl, filterColumns(tbl.getColumns(), keyMsg.colNames()), stats);\n-    }\n-\n-    /**\n-     * Aggregate partition level statistics to local level one.\n-     *\n-     * @param tbl Table to aggregate statistics by.\n-     * @param selectedCols Columns to aggregate statistics by.\n-     * @param stats Collection of partition level or local level statistics to aggregate.\n-     * @return Local level statistics.\n-     */\n-    private ObjectStatisticsImpl aggregateLocalStatistics(\n-            GridH2Table tbl,\n-            Column[] selectedCols,\n-            Collection<? extends ObjectStatisticsImpl> stats\n-    ) {\n-        Map<Column, List<ColumnStatistics>> colPartStats = new HashMap<>(selectedCols.length);\n-        long rowCnt = 0;\n-        for (Column col : selectedCols)\n-            colPartStats.put(col, new ArrayList<>());\n-\n-        for (ObjectStatisticsImpl partStat : stats) {\n-            for (Column col : selectedCols) {\n-                ColumnStatistics colPartStat = partStat.columnStatistics(col.getName());\n-                if (colPartStat != null) {\n-                    colPartStats.computeIfPresent(col, (k, v) -> {\n-                        v.add(colPartStat);\n-\n-                        return v;\n-                    });\n-                }\n-            }\n-            rowCnt += partStat.rowCount();\n-        }\n-\n-        Map<String, ColumnStatistics> colStats = new HashMap<>(selectedCols.length);\n-        for (Column col : selectedCols) {\n-            ColumnStatistics stat = ColumnStatisticsCollector.aggregate(tbl::compareValues, colPartStats.get(col));\n-            colStats.put(col.getName(), stat);\n-        }\n-\n-        ObjectStatisticsImpl tblStats = new ObjectStatisticsImpl(rowCnt, colStats);\n-\n-        return tblStats;\n-    }\n-\n-    /**\n-     * Receive and handle statistics propagation message with partitions statistics.\n-     *\n-     * @param nodeId Sender node id.\n-     * @param msg Statistics propagation message with partitions statistics to handle.\n-     * @throws IgniteCheckedException In case of errors.\n-     */\n-    private void receivePartitionsStatistics(UUID nodeId, StatsPropagationMessage msg) throws IgniteCheckedException {\n-        UUID locNode = ctx.discovery().localNode().id();\n-        for (StatsObjectData partData : msg.data()) {\n-            StatsKey key = new StatsKey(partData.key().schema(), partData.key().obj());\n-\n-            assert partData.type() == StatsType.PARTITION : \"Got non partition level statistics by \" + key\n+            assert partData.type() == StatisticsType.PARTITION : \"Got non partition level statistics by \" + key\n                     + \" without request\";\n \n             if (log.isTraceEnabled())\n-                log.trace(String.format(\"Received partition statistics %s.%s:%d from node %s\", key.schema(),\n-                        key.obj(), partData.partId(), nodeId));\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d\", key.schema(), key.obj(),\n+                    partData.partId()));\n \n             GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n             if (tbl == null) {\n                 if (log.isInfoEnabled())\n-                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d from node %s\",\n-                            key.schema(), key.obj(), partData.partId(), nodeId));\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d\", key.schema(), key.obj(),\n+                        partData.partId()));\n \n                 continue;\n             }\n-            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(locNode, partData.partId());\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(ctx.localNodeId(), partData.partId());\n             if (partState != OWNING) {\n                 if (log.isInfoEnabled())\n-                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d from node %s\",\n-                            key.schema(), key.obj(), partData.partId(), nodeId));\n+                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d\",\n+                            key.schema(), key.obj(), partData.partId()));\n \n                 continue;\n             }\n \n-            ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n+            try {\n+                ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n \n-            statsRepos.saveLocalPartitionStatistics(key, opStat);\n+                statsRepos.saveLocalPartitionStatistics(key, opStat);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Unable to parse partition statistics for %s.%s:%d because of: %s\",\n+                        key.schema(), key.obj(), partData.partId(), e.getMessage()));\n+            }\n         }\n     }\n \n     /**\n-     * Receive and handle statistics propagation message as response for collection request.\n-     *\n-     * @param nodeId Sender node id.\n-     * @param msg Statistics propagation message with partitions statistics to handle.\n-     * @throws IgniteCheckedException In case of errors.\n+     * Aggregate specified gathered statistics, remove it form local and complete its future.\n+     * @param gatId Gathering to complete.\n      */\n-    private void receiveLocalStatistics(UUID nodeId, StatsCollectionResponse msg) {\n-        assert msg.data().keySet().stream().noneMatch(pd -> pd.type() == StatsType.PARTITION)\n-                : \"Got partition statistics by request \" + msg.reqId();\n-\n-        currCollections.updateCollection(msg.colId(), stat -> {\n-            if (stat == null) {\n-                if (log.isDebugEnabled())\n-                    log.debug(String.format(\n-                        \"Ignoring outdated local statistics collection response from node %s to col %s req %s\",\n-                            nodeId, msg.colId(), msg.reqId()));\n-\n-                return stat;\n-            }\n-\n-            assert stat.colId().equals(msg.colId());\n-\n-            // Need syncronization here to avoid races between removing remaining reqs and adding new ones.\n-            synchronized (stat) {\n-                StatsAddrRequest<StatsCollectionRequest> req = stat.remainingCollectionReqs().remove(msg.reqId());\n-\n-                if (req == null) {\n-                    if (log.isDebugEnabled())\n-                        log.debug(String.format(\n-                                \"Ignoring unknown local statistics collection response from node %s to col %s req %s\",\n-                                nodeId, msg.colId(), msg.reqId()));\n-\n-                    return stat;\n-                }\n-\n-                stat.localStatistics().add(msg);\n-                // TODO: reschedule if not all partition collected.\n-\n-                if (stat.remainingCollectionReqs().isEmpty()) {\n-                    Map<StatsKey, ObjectStatisticsImpl> mergedGlobal = finishStatCollection(stat);\n-\n-                    stat.doneFut().onDone(null);\n-\n-                    return null;\n-                }\n-            }\n-            return stat;\n-        });\n-        /**currCollections.compute(msg.reqId(), (k, v) -> {\n-            if (v == null) {\n-                if (log.isInfoEnabled())\n-                    log.info(String.format(\"Ignoring outdated local statistics collection response from node %s to req %s\",\n-                            nodeId, msg.reqId()));\n-\n-                return null;\n-            }\n-\n-            assert msg.reqId().equals(v.reqId);\n-\n-            boolean rmv = v.remainingNodes.remove(nodeId);\n-            if (!rmv) {\n-                log.warning(String.format(\"Ignoring statistics propagation message from unexpected node %s by request %s.\",\n-                        nodeId, v.reqId));\n-\n-                return v;\n-            }\n+    public void finishStatisticsCollection(UUID gatId) {\n+        StatisticsGatheringContext ctx = currColls.remove(gatId);\n+        if (ctx == null)\n+            return;\n \n-            v.locStatistics.add(msg);\n+        Map<StatisticsKeyMessage, ObjectStatisticsImpl> keysStats = new HashMap<>();\n+        for(Map.Entry<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : ctx.localStatistics().e\n \n-            if (v.remainingNodes.isEmpty()) {\n-                aggregateCollected(v);\n-\n-                return null;\n-            }\n+    }\n \n-            return v;\n-        });**/\n+    public void registerLocalResult(UUID gatId, Collection<StatisticsObjectData> data) {\n+        StatisticsGatheringContext ctx = currColls.get(gatId);\n+        if (ctx == null) {\n+            // TODO: log\n+            return;\n+        }\n+        ctx.registerCollected(data);\n     }\n \n     /**\n", "next_change": {"commit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex f208a744d01..1f98ad5ca73 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -379,25 +381,80 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n \n     /**\n      * Aggregate specified gathered statistics, remove it form local and complete its future.\n-     * @param gatId Gathering to complete.\n+     *\n+     * @param stCtx Gathering to complete.\n      */\n-    public void finishStatisticsCollection(UUID gatId) {\n-        StatisticsGatheringContext ctx = currColls.remove(gatId);\n-        if (ctx == null)\n-            return;\n+    public void finishStatisticsCollection(StatisticsGatheringContext stCtx) {\n+        currColls.remove(stCtx.gatId());\n+\n+        Map<StatisticsKeyMessage, ObjectStatisticsImpl> keysGlobalStats = new HashMap<>();\n+        for (Map.Entry<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : stCtx.collectedStatistics()\n+                .entrySet()) {\n+            ObjectStatisticsImpl globalCollectedStat = statGathering.aggregateLocalStatistics(keyStats.getKey(),\n+                keyStats.getValue());\n+            StatisticsKey statsKey = new StatisticsKey(keyStats.getKey().schema(), keyStats.getKey().obj());\n+            ObjectStatisticsImpl globalStat = statsRepos.mergeGlobalStatistics(statsKey, globalCollectedStat);\n+            keysGlobalStats.put(keyStats.getKey(), globalStat);\n+        }\n \n-        Map<StatisticsKeyMessage, ObjectStatisticsImpl> keysStats = new HashMap<>();\n-        for(Map.Entry<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : ctx.localStatistics().e\n+        statCrawler.sendGlobalStat(keysGlobalStats);\n+    }\n \n+    /**\n+     * Cache global statistics.\n+     *\n+     * @param data Global statistics to cache.\n+     */\n+    public void saveGlobalStatistics(Collection<StatisticsObjectData> data) {\n+        data.forEach(objData -> {\n+            try {\n+                ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(this.ctx, objData);\n+\n+                statsRepos.saveGlobalStatistics(new StatisticsKey(objData.key().schema(), objData.key().obj()), objStat);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Cannot read global statistics %s\", objData.key()));\n+            }\n+        });\n     }\n \n-    public void registerLocalResult(UUID gatId, Collection<StatisticsObjectData> data) {\n-        StatisticsGatheringContext ctx = currColls.get(gatId);\n-        if (ctx == null) {\n-            // TODO: log\n+    /**\n+     * Register\n+     *\n+     * @param gatId Gathering id.\n+     * @param data Collected statistics.\n+     */\n+    public void registerLocalResult(UUID gatId, Map<StatisticsObjectData, int[]> data) {\n+        StatisticsGatheringContext stCtx = currColls.get(gatId);\n+        if (stCtx == null) {\n+            if (log.isDebugEnabled())\n+                log.debug(String.format(\"Unable to register outdated statistics collection result %s\", gatId));\n+\n             return;\n         }\n-        ctx.registerCollected(data);\n+        Map<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats = new HashMap<>();\n+        for (StatisticsObjectData objData : data.keySet()) {\n+            keyStats.compute(objData.key(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                try {\n+                    ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n+\n+                    v.add(objStat);\n+                }\n+                catch (IgniteCheckedException e) {\n+                    if (log.isDebugEnabled())\n+                        log.debug(String.format(\"Cannot read local statistics %s by gathering task %s\", objData.key(),\n+                            gatId));\n+                }\n+\n+                return v;\n+            });\n+        }\n+        if (stCtx.registerCollected(keyStats, data.values().stream().mapToInt(a -> a.length).sum()))\n+            finishStatisticsCollection(stCtx);\n     }\n \n     /**\n", "next_change": {"commit": "7ef165002105dd10417170217e86d65771c524bb", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 1f98ad5ca73..4e5949c6399 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -453,35 +461,9 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n                 return v;\n             });\n         }\n-        if (stCtx.registerCollected(keyStats, data.values().stream().mapToInt(a -> a.length).sum()))\n-            finishStatisticsCollection(stCtx);\n-    }\n \n-    /**\n-     * Aggregate local statistics to global one.\n-     *\n-     * @param stat Statistics collection status to aggregate.\n-     * @return Map stats key to merged global statistics.\n-     */\n-    private Map<StatisticsKey, ObjectStatisticsImpl> finishStatCollection(StatisticsGatheringContext stat) {\n-        Map<StatisticsKey, ObjectStatisticsImpl> res = new HashMap<>();\n-        for (Map.Entry<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : stat.collectedStatistics()\n-                .entrySet()) {\n-            StatisticsKeyMessage keyMsg = keyStats.getKey();\n-            GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n-            if (tbl == null) {\n-                if (log.isInfoEnabled())\n-                    log.info(String.format(\"Unable to find object %s.%s to save collected statistics by.\",\n-                            keyMsg.schema(), keyMsg.obj()));\n-\n-                continue;\n-            }\n-\n-            ObjectStatisticsImpl globalStat = statGathering.aggregateLocalStatistics(keyMsg, keyStats.getValue());\n-            StatisticsKey key = new StatisticsKey(keyMsg.schema(), keyMsg.obj());\n-            res.put(key, statsRepos.mergeGlobalStatistics(key, globalStat));\n-        }\n-        return res;\n+        if (stCtx.registerCollected(keyStats, partsCount))\n+            finishStatisticsCollection(stCtx);\n     }\n \n     /**\n", "next_change": {"commit": "05b732cd7e8840c429c48f5561e7c98e0289bcf6", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 4e5949c6399..ab2c41eca80 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -443,23 +447,17 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n         }\n         Map<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats = new HashMap<>();\n         for (StatisticsObjectData objData : data) {\n-            keyStats.compute(objData.key(), (k, v) -> {\n-                if (v == null)\n-                    v = new ArrayList<>();\n-\n-                try {\n-                    ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n-\n-                    v.add(objStat);\n-                }\n-                catch (IgniteCheckedException e) {\n-                    if (log.isDebugEnabled())\n-                        log.debug(String.format(\"Cannot read local statistics %s by gathering task %s\", objData.key(),\n-                            gatId));\n-                }\n-\n-                return v;\n-            });\n+            Collection<ObjectStatisticsImpl> keyObjStats = keyStats.computeIfAbsent(objData.key(), k -> new ArrayList<>());\n+            try {\n+                ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n+\n+                keyObjStats.add(objStat);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Cannot read local statistics %s by gathering task %s\", objData.key(),\n+                        gatId));\n+            }\n         }\n \n         if (stCtx.registerCollected(keyStats, partsCount))\n", "next_change": null}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3MDU1OQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545470559", "body": "Why a MOVING partition ignores incoming statistics from? It is feasible primary or backup.\r\nIf first then we will need to recalculate statistics, in other words make the job twice.\r\nIf second - we'll loose statistics?", "bodyText": "Why a MOVING partition ignores incoming statistics from? It is feasible primary or backup.\nIf first then we will need to recalculate statistics, in other words make the job twice.\nIf second - we'll loose statistics?", "bodyHTML": "<p dir=\"auto\">Why a MOVING partition ignores incoming statistics from? It is feasible primary or backup.<br>\nIf first then we will need to recalculate statistics, in other words make the job twice.<br>\nIf second - we'll loose statistics?</p>", "author": "AMashenkov", "createdAt": "2020-12-17T23:24:01Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -278,4 +739,349 @@ private ObjectStatisticsImpl aggregateLocalStatistics(\n \n         return tblStats;\n     }\n+\n+    /**\n+     * Receive and handle statistics propagation message with partitions statistics.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receivePartitionsStatistics(UUID nodeId, StatsPropagationMessage msg) throws IgniteCheckedException {\n+        UUID locNode = ctx.discovery().localNode().id();\n+        for (StatsObjectData partData : msg.data()) {\n+            StatsKey key = new StatsKey(partData.key().schema(), partData.key().obj());\n+\n+            assert partData.type() == StatsType.PARTITION : \"Got non partition level statistics by \" + key\n+                    + \" without request\";\n+\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d from node %s\", key.schema(),\n+                        key.obj(), partData.partId(), nodeId));\n+\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(locNode, partData.partId());\n+            if (partState != OWNING) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTAxNTI3MQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555015271", "bodyText": "Please take a look at current solution. I'll try to scan only local primary partitions. If some partitions wasn't collected on some node - they won't be in parts array in response and sender will reschedule they to some other node.", "author": "Berkof", "createdAt": "2021-01-11T12:32:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3MDU1OQ=="}], "type": "inlineReview", "revised_code": {"commit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex ca50e8e339b..f208a744d01 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -379,537 +222,253 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n             String objName,\n             String... colNames\n     ) throws IgniteCheckedException {\n-        StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n-        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n-        UUID colId = UUID.randomUUID();\n-        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.singletonList(keyMsg),\n-            Collections.emptyMap(), doneFut);\n-        synchronized (status) {\n-            currCollections.updateCollection(colId, s -> status);\n-            Map<StatsKeyMessage, int[]> failedPartitions = null;\n-            int cnt = 0;\n-            do {\n-                Collection<StatsCollectionAddrRequest> reqs = currCollections.generateCollectionRequests(colId,\n-                    Collections.singletonList(keyMsg), failedPartitions);\n-                Map<UUID, StatsCollectionRequest> msgs = reqs.stream().collect(Collectors.toMap(\n-                    StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req));\n-\n-                Map<UUID, StatsCollectionRequest> failedMsgs = sendLocalRequests(msgs);\n-                failedPartitions = currCollections.extractFailed(failedMsgs.values()\n-                    .toArray(new StatsCollectionRequest[0]));\n-                if (cnt++ > 10)\n-                    throw new IgniteCheckedException(String.format(\n-                            \"Unable to send all messages to collect statistics by key %s.%s\", schemaName, objName));\n-            }\n-            while (!failedPartitions.isEmpty());\n-        }\n-        UUID locNode = ctx.discovery().localNode().id();\n-        StatsCollectionAddrRequest locReq = status.remainingCollectionReqs().get(locNode);\n-        statMgmtPool.submit(() -> processLocal(ctx.discovery().localNode().id(), locReq.req()));\n-        /*final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n-\n-        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n-        UUID colId = UUID.randomUUID();\n-        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.emptyMap(), doneFut);\n-\n-        synchronized (status) {\n-            currCollections.put(colId, status);\n-            if (!doRequests(status, Collections.singletonList(keyMsg))) {\n-                status.doneFut().cancel();\n-                currCollections.remove(colId);\n-                throw new IgniteCheckedException(\"Unable to send statistics collection messages to all necessary nodes\");\n-            }\n-        }\n-        UUID locNode = ctx.discovery().localNode().id();\n-        StatsCollectionAddrRequest locReq = status.remainingCollectionReqs().get(locNode);\n-        if (locReq != null)\n-            statMgmtPool.submit(() -> processLocal(locNode, locReq.req()));\n-\n-        doneFut.get();\n-        */\n-\n-//\n-//        StatsKey key = new StatsKey(schemaName, objName);\n-//\n-//        List<CacheGroupContext> grpContexts = extractGroups(Collections.singletonList(key));\n-//\n-//        assert grpContexts.size() == 1;\n-//\n-//        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n-//        Map<UUID, List<Integer>> reqNodes = nodePartitions(grpContexts.get(0), null);\n-//        Map<UUID, StatsCollectionAddrRequest> reqs = prepareRequests(colId, keyMsg, reqNodes);\n-//\n-//        synchronized (status) {\n-//            currCollections.put(colId, status);\n-//\n-//            Map<UUID, StatsCollectionRequest> failedReqs = sendLocalRequests(reqs.values().stream().collect(\n-//                    Collectors.toMap(StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req)));\n-//\n-//            if (failedReqs != null) {\n-//                for (UUID failedReqId : failedReqs.keySet())\n-//                    status.remainingCollectionReqs().remove(failedReqId);\n-//\n-//                Map<StatsKeyMessage,List<Integer>> failedPartIds = extractFailed(failedReqs.values());\n-//\n-//                assert failedPartIds.size() == 1;\n-//\n-//                List<Integer> newPartIds = failedPartIds.get(keyMsg);\n-//\n-//                assert newPartIds != null;\n-//\n-//                Map<UUID, List<Integer>> newReqNodes = nodePartitions(grpContexts.get(0), newPartIds);\n-//                Map<UUID, StatsCollectionAddrRequest> newReqs = prepareRequests(colId, keyMsg, newReqNodes);\n-//                Map<UUID, StatsCollectionRequest> newFailedReqs = sendLocalRequests(newReqs.values().stream().collect(\n-//                        Collectors.toMap(StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req)));\n-//                if (newFailedReqs != null) {\n-//                    doneFut.cancel();\n-//\n-//                    // TODO: is it safe?\n-//                    currCollections.remove(colId);\n-//\n-//                    throw new IgniteCheckedException(String.format(\n-//                            \"Unable to send statistics collection request to %d nodes. Cancelling collection %s\",\n-//                            newFailedReqs.size(), colId));\n-//                }\n-//                status.remainingCollectionReqs().putAll(newReqs);\n-//\n-//                failedReqs.values().stream().forEach(req -> req.keys().values().forEach(failedPartIds.addAll()));\n-//                rescheduleFailedPartitions(colId, Collections.singletonMap(keyMsg, ));\n-//            }\n-//            UUID locNode = ctx.discovery().localNode().id();\n-//            StatsCollectionAddrRequest locReq = reqs.get(locNode);\n-//            if (locReq != null)\n-//                statMgmtPool.submit(() -> processLocal(locNode, locReq.req()));\n-//\n-//        }\n-//\n-//        doneFut.get();\n+        StatisticsKeyMessage keyMsg = new StatisticsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        StatisticsGatheringContext status = new StatisticsGatheringContext(Collections.singleton(keyMsg));\n+        currColls.put(status.gatId(), status);\n+        collectObjectStatistics(status);\n+\n+        status.doneFut().get();\n     }\n \n     /**\n-     * Generate and try to send all request for particular status. Should be called inside status lock after putting it\n-     * into currCollections map. REMOVE!!!!\n+     * Ensure that local gathering context exists and schedule local statistics gathering.\n      *\n-     * @param status Status to process.\n-     * @param keys Collection of object keys to collect statistics by.\n-     * @return {@code true} if all request was successfully sended, {@code false} - otherwise (one should remove\n-     * status from cullCollections.\n+     * @param nodeId Initiator node id.\n+     * @param gatId Gathering id.\n+     * @param reqId Request id.\n+     * @param keys Keys to collect statistics by.\n      */\n-    protected boolean doRequests(StatCollectionStatus status, List<StatsKeyMessage> keys) throws IgniteCheckedException {\n-        /*Map<CacheGroupContext, Collection<StatsKeyMessage>> grpContexts = extractGroups(keys);\n-        List<Map<UUID, StatsCollectionAddrRequest>> reqsByGrps = new ArrayList<>(grpContexts.size());\n-        for (Map.Entry<CacheGroupContext, Collection<StatsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n-            Map<UUID, List<Integer>> reqNodes = nodePartitions(grpEntry.getKey(), null);\n-            for(StatsKeyMessage keyMsg : grpEntry.getValue())\n-                reqsByGrps.add(prepareRequests(status.colId(), keyMsg, reqNodes));\n-\n-        }\n-        Map<UUID, StatsCollectionAddrRequest> reqs = compressRequests(reqsByGrps);\n-\n-        status.remainingCollectionReqs().putAll(reqs);\n+    public void gatherLocalObjectStatisticsAsync(UUID gatId, UUID reqId, Map<StatisticsKeyMessage, int[]> keys) {\n+        StatisticsGatheringContext[] ctxs = new StatisticsGatheringContext[1];\n+        currColls.compute(gatId, (k, v) -> {\n+            if (v == null)\n+                v = new StatisticsGatheringContext(gatId, keys.keySet());\n \n-        Map<UUID, StatsCollectionRequest> failedReqs = sendLocalRequests(reqs.values().stream().collect(\n-                Collectors.toMap(StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req)));\n-        // TODO: cycle replanning and sending\n-        return failedReqs.isEmpty();\n+            ctxs[0] = v;\n \n-         */\n-        return false;\n-    }\n+            return v;\n+        });\n \n-    /**\n-     * Group request by target node id. REMOVE!!!!\n-     *\n-     * @param reqsByGrps Requests to compress, map.\n-     * @return Grouped requests.\n-     */\n-    protected Map<UUID, StatsCollectionAddrRequest> compressRequests(List<Map<UUID, StatsCollectionAddrRequest>> reqsByGrps) {\n-        // NodeId to base request map\n-        Map<UUID, StatsCollectionAddrRequest> reqByNode = new HashMap<>();\n-        for (Map<UUID, StatsCollectionAddrRequest> grpReqs : reqsByGrps)\n-            for (StatsCollectionAddrRequest addReq : grpReqs.values())\n-                reqByNode.compute(addReq.nodeId(), (k, v) -> (v == null) ? addReq : addKey(v, addReq));\n-\n-        return reqByNode.entrySet().stream().collect(Collectors.toMap(e -> e.getValue().req().reqId(),\n-            Map.Entry::getValue));\n+        statGathering.collectLocalObjectStatisticsAsync(reqId, keys);\n     }\n \n-    /**\n-     * Add keys from add request to the base one and return it.\n-     *\n-     * @param base Base request to add to.\n-     * @param add Add request to add.\n-     * @return Request with all keys from both specified.\n-     */\n-    protected StatsCollectionAddrRequest addKey(StatsCollectionAddrRequest base, StatsCollectionAddrRequest add) {\n-        assert base.nodeId().equals(add.nodeId());\n+    /** {@inheritDoc} */\n+    @Override public StatsCollectionFuture<Map<GridTuple3<String, String, String[]>, ObjectStatistics>>\n+    collectObjectStatisticsAsync(\n+        GridTuple3<String, String, String[]>... keys\n+    ) throws IgniteCheckedException {\n+        Set<StatisticsKeyMessage> keysMsg = Arrays.stream(keys).map(\n+                k -> new StatisticsKeyMessage(k.get1(), k.get2(), Arrays.asList(k.get3()))).collect(Collectors.toSet());\n \n-        base.req().keys().putAll(add.req().keys());\n-        return base;\n-    }\n+        StatisticsGatheringContext status = new StatisticsGatheringContext(keysMsg);\n \n+        collectObjectStatistics(status);\n \n-    /**\n-     * Prepare statistics collection request for each nodes. MOVED!!!!\n-     *\n-     * @param colId Collection id.\n-     * @param keyMsg Key to collect statistics by.\n-     * @param reqNodes Map of node id to array of partition ids to be collected on that node.\n-     * @return Map: request id to statistics collection addressed request.\n-     */\n-    protected Map<UUID, StatsCollectionAddrRequest> _____prepareRequests(\n-            UUID colId,\n-            StatsKeyMessage keyMsg,\n-            Map<UUID, List<Integer>> reqNodes\n-    ) {\n-        Map<UUID, StatsCollectionAddrRequest> res = new HashMap<>(reqNodes.size());\n-        for (Map.Entry<UUID, List<Integer>> reqNode : reqNodes.entrySet()) {\n-            UUID reqId = UUID.randomUUID();\n-            StatsCollectionRequest colReq = new StatsCollectionRequest(colId, reqId, Collections.singletonMap(keyMsg,\n-                    reqNode.getValue().stream().mapToInt(Integer::intValue).toArray()));\n-            StatsCollectionAddrRequest addrReq = new StatsCollectionAddrRequest(colReq, reqNode.getKey());\n-            res.put(reqId, addrReq);\n-        }\n-        return res;\n+        return status.doneFut();\n     }\n \n     /**\n-     * TODO\n+     * Cancel specified statistics gathering process.\n+     *\n+     * @param gatId Gathering id to cancel.\n      */\n-    public void stop() {\n-        if (statMgmtPool != null) {\n-            List<Runnable> unfinishedTasks = statMgmtPool.shutdownNow();\n-            if (!unfinishedTasks.isEmpty())\n-                log.warning(String.format(\"%d statistics collection request cancelled.\", unfinishedTasks.size()));\n-        }\n+    public void cancelLocalStatisticsGathering(UUID gatId){\n+       StatisticsGatheringContext ctx = currColls.remove(gatId);\n+       if (ctx != null)\n+           ctx.doneFut().cancel();\n     }\n \n-    /**\n-     * Collect partition level statistics.\n-     *\n-     * @param tbl Table to collect statistics by.\n-     * @param partIds Array of partition ids to collect statistics by.\n-     * @param selectedCols Columns to collect statistics by.\n-     * @param cancelled Supplier to check if collection was cancelled.\n-     * @return Collection of partition level statistics by local primary partitions.\n-     * @throws IgniteCheckedException in case of error.\n-     */\n-    private Collection<ObjectPartitionStatisticsImpl> collectPartitionStatistics(\n-            GridH2Table tbl,\n-            int[] partIds,\n-            Column[] selectedCols,\n-            Supplier<Boolean> cancelled\n-    ) throws IgniteCheckedException {\n-        List<ObjectPartitionStatisticsImpl> tblPartStats = new ArrayList<>();\n-        GridH2RowDescriptor desc = tbl.rowDescriptor();\n-        String tblName = tbl.getName();\n-        GridDhtPartitionTopology topology = tbl.cacheContext().topology();\n-        AffinityTopologyVersion topologyVersion = topology.readyTopologyVersion();\n-\n-        for (int partId : partIds) {\n-            GridDhtLocalPartition locPart = topology.localPartition(partId, topologyVersion, false);\n-            if (locPart == null)\n-                continue;\n+    /** {@inheritDoc} */\n+    @Override public boolean cancelObjectStatisticsGathering(UUID colId) {\n+        boolean[] res = new boolean[]{true};\n \n-            if (cancelled.get()) {\n-                if (log.isInfoEnabled())\n-                    log.info(String.format(\"Canceled collection of object %s.%s statistics.\", tbl.identifier().schema(),\n-                            tbl.identifier().table()));\n+        helper.updateCollection(colId, s -> {\n+            if (s == null) {\n+                res[0] = false;\n \n                 return null;\n             }\n \n-            final boolean reserved = locPart.reserve();\n-\n-            try {\n-                if (!reserved || (locPart.state() != OWNING && locPart.state() != MOVING)\n-                        || !locPart.primary(ctx.discovery().topologyVersionEx()))\n-                    continue;\n-\n-                if (locPart.state() == MOVING)\n-                    tbl.cacheContext().preloader().syncFuture().get();\n-\n-                long rowsCnt = 0;\n-\n-                List<ColumnStatisticsCollector> colStatsCollectors = new ArrayList<>(selectedCols.length);\n+            s.doneFut().cancel();\n \n-                for (Column col : selectedCols)\n-                    colStatsCollectors.add(new ColumnStatisticsCollector(col, tbl::compareValues));\n+            Map<UUID, List<UUID>> nodeRequests = new HashMap<>();\n+            for (StatisticsAddrRequest<StatisticsGatheringRequest> req : s.remainingCollectionReqs().values()) {\n+                nodeRequests.compute(req.nodeId(), (k, v) -> {\n+                   if (v == null)\n+                       v = new ArrayList<>();\n+                   v.add(req.req().reqId());\n \n-                for (CacheDataRow row : tbl.cacheContext().offheap().cachePartitionIterator(tbl.cacheId(), locPart.id(),\n-                        null, true)) {\n-                    GridQueryTypeDescriptor typeDesc = ctx.query().typeByValue(tbl.cacheName(),\n-                            tbl.cacheContext().cacheObjectContext(), row.key(), row.value(), false);\n-                    if (!tblName.equals(typeDesc.tableName()))\n-                        continue;\n-\n-                    rowsCnt++;\n-\n-                    H2Row row0 = desc.createRow(row);\n-\n-                    for (ColumnStatisticsCollector colStat : colStatsCollectors)\n-                        colStat.add(row0.getValue(colStat.col().getColumnId()));\n-\n-                }\n-\n-                Map<String, ColumnStatistics> colStats = colStatsCollectors.stream().collect(Collectors.toMap(\n-                        csc -> csc.col().getName(), csc -> csc.finish()\n-                ));\n+                   return v;\n+                });\n+            }\n \n-                tblPartStats.add(new ObjectPartitionStatisticsImpl(locPart.id(), true, rowsCnt,\n-                        locPart.updateCounter(), colStats));\n+            Collection<StatisticsAddrRequest<CancelStatisticsGatheringRequest>> cancelReqs = nodeRequests.entrySet().stream().map(\n+                        targetNode -> new StatisticsAddrRequest<>(\n+                            new CancelStatisticsGatheringRequest(colId, targetNode.getValue().toArray(new UUID[0])),\n+                            targetNode.getKey()))\n+                    .collect(Collectors.toList());\n \n-                if (log.isTraceEnabled())\n-                    log.trace(String.format(\"Finished statistics collection on %s.%s:%d\",\n-                            tbl.identifier().schema(), tbl.identifier().table(), locPart.id()));\n-            }\n-            finally {\n-                if (reserved)\n-                    locPart.release();\n-            }\n-        }\n+            Collection<StatisticsAddrRequest<CancelStatisticsGatheringRequest>> failed = sendRequests(cancelReqs);\n+            if (!F.isEmpty(failed))\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Unable to cancel all statistics collections requests (%d failed) by colId %s\",\n+                            failed.size(), colId));\n \n-        return tblPartStats;\n-    }\n+            return null;\n+        });\n \n-    /**\n-     * Aggregate specified partition level statistics to local level statistics.\n-     *\n-     * @param key Aggregation key.\n-     * @param tblPartStats Collection of all local partition level statistics by specified key.\n-     * @return Local level aggregated statistics.\n-     */\n-    public ObjectStatisticsImpl aggregateLocalStatistics(\n-            StatsKey key,\n-            Collection<ObjectPartitionStatisticsImpl> tblPartStats\n-    ) {\n-        // For now there can be only tables\n-        GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n-\n-        if (tbl == null) {\n-            // remove all loaded statistics.\n-            if (log.isDebugEnabled())\n-                log.debug(String.format(\"Removing statistics for object %s.%s cause table doesn't exists.\",\n-                        key.schema(), key.obj()));\n-\n-            statsRepos.clearLocalPartitionsStatistics(key);\n-        }\n-        return aggregateLocalStatistics(tbl, tbl.getColumns(), tblPartStats);\n+        return res[0];\n     }\n \n     /**\n-     * Aggregate partition level statistics to local level one.\n-     *\n-     * @param tbl Table to aggregate statistics by.\n-     * @param selectedCols Columns to aggregate statistics by.\n-     * @param tblPartStats Collection of partition level statistics.\n-     * @return Local level statistics.\n+     * Stop statistics manager.\n      */\n-    private ObjectStatisticsImpl aggregateLocalStatistics(\n-            GridH2Table tbl,\n-            Column[] selectedCols,\n-            Collection<ObjectPartitionStatisticsImpl> tblPartStats\n-    ) {\n-        Map<Column, List<ColumnStatistics>> colPartStats = new HashMap<>(selectedCols.length);\n-        long rowCnt = 0;\n-        for (Column col : selectedCols)\n-            colPartStats.put(col, new ArrayList<>());\n-\n-        for (ObjectPartitionStatisticsImpl partStat : tblPartStats) {\n-            for (Column col : selectedCols) {\n-                ColumnStatistics colPartStat = partStat.columnStatistics(col.getName());\n-                if (colPartStat != null) {\n-                    colPartStats.computeIfPresent(col, (k, v) -> {\n-                        v.add(colPartStat);\n-\n-                        return v;\n-                    });\n-                }\n-            }\n-            rowCnt += partStat.rowCount();\n-        }\n-\n-        Map<String, ColumnStatistics> colStats = new HashMap<>(selectedCols.length);\n-        for (Column col : selectedCols) {\n-            ColumnStatistics stat = ColumnStatisticsCollector.aggregate(tbl::compareValues, colPartStats.get(col));\n-            colStats.put(col.getName(), stat);\n+    public void stop() {\n+        if (statMgmtPool != null) {\n+            List<Runnable> unfinishedTasks = statMgmtPool.shutdownNow();\n+            if (!unfinishedTasks.isEmpty())\n+                log.warning(String.format(\"%d statistics collection request cancelled.\", unfinishedTasks.size()));\n         }\n-\n-        ObjectStatisticsImpl tblStats = new ObjectStatisticsImpl(rowCnt, colStats);\n-\n-        return tblStats;\n     }\n \n     /**\n-     * Receive and handle statistics propagation message with partitions statistics.\n+     * Receive and store partition statistics object data for locals backup partition.\n      *\n-     * @param nodeId Sender node id.\n-     * @param msg Statistics propagation message with partitions statistics to handle.\n-     * @throws IgniteCheckedException In case of errors.\n+     * @param data Collection of partition level statistics of local bacup partitions.\n      */\n-    private void receivePartitionsStatistics(UUID nodeId, StatsPropagationMessage msg) throws IgniteCheckedException {\n-        UUID locNode = ctx.discovery().localNode().id();\n-        for (StatsObjectData partData : msg.data()) {\n-            StatsKey key = new StatsKey(partData.key().schema(), partData.key().obj());\n+    public void receivePartitionsStatistics(Collection<StatisticsObjectData> data) {\n+        for (StatisticsObjectData partData : data) {\n+            StatisticsKey key = new StatisticsKey(partData.key().schema(), partData.key().obj());\n \n-            assert partData.type() == StatsType.PARTITION : \"Got non partition level statistics by \" + key\n+            assert partData.type() == StatisticsType.PARTITION : \"Got non partition level statistics by \" + key\n                     + \" without request\";\n \n             if (log.isTraceEnabled())\n-                log.trace(String.format(\"Received partition statistics %s.%s:%d from node %s\", key.schema(),\n-                        key.obj(), partData.partId(), nodeId));\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d\", key.schema(), key.obj(),\n+                    partData.partId()));\n \n             GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n             if (tbl == null) {\n                 if (log.isInfoEnabled())\n-                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d from node %s\",\n-                            key.schema(), key.obj(), partData.partId(), nodeId));\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d\", key.schema(), key.obj(),\n+                        partData.partId()));\n \n                 continue;\n             }\n-            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(locNode, partData.partId());\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(ctx.localNodeId(), partData.partId());\n             if (partState != OWNING) {\n                 if (log.isInfoEnabled())\n-                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d from node %s\",\n-                            key.schema(), key.obj(), partData.partId(), nodeId));\n+                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d\",\n+                            key.schema(), key.obj(), partData.partId()));\n \n                 continue;\n             }\n \n-            ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n+            try {\n+                ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n \n-            statsRepos.saveLocalPartitionStatistics(key, opStat);\n+                statsRepos.saveLocalPartitionStatistics(key, opStat);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Unable to parse partition statistics for %s.%s:%d because of: %s\",\n+                        key.schema(), key.obj(), partData.partId(), e.getMessage()));\n+            }\n         }\n     }\n \n     /**\n-     * Receive and handle statistics propagation message as response for collection request.\n-     *\n-     * @param nodeId Sender node id.\n-     * @param msg Statistics propagation message with partitions statistics to handle.\n-     * @throws IgniteCheckedException In case of errors.\n+     * Aggregate specified gathered statistics, remove it form local and complete its future.\n+     * @param gatId Gathering to complete.\n      */\n-    private void receiveLocalStatistics(UUID nodeId, StatsCollectionResponse msg) {\n-        assert msg.data().keySet().stream().noneMatch(pd -> pd.type() == StatsType.PARTITION)\n-                : \"Got partition statistics by request \" + msg.reqId();\n-\n-        /**currCollections.compute(msg.reqId(), (k, v) -> {\n-            if (v == null) {\n-                if (log.isInfoEnabled())\n-                    log.info(String.format(\"Ignoring outdated local statistics collection response from node %s to req %s\",\n-                            nodeId, msg.reqId()));\n-\n-                return null;\n-            }\n-\n-            assert msg.reqId().equals(v.reqId);\n-\n-            boolean rmv = v.remainingNodes.remove(nodeId);\n-            if (!rmv) {\n-                log.warning(String.format(\"Ignoring statistics propagation message from unexpected node %s by request %s.\",\n-                        nodeId, v.reqId));\n-\n-                return v;\n-            }\n-\n-            v.locStatistics.add(msg);\n+    public void finishStatisticsCollection(UUID gatId) {\n+        StatisticsGatheringContext ctx = currColls.remove(gatId);\n+        if (ctx == null)\n+            return;\n \n-            if (v.remainingNodes.isEmpty()) {\n-                aggregateCollected(v);\n+        Map<StatisticsKeyMessage, ObjectStatisticsImpl> keysStats = new HashMap<>();\n+        for(Map.Entry<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : ctx.localStatistics().e\n \n-                return null;\n-            }\n+    }\n \n-            return v;\n-        });**/\n+    public void registerLocalResult(UUID gatId, Collection<StatisticsObjectData> data) {\n+        StatisticsGatheringContext ctx = currColls.get(gatId);\n+        if (ctx == null) {\n+            // TODO: log\n+            return;\n+        }\n+        ctx.registerCollected(data);\n     }\n \n     /**\n-     * Send statistics by request.\n+     * Aggregate local statistics to global one.\n      *\n-     * @param nodeId Node to send statistics to.\n-     * @param msg Statistics request to process.\n-     * @throws IgniteCheckedException In case of errors.\n+     * @param stat Statistics collection status to aggregate.\n+     * @return Map stats key to merged global statistics.\n      */\n-    private void supplyStatistics(UUID nodeId, StatsGetRequest msg) throws IgniteCheckedException {\n-        List<StatsObjectData> data = new ArrayList<>(msg.keys().size());\n-        for (StatsKeyMessage keyMsg : msg.keys()) {\n-            StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n-            ObjectStatisticsImpl objStats = statsRepos.getGlobalStatistics(key);\n-\n-            if (objStats != null)\n-                data.add(StatisticsUtils.toObjectData(keyMsg, StatsType.GLOBAL, objStats));\n-        }\n-        StatsPropagationMessage res = new StatsPropagationMessage(data);\n-        ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n+    private Map<StatisticsKey, ObjectStatisticsImpl> finishStatCollection(StatisticsGatheringContext stat) {\n+        Map<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keysStats = new HashMap<>();\n+        for (StatisticsGatheringResponse resp : stat.localStatistics()) {\n+            for (StatisticsObjectData objData : resp.data().keySet()) {\n+                keysStats.compute(objData.key(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+                    try {\n+                        ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n \n-        /**List<StatsObjectData> data = new ArrayList<>();\n-        for (StatsKeyMessage key : msg.keys()) {\n-            StatsKey statsKey = new StatsKey(key.schema(), key.obj());\n-            ObjectStatisticsImpl objStats = statsRepos.getGlobalStatistics(statsKey);\n+                        v.add(objStat);\n+                    } catch (IgniteCheckedException e) {\n+                        if (log.isInfoEnabled())\n+                            log.info(String.format(\"Unable to parse statistics for object %s from response %s\",\n+                                    objData.key(), resp.reqId()));\n+                    }\n \n-            if (objStats != null)\n-                data.add(StatisticsUtils.toMessage(statsKey, StatsType.GLOBAL, objStats));\n+                    return v;\n+                });\n+            }\n         }\n \n-        StatsPropagationMessage res = new StatsPropagationMessage(msg.reqId(), data);\n-        ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);**/\n-    }\n-\n-    private void cancelStatisticsCollection(UUID nodeId, CancelStatsCollectionRequest msg) {\n-        currCollections.updateCollection(msg.colId(), stat -> {\n-            stat.doneFut().cancel();\n-            return null;\n-        });\n-        /*StatCollectionStatus currState = currCollections.remove(msg.reqId());\n-        if (currState != null) {\n-            if (log.isDebugEnabled())\n-                log.debug(String.format(\"Cancelling statistics collection by reqId = %s from node %s\", msg.reqId(),\n-                        nodeId));\n-\n-            currState.doneFut().cancel();\n-        } else\n-        if (log.isDebugEnabled())\n-            log.debug(String.format(\"Unable to cancel staitstics collection by req = %s from node %s\", msg.reqId(),\n-                    nodeId));*/\n-    }\n+        Map<StatisticsKey, ObjectStatisticsImpl> res = new HashMap<>();\n+        for (Map.Entry<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : keysStats.entrySet()) {\n+            StatisticsKeyMessage keyMsg = keyStats.getKey();\n+            GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Unable to find object %s.%s to save collected statistics by.\",\n+                            keyMsg.schema(), keyMsg.obj()));\n \n-    /** {@inheritDoc} */\n-    @Override public void onMessage(UUID nodeId, Object msg, byte plc) {\n-        try {\n-            if (msg instanceof StatsPropagationMessage)\n-                receivePartitionsStatistics(nodeId, (StatsPropagationMessage) msg);\n-            else if (msg instanceof StatsCollectionResponse)\n-                receiveLocalStatistics(nodeId, (StatsCollectionResponse) msg);\n-            else if (msg instanceof StatsGetRequest)\n-                supplyStatistics(nodeId, (StatsGetRequest) msg);\n-            else if (msg instanceof StatsCollectionRequest)\n-                handleCollectionRequest(nodeId, (StatsCollectionRequest)msg);\n-            else if (msg instanceof CancelStatsCollectionRequest)\n-                cancelStatisticsCollection(nodeId, (CancelStatsCollectionRequest) msg);\n-            else if (msg instanceof StatsClearRequest)\n-                clearObjectStatistics(nodeId, (StatsClearRequest)msg);\n-            else\n-                log.warning(\"Unknown msg \" + msg +  \" in statistics topic \" + TOPIC + \" from node \" + nodeId);\n-        } catch (IgniteCheckedException e) {\n-            log.warning(\"Statistic msg from node \" + nodeId + \" processing failed\", e);\n+                continue;\n+            }\n+            ObjectStatisticsImpl globalStat = aggregateLocalStatistics(keyMsg, keyStats.getValue());\n+            StatisticsKey key = new StatisticsKey(keyMsg.schema(), keyMsg.obj());\n+            res.put(key, statsRepos.mergeGlobalStatistics(key, globalStat));\n         }\n+        return res;\n     }\n \n     /**\n-     * Handle statistics clear request.\n+     * Get global statistics by key.\n      *\n-     * @param nodeId UUID of request sender node.\n-     * @param msg Clear request message.\n+     * @param key Key to get statistics by.\n+     * @return Global statistics or {@code null} if there are no statistics for specified key.\n      */\n-    private void clearObjectStatistics(UUID nodeId, StatsClearRequest msg) {\n-        for (StatsKeyMessage key : msg.keys()) {\n-            if (log.isTraceEnabled())\n-                log.trace(String.format(\"Clearing statistics by request %s from node %s by key %s.%s\", msg.reqId(),\n-                        nodeId, key.schema(), key.obj()));\n-            statMgmtPool.submit(() -> clearObjectStatisticsLocal(key));\n-        }\n-    }\n+   public ObjectStatisticsImpl getGlobalStatistics(StatisticsKeyMessage key) {\n+        ObjectStatisticsImpl stat = statsRepos.getGlobalStatistics(new StatisticsKey(key.schema(), key.obj()));\n+        if (stat != null && !F.isEmpty(key.colNames()))\n+            stat = IgniteStatisticsHelper.filterColumns(stat, key.colNames());\n+\n+        return stat;\n+   }\n+\n+    /**\n+     * Clear object statistics by specified keys.\n+     *\n+     * @param keys Collection of keys to clean statistics by.\n+     */\n+   public void clearObjectStatisticsLocal(Collection<StatisticsKeyMessage> keys) {\n+       for (StatisticsKeyMessage key : keys)\n+           clearObjectStatisticsLocal(key);\n+   }\n \n     /**\n      * Collect local object statistics by specified request (possibly for a few objects) and send result back to origin\n", "next_change": {"commit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex f208a744d01..1f98ad5ca73 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -476,7 +514,7 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n      *\n      * @param req request to collect statistics by.\n      */\n-    private void processLocal(UUID nodeId, StatisticsGatheringRequest req) {\n+    /*private void processLocal(UUID nodeId, StatisticsGatheringRequest req) {\n         UUID locNode = ctx.localNodeId();\n \n         StatisticsGatheringContext stat = (nodeId.equals(locNode)) ? helper.getCollection(req.gatId()) :\n", "next_change": {"commit": "e54c934091d0917505fbe4bd919fd766a492897e", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 1f98ad5ca73..c989b5605e7 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -507,59 +487,4 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n        for (StatisticsKeyMessage key : keys)\n            clearObjectStatisticsLocal(key);\n    }\n-\n-    /**\n-     * Collect local object statistics by specified request (possibly for a few objects) and send result back to origin\n-     * node specified. If local node id specified - process result without sending it throw the communication.\n-     *\n-     * @param req request to collect statistics by.\n-     */\n-    /*private void processLocal(UUID nodeId, StatisticsGatheringRequest req) {\n-        UUID locNode = ctx.localNodeId();\n-\n-        StatisticsGatheringContext stat = (nodeId.equals(locNode)) ? helper.getCollection(req.gatId()) :\n-            helper.getCollection(req.reqId());\n-\n-        if (stat == null)\n-            return;\n-\n-        Map<StatisticsObjectData, int[]> collected = new HashMap<>(req.keys().size());\n-        for (Map.Entry<StatisticsKeyMessage, int[]> keyEntry : req.keys().entrySet()) {\n-            try {\n-                StatisticsKeyMessage key = keyEntry.getKey();\n-                IgniteBiTuple <ObjectStatisticsImpl, int[]> loStat = gatherLocalObjectStatisticsAsync(key,\n-                        keyEntry.getValue(), () -> stat.doneFut().isCancelled());\n-                StatisticsKey statsKey = new StatisticsKey(key.schema(), key.obj());\n-\n-                // TODO?\n-                statsRepos.mergeLocalStatistics(statsKey, loStat.getKey());\n-\n-                StatisticsObjectData objData = StatisticsUtils.toObjectData(key, StatisticsType.LOCAL, loStat.getKey());\n-                collected.put(objData, loStat.getValue());\n-            }\n-            catch (IgniteCheckedException e) {\n-                log.warning(String.format(\"Unable to complete request %s due to error %s\", req.reqId(), e.getMessage()));\n-                // TODO: send cancel to originator node\n-            }\n-        }\n-\n-        StatisticsGatheringResponse res = new StatisticsGatheringResponse(req.gatId(), req.reqId(), collected);\n-\n-        if (locNode.equals(nodeId))\n-            receiveLocalStatistics(nodeId, res);\n-        else {\n-            try {\n-                ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n-            }\n-            catch (IgniteCheckedException e) {\n-                if (log.isDebugEnabled())\n-                    log.debug(String.format(\n-                            \"Unable to send statistics collection result to node %s in response to colId %s, reqId %s\",\n-                        nodeId, req.gatId(), req.reqId()));\n-            }\n-\n-            // Not local collection - remove by its reqId.\n-            helper.updateCollection(req.reqId(), s -> null);\n-        }\n-    }*/\n }\n", "next_change": {"commit": "33170812024f6c4d321f85287fea0b6c3abdb9e5", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex c989b5605e7..5011b1a87a5 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -478,13 +458,20 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n         return stat;\n    }\n \n+    /** {@inheritDoc} */\n+    @Override public ObjectStatistics getGlobalStatistics(String schemaName, String objName) {\n+        return statsRepos.getGlobalStatistics(new StatisticsKey(schemaName, objName));\n+    }\n+\n     /**\n-     * Clear object statistics by specified keys.\n+     * Check that all server nodes in the cluster support STATISTICS_COLLECTION features.\n      *\n-     * @param keys Collection of keys to clean statistics by.\n+     * @param op Operation name.\n      */\n-   public void clearObjectStatisticsLocal(Collection<StatisticsKeyMessage> keys) {\n-       for (StatisticsKeyMessage key : keys)\n-           clearObjectStatisticsLocal(key);\n+   private void checkSupport(String op) throws IgniteCheckedException {\n+       if (!IgniteFeatures.allNodesSupport(ctx, IgniteFeatures.STATISTICS_COLLECTION, IgniteDiscoverySpi.SRV_NODES)) {\n+           throw new IgniteCheckedException(String.format(\n+               \"Unable to perform %s due to not all server nodes supports STATISTICS_COLLECTION feature.\", op));\n+       }\n    }\n }\n", "next_change": {"commit": "f5aafee54b1036c09d4944ca9bf0254f8bfd2b1e", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 5011b1a87a5..4df3ed6f1e0 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -464,11 +485,13 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n     }\n \n     /**\n-     * Check that all server nodes in the cluster support STATISTICS_COLLECTION features.\n+     * Check that all server nodes in the cluster support STATISTICS_COLLECTION feature. Throws IgniteCheckedException\n+     * in not.\n      *\n      * @param op Operation name.\n+     * @throws IgniteCheckedException If at least one server node doesn't support feature.\n      */\n-   private void checkSupport(String op) throws IgniteCheckedException {\n+   private void checkStatisticsSupport(String op) throws IgniteCheckedException {\n        if (!IgniteFeatures.allNodesSupport(ctx, IgniteFeatures.STATISTICS_COLLECTION, IgniteDiscoverySpi.SRV_NODES)) {\n            throw new IgniteCheckedException(String.format(\n                \"Unable to perform %s due to not all server nodes supports STATISTICS_COLLECTION feature.\", op));\n", "next_change": {"commit": "65caf2d646409c3be32c4d00f762fcdc7ec4ceb0", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 4df3ed6f1e0..47277987f34 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -492,9 +492,18 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n      * @throws IgniteCheckedException If at least one server node doesn't support feature.\n      */\n    private void checkStatisticsSupport(String op) throws IgniteCheckedException {\n-       if (!IgniteFeatures.allNodesSupport(ctx, IgniteFeatures.STATISTICS_COLLECTION, IgniteDiscoverySpi.SRV_NODES)) {\n+       if (!isStatisticsSupport()) {\n            throw new IgniteCheckedException(String.format(\n                \"Unable to perform %s due to not all server nodes supports STATISTICS_COLLECTION feature.\", op));\n        }\n    }\n+\n+    /**\n+     * Test is statistics collection feature are supported by each server node in cluster.\n+     *\n+     * @return {@code true} if all server nodes support STATISTICS_COLLECTION feature, {@code false} - otherwise.\n+     */\n+   private boolean isStatisticsSupport() {\n+       return IgniteFeatures.allNodesSupport(ctx, IgniteFeatures.STATISTICS_COLLECTION, IgniteDiscoverySpi.SRV_NODES);\n+   }\n }\n", "next_change": null}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3MTA5OQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545471099", "body": "What does mean 'local' in method name?", "bodyText": "What does mean 'local' in method name?", "bodyHTML": "<p dir=\"auto\">What does mean 'local' in method name?</p>", "author": "AMashenkov", "createdAt": "2020-12-17T23:25:15Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -278,4 +739,349 @@ private ObjectStatisticsImpl aggregateLocalStatistics(\n \n         return tblStats;\n     }\n+\n+    /**\n+     * Receive and handle statistics propagation message with partitions statistics.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receivePartitionsStatistics(UUID nodeId, StatsPropagationMessage msg) throws IgniteCheckedException {\n+        UUID locNode = ctx.discovery().localNode().id();\n+        for (StatsObjectData partData : msg.data()) {\n+            StatsKey key = new StatsKey(partData.key().schema(), partData.key().obj());\n+\n+            assert partData.type() == StatsType.PARTITION : \"Got non partition level statistics by \" + key\n+                    + \" without request\";\n+\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d from node %s\", key.schema(),\n+                        key.obj(), partData.partId(), nodeId));\n+\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(locNode, partData.partId());\n+            if (partState != OWNING) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+\n+            ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n+\n+            statsRepos.saveLocalPartitionStatistics(key, opStat);\n+        }\n+    }\n+\n+    /**\n+     * Receive and handle statistics propagation message as response for collection request.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receiveLocalStatistics(UUID nodeId, StatsCollectionResponse msg) {", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTc2ODA5OQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545768099", "bodyText": "\"Level\" of statistics. There are partition, local and global statistics. Yes, strictly it can be not exactly local statistics, if there are some rescheduling during whole process, but in general receiveLocalStatistics method should receive collected \"local\" statistics and try to finalyze statistics collection process.", "author": "Berkof", "createdAt": "2020-12-18T11:20:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3MTA5OQ=="}], "type": "inlineReview", "revised_code": {"commit": "ec4a9ef0e7691b605225c12527d496d07d573b42", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex ca50e8e339b..aa95be0231f 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -793,6 +802,44 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n         assert msg.data().keySet().stream().noneMatch(pd -> pd.type() == StatsType.PARTITION)\n                 : \"Got partition statistics by request \" + msg.reqId();\n \n+        currCollections.updateCollection(msg.colId(), stat -> {\n+            if (stat == null) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\n+                        \"Ignoring outdated local statistics collection response from node %s to col %s req %s\",\n+                            nodeId, msg.colId(), msg.reqId()));\n+\n+                return stat;\n+            }\n+\n+            assert stat.colId().equals(msg.colId());\n+\n+            // Need syncronization here to avoid races between removing remaining reqs and adding new ones.\n+            synchronized (stat) {\n+                StatsAddrRequest<StatsCollectionRequest> req = stat.remainingCollectionReqs().remove(msg.reqId());\n+\n+                if (req == null) {\n+                    if (log.isDebugEnabled())\n+                        log.debug(String.format(\n+                                \"Ignoring unknown local statistics collection response from node %s to col %s req %s\",\n+                                nodeId, msg.colId(), msg.reqId()));\n+\n+                    return stat;\n+                }\n+\n+                stat.localStatistics().add(msg);\n+                // TODO: reschedule if not all partition collected.\n+\n+                if (stat.remainingCollectionReqs().isEmpty()) {\n+                    Map<StatsKey, ObjectStatisticsImpl> mergedGlobal = finishStatCollection(stat);\n+\n+                    stat.doneFut().onDone(null);\n+\n+                    return null;\n+                }\n+            }\n+            return stat;\n+        });\n         /**currCollections.compute(msg.reqId(), (k, v) -> {\n             if (v == null) {\n                 if (log.isInfoEnabled())\n", "next_change": {"commit": "d8c6c6bb46b36bf8d36a0578e7c1813e04bfabfe", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex aa95be0231f..0f88eff3479 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -840,35 +706,6 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n             }\n             return stat;\n         });\n-        /**currCollections.compute(msg.reqId(), (k, v) -> {\n-            if (v == null) {\n-                if (log.isInfoEnabled())\n-                    log.info(String.format(\"Ignoring outdated local statistics collection response from node %s to req %s\",\n-                            nodeId, msg.reqId()));\n-\n-                return null;\n-            }\n-\n-            assert msg.reqId().equals(v.reqId);\n-\n-            boolean rmv = v.remainingNodes.remove(nodeId);\n-            if (!rmv) {\n-                log.warning(String.format(\"Ignoring statistics propagation message from unexpected node %s by request %s.\",\n-                        nodeId, v.reqId));\n-\n-                return v;\n-            }\n-\n-            v.locStatistics.add(msg);\n-\n-            if (v.remainingNodes.isEmpty()) {\n-                aggregateCollected(v);\n-\n-                return null;\n-            }\n-\n-            return v;\n-        });**/\n     }\n \n     /**\n", "next_change": {"commit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 0f88eff3479..f208a744d01 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -458,254 +332,72 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n     }\n \n     /**\n-     * Collect partition level statistics.\n-     *\n-     * @param tbl Table to collect statistics by.\n-     * @param partIds Array of partition ids to collect statistics by.\n-     * @param selectedCols Columns to collect statistics by.\n-     * @param cancelled Supplier to check if collection was cancelled.\n-     * @return Collection of partition level statistics by local primary partitions.\n-     * @throws IgniteCheckedException in case of error.\n-     */\n-    private Collection<ObjectPartitionStatisticsImpl> collectPartitionStatistics(\n-            GridH2Table tbl,\n-            int[] partIds,\n-            Column[] selectedCols,\n-            Supplier<Boolean> cancelled\n-    ) throws IgniteCheckedException {\n-        List<ObjectPartitionStatisticsImpl> tblPartStats = new ArrayList<>();\n-        GridH2RowDescriptor desc = tbl.rowDescriptor();\n-        String tblName = tbl.getName();\n-        GridDhtPartitionTopology topology = tbl.cacheContext().topology();\n-        AffinityTopologyVersion topologyVersion = topology.readyTopologyVersion();\n-\n-        for (int partId : partIds) {\n-            GridDhtLocalPartition locPart = topology.localPartition(partId, topologyVersion, false);\n-            if (locPart == null)\n-                continue;\n-\n-            if (cancelled.get()) {\n-                if (log.isInfoEnabled())\n-                    log.info(String.format(\"Canceled collection of object %s.%s statistics.\", tbl.identifier().schema(),\n-                            tbl.identifier().table()));\n-\n-                return null;\n-            }\n-\n-            final boolean reserved = locPart.reserve();\n-\n-            try {\n-                if (!reserved || (locPart.state() != OWNING && locPart.state() != MOVING)\n-                        || !locPart.primary(ctx.discovery().topologyVersionEx()))\n-                    continue;\n-\n-                if (locPart.state() == MOVING)\n-                    tbl.cacheContext().preloader().syncFuture().get();\n-\n-                long rowsCnt = 0;\n-\n-                List<ColumnStatisticsCollector> colStatsCollectors = new ArrayList<>(selectedCols.length);\n-\n-                for (Column col : selectedCols)\n-                    colStatsCollectors.add(new ColumnStatisticsCollector(col, tbl::compareValues));\n-\n-                for (CacheDataRow row : tbl.cacheContext().offheap().cachePartitionIterator(tbl.cacheId(), locPart.id(),\n-                        null, true)) {\n-                    GridQueryTypeDescriptor typeDesc = ctx.query().typeByValue(tbl.cacheName(),\n-                            tbl.cacheContext().cacheObjectContext(), row.key(), row.value(), false);\n-                    if (!tblName.equals(typeDesc.tableName()))\n-                        continue;\n-\n-                    rowsCnt++;\n-\n-                    H2Row row0 = desc.createRow(row);\n-\n-                    for (ColumnStatisticsCollector colStat : colStatsCollectors)\n-                        colStat.add(row0.getValue(colStat.col().getColumnId()));\n-\n-                }\n-\n-                Map<String, ColumnStatistics> colStats = colStatsCollectors.stream().collect(Collectors.toMap(\n-                        csc -> csc.col().getName(), csc -> csc.finish()\n-                ));\n-\n-                tblPartStats.add(new ObjectPartitionStatisticsImpl(locPart.id(), true, rowsCnt,\n-                        locPart.updateCounter(), colStats));\n-\n-                if (log.isTraceEnabled())\n-                    log.trace(String.format(\"Finished statistics collection on %s.%s:%d\",\n-                            tbl.identifier().schema(), tbl.identifier().table(), locPart.id()));\n-            }\n-            finally {\n-                if (reserved)\n-                    locPart.release();\n-            }\n-        }\n-\n-        return tblPartStats;\n-    }\n-\n-    /**\n-     * Aggregate specified partition level statistics to local level statistics.\n-     *\n-     * @param keyMsg Aggregation key.\n-     * @param stats Collection of all local partition level or local level statistics by specified key to aggregate.\n-     * @return Local level aggregated statistics.\n-     */\n-    public ObjectStatisticsImpl aggregateLocalStatistics(\n-            StatsKeyMessage keyMsg,\n-            Collection<? extends ObjectStatisticsImpl> stats\n-    ) {\n-        // For now there can be only tables\n-        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n-\n-        if (tbl == null) {\n-            // remove all loaded statistics.\n-            if (log.isDebugEnabled())\n-                log.debug(String.format(\"Removing statistics for object %s.%s cause table doesn't exists.\",\n-                        keyMsg.schema(), keyMsg.obj()));\n-\n-            // Just to double check\n-            statsRepos.clearLocalPartitionsStatistics(new StatsKey(keyMsg.schema(), keyMsg.obj()));\n-        }\n-\n-        return aggregateLocalStatistics(tbl, filterColumns(tbl.getColumns(), keyMsg.colNames()), stats);\n-    }\n-\n-    /**\n-     * Aggregate partition level statistics to local level one.\n-     *\n-     * @param tbl Table to aggregate statistics by.\n-     * @param selectedCols Columns to aggregate statistics by.\n-     * @param stats Collection of partition level or local level statistics to aggregate.\n-     * @return Local level statistics.\n-     */\n-    private ObjectStatisticsImpl aggregateLocalStatistics(\n-            GridH2Table tbl,\n-            Column[] selectedCols,\n-            Collection<? extends ObjectStatisticsImpl> stats\n-    ) {\n-        Map<Column, List<ColumnStatistics>> colPartStats = new HashMap<>(selectedCols.length);\n-        long rowCnt = 0;\n-        for (Column col : selectedCols)\n-            colPartStats.put(col, new ArrayList<>());\n-\n-        for (ObjectStatisticsImpl partStat : stats) {\n-            for (Column col : selectedCols) {\n-                ColumnStatistics colPartStat = partStat.columnStatistics(col.getName());\n-                if (colPartStat != null) {\n-                    colPartStats.computeIfPresent(col, (k, v) -> {\n-                        v.add(colPartStat);\n-\n-                        return v;\n-                    });\n-                }\n-            }\n-            rowCnt += partStat.rowCount();\n-        }\n-\n-        Map<String, ColumnStatistics> colStats = new HashMap<>(selectedCols.length);\n-        for (Column col : selectedCols) {\n-            ColumnStatistics stat = ColumnStatisticsCollector.aggregate(tbl::compareValues, colPartStats.get(col));\n-            colStats.put(col.getName(), stat);\n-        }\n-\n-        ObjectStatisticsImpl tblStats = new ObjectStatisticsImpl(rowCnt, colStats);\n-\n-        return tblStats;\n-    }\n-\n-    /**\n-     * Receive and handle statistics propagation message with partitions statistics.\n+     * Receive and store partition statistics object data for locals backup partition.\n      *\n-     * @param nodeId Sender node id.\n-     * @param msg Statistics propagation message with partitions statistics to handle.\n-     * @throws IgniteCheckedException In case of errors.\n+     * @param data Collection of partition level statistics of local bacup partitions.\n      */\n-    private void receivePartitionsStatistics(UUID nodeId, StatsPropagationMessage msg) throws IgniteCheckedException {\n-        UUID locNode = ctx.localNodeId();\n-        for (StatsObjectData partData : msg.data()) {\n-            StatsKey key = new StatsKey(partData.key().schema(), partData.key().obj());\n+    public void receivePartitionsStatistics(Collection<StatisticsObjectData> data) {\n+        for (StatisticsObjectData partData : data) {\n+            StatisticsKey key = new StatisticsKey(partData.key().schema(), partData.key().obj());\n \n-            assert partData.type() == StatsType.PARTITION : \"Got non partition level statistics by \" + key\n+            assert partData.type() == StatisticsType.PARTITION : \"Got non partition level statistics by \" + key\n                     + \" without request\";\n \n             if (log.isTraceEnabled())\n-                log.trace(String.format(\"Received partition statistics %s.%s:%d from node %s\", key.schema(),\n-                        key.obj(), partData.partId(), nodeId));\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d\", key.schema(), key.obj(),\n+                    partData.partId()));\n \n             GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n             if (tbl == null) {\n                 if (log.isInfoEnabled())\n-                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d from node %s\",\n-                            key.schema(), key.obj(), partData.partId(), nodeId));\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d\", key.schema(), key.obj(),\n+                        partData.partId()));\n \n                 continue;\n             }\n-            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(locNode, partData.partId());\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(ctx.localNodeId(), partData.partId());\n             if (partState != OWNING) {\n                 if (log.isInfoEnabled())\n-                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d from node %s\",\n-                            key.schema(), key.obj(), partData.partId(), nodeId));\n+                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d\",\n+                            key.schema(), key.obj(), partData.partId()));\n \n                 continue;\n             }\n \n-            ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n+            try {\n+                ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n \n-            statsRepos.saveLocalPartitionStatistics(key, opStat);\n+                statsRepos.saveLocalPartitionStatistics(key, opStat);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Unable to parse partition statistics for %s.%s:%d because of: %s\",\n+                        key.schema(), key.obj(), partData.partId(), e.getMessage()));\n+            }\n         }\n     }\n \n     /**\n-     * Receive and handle statistics propagation message as response for collection request.\n-     *\n-     * @param nodeId Sender node id.\n-     * @param msg Statistics propagation message with partitions statistics to handle.\n-     * @throws IgniteCheckedException In case of errors.\n+     * Aggregate specified gathered statistics, remove it form local and complete its future.\n+     * @param gatId Gathering to complete.\n      */\n-    private void receiveLocalStatistics(UUID nodeId, StatsCollectionResponse msg) {\n-        assert msg.data().keySet().stream().noneMatch(pd -> pd.type() == StatsType.PARTITION)\n-                : \"Got partition statistics by request \" + msg.reqId();\n-\n-        currCollections.updateCollection(msg.colId(), stat -> {\n-            if (stat == null) {\n-                if (log.isDebugEnabled())\n-                    log.debug(String.format(\n-                        \"Ignoring outdated local statistics collection response from node %s to col %s req %s\",\n-                            nodeId, msg.colId(), msg.reqId()));\n-\n-                return stat;\n-            }\n-\n-            assert stat.colId().equals(msg.colId());\n-\n-            // Need syncronization here to avoid races between removing remaining reqs and adding new ones.\n-            synchronized (stat) {\n-                StatsAddrRequest<StatsCollectionRequest> req = stat.remainingCollectionReqs().remove(msg.reqId());\n-\n-                if (req == null) {\n-                    if (log.isDebugEnabled())\n-                        log.debug(String.format(\n-                                \"Ignoring unknown local statistics collection response from node %s to col %s req %s\",\n-                                nodeId, msg.colId(), msg.reqId()));\n-\n-                    return stat;\n-                }\n-\n-                stat.localStatistics().add(msg);\n-                // TODO: reschedule if not all partition collected.\n+    public void finishStatisticsCollection(UUID gatId) {\n+        StatisticsGatheringContext ctx = currColls.remove(gatId);\n+        if (ctx == null)\n+            return;\n \n-                if (stat.remainingCollectionReqs().isEmpty()) {\n-                    Map<StatsKey, ObjectStatisticsImpl> mergedGlobal = finishStatCollection(stat);\n+        Map<StatisticsKeyMessage, ObjectStatisticsImpl> keysStats = new HashMap<>();\n+        for(Map.Entry<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : ctx.localStatistics().e\n \n-                    stat.doneFut().onDone(null);\n+    }\n \n-                    return null;\n-                }\n-            }\n-            return stat;\n-        });\n+    public void registerLocalResult(UUID gatId, Collection<StatisticsObjectData> data) {\n+        StatisticsGatheringContext ctx = currColls.get(gatId);\n+        if (ctx == null) {\n+            // TODO: log\n+            return;\n+        }\n+        ctx.registerCollected(data);\n     }\n \n     /**\n", "next_change": {"commit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex f208a744d01..1f98ad5ca73 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -379,25 +381,80 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n \n     /**\n      * Aggregate specified gathered statistics, remove it form local and complete its future.\n-     * @param gatId Gathering to complete.\n+     *\n+     * @param stCtx Gathering to complete.\n      */\n-    public void finishStatisticsCollection(UUID gatId) {\n-        StatisticsGatheringContext ctx = currColls.remove(gatId);\n-        if (ctx == null)\n-            return;\n+    public void finishStatisticsCollection(StatisticsGatheringContext stCtx) {\n+        currColls.remove(stCtx.gatId());\n+\n+        Map<StatisticsKeyMessage, ObjectStatisticsImpl> keysGlobalStats = new HashMap<>();\n+        for (Map.Entry<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : stCtx.collectedStatistics()\n+                .entrySet()) {\n+            ObjectStatisticsImpl globalCollectedStat = statGathering.aggregateLocalStatistics(keyStats.getKey(),\n+                keyStats.getValue());\n+            StatisticsKey statsKey = new StatisticsKey(keyStats.getKey().schema(), keyStats.getKey().obj());\n+            ObjectStatisticsImpl globalStat = statsRepos.mergeGlobalStatistics(statsKey, globalCollectedStat);\n+            keysGlobalStats.put(keyStats.getKey(), globalStat);\n+        }\n \n-        Map<StatisticsKeyMessage, ObjectStatisticsImpl> keysStats = new HashMap<>();\n-        for(Map.Entry<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : ctx.localStatistics().e\n+        statCrawler.sendGlobalStat(keysGlobalStats);\n+    }\n \n+    /**\n+     * Cache global statistics.\n+     *\n+     * @param data Global statistics to cache.\n+     */\n+    public void saveGlobalStatistics(Collection<StatisticsObjectData> data) {\n+        data.forEach(objData -> {\n+            try {\n+                ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(this.ctx, objData);\n+\n+                statsRepos.saveGlobalStatistics(new StatisticsKey(objData.key().schema(), objData.key().obj()), objStat);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Cannot read global statistics %s\", objData.key()));\n+            }\n+        });\n     }\n \n-    public void registerLocalResult(UUID gatId, Collection<StatisticsObjectData> data) {\n-        StatisticsGatheringContext ctx = currColls.get(gatId);\n-        if (ctx == null) {\n-            // TODO: log\n+    /**\n+     * Register\n+     *\n+     * @param gatId Gathering id.\n+     * @param data Collected statistics.\n+     */\n+    public void registerLocalResult(UUID gatId, Map<StatisticsObjectData, int[]> data) {\n+        StatisticsGatheringContext stCtx = currColls.get(gatId);\n+        if (stCtx == null) {\n+            if (log.isDebugEnabled())\n+                log.debug(String.format(\"Unable to register outdated statistics collection result %s\", gatId));\n+\n             return;\n         }\n-        ctx.registerCollected(data);\n+        Map<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats = new HashMap<>();\n+        for (StatisticsObjectData objData : data.keySet()) {\n+            keyStats.compute(objData.key(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                try {\n+                    ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n+\n+                    v.add(objStat);\n+                }\n+                catch (IgniteCheckedException e) {\n+                    if (log.isDebugEnabled())\n+                        log.debug(String.format(\"Cannot read local statistics %s by gathering task %s\", objData.key(),\n+                            gatId));\n+                }\n+\n+                return v;\n+            });\n+        }\n+        if (stCtx.registerCollected(keyStats, data.values().stream().mapToInt(a -> a.length).sum()))\n+            finishStatisticsCollection(stCtx);\n     }\n \n     /**\n", "next_change": {"commit": "7ef165002105dd10417170217e86d65771c524bb", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 1f98ad5ca73..4e5949c6399 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -453,35 +461,9 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n                 return v;\n             });\n         }\n-        if (stCtx.registerCollected(keyStats, data.values().stream().mapToInt(a -> a.length).sum()))\n-            finishStatisticsCollection(stCtx);\n-    }\n \n-    /**\n-     * Aggregate local statistics to global one.\n-     *\n-     * @param stat Statistics collection status to aggregate.\n-     * @return Map stats key to merged global statistics.\n-     */\n-    private Map<StatisticsKey, ObjectStatisticsImpl> finishStatCollection(StatisticsGatheringContext stat) {\n-        Map<StatisticsKey, ObjectStatisticsImpl> res = new HashMap<>();\n-        for (Map.Entry<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : stat.collectedStatistics()\n-                .entrySet()) {\n-            StatisticsKeyMessage keyMsg = keyStats.getKey();\n-            GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n-            if (tbl == null) {\n-                if (log.isInfoEnabled())\n-                    log.info(String.format(\"Unable to find object %s.%s to save collected statistics by.\",\n-                            keyMsg.schema(), keyMsg.obj()));\n-\n-                continue;\n-            }\n-\n-            ObjectStatisticsImpl globalStat = statGathering.aggregateLocalStatistics(keyMsg, keyStats.getValue());\n-            StatisticsKey key = new StatisticsKey(keyMsg.schema(), keyMsg.obj());\n-            res.put(key, statsRepos.mergeGlobalStatistics(key, globalStat));\n-        }\n-        return res;\n+        if (stCtx.registerCollected(keyStats, partsCount))\n+            finishStatisticsCollection(stCtx);\n     }\n \n     /**\n", "next_change": {"commit": "05b732cd7e8840c429c48f5561e7c98e0289bcf6", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 4e5949c6399..ab2c41eca80 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -443,23 +447,17 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n         }\n         Map<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats = new HashMap<>();\n         for (StatisticsObjectData objData : data) {\n-            keyStats.compute(objData.key(), (k, v) -> {\n-                if (v == null)\n-                    v = new ArrayList<>();\n-\n-                try {\n-                    ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n-\n-                    v.add(objStat);\n-                }\n-                catch (IgniteCheckedException e) {\n-                    if (log.isDebugEnabled())\n-                        log.debug(String.format(\"Cannot read local statistics %s by gathering task %s\", objData.key(),\n-                            gatId));\n-                }\n-\n-                return v;\n-            });\n+            Collection<ObjectStatisticsImpl> keyObjStats = keyStats.computeIfAbsent(objData.key(), k -> new ArrayList<>());\n+            try {\n+                ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n+\n+                keyObjStats.add(objStat);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Cannot read local statistics %s by gathering task %s\", objData.key(),\n+                        gatId));\n+            }\n         }\n \n         if (stCtx.registerCollected(keyStats, partsCount))\n", "next_change": null}]}}]}}]}}, {"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 0f88eff3479..f208a744d01 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -714,10 +406,10 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n      * @param stat Statistics collection status to aggregate.\n      * @return Map stats key to merged global statistics.\n      */\n-    private Map<StatsKey, ObjectStatisticsImpl> finishStatCollection(StatCollectionStatus stat) {\n-        Map<StatsKeyMessage, Collection<ObjectStatisticsImpl>> keysStats = new HashMap<>();\n-        for (StatsCollectionResponse resp : stat.localStatistics()) {\n-            for (StatsObjectData objData : resp.data().keySet()) {\n+    private Map<StatisticsKey, ObjectStatisticsImpl> finishStatCollection(StatisticsGatheringContext stat) {\n+        Map<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keysStats = new HashMap<>();\n+        for (StatisticsGatheringResponse resp : stat.localStatistics()) {\n+            for (StatisticsObjectData objData : resp.data().keySet()) {\n                 keysStats.compute(objData.key(), (k, v) -> {\n                     if (v == null)\n                         v = new ArrayList<>();\n", "next_change": {"commit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex f208a744d01..1f98ad5ca73 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -407,29 +464,9 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n      * @return Map stats key to merged global statistics.\n      */\n     private Map<StatisticsKey, ObjectStatisticsImpl> finishStatCollection(StatisticsGatheringContext stat) {\n-        Map<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keysStats = new HashMap<>();\n-        for (StatisticsGatheringResponse resp : stat.localStatistics()) {\n-            for (StatisticsObjectData objData : resp.data().keySet()) {\n-                keysStats.compute(objData.key(), (k, v) -> {\n-                    if (v == null)\n-                        v = new ArrayList<>();\n-                    try {\n-                        ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n-\n-                        v.add(objStat);\n-                    } catch (IgniteCheckedException e) {\n-                        if (log.isInfoEnabled())\n-                            log.info(String.format(\"Unable to parse statistics for object %s from response %s\",\n-                                    objData.key(), resp.reqId()));\n-                    }\n-\n-                    return v;\n-                });\n-            }\n-        }\n-\n         Map<StatisticsKey, ObjectStatisticsImpl> res = new HashMap<>();\n-        for (Map.Entry<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : keysStats.entrySet()) {\n+        for (Map.Entry<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : stat.collectedStatistics()\n+                .entrySet()) {\n             StatisticsKeyMessage keyMsg = keyStats.getKey();\n             GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n             if (tbl == null) {\n", "next_change": {"commit": "7ef165002105dd10417170217e86d65771c524bb", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 1f98ad5ca73..4e5949c6399 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -453,35 +461,9 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n                 return v;\n             });\n         }\n-        if (stCtx.registerCollected(keyStats, data.values().stream().mapToInt(a -> a.length).sum()))\n-            finishStatisticsCollection(stCtx);\n-    }\n \n-    /**\n-     * Aggregate local statistics to global one.\n-     *\n-     * @param stat Statistics collection status to aggregate.\n-     * @return Map stats key to merged global statistics.\n-     */\n-    private Map<StatisticsKey, ObjectStatisticsImpl> finishStatCollection(StatisticsGatheringContext stat) {\n-        Map<StatisticsKey, ObjectStatisticsImpl> res = new HashMap<>();\n-        for (Map.Entry<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : stat.collectedStatistics()\n-                .entrySet()) {\n-            StatisticsKeyMessage keyMsg = keyStats.getKey();\n-            GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n-            if (tbl == null) {\n-                if (log.isInfoEnabled())\n-                    log.info(String.format(\"Unable to find object %s.%s to save collected statistics by.\",\n-                            keyMsg.schema(), keyMsg.obj()));\n-\n-                continue;\n-            }\n-\n-            ObjectStatisticsImpl globalStat = statGathering.aggregateLocalStatistics(keyMsg, keyStats.getValue());\n-            StatisticsKey key = new StatisticsKey(keyMsg.schema(), keyMsg.obj());\n-            res.put(key, statsRepos.mergeGlobalStatistics(key, globalStat));\n-        }\n-        return res;\n+        if (stCtx.registerCollected(keyStats, partsCount))\n+            finishStatisticsCollection(stCtx);\n     }\n \n     /**\n", "next_change": {"commit": "05b732cd7e8840c429c48f5561e7c98e0289bcf6", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 4e5949c6399..ab2c41eca80 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -443,23 +447,17 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n         }\n         Map<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats = new HashMap<>();\n         for (StatisticsObjectData objData : data) {\n-            keyStats.compute(objData.key(), (k, v) -> {\n-                if (v == null)\n-                    v = new ArrayList<>();\n-\n-                try {\n-                    ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n-\n-                    v.add(objStat);\n-                }\n-                catch (IgniteCheckedException e) {\n-                    if (log.isDebugEnabled())\n-                        log.debug(String.format(\"Cannot read local statistics %s by gathering task %s\", objData.key(),\n-                            gatId));\n-                }\n-\n-                return v;\n-            });\n+            Collection<ObjectStatisticsImpl> keyObjStats = keyStats.computeIfAbsent(objData.key(), k -> new ArrayList<>());\n+            try {\n+                ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n+\n+                keyObjStats.add(objStat);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Cannot read local statistics %s by gathering task %s\", objData.key(),\n+                        gatId));\n+            }\n         }\n \n         if (stCtx.registerCollected(keyStats, partsCount))\n", "next_change": null}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3NTUxMQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545475511", "body": "As I understand StatsGetRequest is just return current aggregated statistics and doesn't trigger gathering new stats, right?\r\nThis is a different floew and may be we need a separate component for this.", "bodyText": "As I understand StatsGetRequest is just return current aggregated statistics and doesn't trigger gathering new stats, right?\nThis is a different floew and may be we need a separate component for this.", "bodyHTML": "<p dir=\"auto\">As I understand StatsGetRequest is just return current aggregated statistics and doesn't trigger gathering new stats, right?<br>\nThis is a different floew and may be we need a separate component for this.</p>", "author": "AMashenkov", "createdAt": "2020-12-17T23:36:18Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -278,4 +739,349 @@ private ObjectStatisticsImpl aggregateLocalStatistics(\n \n         return tblStats;\n     }\n+\n+    /**\n+     * Receive and handle statistics propagation message with partitions statistics.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receivePartitionsStatistics(UUID nodeId, StatsPropagationMessage msg) throws IgniteCheckedException {\n+        UUID locNode = ctx.discovery().localNode().id();\n+        for (StatsObjectData partData : msg.data()) {\n+            StatsKey key = new StatsKey(partData.key().schema(), partData.key().obj());\n+\n+            assert partData.type() == StatsType.PARTITION : \"Got non partition level statistics by \" + key\n+                    + \" without request\";\n+\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d from node %s\", key.schema(),\n+                        key.obj(), partData.partId(), nodeId));\n+\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(locNode, partData.partId());\n+            if (partState != OWNING) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+\n+            ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n+\n+            statsRepos.saveLocalPartitionStatistics(key, opStat);\n+        }\n+    }\n+\n+    /**\n+     * Receive and handle statistics propagation message as response for collection request.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receiveLocalStatistics(UUID nodeId, StatsCollectionResponse msg) {\n+        assert msg.data().keySet().stream().noneMatch(pd -> pd.type() == StatsType.PARTITION)\n+                : \"Got partition statistics by request \" + msg.reqId();\n+\n+        /**currCollections.compute(msg.reqId(), (k, v) -> {\n+            if (v == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring outdated local statistics collection response from node %s to req %s\",\n+                            nodeId, msg.reqId()));\n+\n+                return null;\n+            }\n+\n+            assert msg.reqId().equals(v.reqId);\n+\n+            boolean rmv = v.remainingNodes.remove(nodeId);\n+            if (!rmv) {\n+                log.warning(String.format(\"Ignoring statistics propagation message from unexpected node %s by request %s.\",\n+                        nodeId, v.reqId));\n+\n+                return v;\n+            }\n+\n+            v.locStatistics.add(msg);\n+\n+            if (v.remainingNodes.isEmpty()) {\n+                aggregateCollected(v);\n+\n+                return null;\n+            }\n+\n+            return v;\n+        });**/\n+    }\n+\n+    /**\n+     * Send statistics by request.\n+     *\n+     * @param nodeId Node to send statistics to.\n+     * @param msg Statistics request to process.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void supplyStatistics(UUID nodeId, StatsGetRequest msg) throws IgniteCheckedException {\n+        List<StatsObjectData> data = new ArrayList<>(msg.keys().size());\n+        for (StatsKeyMessage keyMsg : msg.keys()) {\n+            StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+            ObjectStatisticsImpl objStats = statsRepos.getGlobalStatistics(key);\n+\n+            if (objStats != null)\n+                data.add(StatisticsUtils.toObjectData(keyMsg, StatsType.GLOBAL, objStats));\n+        }\n+        StatsPropagationMessage res = new StatsPropagationMessage(data);\n+        ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n+\n+        /**List<StatsObjectData> data = new ArrayList<>();\n+        for (StatsKeyMessage key : msg.keys()) {\n+            StatsKey statsKey = new StatsKey(key.schema(), key.obj());\n+            ObjectStatisticsImpl objStats = statsRepos.getGlobalStatistics(statsKey);\n+\n+            if (objStats != null)\n+                data.add(StatisticsUtils.toMessage(statsKey, StatsType.GLOBAL, objStats));\n+        }\n+\n+        StatsPropagationMessage res = new StatsPropagationMessage(msg.reqId(), data);\n+        ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);**/\n+    }\n+\n+    private void cancelStatisticsCollection(UUID nodeId, CancelStatsCollectionRequest msg) {\n+        currCollections.updateCollection(msg.colId(), stat -> {\n+            stat.doneFut().cancel();\n+            return null;\n+        });\n+        /*StatCollectionStatus currState = currCollections.remove(msg.reqId());\n+        if (currState != null) {\n+            if (log.isDebugEnabled())\n+                log.debug(String.format(\"Cancelling statistics collection by reqId = %s from node %s\", msg.reqId(),\n+                        nodeId));\n+\n+            currState.doneFut().cancel();\n+        } else\n+        if (log.isDebugEnabled())\n+            log.debug(String.format(\"Unable to cancel staitstics collection by req = %s from node %s\", msg.reqId(),\n+                    nodeId));*/\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void onMessage(UUID nodeId, Object msg, byte plc) {\n+        try {\n+            if (msg instanceof StatsPropagationMessage)\n+                receivePartitionsStatistics(nodeId, (StatsPropagationMessage) msg);\n+            else if (msg instanceof StatsCollectionResponse)\n+                receiveLocalStatistics(nodeId, (StatsCollectionResponse) msg);\n+            else if (msg instanceof StatsGetRequest)", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3NjI2Ng==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545476266", "bodyText": "Moreover Statistics processor can be started on client node, but it could process only StatGet responses while other messages are not relevant for client node, right?", "author": "AMashenkov", "createdAt": "2020-12-17T23:38:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3NTUxMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTc2OTg0MQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545769841", "bodyText": "I'm not sure about it, we can run statistics collection from client node and so StatisticsManager will handle most of it's messages even on client. But then we should send aggregated statistics back to some server node.", "author": "Berkof", "createdAt": "2020-12-18T11:23:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3NTUxMQ=="}], "type": "inlineReview", "revised_code": {"commit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex ca50e8e339b..f208a744d01 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -379,537 +222,253 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n             String objName,\n             String... colNames\n     ) throws IgniteCheckedException {\n-        StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n-        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n-        UUID colId = UUID.randomUUID();\n-        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.singletonList(keyMsg),\n-            Collections.emptyMap(), doneFut);\n-        synchronized (status) {\n-            currCollections.updateCollection(colId, s -> status);\n-            Map<StatsKeyMessage, int[]> failedPartitions = null;\n-            int cnt = 0;\n-            do {\n-                Collection<StatsCollectionAddrRequest> reqs = currCollections.generateCollectionRequests(colId,\n-                    Collections.singletonList(keyMsg), failedPartitions);\n-                Map<UUID, StatsCollectionRequest> msgs = reqs.stream().collect(Collectors.toMap(\n-                    StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req));\n-\n-                Map<UUID, StatsCollectionRequest> failedMsgs = sendLocalRequests(msgs);\n-                failedPartitions = currCollections.extractFailed(failedMsgs.values()\n-                    .toArray(new StatsCollectionRequest[0]));\n-                if (cnt++ > 10)\n-                    throw new IgniteCheckedException(String.format(\n-                            \"Unable to send all messages to collect statistics by key %s.%s\", schemaName, objName));\n-            }\n-            while (!failedPartitions.isEmpty());\n-        }\n-        UUID locNode = ctx.discovery().localNode().id();\n-        StatsCollectionAddrRequest locReq = status.remainingCollectionReqs().get(locNode);\n-        statMgmtPool.submit(() -> processLocal(ctx.discovery().localNode().id(), locReq.req()));\n-        /*final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter();\n-\n-        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n-        UUID colId = UUID.randomUUID();\n-        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.emptyMap(), doneFut);\n-\n-        synchronized (status) {\n-            currCollections.put(colId, status);\n-            if (!doRequests(status, Collections.singletonList(keyMsg))) {\n-                status.doneFut().cancel();\n-                currCollections.remove(colId);\n-                throw new IgniteCheckedException(\"Unable to send statistics collection messages to all necessary nodes\");\n-            }\n-        }\n-        UUID locNode = ctx.discovery().localNode().id();\n-        StatsCollectionAddrRequest locReq = status.remainingCollectionReqs().get(locNode);\n-        if (locReq != null)\n-            statMgmtPool.submit(() -> processLocal(locNode, locReq.req()));\n-\n-        doneFut.get();\n-        */\n-\n-//\n-//        StatsKey key = new StatsKey(schemaName, objName);\n-//\n-//        List<CacheGroupContext> grpContexts = extractGroups(Collections.singletonList(key));\n-//\n-//        assert grpContexts.size() == 1;\n-//\n-//        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n-//        Map<UUID, List<Integer>> reqNodes = nodePartitions(grpContexts.get(0), null);\n-//        Map<UUID, StatsCollectionAddrRequest> reqs = prepareRequests(colId, keyMsg, reqNodes);\n-//\n-//        synchronized (status) {\n-//            currCollections.put(colId, status);\n-//\n-//            Map<UUID, StatsCollectionRequest> failedReqs = sendLocalRequests(reqs.values().stream().collect(\n-//                    Collectors.toMap(StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req)));\n-//\n-//            if (failedReqs != null) {\n-//                for (UUID failedReqId : failedReqs.keySet())\n-//                    status.remainingCollectionReqs().remove(failedReqId);\n-//\n-//                Map<StatsKeyMessage,List<Integer>> failedPartIds = extractFailed(failedReqs.values());\n-//\n-//                assert failedPartIds.size() == 1;\n-//\n-//                List<Integer> newPartIds = failedPartIds.get(keyMsg);\n-//\n-//                assert newPartIds != null;\n-//\n-//                Map<UUID, List<Integer>> newReqNodes = nodePartitions(grpContexts.get(0), newPartIds);\n-//                Map<UUID, StatsCollectionAddrRequest> newReqs = prepareRequests(colId, keyMsg, newReqNodes);\n-//                Map<UUID, StatsCollectionRequest> newFailedReqs = sendLocalRequests(newReqs.values().stream().collect(\n-//                        Collectors.toMap(StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req)));\n-//                if (newFailedReqs != null) {\n-//                    doneFut.cancel();\n-//\n-//                    // TODO: is it safe?\n-//                    currCollections.remove(colId);\n-//\n-//                    throw new IgniteCheckedException(String.format(\n-//                            \"Unable to send statistics collection request to %d nodes. Cancelling collection %s\",\n-//                            newFailedReqs.size(), colId));\n-//                }\n-//                status.remainingCollectionReqs().putAll(newReqs);\n-//\n-//                failedReqs.values().stream().forEach(req -> req.keys().values().forEach(failedPartIds.addAll()));\n-//                rescheduleFailedPartitions(colId, Collections.singletonMap(keyMsg, ));\n-//            }\n-//            UUID locNode = ctx.discovery().localNode().id();\n-//            StatsCollectionAddrRequest locReq = reqs.get(locNode);\n-//            if (locReq != null)\n-//                statMgmtPool.submit(() -> processLocal(locNode, locReq.req()));\n-//\n-//        }\n-//\n-//        doneFut.get();\n+        StatisticsKeyMessage keyMsg = new StatisticsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        StatisticsGatheringContext status = new StatisticsGatheringContext(Collections.singleton(keyMsg));\n+        currColls.put(status.gatId(), status);\n+        collectObjectStatistics(status);\n+\n+        status.doneFut().get();\n     }\n \n     /**\n-     * Generate and try to send all request for particular status. Should be called inside status lock after putting it\n-     * into currCollections map. REMOVE!!!!\n+     * Ensure that local gathering context exists and schedule local statistics gathering.\n      *\n-     * @param status Status to process.\n-     * @param keys Collection of object keys to collect statistics by.\n-     * @return {@code true} if all request was successfully sended, {@code false} - otherwise (one should remove\n-     * status from cullCollections.\n+     * @param nodeId Initiator node id.\n+     * @param gatId Gathering id.\n+     * @param reqId Request id.\n+     * @param keys Keys to collect statistics by.\n      */\n-    protected boolean doRequests(StatCollectionStatus status, List<StatsKeyMessage> keys) throws IgniteCheckedException {\n-        /*Map<CacheGroupContext, Collection<StatsKeyMessage>> grpContexts = extractGroups(keys);\n-        List<Map<UUID, StatsCollectionAddrRequest>> reqsByGrps = new ArrayList<>(grpContexts.size());\n-        for (Map.Entry<CacheGroupContext, Collection<StatsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n-            Map<UUID, List<Integer>> reqNodes = nodePartitions(grpEntry.getKey(), null);\n-            for(StatsKeyMessage keyMsg : grpEntry.getValue())\n-                reqsByGrps.add(prepareRequests(status.colId(), keyMsg, reqNodes));\n-\n-        }\n-        Map<UUID, StatsCollectionAddrRequest> reqs = compressRequests(reqsByGrps);\n-\n-        status.remainingCollectionReqs().putAll(reqs);\n+    public void gatherLocalObjectStatisticsAsync(UUID gatId, UUID reqId, Map<StatisticsKeyMessage, int[]> keys) {\n+        StatisticsGatheringContext[] ctxs = new StatisticsGatheringContext[1];\n+        currColls.compute(gatId, (k, v) -> {\n+            if (v == null)\n+                v = new StatisticsGatheringContext(gatId, keys.keySet());\n \n-        Map<UUID, StatsCollectionRequest> failedReqs = sendLocalRequests(reqs.values().stream().collect(\n-                Collectors.toMap(StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req)));\n-        // TODO: cycle replanning and sending\n-        return failedReqs.isEmpty();\n+            ctxs[0] = v;\n \n-         */\n-        return false;\n-    }\n+            return v;\n+        });\n \n-    /**\n-     * Group request by target node id. REMOVE!!!!\n-     *\n-     * @param reqsByGrps Requests to compress, map.\n-     * @return Grouped requests.\n-     */\n-    protected Map<UUID, StatsCollectionAddrRequest> compressRequests(List<Map<UUID, StatsCollectionAddrRequest>> reqsByGrps) {\n-        // NodeId to base request map\n-        Map<UUID, StatsCollectionAddrRequest> reqByNode = new HashMap<>();\n-        for (Map<UUID, StatsCollectionAddrRequest> grpReqs : reqsByGrps)\n-            for (StatsCollectionAddrRequest addReq : grpReqs.values())\n-                reqByNode.compute(addReq.nodeId(), (k, v) -> (v == null) ? addReq : addKey(v, addReq));\n-\n-        return reqByNode.entrySet().stream().collect(Collectors.toMap(e -> e.getValue().req().reqId(),\n-            Map.Entry::getValue));\n+        statGathering.collectLocalObjectStatisticsAsync(reqId, keys);\n     }\n \n-    /**\n-     * Add keys from add request to the base one and return it.\n-     *\n-     * @param base Base request to add to.\n-     * @param add Add request to add.\n-     * @return Request with all keys from both specified.\n-     */\n-    protected StatsCollectionAddrRequest addKey(StatsCollectionAddrRequest base, StatsCollectionAddrRequest add) {\n-        assert base.nodeId().equals(add.nodeId());\n+    /** {@inheritDoc} */\n+    @Override public StatsCollectionFuture<Map<GridTuple3<String, String, String[]>, ObjectStatistics>>\n+    collectObjectStatisticsAsync(\n+        GridTuple3<String, String, String[]>... keys\n+    ) throws IgniteCheckedException {\n+        Set<StatisticsKeyMessage> keysMsg = Arrays.stream(keys).map(\n+                k -> new StatisticsKeyMessage(k.get1(), k.get2(), Arrays.asList(k.get3()))).collect(Collectors.toSet());\n \n-        base.req().keys().putAll(add.req().keys());\n-        return base;\n-    }\n+        StatisticsGatheringContext status = new StatisticsGatheringContext(keysMsg);\n \n+        collectObjectStatistics(status);\n \n-    /**\n-     * Prepare statistics collection request for each nodes. MOVED!!!!\n-     *\n-     * @param colId Collection id.\n-     * @param keyMsg Key to collect statistics by.\n-     * @param reqNodes Map of node id to array of partition ids to be collected on that node.\n-     * @return Map: request id to statistics collection addressed request.\n-     */\n-    protected Map<UUID, StatsCollectionAddrRequest> _____prepareRequests(\n-            UUID colId,\n-            StatsKeyMessage keyMsg,\n-            Map<UUID, List<Integer>> reqNodes\n-    ) {\n-        Map<UUID, StatsCollectionAddrRequest> res = new HashMap<>(reqNodes.size());\n-        for (Map.Entry<UUID, List<Integer>> reqNode : reqNodes.entrySet()) {\n-            UUID reqId = UUID.randomUUID();\n-            StatsCollectionRequest colReq = new StatsCollectionRequest(colId, reqId, Collections.singletonMap(keyMsg,\n-                    reqNode.getValue().stream().mapToInt(Integer::intValue).toArray()));\n-            StatsCollectionAddrRequest addrReq = new StatsCollectionAddrRequest(colReq, reqNode.getKey());\n-            res.put(reqId, addrReq);\n-        }\n-        return res;\n+        return status.doneFut();\n     }\n \n     /**\n-     * TODO\n+     * Cancel specified statistics gathering process.\n+     *\n+     * @param gatId Gathering id to cancel.\n      */\n-    public void stop() {\n-        if (statMgmtPool != null) {\n-            List<Runnable> unfinishedTasks = statMgmtPool.shutdownNow();\n-            if (!unfinishedTasks.isEmpty())\n-                log.warning(String.format(\"%d statistics collection request cancelled.\", unfinishedTasks.size()));\n-        }\n+    public void cancelLocalStatisticsGathering(UUID gatId){\n+       StatisticsGatheringContext ctx = currColls.remove(gatId);\n+       if (ctx != null)\n+           ctx.doneFut().cancel();\n     }\n \n-    /**\n-     * Collect partition level statistics.\n-     *\n-     * @param tbl Table to collect statistics by.\n-     * @param partIds Array of partition ids to collect statistics by.\n-     * @param selectedCols Columns to collect statistics by.\n-     * @param cancelled Supplier to check if collection was cancelled.\n-     * @return Collection of partition level statistics by local primary partitions.\n-     * @throws IgniteCheckedException in case of error.\n-     */\n-    private Collection<ObjectPartitionStatisticsImpl> collectPartitionStatistics(\n-            GridH2Table tbl,\n-            int[] partIds,\n-            Column[] selectedCols,\n-            Supplier<Boolean> cancelled\n-    ) throws IgniteCheckedException {\n-        List<ObjectPartitionStatisticsImpl> tblPartStats = new ArrayList<>();\n-        GridH2RowDescriptor desc = tbl.rowDescriptor();\n-        String tblName = tbl.getName();\n-        GridDhtPartitionTopology topology = tbl.cacheContext().topology();\n-        AffinityTopologyVersion topologyVersion = topology.readyTopologyVersion();\n-\n-        for (int partId : partIds) {\n-            GridDhtLocalPartition locPart = topology.localPartition(partId, topologyVersion, false);\n-            if (locPart == null)\n-                continue;\n+    /** {@inheritDoc} */\n+    @Override public boolean cancelObjectStatisticsGathering(UUID colId) {\n+        boolean[] res = new boolean[]{true};\n \n-            if (cancelled.get()) {\n-                if (log.isInfoEnabled())\n-                    log.info(String.format(\"Canceled collection of object %s.%s statistics.\", tbl.identifier().schema(),\n-                            tbl.identifier().table()));\n+        helper.updateCollection(colId, s -> {\n+            if (s == null) {\n+                res[0] = false;\n \n                 return null;\n             }\n \n-            final boolean reserved = locPart.reserve();\n-\n-            try {\n-                if (!reserved || (locPart.state() != OWNING && locPart.state() != MOVING)\n-                        || !locPart.primary(ctx.discovery().topologyVersionEx()))\n-                    continue;\n-\n-                if (locPart.state() == MOVING)\n-                    tbl.cacheContext().preloader().syncFuture().get();\n-\n-                long rowsCnt = 0;\n-\n-                List<ColumnStatisticsCollector> colStatsCollectors = new ArrayList<>(selectedCols.length);\n+            s.doneFut().cancel();\n \n-                for (Column col : selectedCols)\n-                    colStatsCollectors.add(new ColumnStatisticsCollector(col, tbl::compareValues));\n+            Map<UUID, List<UUID>> nodeRequests = new HashMap<>();\n+            for (StatisticsAddrRequest<StatisticsGatheringRequest> req : s.remainingCollectionReqs().values()) {\n+                nodeRequests.compute(req.nodeId(), (k, v) -> {\n+                   if (v == null)\n+                       v = new ArrayList<>();\n+                   v.add(req.req().reqId());\n \n-                for (CacheDataRow row : tbl.cacheContext().offheap().cachePartitionIterator(tbl.cacheId(), locPart.id(),\n-                        null, true)) {\n-                    GridQueryTypeDescriptor typeDesc = ctx.query().typeByValue(tbl.cacheName(),\n-                            tbl.cacheContext().cacheObjectContext(), row.key(), row.value(), false);\n-                    if (!tblName.equals(typeDesc.tableName()))\n-                        continue;\n-\n-                    rowsCnt++;\n-\n-                    H2Row row0 = desc.createRow(row);\n-\n-                    for (ColumnStatisticsCollector colStat : colStatsCollectors)\n-                        colStat.add(row0.getValue(colStat.col().getColumnId()));\n-\n-                }\n-\n-                Map<String, ColumnStatistics> colStats = colStatsCollectors.stream().collect(Collectors.toMap(\n-                        csc -> csc.col().getName(), csc -> csc.finish()\n-                ));\n+                   return v;\n+                });\n+            }\n \n-                tblPartStats.add(new ObjectPartitionStatisticsImpl(locPart.id(), true, rowsCnt,\n-                        locPart.updateCounter(), colStats));\n+            Collection<StatisticsAddrRequest<CancelStatisticsGatheringRequest>> cancelReqs = nodeRequests.entrySet().stream().map(\n+                        targetNode -> new StatisticsAddrRequest<>(\n+                            new CancelStatisticsGatheringRequest(colId, targetNode.getValue().toArray(new UUID[0])),\n+                            targetNode.getKey()))\n+                    .collect(Collectors.toList());\n \n-                if (log.isTraceEnabled())\n-                    log.trace(String.format(\"Finished statistics collection on %s.%s:%d\",\n-                            tbl.identifier().schema(), tbl.identifier().table(), locPart.id()));\n-            }\n-            finally {\n-                if (reserved)\n-                    locPart.release();\n-            }\n-        }\n+            Collection<StatisticsAddrRequest<CancelStatisticsGatheringRequest>> failed = sendRequests(cancelReqs);\n+            if (!F.isEmpty(failed))\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Unable to cancel all statistics collections requests (%d failed) by colId %s\",\n+                            failed.size(), colId));\n \n-        return tblPartStats;\n-    }\n+            return null;\n+        });\n \n-    /**\n-     * Aggregate specified partition level statistics to local level statistics.\n-     *\n-     * @param key Aggregation key.\n-     * @param tblPartStats Collection of all local partition level statistics by specified key.\n-     * @return Local level aggregated statistics.\n-     */\n-    public ObjectStatisticsImpl aggregateLocalStatistics(\n-            StatsKey key,\n-            Collection<ObjectPartitionStatisticsImpl> tblPartStats\n-    ) {\n-        // For now there can be only tables\n-        GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n-\n-        if (tbl == null) {\n-            // remove all loaded statistics.\n-            if (log.isDebugEnabled())\n-                log.debug(String.format(\"Removing statistics for object %s.%s cause table doesn't exists.\",\n-                        key.schema(), key.obj()));\n-\n-            statsRepos.clearLocalPartitionsStatistics(key);\n-        }\n-        return aggregateLocalStatistics(tbl, tbl.getColumns(), tblPartStats);\n+        return res[0];\n     }\n \n     /**\n-     * Aggregate partition level statistics to local level one.\n-     *\n-     * @param tbl Table to aggregate statistics by.\n-     * @param selectedCols Columns to aggregate statistics by.\n-     * @param tblPartStats Collection of partition level statistics.\n-     * @return Local level statistics.\n+     * Stop statistics manager.\n      */\n-    private ObjectStatisticsImpl aggregateLocalStatistics(\n-            GridH2Table tbl,\n-            Column[] selectedCols,\n-            Collection<ObjectPartitionStatisticsImpl> tblPartStats\n-    ) {\n-        Map<Column, List<ColumnStatistics>> colPartStats = new HashMap<>(selectedCols.length);\n-        long rowCnt = 0;\n-        for (Column col : selectedCols)\n-            colPartStats.put(col, new ArrayList<>());\n-\n-        for (ObjectPartitionStatisticsImpl partStat : tblPartStats) {\n-            for (Column col : selectedCols) {\n-                ColumnStatistics colPartStat = partStat.columnStatistics(col.getName());\n-                if (colPartStat != null) {\n-                    colPartStats.computeIfPresent(col, (k, v) -> {\n-                        v.add(colPartStat);\n-\n-                        return v;\n-                    });\n-                }\n-            }\n-            rowCnt += partStat.rowCount();\n-        }\n-\n-        Map<String, ColumnStatistics> colStats = new HashMap<>(selectedCols.length);\n-        for (Column col : selectedCols) {\n-            ColumnStatistics stat = ColumnStatisticsCollector.aggregate(tbl::compareValues, colPartStats.get(col));\n-            colStats.put(col.getName(), stat);\n+    public void stop() {\n+        if (statMgmtPool != null) {\n+            List<Runnable> unfinishedTasks = statMgmtPool.shutdownNow();\n+            if (!unfinishedTasks.isEmpty())\n+                log.warning(String.format(\"%d statistics collection request cancelled.\", unfinishedTasks.size()));\n         }\n-\n-        ObjectStatisticsImpl tblStats = new ObjectStatisticsImpl(rowCnt, colStats);\n-\n-        return tblStats;\n     }\n \n     /**\n-     * Receive and handle statistics propagation message with partitions statistics.\n+     * Receive and store partition statistics object data for locals backup partition.\n      *\n-     * @param nodeId Sender node id.\n-     * @param msg Statistics propagation message with partitions statistics to handle.\n-     * @throws IgniteCheckedException In case of errors.\n+     * @param data Collection of partition level statistics of local bacup partitions.\n      */\n-    private void receivePartitionsStatistics(UUID nodeId, StatsPropagationMessage msg) throws IgniteCheckedException {\n-        UUID locNode = ctx.discovery().localNode().id();\n-        for (StatsObjectData partData : msg.data()) {\n-            StatsKey key = new StatsKey(partData.key().schema(), partData.key().obj());\n+    public void receivePartitionsStatistics(Collection<StatisticsObjectData> data) {\n+        for (StatisticsObjectData partData : data) {\n+            StatisticsKey key = new StatisticsKey(partData.key().schema(), partData.key().obj());\n \n-            assert partData.type() == StatsType.PARTITION : \"Got non partition level statistics by \" + key\n+            assert partData.type() == StatisticsType.PARTITION : \"Got non partition level statistics by \" + key\n                     + \" without request\";\n \n             if (log.isTraceEnabled())\n-                log.trace(String.format(\"Received partition statistics %s.%s:%d from node %s\", key.schema(),\n-                        key.obj(), partData.partId(), nodeId));\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d\", key.schema(), key.obj(),\n+                    partData.partId()));\n \n             GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n             if (tbl == null) {\n                 if (log.isInfoEnabled())\n-                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d from node %s\",\n-                            key.schema(), key.obj(), partData.partId(), nodeId));\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d\", key.schema(), key.obj(),\n+                        partData.partId()));\n \n                 continue;\n             }\n-            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(locNode, partData.partId());\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(ctx.localNodeId(), partData.partId());\n             if (partState != OWNING) {\n                 if (log.isInfoEnabled())\n-                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d from node %s\",\n-                            key.schema(), key.obj(), partData.partId(), nodeId));\n+                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d\",\n+                            key.schema(), key.obj(), partData.partId()));\n \n                 continue;\n             }\n \n-            ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n+            try {\n+                ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n \n-            statsRepos.saveLocalPartitionStatistics(key, opStat);\n+                statsRepos.saveLocalPartitionStatistics(key, opStat);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Unable to parse partition statistics for %s.%s:%d because of: %s\",\n+                        key.schema(), key.obj(), partData.partId(), e.getMessage()));\n+            }\n         }\n     }\n \n     /**\n-     * Receive and handle statistics propagation message as response for collection request.\n-     *\n-     * @param nodeId Sender node id.\n-     * @param msg Statistics propagation message with partitions statistics to handle.\n-     * @throws IgniteCheckedException In case of errors.\n+     * Aggregate specified gathered statistics, remove it form local and complete its future.\n+     * @param gatId Gathering to complete.\n      */\n-    private void receiveLocalStatistics(UUID nodeId, StatsCollectionResponse msg) {\n-        assert msg.data().keySet().stream().noneMatch(pd -> pd.type() == StatsType.PARTITION)\n-                : \"Got partition statistics by request \" + msg.reqId();\n-\n-        /**currCollections.compute(msg.reqId(), (k, v) -> {\n-            if (v == null) {\n-                if (log.isInfoEnabled())\n-                    log.info(String.format(\"Ignoring outdated local statistics collection response from node %s to req %s\",\n-                            nodeId, msg.reqId()));\n-\n-                return null;\n-            }\n-\n-            assert msg.reqId().equals(v.reqId);\n-\n-            boolean rmv = v.remainingNodes.remove(nodeId);\n-            if (!rmv) {\n-                log.warning(String.format(\"Ignoring statistics propagation message from unexpected node %s by request %s.\",\n-                        nodeId, v.reqId));\n-\n-                return v;\n-            }\n-\n-            v.locStatistics.add(msg);\n+    public void finishStatisticsCollection(UUID gatId) {\n+        StatisticsGatheringContext ctx = currColls.remove(gatId);\n+        if (ctx == null)\n+            return;\n \n-            if (v.remainingNodes.isEmpty()) {\n-                aggregateCollected(v);\n+        Map<StatisticsKeyMessage, ObjectStatisticsImpl> keysStats = new HashMap<>();\n+        for(Map.Entry<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : ctx.localStatistics().e\n \n-                return null;\n-            }\n+    }\n \n-            return v;\n-        });**/\n+    public void registerLocalResult(UUID gatId, Collection<StatisticsObjectData> data) {\n+        StatisticsGatheringContext ctx = currColls.get(gatId);\n+        if (ctx == null) {\n+            // TODO: log\n+            return;\n+        }\n+        ctx.registerCollected(data);\n     }\n \n     /**\n-     * Send statistics by request.\n+     * Aggregate local statistics to global one.\n      *\n-     * @param nodeId Node to send statistics to.\n-     * @param msg Statistics request to process.\n-     * @throws IgniteCheckedException In case of errors.\n+     * @param stat Statistics collection status to aggregate.\n+     * @return Map stats key to merged global statistics.\n      */\n-    private void supplyStatistics(UUID nodeId, StatsGetRequest msg) throws IgniteCheckedException {\n-        List<StatsObjectData> data = new ArrayList<>(msg.keys().size());\n-        for (StatsKeyMessage keyMsg : msg.keys()) {\n-            StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n-            ObjectStatisticsImpl objStats = statsRepos.getGlobalStatistics(key);\n-\n-            if (objStats != null)\n-                data.add(StatisticsUtils.toObjectData(keyMsg, StatsType.GLOBAL, objStats));\n-        }\n-        StatsPropagationMessage res = new StatsPropagationMessage(data);\n-        ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n+    private Map<StatisticsKey, ObjectStatisticsImpl> finishStatCollection(StatisticsGatheringContext stat) {\n+        Map<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keysStats = new HashMap<>();\n+        for (StatisticsGatheringResponse resp : stat.localStatistics()) {\n+            for (StatisticsObjectData objData : resp.data().keySet()) {\n+                keysStats.compute(objData.key(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+                    try {\n+                        ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n \n-        /**List<StatsObjectData> data = new ArrayList<>();\n-        for (StatsKeyMessage key : msg.keys()) {\n-            StatsKey statsKey = new StatsKey(key.schema(), key.obj());\n-            ObjectStatisticsImpl objStats = statsRepos.getGlobalStatistics(statsKey);\n+                        v.add(objStat);\n+                    } catch (IgniteCheckedException e) {\n+                        if (log.isInfoEnabled())\n+                            log.info(String.format(\"Unable to parse statistics for object %s from response %s\",\n+                                    objData.key(), resp.reqId()));\n+                    }\n \n-            if (objStats != null)\n-                data.add(StatisticsUtils.toMessage(statsKey, StatsType.GLOBAL, objStats));\n+                    return v;\n+                });\n+            }\n         }\n \n-        StatsPropagationMessage res = new StatsPropagationMessage(msg.reqId(), data);\n-        ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);**/\n-    }\n-\n-    private void cancelStatisticsCollection(UUID nodeId, CancelStatsCollectionRequest msg) {\n-        currCollections.updateCollection(msg.colId(), stat -> {\n-            stat.doneFut().cancel();\n-            return null;\n-        });\n-        /*StatCollectionStatus currState = currCollections.remove(msg.reqId());\n-        if (currState != null) {\n-            if (log.isDebugEnabled())\n-                log.debug(String.format(\"Cancelling statistics collection by reqId = %s from node %s\", msg.reqId(),\n-                        nodeId));\n-\n-            currState.doneFut().cancel();\n-        } else\n-        if (log.isDebugEnabled())\n-            log.debug(String.format(\"Unable to cancel staitstics collection by req = %s from node %s\", msg.reqId(),\n-                    nodeId));*/\n-    }\n+        Map<StatisticsKey, ObjectStatisticsImpl> res = new HashMap<>();\n+        for (Map.Entry<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : keysStats.entrySet()) {\n+            StatisticsKeyMessage keyMsg = keyStats.getKey();\n+            GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Unable to find object %s.%s to save collected statistics by.\",\n+                            keyMsg.schema(), keyMsg.obj()));\n \n-    /** {@inheritDoc} */\n-    @Override public void onMessage(UUID nodeId, Object msg, byte plc) {\n-        try {\n-            if (msg instanceof StatsPropagationMessage)\n-                receivePartitionsStatistics(nodeId, (StatsPropagationMessage) msg);\n-            else if (msg instanceof StatsCollectionResponse)\n-                receiveLocalStatistics(nodeId, (StatsCollectionResponse) msg);\n-            else if (msg instanceof StatsGetRequest)\n-                supplyStatistics(nodeId, (StatsGetRequest) msg);\n-            else if (msg instanceof StatsCollectionRequest)\n-                handleCollectionRequest(nodeId, (StatsCollectionRequest)msg);\n-            else if (msg instanceof CancelStatsCollectionRequest)\n-                cancelStatisticsCollection(nodeId, (CancelStatsCollectionRequest) msg);\n-            else if (msg instanceof StatsClearRequest)\n-                clearObjectStatistics(nodeId, (StatsClearRequest)msg);\n-            else\n-                log.warning(\"Unknown msg \" + msg +  \" in statistics topic \" + TOPIC + \" from node \" + nodeId);\n-        } catch (IgniteCheckedException e) {\n-            log.warning(\"Statistic msg from node \" + nodeId + \" processing failed\", e);\n+                continue;\n+            }\n+            ObjectStatisticsImpl globalStat = aggregateLocalStatistics(keyMsg, keyStats.getValue());\n+            StatisticsKey key = new StatisticsKey(keyMsg.schema(), keyMsg.obj());\n+            res.put(key, statsRepos.mergeGlobalStatistics(key, globalStat));\n         }\n+        return res;\n     }\n \n     /**\n-     * Handle statistics clear request.\n+     * Get global statistics by key.\n      *\n-     * @param nodeId UUID of request sender node.\n-     * @param msg Clear request message.\n+     * @param key Key to get statistics by.\n+     * @return Global statistics or {@code null} if there are no statistics for specified key.\n      */\n-    private void clearObjectStatistics(UUID nodeId, StatsClearRequest msg) {\n-        for (StatsKeyMessage key : msg.keys()) {\n-            if (log.isTraceEnabled())\n-                log.trace(String.format(\"Clearing statistics by request %s from node %s by key %s.%s\", msg.reqId(),\n-                        nodeId, key.schema(), key.obj()));\n-            statMgmtPool.submit(() -> clearObjectStatisticsLocal(key));\n-        }\n-    }\n+   public ObjectStatisticsImpl getGlobalStatistics(StatisticsKeyMessage key) {\n+        ObjectStatisticsImpl stat = statsRepos.getGlobalStatistics(new StatisticsKey(key.schema(), key.obj()));\n+        if (stat != null && !F.isEmpty(key.colNames()))\n+            stat = IgniteStatisticsHelper.filterColumns(stat, key.colNames());\n+\n+        return stat;\n+   }\n+\n+    /**\n+     * Clear object statistics by specified keys.\n+     *\n+     * @param keys Collection of keys to clean statistics by.\n+     */\n+   public void clearObjectStatisticsLocal(Collection<StatisticsKeyMessage> keys) {\n+       for (StatisticsKeyMessage key : keys)\n+           clearObjectStatisticsLocal(key);\n+   }\n \n     /**\n      * Collect local object statistics by specified request (possibly for a few objects) and send result back to origin\n", "next_change": {"commit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex f208a744d01..1f98ad5ca73 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -476,7 +514,7 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n      *\n      * @param req request to collect statistics by.\n      */\n-    private void processLocal(UUID nodeId, StatisticsGatheringRequest req) {\n+    /*private void processLocal(UUID nodeId, StatisticsGatheringRequest req) {\n         UUID locNode = ctx.localNodeId();\n \n         StatisticsGatheringContext stat = (nodeId.equals(locNode)) ? helper.getCollection(req.gatId()) :\n", "next_change": {"commit": "e54c934091d0917505fbe4bd919fd766a492897e", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 1f98ad5ca73..c989b5605e7 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -507,59 +487,4 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n        for (StatisticsKeyMessage key : keys)\n            clearObjectStatisticsLocal(key);\n    }\n-\n-    /**\n-     * Collect local object statistics by specified request (possibly for a few objects) and send result back to origin\n-     * node specified. If local node id specified - process result without sending it throw the communication.\n-     *\n-     * @param req request to collect statistics by.\n-     */\n-    /*private void processLocal(UUID nodeId, StatisticsGatheringRequest req) {\n-        UUID locNode = ctx.localNodeId();\n-\n-        StatisticsGatheringContext stat = (nodeId.equals(locNode)) ? helper.getCollection(req.gatId()) :\n-            helper.getCollection(req.reqId());\n-\n-        if (stat == null)\n-            return;\n-\n-        Map<StatisticsObjectData, int[]> collected = new HashMap<>(req.keys().size());\n-        for (Map.Entry<StatisticsKeyMessage, int[]> keyEntry : req.keys().entrySet()) {\n-            try {\n-                StatisticsKeyMessage key = keyEntry.getKey();\n-                IgniteBiTuple <ObjectStatisticsImpl, int[]> loStat = gatherLocalObjectStatisticsAsync(key,\n-                        keyEntry.getValue(), () -> stat.doneFut().isCancelled());\n-                StatisticsKey statsKey = new StatisticsKey(key.schema(), key.obj());\n-\n-                // TODO?\n-                statsRepos.mergeLocalStatistics(statsKey, loStat.getKey());\n-\n-                StatisticsObjectData objData = StatisticsUtils.toObjectData(key, StatisticsType.LOCAL, loStat.getKey());\n-                collected.put(objData, loStat.getValue());\n-            }\n-            catch (IgniteCheckedException e) {\n-                log.warning(String.format(\"Unable to complete request %s due to error %s\", req.reqId(), e.getMessage()));\n-                // TODO: send cancel to originator node\n-            }\n-        }\n-\n-        StatisticsGatheringResponse res = new StatisticsGatheringResponse(req.gatId(), req.reqId(), collected);\n-\n-        if (locNode.equals(nodeId))\n-            receiveLocalStatistics(nodeId, res);\n-        else {\n-            try {\n-                ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n-            }\n-            catch (IgniteCheckedException e) {\n-                if (log.isDebugEnabled())\n-                    log.debug(String.format(\n-                            \"Unable to send statistics collection result to node %s in response to colId %s, reqId %s\",\n-                        nodeId, req.gatId(), req.reqId()));\n-            }\n-\n-            // Not local collection - remove by its reqId.\n-            helper.updateCollection(req.reqId(), s -> null);\n-        }\n-    }*/\n }\n", "next_change": {"commit": "33170812024f6c4d321f85287fea0b6c3abdb9e5", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex c989b5605e7..5011b1a87a5 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -478,13 +458,20 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n         return stat;\n    }\n \n+    /** {@inheritDoc} */\n+    @Override public ObjectStatistics getGlobalStatistics(String schemaName, String objName) {\n+        return statsRepos.getGlobalStatistics(new StatisticsKey(schemaName, objName));\n+    }\n+\n     /**\n-     * Clear object statistics by specified keys.\n+     * Check that all server nodes in the cluster support STATISTICS_COLLECTION features.\n      *\n-     * @param keys Collection of keys to clean statistics by.\n+     * @param op Operation name.\n      */\n-   public void clearObjectStatisticsLocal(Collection<StatisticsKeyMessage> keys) {\n-       for (StatisticsKeyMessage key : keys)\n-           clearObjectStatisticsLocal(key);\n+   private void checkSupport(String op) throws IgniteCheckedException {\n+       if (!IgniteFeatures.allNodesSupport(ctx, IgniteFeatures.STATISTICS_COLLECTION, IgniteDiscoverySpi.SRV_NODES)) {\n+           throw new IgniteCheckedException(String.format(\n+               \"Unable to perform %s due to not all server nodes supports STATISTICS_COLLECTION feature.\", op));\n+       }\n    }\n }\n", "next_change": {"commit": "f5aafee54b1036c09d4944ca9bf0254f8bfd2b1e", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 5011b1a87a5..4df3ed6f1e0 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -464,11 +485,13 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n     }\n \n     /**\n-     * Check that all server nodes in the cluster support STATISTICS_COLLECTION features.\n+     * Check that all server nodes in the cluster support STATISTICS_COLLECTION feature. Throws IgniteCheckedException\n+     * in not.\n      *\n      * @param op Operation name.\n+     * @throws IgniteCheckedException If at least one server node doesn't support feature.\n      */\n-   private void checkSupport(String op) throws IgniteCheckedException {\n+   private void checkStatisticsSupport(String op) throws IgniteCheckedException {\n        if (!IgniteFeatures.allNodesSupport(ctx, IgniteFeatures.STATISTICS_COLLECTION, IgniteDiscoverySpi.SRV_NODES)) {\n            throw new IgniteCheckedException(String.format(\n                \"Unable to perform %s due to not all server nodes supports STATISTICS_COLLECTION feature.\", op));\n", "next_change": {"commit": "65caf2d646409c3be32c4d00f762fcdc7ec4ceb0", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 4df3ed6f1e0..47277987f34 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -492,9 +492,18 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n      * @throws IgniteCheckedException If at least one server node doesn't support feature.\n      */\n    private void checkStatisticsSupport(String op) throws IgniteCheckedException {\n-       if (!IgniteFeatures.allNodesSupport(ctx, IgniteFeatures.STATISTICS_COLLECTION, IgniteDiscoverySpi.SRV_NODES)) {\n+       if (!isStatisticsSupport()) {\n            throw new IgniteCheckedException(String.format(\n                \"Unable to perform %s due to not all server nodes supports STATISTICS_COLLECTION feature.\", op));\n        }\n    }\n+\n+    /**\n+     * Test is statistics collection feature are supported by each server node in cluster.\n+     *\n+     * @return {@code true} if all server nodes support STATISTICS_COLLECTION feature, {@code false} - otherwise.\n+     */\n+   private boolean isStatisticsSupport() {\n+       return IgniteFeatures.allNodesSupport(ctx, IgniteFeatures.STATISTICS_COLLECTION, IgniteDiscoverySpi.SRV_NODES);\n+   }\n }\n", "next_change": null}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3NzczOQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545477739", "body": "You can use @IgniteLogger annotation and call kernalContext.resource().inject() from outside.", "bodyText": "You can use @IgniteLogger annotation and call kernalContext.resource().inject() from outside.", "bodyHTML": "<p dir=\"auto\">You can use @IgniteLogger annotation and call kernalContext.resource().inject() from outside.</p>", "author": "AMashenkov", "createdAt": "2020-12-17T23:42:06Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsPersistenceStoreImpl.java", "diffHunk": "@@ -0,0 +1,472 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.processors.cache.persistence.IgniteCacheDatabaseSharedManager;\n+import org.apache.ignite.internal.processors.cache.persistence.metastorage.MetastorageLifecycleListener;\n+import org.apache.ignite.internal.processors.cache.persistence.metastorage.ReadOnlyMetastorage;\n+import org.apache.ignite.internal.processors.cache.persistence.metastorage.ReadWriteMetastorage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.processors.subscription.GridInternalSubscriptionProcessor;\n+\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.BiConsumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Sql statistics storage in metastore.\n+ * Will store all statistics related objects with prefix \"stats.\"\n+ * Store only partition level statistics.\n+ */\n+public class IgniteStatisticsPersistenceStoreImpl implements IgniteStatisticsStore, MetastorageLifecycleListener {\n+    /** In local meta store it store partitions statistics by path: stats.<SCHEMA>.<OBJECT>.<partId> */\n+    private static final String META_SEPARATOR = \".\";\n+\n+    /** Local metastore statistics prefix. */\n+    private static final String META_STAT_PREFIX = \"stats\";\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** Database shared manager. */\n+    private final IgniteCacheDatabaseSharedManager db;\n+\n+    /** Statistics repository. */\n+    private final IgniteStatisticsRepository repo;\n+\n+    /** Metastorage. */\n+    private volatile ReadWriteMetastorage metastore;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param subscriptionProcessor Grid subscription processor to track metastorage availability.\n+     * @param db Database shared manager to lock db while reading/writing metastorage.\n+     * @param repo Repository to fulfill on metastore available.\n+     * @param logSupplier Logger getting function.\n+     */\n+    public IgniteStatisticsPersistenceStoreImpl(\n+            GridInternalSubscriptionProcessor subscriptionProcessor,\n+            IgniteCacheDatabaseSharedManager db,\n+            IgniteStatisticsRepository repo,\n+            Function<Class<?>, IgniteLogger> logSupplier", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTc3MDY1OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545770658", "bodyText": "Will it works for unit tests?", "author": "Berkof", "createdAt": "2020-12-18T11:25:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3NzczOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM2NDY0Nw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549364647", "bodyText": "Sure, see IgniteTestResources and GridAbstractTest.getTestResources()", "author": "AMashenkov", "createdAt": "2020-12-28T14:21:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3NzczOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTU5NjU2OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r559596568", "bodyText": "I'll fix it in next statistics related PR", "author": "Berkof", "createdAt": "2021-01-18T14:17:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3NzczOQ=="}], "type": "inlineReview", "revised_code": {"commit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsPersistenceStoreImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsPersistenceStoreImpl.java\nindex 285136b484c..6e667ec2f41 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsPersistenceStoreImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsPersistenceStoreImpl.java\n", "chunk": "@@ -67,19 +66,15 @@ public class IgniteStatisticsPersistenceStoreImpl implements IgniteStatisticsSto\n      *\n      * @param subscriptionProcessor Grid subscription processor to track metastorage availability.\n      * @param db Database shared manager to lock db while reading/writing metastorage.\n-     * @param repo Repository to fulfill on metastore available.\n      * @param logSupplier Logger getting function.\n      */\n     public IgniteStatisticsPersistenceStoreImpl(\n             GridInternalSubscriptionProcessor subscriptionProcessor,\n             IgniteCacheDatabaseSharedManager db,\n-            IgniteStatisticsRepository repo,\n             Function<Class<?>, IgniteLogger> logSupplier\n     ) {\n         this.db = db;\n-        this.repo = repo;\n         subscriptionProcessor.registerMetastorageListener(this);\n-\n         this.log = logSupplier.apply(IgniteStatisticsPersistenceStoreImpl.class);\n     }\n \n", "next_change": {"commit": "48b736c4cf138d5db12978e2004c446e26e1f097", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsPersistenceStoreImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsPersistenceStoreImpl.java\nindex 6e667ec2f41..51e4dade5ab 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsPersistenceStoreImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsPersistenceStoreImpl.java\n", "chunk": "@@ -66,15 +75,18 @@ public class IgniteStatisticsPersistenceStoreImpl implements IgniteStatisticsSto\n      *\n      * @param subscriptionProcessor Grid subscription processor to track metastorage availability.\n      * @param db Database shared manager to lock db while reading/writing metastorage.\n+     * @param loadHnd Handler to process loaded statistics after start.\n      * @param logSupplier Logger getting function.\n      */\n     public IgniteStatisticsPersistenceStoreImpl(\n             GridInternalSubscriptionProcessor subscriptionProcessor,\n             IgniteCacheDatabaseSharedManager db,\n+            BiConsumer<StatisticsKey, List<ObjectPartitionStatisticsImpl>> loadHnd,\n             Function<Class<?>, IgniteLogger> logSupplier\n     ) {\n         this.db = db;\n         subscriptionProcessor.registerMetastorageListener(this);\n+        this.loadHnd = loadHnd;\n         this.log = logSupplier.apply(IgniteStatisticsPersistenceStoreImpl.class);\n     }\n \n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3OTc1MQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545479751", "body": "Is it ever unregistered?", "bodyText": "Is it ever unregistered?", "bodyHTML": "<p dir=\"auto\">Is it ever unregistered?</p>", "author": "AMashenkov", "createdAt": "2020-12-17T23:47:24Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsPersistenceStoreImpl.java", "diffHunk": "@@ -0,0 +1,472 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.processors.cache.persistence.IgniteCacheDatabaseSharedManager;\n+import org.apache.ignite.internal.processors.cache.persistence.metastorage.MetastorageLifecycleListener;\n+import org.apache.ignite.internal.processors.cache.persistence.metastorage.ReadOnlyMetastorage;\n+import org.apache.ignite.internal.processors.cache.persistence.metastorage.ReadWriteMetastorage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.processors.subscription.GridInternalSubscriptionProcessor;\n+\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.BiConsumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Sql statistics storage in metastore.\n+ * Will store all statistics related objects with prefix \"stats.\"\n+ * Store only partition level statistics.\n+ */\n+public class IgniteStatisticsPersistenceStoreImpl implements IgniteStatisticsStore, MetastorageLifecycleListener {\n+    /** In local meta store it store partitions statistics by path: stats.<SCHEMA>.<OBJECT>.<partId> */\n+    private static final String META_SEPARATOR = \".\";\n+\n+    /** Local metastore statistics prefix. */\n+    private static final String META_STAT_PREFIX = \"stats\";\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** Database shared manager. */\n+    private final IgniteCacheDatabaseSharedManager db;\n+\n+    /** Statistics repository. */\n+    private final IgniteStatisticsRepository repo;\n+\n+    /** Metastorage. */\n+    private volatile ReadWriteMetastorage metastore;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param subscriptionProcessor Grid subscription processor to track metastorage availability.\n+     * @param db Database shared manager to lock db while reading/writing metastorage.\n+     * @param repo Repository to fulfill on metastore available.\n+     * @param logSupplier Logger getting function.\n+     */\n+    public IgniteStatisticsPersistenceStoreImpl(\n+            GridInternalSubscriptionProcessor subscriptionProcessor,\n+            IgniteCacheDatabaseSharedManager db,\n+            IgniteStatisticsRepository repo,\n+            Function<Class<?>, IgniteLogger> logSupplier\n+    ) {\n+        this.db = db;\n+        this.repo = repo;\n+        subscriptionProcessor.registerMetastorageListener(this);", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4MDc1OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545480758", "bodyText": "This statistic store either should have lifecycle methods or should be subscribed from outside?", "author": "AMashenkov", "createdAt": "2020-12-17T23:50:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3OTc1MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTc3MzA1Mg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545773052", "bodyText": "GridInternalSubscriptionProcessor events looks like one-time events and there are no methods like unregisterMetastorageListener at all. Neither have documentation on most of methods.", "author": "Berkof", "createdAt": "2020-12-18T11:30:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3OTc1MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM2NjUzMw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549366533", "bodyText": "Ok, as IgniteStatisticsPersistenceStoreImpl is a node single instance.", "author": "AMashenkov", "createdAt": "2020-12-28T14:27:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3OTc1MQ=="}], "type": "inlineReview", "revised_code": {"commit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsPersistenceStoreImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsPersistenceStoreImpl.java\nindex 285136b484c..6e667ec2f41 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsPersistenceStoreImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsPersistenceStoreImpl.java\n", "chunk": "@@ -67,19 +66,15 @@ public class IgniteStatisticsPersistenceStoreImpl implements IgniteStatisticsSto\n      *\n      * @param subscriptionProcessor Grid subscription processor to track metastorage availability.\n      * @param db Database shared manager to lock db while reading/writing metastorage.\n-     * @param repo Repository to fulfill on metastore available.\n      * @param logSupplier Logger getting function.\n      */\n     public IgniteStatisticsPersistenceStoreImpl(\n             GridInternalSubscriptionProcessor subscriptionProcessor,\n             IgniteCacheDatabaseSharedManager db,\n-            IgniteStatisticsRepository repo,\n             Function<Class<?>, IgniteLogger> logSupplier\n     ) {\n         this.db = db;\n-        this.repo = repo;\n         subscriptionProcessor.registerMetastorageListener(this);\n-\n         this.log = logSupplier.apply(IgniteStatisticsPersistenceStoreImpl.class);\n     }\n \n", "next_change": {"commit": "48b736c4cf138d5db12978e2004c446e26e1f097", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsPersistenceStoreImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsPersistenceStoreImpl.java\nindex 6e667ec2f41..51e4dade5ab 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsPersistenceStoreImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsPersistenceStoreImpl.java\n", "chunk": "@@ -66,15 +75,18 @@ public class IgniteStatisticsPersistenceStoreImpl implements IgniteStatisticsSto\n      *\n      * @param subscriptionProcessor Grid subscription processor to track metastorage availability.\n      * @param db Database shared manager to lock db while reading/writing metastorage.\n+     * @param loadHnd Handler to process loaded statistics after start.\n      * @param logSupplier Logger getting function.\n      */\n     public IgniteStatisticsPersistenceStoreImpl(\n             GridInternalSubscriptionProcessor subscriptionProcessor,\n             IgniteCacheDatabaseSharedManager db,\n+            BiConsumer<StatisticsKey, List<ObjectPartitionStatisticsImpl>> loadHnd,\n             Function<Class<?>, IgniteLogger> logSupplier\n     ) {\n         this.db = db;\n         subscriptionProcessor.registerMetastorageListener(this);\n+        this.loadHnd = loadHnd;\n         this.log = logSupplier.apply(IgniteStatisticsPersistenceStoreImpl.class);\n     }\n \n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4MzkxMQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545483911", "body": "What the difference bw local and global stats?\r\nDoes it mean localStats contains only local per-partition raw statistics? or local aggregates as well?\r\nDoes it mean globalStats contains only aggregated cluster-wide statistics or raw remote partition stats as well?\r\nIf both contains raw partition statistics, can these collections has duplicates?\r\n\r\nI thought it make sense to store only raw statistics, and calculate aggregated on deman. Aggregated statistics can cached for performance purposes and thus can be easily invalidated.", "bodyText": "What the difference bw local and global stats?\nDoes it mean localStats contains only local per-partition raw statistics? or local aggregates as well?\nDoes it mean globalStats contains only aggregated cluster-wide statistics or raw remote partition stats as well?\nIf both contains raw partition statistics, can these collections has duplicates?\nI thought it make sense to store only raw statistics, and calculate aggregated on deman. Aggregated statistics can cached for performance purposes and thus can be easily invalidated.", "bodyHTML": "<p dir=\"auto\">What the difference bw local and global stats?<br>\nDoes it mean localStats contains only local per-partition raw statistics? or local aggregates as well?<br>\nDoes it mean globalStats contains only aggregated cluster-wide statistics or raw remote partition stats as well?<br>\nIf both contains raw partition statistics, can these collections has duplicates?</p>\n<p dir=\"auto\">I thought it make sense to store only raw statistics, and calculate aggregated on deman. Aggregated statistics can cached for performance purposes and thus can be easily invalidated.</p>", "author": "AMashenkov", "createdAt": "2020-12-17T23:58:24Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java", "diffHunk": "@@ -16,27 +16,32 @@\n package org.apache.ignite.internal.processors.query.stat;\n \n import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.processors.cache.persistence.IgniteCacheDatabaseSharedManager;\n+import org.apache.ignite.internal.processors.subscription.GridInternalSubscriptionProcessor;\n+import org.apache.ignite.internal.util.typedef.F;\n \n+import java.util.ArrayList;\n import java.util.Collection;\n import java.util.Collections;\n import java.util.Map;\n import java.util.concurrent.ConcurrentHashMap;\n+import java.util.function.Function;\n \n /**\n  * Statistics repository implementation.\n  */\n public class IgniteStatisticsRepositoryImpl implements IgniteStatisticsRepository {\n     /** Logger. */\n-    private IgniteLogger log;\n+    private final IgniteLogger log;\n \n-    /** Statistics manager. */\n-    private final IgniteStatisticsManagerImpl statisticsManager;\n+    /** Statistics store. */\n+    private final IgniteStatisticsStore store;\n \n-    /** Table->Partition->Partition Statistics map, populated only on server nodes without persistence enabled. */\n-    private final Map<StatsKey, Map<Integer, ObjectPartitionStatisticsImpl>> partsStats;\n+    /** Statistics manager. */\n+    private final IgniteStatisticsManagerImpl statisticsMgr;\n \n     /** Local (for current node) object statistics. */\n-    private final Map<StatsKey, ObjectStatisticsImpl> localStats;\n+    private final Map<StatsKey, ObjectStatisticsImpl> locStats;\n \n     /** Global (for whole cluster) object statistics. */\n     private final Map<StatsKey, ObjectStatisticsImpl> globalStats = new ConcurrentHashMap<>();", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTc3NjYzMw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545776633", "bodyText": "Partition level statistics contains per-partition statistics, but there are only two difference in statistics objects: partition one have update counter and partId additional fields.\nAnd yes, we store only partition level statistics and aggregate localOne from it and after aggregate global one from each local statistics.\nFor example:\nnode1 partId1 \"partition\" level statistics: min = 1, max = 10, nulls = 1, total=10, cord = 100, rawCord = byte[]...; updCnt=10, partId=1\nnode1 part2 \"partition\" level statistics: min = 11, max = 21, nulls = 1, total=10, cord = 100, rawCord = byte[]...; updCnt=12, partId=2\nnode2 part3 \"partition\" level statistics: min = 1, max = 200, nulls = 3, total=10, cord = 100, rawCord = byte[]...; updCnt=19, partId=3\nSo after aggregation we'll get \"local\" statistics:\nnode1 \"local\" level statistics: min = 1, max = 21, nulls = 2, total=20, cord = 100, rawCord = byte[]...;\nnode2 \"local\" level statistics: min = 1, max = 200, nulls = 3, total=10, cord = 100, rawCord = byte[]...;\nAnd after final aggregation to global one:\n\"global\" level statistics: min = 1, max = 200, nulls = 5, total=30, cord = 98, rawCord = byte[]...;", "author": "Berkof", "createdAt": "2020-12-18T11:38:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4MzkxMQ=="}], "type": "inlineReview", "revised_code": {"commit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\nindex 9caaff0cb52..19931b08d25 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n", "chunk": "@@ -41,10 +41,10 @@ public class IgniteStatisticsRepositoryImpl implements IgniteStatisticsRepositor\n     private final IgniteStatisticsManagerImpl statisticsMgr;\n \n     /** Local (for current node) object statistics. */\n-    private final Map<StatsKey, ObjectStatisticsImpl> locStats;\n+    private final Map<StatisticsKey, ObjectStatisticsImpl> locStats;\n \n     /** Global (for whole cluster) object statistics. */\n-    private final Map<StatsKey, ObjectStatisticsImpl> globalStats = new ConcurrentHashMap<>();\n+    private final Map<StatisticsKey, ObjectStatisticsImpl> globalStats = new ConcurrentHashMap<>();\n \n     /**\n      * Constructor.\n", "next_change": {"commit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\nindex 19931b08d25..7cd002fe85c 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n", "chunk": "@@ -43,26 +43,28 @@ public class IgniteStatisticsRepositoryImpl implements IgniteStatisticsRepositor\n     /** Local (for current node) object statistics. */\n     private final Map<StatisticsKey, ObjectStatisticsImpl> locStats;\n \n+    /** Statistics gathering. */\n+    private final StatisticsGathering statisticsGathering;\n+\n     /** Global (for whole cluster) object statistics. */\n     private final Map<StatisticsKey, ObjectStatisticsImpl> globalStats = new ConcurrentHashMap<>();\n \n     /**\n      * Constructor.\n      *\n-     * @param storeData If {@code true} - node stores data locally, {@code false} - otherwise.\n      * @param db Database to use in storage if persistence enabled.\n      * @param subscriptionProcessor Subscription processor.\n      * @param statisticsMgr Ignite statistics manager.\n+     * @param statisticsGathering Statistics gathering.\n      * @param logSupplier Ignite logger supplier to get logger from.\n      */\n     public IgniteStatisticsRepositoryImpl(\n-            boolean storeData,\n-            IgniteCacheDatabaseSharedManager db,\n-            GridInternalSubscriptionProcessor subscriptionProcessor,\n+            IgniteStatisticsStore store,\n             IgniteStatisticsManagerImpl statisticsMgr,\n+            StatisticsGathering statisticsGathering,\n             Function<Class<?>, IgniteLogger> logSupplier\n     ) {\n-        if (storeData) {\n+        /*if (storeData) {\n             // Persistence store\n             store = (db == null) ? new IgniteStatisticsInMemoryStoreImpl(logSupplier) :\n                     new IgniteStatisticsPersistenceStoreImpl(subscriptionProcessor, db, this, logSupplier);\n", "next_change": {"commit": "7ef165002105dd10417170217e86d65771c524bb", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\nindex 7cd002fe85c..a85ac18622b 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n", "chunk": "@@ -64,18 +64,6 @@ public class IgniteStatisticsRepositoryImpl implements IgniteStatisticsRepositor\n             StatisticsGathering statisticsGathering,\n             Function<Class<?>, IgniteLogger> logSupplier\n     ) {\n-        /*if (storeData) {\n-            // Persistence store\n-            store = (db == null) ? new IgniteStatisticsInMemoryStoreImpl(logSupplier) :\n-                    new IgniteStatisticsPersistenceStoreImpl(subscriptionProcessor, db, this, logSupplier);\n-\n-            locStats = new ConcurrentHashMap<>();\n-        }\n-        else {\n-            // Cache only global statistics, no store\n-            store = new IgniteStatisticsDummyStoreImpl(logSupplier);\n-            locStats = null;\n-        }*/\n         this.store = store;\n         this.locStats = new ConcurrentHashMap<>();\n         this.statisticsMgr = statisticsMgr;\n", "next_change": {"commit": "efd6b5e9f1f91625c2e6106b4c75522dada68b46", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\nindex a85ac18622b..aa46a02fd10 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n", "chunk": "@@ -52,21 +48,17 @@ public class IgniteStatisticsRepositoryImpl implements IgniteStatisticsRepositor\n     /**\n      * Constructor.\n      *\n-     * @param db Database to use in storage if persistence enabled.\n-     * @param subscriptionProcessor Subscription processor.\n-     * @param statisticsMgr Ignite statistics manager.\n+     * @param store Ignite statistics store to use.\n      * @param statisticsGathering Statistics gathering.\n      * @param logSupplier Ignite logger supplier to get logger from.\n      */\n     public IgniteStatisticsRepositoryImpl(\n             IgniteStatisticsStore store,\n-            IgniteStatisticsManagerImpl statisticsMgr,\n             StatisticsGathering statisticsGathering,\n             Function<Class<?>, IgniteLogger> logSupplier\n     ) {\n         this.store = store;\n         this.locStats = new ConcurrentHashMap<>();\n-        this.statisticsMgr = statisticsMgr;\n         this.statisticsGathering = statisticsGathering;\n         this.log = logSupplier.apply(IgniteStatisticsRepositoryImpl.class);\n     }\n", "next_change": {"commit": "48b736c4cf138d5db12978e2004c446e26e1f097", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\nindex aa46a02fd10..a869c30ad41 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n", "chunk": "@@ -49,17 +49,17 @@ public class IgniteStatisticsRepositoryImpl implements IgniteStatisticsRepositor\n      * Constructor.\n      *\n      * @param store Ignite statistics store to use.\n-     * @param statisticsGathering Statistics gathering.\n+     * @param helper IgniteStatisticsHelper.\n      * @param logSupplier Ignite logger supplier to get logger from.\n      */\n     public IgniteStatisticsRepositoryImpl(\n             IgniteStatisticsStore store,\n-            StatisticsGathering statisticsGathering,\n+            IgniteStatisticsHelper helper,\n             Function<Class<?>, IgniteLogger> logSupplier\n     ) {\n         this.store = store;\n         this.locStats = new ConcurrentHashMap<>();\n-        this.statisticsGathering = statisticsGathering;\n+        this.helper = helper;\n         this.log = logSupplier.apply(IgniteStatisticsRepositoryImpl.class);\n     }\n \n", "next_change": null}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4NTI3Ng==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545485276", "body": "Let's pass correct implementation from outside.\r\n", "bodyText": "Let's pass correct implementation from outside.", "bodyHTML": "<p dir=\"auto\">Let's pass correct implementation from outside.</p>", "author": "AMashenkov", "createdAt": "2020-12-18T00:02:11Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java", "diffHunk": "@@ -45,204 +50,214 @@\n      * Constructor.\n      *\n      * @param storeData If {@code true} - node stores data locally, {@code false} - otherwise.\n-     * @param persistence If {@code true} - node have persistence store, {@code false} - otherwise.\n-     * @param statisticsManager Ignite statistics manager.\n-     * @param log Ignite logger to use.\n+     * @param db Database to use in storage if persistence enabled.\n+     * @param subscriptionProcessor Subscription processor.\n+     * @param statisticsMgr Ignite statistics manager.\n+     * @param logSupplier Ignite logger supplier to get logger from.\n      */\n     public IgniteStatisticsRepositoryImpl(\n             boolean storeData,\n-            boolean persistence,\n-            IgniteStatisticsManagerImpl statisticsManager,\n-            IgniteLogger log) {\n+            IgniteCacheDatabaseSharedManager db,\n+            GridInternalSubscriptionProcessor subscriptionProcessor,\n+            IgniteStatisticsManagerImpl statisticsMgr,\n+            Function<Class<?>, IgniteLogger> logSupplier\n+    ) {\n         if (storeData) {\n             // Persistence store\n-            partsStats = (persistence) ? null : new ConcurrentHashMap<>();\n-            localStats = new ConcurrentHashMap<>();\n+            store = (db == null) ? new IgniteStatisticsInMemoryStoreImpl(logSupplier) :", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTc3ODIxMg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545778212", "bodyText": "But earlier we decided that implementation can be selected by existence of the database. And in which situation we could pass different store here?", "author": "Berkof", "createdAt": "2020-12-18T11:41:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4NTI3Ng=="}], "type": "inlineReview", "revised_code": {"commit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\nindex 9caaff0cb52..7cd002fe85c 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n", "chunk": "@@ -41,28 +41,30 @@ public class IgniteStatisticsRepositoryImpl implements IgniteStatisticsRepositor\n     private final IgniteStatisticsManagerImpl statisticsMgr;\n \n     /** Local (for current node) object statistics. */\n-    private final Map<StatsKey, ObjectStatisticsImpl> locStats;\n+    private final Map<StatisticsKey, ObjectStatisticsImpl> locStats;\n+\n+    /** Statistics gathering. */\n+    private final StatisticsGathering statisticsGathering;\n \n     /** Global (for whole cluster) object statistics. */\n-    private final Map<StatsKey, ObjectStatisticsImpl> globalStats = new ConcurrentHashMap<>();\n+    private final Map<StatisticsKey, ObjectStatisticsImpl> globalStats = new ConcurrentHashMap<>();\n \n     /**\n      * Constructor.\n      *\n-     * @param storeData If {@code true} - node stores data locally, {@code false} - otherwise.\n      * @param db Database to use in storage if persistence enabled.\n      * @param subscriptionProcessor Subscription processor.\n      * @param statisticsMgr Ignite statistics manager.\n+     * @param statisticsGathering Statistics gathering.\n      * @param logSupplier Ignite logger supplier to get logger from.\n      */\n     public IgniteStatisticsRepositoryImpl(\n-            boolean storeData,\n-            IgniteCacheDatabaseSharedManager db,\n-            GridInternalSubscriptionProcessor subscriptionProcessor,\n+            IgniteStatisticsStore store,\n             IgniteStatisticsManagerImpl statisticsMgr,\n+            StatisticsGathering statisticsGathering,\n             Function<Class<?>, IgniteLogger> logSupplier\n     ) {\n-        if (storeData) {\n+        /*if (storeData) {\n             // Persistence store\n             store = (db == null) ? new IgniteStatisticsInMemoryStoreImpl(logSupplier) :\n                     new IgniteStatisticsPersistenceStoreImpl(subscriptionProcessor, db, this, logSupplier);\n", "next_change": {"commit": "7ef165002105dd10417170217e86d65771c524bb", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\nindex 7cd002fe85c..a85ac18622b 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n", "chunk": "@@ -64,18 +64,6 @@ public class IgniteStatisticsRepositoryImpl implements IgniteStatisticsRepositor\n             StatisticsGathering statisticsGathering,\n             Function<Class<?>, IgniteLogger> logSupplier\n     ) {\n-        /*if (storeData) {\n-            // Persistence store\n-            store = (db == null) ? new IgniteStatisticsInMemoryStoreImpl(logSupplier) :\n-                    new IgniteStatisticsPersistenceStoreImpl(subscriptionProcessor, db, this, logSupplier);\n-\n-            locStats = new ConcurrentHashMap<>();\n-        }\n-        else {\n-            // Cache only global statistics, no store\n-            store = new IgniteStatisticsDummyStoreImpl(logSupplier);\n-            locStats = null;\n-        }*/\n         this.store = store;\n         this.locStats = new ConcurrentHashMap<>();\n         this.statisticsMgr = statisticsMgr;\n", "next_change": {"commit": "efd6b5e9f1f91625c2e6106b4c75522dada68b46", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\nindex a85ac18622b..aa46a02fd10 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n", "chunk": "@@ -52,21 +48,17 @@ public class IgniteStatisticsRepositoryImpl implements IgniteStatisticsRepositor\n     /**\n      * Constructor.\n      *\n-     * @param db Database to use in storage if persistence enabled.\n-     * @param subscriptionProcessor Subscription processor.\n-     * @param statisticsMgr Ignite statistics manager.\n+     * @param store Ignite statistics store to use.\n      * @param statisticsGathering Statistics gathering.\n      * @param logSupplier Ignite logger supplier to get logger from.\n      */\n     public IgniteStatisticsRepositoryImpl(\n             IgniteStatisticsStore store,\n-            IgniteStatisticsManagerImpl statisticsMgr,\n             StatisticsGathering statisticsGathering,\n             Function<Class<?>, IgniteLogger> logSupplier\n     ) {\n         this.store = store;\n         this.locStats = new ConcurrentHashMap<>();\n-        this.statisticsMgr = statisticsMgr;\n         this.statisticsGathering = statisticsGathering;\n         this.log = logSupplier.apply(IgniteStatisticsRepositoryImpl.class);\n     }\n", "next_change": {"commit": "48b736c4cf138d5db12978e2004c446e26e1f097", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\nindex aa46a02fd10..a869c30ad41 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n", "chunk": "@@ -49,17 +49,17 @@ public class IgniteStatisticsRepositoryImpl implements IgniteStatisticsRepositor\n      * Constructor.\n      *\n      * @param store Ignite statistics store to use.\n-     * @param statisticsGathering Statistics gathering.\n+     * @param helper IgniteStatisticsHelper.\n      * @param logSupplier Ignite logger supplier to get logger from.\n      */\n     public IgniteStatisticsRepositoryImpl(\n             IgniteStatisticsStore store,\n-            StatisticsGathering statisticsGathering,\n+            IgniteStatisticsHelper helper,\n             Function<Class<?>, IgniteLogger> logSupplier\n     ) {\n         this.store = store;\n         this.locStats = new ConcurrentHashMap<>();\n-        this.statisticsGathering = statisticsGathering;\n+        this.helper = helper;\n         this.log = logSupplier.apply(IgniteStatisticsRepositoryImpl.class);\n     }\n \n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4NTg3NQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545485875", "body": "Does it make sense to have dummy repository implementation or may be do not create it on client node at all?", "bodyText": "Does it make sense to have dummy repository implementation or may be do not create it on client node at all?", "bodyHTML": "<p dir=\"auto\">Does it make sense to have dummy repository implementation or may be do not create it on client node at all?</p>", "author": "AMashenkov", "createdAt": "2020-12-18T00:03:53Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java", "diffHunk": "@@ -45,204 +50,214 @@\n      * Constructor.\n      *\n      * @param storeData If {@code true} - node stores data locally, {@code false} - otherwise.\n-     * @param persistence If {@code true} - node have persistence store, {@code false} - otherwise.\n-     * @param statisticsManager Ignite statistics manager.\n-     * @param log Ignite logger to use.\n+     * @param db Database to use in storage if persistence enabled.\n+     * @param subscriptionProcessor Subscription processor.\n+     * @param statisticsMgr Ignite statistics manager.\n+     * @param logSupplier Ignite logger supplier to get logger from.\n      */\n     public IgniteStatisticsRepositoryImpl(\n             boolean storeData,\n-            boolean persistence,\n-            IgniteStatisticsManagerImpl statisticsManager,\n-            IgniteLogger log) {\n+            IgniteCacheDatabaseSharedManager db,\n+            GridInternalSubscriptionProcessor subscriptionProcessor,\n+            IgniteStatisticsManagerImpl statisticsMgr,\n+            Function<Class<?>, IgniteLogger> logSupplier\n+    ) {\n         if (storeData) {\n             // Persistence store\n-            partsStats = (persistence) ? null : new ConcurrentHashMap<>();\n-            localStats = new ConcurrentHashMap<>();\n+            store = (db == null) ? new IgniteStatisticsInMemoryStoreImpl(logSupplier) :\n+                    new IgniteStatisticsPersistenceStoreImpl(subscriptionProcessor, db, this, logSupplier);\n+\n+            locStats = new ConcurrentHashMap<>();\n         }\n         else {\n             // Cache only global statistics, no store\n-            partsStats = null;\n-            localStats = null;\n-        }\n-        this.statisticsManager = statisticsManager;\n-        this.log = log;\n-    }\n-\n-    /**\n-     * Convert collection of partition level statistics into map(partId->partStatistics).\n-     *\n-     * @param key Object key.\n-     * @param statistics Collection of tables partition statistics.\n-     * @return Partition id to statistics map.\n-     */\n-    private Map<Integer, ObjectPartitionStatisticsImpl> buildStatisticsMap(\n-            StatsKey key,\n-            Collection<ObjectPartitionStatisticsImpl> statistics\n-    ) {\n-        Map<Integer, ObjectPartitionStatisticsImpl> statisticsMap = new ConcurrentHashMap<>();\n-        for (ObjectPartitionStatisticsImpl s : statistics) {\n-            if (statisticsMap.put(s.partId(), s) != null)\n-                log.warning(String.format(\"Trying to save more than one %s.%s partition statistics for partition %d\",\n-                        key.schema(), key.obj(), s.partId()));\n+            store = null;", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4NjA4NA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545486084", "bodyText": "\"if (store==null) return\" in every method looks ugly.", "author": "AMashenkov", "createdAt": "2020-12-18T00:04:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4NTg3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTc4MDI4Nw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545780287", "bodyText": "Yes, we can have a dummy implementation for the client nodes. But there are locStats map too, so part of such ugly tests staing even after that.", "author": "Berkof", "createdAt": "2020-12-18T11:46:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4NTg3NQ=="}], "type": "inlineReview", "revised_code": {"commit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\nindex 9caaff0cb52..19931b08d25 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n", "chunk": "@@ -71,7 +71,7 @@ public class IgniteStatisticsRepositoryImpl implements IgniteStatisticsRepositor\n         }\n         else {\n             // Cache only global statistics, no store\n-            store = null;\n+            store = new IgniteStatisticsDummyStoreImpl(logSupplier);\n             locStats = null;\n         }\n         this.statisticsMgr = statisticsMgr;\n", "next_change": {"commit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\nindex 19931b08d25..7cd002fe85c 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n", "chunk": "@@ -73,8 +75,11 @@ public class IgniteStatisticsRepositoryImpl implements IgniteStatisticsRepositor\n             // Cache only global statistics, no store\n             store = new IgniteStatisticsDummyStoreImpl(logSupplier);\n             locStats = null;\n-        }\n+        }*/\n+        this.store = store;\n+        this.locStats = new ConcurrentHashMap<>();\n         this.statisticsMgr = statisticsMgr;\n+        this.statisticsGathering = statisticsGathering;\n         this.log = logSupplier.apply(IgniteStatisticsRepositoryImpl.class);\n     }\n \n", "next_change": {"commit": "7ef165002105dd10417170217e86d65771c524bb", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\nindex 7cd002fe85c..a85ac18622b 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n", "chunk": "@@ -64,18 +64,6 @@ public class IgniteStatisticsRepositoryImpl implements IgniteStatisticsRepositor\n             StatisticsGathering statisticsGathering,\n             Function<Class<?>, IgniteLogger> logSupplier\n     ) {\n-        /*if (storeData) {\n-            // Persistence store\n-            store = (db == null) ? new IgniteStatisticsInMemoryStoreImpl(logSupplier) :\n-                    new IgniteStatisticsPersistenceStoreImpl(subscriptionProcessor, db, this, logSupplier);\n-\n-            locStats = new ConcurrentHashMap<>();\n-        }\n-        else {\n-            // Cache only global statistics, no store\n-            store = new IgniteStatisticsDummyStoreImpl(logSupplier);\n-            locStats = null;\n-        }*/\n         this.store = store;\n         this.locStats = new ConcurrentHashMap<>();\n         this.statisticsMgr = statisticsMgr;\n", "next_change": {"commit": "efd6b5e9f1f91625c2e6106b4c75522dada68b46", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\nindex a85ac18622b..aa46a02fd10 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n", "chunk": "@@ -52,21 +48,17 @@ public class IgniteStatisticsRepositoryImpl implements IgniteStatisticsRepositor\n     /**\n      * Constructor.\n      *\n-     * @param db Database to use in storage if persistence enabled.\n-     * @param subscriptionProcessor Subscription processor.\n-     * @param statisticsMgr Ignite statistics manager.\n+     * @param store Ignite statistics store to use.\n      * @param statisticsGathering Statistics gathering.\n      * @param logSupplier Ignite logger supplier to get logger from.\n      */\n     public IgniteStatisticsRepositoryImpl(\n             IgniteStatisticsStore store,\n-            IgniteStatisticsManagerImpl statisticsMgr,\n             StatisticsGathering statisticsGathering,\n             Function<Class<?>, IgniteLogger> logSupplier\n     ) {\n         this.store = store;\n         this.locStats = new ConcurrentHashMap<>();\n-        this.statisticsMgr = statisticsMgr;\n         this.statisticsGathering = statisticsGathering;\n         this.log = logSupplier.apply(IgniteStatisticsRepositoryImpl.class);\n     }\n", "next_change": {"commit": "48b736c4cf138d5db12978e2004c446e26e1f097", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\nindex aa46a02fd10..a869c30ad41 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n", "chunk": "@@ -49,17 +49,17 @@ public class IgniteStatisticsRepositoryImpl implements IgniteStatisticsRepositor\n      * Constructor.\n      *\n      * @param store Ignite statistics store to use.\n-     * @param statisticsGathering Statistics gathering.\n+     * @param helper IgniteStatisticsHelper.\n      * @param logSupplier Ignite logger supplier to get logger from.\n      */\n     public IgniteStatisticsRepositoryImpl(\n             IgniteStatisticsStore store,\n-            StatisticsGathering statisticsGathering,\n+            IgniteStatisticsHelper helper,\n             Function<Class<?>, IgniteLogger> logSupplier\n     ) {\n         this.store = store;\n         this.locStats = new ConcurrentHashMap<>();\n-        this.statisticsGathering = statisticsGathering;\n+        this.helper = helper;\n         this.log = logSupplier.apply(IgniteStatisticsRepositoryImpl.class);\n     }\n \n", "next_change": null}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4NzIzMw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545487233", "body": "Confusing javadoc.", "bodyText": "Confusing javadoc.", "bodyHTML": "<p dir=\"auto\">Confusing javadoc.</p>", "author": "AMashenkov", "createdAt": "2020-12-18T00:07:51Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java", "diffHunk": "@@ -0,0 +1,343 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Statistics collection routine.\n+ */\n+public class IgniteStatisticsRequestCollection {", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTc4MTQwOQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545781409", "bodyText": "Tried to improve.", "author": "Berkof", "createdAt": "2020-12-18T11:48:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4NzIzMw=="}], "type": "inlineReview", "revised_code": {"commit": "d8c6c6bb46b36bf8d36a0578e7c1813e04bfabfe", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\nindex ed9fc9df3ad..02fce6bdf6d 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\n", "chunk": "@@ -27,7 +46,7 @@ import java.util.function.Function;\n import java.util.stream.Collectors;\n \n /**\n- * Statistics collection routine.\n+ * Current statistics collections with methods to work with it's messages.\n  */\n public class IgniteStatisticsRequestCollection {\n     /** Current collections, collection id to collection status map. */\n", "next_change": {"commit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nsimilarity index 56%\nrename from modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\nrename to modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 02fce6bdf6d..f0bc33ee4ba 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -21,37 +21,27 @@ import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n-import org.apache.ignite.internal.processors.query.stat.messages.StatsClearRequest;\n-import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n-import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n-import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n-import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n import org.apache.ignite.internal.util.GridArrays;\n-import org.apache.ignite.internal.util.lang.GridFunc;\n import org.apache.ignite.internal.util.typedef.F;\n \n import java.util.ArrayList;\n-import java.util.Arrays;\n import java.util.Collection;\n import java.util.HashMap;\n import java.util.HashSet;\n import java.util.List;\n import java.util.Map;\n-import java.util.Set;\n import java.util.UUID;\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.concurrent.locks.ReentrantReadWriteLock;\n-import java.util.function.Consumer;\n-import java.util.function.Function;\n import java.util.stream.Collectors;\n \n /**\n  * Current statistics collections with methods to work with it's messages.\n  */\n-public class IgniteStatisticsRequestCollection {\n-    /** Current collections, collection id to collection status map. */\n-    private final Map<UUID, StatCollectionStatus> currColls = new ConcurrentHashMap<>();\n-\n+public class IgniteStatisticsHelper {\n     /** Schema manager. */\n     private final SchemaManager schemaMgr;\n \n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4ODAwOA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545488008", "body": "Method is declared as to add a collection, but got 'status'. ", "bodyText": "Method is declared as to add a collection, but got 'status'.", "bodyHTML": "<p dir=\"auto\">Method is declared as to add a collection, but got 'status'.</p>", "author": "AMashenkov", "createdAt": "2020-12-18T00:10:08Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java", "diffHunk": "@@ -0,0 +1,343 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Statistics collection routine.\n+ */\n+public class IgniteStatisticsRequestCollection {\n+    /** Current collections, collection id to collection status map. */\n+    private final Map<UUID, StatCollectionStatus> currColls = new ConcurrentHashMap<>();\n+\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsRequestCollection(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Add new statistics collection status.\n+     *\n+     * @param status status to add.\n+     */\n+    public void addCollection(StatCollectionStatus status) {", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTc4MjM1OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545782358", "bodyText": "It was about statistics collection status. I renamed it.", "author": "Berkof", "createdAt": "2020-12-18T11:50:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4ODAwOA=="}], "type": "inlineReview", "revised_code": {"commit": "b69634fd8544d7b27bd76f84bdee9a1e4f0ac470", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\nindex ed9fc9df3ad..1dba277a621 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\n", "chunk": "@@ -48,30 +67,31 @@ public class IgniteStatisticsRequestCollection {\n     /**\n      * Add new statistics collection status.\n      *\n+     * @param id Id to save status by.\n      * @param status status to add.\n      */\n-    public void addCollection(StatCollectionStatus status) {\n-        currColls.put(status.colId(), status);\n+    public void addCollection(UUID id, StatCollectionStatus status) {\n+        currColls.put(id, status);\n     }\n \n     /**\n      * Thread safe update of statistics collection.\n      *\n-     * @param colId statistics collection.\n+     * @param id statistics collection.\n      * @param transformation transformation, if return {@code null} - status will be removed.\n      */\n-    public void updateCollection(UUID colId, Function<StatCollectionStatus, StatCollectionStatus> transformation) {\n-        currColls.compute(colId, (k, v) -> transformation.apply(v));\n+    public void updateCollection(UUID id, Function<StatCollectionStatus, StatCollectionStatus> transformation) {\n+        currColls.compute(id, (k, v) -> transformation.apply(v));\n     }\n \n     /**\n      * Get collection status.\n      *\n-     * @param colId Collection id.\n+     * @param id Id to get status by.\n      * @return Collection status.\n      */\n-    public StatCollectionStatus getCollection(UUID colId) {\n-        return currColls.get(colId);\n+    public StatCollectionStatus getCollection(UUID id) {\n+        return currColls.get(id);\n     }\n \n \n", "next_change": {"commit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nsimilarity index 56%\nrename from modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\nrename to modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 1dba277a621..f0bc33ee4ba 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -60,41 +50,10 @@ public class IgniteStatisticsRequestCollection {\n      *\n      * @param schemaMgr Schema manager.\n      */\n-    public IgniteStatisticsRequestCollection(SchemaManager schemaMgr) {\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n         this.schemaMgr = schemaMgr;\n     }\n \n-    /**\n-     * Add new statistics collection status.\n-     *\n-     * @param id Id to save status by.\n-     * @param status status to add.\n-     */\n-    public void addCollection(UUID id, StatCollectionStatus status) {\n-        currColls.put(id, status);\n-    }\n-\n-    /**\n-     * Thread safe update of statistics collection.\n-     *\n-     * @param id statistics collection.\n-     * @param transformation transformation, if return {@code null} - status will be removed.\n-     */\n-    public void updateCollection(UUID id, Function<StatCollectionStatus, StatCollectionStatus> transformation) {\n-        currColls.compute(id, (k, v) -> transformation.apply(v));\n-    }\n-\n-    /**\n-     * Get collection status.\n-     *\n-     * @param id Id to get status by.\n-     * @return Collection status.\n-     */\n-    public StatCollectionStatus getCollection(UUID id) {\n-        return currColls.get(id);\n-    }\n-\n-\n     /**\n      * Extract groups of stats keys.\n      *\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4ODQzNA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545488434", "body": "```suggestion\r\n     * Update status of statistic gathering task\r\n```", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                 * Thread safe update of statistics collection.\n          \n          \n            \n                 * Update status of statistic gathering task", "bodyHTML": "  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">     <span class=\"pl-k\">*</span> <span class=\"pl-smi x x-first\">Thread</span><span class=\"x x-last\"> safe update </span>of <span class=\"x x-first x-last\">statistics collection.</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">     <span class=\"pl-k\">*</span> <span class=\"pl-smi x x-first\">Update</span><span class=\"x x-last\"> status </span>of <span class=\"x x-first x-last\">statistic gathering task</span></td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "AMashenkov", "createdAt": "2020-12-18T00:11:26Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java", "diffHunk": "@@ -0,0 +1,343 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Statistics collection routine.\n+ */\n+public class IgniteStatisticsRequestCollection {\n+    /** Current collections, collection id to collection status map. */\n+    private final Map<UUID, StatCollectionStatus> currColls = new ConcurrentHashMap<>();\n+\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsRequestCollection(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Add new statistics collection status.\n+     *\n+     * @param status status to add.\n+     */\n+    public void addCollection(StatCollectionStatus status) {\n+        currColls.put(status.colId(), status);\n+    }\n+\n+    /**\n+     * Thread safe update of statistics collection.", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTc4MzIxNQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545783215", "bodyText": "Fixed", "author": "Berkof", "createdAt": "2020-12-18T11:52:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ4ODQzNA=="}], "type": "inlineReview", "revised_code": {"commit": "b69634fd8544d7b27bd76f84bdee9a1e4f0ac470", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\nindex ed9fc9df3ad..1dba277a621 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\n", "chunk": "@@ -48,30 +67,31 @@ public class IgniteStatisticsRequestCollection {\n     /**\n      * Add new statistics collection status.\n      *\n+     * @param id Id to save status by.\n      * @param status status to add.\n      */\n-    public void addCollection(StatCollectionStatus status) {\n-        currColls.put(status.colId(), status);\n+    public void addCollection(UUID id, StatCollectionStatus status) {\n+        currColls.put(id, status);\n     }\n \n     /**\n      * Thread safe update of statistics collection.\n      *\n-     * @param colId statistics collection.\n+     * @param id statistics collection.\n      * @param transformation transformation, if return {@code null} - status will be removed.\n      */\n-    public void updateCollection(UUID colId, Function<StatCollectionStatus, StatCollectionStatus> transformation) {\n-        currColls.compute(colId, (k, v) -> transformation.apply(v));\n+    public void updateCollection(UUID id, Function<StatCollectionStatus, StatCollectionStatus> transformation) {\n+        currColls.compute(id, (k, v) -> transformation.apply(v));\n     }\n \n     /**\n      * Get collection status.\n      *\n-     * @param colId Collection id.\n+     * @param id Id to get status by.\n      * @return Collection status.\n      */\n-    public StatCollectionStatus getCollection(UUID colId) {\n-        return currColls.get(colId);\n+    public StatCollectionStatus getCollection(UUID id) {\n+        return currColls.get(id);\n     }\n \n \n", "next_change": {"commit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nsimilarity index 56%\nrename from modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\nrename to modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 1dba277a621..f0bc33ee4ba 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -60,41 +50,10 @@ public class IgniteStatisticsRequestCollection {\n      *\n      * @param schemaMgr Schema manager.\n      */\n-    public IgniteStatisticsRequestCollection(SchemaManager schemaMgr) {\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n         this.schemaMgr = schemaMgr;\n     }\n \n-    /**\n-     * Add new statistics collection status.\n-     *\n-     * @param id Id to save status by.\n-     * @param status status to add.\n-     */\n-    public void addCollection(UUID id, StatCollectionStatus status) {\n-        currColls.put(id, status);\n-    }\n-\n-    /**\n-     * Thread safe update of statistics collection.\n-     *\n-     * @param id statistics collection.\n-     * @param transformation transformation, if return {@code null} - status will be removed.\n-     */\n-    public void updateCollection(UUID id, Function<StatCollectionStatus, StatCollectionStatus> transformation) {\n-        currColls.compute(id, (k, v) -> transformation.apply(v));\n-    }\n-\n-    /**\n-     * Get collection status.\n-     *\n-     * @param id Id to get status by.\n-     * @return Collection status.\n-     */\n-    public StatCollectionStatus getCollection(UUID id) {\n-        return currColls.get(id);\n-    }\n-\n-\n     /**\n      * Extract groups of stats keys.\n      *\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ5MDAxNw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545490017", "body": "What if one of cache was stopped somewhen in between, but other are operational?\r\nWill statistics task result be thrown away or task crashed?", "bodyText": "What if one of cache was stopped somewhen in between, but other are operational?\nWill statistics task result be thrown away or task crashed?", "bodyHTML": "<p dir=\"auto\">What if one of cache was stopped somewhen in between, but other are operational?<br>\nWill statistics task result be thrown away or task crashed?</p>", "author": "AMashenkov", "createdAt": "2020-12-18T00:16:00Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java", "diffHunk": "@@ -0,0 +1,343 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Statistics collection routine.\n+ */\n+public class IgniteStatisticsRequestCollection {\n+    /** Current collections, collection id to collection status map. */\n+    private final Map<UUID, StatCollectionStatus> currColls = new ConcurrentHashMap<>();\n+\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsRequestCollection(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Add new statistics collection status.\n+     *\n+     * @param status status to add.\n+     */\n+    public void addCollection(StatCollectionStatus status) {\n+        currColls.put(status.colId(), status);\n+    }\n+\n+    /**\n+     * Thread safe update of statistics collection.\n+     *\n+     * @param colId statistics collection.\n+     * @param transformation transformation, if return {@code null} - status will be removed.\n+     */\n+    public void updateCollection(UUID colId, Function<StatCollectionStatus, StatCollectionStatus> transformation) {\n+        currColls.compute(colId, (k, v) -> transformation.apply(v));\n+    }\n+\n+    /**\n+     * Get collection status.\n+     *\n+     * @param colId Collection id.\n+     * @return Collection status.\n+     */\n+    public StatCollectionStatus getCollection(UUID colId) {\n+        return currColls.get(colId);\n+    }\n+\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatsKeyMessage>> extractGroups(Collection<StatsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTc4Mzg3Mg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545783872", "bodyText": "For now - whole task should be cancelled. I'll check it...", "author": "Berkof", "createdAt": "2020-12-18T11:53:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ5MDAxNw=="}], "type": "inlineReview", "revised_code": {"commit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nsimilarity index 51%\nrename from modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\nrename to modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex ed9fc9df3ad..f0bc33ee4ba 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -82,10 +61,10 @@ public class IgniteStatisticsRequestCollection {\n      * @return Map of <group ids></group> to <collection of keys in groups>\n      * @throws IgniteCheckedException In case of lack some of specified objects.\n      */\n-    protected Map<CacheGroupContext, Collection<StatsKeyMessage>> extractGroups(Collection<StatsKeyMessage> keys)\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n             throws IgniteCheckedException {\n-        Map<CacheGroupContext, Collection<StatsKeyMessage>> res = new HashMap<>(keys.size());\n-        for (StatsKeyMessage key : keys) {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n             GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n             if (tbl == null)\n                 throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ5MTQwOQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545491409", "body": "Can we be sure both arrays are sorted?\r\nIf so, intersect will of sorted arrays is trivial.\r\nOr may be BitSet fits your needs better?", "bodyText": "Can we be sure both arrays are sorted?\nIf so, intersect will of sorted arrays is trivial.\nOr may be BitSet fits your needs better?", "bodyHTML": "<p dir=\"auto\">Can we be sure both arrays are sorted?<br>\nIf so, intersect will of sorted arrays is trivial.<br>\nOr may be BitSet fits your needs better?</p>", "author": "AMashenkov", "createdAt": "2020-12-18T00:20:03Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java", "diffHunk": "@@ -0,0 +1,343 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Statistics collection routine.\n+ */\n+public class IgniteStatisticsRequestCollection {\n+    /** Current collections, collection id to collection status map. */\n+    private final Map<UUID, StatCollectionStatus> currColls = new ConcurrentHashMap<>();\n+\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsRequestCollection(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Add new statistics collection status.\n+     *\n+     * @param status status to add.\n+     */\n+    public void addCollection(StatCollectionStatus status) {\n+        currColls.put(status.colId(), status);\n+    }\n+\n+    /**\n+     * Thread safe update of statistics collection.\n+     *\n+     * @param colId statistics collection.\n+     * @param transformation transformation, if return {@code null} - status will be removed.\n+     */\n+    public void updateCollection(UUID colId, Function<StatCollectionStatus, StatCollectionStatus> transformation) {\n+        currColls.compute(colId, (k, v) -> transformation.apply(v));\n+    }\n+\n+    /**\n+     * Get collection status.\n+     *\n+     * @param colId Collection id.\n+     * @return Collection status.\n+     */\n+    public StatCollectionStatus getCollection(UUID colId) {\n+        return currColls.get(colId);\n+    }\n+\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatsKeyMessage>> extractGroups(Collection<StatsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds)\n+            throws IgniteCheckedException {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<Integer>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatsCollectionRequest prepareRequest(UUID colId, Map<StatsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatsCollectionRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n+     *            If {@code null} - requests will be\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public static Collection<StatsCollectionAddrRequest> generateCollectionRequests(\n+            UUID colId,\n+            Collection<StatsKeyMessage> keys,\n+            Map<StatsKeyMessage, int[]> failedPartitions,\n+            Map<CacheGroupContext, Collection<StatsKeyMessage>> grpContexts\n+    ) throws IgniteCheckedException {\n+        Map<StatsKeyMessage, CacheGroupContext> keyGroups = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatsKeyMessage>> grpKeys : grpContexts.entrySet())\n+            for(StatsKeyMessage key : grpKeys.getValue())\n+                keyGroups.put(key, grpKeys.getKey());\n+\n+        // NodeId to <Key to partitions on node> map\n+        Map<UUID, Map<StatsKeyMessage, int[]>> reqMap = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n+            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null);\n+            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n+                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n+                    if (v == null)\n+                        v = new HashMap<>();\n+\n+                    Collection<StatsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n+\n+                    for (StatsKeyMessage key : grpKeys) {\n+                        int[] keyNodeParts = (failedPartitions == null) ? nodeParts.getValue() :\n+                                intersect(nodeParts.getValue(), failedPartitions.get(key));\n+\n+                        if (keyNodeParts.length > 0)\n+                            v.put(key, keyNodeParts);\n+                    }\n+\n+                    return v.size() > 0 ? v : null;\n+                });\n+        }\n+\n+        Collection<StatsCollectionAddrRequest> reqs = new ArrayList<>();\n+        for (Map.Entry<UUID, Map<StatsKeyMessage, int[]>> nodeGpsParts: reqMap.entrySet()) {\n+            if (nodeGpsParts.getValue().isEmpty())\n+                continue;\n+            StatsCollectionRequest req = prepareRequest(colId, nodeGpsParts.getValue());\n+            reqs.add(new StatsCollectionAddrRequest(req, nodeGpsParts.getKey()));\n+        }\n+\n+        return reqs;\n+    }\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    protected Collection<StatsCollectionAddrRequest> generateCollectionRequests(\n+        UUID colId,\n+        Collection<StatsKeyMessage> keys,\n+        Map<StatsKeyMessage, int[]> failedPartitions\n+    ) throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatsKeyMessage>> grpContexts = extractGroups(keys);\n+        return generateCollectionRequests(colId, keys, failedPartitions, grpContexts);\n+    }\n+\n+    /**\n+     * Intersect two specified arrays.\n+     *\n+     * @param a First array.\n+     * @param b Second array.\n+     * @return Arrays intersection.\n+     */\n+    protected static int[] intersect(int[] a, int[] b) {\n+        if (a == null || b == null)\n+            return new int[0];\n+        Set<Integer> aSet = Arrays.stream(a).boxed().collect(Collectors.toSet());", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzQwMTczMQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r557401731", "bodyText": "Code removed.", "author": "Berkof", "createdAt": "2021-01-14T13:40:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ5MTQwOQ=="}], "type": "inlineReview", "revised_code": {"commit": "ec4a9ef0e7691b605225c12527d496d07d573b42", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\nindex ed9fc9df3ad..d8ba7c4aed7 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\n", "chunk": "@@ -240,40 +311,6 @@ public class IgniteStatisticsRequestCollection {\n         return generateCollectionRequests(colId, keys, failedPartitions, grpContexts);\n     }\n \n-    /**\n-     * Intersect two specified arrays.\n-     *\n-     * @param a First array.\n-     * @param b Second array.\n-     * @return Arrays intersection.\n-     */\n-    protected static int[] intersect(int[] a, int[] b) {\n-        if (a == null || b == null)\n-            return new int[0];\n-        Set<Integer> aSet = Arrays.stream(a).boxed().collect(Collectors.toSet());\n-        List<Integer> res = new ArrayList<>();\n-        for (int bVal : b)\n-            if (aSet.contains(bVal))\n-                res.add(bVal);\n-        return res.stream().mapToInt(Integer::intValue).toArray();\n-    }\n-\n-    /**\n-     * Subtract b array from a array.\n-     *\n-     * @param a Base array.\n-     * @param b Array to substract from the base one.\n-     * @return Substraction result.\n-     */\n-    protected static int[] subtract(int[] a, int[] b) {\n-        Set<Integer> bSet = Arrays.stream(b).boxed().collect(Collectors.toSet());\n-        List<Integer> res = new ArrayList<>();\n-        for (int aVal : a)\n-            if (!bSet.contains(aVal))\n-                res.add(aVal);\n-        return res.stream().mapToInt(Integer::intValue).toArray();\n-    }\n-\n     /**\n      * Extract all partitions from specified statistics collection requests.\n      *\n", "next_change": {"commit": "b595e90b5b480aaf80a9256558b1841334df97de", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\nindex d8ba7c4aed7..acb7c1d527e 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\n", "chunk": "@@ -308,6 +293,7 @@ public class IgniteStatisticsRequestCollection {\n         Map<StatsKeyMessage, int[]> failedPartitions\n     ) throws IgniteCheckedException {\n         Map<CacheGroupContext, Collection<StatsKeyMessage>> grpContexts = extractGroups(keys);\n+\n         return generateCollectionRequests(colId, keys, failedPartitions, grpContexts);\n     }\n \n", "next_change": {"commit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nsimilarity index 64%\nrename from modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\nrename to modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex acb7c1d527e..f0bc33ee4ba 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -282,19 +246,19 @@ public class IgniteStatisticsRequestCollection {\n     /**\n      * Generate statistics collection requests by given keys.\n      *\n-     * @param colId Collection id.\n+     * @param gatId Gathering id.\n      * @param keys Collection of keys to collect statistics by.\n      * @return Collection of statistics collection addressed request.\n      * @throws IgniteCheckedException In case of errors.\n      */\n-    protected Collection<StatsAddrRequest<StatsCollectionRequest>> generateCollectionRequests(\n-        UUID colId,\n-        Collection<StatsKeyMessage> keys,\n-        Map<StatsKeyMessage, int[]> failedPartitions\n+    protected Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n+        UUID gatId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions\n     ) throws IgniteCheckedException {\n-        Map<CacheGroupContext, Collection<StatsKeyMessage>> grpContexts = extractGroups(keys);\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts = extractGroups(keys);\n \n-        return generateCollectionRequests(colId, keys, failedPartitions, grpContexts);\n+        return generateCollectionRequests(gatId, keys, failedPartitions, grpContexts);\n     }\n \n     /**\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ5MjQ1MQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545492451", "body": "Why 'local'?\r\nDoes it mean we store statistics for local partitions only? primary or backups or both?\r\nMay it worth to rename the interface itself?", "bodyText": "Why 'local'?\nDoes it mean we store statistics for local partitions only? primary or backups or both?\nMay it worth to rename the interface itself?", "bodyHTML": "<p dir=\"auto\">Why 'local'?<br>\nDoes it mean we store statistics for local partitions only? primary or backups or both?<br>\nMay it worth to rename the interface itself?</p>", "author": "AMashenkov", "createdAt": "2020-12-18T00:23:17Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsStore.java", "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import java.util.Collection;\n+\n+/**\n+ * Statistics store interface.\n+ */\n+public interface IgniteStatisticsStore {\n+    /**\n+     * Clear statistics of any type for any objects;\n+     */\n+    public void clearAllStatistics();\n+\n+    /**\n+     * Replace all tables partition statistics with specified ones.\n+     *\n+     * @param key Statistics key to replace statistics by.\n+     * @param statistics Collection of partition level statistics.\n+     */\n+    public void replaceLocalPartitionsStatistics(StatsKey key, Collection<ObjectPartitionStatisticsImpl> statistics);\n+\n+    /**\n+     * Get local partition statistics by specified object.\n+     *\n+     * @param key Key to get statistics by.\n+     * @return Collection of partitions statistics.\n+     */\n+    public Collection<ObjectPartitionStatisticsImpl> getLocalPartitionsStatistics(StatsKey key);", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTc4NjMxMg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545786312", "bodyText": "Because it should return only statistics for locals (both primary and backups) partitions.\nDidn't get the idea, what name you suppose?", "author": "Berkof", "createdAt": "2020-12-18T11:58:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ5MjQ1MQ=="}], "type": "inlineReview", "revised_code": {"commit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsStore.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsStore.java\nindex 8fcf66c278f..b80ee1fc152 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsStore.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsStore.java\n", "chunk": "@@ -32,7 +32,7 @@ public interface IgniteStatisticsStore {\n      * @param key Statistics key to replace statistics by.\n      * @param statistics Collection of partition level statistics.\n      */\n-    public void replaceLocalPartitionsStatistics(StatsKey key, Collection<ObjectPartitionStatisticsImpl> statistics);\n+    public void replaceLocalPartitionsStatistics(StatisticsKey key, Collection<ObjectPartitionStatisticsImpl> statistics);\n \n     /**\n      * Get local partition statistics by specified object.\n", "next_change": null}, {"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsStore.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsStore.java\nindex 8fcf66c278f..b80ee1fc152 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsStore.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsStore.java\n", "chunk": "@@ -40,14 +40,14 @@ public interface IgniteStatisticsStore {\n      * @param key Key to get statistics by.\n      * @return Collection of partitions statistics.\n      */\n-    public Collection<ObjectPartitionStatisticsImpl> getLocalPartitionsStatistics(StatsKey key);\n+    public Collection<ObjectPartitionStatisticsImpl> getLocalPartitionsStatistics(StatisticsKey key);\n \n     /**\n      * Clear partition statistics for specified object.\n      *\n      * @param key Key to clear statistics by.\n      */\n-    public void clearLocalPartitionsStatistics(StatsKey key);\n+    public void clearLocalPartitionsStatistics(StatisticsKey key);\n \n     /**\n      * Get partition statistics.\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ5NjIwOA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545496208", "body": "Why it serializable?", "bodyText": "Why it serializable?", "bodyHTML": "<p dir=\"auto\">Why it serializable?</p>", "author": "AMashenkov", "createdAt": "2020-12-18T00:34:36Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatsKey.java", "diffHunk": "@@ -15,17 +15,21 @@\n  */\n package org.apache.ignite.internal.processors.query.stat;\n \n+import java.io.Serializable;\n import java.util.Objects;\n \n /**\n  * Statistics key.\n  */\n-public class StatsKey {\n+public class StatsKey implements Serializable {", "originalCommit": "3e805fd86dc11b66f2824b7b1bfa62ff5ec82da8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTc4NzE0NA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r545787144", "bodyText": "Obsolete implements, removed.", "author": "Berkof", "createdAt": "2020-12-18T12:00:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ5NjIwOA=="}], "type": "inlineReview", "revised_code": {"commit": "d8c6c6bb46b36bf8d36a0578e7c1813e04bfabfe", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatsKey.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatsKey.java\nindex f7572727076..ac9e28f1673 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatsKey.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatsKey.java\n", "chunk": "@@ -15,16 +15,12 @@\n  */\n package org.apache.ignite.internal.processors.query.stat;\n \n-import java.io.Serializable;\n import java.util.Objects;\n \n /**\n  * Statistics key.\n  */\n-public class StatsKey implements Serializable {\n-    /** */\n-    private static final long serialVersionUID = 0L;\n-\n+public class StatsKey {\n     /** Object schema. */\n     private final String schema;\n \n", "next_change": {"commit": "671a2471ef7d2a50a01f45f09289202a9528221d", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatsKey.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatsKey.java\nindex ac9e28f1673..f7572727076 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatsKey.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatsKey.java\n", "chunk": "@@ -15,12 +15,16 @@\n  */\n package org.apache.ignite.internal.processors.query.stat;\n \n+import java.io.Serializable;\n import java.util.Objects;\n \n /**\n  * Statistics key.\n  */\n-public class StatsKey {\n+public class StatsKey implements Serializable {\n+    /** */\n+    private static final long serialVersionUID = 0L;\n+\n     /** Object schema. */\n     private final String schema;\n \n", "next_change": {"commit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatsKey.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsKey.java\nsimilarity index 92%\nrename from modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatsKey.java\nrename to modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsKey.java\nindex f7572727076..a16117ab4e7 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatsKey.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsKey.java\n", "chunk": "@@ -21,7 +21,7 @@ import java.util.Objects;\n /**\n  * Statistics key.\n  */\n-public class StatsKey implements Serializable {\n+public class StatisticsKey implements Serializable {\n     /** */\n     private static final long serialVersionUID = 0L;\n \n", "next_change": null}]}}]}}]}}, {"oid": "ec4a9ef0e7691b605225c12527d496d07d573b42", "url": "https://github.com/gridgain/gridgain/commit/ec4a9ef0e7691b605225c12527d496d07d573b42", "message": "gg-31094: fix main issues with cluster wide collection", "committedDate": "2020-12-18T05:59:41Z", "type": "commit"}, {"oid": "b69634fd8544d7b27bd76f84bdee9a1e4f0ac470", "url": "https://github.com/gridgain/gridgain/commit/b69634fd8544d7b27bd76f84bdee9a1e4f0ac470", "message": "gg-31094: fix multiple local requests statistics handling.", "committedDate": "2020-12-18T07:30:11Z", "type": "commit"}, {"oid": "d8c6c6bb46b36bf8d36a0578e7c1813e04bfabfe", "url": "https://github.com/gridgain/gridgain/commit/d8c6c6bb46b36bf8d36a0578e7c1813e04bfabfe", "message": "gg-31094: minor fixes by review", "committedDate": "2020-12-18T12:23:00Z", "type": "commit"}, {"oid": "671a2471ef7d2a50a01f45f09289202a9528221d", "url": "https://github.com/gridgain/gridgain/commit/671a2471ef7d2a50a01f45f09289202a9528221d", "message": "Merge remote-tracking branch 'gridgain-ce/master' into gg-31094", "committedDate": "2020-12-21T08:37:07Z", "type": "commit"}, {"oid": "adb2fc38f05374d597d32f3164fa444dec40cb8f", "url": "https://github.com/gridgain/gridgain/commit/adb2fc38f05374d597d32f3164fa444dec40cb8f", "message": "GG-31094: more tests on collection process", "committedDate": "2020-12-21T11:00:05Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjY3MTQ3MA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546671470", "body": "it looks like statistics collection manager, so let's give it appropriate name", "bodyText": "it looks like statistics collection manager, so let's give it appropriate name", "bodyHTML": "<p dir=\"auto\">it looks like statistics collection manager, so let's give it appropriate name</p>", "author": "korlov42", "createdAt": "2020-12-21T12:09:41Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java", "diffHunk": "@@ -0,0 +1,381 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.lang.GridFunc;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsRequestCollection {", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjI4OTkxMw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556289913", "bodyText": "renamed", "author": "Berkof", "createdAt": "2021-01-13T06:30:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjY3MTQ3MA=="}], "type": "inlineReview", "revised_code": {"commit": "b595e90b5b480aaf80a9256558b1841334df97de", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\nindex 02fce6bdf6d..acb7c1d527e 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\n", "chunk": "@@ -27,21 +27,16 @@ import org.apache.ignite.internal.processors.query.stat.messages.StatsCollection\n import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n import org.apache.ignite.internal.util.GridArrays;\n-import org.apache.ignite.internal.util.lang.GridFunc;\n import org.apache.ignite.internal.util.typedef.F;\n \n import java.util.ArrayList;\n-import java.util.Arrays;\n import java.util.Collection;\n import java.util.HashMap;\n import java.util.HashSet;\n import java.util.List;\n import java.util.Map;\n-import java.util.Set;\n import java.util.UUID;\n import java.util.concurrent.ConcurrentHashMap;\n-import java.util.concurrent.locks.ReentrantReadWriteLock;\n-import java.util.function.Consumer;\n import java.util.function.Function;\n import java.util.stream.Collectors;\n \n", "next_change": {"commit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nsimilarity index 64%\nrename from modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\nrename to modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex acb7c1d527e..f0bc33ee4ba 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -36,17 +36,12 @@ import java.util.HashSet;\n import java.util.List;\n import java.util.Map;\n import java.util.UUID;\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.function.Function;\n import java.util.stream.Collectors;\n \n /**\n  * Current statistics collections with methods to work with it's messages.\n  */\n-public class IgniteStatisticsRequestCollection {\n-    /** Current collections, collection id to collection status map. */\n-    private final Map<UUID, StatCollectionStatus> currColls = new ConcurrentHashMap<>();\n-\n+public class IgniteStatisticsHelper {\n     /** Schema manager. */\n     private final SchemaManager schemaMgr;\n \n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjY3NDMyMw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546674323", "body": "could be final", "bodyText": "could be final", "bodyHTML": "<p dir=\"auto\">could be final</p>", "author": "korlov42", "createdAt": "2020-12-21T12:16:51Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java", "diffHunk": "@@ -0,0 +1,144 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+\n+/**\n+ * Statistics collection status by local or global request.\n+ */\n+public class StatCollectionStatus {\n+    /** Collection id. */\n+    private final UUID colId;\n+\n+    /** Keys to collect statistics by. */\n+    private Collection<StatsKeyMessage> keys;", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTAyNDU4Mw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555024583", "bodyText": "done", "author": "Berkof", "createdAt": "2021-01-11T12:50:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjY3NDMyMw=="}], "type": "inlineReview", "revised_code": {"commit": "29e078f2df2c845f1d97ba432d2033c88bdf6464", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringContext.java\nsimilarity index 68%\nrename from modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java\nrename to modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringContext.java\nindex 17eaefef074..2fcdc571f2a 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringContext.java\n", "chunk": "@@ -14,23 +14,23 @@ import java.util.concurrent.ConcurrentHashMap;\n import java.util.concurrent.ConcurrentMap;\n \n /**\n- * Statistics collection status by local or global request.\n+ * Statistics collection context by local or global request.\n  */\n-public class StatCollectionStatus {\n+public class StatisticsCollectionContext {\n     /** Collection id. */\n     private final UUID colId;\n \n     /** Keys to collect statistics by. */\n-    private Collection<StatsKeyMessage> keys;\n+    private Collection<StatisticsKeyMessage> keys;\n \n     /** Map request id to collection request. */\n-    private final ConcurrentMap<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs;\n+    private final ConcurrentMap<UUID, StatisticssAddrRequest<StatisticsGatheringRequest>> remainingColReqs;\n \n     /** Collected local statistics. */\n-    private final List<StatsCollectionResponse> locStatistics;\n+    private final List<StatisticsGatheringResponse> locStatistics;\n \n     /** Done future adapter. */\n-    private final StatsCollectionFutureAdapter doneFut;\n+    private final StatisticsCollectionFutureAdapter doneFut;\n \n     /**\n      * Constructor.\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjY3OTYyMg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546679622", "body": "both invocations of `locStatistics()` assumes that `locStatistics` is always non null value ", "bodyText": "both invocations of locStatistics() assumes that locStatistics is always non null value", "bodyHTML": "<p dir=\"auto\">both invocations of <code>locStatistics()</code> assumes that <code>locStatistics</code> is always non null value</p>", "author": "korlov42", "createdAt": "2020-12-21T12:29:38Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java", "diffHunk": "@@ -0,0 +1,144 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+\n+/**\n+ * Statistics collection status by local or global request.\n+ */\n+public class StatCollectionStatus {\n+    /** Collection id. */\n+    private final UUID colId;\n+\n+    /** Keys to collect statistics by. */\n+    private Collection<StatsKeyMessage> keys;\n+\n+    /** Map request id to collection request. */\n+    private final ConcurrentMap<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs;\n+\n+    /** Collected local statistics. */\n+    private final List<StatsCollectionResponse> locStatistics;\n+\n+    /** Done future adapter. */\n+    private final StatsCollectionFutureAdapter doneFut;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Keys to collect statistics by.\n+     * @param remainingColReqs Collection of remaining requests. If {@code null} - it's local collection task.\n+     */\n+    public StatCollectionStatus(\n+            UUID colId,\n+            Collection<StatsKeyMessage> keys,\n+            Map<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs\n+    ) {\n+        this.colId = colId;\n+        this.keys = keys;\n+        this.remainingColReqs = new ConcurrentHashMap<>(remainingColReqs);\n+        locStatistics = (remainingColReqs == null) ? null : Collections.synchronizedList(", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjI5MDMyNw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556290327", "bodyText": "fixed", "author": "Berkof", "createdAt": "2021-01-13T06:31:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjY3OTYyMg=="}], "type": "inlineReview", "revised_code": {"commit": "b595e90b5b480aaf80a9256558b1841334df97de", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java\nindex 17eaefef074..e900af0fd13 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java\n", "chunk": "@@ -46,7 +46,7 @@ public class StatCollectionStatus {\n     ) {\n         this.colId = colId;\n         this.keys = keys;\n-        this.remainingColReqs = new ConcurrentHashMap<>(remainingColReqs);\n+        this.remainingColReqs = (remainingColReqs == null) ? null : new ConcurrentHashMap<>(remainingColReqs);\n         locStatistics = (remainingColReqs == null) ? null : Collections.synchronizedList(\n                 new ArrayList<>(remainingColReqs.size()));\n         this.doneFut = new StatsCollectionFutureAdapter(colId);;\n", "next_change": {"commit": "29e078f2df2c845f1d97ba432d2033c88bdf6464", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringContext.java\nsimilarity index 71%\nrename from modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java\nrename to modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringContext.java\nindex e900af0fd13..2fcdc571f2a 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringContext.java\n", "chunk": "@@ -39,23 +39,23 @@ public class StatCollectionStatus {\n      * @param keys Keys to collect statistics by.\n      * @param remainingColReqs Collection of remaining requests. If {@code null} - it's local collection task.\n      */\n-    public StatCollectionStatus(\n+    public StatisticsCollectionContext(\n             UUID colId,\n-            Collection<StatsKeyMessage> keys,\n-            Map<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs\n+            Collection<StatisticsKeyMessage> keys,\n+            Map<UUID, StatisticssAddrRequest<StatisticsGatheringRequest>> remainingColReqs\n     ) {\n         this.colId = colId;\n         this.keys = keys;\n         this.remainingColReqs = (remainingColReqs == null) ? null : new ConcurrentHashMap<>(remainingColReqs);\n         locStatistics = (remainingColReqs == null) ? null : Collections.synchronizedList(\n                 new ArrayList<>(remainingColReqs.size()));\n-        this.doneFut = new StatsCollectionFutureAdapter(colId);;\n+        this.doneFut = new StatisticsCollectionFutureAdapter(colId);;\n     }\n \n     /**\n      * @return Collection of keys to collect statistics by.\n      */\n-    public Collection<StatsKeyMessage> keys() {\n+    public Collection<StatisticsKeyMessage> keys() {\n         return keys;\n     }\n \n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjY4Mjk2NA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546682964", "body": "constructor ConcurrentHashMap requires non null argument", "bodyText": "constructor ConcurrentHashMap requires non null argument", "bodyHTML": "<p dir=\"auto\">constructor ConcurrentHashMap requires non null argument</p>", "author": "korlov42", "createdAt": "2020-12-21T12:37:58Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java", "diffHunk": "@@ -0,0 +1,144 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+\n+/**\n+ * Statistics collection status by local or global request.\n+ */\n+public class StatCollectionStatus {\n+    /** Collection id. */\n+    private final UUID colId;\n+\n+    /** Keys to collect statistics by. */\n+    private Collection<StatsKeyMessage> keys;\n+\n+    /** Map request id to collection request. */\n+    private final ConcurrentMap<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs;\n+\n+    /** Collected local statistics. */\n+    private final List<StatsCollectionResponse> locStatistics;\n+\n+    /** Done future adapter. */\n+    private final StatsCollectionFutureAdapter doneFut;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Keys to collect statistics by.\n+     * @param remainingColReqs Collection of remaining requests. If {@code null} - it's local collection task.\n+     */\n+    public StatCollectionStatus(\n+            UUID colId,\n+            Collection<StatsKeyMessage> keys,\n+            Map<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs\n+    ) {\n+        this.colId = colId;\n+        this.keys = keys;\n+        this.remainingColReqs = new ConcurrentHashMap<>(remainingColReqs);", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjI5MDUwOA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556290508", "bodyText": "removed from CollectionStatus", "author": "Berkof", "createdAt": "2021-01-13T06:32:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjY4Mjk2NA=="}], "type": "inlineReview", "revised_code": {"commit": "b595e90b5b480aaf80a9256558b1841334df97de", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java\nindex 17eaefef074..e900af0fd13 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java\n", "chunk": "@@ -46,7 +46,7 @@ public class StatCollectionStatus {\n     ) {\n         this.colId = colId;\n         this.keys = keys;\n-        this.remainingColReqs = new ConcurrentHashMap<>(remainingColReqs);\n+        this.remainingColReqs = (remainingColReqs == null) ? null : new ConcurrentHashMap<>(remainingColReqs);\n         locStatistics = (remainingColReqs == null) ? null : Collections.synchronizedList(\n                 new ArrayList<>(remainingColReqs.size()));\n         this.doneFut = new StatsCollectionFutureAdapter(colId);;\n", "next_change": {"commit": "29e078f2df2c845f1d97ba432d2033c88bdf6464", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringContext.java\nsimilarity index 71%\nrename from modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java\nrename to modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringContext.java\nindex e900af0fd13..2fcdc571f2a 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringContext.java\n", "chunk": "@@ -39,23 +39,23 @@ public class StatCollectionStatus {\n      * @param keys Keys to collect statistics by.\n      * @param remainingColReqs Collection of remaining requests. If {@code null} - it's local collection task.\n      */\n-    public StatCollectionStatus(\n+    public StatisticsCollectionContext(\n             UUID colId,\n-            Collection<StatsKeyMessage> keys,\n-            Map<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs\n+            Collection<StatisticsKeyMessage> keys,\n+            Map<UUID, StatisticssAddrRequest<StatisticsGatheringRequest>> remainingColReqs\n     ) {\n         this.colId = colId;\n         this.keys = keys;\n         this.remainingColReqs = (remainingColReqs == null) ? null : new ConcurrentHashMap<>(remainingColReqs);\n         locStatistics = (remainingColReqs == null) ? null : Collections.synchronizedList(\n                 new ArrayList<>(remainingColReqs.size()));\n-        this.doneFut = new StatsCollectionFutureAdapter(colId);;\n+        this.doneFut = new StatisticsCollectionFutureAdapter(colId);;\n     }\n \n     /**\n      * @return Collection of keys to collect statistics by.\n      */\n-    public Collection<StatsKeyMessage> keys() {\n+    public Collection<StatisticsKeyMessage> keys() {\n         return keys;\n     }\n \n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjY5NTM5Mg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546695392", "body": "possible NPE here", "bodyText": "possible NPE here", "bodyHTML": "<p dir=\"auto\">possible NPE here</p>", "author": "korlov42", "createdAt": "2020-12-21T13:07:05Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java", "diffHunk": "@@ -0,0 +1,144 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+\n+/**\n+ * Statistics collection status by local or global request.\n+ */\n+public class StatCollectionStatus {\n+    /** Collection id. */\n+    private final UUID colId;\n+\n+    /** Keys to collect statistics by. */\n+    private Collection<StatsKeyMessage> keys;\n+\n+    /** Map request id to collection request. */\n+    private final ConcurrentMap<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs;\n+\n+    /** Collected local statistics. */\n+    private final List<StatsCollectionResponse> locStatistics;\n+\n+    /** Done future adapter. */\n+    private final StatsCollectionFutureAdapter doneFut;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Keys to collect statistics by.\n+     * @param remainingColReqs Collection of remaining requests. If {@code null} - it's local collection task.\n+     */\n+    public StatCollectionStatus(\n+            UUID colId,\n+            Collection<StatsKeyMessage> keys,\n+            Map<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs\n+    ) {\n+        this.colId = colId;\n+        this.keys = keys;\n+        this.remainingColReqs = new ConcurrentHashMap<>(remainingColReqs);\n+        locStatistics = (remainingColReqs == null) ? null : Collections.synchronizedList(\n+                new ArrayList<>(remainingColReqs.size()));\n+        this.doneFut = new StatsCollectionFutureAdapter(colId);;\n+    }\n+\n+    /**\n+     * @return Collection of keys to collect statistics by.\n+     */\n+    public Collection<StatsKeyMessage> keys() {\n+        return keys;\n+    }\n+\n+    /**\n+     * Register collected response. If the response contains not all requested partitions - replace should be called\n+     * instead.\n+     *\n+     * @param resp Collection response to register.\n+     * @return {@code true} if all request finished and global statistics could be aggregated,\n+     *     {@code false} - otherwise.\n+     */\n+    public boolean registerCollected(StatsCollectionResponse resp) {\n+        assert colId.equals(resp.colId());\n+\n+        locStatistics.add(resp);", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTAyNDk3Ng==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555024976", "bodyText": "fixed", "author": "Berkof", "createdAt": "2021-01-11T12:51:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjY5NTM5Mg=="}], "type": "inlineReview", "revised_code": {"commit": "29e078f2df2c845f1d97ba432d2033c88bdf6464", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringContext.java\nsimilarity index 68%\nrename from modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java\nrename to modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringContext.java\nindex 17eaefef074..2fcdc571f2a 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringContext.java\n", "chunk": "@@ -67,7 +67,7 @@ public class StatCollectionStatus {\n      * @return {@code true} if all request finished and global statistics could be aggregated,\n      *     {@code false} - otherwise.\n      */\n-    public boolean registerCollected(StatsCollectionResponse resp) {\n+    public boolean registerCollected(StatisticsGatheringResponse resp) {\n         assert colId.equals(resp.colId());\n \n         locStatistics.add(resp);\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjY5NjM3MA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546696370", "body": "btw it is not used anywhere, so let's remove it", "bodyText": "btw it is not used anywhere, so let's remove it", "bodyHTML": "<p dir=\"auto\">btw it is not used anywhere, so let's remove it</p>", "author": "korlov42", "createdAt": "2020-12-21T13:09:22Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java", "diffHunk": "@@ -0,0 +1,144 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+\n+/**\n+ * Statistics collection status by local or global request.\n+ */\n+public class StatCollectionStatus {\n+    /** Collection id. */\n+    private final UUID colId;\n+\n+    /** Keys to collect statistics by. */\n+    private Collection<StatsKeyMessage> keys;\n+\n+    /** Map request id to collection request. */\n+    private final ConcurrentMap<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs;\n+\n+    /** Collected local statistics. */\n+    private final List<StatsCollectionResponse> locStatistics;\n+\n+    /** Done future adapter. */\n+    private final StatsCollectionFutureAdapter doneFut;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Keys to collect statistics by.\n+     * @param remainingColReqs Collection of remaining requests. If {@code null} - it's local collection task.\n+     */\n+    public StatCollectionStatus(\n+            UUID colId,\n+            Collection<StatsKeyMessage> keys,\n+            Map<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs\n+    ) {\n+        this.colId = colId;\n+        this.keys = keys;\n+        this.remainingColReqs = new ConcurrentHashMap<>(remainingColReqs);\n+        locStatistics = (remainingColReqs == null) ? null : Collections.synchronizedList(\n+                new ArrayList<>(remainingColReqs.size()));\n+        this.doneFut = new StatsCollectionFutureAdapter(colId);;\n+    }\n+\n+    /**\n+     * @return Collection of keys to collect statistics by.\n+     */\n+    public Collection<StatsKeyMessage> keys() {\n+        return keys;\n+    }\n+\n+    /**\n+     * Register collected response. If the response contains not all requested partitions - replace should be called\n+     * instead.\n+     *\n+     * @param resp Collection response to register.\n+     * @return {@code true} if all request finished and global statistics could be aggregated,\n+     *     {@code false} - otherwise.\n+     */\n+    public boolean registerCollected(StatsCollectionResponse resp) {", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA0Mjk3Ng==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r560042976", "bodyText": "now its used again", "author": "Berkof", "createdAt": "2021-01-19T09:44:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjY5NjM3MA=="}], "type": "inlineReview", "revised_code": {"commit": "29e078f2df2c845f1d97ba432d2033c88bdf6464", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringContext.java\nsimilarity index 68%\nrename from modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java\nrename to modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringContext.java\nindex 17eaefef074..2fcdc571f2a 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringContext.java\n", "chunk": "@@ -67,7 +67,7 @@ public class StatCollectionStatus {\n      * @return {@code true} if all request finished and global statistics could be aggregated,\n      *     {@code false} - otherwise.\n      */\n-    public boolean registerCollected(StatsCollectionResponse resp) {\n+    public boolean registerCollected(StatisticsGatheringResponse resp) {\n         assert colId.equals(resp.colId());\n \n         locStatistics.add(resp);\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjY5NjYwMA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546696600", "body": "possible NPE here", "bodyText": "possible NPE here", "bodyHTML": "<p dir=\"auto\">possible NPE here</p>", "author": "korlov42", "createdAt": "2020-12-21T13:09:51Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java", "diffHunk": "@@ -0,0 +1,144 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+\n+/**\n+ * Statistics collection status by local or global request.\n+ */\n+public class StatCollectionStatus {\n+    /** Collection id. */\n+    private final UUID colId;\n+\n+    /** Keys to collect statistics by. */\n+    private Collection<StatsKeyMessage> keys;\n+\n+    /** Map request id to collection request. */\n+    private final ConcurrentMap<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs;\n+\n+    /** Collected local statistics. */\n+    private final List<StatsCollectionResponse> locStatistics;\n+\n+    /** Done future adapter. */\n+    private final StatsCollectionFutureAdapter doneFut;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Keys to collect statistics by.\n+     * @param remainingColReqs Collection of remaining requests. If {@code null} - it's local collection task.\n+     */\n+    public StatCollectionStatus(\n+            UUID colId,\n+            Collection<StatsKeyMessage> keys,\n+            Map<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs\n+    ) {\n+        this.colId = colId;\n+        this.keys = keys;\n+        this.remainingColReqs = new ConcurrentHashMap<>(remainingColReqs);\n+        locStatistics = (remainingColReqs == null) ? null : Collections.synchronizedList(\n+                new ArrayList<>(remainingColReqs.size()));\n+        this.doneFut = new StatsCollectionFutureAdapter(colId);;\n+    }\n+\n+    /**\n+     * @return Collection of keys to collect statistics by.\n+     */\n+    public Collection<StatsKeyMessage> keys() {\n+        return keys;\n+    }\n+\n+    /**\n+     * Register collected response. If the response contains not all requested partitions - replace should be called\n+     * instead.\n+     *\n+     * @param resp Collection response to register.\n+     * @return {@code true} if all request finished and global statistics could be aggregated,\n+     *     {@code false} - otherwise.\n+     */\n+    public boolean registerCollected(StatsCollectionResponse resp) {\n+        assert colId.equals(resp.colId());\n+\n+        locStatistics.add(resp);\n+        remainingColReqs.remove(resp.reqId());\n+        return remainingColReqs.isEmpty();\n+    }\n+\n+    /**\n+     * Replace collection of old requests with new ones. Should be called on receiving response with not all requested\n+     * partitions.\n+     *\n+     * @param oldReqIds Old request id to remove from state.\n+     * @param newReqs new requests to add to the state.\n+     * @param resp Collected response to add to the state.\n+     */\n+    public void replaceStatsCollectionRequest(\n+        UUID oldReqId,\n+        Map<UUID, StatsAddrRequest<StatsCollectionRequest>> newReqs,\n+        StatsCollectionResponse resp\n+    ) {\n+        locStatistics.add(resp);", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA0MzM5MA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r560043390", "bodyText": "outdated", "author": "Berkof", "createdAt": "2021-01-19T09:45:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjY5NjYwMA=="}], "type": "inlineReview", "revised_code": {"commit": "29e078f2df2c845f1d97ba432d2033c88bdf6464", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringContext.java\nsimilarity index 68%\nrename from modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java\nrename to modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringContext.java\nindex 17eaefef074..2fcdc571f2a 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringContext.java\n", "chunk": "@@ -85,8 +85,8 @@ public class StatCollectionStatus {\n      */\n     public void replaceStatsCollectionRequest(\n         UUID oldReqId,\n-        Map<UUID, StatsAddrRequest<StatsCollectionRequest>> newReqs,\n-        StatsCollectionResponse resp\n+        Map<UUID, StatisticssAddrRequest<StatisticsGatheringRequest>> newReqs,\n+        StatisticsGatheringResponse resp\n     ) {\n         locStatistics.add(resp);\n         remainingColReqs.putAll(newReqs);\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjY5NzAzMw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546697033", "body": "this is not used as well", "bodyText": "this is not used as well", "bodyHTML": "<p dir=\"auto\">this is not used as well</p>", "author": "korlov42", "createdAt": "2020-12-21T13:10:52Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java", "diffHunk": "@@ -0,0 +1,144 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+\n+/**\n+ * Statistics collection status by local or global request.\n+ */\n+public class StatCollectionStatus {\n+    /** Collection id. */\n+    private final UUID colId;\n+\n+    /** Keys to collect statistics by. */\n+    private Collection<StatsKeyMessage> keys;\n+\n+    /** Map request id to collection request. */\n+    private final ConcurrentMap<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs;\n+\n+    /** Collected local statistics. */\n+    private final List<StatsCollectionResponse> locStatistics;\n+\n+    /** Done future adapter. */\n+    private final StatsCollectionFutureAdapter doneFut;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Keys to collect statistics by.\n+     * @param remainingColReqs Collection of remaining requests. If {@code null} - it's local collection task.\n+     */\n+    public StatCollectionStatus(\n+            UUID colId,\n+            Collection<StatsKeyMessage> keys,\n+            Map<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs\n+    ) {\n+        this.colId = colId;\n+        this.keys = keys;\n+        this.remainingColReqs = new ConcurrentHashMap<>(remainingColReqs);\n+        locStatistics = (remainingColReqs == null) ? null : Collections.synchronizedList(\n+                new ArrayList<>(remainingColReqs.size()));\n+        this.doneFut = new StatsCollectionFutureAdapter(colId);;\n+    }\n+\n+    /**\n+     * @return Collection of keys to collect statistics by.\n+     */\n+    public Collection<StatsKeyMessage> keys() {\n+        return keys;\n+    }\n+\n+    /**\n+     * Register collected response. If the response contains not all requested partitions - replace should be called\n+     * instead.\n+     *\n+     * @param resp Collection response to register.\n+     * @return {@code true} if all request finished and global statistics could be aggregated,\n+     *     {@code false} - otherwise.\n+     */\n+    public boolean registerCollected(StatsCollectionResponse resp) {\n+        assert colId.equals(resp.colId());\n+\n+        locStatistics.add(resp);\n+        remainingColReqs.remove(resp.reqId());\n+        return remainingColReqs.isEmpty();\n+    }\n+\n+    /**\n+     * Replace collection of old requests with new ones. Should be called on receiving response with not all requested\n+     * partitions.\n+     *\n+     * @param oldReqIds Old request id to remove from state.\n+     * @param newReqs new requests to add to the state.\n+     * @param resp Collected response to add to the state.\n+     */\n+    public void replaceStatsCollectionRequest(", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "29e078f2df2c845f1d97ba432d2033c88bdf6464", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringContext.java\nsimilarity index 68%\nrename from modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java\nrename to modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringContext.java\nindex 17eaefef074..2fcdc571f2a 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringContext.java\n", "chunk": "@@ -85,8 +85,8 @@ public class StatCollectionStatus {\n      */\n     public void replaceStatsCollectionRequest(\n         UUID oldReqId,\n-        Map<UUID, StatsAddrRequest<StatsCollectionRequest>> newReqs,\n-        StatsCollectionResponse resp\n+        Map<UUID, StatisticssAddrRequest<StatisticsGatheringRequest>> newReqs,\n+        StatisticsGatheringResponse resp\n     ) {\n         locStatistics.add(resp);\n         remainingColReqs.putAll(newReqs);\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjY5NzEyOQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546697129", "body": "misspell in param name", "bodyText": "misspell in param name", "bodyHTML": "<p dir=\"auto\">misspell in param name</p>", "author": "korlov42", "createdAt": "2020-12-21T13:11:08Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java", "diffHunk": "@@ -0,0 +1,144 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+\n+/**\n+ * Statistics collection status by local or global request.\n+ */\n+public class StatCollectionStatus {\n+    /** Collection id. */\n+    private final UUID colId;\n+\n+    /** Keys to collect statistics by. */\n+    private Collection<StatsKeyMessage> keys;\n+\n+    /** Map request id to collection request. */\n+    private final ConcurrentMap<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs;\n+\n+    /** Collected local statistics. */\n+    private final List<StatsCollectionResponse> locStatistics;\n+\n+    /** Done future adapter. */\n+    private final StatsCollectionFutureAdapter doneFut;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Keys to collect statistics by.\n+     * @param remainingColReqs Collection of remaining requests. If {@code null} - it's local collection task.\n+     */\n+    public StatCollectionStatus(\n+            UUID colId,\n+            Collection<StatsKeyMessage> keys,\n+            Map<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs\n+    ) {\n+        this.colId = colId;\n+        this.keys = keys;\n+        this.remainingColReqs = new ConcurrentHashMap<>(remainingColReqs);\n+        locStatistics = (remainingColReqs == null) ? null : Collections.synchronizedList(\n+                new ArrayList<>(remainingColReqs.size()));\n+        this.doneFut = new StatsCollectionFutureAdapter(colId);;\n+    }\n+\n+    /**\n+     * @return Collection of keys to collect statistics by.\n+     */\n+    public Collection<StatsKeyMessage> keys() {\n+        return keys;\n+    }\n+\n+    /**\n+     * Register collected response. If the response contains not all requested partitions - replace should be called\n+     * instead.\n+     *\n+     * @param resp Collection response to register.\n+     * @return {@code true} if all request finished and global statistics could be aggregated,\n+     *     {@code false} - otherwise.\n+     */\n+    public boolean registerCollected(StatsCollectionResponse resp) {\n+        assert colId.equals(resp.colId());\n+\n+        locStatistics.add(resp);\n+        remainingColReqs.remove(resp.reqId());\n+        return remainingColReqs.isEmpty();\n+    }\n+\n+    /**\n+     * Replace collection of old requests with new ones. Should be called on receiving response with not all requested\n+     * partitions.\n+     *\n+     * @param oldReqIds Old request id to remove from state.", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java\ndeleted file mode 100644\nindex 17eaefef074..00000000000\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java\n+++ /dev/null\n", "chunk": "@@ -1,144 +0,0 @@\n-package org.apache.ignite.internal.processors.query.stat;\n-\n-import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n-import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n-import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n-\n-import java.util.ArrayList;\n-import java.util.Collection;\n-import java.util.Collections;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.UUID;\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.concurrent.ConcurrentMap;\n-\n-/**\n- * Statistics collection status by local or global request.\n- */\n-public class StatCollectionStatus {\n-    /** Collection id. */\n-    private final UUID colId;\n-\n-    /** Keys to collect statistics by. */\n-    private Collection<StatsKeyMessage> keys;\n-\n-    /** Map request id to collection request. */\n-    private final ConcurrentMap<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs;\n-\n-    /** Collected local statistics. */\n-    private final List<StatsCollectionResponse> locStatistics;\n-\n-    /** Done future adapter. */\n-    private final StatsCollectionFutureAdapter doneFut;\n-\n-    /**\n-     * Constructor.\n-     *\n-     * @param colId Collection id.\n-     * @param keys Keys to collect statistics by.\n-     * @param remainingColReqs Collection of remaining requests. If {@code null} - it's local collection task.\n-     */\n-    public StatCollectionStatus(\n-            UUID colId,\n-            Collection<StatsKeyMessage> keys,\n-            Map<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs\n-    ) {\n-        this.colId = colId;\n-        this.keys = keys;\n-        this.remainingColReqs = new ConcurrentHashMap<>(remainingColReqs);\n-        locStatistics = (remainingColReqs == null) ? null : Collections.synchronizedList(\n-                new ArrayList<>(remainingColReqs.size()));\n-        this.doneFut = new StatsCollectionFutureAdapter(colId);;\n-    }\n-\n-    /**\n-     * @return Collection of keys to collect statistics by.\n-     */\n-    public Collection<StatsKeyMessage> keys() {\n-        return keys;\n-    }\n-\n-    /**\n-     * Register collected response. If the response contains not all requested partitions - replace should be called\n-     * instead.\n-     *\n-     * @param resp Collection response to register.\n-     * @return {@code true} if all request finished and global statistics could be aggregated,\n-     *     {@code false} - otherwise.\n-     */\n-    public boolean registerCollected(StatsCollectionResponse resp) {\n-        assert colId.equals(resp.colId());\n-\n-        locStatistics.add(resp);\n-        remainingColReqs.remove(resp.reqId());\n-        return remainingColReqs.isEmpty();\n-    }\n-\n-    /**\n-     * Replace collection of old requests with new ones. Should be called on receiving response with not all requested\n-     * partitions.\n-     *\n-     * @param oldReqIds Old request id to remove from state.\n-     * @param newReqs new requests to add to the state.\n-     * @param resp Collected response to add to the state.\n-     */\n-    public void replaceStatsCollectionRequest(\n-        UUID oldReqId,\n-        Map<UUID, StatsAddrRequest<StatsCollectionRequest>> newReqs,\n-        StatsCollectionResponse resp\n-    ) {\n-        locStatistics.add(resp);\n-        remainingColReqs.putAll(newReqs);\n-        remainingColReqs.remove(oldReqId);\n-    }\n-\n-    /**\n-     * Remove all requests to specified node id (due to its failure).\n-     *\n-     * @param nodeId node id to remove requests by.\n-     * @return Collection of removed requests.\n-     */\n-    public Collection<StatsCollectionRequest> removeNodeRequest(UUID nodeId) {\n-        Collection<StatsCollectionRequest> res = new ArrayList<>();\n-\n-        remainingColReqs.values().removeIf(req -> {\n-            if (nodeId.equals(req.nodeId())) {\n-                res.add(req.req());\n-\n-                return true;\n-            }\n-            return false;\n-        });\n-\n-        return res;\n-    }\n-\n-    /**\n-     * @return Collection id.\n-     */\n-    public UUID colId() {\n-        return colId;\n-    }\n-\n-    /**\n-     * @return Map request id to collection request.\n-     */\n-    public Map<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingCollectionReqs() {\n-        return remainingColReqs;\n-    }\n-\n-    /**\n-     * @return Collected local statistics.\n-     */\n-    public List<StatsCollectionResponse> localStatistics() {\n-        return locStatistics;\n-    }\n-\n-    /**\n-     * @return Collection control future.\n-     */\n-    public StatsCollectionFutureAdapter doneFut() {\n-        return doneFut;\n-    }\n-}\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjcwMzU0OQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546703549", "body": "not used", "bodyText": "not used", "bodyHTML": "<p dir=\"auto\">not used</p>", "author": "korlov42", "createdAt": "2020-12-21T13:24:54Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java", "diffHunk": "@@ -0,0 +1,144 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+\n+/**\n+ * Statistics collection status by local or global request.\n+ */\n+public class StatCollectionStatus {\n+    /** Collection id. */\n+    private final UUID colId;\n+\n+    /** Keys to collect statistics by. */\n+    private Collection<StatsKeyMessage> keys;\n+\n+    /** Map request id to collection request. */\n+    private final ConcurrentMap<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs;\n+\n+    /** Collected local statistics. */\n+    private final List<StatsCollectionResponse> locStatistics;\n+\n+    /** Done future adapter. */\n+    private final StatsCollectionFutureAdapter doneFut;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Keys to collect statistics by.\n+     * @param remainingColReqs Collection of remaining requests. If {@code null} - it's local collection task.\n+     */\n+    public StatCollectionStatus(\n+            UUID colId,\n+            Collection<StatsKeyMessage> keys,\n+            Map<UUID, StatsAddrRequest<StatsCollectionRequest>> remainingColReqs\n+    ) {\n+        this.colId = colId;\n+        this.keys = keys;\n+        this.remainingColReqs = new ConcurrentHashMap<>(remainingColReqs);\n+        locStatistics = (remainingColReqs == null) ? null : Collections.synchronizedList(\n+                new ArrayList<>(remainingColReqs.size()));\n+        this.doneFut = new StatsCollectionFutureAdapter(colId);;\n+    }\n+\n+    /**\n+     * @return Collection of keys to collect statistics by.\n+     */\n+    public Collection<StatsKeyMessage> keys() {\n+        return keys;\n+    }\n+\n+    /**\n+     * Register collected response. If the response contains not all requested partitions - replace should be called\n+     * instead.\n+     *\n+     * @param resp Collection response to register.\n+     * @return {@code true} if all request finished and global statistics could be aggregated,\n+     *     {@code false} - otherwise.\n+     */\n+    public boolean registerCollected(StatsCollectionResponse resp) {\n+        assert colId.equals(resp.colId());\n+\n+        locStatistics.add(resp);\n+        remainingColReqs.remove(resp.reqId());\n+        return remainingColReqs.isEmpty();\n+    }\n+\n+    /**\n+     * Replace collection of old requests with new ones. Should be called on receiving response with not all requested\n+     * partitions.\n+     *\n+     * @param oldReqIds Old request id to remove from state.\n+     * @param newReqs new requests to add to the state.\n+     * @param resp Collected response to add to the state.\n+     */\n+    public void replaceStatsCollectionRequest(\n+        UUID oldReqId,\n+        Map<UUID, StatsAddrRequest<StatsCollectionRequest>> newReqs,\n+        StatsCollectionResponse resp\n+    ) {\n+        locStatistics.add(resp);\n+        remainingColReqs.putAll(newReqs);\n+        remainingColReqs.remove(oldReqId);\n+    }\n+\n+    /**\n+     * Remove all requests to specified node id (due to its failure).\n+     *\n+     * @param nodeId node id to remove requests by.\n+     * @return Collection of removed requests.\n+     */\n+    public Collection<StatsCollectionRequest> removeNodeRequest(UUID nodeId) {", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "29e078f2df2c845f1d97ba432d2033c88bdf6464", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringContext.java\nsimilarity index 68%\nrename from modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java\nrename to modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringContext.java\nindex 17eaefef074..2fcdc571f2a 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatCollectionStatus.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringContext.java\n", "chunk": "@@ -99,8 +99,8 @@ public class StatCollectionStatus {\n      * @param nodeId node id to remove requests by.\n      * @return Collection of removed requests.\n      */\n-    public Collection<StatsCollectionRequest> removeNodeRequest(UUID nodeId) {\n-        Collection<StatsCollectionRequest> res = new ArrayList<>();\n+    public Collection<StatisticsGatheringRequest> removeNodeRequest(UUID nodeId) {\n+        Collection<StatisticsGatheringRequest> res = new ArrayList<>();\n \n         remainingColReqs.values().removeIf(req -> {\n             if (nodeId.equals(req.nodeId())) {\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc2MDYyMw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546760623", "body": "Is there any reason to have this as a field? ", "bodyText": "Is there any reason to have this as a field?", "bodyHTML": "<p dir=\"auto\">Is there any reason to have this as a field?</p>", "author": "korlov42", "createdAt": "2020-12-21T15:12:58Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -18,35 +18,73 @@\n import java.util.ArrayList;\n import java.util.Arrays;\n import java.util.Collection;\n+import java.util.Collections;\n import java.util.HashMap;\n import java.util.HashSet;\n import java.util.List;\n import java.util.Map;\n import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.function.Supplier;\n import java.util.stream.Collectors;\n \n import org.apache.ignite.IgniteCheckedException;\n import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.configuration.IgniteConfiguration;\n+import org.apache.ignite.events.DiscoveryEvent;\n+import org.apache.ignite.events.Event;\n+import org.apache.ignite.events.EventType;\n import org.apache.ignite.internal.GridKernalContext;\n+import org.apache.ignite.internal.GridTopic;\n+import org.apache.ignite.internal.managers.communication.GridIoPolicy;\n+import org.apache.ignite.internal.managers.communication.GridMessageListener;\n+import org.apache.ignite.internal.managers.eventstorage.GridLocalEventListener;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n import org.apache.ignite.internal.processors.cache.GridCacheUtils;\n import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtLocalPartition;\n+import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionState;\n+import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionTopology;\n import org.apache.ignite.internal.processors.cache.persistence.CacheDataRow;\n import org.apache.ignite.internal.processors.cache.persistence.IgniteCacheDatabaseSharedManager;\n import org.apache.ignite.internal.processors.query.GridQueryTypeDescriptor;\n import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n import org.apache.ignite.internal.processors.query.h2.opt.GridH2RowDescriptor;\n import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n import org.apache.ignite.internal.processors.query.h2.opt.H2Row;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.CancelStatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsPropagationMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsGetRequest;\n+import org.apache.ignite.internal.util.lang.GridTuple3;\n import org.apache.ignite.internal.util.typedef.F;\n+import org.apache.ignite.lang.IgniteBiTuple;\n+import org.apache.ignite.plugin.extensions.communication.Message;\n+import org.apache.ignite.thread.IgniteThreadPoolExecutor;\n import org.gridgain.internal.h2.table.Column;\n+import org.jetbrains.annotations.Nullable;\n \n import static org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionState.MOVING;\n import static org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionState.OWNING;\n \n /**\n  * Statistics manager implementation.\n  */\n-public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n+public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, GridMessageListener {\n+    /** Statistics related messages topic name. */\n+    private static final Object TOPIC = GridTopic.TOPIC_CACHE.topic(\"statistics\");\n+\n+    /** Size of statistics collection pool. */\n+    private static final int STATS_POOL_SIZE = 1;\n+\n+    /** Node left listener to complete statistics collection tasks without left nodes. */\n+    private final NodeLeftListener nodeLeftLsnr;", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM1MDQyMA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549350420", "bodyText": "My guess is the manager should be unsubscribed on stop\\deactivation.", "author": "AMashenkov", "createdAt": "2020-12-28T13:36:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc2MDYyMw=="}], "type": "inlineReview", "revised_code": {"commit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 0f88eff3479..f208a744d01 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -20,71 +20,44 @@ import java.util.Arrays;\n import java.util.Collection;\n import java.util.Collections;\n import java.util.HashMap;\n-import java.util.HashSet;\n import java.util.List;\n import java.util.Map;\n import java.util.Set;\n import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n import java.util.concurrent.LinkedBlockingQueue;\n-import java.util.function.Supplier;\n import java.util.stream.Collectors;\n \n import org.apache.ignite.IgniteCheckedException;\n import org.apache.ignite.IgniteLogger;\n-import org.apache.ignite.cluster.ClusterNode;\n import org.apache.ignite.configuration.IgniteConfiguration;\n-import org.apache.ignite.events.DiscoveryEvent;\n-import org.apache.ignite.events.Event;\n-import org.apache.ignite.events.EventType;\n import org.apache.ignite.internal.GridKernalContext;\n-import org.apache.ignite.internal.GridTopic;\n import org.apache.ignite.internal.managers.communication.GridIoPolicy;\n-import org.apache.ignite.internal.managers.communication.GridMessageListener;\n-import org.apache.ignite.internal.managers.eventstorage.GridLocalEventListener;\n-import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n import org.apache.ignite.internal.processors.cache.GridCacheUtils;\n-import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtLocalPartition;\n import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionState;\n-import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionTopology;\n-import org.apache.ignite.internal.processors.cache.persistence.CacheDataRow;\n import org.apache.ignite.internal.processors.cache.persistence.IgniteCacheDatabaseSharedManager;\n-import org.apache.ignite.internal.processors.query.GridQueryTypeDescriptor;\n import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n-import org.apache.ignite.internal.processors.query.h2.opt.GridH2RowDescriptor;\n import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n-import org.apache.ignite.internal.processors.query.h2.opt.H2Row;\n-import org.apache.ignite.internal.processors.query.stat.messages.StatsClearRequest;\n-import org.apache.ignite.internal.processors.query.stat.messages.CancelStatsCollectionRequest;\n-import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n-import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n-import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n-import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n-import org.apache.ignite.internal.processors.query.stat.messages.StatsPropagationMessage;\n-import org.apache.ignite.internal.processors.query.stat.messages.StatsGetRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.CancelStatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n import org.apache.ignite.internal.util.lang.GridTuple3;\n import org.apache.ignite.internal.util.typedef.F;\n import org.apache.ignite.lang.IgniteBiTuple;\n-import org.apache.ignite.plugin.extensions.communication.Message;\n import org.apache.ignite.thread.IgniteThreadPoolExecutor;\n-import org.gridgain.internal.h2.table.Column;\n-import org.jetbrains.annotations.Nullable;\n \n-import static org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionState.MOVING;\n import static org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionState.OWNING;\n \n /**\n  * Statistics manager implementation.\n  */\n-public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, GridMessageListener {\n-    /** Statistics related messages topic name. */\n-    private static final Object TOPIC = GridTopic.TOPIC_CACHE.topic(\"statistics\");\n-\n+public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n     /** Size of statistics collection pool. */\n     private static final int STATS_POOL_SIZE = 1;\n \n-    /** Node left listener to complete statistics collection tasks without left nodes. */\n-    private final NodeLeftListener nodeLeftLsnr;\n-\n     /** Logger. */\n     private final IgniteLogger log;\n \n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc2NjMzMQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546766331", "body": "this class could be static", "bodyText": "this class could be static", "bodyHTML": "<p dir=\"auto\">this class could be static</p>", "author": "korlov42", "createdAt": "2020-12-21T15:23:18Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -278,4 +614,373 @@ private ObjectStatisticsImpl aggregateLocalStatistics(\n \n         return tblStats;\n     }\n+\n+    /**\n+     * Receive and handle statistics propagation message with partitions statistics.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receivePartitionsStatistics(UUID nodeId, StatsPropagationMessage msg) throws IgniteCheckedException {\n+        UUID locNode = ctx.localNodeId();\n+        for (StatsObjectData partData : msg.data()) {\n+            StatsKey key = new StatsKey(partData.key().schema(), partData.key().obj());\n+\n+            assert partData.type() == StatsType.PARTITION : \"Got non partition level statistics by \" + key\n+                    + \" without request\";\n+\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d from node %s\", key.schema(),\n+                        key.obj(), partData.partId(), nodeId));\n+\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(locNode, partData.partId());\n+            if (partState != OWNING) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+\n+            ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n+\n+            statsRepos.saveLocalPartitionStatistics(key, opStat);\n+        }\n+    }\n+\n+    /**\n+     * Receive and handle statistics propagation message as response for collection request.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receiveLocalStatistics(UUID nodeId, StatsCollectionResponse msg) {\n+        assert msg.data().keySet().stream().noneMatch(pd -> pd.type() == StatsType.PARTITION)\n+                : \"Got partition statistics by request \" + msg.reqId();\n+\n+        currCollections.updateCollection(msg.colId(), stat -> {\n+            if (stat == null) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\n+                        \"Ignoring outdated local statistics collection response from node %s to col %s req %s\",\n+                            nodeId, msg.colId(), msg.reqId()));\n+\n+                return stat;\n+            }\n+\n+            assert stat.colId().equals(msg.colId());\n+\n+            // Need syncronization here to avoid races between removing remaining reqs and adding new ones.\n+            synchronized (stat) {\n+                StatsAddrRequest<StatsCollectionRequest> req = stat.remainingCollectionReqs().remove(msg.reqId());\n+\n+                if (req == null) {\n+                    if (log.isDebugEnabled())\n+                        log.debug(String.format(\n+                                \"Ignoring unknown local statistics collection response from node %s to col %s req %s\",\n+                                nodeId, msg.colId(), msg.reqId()));\n+\n+                    return stat;\n+                }\n+\n+                stat.localStatistics().add(msg);\n+                // TODO: reschedule if not all partition collected.\n+\n+                if (stat.remainingCollectionReqs().isEmpty()) {\n+                    Map<StatsKey, ObjectStatisticsImpl> mergedGlobal = finishStatCollection(stat);\n+\n+                    stat.doneFut().onDone(null);\n+\n+                    return null;\n+                }\n+            }\n+            return stat;\n+        });\n+    }\n+\n+    /**\n+     * Aggregate local statistics to global one.\n+     *\n+     * @param stat Statistics collection status to aggregate.\n+     * @return Map stats key to merged global statistics.\n+     */\n+    private Map<StatsKey, ObjectStatisticsImpl> finishStatCollection(StatCollectionStatus stat) {\n+        Map<StatsKeyMessage, Collection<ObjectStatisticsImpl>> keysStats = new HashMap<>();\n+        for (StatsCollectionResponse resp : stat.localStatistics()) {\n+            for (StatsObjectData objData : resp.data().keySet()) {\n+                keysStats.compute(objData.key(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+                    try {\n+                        ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n+\n+                        v.add(objStat);\n+                    } catch (IgniteCheckedException e) {\n+                        if (log.isInfoEnabled())\n+                            log.info(String.format(\"Unable to parse statistics for object %s from response %s\",\n+                                    objData.key(), resp.reqId()));\n+                    }\n+\n+                    return v;\n+                });\n+            }\n+        }\n+\n+        Map<StatsKey, ObjectStatisticsImpl> res = new HashMap<>();\n+        for (Map.Entry<StatsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : keysStats.entrySet()) {\n+            StatsKeyMessage keyMsg = keyStats.getKey();\n+            GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Unable to find object %s.%s to save collected statistics by.\",\n+                            keyMsg.schema(), keyMsg.obj()));\n+\n+                continue;\n+            }\n+            ObjectStatisticsImpl globalStat = aggregateLocalStatistics(keyMsg, keyStats.getValue());\n+            StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+            res.put(key, statsRepos.mergeGlobalStatistics(key, globalStat));\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Send statistics by request.\n+     *\n+     * @param nodeId Node to send statistics to.\n+     * @param msg Statistics request to process.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void supplyStatistics(UUID nodeId, StatsGetRequest msg) throws IgniteCheckedException {\n+        List<StatsObjectData> data = new ArrayList<>(msg.keys().size());\n+        for (StatsKeyMessage keyMsg : msg.keys()) {\n+            StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+            ObjectStatisticsImpl objStats = statsRepos.getGlobalStatistics(key);\n+\n+            if (objStats != null)\n+                data.add(StatisticsUtils.toObjectData(keyMsg, StatsType.GLOBAL, objStats));\n+        }\n+        StatsPropagationMessage res = new StatsPropagationMessage(data);\n+        ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n+    }\n+\n+    /**\n+     * Cancel local statistics collection task.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Cancel request.\n+     */\n+    private void cancelStatisticsCollection(UUID nodeId, CancelStatsCollectionRequest msg) {\n+        for (UUID reqId : msg.reqIds()) {\n+            currCollections.updateCollection(reqId, stat -> {\n+                if (stat == null) {\n+                    if (log.isDebugEnabled())\n+                        log.debug(String.format(\"Unable to cancel statistics collection %s by req %s from node %s\",\n+                                msg.colId(), reqId, nodeId));\n+\n+                    return null;\n+                }\n+\n+                stat.doneFut().cancel();\n+\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Cancelling statistics collection by colId = %s, reqId = %s from node %s\",\n+                            msg.colId(), reqId, nodeId));\n+\n+                return null;\n+            });\n+        }\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void onMessage(UUID nodeId, Object msg, byte plc) {\n+        try {\n+            if (msg instanceof StatsPropagationMessage)\n+                receivePartitionsStatistics(nodeId, (StatsPropagationMessage) msg);\n+            else if (msg instanceof StatsCollectionResponse)\n+                receiveLocalStatistics(nodeId, (StatsCollectionResponse) msg);\n+            else if (msg instanceof StatsGetRequest)\n+                supplyStatistics(nodeId, (StatsGetRequest) msg);\n+            else if (msg instanceof StatsCollectionRequest)\n+                handleCollectionRequest(nodeId, (StatsCollectionRequest)msg);\n+            else if (msg instanceof CancelStatsCollectionRequest)\n+                cancelStatisticsCollection(nodeId, (CancelStatsCollectionRequest) msg);\n+            else if (msg instanceof StatsClearRequest)\n+                clearObjectStatistics(nodeId, (StatsClearRequest)msg);\n+            else\n+                log.warning(\"Unknown msg \" + msg +  \" in statistics topic \" + TOPIC + \" from node \" + nodeId);\n+        } catch (IgniteCheckedException e) {\n+            log.warning(\"Statistic msg from node \" + nodeId + \" processing failed\", e);\n+        }\n+    }\n+\n+    /**\n+     * Handle statistics clear request.\n+     *\n+     * @param nodeId UUID of request sender node.\n+     * @param msg Clear request message.\n+     */\n+    private void clearObjectStatistics(UUID nodeId, StatsClearRequest msg) {\n+        for (StatsKeyMessage key : msg.keys()) {\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Clearing statistics by request %s from node %s by key %s.%s\", msg.reqId(),\n+                        nodeId, key.schema(), key.obj()));\n+            statMgmtPool.submit(() -> clearObjectStatisticsLocal(key));\n+        }\n+    }\n+\n+    /**\n+     * Collect local object statistics by specified request (possibly for a few objects) and send result back to origin\n+     * node specified. If local node id specified - process result without sending it throw the communication.\n+     *\n+     * @param req request to collect statistics by.\n+     */\n+    private void processLocal(UUID nodeId, StatsCollectionRequest req) {\n+        UUID locNode = ctx.localNodeId();\n+\n+        StatCollectionStatus stat = (nodeId.equals(locNode)) ? currCollections.getCollection(req.colId()) :\n+            currCollections.getCollection(req.reqId());\n+\n+        if (stat == null)\n+            return;\n+\n+        Map<StatsObjectData, int[]> collected = new HashMap<>(req.keys().size());\n+        for (Map.Entry<StatsKeyMessage, int[]> keyEntry : req.keys().entrySet()) {\n+            try {\n+                StatsKeyMessage key = keyEntry.getKey();\n+                IgniteBiTuple <ObjectStatisticsImpl, int[]> loStat = collectLocalObjectStatistics(key,\n+                        keyEntry.getValue(), () -> stat.doneFut().isCancelled());\n+                StatsKey statsKey = new StatsKey(key.schema(), key.obj());\n+\n+                // TODO?\n+                statsRepos.mergeLocalStatistics(statsKey, loStat.getKey());\n+\n+                StatsObjectData objData = StatisticsUtils.toObjectData(key, StatsType.LOCAL, loStat.getKey());\n+                collected.put(objData, loStat.getValue());\n+            }\n+            catch (IgniteCheckedException e) {\n+                log.warning(String.format(\"Unable to complete request %s due to error %s\", req.reqId(), e.getMessage()));\n+                // TODO: send cancel to originator node\n+            }\n+        }\n+\n+        StatsCollectionResponse res = new StatsCollectionResponse(req.colId(), req.reqId(), collected);\n+\n+        if (locNode.equals(nodeId))\n+            receiveLocalStatistics(nodeId, res);\n+        else {\n+            try {\n+                ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\n+                            \"Unable to send statistics collection result to node %s in response to colId %s, reqId %s\",\n+                        nodeId, req.colId(), req.reqId()));\n+            }\n+\n+            // Not local collection - remove by its reqId.\n+            currCollections.updateCollection(req.reqId(), s -> null);\n+        }\n+    }\n+\n+    /**\n+     * Schedule statistics collection by specified request.\n+     *\n+     * @param nodeId request origin node.\n+     * @param msg request message.\n+     */\n+    private void handleCollectionRequest(UUID nodeId, StatsCollectionRequest msg) {\n+        assert msg.reqId() != null : \"Got statistics collection request without request id\";\n+\n+        currCollections.addActiveCollectionStatus(msg.reqId(), new StatCollectionStatus(msg.colId(), msg.keys().keySet(), null));\n+\n+        statMgmtPool.submit(() -> processLocal(nodeId, msg));\n+    }\n+\n+    /**\n+     * Send requests to target nodes except of local one.\n+     *\n+     * @param reqs Collection of addressed requests to send.\n+     * @return Collection of addressed requests that has errors while sending or {@code null} if all requests was send\n+     * successfully.\n+     */\n+    private <T extends Message> Collection<StatsAddrRequest<T>> sendRequests(Collection<StatsAddrRequest<T>> reqs) {\n+        UUID locNode = ctx.localNodeId();\n+        Collection<StatsAddrRequest<T>> res = null;\n+\n+        for (StatsAddrRequest<T> req : reqs) {\n+            if (locNode.equals(req.nodeId()))\n+                continue;\n+\n+            try {\n+                ctx.io().sendToCustomTopic(req.nodeId(), TOPIC, req.req(), GridIoPolicy.QUERY_POOL);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (res == null)\n+                    res = new ArrayList<>();\n+\n+                res.add(req);\n+            }\n+        }\n+\n+        return res;\n+    }\n+\n+    /**\n+     * Handle node left event:\n+     * 1) Cancel all collection tasks which expect specified node statistics result.\n+     * 2) Cancel collection task requested by node left.\n+     *\n+     * @param nodeId leaved node id.\n+     */\n+    private void onNodeLeft(UUID nodeId) {\n+        Map<UUID, Map<StatsKeyMessage, int[]>> failedCollections = new HashMap<>();\n+        currCollections.updateAllCollections(colStat -> {\n+            StatsCollectionRequest[] nodeRequests = (StatsCollectionRequest[])colStat.remainingCollectionReqs()\n+                    .values().stream().filter(\n+                    addReq -> nodeId.equals(addReq.nodeId())).map(StatsAddrRequest::req).toArray();\n+            if (!F.isEmpty(nodeRequests)) {\n+                Map<StatsKeyMessage, int[]> failedKeys = IgniteStatisticsRequestCollection.extractFailed(nodeRequests);\n+                try {\n+                    Collection<StatsAddrRequest<StatsCollectionRequest>> reqs = currCollections\n+                        .generateCollectionRequests(colStat.colId(), colStat.keys(), failedKeys);\n+                    //Map<UUID, StatsCollectionRequest> msgs = reqs.stream().collect(Collectors.toMap(\n+                    //        StatsAddrRequest::nodeId, StatsAddrRequest::req));\n+                    // TODO: resend it\n+                    sendRequests(reqs);\n+                } catch (IgniteCheckedException e) {\n+                    // TODO\n+                    e.printStackTrace();\n+                }\n+\n+            }\n+            return null;\n+        });\n+    }\n+\n+    /**\n+     * Listener to handle nodeLeft/nodeFailed and call onNodeLeft method.\n+     */\n+    private class NodeLeftListener implements GridLocalEventListener {", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 0f88eff3479..f208a744d01 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -886,101 +517,11 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n                 if (log.isDebugEnabled())\n                     log.debug(String.format(\n                             \"Unable to send statistics collection result to node %s in response to colId %s, reqId %s\",\n-                        nodeId, req.colId(), req.reqId()));\n+                        nodeId, req.gatId(), req.reqId()));\n             }\n \n             // Not local collection - remove by its reqId.\n-            currCollections.updateCollection(req.reqId(), s -> null);\n-        }\n-    }\n-\n-    /**\n-     * Schedule statistics collection by specified request.\n-     *\n-     * @param nodeId request origin node.\n-     * @param msg request message.\n-     */\n-    private void handleCollectionRequest(UUID nodeId, StatsCollectionRequest msg) {\n-        assert msg.reqId() != null : \"Got statistics collection request without request id\";\n-\n-        currCollections.addActiveCollectionStatus(msg.reqId(), new StatCollectionStatus(msg.colId(), msg.keys().keySet(), null));\n-\n-        statMgmtPool.submit(() -> processLocal(nodeId, msg));\n-    }\n-\n-    /**\n-     * Send requests to target nodes except of local one.\n-     *\n-     * @param reqs Collection of addressed requests to send.\n-     * @return Collection of addressed requests that has errors while sending or {@code null} if all requests was send\n-     * successfully.\n-     */\n-    private <T extends Message> Collection<StatsAddrRequest<T>> sendRequests(Collection<StatsAddrRequest<T>> reqs) {\n-        UUID locNode = ctx.localNodeId();\n-        Collection<StatsAddrRequest<T>> res = null;\n-\n-        for (StatsAddrRequest<T> req : reqs) {\n-            if (locNode.equals(req.nodeId()))\n-                continue;\n-\n-            try {\n-                ctx.io().sendToCustomTopic(req.nodeId(), TOPIC, req.req(), GridIoPolicy.QUERY_POOL);\n-            }\n-            catch (IgniteCheckedException e) {\n-                if (res == null)\n-                    res = new ArrayList<>();\n-\n-                res.add(req);\n-            }\n-        }\n-\n-        return res;\n-    }\n-\n-    /**\n-     * Handle node left event:\n-     * 1) Cancel all collection tasks which expect specified node statistics result.\n-     * 2) Cancel collection task requested by node left.\n-     *\n-     * @param nodeId leaved node id.\n-     */\n-    private void onNodeLeft(UUID nodeId) {\n-        Map<UUID, Map<StatsKeyMessage, int[]>> failedCollections = new HashMap<>();\n-        currCollections.updateAllCollections(colStat -> {\n-            StatsCollectionRequest[] nodeRequests = (StatsCollectionRequest[])colStat.remainingCollectionReqs()\n-                    .values().stream().filter(\n-                    addReq -> nodeId.equals(addReq.nodeId())).map(StatsAddrRequest::req).toArray();\n-            if (!F.isEmpty(nodeRequests)) {\n-                Map<StatsKeyMessage, int[]> failedKeys = IgniteStatisticsRequestCollection.extractFailed(nodeRequests);\n-                try {\n-                    Collection<StatsAddrRequest<StatsCollectionRequest>> reqs = currCollections\n-                        .generateCollectionRequests(colStat.colId(), colStat.keys(), failedKeys);\n-                    //Map<UUID, StatsCollectionRequest> msgs = reqs.stream().collect(Collectors.toMap(\n-                    //        StatsAddrRequest::nodeId, StatsAddrRequest::req));\n-                    // TODO: resend it\n-                    sendRequests(reqs);\n-                } catch (IgniteCheckedException e) {\n-                    // TODO\n-                    e.printStackTrace();\n-                }\n-\n-            }\n-            return null;\n-        });\n-    }\n-\n-    /**\n-     * Listener to handle nodeLeft/nodeFailed and call onNodeLeft method.\n-     */\n-    private class NodeLeftListener implements GridLocalEventListener {\n-\n-        /** {@inheritDoc} */\n-        @Override public void onEvent(Event evt) {\n-            assert evt.type() == EventType.EVT_NODE_FAILED || evt.type() == EventType.EVT_NODE_LEFT;\n-\n-            final UUID nodeId = ((DiscoveryEvent)evt).eventNode().id();\n-\n-            ctx.closure().runLocalSafe(() -> onNodeLeft(nodeId), GridIoPolicy.QUERY_POOL);\n+            helper.updateCollection(req.reqId(), s -> null);\n         }\n     }\n }\n", "next_change": {"commit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex f208a744d01..1f98ad5ca73 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -523,5 +561,5 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n             // Not local collection - remove by its reqId.\n             helper.updateCollection(req.reqId(), s -> null);\n         }\n-    }\n+    }*/\n }\n", "next_change": {"commit": "e54c934091d0917505fbe4bd919fd766a492897e", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 1f98ad5ca73..c989b5605e7 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -507,59 +487,4 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n        for (StatisticsKeyMessage key : keys)\n            clearObjectStatisticsLocal(key);\n    }\n-\n-    /**\n-     * Collect local object statistics by specified request (possibly for a few objects) and send result back to origin\n-     * node specified. If local node id specified - process result without sending it throw the communication.\n-     *\n-     * @param req request to collect statistics by.\n-     */\n-    /*private void processLocal(UUID nodeId, StatisticsGatheringRequest req) {\n-        UUID locNode = ctx.localNodeId();\n-\n-        StatisticsGatheringContext stat = (nodeId.equals(locNode)) ? helper.getCollection(req.gatId()) :\n-            helper.getCollection(req.reqId());\n-\n-        if (stat == null)\n-            return;\n-\n-        Map<StatisticsObjectData, int[]> collected = new HashMap<>(req.keys().size());\n-        for (Map.Entry<StatisticsKeyMessage, int[]> keyEntry : req.keys().entrySet()) {\n-            try {\n-                StatisticsKeyMessage key = keyEntry.getKey();\n-                IgniteBiTuple <ObjectStatisticsImpl, int[]> loStat = gatherLocalObjectStatisticsAsync(key,\n-                        keyEntry.getValue(), () -> stat.doneFut().isCancelled());\n-                StatisticsKey statsKey = new StatisticsKey(key.schema(), key.obj());\n-\n-                // TODO?\n-                statsRepos.mergeLocalStatistics(statsKey, loStat.getKey());\n-\n-                StatisticsObjectData objData = StatisticsUtils.toObjectData(key, StatisticsType.LOCAL, loStat.getKey());\n-                collected.put(objData, loStat.getValue());\n-            }\n-            catch (IgniteCheckedException e) {\n-                log.warning(String.format(\"Unable to complete request %s due to error %s\", req.reqId(), e.getMessage()));\n-                // TODO: send cancel to originator node\n-            }\n-        }\n-\n-        StatisticsGatheringResponse res = new StatisticsGatheringResponse(req.gatId(), req.reqId(), collected);\n-\n-        if (locNode.equals(nodeId))\n-            receiveLocalStatistics(nodeId, res);\n-        else {\n-            try {\n-                ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n-            }\n-            catch (IgniteCheckedException e) {\n-                if (log.isDebugEnabled())\n-                    log.debug(String.format(\n-                            \"Unable to send statistics collection result to node %s in response to colId %s, reqId %s\",\n-                        nodeId, req.gatId(), req.reqId()));\n-            }\n-\n-            // Not local collection - remove by its reqId.\n-            helper.updateCollection(req.reqId(), s -> null);\n-        }\n-    }*/\n }\n", "next_change": {"commit": "33170812024f6c4d321f85287fea0b6c3abdb9e5", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex c989b5605e7..5011b1a87a5 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -478,13 +458,20 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n         return stat;\n    }\n \n+    /** {@inheritDoc} */\n+    @Override public ObjectStatistics getGlobalStatistics(String schemaName, String objName) {\n+        return statsRepos.getGlobalStatistics(new StatisticsKey(schemaName, objName));\n+    }\n+\n     /**\n-     * Clear object statistics by specified keys.\n+     * Check that all server nodes in the cluster support STATISTICS_COLLECTION features.\n      *\n-     * @param keys Collection of keys to clean statistics by.\n+     * @param op Operation name.\n      */\n-   public void clearObjectStatisticsLocal(Collection<StatisticsKeyMessage> keys) {\n-       for (StatisticsKeyMessage key : keys)\n-           clearObjectStatisticsLocal(key);\n+   private void checkSupport(String op) throws IgniteCheckedException {\n+       if (!IgniteFeatures.allNodesSupport(ctx, IgniteFeatures.STATISTICS_COLLECTION, IgniteDiscoverySpi.SRV_NODES)) {\n+           throw new IgniteCheckedException(String.format(\n+               \"Unable to perform %s due to not all server nodes supports STATISTICS_COLLECTION feature.\", op));\n+       }\n    }\n }\n", "next_change": {"commit": "f5aafee54b1036c09d4944ca9bf0254f8bfd2b1e", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 5011b1a87a5..4df3ed6f1e0 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -464,11 +485,13 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n     }\n \n     /**\n-     * Check that all server nodes in the cluster support STATISTICS_COLLECTION features.\n+     * Check that all server nodes in the cluster support STATISTICS_COLLECTION feature. Throws IgniteCheckedException\n+     * in not.\n      *\n      * @param op Operation name.\n+     * @throws IgniteCheckedException If at least one server node doesn't support feature.\n      */\n-   private void checkSupport(String op) throws IgniteCheckedException {\n+   private void checkStatisticsSupport(String op) throws IgniteCheckedException {\n        if (!IgniteFeatures.allNodesSupport(ctx, IgniteFeatures.STATISTICS_COLLECTION, IgniteDiscoverySpi.SRV_NODES)) {\n            throw new IgniteCheckedException(String.format(\n                \"Unable to perform %s due to not all server nodes supports STATISTICS_COLLECTION feature.\", op));\n", "next_change": {"commit": "65caf2d646409c3be32c4d00f762fcdc7ec4ceb0", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 4df3ed6f1e0..47277987f34 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -492,9 +492,18 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n      * @throws IgniteCheckedException If at least one server node doesn't support feature.\n      */\n    private void checkStatisticsSupport(String op) throws IgniteCheckedException {\n-       if (!IgniteFeatures.allNodesSupport(ctx, IgniteFeatures.STATISTICS_COLLECTION, IgniteDiscoverySpi.SRV_NODES)) {\n+       if (!isStatisticsSupport()) {\n            throw new IgniteCheckedException(String.format(\n                \"Unable to perform %s due to not all server nodes supports STATISTICS_COLLECTION feature.\", op));\n        }\n    }\n+\n+    /**\n+     * Test is statistics collection feature are supported by each server node in cluster.\n+     *\n+     * @return {@code true} if all server nodes support STATISTICS_COLLECTION feature, {@code false} - otherwise.\n+     */\n+   private boolean isStatisticsSupport() {\n+       return IgniteFeatures.allNodesSupport(ctx, IgniteFeatures.STATISTICS_COLLECTION, IgniteDiscoverySpi.SRV_NODES);\n+   }\n }\n", "next_change": null}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc2NjcwOQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546766709", "body": "this should be part of NodeLeftListener", "bodyText": "this should be part of NodeLeftListener", "bodyHTML": "<p dir=\"auto\">this should be part of NodeLeftListener</p>", "author": "korlov42", "createdAt": "2020-12-21T15:23:57Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -278,4 +614,373 @@ private ObjectStatisticsImpl aggregateLocalStatistics(\n \n         return tblStats;\n     }\n+\n+    /**\n+     * Receive and handle statistics propagation message with partitions statistics.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receivePartitionsStatistics(UUID nodeId, StatsPropagationMessage msg) throws IgniteCheckedException {\n+        UUID locNode = ctx.localNodeId();\n+        for (StatsObjectData partData : msg.data()) {\n+            StatsKey key = new StatsKey(partData.key().schema(), partData.key().obj());\n+\n+            assert partData.type() == StatsType.PARTITION : \"Got non partition level statistics by \" + key\n+                    + \" without request\";\n+\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d from node %s\", key.schema(),\n+                        key.obj(), partData.partId(), nodeId));\n+\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(locNode, partData.partId());\n+            if (partState != OWNING) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+\n+            ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n+\n+            statsRepos.saveLocalPartitionStatistics(key, opStat);\n+        }\n+    }\n+\n+    /**\n+     * Receive and handle statistics propagation message as response for collection request.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receiveLocalStatistics(UUID nodeId, StatsCollectionResponse msg) {\n+        assert msg.data().keySet().stream().noneMatch(pd -> pd.type() == StatsType.PARTITION)\n+                : \"Got partition statistics by request \" + msg.reqId();\n+\n+        currCollections.updateCollection(msg.colId(), stat -> {\n+            if (stat == null) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\n+                        \"Ignoring outdated local statistics collection response from node %s to col %s req %s\",\n+                            nodeId, msg.colId(), msg.reqId()));\n+\n+                return stat;\n+            }\n+\n+            assert stat.colId().equals(msg.colId());\n+\n+            // Need syncronization here to avoid races between removing remaining reqs and adding new ones.\n+            synchronized (stat) {\n+                StatsAddrRequest<StatsCollectionRequest> req = stat.remainingCollectionReqs().remove(msg.reqId());\n+\n+                if (req == null) {\n+                    if (log.isDebugEnabled())\n+                        log.debug(String.format(\n+                                \"Ignoring unknown local statistics collection response from node %s to col %s req %s\",\n+                                nodeId, msg.colId(), msg.reqId()));\n+\n+                    return stat;\n+                }\n+\n+                stat.localStatistics().add(msg);\n+                // TODO: reschedule if not all partition collected.\n+\n+                if (stat.remainingCollectionReqs().isEmpty()) {\n+                    Map<StatsKey, ObjectStatisticsImpl> mergedGlobal = finishStatCollection(stat);\n+\n+                    stat.doneFut().onDone(null);\n+\n+                    return null;\n+                }\n+            }\n+            return stat;\n+        });\n+    }\n+\n+    /**\n+     * Aggregate local statistics to global one.\n+     *\n+     * @param stat Statistics collection status to aggregate.\n+     * @return Map stats key to merged global statistics.\n+     */\n+    private Map<StatsKey, ObjectStatisticsImpl> finishStatCollection(StatCollectionStatus stat) {\n+        Map<StatsKeyMessage, Collection<ObjectStatisticsImpl>> keysStats = new HashMap<>();\n+        for (StatsCollectionResponse resp : stat.localStatistics()) {\n+            for (StatsObjectData objData : resp.data().keySet()) {\n+                keysStats.compute(objData.key(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+                    try {\n+                        ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n+\n+                        v.add(objStat);\n+                    } catch (IgniteCheckedException e) {\n+                        if (log.isInfoEnabled())\n+                            log.info(String.format(\"Unable to parse statistics for object %s from response %s\",\n+                                    objData.key(), resp.reqId()));\n+                    }\n+\n+                    return v;\n+                });\n+            }\n+        }\n+\n+        Map<StatsKey, ObjectStatisticsImpl> res = new HashMap<>();\n+        for (Map.Entry<StatsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : keysStats.entrySet()) {\n+            StatsKeyMessage keyMsg = keyStats.getKey();\n+            GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Unable to find object %s.%s to save collected statistics by.\",\n+                            keyMsg.schema(), keyMsg.obj()));\n+\n+                continue;\n+            }\n+            ObjectStatisticsImpl globalStat = aggregateLocalStatistics(keyMsg, keyStats.getValue());\n+            StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+            res.put(key, statsRepos.mergeGlobalStatistics(key, globalStat));\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Send statistics by request.\n+     *\n+     * @param nodeId Node to send statistics to.\n+     * @param msg Statistics request to process.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void supplyStatistics(UUID nodeId, StatsGetRequest msg) throws IgniteCheckedException {\n+        List<StatsObjectData> data = new ArrayList<>(msg.keys().size());\n+        for (StatsKeyMessage keyMsg : msg.keys()) {\n+            StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+            ObjectStatisticsImpl objStats = statsRepos.getGlobalStatistics(key);\n+\n+            if (objStats != null)\n+                data.add(StatisticsUtils.toObjectData(keyMsg, StatsType.GLOBAL, objStats));\n+        }\n+        StatsPropagationMessage res = new StatsPropagationMessage(data);\n+        ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n+    }\n+\n+    /**\n+     * Cancel local statistics collection task.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Cancel request.\n+     */\n+    private void cancelStatisticsCollection(UUID nodeId, CancelStatsCollectionRequest msg) {\n+        for (UUID reqId : msg.reqIds()) {\n+            currCollections.updateCollection(reqId, stat -> {\n+                if (stat == null) {\n+                    if (log.isDebugEnabled())\n+                        log.debug(String.format(\"Unable to cancel statistics collection %s by req %s from node %s\",\n+                                msg.colId(), reqId, nodeId));\n+\n+                    return null;\n+                }\n+\n+                stat.doneFut().cancel();\n+\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Cancelling statistics collection by colId = %s, reqId = %s from node %s\",\n+                            msg.colId(), reqId, nodeId));\n+\n+                return null;\n+            });\n+        }\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void onMessage(UUID nodeId, Object msg, byte plc) {\n+        try {\n+            if (msg instanceof StatsPropagationMessage)\n+                receivePartitionsStatistics(nodeId, (StatsPropagationMessage) msg);\n+            else if (msg instanceof StatsCollectionResponse)\n+                receiveLocalStatistics(nodeId, (StatsCollectionResponse) msg);\n+            else if (msg instanceof StatsGetRequest)\n+                supplyStatistics(nodeId, (StatsGetRequest) msg);\n+            else if (msg instanceof StatsCollectionRequest)\n+                handleCollectionRequest(nodeId, (StatsCollectionRequest)msg);\n+            else if (msg instanceof CancelStatsCollectionRequest)\n+                cancelStatisticsCollection(nodeId, (CancelStatsCollectionRequest) msg);\n+            else if (msg instanceof StatsClearRequest)\n+                clearObjectStatistics(nodeId, (StatsClearRequest)msg);\n+            else\n+                log.warning(\"Unknown msg \" + msg +  \" in statistics topic \" + TOPIC + \" from node \" + nodeId);\n+        } catch (IgniteCheckedException e) {\n+            log.warning(\"Statistic msg from node \" + nodeId + \" processing failed\", e);\n+        }\n+    }\n+\n+    /**\n+     * Handle statistics clear request.\n+     *\n+     * @param nodeId UUID of request sender node.\n+     * @param msg Clear request message.\n+     */\n+    private void clearObjectStatistics(UUID nodeId, StatsClearRequest msg) {\n+        for (StatsKeyMessage key : msg.keys()) {\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Clearing statistics by request %s from node %s by key %s.%s\", msg.reqId(),\n+                        nodeId, key.schema(), key.obj()));\n+            statMgmtPool.submit(() -> clearObjectStatisticsLocal(key));\n+        }\n+    }\n+\n+    /**\n+     * Collect local object statistics by specified request (possibly for a few objects) and send result back to origin\n+     * node specified. If local node id specified - process result without sending it throw the communication.\n+     *\n+     * @param req request to collect statistics by.\n+     */\n+    private void processLocal(UUID nodeId, StatsCollectionRequest req) {\n+        UUID locNode = ctx.localNodeId();\n+\n+        StatCollectionStatus stat = (nodeId.equals(locNode)) ? currCollections.getCollection(req.colId()) :\n+            currCollections.getCollection(req.reqId());\n+\n+        if (stat == null)\n+            return;\n+\n+        Map<StatsObjectData, int[]> collected = new HashMap<>(req.keys().size());\n+        for (Map.Entry<StatsKeyMessage, int[]> keyEntry : req.keys().entrySet()) {\n+            try {\n+                StatsKeyMessage key = keyEntry.getKey();\n+                IgniteBiTuple <ObjectStatisticsImpl, int[]> loStat = collectLocalObjectStatistics(key,\n+                        keyEntry.getValue(), () -> stat.doneFut().isCancelled());\n+                StatsKey statsKey = new StatsKey(key.schema(), key.obj());\n+\n+                // TODO?\n+                statsRepos.mergeLocalStatistics(statsKey, loStat.getKey());\n+\n+                StatsObjectData objData = StatisticsUtils.toObjectData(key, StatsType.LOCAL, loStat.getKey());\n+                collected.put(objData, loStat.getValue());\n+            }\n+            catch (IgniteCheckedException e) {\n+                log.warning(String.format(\"Unable to complete request %s due to error %s\", req.reqId(), e.getMessage()));\n+                // TODO: send cancel to originator node\n+            }\n+        }\n+\n+        StatsCollectionResponse res = new StatsCollectionResponse(req.colId(), req.reqId(), collected);\n+\n+        if (locNode.equals(nodeId))\n+            receiveLocalStatistics(nodeId, res);\n+        else {\n+            try {\n+                ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\n+                            \"Unable to send statistics collection result to node %s in response to colId %s, reqId %s\",\n+                        nodeId, req.colId(), req.reqId()));\n+            }\n+\n+            // Not local collection - remove by its reqId.\n+            currCollections.updateCollection(req.reqId(), s -> null);\n+        }\n+    }\n+\n+    /**\n+     * Schedule statistics collection by specified request.\n+     *\n+     * @param nodeId request origin node.\n+     * @param msg request message.\n+     */\n+    private void handleCollectionRequest(UUID nodeId, StatsCollectionRequest msg) {\n+        assert msg.reqId() != null : \"Got statistics collection request without request id\";\n+\n+        currCollections.addActiveCollectionStatus(msg.reqId(), new StatCollectionStatus(msg.colId(), msg.keys().keySet(), null));\n+\n+        statMgmtPool.submit(() -> processLocal(nodeId, msg));\n+    }\n+\n+    /**\n+     * Send requests to target nodes except of local one.\n+     *\n+     * @param reqs Collection of addressed requests to send.\n+     * @return Collection of addressed requests that has errors while sending or {@code null} if all requests was send\n+     * successfully.\n+     */\n+    private <T extends Message> Collection<StatsAddrRequest<T>> sendRequests(Collection<StatsAddrRequest<T>> reqs) {\n+        UUID locNode = ctx.localNodeId();\n+        Collection<StatsAddrRequest<T>> res = null;\n+\n+        for (StatsAddrRequest<T> req : reqs) {\n+            if (locNode.equals(req.nodeId()))\n+                continue;\n+\n+            try {\n+                ctx.io().sendToCustomTopic(req.nodeId(), TOPIC, req.req(), GridIoPolicy.QUERY_POOL);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (res == null)\n+                    res = new ArrayList<>();\n+\n+                res.add(req);\n+            }\n+        }\n+\n+        return res;\n+    }\n+\n+    /**\n+     * Handle node left event:\n+     * 1) Cancel all collection tasks which expect specified node statistics result.\n+     * 2) Cancel collection task requested by node left.\n+     *\n+     * @param nodeId leaved node id.\n+     */\n+    private void onNodeLeft(UUID nodeId) {", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTAyNTM0NQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555025345", "bodyText": "removed", "author": "Berkof", "createdAt": "2021-01-11T12:52:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc2NjcwOQ=="}], "type": "inlineReview", "revised_code": {"commit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 0f88eff3479..f208a744d01 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -886,101 +517,11 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n                 if (log.isDebugEnabled())\n                     log.debug(String.format(\n                             \"Unable to send statistics collection result to node %s in response to colId %s, reqId %s\",\n-                        nodeId, req.colId(), req.reqId()));\n+                        nodeId, req.gatId(), req.reqId()));\n             }\n \n             // Not local collection - remove by its reqId.\n-            currCollections.updateCollection(req.reqId(), s -> null);\n-        }\n-    }\n-\n-    /**\n-     * Schedule statistics collection by specified request.\n-     *\n-     * @param nodeId request origin node.\n-     * @param msg request message.\n-     */\n-    private void handleCollectionRequest(UUID nodeId, StatsCollectionRequest msg) {\n-        assert msg.reqId() != null : \"Got statistics collection request without request id\";\n-\n-        currCollections.addActiveCollectionStatus(msg.reqId(), new StatCollectionStatus(msg.colId(), msg.keys().keySet(), null));\n-\n-        statMgmtPool.submit(() -> processLocal(nodeId, msg));\n-    }\n-\n-    /**\n-     * Send requests to target nodes except of local one.\n-     *\n-     * @param reqs Collection of addressed requests to send.\n-     * @return Collection of addressed requests that has errors while sending or {@code null} if all requests was send\n-     * successfully.\n-     */\n-    private <T extends Message> Collection<StatsAddrRequest<T>> sendRequests(Collection<StatsAddrRequest<T>> reqs) {\n-        UUID locNode = ctx.localNodeId();\n-        Collection<StatsAddrRequest<T>> res = null;\n-\n-        for (StatsAddrRequest<T> req : reqs) {\n-            if (locNode.equals(req.nodeId()))\n-                continue;\n-\n-            try {\n-                ctx.io().sendToCustomTopic(req.nodeId(), TOPIC, req.req(), GridIoPolicy.QUERY_POOL);\n-            }\n-            catch (IgniteCheckedException e) {\n-                if (res == null)\n-                    res = new ArrayList<>();\n-\n-                res.add(req);\n-            }\n-        }\n-\n-        return res;\n-    }\n-\n-    /**\n-     * Handle node left event:\n-     * 1) Cancel all collection tasks which expect specified node statistics result.\n-     * 2) Cancel collection task requested by node left.\n-     *\n-     * @param nodeId leaved node id.\n-     */\n-    private void onNodeLeft(UUID nodeId) {\n-        Map<UUID, Map<StatsKeyMessage, int[]>> failedCollections = new HashMap<>();\n-        currCollections.updateAllCollections(colStat -> {\n-            StatsCollectionRequest[] nodeRequests = (StatsCollectionRequest[])colStat.remainingCollectionReqs()\n-                    .values().stream().filter(\n-                    addReq -> nodeId.equals(addReq.nodeId())).map(StatsAddrRequest::req).toArray();\n-            if (!F.isEmpty(nodeRequests)) {\n-                Map<StatsKeyMessage, int[]> failedKeys = IgniteStatisticsRequestCollection.extractFailed(nodeRequests);\n-                try {\n-                    Collection<StatsAddrRequest<StatsCollectionRequest>> reqs = currCollections\n-                        .generateCollectionRequests(colStat.colId(), colStat.keys(), failedKeys);\n-                    //Map<UUID, StatsCollectionRequest> msgs = reqs.stream().collect(Collectors.toMap(\n-                    //        StatsAddrRequest::nodeId, StatsAddrRequest::req));\n-                    // TODO: resend it\n-                    sendRequests(reqs);\n-                } catch (IgniteCheckedException e) {\n-                    // TODO\n-                    e.printStackTrace();\n-                }\n-\n-            }\n-            return null;\n-        });\n-    }\n-\n-    /**\n-     * Listener to handle nodeLeft/nodeFailed and call onNodeLeft method.\n-     */\n-    private class NodeLeftListener implements GridLocalEventListener {\n-\n-        /** {@inheritDoc} */\n-        @Override public void onEvent(Event evt) {\n-            assert evt.type() == EventType.EVT_NODE_FAILED || evt.type() == EventType.EVT_NODE_LEFT;\n-\n-            final UUID nodeId = ((DiscoveryEvent)evt).eventNode().id();\n-\n-            ctx.closure().runLocalSafe(() -> onNodeLeft(nodeId), GridIoPolicy.QUERY_POOL);\n+            helper.updateCollection(req.reqId(), s -> null);\n         }\n     }\n }\n", "next_change": {"commit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex f208a744d01..1f98ad5ca73 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -523,5 +561,5 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n             // Not local collection - remove by its reqId.\n             helper.updateCollection(req.reqId(), s -> null);\n         }\n-    }\n+    }*/\n }\n", "next_change": {"commit": "e54c934091d0917505fbe4bd919fd766a492897e", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 1f98ad5ca73..c989b5605e7 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -507,59 +487,4 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n        for (StatisticsKeyMessage key : keys)\n            clearObjectStatisticsLocal(key);\n    }\n-\n-    /**\n-     * Collect local object statistics by specified request (possibly for a few objects) and send result back to origin\n-     * node specified. If local node id specified - process result without sending it throw the communication.\n-     *\n-     * @param req request to collect statistics by.\n-     */\n-    /*private void processLocal(UUID nodeId, StatisticsGatheringRequest req) {\n-        UUID locNode = ctx.localNodeId();\n-\n-        StatisticsGatheringContext stat = (nodeId.equals(locNode)) ? helper.getCollection(req.gatId()) :\n-            helper.getCollection(req.reqId());\n-\n-        if (stat == null)\n-            return;\n-\n-        Map<StatisticsObjectData, int[]> collected = new HashMap<>(req.keys().size());\n-        for (Map.Entry<StatisticsKeyMessage, int[]> keyEntry : req.keys().entrySet()) {\n-            try {\n-                StatisticsKeyMessage key = keyEntry.getKey();\n-                IgniteBiTuple <ObjectStatisticsImpl, int[]> loStat = gatherLocalObjectStatisticsAsync(key,\n-                        keyEntry.getValue(), () -> stat.doneFut().isCancelled());\n-                StatisticsKey statsKey = new StatisticsKey(key.schema(), key.obj());\n-\n-                // TODO?\n-                statsRepos.mergeLocalStatistics(statsKey, loStat.getKey());\n-\n-                StatisticsObjectData objData = StatisticsUtils.toObjectData(key, StatisticsType.LOCAL, loStat.getKey());\n-                collected.put(objData, loStat.getValue());\n-            }\n-            catch (IgniteCheckedException e) {\n-                log.warning(String.format(\"Unable to complete request %s due to error %s\", req.reqId(), e.getMessage()));\n-                // TODO: send cancel to originator node\n-            }\n-        }\n-\n-        StatisticsGatheringResponse res = new StatisticsGatheringResponse(req.gatId(), req.reqId(), collected);\n-\n-        if (locNode.equals(nodeId))\n-            receiveLocalStatistics(nodeId, res);\n-        else {\n-            try {\n-                ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n-            }\n-            catch (IgniteCheckedException e) {\n-                if (log.isDebugEnabled())\n-                    log.debug(String.format(\n-                            \"Unable to send statistics collection result to node %s in response to colId %s, reqId %s\",\n-                        nodeId, req.gatId(), req.reqId()));\n-            }\n-\n-            // Not local collection - remove by its reqId.\n-            helper.updateCollection(req.reqId(), s -> null);\n-        }\n-    }*/\n }\n", "next_change": {"commit": "33170812024f6c4d321f85287fea0b6c3abdb9e5", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex c989b5605e7..5011b1a87a5 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -478,13 +458,20 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n         return stat;\n    }\n \n+    /** {@inheritDoc} */\n+    @Override public ObjectStatistics getGlobalStatistics(String schemaName, String objName) {\n+        return statsRepos.getGlobalStatistics(new StatisticsKey(schemaName, objName));\n+    }\n+\n     /**\n-     * Clear object statistics by specified keys.\n+     * Check that all server nodes in the cluster support STATISTICS_COLLECTION features.\n      *\n-     * @param keys Collection of keys to clean statistics by.\n+     * @param op Operation name.\n      */\n-   public void clearObjectStatisticsLocal(Collection<StatisticsKeyMessage> keys) {\n-       for (StatisticsKeyMessage key : keys)\n-           clearObjectStatisticsLocal(key);\n+   private void checkSupport(String op) throws IgniteCheckedException {\n+       if (!IgniteFeatures.allNodesSupport(ctx, IgniteFeatures.STATISTICS_COLLECTION, IgniteDiscoverySpi.SRV_NODES)) {\n+           throw new IgniteCheckedException(String.format(\n+               \"Unable to perform %s due to not all server nodes supports STATISTICS_COLLECTION feature.\", op));\n+       }\n    }\n }\n", "next_change": {"commit": "f5aafee54b1036c09d4944ca9bf0254f8bfd2b1e", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 5011b1a87a5..4df3ed6f1e0 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -464,11 +485,13 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n     }\n \n     /**\n-     * Check that all server nodes in the cluster support STATISTICS_COLLECTION features.\n+     * Check that all server nodes in the cluster support STATISTICS_COLLECTION feature. Throws IgniteCheckedException\n+     * in not.\n      *\n      * @param op Operation name.\n+     * @throws IgniteCheckedException If at least one server node doesn't support feature.\n      */\n-   private void checkSupport(String op) throws IgniteCheckedException {\n+   private void checkStatisticsSupport(String op) throws IgniteCheckedException {\n        if (!IgniteFeatures.allNodesSupport(ctx, IgniteFeatures.STATISTICS_COLLECTION, IgniteDiscoverySpi.SRV_NODES)) {\n            throw new IgniteCheckedException(String.format(\n                \"Unable to perform %s due to not all server nodes supports STATISTICS_COLLECTION feature.\", op));\n", "next_change": {"commit": "65caf2d646409c3be32c4d00f762fcdc7ec4ceb0", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 4df3ed6f1e0..47277987f34 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -492,9 +492,18 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n      * @throws IgniteCheckedException If at least one server node doesn't support feature.\n      */\n    private void checkStatisticsSupport(String op) throws IgniteCheckedException {\n-       if (!IgniteFeatures.allNodesSupport(ctx, IgniteFeatures.STATISTICS_COLLECTION, IgniteDiscoverySpi.SRV_NODES)) {\n+       if (!isStatisticsSupport()) {\n            throw new IgniteCheckedException(String.format(\n                \"Unable to perform %s due to not all server nodes supports STATISTICS_COLLECTION feature.\", op));\n        }\n    }\n+\n+    /**\n+     * Test is statistics collection feature are supported by each server node in cluster.\n+     *\n+     * @return {@code true} if all server nodes support STATISTICS_COLLECTION feature, {@code false} - otherwise.\n+     */\n+   private boolean isStatisticsSupport() {\n+       return IgniteFeatures.allNodesSupport(ctx, IgniteFeatures.STATISTICS_COLLECTION, IgniteDiscoverySpi.SRV_NODES);\n+   }\n }\n", "next_change": null}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc2Njg1OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546766858", "body": "commented code", "bodyText": "commented code", "bodyHTML": "<p dir=\"auto\">commented code</p>", "author": "korlov42", "createdAt": "2020-12-21T15:24:15Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -278,4 +614,373 @@ private ObjectStatisticsImpl aggregateLocalStatistics(\n \n         return tblStats;\n     }\n+\n+    /**\n+     * Receive and handle statistics propagation message with partitions statistics.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receivePartitionsStatistics(UUID nodeId, StatsPropagationMessage msg) throws IgniteCheckedException {\n+        UUID locNode = ctx.localNodeId();\n+        for (StatsObjectData partData : msg.data()) {\n+            StatsKey key = new StatsKey(partData.key().schema(), partData.key().obj());\n+\n+            assert partData.type() == StatsType.PARTITION : \"Got non partition level statistics by \" + key\n+                    + \" without request\";\n+\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d from node %s\", key.schema(),\n+                        key.obj(), partData.partId(), nodeId));\n+\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(locNode, partData.partId());\n+            if (partState != OWNING) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+\n+            ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n+\n+            statsRepos.saveLocalPartitionStatistics(key, opStat);\n+        }\n+    }\n+\n+    /**\n+     * Receive and handle statistics propagation message as response for collection request.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receiveLocalStatistics(UUID nodeId, StatsCollectionResponse msg) {\n+        assert msg.data().keySet().stream().noneMatch(pd -> pd.type() == StatsType.PARTITION)\n+                : \"Got partition statistics by request \" + msg.reqId();\n+\n+        currCollections.updateCollection(msg.colId(), stat -> {\n+            if (stat == null) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\n+                        \"Ignoring outdated local statistics collection response from node %s to col %s req %s\",\n+                            nodeId, msg.colId(), msg.reqId()));\n+\n+                return stat;\n+            }\n+\n+            assert stat.colId().equals(msg.colId());\n+\n+            // Need syncronization here to avoid races between removing remaining reqs and adding new ones.\n+            synchronized (stat) {\n+                StatsAddrRequest<StatsCollectionRequest> req = stat.remainingCollectionReqs().remove(msg.reqId());\n+\n+                if (req == null) {\n+                    if (log.isDebugEnabled())\n+                        log.debug(String.format(\n+                                \"Ignoring unknown local statistics collection response from node %s to col %s req %s\",\n+                                nodeId, msg.colId(), msg.reqId()));\n+\n+                    return stat;\n+                }\n+\n+                stat.localStatistics().add(msg);\n+                // TODO: reschedule if not all partition collected.\n+\n+                if (stat.remainingCollectionReqs().isEmpty()) {\n+                    Map<StatsKey, ObjectStatisticsImpl> mergedGlobal = finishStatCollection(stat);\n+\n+                    stat.doneFut().onDone(null);\n+\n+                    return null;\n+                }\n+            }\n+            return stat;\n+        });\n+    }\n+\n+    /**\n+     * Aggregate local statistics to global one.\n+     *\n+     * @param stat Statistics collection status to aggregate.\n+     * @return Map stats key to merged global statistics.\n+     */\n+    private Map<StatsKey, ObjectStatisticsImpl> finishStatCollection(StatCollectionStatus stat) {\n+        Map<StatsKeyMessage, Collection<ObjectStatisticsImpl>> keysStats = new HashMap<>();\n+        for (StatsCollectionResponse resp : stat.localStatistics()) {\n+            for (StatsObjectData objData : resp.data().keySet()) {\n+                keysStats.compute(objData.key(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+                    try {\n+                        ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n+\n+                        v.add(objStat);\n+                    } catch (IgniteCheckedException e) {\n+                        if (log.isInfoEnabled())\n+                            log.info(String.format(\"Unable to parse statistics for object %s from response %s\",\n+                                    objData.key(), resp.reqId()));\n+                    }\n+\n+                    return v;\n+                });\n+            }\n+        }\n+\n+        Map<StatsKey, ObjectStatisticsImpl> res = new HashMap<>();\n+        for (Map.Entry<StatsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : keysStats.entrySet()) {\n+            StatsKeyMessage keyMsg = keyStats.getKey();\n+            GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Unable to find object %s.%s to save collected statistics by.\",\n+                            keyMsg.schema(), keyMsg.obj()));\n+\n+                continue;\n+            }\n+            ObjectStatisticsImpl globalStat = aggregateLocalStatistics(keyMsg, keyStats.getValue());\n+            StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+            res.put(key, statsRepos.mergeGlobalStatistics(key, globalStat));\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Send statistics by request.\n+     *\n+     * @param nodeId Node to send statistics to.\n+     * @param msg Statistics request to process.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void supplyStatistics(UUID nodeId, StatsGetRequest msg) throws IgniteCheckedException {\n+        List<StatsObjectData> data = new ArrayList<>(msg.keys().size());\n+        for (StatsKeyMessage keyMsg : msg.keys()) {\n+            StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+            ObjectStatisticsImpl objStats = statsRepos.getGlobalStatistics(key);\n+\n+            if (objStats != null)\n+                data.add(StatisticsUtils.toObjectData(keyMsg, StatsType.GLOBAL, objStats));\n+        }\n+        StatsPropagationMessage res = new StatsPropagationMessage(data);\n+        ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n+    }\n+\n+    /**\n+     * Cancel local statistics collection task.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Cancel request.\n+     */\n+    private void cancelStatisticsCollection(UUID nodeId, CancelStatsCollectionRequest msg) {\n+        for (UUID reqId : msg.reqIds()) {\n+            currCollections.updateCollection(reqId, stat -> {\n+                if (stat == null) {\n+                    if (log.isDebugEnabled())\n+                        log.debug(String.format(\"Unable to cancel statistics collection %s by req %s from node %s\",\n+                                msg.colId(), reqId, nodeId));\n+\n+                    return null;\n+                }\n+\n+                stat.doneFut().cancel();\n+\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Cancelling statistics collection by colId = %s, reqId = %s from node %s\",\n+                            msg.colId(), reqId, nodeId));\n+\n+                return null;\n+            });\n+        }\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void onMessage(UUID nodeId, Object msg, byte plc) {\n+        try {\n+            if (msg instanceof StatsPropagationMessage)\n+                receivePartitionsStatistics(nodeId, (StatsPropagationMessage) msg);\n+            else if (msg instanceof StatsCollectionResponse)\n+                receiveLocalStatistics(nodeId, (StatsCollectionResponse) msg);\n+            else if (msg instanceof StatsGetRequest)\n+                supplyStatistics(nodeId, (StatsGetRequest) msg);\n+            else if (msg instanceof StatsCollectionRequest)\n+                handleCollectionRequest(nodeId, (StatsCollectionRequest)msg);\n+            else if (msg instanceof CancelStatsCollectionRequest)\n+                cancelStatisticsCollection(nodeId, (CancelStatsCollectionRequest) msg);\n+            else if (msg instanceof StatsClearRequest)\n+                clearObjectStatistics(nodeId, (StatsClearRequest)msg);\n+            else\n+                log.warning(\"Unknown msg \" + msg +  \" in statistics topic \" + TOPIC + \" from node \" + nodeId);\n+        } catch (IgniteCheckedException e) {\n+            log.warning(\"Statistic msg from node \" + nodeId + \" processing failed\", e);\n+        }\n+    }\n+\n+    /**\n+     * Handle statistics clear request.\n+     *\n+     * @param nodeId UUID of request sender node.\n+     * @param msg Clear request message.\n+     */\n+    private void clearObjectStatistics(UUID nodeId, StatsClearRequest msg) {\n+        for (StatsKeyMessage key : msg.keys()) {\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Clearing statistics by request %s from node %s by key %s.%s\", msg.reqId(),\n+                        nodeId, key.schema(), key.obj()));\n+            statMgmtPool.submit(() -> clearObjectStatisticsLocal(key));\n+        }\n+    }\n+\n+    /**\n+     * Collect local object statistics by specified request (possibly for a few objects) and send result back to origin\n+     * node specified. If local node id specified - process result without sending it throw the communication.\n+     *\n+     * @param req request to collect statistics by.\n+     */\n+    private void processLocal(UUID nodeId, StatsCollectionRequest req) {\n+        UUID locNode = ctx.localNodeId();\n+\n+        StatCollectionStatus stat = (nodeId.equals(locNode)) ? currCollections.getCollection(req.colId()) :\n+            currCollections.getCollection(req.reqId());\n+\n+        if (stat == null)\n+            return;\n+\n+        Map<StatsObjectData, int[]> collected = new HashMap<>(req.keys().size());\n+        for (Map.Entry<StatsKeyMessage, int[]> keyEntry : req.keys().entrySet()) {\n+            try {\n+                StatsKeyMessage key = keyEntry.getKey();\n+                IgniteBiTuple <ObjectStatisticsImpl, int[]> loStat = collectLocalObjectStatistics(key,\n+                        keyEntry.getValue(), () -> stat.doneFut().isCancelled());\n+                StatsKey statsKey = new StatsKey(key.schema(), key.obj());\n+\n+                // TODO?\n+                statsRepos.mergeLocalStatistics(statsKey, loStat.getKey());\n+\n+                StatsObjectData objData = StatisticsUtils.toObjectData(key, StatsType.LOCAL, loStat.getKey());\n+                collected.put(objData, loStat.getValue());\n+            }\n+            catch (IgniteCheckedException e) {\n+                log.warning(String.format(\"Unable to complete request %s due to error %s\", req.reqId(), e.getMessage()));\n+                // TODO: send cancel to originator node\n+            }\n+        }\n+\n+        StatsCollectionResponse res = new StatsCollectionResponse(req.colId(), req.reqId(), collected);\n+\n+        if (locNode.equals(nodeId))\n+            receiveLocalStatistics(nodeId, res);\n+        else {\n+            try {\n+                ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\n+                            \"Unable to send statistics collection result to node %s in response to colId %s, reqId %s\",\n+                        nodeId, req.colId(), req.reqId()));\n+            }\n+\n+            // Not local collection - remove by its reqId.\n+            currCollections.updateCollection(req.reqId(), s -> null);\n+        }\n+    }\n+\n+    /**\n+     * Schedule statistics collection by specified request.\n+     *\n+     * @param nodeId request origin node.\n+     * @param msg request message.\n+     */\n+    private void handleCollectionRequest(UUID nodeId, StatsCollectionRequest msg) {\n+        assert msg.reqId() != null : \"Got statistics collection request without request id\";\n+\n+        currCollections.addActiveCollectionStatus(msg.reqId(), new StatCollectionStatus(msg.colId(), msg.keys().keySet(), null));\n+\n+        statMgmtPool.submit(() -> processLocal(nodeId, msg));\n+    }\n+\n+    /**\n+     * Send requests to target nodes except of local one.\n+     *\n+     * @param reqs Collection of addressed requests to send.\n+     * @return Collection of addressed requests that has errors while sending or {@code null} if all requests was send\n+     * successfully.\n+     */\n+    private <T extends Message> Collection<StatsAddrRequest<T>> sendRequests(Collection<StatsAddrRequest<T>> reqs) {\n+        UUID locNode = ctx.localNodeId();\n+        Collection<StatsAddrRequest<T>> res = null;\n+\n+        for (StatsAddrRequest<T> req : reqs) {\n+            if (locNode.equals(req.nodeId()))\n+                continue;\n+\n+            try {\n+                ctx.io().sendToCustomTopic(req.nodeId(), TOPIC, req.req(), GridIoPolicy.QUERY_POOL);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (res == null)\n+                    res = new ArrayList<>();\n+\n+                res.add(req);\n+            }\n+        }\n+\n+        return res;\n+    }\n+\n+    /**\n+     * Handle node left event:\n+     * 1) Cancel all collection tasks which expect specified node statistics result.\n+     * 2) Cancel collection task requested by node left.\n+     *\n+     * @param nodeId leaved node id.\n+     */\n+    private void onNodeLeft(UUID nodeId) {\n+        Map<UUID, Map<StatsKeyMessage, int[]>> failedCollections = new HashMap<>();\n+        currCollections.updateAllCollections(colStat -> {\n+            StatsCollectionRequest[] nodeRequests = (StatsCollectionRequest[])colStat.remainingCollectionReqs()\n+                    .values().stream().filter(\n+                    addReq -> nodeId.equals(addReq.nodeId())).map(StatsAddrRequest::req).toArray();\n+            if (!F.isEmpty(nodeRequests)) {\n+                Map<StatsKeyMessage, int[]> failedKeys = IgniteStatisticsRequestCollection.extractFailed(nodeRequests);\n+                try {\n+                    Collection<StatsAddrRequest<StatsCollectionRequest>> reqs = currCollections\n+                        .generateCollectionRequests(colStat.colId(), colStat.keys(), failedKeys);\n+                    //Map<UUID, StatsCollectionRequest> msgs = reqs.stream().collect(Collectors.toMap(\n+                    //        StatsAddrRequest::nodeId, StatsAddrRequest::req));", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTAyNTU4NQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555025585", "bodyText": "removed", "author": "Berkof", "createdAt": "2021-01-11T12:52:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc2Njg1OA=="}], "type": "inlineReview", "revised_code": {"commit": "b595e90b5b480aaf80a9256558b1841334df97de", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 0f88eff3479..7fab3588e96 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -955,8 +937,6 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n                 try {\n                     Collection<StatsAddrRequest<StatsCollectionRequest>> reqs = currCollections\n                         .generateCollectionRequests(colStat.colId(), colStat.keys(), failedKeys);\n-                    //Map<UUID, StatsCollectionRequest> msgs = reqs.stream().collect(Collectors.toMap(\n-                    //        StatsAddrRequest::nodeId, StatsAddrRequest::req));\n                     // TODO: resend it\n                     sendRequests(reqs);\n                 } catch (IgniteCheckedException e) {\n", "next_change": {"commit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 7fab3588e96..f208a744d01 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -868,99 +517,11 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n                 if (log.isDebugEnabled())\n                     log.debug(String.format(\n                             \"Unable to send statistics collection result to node %s in response to colId %s, reqId %s\",\n-                        nodeId, req.colId(), req.reqId()));\n+                        nodeId, req.gatId(), req.reqId()));\n             }\n \n             // Not local collection - remove by its reqId.\n-            currCollections.updateCollection(req.reqId(), s -> null);\n-        }\n-    }\n-\n-    /**\n-     * Schedule statistics collection by specified request.\n-     *\n-     * @param nodeId request origin node.\n-     * @param msg request message.\n-     */\n-    private void handleCollectionRequest(UUID nodeId, StatsCollectionRequest msg) {\n-        assert msg.reqId() != null : \"Got statistics collection request without request id\";\n-\n-        currCollections.addActiveCollectionStatus(msg.reqId(), new StatCollectionStatus(msg.colId(), msg.keys().keySet(), null));\n-\n-        statMgmtPool.submit(() -> processLocal(nodeId, msg));\n-    }\n-\n-    /**\n-     * Send requests to target nodes except of local one.\n-     *\n-     * @param reqs Collection of addressed requests to send.\n-     * @return Collection of addressed requests that has errors while sending or {@code null} if all requests was send\n-     * successfully.\n-     */\n-    private <T extends Message> Collection<StatsAddrRequest<T>> sendRequests(Collection<StatsAddrRequest<T>> reqs) {\n-        UUID locNode = ctx.localNodeId();\n-        Collection<StatsAddrRequest<T>> res = null;\n-\n-        for (StatsAddrRequest<T> req : reqs) {\n-            if (locNode.equals(req.nodeId()))\n-                continue;\n-\n-            try {\n-                ctx.io().sendToCustomTopic(req.nodeId(), TOPIC, req.req(), GridIoPolicy.QUERY_POOL);\n-            }\n-            catch (IgniteCheckedException e) {\n-                if (res == null)\n-                    res = new ArrayList<>();\n-\n-                res.add(req);\n-            }\n-        }\n-\n-        return res;\n-    }\n-\n-    /**\n-     * Handle node left event:\n-     * 1) Cancel all collection tasks which expect specified node statistics result.\n-     * 2) Cancel collection task requested by node left.\n-     *\n-     * @param nodeId leaved node id.\n-     */\n-    private void onNodeLeft(UUID nodeId) {\n-        Map<UUID, Map<StatsKeyMessage, int[]>> failedCollections = new HashMap<>();\n-        currCollections.updateAllCollections(colStat -> {\n-            StatsCollectionRequest[] nodeRequests = (StatsCollectionRequest[])colStat.remainingCollectionReqs()\n-                    .values().stream().filter(\n-                    addReq -> nodeId.equals(addReq.nodeId())).map(StatsAddrRequest::req).toArray();\n-            if (!F.isEmpty(nodeRequests)) {\n-                Map<StatsKeyMessage, int[]> failedKeys = IgniteStatisticsRequestCollection.extractFailed(nodeRequests);\n-                try {\n-                    Collection<StatsAddrRequest<StatsCollectionRequest>> reqs = currCollections\n-                        .generateCollectionRequests(colStat.colId(), colStat.keys(), failedKeys);\n-                    // TODO: resend it\n-                    sendRequests(reqs);\n-                } catch (IgniteCheckedException e) {\n-                    // TODO\n-                    e.printStackTrace();\n-                }\n-\n-            }\n-            return null;\n-        });\n-    }\n-\n-    /**\n-     * Listener to handle nodeLeft/nodeFailed and call onNodeLeft method.\n-     */\n-    private class NodeLeftListener implements GridLocalEventListener {\n-\n-        /** {@inheritDoc} */\n-        @Override public void onEvent(Event evt) {\n-            assert evt.type() == EventType.EVT_NODE_FAILED || evt.type() == EventType.EVT_NODE_LEFT;\n-\n-            final UUID nodeId = ((DiscoveryEvent)evt).eventNode().id();\n-\n-            ctx.closure().runLocalSafe(() -> onNodeLeft(nodeId), GridIoPolicy.QUERY_POOL);\n+            helper.updateCollection(req.reqId(), s -> null);\n         }\n     }\n }\n", "next_change": {"commit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex f208a744d01..1f98ad5ca73 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -523,5 +561,5 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n             // Not local collection - remove by its reqId.\n             helper.updateCollection(req.reqId(), s -> null);\n         }\n-    }\n+    }*/\n }\n", "next_change": {"commit": "e54c934091d0917505fbe4bd919fd766a492897e", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 1f98ad5ca73..c989b5605e7 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -507,59 +487,4 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n        for (StatisticsKeyMessage key : keys)\n            clearObjectStatisticsLocal(key);\n    }\n-\n-    /**\n-     * Collect local object statistics by specified request (possibly for a few objects) and send result back to origin\n-     * node specified. If local node id specified - process result without sending it throw the communication.\n-     *\n-     * @param req request to collect statistics by.\n-     */\n-    /*private void processLocal(UUID nodeId, StatisticsGatheringRequest req) {\n-        UUID locNode = ctx.localNodeId();\n-\n-        StatisticsGatheringContext stat = (nodeId.equals(locNode)) ? helper.getCollection(req.gatId()) :\n-            helper.getCollection(req.reqId());\n-\n-        if (stat == null)\n-            return;\n-\n-        Map<StatisticsObjectData, int[]> collected = new HashMap<>(req.keys().size());\n-        for (Map.Entry<StatisticsKeyMessage, int[]> keyEntry : req.keys().entrySet()) {\n-            try {\n-                StatisticsKeyMessage key = keyEntry.getKey();\n-                IgniteBiTuple <ObjectStatisticsImpl, int[]> loStat = gatherLocalObjectStatisticsAsync(key,\n-                        keyEntry.getValue(), () -> stat.doneFut().isCancelled());\n-                StatisticsKey statsKey = new StatisticsKey(key.schema(), key.obj());\n-\n-                // TODO?\n-                statsRepos.mergeLocalStatistics(statsKey, loStat.getKey());\n-\n-                StatisticsObjectData objData = StatisticsUtils.toObjectData(key, StatisticsType.LOCAL, loStat.getKey());\n-                collected.put(objData, loStat.getValue());\n-            }\n-            catch (IgniteCheckedException e) {\n-                log.warning(String.format(\"Unable to complete request %s due to error %s\", req.reqId(), e.getMessage()));\n-                // TODO: send cancel to originator node\n-            }\n-        }\n-\n-        StatisticsGatheringResponse res = new StatisticsGatheringResponse(req.gatId(), req.reqId(), collected);\n-\n-        if (locNode.equals(nodeId))\n-            receiveLocalStatistics(nodeId, res);\n-        else {\n-            try {\n-                ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n-            }\n-            catch (IgniteCheckedException e) {\n-                if (log.isDebugEnabled())\n-                    log.debug(String.format(\n-                            \"Unable to send statistics collection result to node %s in response to colId %s, reqId %s\",\n-                        nodeId, req.gatId(), req.reqId()));\n-            }\n-\n-            // Not local collection - remove by its reqId.\n-            helper.updateCollection(req.reqId(), s -> null);\n-        }\n-    }*/\n }\n", "next_change": {"commit": "33170812024f6c4d321f85287fea0b6c3abdb9e5", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex c989b5605e7..5011b1a87a5 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -478,13 +458,20 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n         return stat;\n    }\n \n+    /** {@inheritDoc} */\n+    @Override public ObjectStatistics getGlobalStatistics(String schemaName, String objName) {\n+        return statsRepos.getGlobalStatistics(new StatisticsKey(schemaName, objName));\n+    }\n+\n     /**\n-     * Clear object statistics by specified keys.\n+     * Check that all server nodes in the cluster support STATISTICS_COLLECTION features.\n      *\n-     * @param keys Collection of keys to clean statistics by.\n+     * @param op Operation name.\n      */\n-   public void clearObjectStatisticsLocal(Collection<StatisticsKeyMessage> keys) {\n-       for (StatisticsKeyMessage key : keys)\n-           clearObjectStatisticsLocal(key);\n+   private void checkSupport(String op) throws IgniteCheckedException {\n+       if (!IgniteFeatures.allNodesSupport(ctx, IgniteFeatures.STATISTICS_COLLECTION, IgniteDiscoverySpi.SRV_NODES)) {\n+           throw new IgniteCheckedException(String.format(\n+               \"Unable to perform %s due to not all server nodes supports STATISTICS_COLLECTION feature.\", op));\n+       }\n    }\n }\n", "next_change": {"commit": "f5aafee54b1036c09d4944ca9bf0254f8bfd2b1e", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 5011b1a87a5..4df3ed6f1e0 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -464,11 +485,13 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n     }\n \n     /**\n-     * Check that all server nodes in the cluster support STATISTICS_COLLECTION features.\n+     * Check that all server nodes in the cluster support STATISTICS_COLLECTION feature. Throws IgniteCheckedException\n+     * in not.\n      *\n      * @param op Operation name.\n+     * @throws IgniteCheckedException If at least one server node doesn't support feature.\n      */\n-   private void checkSupport(String op) throws IgniteCheckedException {\n+   private void checkStatisticsSupport(String op) throws IgniteCheckedException {\n        if (!IgniteFeatures.allNodesSupport(ctx, IgniteFeatures.STATISTICS_COLLECTION, IgniteDiscoverySpi.SRV_NODES)) {\n            throw new IgniteCheckedException(String.format(\n                \"Unable to perform %s due to not all server nodes supports STATISTICS_COLLECTION feature.\", op));\n", "next_change": {"commit": "65caf2d646409c3be32c4d00f762fcdc7ec4ceb0", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 4df3ed6f1e0..47277987f34 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -492,9 +492,18 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n      * @throws IgniteCheckedException If at least one server node doesn't support feature.\n      */\n    private void checkStatisticsSupport(String op) throws IgniteCheckedException {\n-       if (!IgniteFeatures.allNodesSupport(ctx, IgniteFeatures.STATISTICS_COLLECTION, IgniteDiscoverySpi.SRV_NODES)) {\n+       if (!isStatisticsSupport()) {\n            throw new IgniteCheckedException(String.format(\n                \"Unable to perform %s due to not all server nodes supports STATISTICS_COLLECTION feature.\", op));\n        }\n    }\n+\n+    /**\n+     * Test is statistics collection feature are supported by each server node in cluster.\n+     *\n+     * @return {@code true} if all server nodes support STATISTICS_COLLECTION feature, {@code false} - otherwise.\n+     */\n+   private boolean isStatisticsSupport() {\n+       return IgniteFeatures.allNodesSupport(ctx, IgniteFeatures.STATISTICS_COLLECTION, IgniteDiscoverySpi.SRV_NODES);\n+   }\n }\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc2NzYwNg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546767606", "body": "uncertain TODO", "bodyText": "uncertain TODO", "bodyHTML": "<p dir=\"auto\">uncertain TODO</p>", "author": "korlov42", "createdAt": "2020-12-21T15:25:35Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -278,4 +614,373 @@ private ObjectStatisticsImpl aggregateLocalStatistics(\n \n         return tblStats;\n     }\n+\n+    /**\n+     * Receive and handle statistics propagation message with partitions statistics.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receivePartitionsStatistics(UUID nodeId, StatsPropagationMessage msg) throws IgniteCheckedException {\n+        UUID locNode = ctx.localNodeId();\n+        for (StatsObjectData partData : msg.data()) {\n+            StatsKey key = new StatsKey(partData.key().schema(), partData.key().obj());\n+\n+            assert partData.type() == StatsType.PARTITION : \"Got non partition level statistics by \" + key\n+                    + \" without request\";\n+\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d from node %s\", key.schema(),\n+                        key.obj(), partData.partId(), nodeId));\n+\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(locNode, partData.partId());\n+            if (partState != OWNING) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+\n+            ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n+\n+            statsRepos.saveLocalPartitionStatistics(key, opStat);\n+        }\n+    }\n+\n+    /**\n+     * Receive and handle statistics propagation message as response for collection request.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receiveLocalStatistics(UUID nodeId, StatsCollectionResponse msg) {\n+        assert msg.data().keySet().stream().noneMatch(pd -> pd.type() == StatsType.PARTITION)\n+                : \"Got partition statistics by request \" + msg.reqId();\n+\n+        currCollections.updateCollection(msg.colId(), stat -> {\n+            if (stat == null) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\n+                        \"Ignoring outdated local statistics collection response from node %s to col %s req %s\",\n+                            nodeId, msg.colId(), msg.reqId()));\n+\n+                return stat;\n+            }\n+\n+            assert stat.colId().equals(msg.colId());\n+\n+            // Need syncronization here to avoid races between removing remaining reqs and adding new ones.\n+            synchronized (stat) {\n+                StatsAddrRequest<StatsCollectionRequest> req = stat.remainingCollectionReqs().remove(msg.reqId());\n+\n+                if (req == null) {\n+                    if (log.isDebugEnabled())\n+                        log.debug(String.format(\n+                                \"Ignoring unknown local statistics collection response from node %s to col %s req %s\",\n+                                nodeId, msg.colId(), msg.reqId()));\n+\n+                    return stat;\n+                }\n+\n+                stat.localStatistics().add(msg);\n+                // TODO: reschedule if not all partition collected.\n+\n+                if (stat.remainingCollectionReqs().isEmpty()) {\n+                    Map<StatsKey, ObjectStatisticsImpl> mergedGlobal = finishStatCollection(stat);\n+\n+                    stat.doneFut().onDone(null);\n+\n+                    return null;\n+                }\n+            }\n+            return stat;\n+        });\n+    }\n+\n+    /**\n+     * Aggregate local statistics to global one.\n+     *\n+     * @param stat Statistics collection status to aggregate.\n+     * @return Map stats key to merged global statistics.\n+     */\n+    private Map<StatsKey, ObjectStatisticsImpl> finishStatCollection(StatCollectionStatus stat) {\n+        Map<StatsKeyMessage, Collection<ObjectStatisticsImpl>> keysStats = new HashMap<>();\n+        for (StatsCollectionResponse resp : stat.localStatistics()) {\n+            for (StatsObjectData objData : resp.data().keySet()) {\n+                keysStats.compute(objData.key(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+                    try {\n+                        ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n+\n+                        v.add(objStat);\n+                    } catch (IgniteCheckedException e) {\n+                        if (log.isInfoEnabled())\n+                            log.info(String.format(\"Unable to parse statistics for object %s from response %s\",\n+                                    objData.key(), resp.reqId()));\n+                    }\n+\n+                    return v;\n+                });\n+            }\n+        }\n+\n+        Map<StatsKey, ObjectStatisticsImpl> res = new HashMap<>();\n+        for (Map.Entry<StatsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : keysStats.entrySet()) {\n+            StatsKeyMessage keyMsg = keyStats.getKey();\n+            GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Unable to find object %s.%s to save collected statistics by.\",\n+                            keyMsg.schema(), keyMsg.obj()));\n+\n+                continue;\n+            }\n+            ObjectStatisticsImpl globalStat = aggregateLocalStatistics(keyMsg, keyStats.getValue());\n+            StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+            res.put(key, statsRepos.mergeGlobalStatistics(key, globalStat));\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Send statistics by request.\n+     *\n+     * @param nodeId Node to send statistics to.\n+     * @param msg Statistics request to process.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void supplyStatistics(UUID nodeId, StatsGetRequest msg) throws IgniteCheckedException {\n+        List<StatsObjectData> data = new ArrayList<>(msg.keys().size());\n+        for (StatsKeyMessage keyMsg : msg.keys()) {\n+            StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+            ObjectStatisticsImpl objStats = statsRepos.getGlobalStatistics(key);\n+\n+            if (objStats != null)\n+                data.add(StatisticsUtils.toObjectData(keyMsg, StatsType.GLOBAL, objStats));\n+        }\n+        StatsPropagationMessage res = new StatsPropagationMessage(data);\n+        ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n+    }\n+\n+    /**\n+     * Cancel local statistics collection task.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Cancel request.\n+     */\n+    private void cancelStatisticsCollection(UUID nodeId, CancelStatsCollectionRequest msg) {\n+        for (UUID reqId : msg.reqIds()) {\n+            currCollections.updateCollection(reqId, stat -> {\n+                if (stat == null) {\n+                    if (log.isDebugEnabled())\n+                        log.debug(String.format(\"Unable to cancel statistics collection %s by req %s from node %s\",\n+                                msg.colId(), reqId, nodeId));\n+\n+                    return null;\n+                }\n+\n+                stat.doneFut().cancel();\n+\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Cancelling statistics collection by colId = %s, reqId = %s from node %s\",\n+                            msg.colId(), reqId, nodeId));\n+\n+                return null;\n+            });\n+        }\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void onMessage(UUID nodeId, Object msg, byte plc) {\n+        try {\n+            if (msg instanceof StatsPropagationMessage)\n+                receivePartitionsStatistics(nodeId, (StatsPropagationMessage) msg);\n+            else if (msg instanceof StatsCollectionResponse)\n+                receiveLocalStatistics(nodeId, (StatsCollectionResponse) msg);\n+            else if (msg instanceof StatsGetRequest)\n+                supplyStatistics(nodeId, (StatsGetRequest) msg);\n+            else if (msg instanceof StatsCollectionRequest)\n+                handleCollectionRequest(nodeId, (StatsCollectionRequest)msg);\n+            else if (msg instanceof CancelStatsCollectionRequest)\n+                cancelStatisticsCollection(nodeId, (CancelStatsCollectionRequest) msg);\n+            else if (msg instanceof StatsClearRequest)\n+                clearObjectStatistics(nodeId, (StatsClearRequest)msg);\n+            else\n+                log.warning(\"Unknown msg \" + msg +  \" in statistics topic \" + TOPIC + \" from node \" + nodeId);\n+        } catch (IgniteCheckedException e) {\n+            log.warning(\"Statistic msg from node \" + nodeId + \" processing failed\", e);\n+        }\n+    }\n+\n+    /**\n+     * Handle statistics clear request.\n+     *\n+     * @param nodeId UUID of request sender node.\n+     * @param msg Clear request message.\n+     */\n+    private void clearObjectStatistics(UUID nodeId, StatsClearRequest msg) {\n+        for (StatsKeyMessage key : msg.keys()) {\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Clearing statistics by request %s from node %s by key %s.%s\", msg.reqId(),\n+                        nodeId, key.schema(), key.obj()));\n+            statMgmtPool.submit(() -> clearObjectStatisticsLocal(key));\n+        }\n+    }\n+\n+    /**\n+     * Collect local object statistics by specified request (possibly for a few objects) and send result back to origin\n+     * node specified. If local node id specified - process result without sending it throw the communication.\n+     *\n+     * @param req request to collect statistics by.\n+     */\n+    private void processLocal(UUID nodeId, StatsCollectionRequest req) {\n+        UUID locNode = ctx.localNodeId();\n+\n+        StatCollectionStatus stat = (nodeId.equals(locNode)) ? currCollections.getCollection(req.colId()) :\n+            currCollections.getCollection(req.reqId());\n+\n+        if (stat == null)\n+            return;\n+\n+        Map<StatsObjectData, int[]> collected = new HashMap<>(req.keys().size());\n+        for (Map.Entry<StatsKeyMessage, int[]> keyEntry : req.keys().entrySet()) {\n+            try {\n+                StatsKeyMessage key = keyEntry.getKey();\n+                IgniteBiTuple <ObjectStatisticsImpl, int[]> loStat = collectLocalObjectStatistics(key,\n+                        keyEntry.getValue(), () -> stat.doneFut().isCancelled());\n+                StatsKey statsKey = new StatsKey(key.schema(), key.obj());\n+\n+                // TODO?\n+                statsRepos.mergeLocalStatistics(statsKey, loStat.getKey());\n+\n+                StatsObjectData objData = StatisticsUtils.toObjectData(key, StatsType.LOCAL, loStat.getKey());\n+                collected.put(objData, loStat.getValue());\n+            }\n+            catch (IgniteCheckedException e) {\n+                log.warning(String.format(\"Unable to complete request %s due to error %s\", req.reqId(), e.getMessage()));\n+                // TODO: send cancel to originator node\n+            }\n+        }\n+\n+        StatsCollectionResponse res = new StatsCollectionResponse(req.colId(), req.reqId(), collected);\n+\n+        if (locNode.equals(nodeId))\n+            receiveLocalStatistics(nodeId, res);\n+        else {\n+            try {\n+                ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\n+                            \"Unable to send statistics collection result to node %s in response to colId %s, reqId %s\",\n+                        nodeId, req.colId(), req.reqId()));\n+            }\n+\n+            // Not local collection - remove by its reqId.\n+            currCollections.updateCollection(req.reqId(), s -> null);\n+        }\n+    }\n+\n+    /**\n+     * Schedule statistics collection by specified request.\n+     *\n+     * @param nodeId request origin node.\n+     * @param msg request message.\n+     */\n+    private void handleCollectionRequest(UUID nodeId, StatsCollectionRequest msg) {\n+        assert msg.reqId() != null : \"Got statistics collection request without request id\";\n+\n+        currCollections.addActiveCollectionStatus(msg.reqId(), new StatCollectionStatus(msg.colId(), msg.keys().keySet(), null));\n+\n+        statMgmtPool.submit(() -> processLocal(nodeId, msg));\n+    }\n+\n+    /**\n+     * Send requests to target nodes except of local one.\n+     *\n+     * @param reqs Collection of addressed requests to send.\n+     * @return Collection of addressed requests that has errors while sending or {@code null} if all requests was send\n+     * successfully.\n+     */\n+    private <T extends Message> Collection<StatsAddrRequest<T>> sendRequests(Collection<StatsAddrRequest<T>> reqs) {\n+        UUID locNode = ctx.localNodeId();\n+        Collection<StatsAddrRequest<T>> res = null;\n+\n+        for (StatsAddrRequest<T> req : reqs) {\n+            if (locNode.equals(req.nodeId()))\n+                continue;\n+\n+            try {\n+                ctx.io().sendToCustomTopic(req.nodeId(), TOPIC, req.req(), GridIoPolicy.QUERY_POOL);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (res == null)\n+                    res = new ArrayList<>();\n+\n+                res.add(req);\n+            }\n+        }\n+\n+        return res;\n+    }\n+\n+    /**\n+     * Handle node left event:\n+     * 1) Cancel all collection tasks which expect specified node statistics result.\n+     * 2) Cancel collection task requested by node left.\n+     *\n+     * @param nodeId leaved node id.\n+     */\n+    private void onNodeLeft(UUID nodeId) {\n+        Map<UUID, Map<StatsKeyMessage, int[]>> failedCollections = new HashMap<>();\n+        currCollections.updateAllCollections(colStat -> {\n+            StatsCollectionRequest[] nodeRequests = (StatsCollectionRequest[])colStat.remainingCollectionReqs()\n+                    .values().stream().filter(\n+                    addReq -> nodeId.equals(addReq.nodeId())).map(StatsAddrRequest::req).toArray();\n+            if (!F.isEmpty(nodeRequests)) {\n+                Map<StatsKeyMessage, int[]> failedKeys = IgniteStatisticsRequestCollection.extractFailed(nodeRequests);\n+                try {\n+                    Collection<StatsAddrRequest<StatsCollectionRequest>> reqs = currCollections\n+                        .generateCollectionRequests(colStat.colId(), colStat.keys(), failedKeys);\n+                    //Map<UUID, StatsCollectionRequest> msgs = reqs.stream().collect(Collectors.toMap(\n+                    //        StatsAddrRequest::nodeId, StatsAddrRequest::req));\n+                    // TODO: resend it\n+                    sendRequests(reqs);\n+                } catch (IgniteCheckedException e) {\n+                    // TODO", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTAyNTY5NA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555025694", "bodyText": "removed", "author": "Berkof", "createdAt": "2021-01-11T12:52:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc2NzYwNg=="}], "type": "inlineReview", "revised_code": {"commit": "b595e90b5b480aaf80a9256558b1841334df97de", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 0f88eff3479..7fab3588e96 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -955,8 +937,6 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n                 try {\n                     Collection<StatsAddrRequest<StatsCollectionRequest>> reqs = currCollections\n                         .generateCollectionRequests(colStat.colId(), colStat.keys(), failedKeys);\n-                    //Map<UUID, StatsCollectionRequest> msgs = reqs.stream().collect(Collectors.toMap(\n-                    //        StatsAddrRequest::nodeId, StatsAddrRequest::req));\n                     // TODO: resend it\n                     sendRequests(reqs);\n                 } catch (IgniteCheckedException e) {\n", "next_change": {"commit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 7fab3588e96..f208a744d01 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -868,99 +517,11 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n                 if (log.isDebugEnabled())\n                     log.debug(String.format(\n                             \"Unable to send statistics collection result to node %s in response to colId %s, reqId %s\",\n-                        nodeId, req.colId(), req.reqId()));\n+                        nodeId, req.gatId(), req.reqId()));\n             }\n \n             // Not local collection - remove by its reqId.\n-            currCollections.updateCollection(req.reqId(), s -> null);\n-        }\n-    }\n-\n-    /**\n-     * Schedule statistics collection by specified request.\n-     *\n-     * @param nodeId request origin node.\n-     * @param msg request message.\n-     */\n-    private void handleCollectionRequest(UUID nodeId, StatsCollectionRequest msg) {\n-        assert msg.reqId() != null : \"Got statistics collection request without request id\";\n-\n-        currCollections.addActiveCollectionStatus(msg.reqId(), new StatCollectionStatus(msg.colId(), msg.keys().keySet(), null));\n-\n-        statMgmtPool.submit(() -> processLocal(nodeId, msg));\n-    }\n-\n-    /**\n-     * Send requests to target nodes except of local one.\n-     *\n-     * @param reqs Collection of addressed requests to send.\n-     * @return Collection of addressed requests that has errors while sending or {@code null} if all requests was send\n-     * successfully.\n-     */\n-    private <T extends Message> Collection<StatsAddrRequest<T>> sendRequests(Collection<StatsAddrRequest<T>> reqs) {\n-        UUID locNode = ctx.localNodeId();\n-        Collection<StatsAddrRequest<T>> res = null;\n-\n-        for (StatsAddrRequest<T> req : reqs) {\n-            if (locNode.equals(req.nodeId()))\n-                continue;\n-\n-            try {\n-                ctx.io().sendToCustomTopic(req.nodeId(), TOPIC, req.req(), GridIoPolicy.QUERY_POOL);\n-            }\n-            catch (IgniteCheckedException e) {\n-                if (res == null)\n-                    res = new ArrayList<>();\n-\n-                res.add(req);\n-            }\n-        }\n-\n-        return res;\n-    }\n-\n-    /**\n-     * Handle node left event:\n-     * 1) Cancel all collection tasks which expect specified node statistics result.\n-     * 2) Cancel collection task requested by node left.\n-     *\n-     * @param nodeId leaved node id.\n-     */\n-    private void onNodeLeft(UUID nodeId) {\n-        Map<UUID, Map<StatsKeyMessage, int[]>> failedCollections = new HashMap<>();\n-        currCollections.updateAllCollections(colStat -> {\n-            StatsCollectionRequest[] nodeRequests = (StatsCollectionRequest[])colStat.remainingCollectionReqs()\n-                    .values().stream().filter(\n-                    addReq -> nodeId.equals(addReq.nodeId())).map(StatsAddrRequest::req).toArray();\n-            if (!F.isEmpty(nodeRequests)) {\n-                Map<StatsKeyMessage, int[]> failedKeys = IgniteStatisticsRequestCollection.extractFailed(nodeRequests);\n-                try {\n-                    Collection<StatsAddrRequest<StatsCollectionRequest>> reqs = currCollections\n-                        .generateCollectionRequests(colStat.colId(), colStat.keys(), failedKeys);\n-                    // TODO: resend it\n-                    sendRequests(reqs);\n-                } catch (IgniteCheckedException e) {\n-                    // TODO\n-                    e.printStackTrace();\n-                }\n-\n-            }\n-            return null;\n-        });\n-    }\n-\n-    /**\n-     * Listener to handle nodeLeft/nodeFailed and call onNodeLeft method.\n-     */\n-    private class NodeLeftListener implements GridLocalEventListener {\n-\n-        /** {@inheritDoc} */\n-        @Override public void onEvent(Event evt) {\n-            assert evt.type() == EventType.EVT_NODE_FAILED || evt.type() == EventType.EVT_NODE_LEFT;\n-\n-            final UUID nodeId = ((DiscoveryEvent)evt).eventNode().id();\n-\n-            ctx.closure().runLocalSafe(() -> onNodeLeft(nodeId), GridIoPolicy.QUERY_POOL);\n+            helper.updateCollection(req.reqId(), s -> null);\n         }\n     }\n }\n", "next_change": {"commit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex f208a744d01..1f98ad5ca73 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -523,5 +561,5 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n             // Not local collection - remove by its reqId.\n             helper.updateCollection(req.reqId(), s -> null);\n         }\n-    }\n+    }*/\n }\n", "next_change": {"commit": "e54c934091d0917505fbe4bd919fd766a492897e", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 1f98ad5ca73..c989b5605e7 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -507,59 +487,4 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n        for (StatisticsKeyMessage key : keys)\n            clearObjectStatisticsLocal(key);\n    }\n-\n-    /**\n-     * Collect local object statistics by specified request (possibly for a few objects) and send result back to origin\n-     * node specified. If local node id specified - process result without sending it throw the communication.\n-     *\n-     * @param req request to collect statistics by.\n-     */\n-    /*private void processLocal(UUID nodeId, StatisticsGatheringRequest req) {\n-        UUID locNode = ctx.localNodeId();\n-\n-        StatisticsGatheringContext stat = (nodeId.equals(locNode)) ? helper.getCollection(req.gatId()) :\n-            helper.getCollection(req.reqId());\n-\n-        if (stat == null)\n-            return;\n-\n-        Map<StatisticsObjectData, int[]> collected = new HashMap<>(req.keys().size());\n-        for (Map.Entry<StatisticsKeyMessage, int[]> keyEntry : req.keys().entrySet()) {\n-            try {\n-                StatisticsKeyMessage key = keyEntry.getKey();\n-                IgniteBiTuple <ObjectStatisticsImpl, int[]> loStat = gatherLocalObjectStatisticsAsync(key,\n-                        keyEntry.getValue(), () -> stat.doneFut().isCancelled());\n-                StatisticsKey statsKey = new StatisticsKey(key.schema(), key.obj());\n-\n-                // TODO?\n-                statsRepos.mergeLocalStatistics(statsKey, loStat.getKey());\n-\n-                StatisticsObjectData objData = StatisticsUtils.toObjectData(key, StatisticsType.LOCAL, loStat.getKey());\n-                collected.put(objData, loStat.getValue());\n-            }\n-            catch (IgniteCheckedException e) {\n-                log.warning(String.format(\"Unable to complete request %s due to error %s\", req.reqId(), e.getMessage()));\n-                // TODO: send cancel to originator node\n-            }\n-        }\n-\n-        StatisticsGatheringResponse res = new StatisticsGatheringResponse(req.gatId(), req.reqId(), collected);\n-\n-        if (locNode.equals(nodeId))\n-            receiveLocalStatistics(nodeId, res);\n-        else {\n-            try {\n-                ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n-            }\n-            catch (IgniteCheckedException e) {\n-                if (log.isDebugEnabled())\n-                    log.debug(String.format(\n-                            \"Unable to send statistics collection result to node %s in response to colId %s, reqId %s\",\n-                        nodeId, req.gatId(), req.reqId()));\n-            }\n-\n-            // Not local collection - remove by its reqId.\n-            helper.updateCollection(req.reqId(), s -> null);\n-        }\n-    }*/\n }\n", "next_change": {"commit": "33170812024f6c4d321f85287fea0b6c3abdb9e5", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex c989b5605e7..5011b1a87a5 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -478,13 +458,20 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n         return stat;\n    }\n \n+    /** {@inheritDoc} */\n+    @Override public ObjectStatistics getGlobalStatistics(String schemaName, String objName) {\n+        return statsRepos.getGlobalStatistics(new StatisticsKey(schemaName, objName));\n+    }\n+\n     /**\n-     * Clear object statistics by specified keys.\n+     * Check that all server nodes in the cluster support STATISTICS_COLLECTION features.\n      *\n-     * @param keys Collection of keys to clean statistics by.\n+     * @param op Operation name.\n      */\n-   public void clearObjectStatisticsLocal(Collection<StatisticsKeyMessage> keys) {\n-       for (StatisticsKeyMessage key : keys)\n-           clearObjectStatisticsLocal(key);\n+   private void checkSupport(String op) throws IgniteCheckedException {\n+       if (!IgniteFeatures.allNodesSupport(ctx, IgniteFeatures.STATISTICS_COLLECTION, IgniteDiscoverySpi.SRV_NODES)) {\n+           throw new IgniteCheckedException(String.format(\n+               \"Unable to perform %s due to not all server nodes supports STATISTICS_COLLECTION feature.\", op));\n+       }\n    }\n }\n", "next_change": {"commit": "f5aafee54b1036c09d4944ca9bf0254f8bfd2b1e", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 5011b1a87a5..4df3ed6f1e0 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -464,11 +485,13 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n     }\n \n     /**\n-     * Check that all server nodes in the cluster support STATISTICS_COLLECTION features.\n+     * Check that all server nodes in the cluster support STATISTICS_COLLECTION feature. Throws IgniteCheckedException\n+     * in not.\n      *\n      * @param op Operation name.\n+     * @throws IgniteCheckedException If at least one server node doesn't support feature.\n      */\n-   private void checkSupport(String op) throws IgniteCheckedException {\n+   private void checkStatisticsSupport(String op) throws IgniteCheckedException {\n        if (!IgniteFeatures.allNodesSupport(ctx, IgniteFeatures.STATISTICS_COLLECTION, IgniteDiscoverySpi.SRV_NODES)) {\n            throw new IgniteCheckedException(String.format(\n                \"Unable to perform %s due to not all server nodes supports STATISTICS_COLLECTION feature.\", op));\n", "next_change": {"commit": "65caf2d646409c3be32c4d00f762fcdc7ec4ceb0", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 4df3ed6f1e0..47277987f34 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -492,9 +492,18 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n      * @throws IgniteCheckedException If at least one server node doesn't support feature.\n      */\n    private void checkStatisticsSupport(String op) throws IgniteCheckedException {\n-       if (!IgniteFeatures.allNodesSupport(ctx, IgniteFeatures.STATISTICS_COLLECTION, IgniteDiscoverySpi.SRV_NODES)) {\n+       if (!isStatisticsSupport()) {\n            throw new IgniteCheckedException(String.format(\n                \"Unable to perform %s due to not all server nodes supports STATISTICS_COLLECTION feature.\", op));\n        }\n    }\n+\n+    /**\n+     * Test is statistics collection feature are supported by each server node in cluster.\n+     *\n+     * @return {@code true} if all server nodes support STATISTICS_COLLECTION feature, {@code false} - otherwise.\n+     */\n+   private boolean isStatisticsSupport() {\n+       return IgniteFeatures.allNodesSupport(ctx, IgniteFeatures.STATISTICS_COLLECTION, IgniteDiscoverySpi.SRV_NODES);\n+   }\n }\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc2Nzg4Mw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546767883", "body": "failedCollections is not used", "bodyText": "failedCollections is not used", "bodyHTML": "<p dir=\"auto\">failedCollections is not used</p>", "author": "korlov42", "createdAt": "2020-12-21T15:26:01Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -278,4 +614,373 @@ private ObjectStatisticsImpl aggregateLocalStatistics(\n \n         return tblStats;\n     }\n+\n+    /**\n+     * Receive and handle statistics propagation message with partitions statistics.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receivePartitionsStatistics(UUID nodeId, StatsPropagationMessage msg) throws IgniteCheckedException {\n+        UUID locNode = ctx.localNodeId();\n+        for (StatsObjectData partData : msg.data()) {\n+            StatsKey key = new StatsKey(partData.key().schema(), partData.key().obj());\n+\n+            assert partData.type() == StatsType.PARTITION : \"Got non partition level statistics by \" + key\n+                    + \" without request\";\n+\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d from node %s\", key.schema(),\n+                        key.obj(), partData.partId(), nodeId));\n+\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(locNode, partData.partId());\n+            if (partState != OWNING) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d from node %s\",\n+                            key.schema(), key.obj(), partData.partId(), nodeId));\n+\n+                continue;\n+            }\n+\n+            ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n+\n+            statsRepos.saveLocalPartitionStatistics(key, opStat);\n+        }\n+    }\n+\n+    /**\n+     * Receive and handle statistics propagation message as response for collection request.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Statistics propagation message with partitions statistics to handle.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void receiveLocalStatistics(UUID nodeId, StatsCollectionResponse msg) {\n+        assert msg.data().keySet().stream().noneMatch(pd -> pd.type() == StatsType.PARTITION)\n+                : \"Got partition statistics by request \" + msg.reqId();\n+\n+        currCollections.updateCollection(msg.colId(), stat -> {\n+            if (stat == null) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\n+                        \"Ignoring outdated local statistics collection response from node %s to col %s req %s\",\n+                            nodeId, msg.colId(), msg.reqId()));\n+\n+                return stat;\n+            }\n+\n+            assert stat.colId().equals(msg.colId());\n+\n+            // Need syncronization here to avoid races between removing remaining reqs and adding new ones.\n+            synchronized (stat) {\n+                StatsAddrRequest<StatsCollectionRequest> req = stat.remainingCollectionReqs().remove(msg.reqId());\n+\n+                if (req == null) {\n+                    if (log.isDebugEnabled())\n+                        log.debug(String.format(\n+                                \"Ignoring unknown local statistics collection response from node %s to col %s req %s\",\n+                                nodeId, msg.colId(), msg.reqId()));\n+\n+                    return stat;\n+                }\n+\n+                stat.localStatistics().add(msg);\n+                // TODO: reschedule if not all partition collected.\n+\n+                if (stat.remainingCollectionReqs().isEmpty()) {\n+                    Map<StatsKey, ObjectStatisticsImpl> mergedGlobal = finishStatCollection(stat);\n+\n+                    stat.doneFut().onDone(null);\n+\n+                    return null;\n+                }\n+            }\n+            return stat;\n+        });\n+    }\n+\n+    /**\n+     * Aggregate local statistics to global one.\n+     *\n+     * @param stat Statistics collection status to aggregate.\n+     * @return Map stats key to merged global statistics.\n+     */\n+    private Map<StatsKey, ObjectStatisticsImpl> finishStatCollection(StatCollectionStatus stat) {\n+        Map<StatsKeyMessage, Collection<ObjectStatisticsImpl>> keysStats = new HashMap<>();\n+        for (StatsCollectionResponse resp : stat.localStatistics()) {\n+            for (StatsObjectData objData : resp.data().keySet()) {\n+                keysStats.compute(objData.key(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+                    try {\n+                        ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n+\n+                        v.add(objStat);\n+                    } catch (IgniteCheckedException e) {\n+                        if (log.isInfoEnabled())\n+                            log.info(String.format(\"Unable to parse statistics for object %s from response %s\",\n+                                    objData.key(), resp.reqId()));\n+                    }\n+\n+                    return v;\n+                });\n+            }\n+        }\n+\n+        Map<StatsKey, ObjectStatisticsImpl> res = new HashMap<>();\n+        for (Map.Entry<StatsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : keysStats.entrySet()) {\n+            StatsKeyMessage keyMsg = keyStats.getKey();\n+            GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Unable to find object %s.%s to save collected statistics by.\",\n+                            keyMsg.schema(), keyMsg.obj()));\n+\n+                continue;\n+            }\n+            ObjectStatisticsImpl globalStat = aggregateLocalStatistics(keyMsg, keyStats.getValue());\n+            StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+            res.put(key, statsRepos.mergeGlobalStatistics(key, globalStat));\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Send statistics by request.\n+     *\n+     * @param nodeId Node to send statistics to.\n+     * @param msg Statistics request to process.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void supplyStatistics(UUID nodeId, StatsGetRequest msg) throws IgniteCheckedException {\n+        List<StatsObjectData> data = new ArrayList<>(msg.keys().size());\n+        for (StatsKeyMessage keyMsg : msg.keys()) {\n+            StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+            ObjectStatisticsImpl objStats = statsRepos.getGlobalStatistics(key);\n+\n+            if (objStats != null)\n+                data.add(StatisticsUtils.toObjectData(keyMsg, StatsType.GLOBAL, objStats));\n+        }\n+        StatsPropagationMessage res = new StatsPropagationMessage(data);\n+        ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n+    }\n+\n+    /**\n+     * Cancel local statistics collection task.\n+     *\n+     * @param nodeId Sender node id.\n+     * @param msg Cancel request.\n+     */\n+    private void cancelStatisticsCollection(UUID nodeId, CancelStatsCollectionRequest msg) {\n+        for (UUID reqId : msg.reqIds()) {\n+            currCollections.updateCollection(reqId, stat -> {\n+                if (stat == null) {\n+                    if (log.isDebugEnabled())\n+                        log.debug(String.format(\"Unable to cancel statistics collection %s by req %s from node %s\",\n+                                msg.colId(), reqId, nodeId));\n+\n+                    return null;\n+                }\n+\n+                stat.doneFut().cancel();\n+\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Cancelling statistics collection by colId = %s, reqId = %s from node %s\",\n+                            msg.colId(), reqId, nodeId));\n+\n+                return null;\n+            });\n+        }\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void onMessage(UUID nodeId, Object msg, byte plc) {\n+        try {\n+            if (msg instanceof StatsPropagationMessage)\n+                receivePartitionsStatistics(nodeId, (StatsPropagationMessage) msg);\n+            else if (msg instanceof StatsCollectionResponse)\n+                receiveLocalStatistics(nodeId, (StatsCollectionResponse) msg);\n+            else if (msg instanceof StatsGetRequest)\n+                supplyStatistics(nodeId, (StatsGetRequest) msg);\n+            else if (msg instanceof StatsCollectionRequest)\n+                handleCollectionRequest(nodeId, (StatsCollectionRequest)msg);\n+            else if (msg instanceof CancelStatsCollectionRequest)\n+                cancelStatisticsCollection(nodeId, (CancelStatsCollectionRequest) msg);\n+            else if (msg instanceof StatsClearRequest)\n+                clearObjectStatistics(nodeId, (StatsClearRequest)msg);\n+            else\n+                log.warning(\"Unknown msg \" + msg +  \" in statistics topic \" + TOPIC + \" from node \" + nodeId);\n+        } catch (IgniteCheckedException e) {\n+            log.warning(\"Statistic msg from node \" + nodeId + \" processing failed\", e);\n+        }\n+    }\n+\n+    /**\n+     * Handle statistics clear request.\n+     *\n+     * @param nodeId UUID of request sender node.\n+     * @param msg Clear request message.\n+     */\n+    private void clearObjectStatistics(UUID nodeId, StatsClearRequest msg) {\n+        for (StatsKeyMessage key : msg.keys()) {\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Clearing statistics by request %s from node %s by key %s.%s\", msg.reqId(),\n+                        nodeId, key.schema(), key.obj()));\n+            statMgmtPool.submit(() -> clearObjectStatisticsLocal(key));\n+        }\n+    }\n+\n+    /**\n+     * Collect local object statistics by specified request (possibly for a few objects) and send result back to origin\n+     * node specified. If local node id specified - process result without sending it throw the communication.\n+     *\n+     * @param req request to collect statistics by.\n+     */\n+    private void processLocal(UUID nodeId, StatsCollectionRequest req) {\n+        UUID locNode = ctx.localNodeId();\n+\n+        StatCollectionStatus stat = (nodeId.equals(locNode)) ? currCollections.getCollection(req.colId()) :\n+            currCollections.getCollection(req.reqId());\n+\n+        if (stat == null)\n+            return;\n+\n+        Map<StatsObjectData, int[]> collected = new HashMap<>(req.keys().size());\n+        for (Map.Entry<StatsKeyMessage, int[]> keyEntry : req.keys().entrySet()) {\n+            try {\n+                StatsKeyMessage key = keyEntry.getKey();\n+                IgniteBiTuple <ObjectStatisticsImpl, int[]> loStat = collectLocalObjectStatistics(key,\n+                        keyEntry.getValue(), () -> stat.doneFut().isCancelled());\n+                StatsKey statsKey = new StatsKey(key.schema(), key.obj());\n+\n+                // TODO?\n+                statsRepos.mergeLocalStatistics(statsKey, loStat.getKey());\n+\n+                StatsObjectData objData = StatisticsUtils.toObjectData(key, StatsType.LOCAL, loStat.getKey());\n+                collected.put(objData, loStat.getValue());\n+            }\n+            catch (IgniteCheckedException e) {\n+                log.warning(String.format(\"Unable to complete request %s due to error %s\", req.reqId(), e.getMessage()));\n+                // TODO: send cancel to originator node\n+            }\n+        }\n+\n+        StatsCollectionResponse res = new StatsCollectionResponse(req.colId(), req.reqId(), collected);\n+\n+        if (locNode.equals(nodeId))\n+            receiveLocalStatistics(nodeId, res);\n+        else {\n+            try {\n+                ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\n+                            \"Unable to send statistics collection result to node %s in response to colId %s, reqId %s\",\n+                        nodeId, req.colId(), req.reqId()));\n+            }\n+\n+            // Not local collection - remove by its reqId.\n+            currCollections.updateCollection(req.reqId(), s -> null);\n+        }\n+    }\n+\n+    /**\n+     * Schedule statistics collection by specified request.\n+     *\n+     * @param nodeId request origin node.\n+     * @param msg request message.\n+     */\n+    private void handleCollectionRequest(UUID nodeId, StatsCollectionRequest msg) {\n+        assert msg.reqId() != null : \"Got statistics collection request without request id\";\n+\n+        currCollections.addActiveCollectionStatus(msg.reqId(), new StatCollectionStatus(msg.colId(), msg.keys().keySet(), null));\n+\n+        statMgmtPool.submit(() -> processLocal(nodeId, msg));\n+    }\n+\n+    /**\n+     * Send requests to target nodes except of local one.\n+     *\n+     * @param reqs Collection of addressed requests to send.\n+     * @return Collection of addressed requests that has errors while sending or {@code null} if all requests was send\n+     * successfully.\n+     */\n+    private <T extends Message> Collection<StatsAddrRequest<T>> sendRequests(Collection<StatsAddrRequest<T>> reqs) {\n+        UUID locNode = ctx.localNodeId();\n+        Collection<StatsAddrRequest<T>> res = null;\n+\n+        for (StatsAddrRequest<T> req : reqs) {\n+            if (locNode.equals(req.nodeId()))\n+                continue;\n+\n+            try {\n+                ctx.io().sendToCustomTopic(req.nodeId(), TOPIC, req.req(), GridIoPolicy.QUERY_POOL);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (res == null)\n+                    res = new ArrayList<>();\n+\n+                res.add(req);\n+            }\n+        }\n+\n+        return res;\n+    }\n+\n+    /**\n+     * Handle node left event:\n+     * 1) Cancel all collection tasks which expect specified node statistics result.\n+     * 2) Cancel collection task requested by node left.\n+     *\n+     * @param nodeId leaved node id.\n+     */\n+    private void onNodeLeft(UUID nodeId) {\n+        Map<UUID, Map<StatsKeyMessage, int[]>> failedCollections = new HashMap<>();", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjI5MTg5NQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556291895", "bodyText": "fixed in StatisticsGatheringRequestCrawlerImpl", "author": "Berkof", "createdAt": "2021-01-13T06:36:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc2Nzg4Mw=="}], "type": "inlineReview", "revised_code": {"commit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 0f88eff3479..f208a744d01 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -886,101 +517,11 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n                 if (log.isDebugEnabled())\n                     log.debug(String.format(\n                             \"Unable to send statistics collection result to node %s in response to colId %s, reqId %s\",\n-                        nodeId, req.colId(), req.reqId()));\n+                        nodeId, req.gatId(), req.reqId()));\n             }\n \n             // Not local collection - remove by its reqId.\n-            currCollections.updateCollection(req.reqId(), s -> null);\n-        }\n-    }\n-\n-    /**\n-     * Schedule statistics collection by specified request.\n-     *\n-     * @param nodeId request origin node.\n-     * @param msg request message.\n-     */\n-    private void handleCollectionRequest(UUID nodeId, StatsCollectionRequest msg) {\n-        assert msg.reqId() != null : \"Got statistics collection request without request id\";\n-\n-        currCollections.addActiveCollectionStatus(msg.reqId(), new StatCollectionStatus(msg.colId(), msg.keys().keySet(), null));\n-\n-        statMgmtPool.submit(() -> processLocal(nodeId, msg));\n-    }\n-\n-    /**\n-     * Send requests to target nodes except of local one.\n-     *\n-     * @param reqs Collection of addressed requests to send.\n-     * @return Collection of addressed requests that has errors while sending or {@code null} if all requests was send\n-     * successfully.\n-     */\n-    private <T extends Message> Collection<StatsAddrRequest<T>> sendRequests(Collection<StatsAddrRequest<T>> reqs) {\n-        UUID locNode = ctx.localNodeId();\n-        Collection<StatsAddrRequest<T>> res = null;\n-\n-        for (StatsAddrRequest<T> req : reqs) {\n-            if (locNode.equals(req.nodeId()))\n-                continue;\n-\n-            try {\n-                ctx.io().sendToCustomTopic(req.nodeId(), TOPIC, req.req(), GridIoPolicy.QUERY_POOL);\n-            }\n-            catch (IgniteCheckedException e) {\n-                if (res == null)\n-                    res = new ArrayList<>();\n-\n-                res.add(req);\n-            }\n-        }\n-\n-        return res;\n-    }\n-\n-    /**\n-     * Handle node left event:\n-     * 1) Cancel all collection tasks which expect specified node statistics result.\n-     * 2) Cancel collection task requested by node left.\n-     *\n-     * @param nodeId leaved node id.\n-     */\n-    private void onNodeLeft(UUID nodeId) {\n-        Map<UUID, Map<StatsKeyMessage, int[]>> failedCollections = new HashMap<>();\n-        currCollections.updateAllCollections(colStat -> {\n-            StatsCollectionRequest[] nodeRequests = (StatsCollectionRequest[])colStat.remainingCollectionReqs()\n-                    .values().stream().filter(\n-                    addReq -> nodeId.equals(addReq.nodeId())).map(StatsAddrRequest::req).toArray();\n-            if (!F.isEmpty(nodeRequests)) {\n-                Map<StatsKeyMessage, int[]> failedKeys = IgniteStatisticsRequestCollection.extractFailed(nodeRequests);\n-                try {\n-                    Collection<StatsAddrRequest<StatsCollectionRequest>> reqs = currCollections\n-                        .generateCollectionRequests(colStat.colId(), colStat.keys(), failedKeys);\n-                    //Map<UUID, StatsCollectionRequest> msgs = reqs.stream().collect(Collectors.toMap(\n-                    //        StatsAddrRequest::nodeId, StatsAddrRequest::req));\n-                    // TODO: resend it\n-                    sendRequests(reqs);\n-                } catch (IgniteCheckedException e) {\n-                    // TODO\n-                    e.printStackTrace();\n-                }\n-\n-            }\n-            return null;\n-        });\n-    }\n-\n-    /**\n-     * Listener to handle nodeLeft/nodeFailed and call onNodeLeft method.\n-     */\n-    private class NodeLeftListener implements GridLocalEventListener {\n-\n-        /** {@inheritDoc} */\n-        @Override public void onEvent(Event evt) {\n-            assert evt.type() == EventType.EVT_NODE_FAILED || evt.type() == EventType.EVT_NODE_LEFT;\n-\n-            final UUID nodeId = ((DiscoveryEvent)evt).eventNode().id();\n-\n-            ctx.closure().runLocalSafe(() -> onNodeLeft(nodeId), GridIoPolicy.QUERY_POOL);\n+            helper.updateCollection(req.reqId(), s -> null);\n         }\n     }\n }\n", "next_change": {"commit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex f208a744d01..1f98ad5ca73 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -523,5 +561,5 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n             // Not local collection - remove by its reqId.\n             helper.updateCollection(req.reqId(), s -> null);\n         }\n-    }\n+    }*/\n }\n", "next_change": {"commit": "e54c934091d0917505fbe4bd919fd766a492897e", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 1f98ad5ca73..c989b5605e7 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -507,59 +487,4 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n        for (StatisticsKeyMessage key : keys)\n            clearObjectStatisticsLocal(key);\n    }\n-\n-    /**\n-     * Collect local object statistics by specified request (possibly for a few objects) and send result back to origin\n-     * node specified. If local node id specified - process result without sending it throw the communication.\n-     *\n-     * @param req request to collect statistics by.\n-     */\n-    /*private void processLocal(UUID nodeId, StatisticsGatheringRequest req) {\n-        UUID locNode = ctx.localNodeId();\n-\n-        StatisticsGatheringContext stat = (nodeId.equals(locNode)) ? helper.getCollection(req.gatId()) :\n-            helper.getCollection(req.reqId());\n-\n-        if (stat == null)\n-            return;\n-\n-        Map<StatisticsObjectData, int[]> collected = new HashMap<>(req.keys().size());\n-        for (Map.Entry<StatisticsKeyMessage, int[]> keyEntry : req.keys().entrySet()) {\n-            try {\n-                StatisticsKeyMessage key = keyEntry.getKey();\n-                IgniteBiTuple <ObjectStatisticsImpl, int[]> loStat = gatherLocalObjectStatisticsAsync(key,\n-                        keyEntry.getValue(), () -> stat.doneFut().isCancelled());\n-                StatisticsKey statsKey = new StatisticsKey(key.schema(), key.obj());\n-\n-                // TODO?\n-                statsRepos.mergeLocalStatistics(statsKey, loStat.getKey());\n-\n-                StatisticsObjectData objData = StatisticsUtils.toObjectData(key, StatisticsType.LOCAL, loStat.getKey());\n-                collected.put(objData, loStat.getValue());\n-            }\n-            catch (IgniteCheckedException e) {\n-                log.warning(String.format(\"Unable to complete request %s due to error %s\", req.reqId(), e.getMessage()));\n-                // TODO: send cancel to originator node\n-            }\n-        }\n-\n-        StatisticsGatheringResponse res = new StatisticsGatheringResponse(req.gatId(), req.reqId(), collected);\n-\n-        if (locNode.equals(nodeId))\n-            receiveLocalStatistics(nodeId, res);\n-        else {\n-            try {\n-                ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n-            }\n-            catch (IgniteCheckedException e) {\n-                if (log.isDebugEnabled())\n-                    log.debug(String.format(\n-                            \"Unable to send statistics collection result to node %s in response to colId %s, reqId %s\",\n-                        nodeId, req.gatId(), req.reqId()));\n-            }\n-\n-            // Not local collection - remove by its reqId.\n-            helper.updateCollection(req.reqId(), s -> null);\n-        }\n-    }*/\n }\n", "next_change": {"commit": "33170812024f6c4d321f85287fea0b6c3abdb9e5", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex c989b5605e7..5011b1a87a5 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -478,13 +458,20 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n         return stat;\n    }\n \n+    /** {@inheritDoc} */\n+    @Override public ObjectStatistics getGlobalStatistics(String schemaName, String objName) {\n+        return statsRepos.getGlobalStatistics(new StatisticsKey(schemaName, objName));\n+    }\n+\n     /**\n-     * Clear object statistics by specified keys.\n+     * Check that all server nodes in the cluster support STATISTICS_COLLECTION features.\n      *\n-     * @param keys Collection of keys to clean statistics by.\n+     * @param op Operation name.\n      */\n-   public void clearObjectStatisticsLocal(Collection<StatisticsKeyMessage> keys) {\n-       for (StatisticsKeyMessage key : keys)\n-           clearObjectStatisticsLocal(key);\n+   private void checkSupport(String op) throws IgniteCheckedException {\n+       if (!IgniteFeatures.allNodesSupport(ctx, IgniteFeatures.STATISTICS_COLLECTION, IgniteDiscoverySpi.SRV_NODES)) {\n+           throw new IgniteCheckedException(String.format(\n+               \"Unable to perform %s due to not all server nodes supports STATISTICS_COLLECTION feature.\", op));\n+       }\n    }\n }\n", "next_change": {"commit": "f5aafee54b1036c09d4944ca9bf0254f8bfd2b1e", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 5011b1a87a5..4df3ed6f1e0 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -464,11 +485,13 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n     }\n \n     /**\n-     * Check that all server nodes in the cluster support STATISTICS_COLLECTION features.\n+     * Check that all server nodes in the cluster support STATISTICS_COLLECTION feature. Throws IgniteCheckedException\n+     * in not.\n      *\n      * @param op Operation name.\n+     * @throws IgniteCheckedException If at least one server node doesn't support feature.\n      */\n-   private void checkSupport(String op) throws IgniteCheckedException {\n+   private void checkStatisticsSupport(String op) throws IgniteCheckedException {\n        if (!IgniteFeatures.allNodesSupport(ctx, IgniteFeatures.STATISTICS_COLLECTION, IgniteDiscoverySpi.SRV_NODES)) {\n            throw new IgniteCheckedException(String.format(\n                \"Unable to perform %s due to not all server nodes supports STATISTICS_COLLECTION feature.\", op));\n", "next_change": {"commit": "65caf2d646409c3be32c4d00f762fcdc7ec4ceb0", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 4df3ed6f1e0..47277987f34 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -492,9 +492,18 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n      * @throws IgniteCheckedException If at least one server node doesn't support feature.\n      */\n    private void checkStatisticsSupport(String op) throws IgniteCheckedException {\n-       if (!IgniteFeatures.allNodesSupport(ctx, IgniteFeatures.STATISTICS_COLLECTION, IgniteDiscoverySpi.SRV_NODES)) {\n+       if (!isStatisticsSupport()) {\n            throw new IgniteCheckedException(String.format(\n                \"Unable to perform %s due to not all server nodes supports STATISTICS_COLLECTION feature.\", op));\n        }\n    }\n+\n+    /**\n+     * Test is statistics collection feature are supported by each server node in cluster.\n+     *\n+     * @return {@code true} if all server nodes support STATISTICS_COLLECTION feature, {@code false} - otherwise.\n+     */\n+   private boolean isStatisticsSupport() {\n+       return IgniteFeatures.allNodesSupport(ctx, IgniteFeatures.STATISTICS_COLLECTION, IgniteDiscoverySpi.SRV_NODES);\n+   }\n }\n", "next_change": null}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc3MjE1MA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546772150", "body": "```suggestion\r\n        currColls.values().forEach(transformation::apply);\r\n```", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    currColls.keySet().forEach(k -> {\n          \n          \n            \n                        currColls.computeIfPresent(k, (k1, v) -> transformation.apply(v)); // TODO sync?\n          \n          \n            \n                    });\n          \n          \n            \n                    currColls.values().forEach(transformation::apply);", "bodyHTML": "  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">        currColls<span class=\"pl-k\">.</span>keySet()<span class=\"pl-k\">.</span>forEach(k <span class=\"pl-k\">-</span><span class=\"pl-k\">&gt;</span> {</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">            currColls<span class=\"pl-k\">.</span>computeIfPresent(k, (k1, v) <span class=\"pl-k\">-</span><span class=\"pl-k\">&gt;</span> transformation<span class=\"pl-k\">.</span>apply(v)); <span class=\"pl-c\"><span class=\"pl-c\">//</span> TODO sync?</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">        });</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">        currColls<span class=\"pl-k\">.</span>values()<span class=\"pl-k\">.</span>forEach(transformation<span class=\"pl-k\">::</span>apply);</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "korlov42", "createdAt": "2020-12-21T15:33:44Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java", "diffHunk": "@@ -0,0 +1,381 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.lang.GridFunc;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsRequestCollection {\n+    /** Current collections, collection id to collection status map. */\n+    private final Map<UUID, StatCollectionStatus> currColls = new ConcurrentHashMap<>();\n+\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsRequestCollection(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Add new statistics collection status.\n+     *\n+     * @param id Id to save status by.\n+     * @param status status to add.\n+     */\n+    public void addActiveCollectionStatus(UUID id, StatCollectionStatus status) {\n+        currColls.put(id, status);\n+    }\n+\n+    /**\n+     * Update status of statistics gathering task.\n+     *\n+     * @param id Statistics collection task id.\n+     * @param transformation Transformation to apply, if it returns {@code null} - status will be removed.\n+     */\n+    public void updateCollection(UUID id, Function<StatCollectionStatus, StatCollectionStatus> transformation) {\n+        currColls.compute(id, (k, v) -> transformation.apply(v));\n+    }\n+\n+    /**\n+     * Get collection status.\n+     *\n+     * @param id Id to get status by.\n+     * @return Collection status.\n+     */\n+    public StatCollectionStatus getCollection(UUID id) {\n+        return currColls.get(id);\n+    }\n+\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatsKeyMessage>> extractGroups(Collection<StatsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds)\n+            throws IgniteCheckedException {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<Integer>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatsCollectionRequest prepareRequest(UUID colId, Map<StatsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatsCollectionRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n+     *            If {@code null} - requests will be\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public static Collection<StatsAddrRequest<StatsCollectionRequest>> generateCollectionRequests(\n+            UUID colId,\n+            Collection<StatsKeyMessage> keys,\n+            Map<StatsKeyMessage, int[]> failedPartitions,\n+            Map<CacheGroupContext, Collection<StatsKeyMessage>> grpContexts\n+    ) throws IgniteCheckedException {\n+        /*Map<StatsKeyMessage, CacheGroupContext> keyGroups = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatsKeyMessage>> grpKeys : grpContexts.entrySet())\n+            for(StatsKeyMessage key : grpKeys.getValue())\n+                keyGroups.put(key, grpKeys.getKey());\n+*/\n+        // NodeId to <Key to partitions on node> map\n+        Map<UUID, Map<StatsKeyMessage, int[]>> reqMap = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n+            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null); // TODO Null?\n+            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n+                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n+                    if (v == null)\n+                        v = new HashMap<>();\n+\n+                    Collection<StatsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n+\n+                    for (StatsKeyMessage key : grpKeys) {\n+                        int[] keyNodeParts = (failedPartitions == null) ? nodeParts.getValue() :\n+                                GridArrays.intersect(nodeParts.getValue(), failedPartitions.get(key));\n+\n+                        if (keyNodeParts.length > 0)\n+                            v.put(key, keyNodeParts);\n+                    }\n+\n+                    return v.size() > 0 ? v : null;\n+                });\n+        }\n+\n+        Collection<StatsAddrRequest<StatsCollectionRequest>> reqs = new ArrayList<>();\n+        for (Map.Entry<UUID, Map<StatsKeyMessage, int[]>> nodeGpsParts: reqMap.entrySet()) {\n+            if (nodeGpsParts.getValue().isEmpty())\n+                continue;\n+            StatsCollectionRequest req = prepareRequest(colId, nodeGpsParts.getValue());\n+            reqs.add(new StatsAddrRequest(req, nodeGpsParts.getKey()));\n+        }\n+\n+        return reqs;\n+    }\n+\n+    /**\n+     * Calculate node id to stats key map.\n+     *\n+     * @param groupKeys Cache group to stats key map.\n+     * @return Node id to stats key map.\n+     */\n+    public static Map<UUID, Set<StatsKeyMessage>> nodeKeys(\n+        Map<CacheGroupContext, Collection<StatsKeyMessage>> groupsKeys\n+    ) {\n+        Map<UUID, Set<StatsKeyMessage>> res = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatsKeyMessage>> groupKeys : groupsKeys.entrySet()) {\n+            CacheGroupContext grp = groupKeys.getKey();\n+\n+            AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+            List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+            for (List<ClusterNode> partNodes : assignments) {\n+                for (ClusterNode node : partNodes) {\n+                    res.compute(node.id(), (k, v) -> {\n+                        if (v == null)\n+                            v = new HashSet<>();\n+\n+                        v.addAll(groupKeys.getValue());\n+\n+                        return v;\n+                    });\n+                }\n+            }\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Generate statistics clear requests.\n+     *\n+     * @param keys Keys to clean statistics by.\n+     * @return Collection of addressed statistics clear requests.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    protected Collection<StatsAddrRequest<StatsClearRequest>> generateClearRequests(\n+        Collection<StatsKeyMessage> keys\n+    ) throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatsKeyMessage>> grpContexts = extractGroups(keys);\n+        Map<UUID, Set<StatsKeyMessage>> nodeKeys = nodeKeys(grpContexts);\n+        List<StatsAddrRequest<StatsClearRequest>> res = new ArrayList<>(nodeKeys.size());\n+\n+        return nodeKeys.entrySet().stream().map(e -> new StatsAddrRequest<StatsClearRequest>(\n+                new StatsClearRequest(UUID.randomUUID(), new ArrayList<>(e.getValue())), e.getKey()))\n+                .collect(Collectors.toList());\n+    }\n+\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    protected Collection<StatsAddrRequest<StatsCollectionRequest>> generateCollectionRequests(\n+        UUID colId,\n+        Collection<StatsKeyMessage> keys,\n+        Map<StatsKeyMessage, int[]> failedPartitions\n+    ) throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatsKeyMessage>> grpContexts = extractGroups(keys);\n+        return generateCollectionRequests(colId, keys, failedPartitions, grpContexts);\n+    }\n+\n+    /**\n+     * Extract all partitions from specified statistics collection requests.\n+     *\n+     * @param reqs Failed request to extract partitions from.\n+     * @return Map StatisticsKeyMessage to List of corresponding partitions.\n+     */\n+    public static Map<StatsKeyMessage, int[]> extractFailed(StatsCollectionRequest[] reqs) {\n+        Map<StatsKeyMessage, List<Integer>> res = new HashMap<>();\n+\n+        UUID colId = null;\n+        for (StatsCollectionRequest req : reqs) {\n+\n+            assert colId == null || colId.equals(req.colId());\n+            colId = req.colId();\n+\n+            for (Map.Entry<StatsKeyMessage, int[]> keyEntry : req.keys().entrySet()) {\n+                res.compute(keyEntry.getKey(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+\n+                    for (int i = 0; i < keyEntry.getValue().length; i++)\n+                        v.add(keyEntry.getValue()[i]);\n+\n+                    return v;\n+                });\n+            }\n+        }\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Get failed partitions map from request and its response.\n+     *\n+     * @param req Request to get the original requested partitions from.\n+     * @param resp Response to get actually collected partitions.\n+     * @return Map of not collected partitions.\n+     */\n+    public static Map<StatsKeyMessage, int[]> extractFailed(StatsCollectionRequest req, StatsCollectionResponse resp) {\n+        assert req.colId().equals(resp.colId());\n+\n+        Map<StatsKeyMessage, int[]> collected = new HashMap<>(resp.data().size());\n+        for (Map.Entry<StatsObjectData, int[]> data : resp.data().entrySet())\n+            collected.put(data.getKey().key(), data.getValue());\n+\n+        Map<StatsKeyMessage, int[]> res = new HashMap<>();\n+        for (Map.Entry<StatsKeyMessage, int[]> keyEntry : req.keys().entrySet()) {\n+            int[] failed = GridArrays.subtract(keyEntry.getValue(), collected.get(keyEntry.getKey()));\n+\n+            if (failed.length > 0)\n+                res.put(keyEntry.getKey(), failed);\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Apply specified transformation to each active statistics collection status.\n+     *\n+     * @param transformation Transformation to apply.\n+     */\n+    public void updateAllCollections(Function<StatCollectionStatus, StatCollectionStatus> transformation) {\n+        currColls.keySet().forEach(k -> {\n+            currColls.computeIfPresent(k, (k1, v) -> transformation.apply(v)); // TODO sync?\n+        });", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nsimilarity index 56%\nrename from modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\nrename to modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 02fce6bdf6d..f0bc33ee4ba 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -367,15 +335,4 @@ public class IgniteStatisticsRequestCollection {\n         }\n         return res;\n     }\n-\n-    /**\n-     * Apply specified transformation to each active statistics collection status.\n-     *\n-     * @param transformation Transformation to apply.\n-     */\n-    public void updateAllCollections(Function<StatCollectionStatus, StatCollectionStatus> transformation) {\n-        currColls.keySet().forEach(k -> {\n-            currColls.computeIfPresent(k, (k1, v) -> transformation.apply(v)); // TODO sync?\n-        });\n-    }\n }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc4MzU4Nw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546783587", "body": "it's not a DR pool", "bodyText": "it's not a DR pool", "bodyHTML": "<p dir=\"auto\">it's not a DR pool</p>", "author": "korlov42", "createdAt": "2020-12-21T15:53:18Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -68,14 +113,32 @@\n     public IgniteStatisticsManagerImpl(GridKernalContext ctx, SchemaManager schemaMgr) {\n         this.ctx = ctx;\n         this.schemaMgr = schemaMgr;\n+        currCollections = new IgniteStatisticsRequestCollection(schemaMgr);\n \n         log = ctx.log(IgniteStatisticsManagerImpl.class);\n \n+        ctx.io().addMessageListener(TOPIC, this);\n+\n         boolean storeData = !(ctx.config().isClientMode() || ctx.isDaemon());\n+\n         IgniteCacheDatabaseSharedManager db = (GridCacheUtils.isPersistenceEnabled(ctx.config())) ?\n                 ctx.cache().context().database() : null;\n+\n         statsRepos = new IgniteStatisticsRepositoryImpl(storeData, db, ctx.internalSubscriptionProcessor(), this,\n                 ctx::log);\n+\n+        nodeLeftLsnr = new NodeLeftListener();\n+\n+        statMgmtPool = new IgniteThreadPoolExecutor(\"dr-mgmt-pool\",", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTAyNzE4Mg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555027182", "bodyText": "fixed", "author": "Berkof", "createdAt": "2021-01-11T12:55:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc4MzU4Nw=="}], "type": "inlineReview", "revised_code": {"commit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 0f88eff3479..f208a744d01 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -127,9 +106,8 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n         statsRepos = new IgniteStatisticsRepositoryImpl(storeData, db, ctx.internalSubscriptionProcessor(), this,\n                 ctx::log);\n \n-        nodeLeftLsnr = new NodeLeftListener();\n-\n-        statMgmtPool = new IgniteThreadPoolExecutor(\"dr-mgmt-pool\",\n+        // nodeLeftLsnr = new NodeLeftListener();\n+        IgniteThreadPoolExecutor gatMgmtPool = new IgniteThreadPoolExecutor(\"stat-gat-mgmt-pool\",\n                 ctx.igniteInstanceName(),\n                 0,\n                 STATS_POOL_SIZE,\n", "next_change": {"commit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex f208a744d01..1f98ad5ca73 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -95,16 +93,9 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n \n         log = ctx.log(IgniteStatisticsManagerImpl.class);\n \n-\n-        //ctx.io().addMessageListener(TOPIC, this);\n-\n-        boolean storeData = !(ctx.config().isClientMode() || ctx.isDaemon());\n-\n         IgniteCacheDatabaseSharedManager db = (GridCacheUtils.isPersistenceEnabled(ctx.config())) ?\n                 ctx.cache().context().database() : null;\n \n-        statsRepos = new IgniteStatisticsRepositoryImpl(storeData, db, ctx.internalSubscriptionProcessor(), this,\n-                ctx::log);\n \n         // nodeLeftLsnr = new NodeLeftListener();\n         IgniteThreadPoolExecutor gatMgmtPool = new IgniteThreadPoolExecutor(\"stat-gat-mgmt-pool\",\n", "next_change": {"commit": "05b732cd7e8840c429c48f5561e7c98e0289bcf6", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 1f98ad5ca73..ab2c41eca80 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -89,15 +88,13 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n     public IgniteStatisticsManagerImpl(GridKernalContext ctx, SchemaManager schemaMgr) {\n         this.ctx = ctx;\n         this.schemaMgr = schemaMgr;\n-        helper = new IgniteStatisticsHelper(schemaMgr);\n+        helper = new IgniteStatisticsHelper(ctx.localNodeId(), schemaMgr, ctx::log);\n \n         log = ctx.log(IgniteStatisticsManagerImpl.class);\n \n         IgniteCacheDatabaseSharedManager db = (GridCacheUtils.isPersistenceEnabled(ctx.config())) ?\n                 ctx.cache().context().database() : null;\n \n-\n-        // nodeLeftLsnr = new NodeLeftListener();\n         IgniteThreadPoolExecutor gatMgmtPool = new IgniteThreadPoolExecutor(\"stat-gat-mgmt-pool\",\n                 ctx.igniteInstanceName(),\n                 0,\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc4NDIyOQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546784229", "body": "commented code", "bodyText": "commented code", "bodyHTML": "<p dir=\"auto\">commented code</p>", "author": "korlov42", "createdAt": "2020-12-21T15:54:31Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -91,81 +154,344 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter(null);\n+\n+        UUID reqId = UUID.randomUUID();\n+        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+        Collection<StatsAddrRequest<StatsClearRequest>> reqs = currCollections\n+                .generateClearRequests(Collections.singletonList(keyMsg));\n+\n+        sendRequests(reqs);\n+        Map<UUID, List<Integer>> requestNodes = null;\n+        /*try {", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjMwMTAyMA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556301020", "bodyText": "removed", "author": "Berkof", "createdAt": "2021-01-13T07:02:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc4NDIyOQ=="}], "type": "inlineReview", "revised_code": {"commit": "b595e90b5b480aaf80a9256558b1841334df97de", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 0f88eff3479..7fab3588e96 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -153,32 +150,50 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n         return statsRepos.getLocalStatistics(new StatsKey(schemaName, objName));\n     }\n \n+    /**\n+     * Clear object statistics implementation.\n+     *\n+     * @param keys Keys to clear statistics by.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void clearObjectStatistics(Collection<StatsKeyMessage> keys) throws IgniteCheckedException {\n+        Collection<StatsAddrRequest<StatsClearRequest>> clearReqs = currCollections.generateClearRequests(keys);\n+\n+        Collection<StatsAddrRequest<StatsClearRequest>> failedReqs = sendRequests(clearReqs);\n+        if (!F.isEmpty(failedReqs))\n+            if (log.isInfoEnabled())\n+                log.info(String.format(\"Unable to send all statistics clear requests to %d nodes for keys %s\",\n+                    failedReqs.size(), keys));\n+\n+\n+        UUID locId = ctx.localNodeId();\n+        StatsAddrRequest<StatsClearRequest> locMsg = clearReqs.stream().filter(m -> locId.equals(m.nodeId())).findAny()\n+                .orElse(null);\n+        if (null != locMsg)\n+            for (StatsKeyMessage locKey : locMsg.req().keys())\n+                clearObjectStatisticsLocal(locKey);\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void clearObjectStatistics(\n+            GridTuple3<String, String, String[]>... keys\n+    ) throws IgniteCheckedException {\n+\n+        Collection<StatsKeyMessage> keyMsgs = Arrays.stream(keys).map(k -> new StatsKeyMessage(k.get1(), k.get2(),\n+                Arrays.asList(k.get3()))).collect(Collectors.toList());\n+\n+        clearObjectStatistics(keyMsgs);\n+    }\n+\n     /** {@inheritDoc} */\n     @Override public void clearObjectStatistics(\n             String schemaName,\n             String objName,\n             String... colNames\n     ) throws IgniteCheckedException {\n-        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter(null);\n-\n-        UUID reqId = UUID.randomUUID();\n         StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n-        Collection<StatsAddrRequest<StatsClearRequest>> reqs = currCollections\n-                .generateClearRequests(Collections.singletonList(keyMsg));\n-\n-        sendRequests(reqs);\n-        Map<UUID, List<Integer>> requestNodes = null;\n-        /*try {\n-            requestNodes = nodePartitions(extractGroups(Collections.singletonList(keyMsg)), null);\n-        } catch (IgniteCheckedException e) {\n-            // TODO: handle & remove task\n-        }\n-\n-        StatsClearRequest req = new StatsClearRequest(reqId, false, Collections.singletonList(keyMsg));\n \n-        sendLocalRequests(reqId, req, requestNodes);*/\n-\n-        clearObjectStatisticsLocal(keyMsg);\n+        clearObjectStatistics(Collections.singleton(keyMsg));\n     }\n \n     /**\n", "next_change": {"commit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 7fab3588e96..f208a744d01 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -191,7 +185,7 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n             String objName,\n             String... colNames\n     ) throws IgniteCheckedException {\n-        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+        StatisticsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n \n         clearObjectStatistics(Collections.singleton(keyMsg));\n     }\n", "next_change": {"commit": "17a54090bea4d97c122cf06d6be8e60177006519", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex f208a744d01..636f380904e 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -151,43 +152,45 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n      * @throws IgniteCheckedException In case of errors.\n      */\n     private void clearObjectStatistics(Collection<StatisticsKeyMessage> keys) throws IgniteCheckedException {\n-        Collection<StatisticsAddrRequest<StatisticsClearRequest>> clearReqs = helper.generateClearRequests(keys);\n-\n-        Collection<StatisticsAddrRequest<StatisticsClearRequest>> failedReqs = sendRequests(clearReqs);\n-        if (!F.isEmpty(failedReqs))\n-            if (log.isInfoEnabled())\n-                log.info(String.format(\"Unable to send all statistics clear requests to %d nodes for keys %s\",\n-                    failedReqs.size(), keys));\n-\n+        statCrawler.sendClearStatisticsAsync(keys);\n+    }\n \n-        UUID locId = ctx.localNodeId();\n-        StatisticsAddrRequest<StatisticsClearRequest> locMsg = clearReqs.stream().filter(m -> locId.equals(m.nodeId())).findAny()\n-                .orElse(null);\n-        if (null != locMsg)\n-            for (StatisticsKeyMessage locKey : locMsg.req().keys())\n-                clearObjectStatisticsLocal(locKey);\n+    /**\n+     * Clear local statistics by specified keys.\n+     *\n+     * @param keys Keys to clear statistics by.\n+     */\n+    public void clearObjectsStatisticsLocal(Collection<StatisticsKeyMessage> keys) {\n+        for (StatisticsKeyMessage key : keys)\n+            clearObjectStatisticsLocal(key);\n     }\n \n-    /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(\n-            GridTuple3<String, String, String[]>... keys\n-    ) throws IgniteCheckedException {\n+    /**\n+     * Update counter to mark that statistics by some partitions where collected by remote request.\n+     *\n+     * @param gatId Gathering id.\n+     * @param parts Partitions count.\n+     */\n+    public void onRemoteGatheringSend(UUID gatId, int parts) {\n+        currColls.compute(gatId, (k,v) -> {\n+           if (v == null) {\n+               if (log.isDebugEnabled())\n+                   log.debug(String.format(\"Unable to mark %d partitions gathered by gathering id %s\", parts, gatId));\n \n-        Collection<StatisticsKeyMessage> keyMsgs = Arrays.stream(keys).map(k -> new StatisticsKeyMessage(k.get1(), k.get2(),\n-                Arrays.asList(k.get3()))).collect(Collectors.toList());\n+               return null;\n+           }\n \n-        clearObjectStatistics(keyMsgs);\n+           return v.registerCollected(Collections.emptyMap(), parts) ? null : v;\n+        });\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(\n-            String schemaName,\n-            String objName,\n-            String... colNames\n-    ) throws IgniteCheckedException {\n-        StatisticsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+    @Override public void clearObjectStatistics(StatisticsTarget... targets) throws IgniteCheckedException {\n \n-        clearObjectStatistics(Collections.singleton(keyMsg));\n+        List<StatisticsKeyMessage> keys = Arrays.stream(targets).map(target -> new StatisticsKeyMessage(target.schema(),\n+            target.obj(), Arrays.asList(target.columns()))).collect(Collectors.toList());\n+\n+        clearObjectStatistics(keys);\n     }\n \n     /**\n", "next_change": null}]}}, {"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 7fab3588e96..f208a744d01 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -201,8 +195,8 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n      *\n      * @param keyMsg Key to clear statistics by.\n      */\n-    private void clearObjectStatisticsLocal(StatsKeyMessage keyMsg) {\n-        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+    private void clearObjectStatisticsLocal(StatisticsKeyMessage keyMsg) {\n+        StatisticsKey key = new StatisticsKey(keyMsg.schema(), keyMsg.obj());\n         String[] colNames = keyMsg.colNames().toArray(new String[0]);\n \n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n", "next_change": null}]}}]}, "revised_code_in_main": {"commit": "baf94dd2b9a49d96b7043541aa6268320cdb908f", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 0f88eff3479..47277987f34 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -150,837 +144,366 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n \n     /** {@inheritDoc} */\n     @Override public ObjectStatistics getLocalStatistics(String schemaName, String objName) {\n-        return statsRepos.getLocalStatistics(new StatsKey(schemaName, objName));\n+        return statsRepos.getLocalStatistics(new StatisticsKey(schemaName, objName));\n     }\n \n-    /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(\n-            String schemaName,\n-            String objName,\n-            String... colNames\n-    ) throws IgniteCheckedException {\n-        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter(null);\n-\n-        UUID reqId = UUID.randomUUID();\n-        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n-        Collection<StatsAddrRequest<StatsClearRequest>> reqs = currCollections\n-                .generateClearRequests(Collections.singletonList(keyMsg));\n-\n-        sendRequests(reqs);\n-        Map<UUID, List<Integer>> requestNodes = null;\n-        /*try {\n-            requestNodes = nodePartitions(extractGroups(Collections.singletonList(keyMsg)), null);\n-        } catch (IgniteCheckedException e) {\n-            // TODO: handle & remove task\n-        }\n-\n-        StatsClearRequest req = new StatsClearRequest(reqId, false, Collections.singletonList(keyMsg));\n-\n-        sendLocalRequests(reqId, req, requestNodes);*/\n+    /**\n+     * Clear object statistics implementation.\n+     *\n+     * @param keys Keys to clear statistics by.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void clearObjectStatistics(Collection<StatisticsKeyMessage> keys) throws IgniteCheckedException {\n+        checkStatisticsSupport(\"clear statistics\");\n \n-        clearObjectStatisticsLocal(keyMsg);\n+        statCrawler.sendClearStatisticsAsync(keys);\n     }\n \n     /**\n-     * Actually clear local object statistics by the given key.\n+     * Clear local statistics by specified keys.\n      *\n-     * @param keyMsg Key to clear statistics by.\n+     * @param keys Keys to clear statistics by.\n      */\n-    private void clearObjectStatisticsLocal(StatsKeyMessage keyMsg) {\n-        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n-        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n-\n-        statsRepos.clearLocalPartitionsStatistics(key, colNames);\n-        statsRepos.clearLocalStatistics(key, colNames);\n-        statsRepos.clearGlobalStatistics(key, colNames);\n+    public void clearObjectsStatisticsLocal(Collection<StatisticsKeyMessage> keys) {\n+        for (StatisticsKeyMessage key : keys)\n+            clearObjectStatisticsLocal(key);\n     }\n \n-    // TODO\n     /**\n-     * Collect local object statistics by primary partitions of specified object.\n+     * Update counter to mark that statistics by some partitions where collected by remote request.\n      *\n-     * @param keyMsg Statistic key message to collect statistics by.\n-     * @param partIds Set of partition ids to collect statistics by.\n-     * @param cancelled Supplier to check if operation was cancelled.\n-     * @return Tuple of Collected local statistics with array of successfully collected partitions.\n-     * @throws IgniteCheckedException\n+     * @param gatId Gathering id.\n+     * @param parts Partitions count.\n      */\n-    private IgniteBiTuple<ObjectStatisticsImpl, int[]> collectLocalObjectStatistics(\n-            StatsKeyMessage keyMsg,\n-            int[] partIds,\n-            Supplier<Boolean> cancelled\n-    ) throws IgniteCheckedException {\n-        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n-        if (tbl == null)\n-            throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", keyMsg.schema(), keyMsg.obj()));\n-\n-        Column[] selectedCols = filterColumns(tbl.getColumns(), keyMsg.colNames());\n-\n-        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, partIds, selectedCols,\n-                cancelled);\n-        if (partsStats == null) {\n-            assert cancelled.get() : \"Error collecting partition level statistics.\";\n-\n-            return null;\n-        }\n+    public void onRemoteGatheringSend(UUID gatId, int parts) {\n+        currColls.compute(gatId, (k,v) -> {\n+           if (v == null) {\n+               if (log.isDebugEnabled())\n+                   log.debug(String.format(\"Unable to mark %d partitions gathered by gathering id %s\", parts, gatId));\n \n-        sendPartitionStatisticsToBackupNodes(tbl, partsStats);\n+               return null;\n+           }\n \n-        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n-        statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n-\n-        ObjectStatisticsImpl tblStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n-        statsRepos.mergeLocalStatistics(key, tblStats);\n-\n-        return new IgniteBiTuple(tblStats, partsStats.stream().map(ObjectPartitionStatisticsImpl::partId).toArray());\n+           return v.registerCollected(Collections.emptyMap(), parts) ? null : v;\n+        });\n     }\n \n-    /**\n-     * Send statistics propagation messages with partition statistics to all backups node.\n-     *\n-     * @param tbl Table to which statistics should be send.\n-     * @param objStats Collection of partition statistics to send.\n-     * @throws IgniteCheckedException In case of errors.\n-     */\n-    private void sendPartitionStatisticsToBackupNodes(\n-            GridH2Table tbl,\n-            Collection<ObjectPartitionStatisticsImpl> objStats\n-    ) throws IgniteCheckedException {\n-        UUID locNode = ctx.localNodeId();\n-        StatsKeyMessage keyMsg = new StatsKeyMessage(tbl.identifier().schema(), tbl.identifier().table(), null);\n-        GridDhtPartitionTopology topology = tbl.cacheContext().topology();\n-        Map<UUID, List<StatsObjectData>> statsByNodes = new HashMap<>();\n-        for (ObjectPartitionStatisticsImpl stat : objStats) {\n-            StatsObjectData statData = StatisticsUtils.toObjectData(keyMsg, StatsType.PARTITION, stat);\n-            for (ClusterNode partNode : topology.nodes(stat.partId(), topology.readyTopologyVersion())) {\n-                if (locNode.equals(partNode.id()))\n-                    continue;\n-\n-                statsByNodes.compute(partNode.id(), (k, v) -> {\n-                    if (v == null)\n-                        v = new ArrayList<>();\n-\n-                    v.add(statData);\n-\n-                    return v;\n-                });\n-            }\n-        }\n+    /** {@inheritDoc} */\n+    @Override public void clearObjectStatistics(StatisticsTarget... targets) throws IgniteCheckedException {\n+        checkStatisticsSupport(\"clear statistics\");\n \n-        for (Map.Entry <UUID, List<StatsObjectData>> statToNode : statsByNodes.entrySet()) {\n-            //StatsPropagationMessage nodeMsg = StatisticsUtils.toMessage(null, statToNode.getValue());\n+        List<StatisticsKeyMessage> keys = Arrays.stream(targets).map(target -> new StatisticsKeyMessage(target.schema(),\n+            target.obj(), Arrays.asList(target.columns()))).collect(Collectors.toList());\n \n-            //ctx.io().sendToCustomTopic(statToNode.getKey(), TOPIC, nodeMsg, GridIoPolicy.QUERY_POOL);\n-        }\n+        clearObjectStatistics(keys);\n     }\n \n     /**\n-     * Filter columns by specified names.\n+     * Actually clear local object statistics by the given key.\n      *\n-     * @param cols Columns to filter.\n-     * @param colNames Column names.\n-     * @return Column with specified names.\n+     * @param keyMsg Key to clear statistics by.\n      */\n-    private Column[] filterColumns(Column[] cols, @Nullable Collection<String> colNames) {\n-        if (F.isEmpty(colNames))\n-            return cols;\n-\n-        Set<String> colNamesSet = new HashSet(Arrays.asList(colNames));\n+    private void clearObjectStatisticsLocal(StatisticsKeyMessage keyMsg) {\n+        StatisticsKey key = new StatisticsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n \n-        return Arrays.stream(cols).filter(c -> colNamesSet.contains(c.getName())).toArray(Column[]::new);\n+        statsRepos.clearLocalPartitionsStatistics(key, colNames);\n+        statsRepos.clearLocalStatistics(key, colNames);\n+        statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n     /**\n      * Collect object statistics prepared status.\n      *\n      * @param status Collection status to collect statistics by.\n-     * @throws IgniteCheckedException In case of errors.\n      */\n-    private void collectObjectStatistics(StatCollectionStatus status) throws IgniteCheckedException {\n-        synchronized (status) {\n-            currCollections.updateCollection(status.colId(), s -> status);\n-            Map<StatsKeyMessage, int[]> failedPartitions = null;\n-            int cnt = 0;\n-            do {\n-                Collection<StatsAddrRequest<StatsCollectionRequest>> reqs = currCollections\n-                        .generateCollectionRequests(status.colId(), status.keys(), failedPartitions);\n-\n-                //Map<UUID, StatsCollectionRequest> msgs = reqs.stream().collect(Collectors.toMap(\n-                //    StatsAddrRequest::nodeId, StatsAddrRequest::req));\n-\n-                Collection<StatsAddrRequest<StatsCollectionRequest>> failedMsgs = sendRequests(reqs);\n-                Map<UUID, StatsAddrRequest<StatsCollectionRequest>> sendedMsgs;\n-                if (failedMsgs == null) {\n-                    sendedMsgs = reqs.stream().collect(Collectors.toMap(r -> r.req().reqId(), r -> r));\n-                    failedPartitions = null;\n-                }\n-                else {\n-                    Set<UUID> failedIds = failedMsgs.stream().map(r -> r.req().reqId()).collect(Collectors.toSet());\n-                    sendedMsgs = reqs.stream().filter(r -> !failedIds.contains(r.req().reqId()))\n-                            .collect(Collectors.toMap(r -> r.req().reqId(), r -> r));\n-                    failedPartitions = currCollections.extractFailed(failedMsgs.stream().map(StatsAddrRequest::req)\n-                            .toArray(StatsCollectionRequest[]::new));\n-                }\n-                status.remainingCollectionReqs().putAll(sendedMsgs);\n-\n-                if (cnt++ > 10) {\n-                    StatsKeyMessage key = status.keys().iterator().next();\n-\n-                    throw new IgniteCheckedException(String.format(\n-                            \"Unable to send all messages to collect statistics by key %s.%s and the others %d\",\n-                            key.schema(), key.obj(), status.keys().size() - 1));\n-                }\n-            }\n-            while (failedPartitions != null);\n-        }\n-\n-        UUID locNode = ctx.localNodeId();\n-        StatsAddrRequest<StatsCollectionRequest> locReq = status.remainingCollectionReqs().values().stream()\n-                .filter(r -> locNode.equals(r.nodeId())).findAny().orElse(null);\n-        if (locReq != null)\n-            statMgmtPool.submit(() -> processLocal(locNode, locReq.req()));\n+    private void collectObjectStatistics(StatisticsGatheringContext status) {\n+        statCrawler.sendGatheringRequestsAsync(status.gatheringId(), status.keys(), null);\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void collectObjectStatistics(\n-            String schemaName,\n-            String objName,\n-            String... colNames\n-    ) throws IgniteCheckedException {\n-        UUID colId = UUID.randomUUID();\n-        StatsKeyMessage keyMsg = new StatsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n-        StatCollectionStatus status = new StatCollectionStatus(colId, Collections.singletonList(keyMsg),\n-            Collections.emptyMap());\n+    @Override public void gatherObjectStatistics(StatisticsTarget target) throws IgniteCheckedException {\n+        checkStatisticsSupport(\"collect statistics\");\n \n-        collectObjectStatistics(status);\n+        StatisticsKeyMessage keyMsg = new StatisticsKeyMessage(target.schema(), target.obj(),\n+            Arrays.asList(target.columns()));\n+        CacheGroupContext grpCtx = helper.getGroupContext(keyMsg);\n \n-        status.doneFut().get();\n-    }\n+        StatisticsGatheringContext status = new StatisticsGatheringContext(UUID.randomUUID(),\n+            Collections.singleton(keyMsg), grpCtx.topology().partitions());\n \n-    /** {@inheritDoc} */\n-    @Override public StatsCollectionFuture<Map<GridTuple3<String, String, String[]>, ObjectStatistics>>\n-    collectObjectStatisticsAsync(\n-        GridTuple3<String, String, String[]>... keys\n-    ) throws IgniteCheckedException {\n-        UUID colId = UUID.randomUUID();\n-        Collection<StatsKeyMessage> keysMsg = Arrays.stream(keys).map(\n-                k -> new StatsKeyMessage(k.get1(), k.get2(), Arrays.asList(k.get3()))).collect(Collectors.toList());\n-\n-        StatCollectionStatus status = new StatCollectionStatus(colId, keysMsg, Collections.emptyMap());\n+        currColls.put(status.gatheringId(), status);\n \n         collectObjectStatistics(status);\n \n-        return status.doneFut();\n-    }\n-\n-    /** {@inheritDoc} */\n-    @Override public boolean cancelObjectStatisticsCollection(UUID colId) {\n-        boolean[] res = new boolean[]{true};\n-\n-        currCollections.updateCollection(colId, s -> {\n-            if (s == null) {\n-                res[0] = false;\n-\n-                return null;\n-            }\n-\n-            s.doneFut().cancel();\n-\n-            Map<UUID, List<UUID>> nodeRequests = new HashMap<>();\n-            for (StatsAddrRequest<StatsCollectionRequest> req : s.remainingCollectionReqs().values()) {\n-                nodeRequests.compute(req.nodeId(), (k, v) -> {\n-                   if (v == null)\n-                       v = new ArrayList();\n-                   v.add(req.req().reqId());\n-\n-                   return v;\n-                });\n-            }\n-\n-            Collection<StatsAddrRequest<CancelStatsCollectionRequest>> cancelReqs = nodeRequests.entrySet().stream().map(\n-                        targetNode -> new StatsAddrRequest<CancelStatsCollectionRequest>(\n-                            new CancelStatsCollectionRequest(colId, targetNode.getValue().toArray(new UUID[0])),\n-                            targetNode.getKey()))\n-                    .collect(Collectors.toList());\n-\n-            Collection<StatsAddrRequest<CancelStatsCollectionRequest>> failed = sendRequests(cancelReqs);\n-            if (failed != null)\n-                if (log.isDebugEnabled())\n-                    log.debug(String.format(\"Unable to cancel all statistics collections requests (%d failed) by colId %s\",\n-                            failed.size(), colId));\n-\n-            return null;\n-        });\n-\n-        return res[0];\n+        status.doneFuture().get();\n     }\n \n     /**\n-     * Generate and try to send all request for particular status. Should be called inside status lock after putting it\n-     * into currCollections map. REMOVE!!!!\n+     * Ensure that local gathering context exists and schedule local statistics gathering.\n      *\n-     * @param status Status to process.\n-     * @param keys Collection of object keys to collect statistics by.\n-     * @return {@code true} if all request was successfully sended, {@code false} - otherwise (one should remove\n-     * status from cullCollections.\n+     * @param nodeId Initiator node id.\n+     * @param gatId Gathering id.\n+     * @param reqId Request id.\n+     * @param keys Keys to collect statistics by.\n+     * @param parts Partitions to collect statistics from.\n      */\n-    protected boolean doRequests(StatCollectionStatus status, List<StatsKeyMessage> keys) throws IgniteCheckedException {\n-        /*Map<CacheGroupContext, Collection<StatsKeyMessage>> grpContexts = extractGroups(keys);\n-        List<Map<UUID, StatsCollectionAddrRequest>> reqsByGrps = new ArrayList<>(grpContexts.size());\n-        for (Map.Entry<CacheGroupContext, Collection<StatsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n-            Map<UUID, List<Integer>> reqNodes = nodePartitions(grpEntry.getKey(), null);\n-            for(StatsKeyMessage keyMsg : grpEntry.getValue())\n-                reqsByGrps.add(prepareRequests(status.colId(), keyMsg, reqNodes));\n-\n-        }\n-        Map<UUID, StatsCollectionAddrRequest> reqs = compressRequests(reqsByGrps);\n-\n-        status.remainingCollectionReqs().putAll(reqs);\n+    public void gatherLocalObjectStatisticsAsync(\n+        UUID gatId,\n+        UUID reqId,\n+        Collection<StatisticsKeyMessage> keys,\n+        int[] parts\n+    ) {\n+        int partsCnt = (int)Arrays.stream(parts).count();\n+        Set<StatisticsKeyMessage> keysSet = new HashSet<>(keys);\n \n-        Map<UUID, StatsCollectionRequest> failedReqs = sendLocalRequests(reqs.values().stream().collect(\n-                Collectors.toMap(StatsCollectionAddrRequest::nodeId, StatsCollectionAddrRequest::req)));\n-        // TODO: cycle replanning and sending\n-        return failedReqs.isEmpty();\n+        StatisticsGatheringContext gCtx = currColls.computeIfAbsent(gatId, k ->\n+            new StatisticsGatheringContext(gatId, keysSet, partsCnt));\n \n-         */\n-        return false;\n+        statGathering.collectLocalObjectsStatisticsAsync(reqId, keysSet, parts, () -> gCtx.doneFuture().isCancelled());\n     }\n \n-    /**\n-     * Stop statistics manager.\n-     */\n-    public void stop() {\n-        if (statMgmtPool != null) {\n-            List<Runnable> unfinishedTasks = statMgmtPool.shutdownNow();\n-            if (!unfinishedTasks.isEmpty())\n-                log.warning(String.format(\"%d statistics collection request cancelled.\", unfinishedTasks.size()));\n-        }\n-    }\n-\n-    /**\n-     * Collect partition level statistics.\n-     *\n-     * @param tbl Table to collect statistics by.\n-     * @param partIds Array of partition ids to collect statistics by.\n-     * @param selectedCols Columns to collect statistics by.\n-     * @param cancelled Supplier to check if collection was cancelled.\n-     * @return Collection of partition level statistics by local primary partitions.\n-     * @throws IgniteCheckedException in case of error.\n-     */\n-    private Collection<ObjectPartitionStatisticsImpl> collectPartitionStatistics(\n-            GridH2Table tbl,\n-            int[] partIds,\n-            Column[] selectedCols,\n-            Supplier<Boolean> cancelled\n-    ) throws IgniteCheckedException {\n-        List<ObjectPartitionStatisticsImpl> tblPartStats = new ArrayList<>();\n-        GridH2RowDescriptor desc = tbl.rowDescriptor();\n-        String tblName = tbl.getName();\n-        GridDhtPartitionTopology topology = tbl.cacheContext().topology();\n-        AffinityTopologyVersion topologyVersion = topology.readyTopologyVersion();\n-\n-        for (int partId : partIds) {\n-            GridDhtLocalPartition locPart = topology.localPartition(partId, topologyVersion, false);\n-            if (locPart == null)\n-                continue;\n-\n-            if (cancelled.get()) {\n-                if (log.isInfoEnabled())\n-                    log.info(String.format(\"Canceled collection of object %s.%s statistics.\", tbl.identifier().schema(),\n-                            tbl.identifier().table()));\n-\n-                return null;\n-            }\n-\n-            final boolean reserved = locPart.reserve();\n-\n-            try {\n-                if (!reserved || (locPart.state() != OWNING && locPart.state() != MOVING)\n-                        || !locPart.primary(ctx.discovery().topologyVersionEx()))\n-                    continue;\n-\n-                if (locPart.state() == MOVING)\n-                    tbl.cacheContext().preloader().syncFuture().get();\n-\n-                long rowsCnt = 0;\n-\n-                List<ColumnStatisticsCollector> colStatsCollectors = new ArrayList<>(selectedCols.length);\n+    /** {@inheritDoc} */\n+    @Override public StatisticsGatheringFuture<Map<StatisticsTarget, ObjectStatistics>>[] gatherObjectStatisticsAsync(\n+        StatisticsTarget... keys\n+    ) {\n \n-                for (Column col : selectedCols)\n-                    colStatsCollectors.add(new ColumnStatisticsCollector(col, tbl::compareValues));\n+        Set<StatisticsKeyMessage> keysMsg = Arrays.stream(keys).map(StatisticsUtils::statisticsKeyMessage)\n+            .collect(Collectors.toSet());\n \n-                for (CacheDataRow row : tbl.cacheContext().offheap().cachePartitionIterator(tbl.cacheId(), locPart.id(),\n-                        null, true)) {\n-                    GridQueryTypeDescriptor typeDesc = ctx.query().typeByValue(tbl.cacheName(),\n-                            tbl.cacheContext().cacheObjectContext(), row.key(), row.value(), false);\n-                    if (!tblName.equals(typeDesc.tableName()))\n-                        continue;\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpsKeys = helper.splitByGroups(keysMsg);\n \n-                    rowsCnt++;\n+        if (!isStatisticsSupport()) {\n+            return grpsKeys.entrySet().stream().map(\n+                grpKeys -> new StatisticsGatheringFutureAdapter(UUID.randomUUID(),\n+                    grpKeys.getValue().stream().map(StatisticsUtils::statisticsTarget).toArray(StatisticsTarget[]::new)))\n+                .toArray(StatisticsGatheringFuture[]::new);\n+        }\n \n-                    H2Row row0 = desc.createRow(row);\n+        Collection<StatisticsKeyMessage> notFoundKeys = grpsKeys.remove(null);\n \n-                    for (ColumnStatisticsCollector colStat : colStatsCollectors)\n-                        colStat.add(row0.getValue(colStat.col().getColumnId()));\n+        List<StatisticsGatheringFuture<Map<StatisticsTarget, ObjectStatistics>>> res = new ArrayList<>();\n \n-                }\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpKeys : grpsKeys.entrySet()) {\n+            int parts = grpKeys.getKey().topology().partitions();\n \n-                Map<String, ColumnStatistics> colStats = colStatsCollectors.stream().collect(Collectors.toMap(\n-                        csc -> csc.col().getName(), csc -> csc.finish()\n-                ));\n+            StatisticsGatheringContext status = new StatisticsGatheringContext(UUID.randomUUID(),\n+                    new HashSet<>(grpKeys.getValue()), parts);\n+            currColls.put(status.gatheringId(), status);\n \n-                tblPartStats.add(new ObjectPartitionStatisticsImpl(locPart.id(), true, rowsCnt,\n-                        locPart.updateCounter(), colStats));\n+            collectObjectStatistics(status);\n \n-                if (log.isTraceEnabled())\n-                    log.trace(String.format(\"Finished statistics collection on %s.%s:%d\",\n-                            tbl.identifier().schema(), tbl.identifier().table(), locPart.id()));\n-            }\n-            finally {\n-                if (reserved)\n-                    locPart.release();\n-            }\n+            res.add(status.doneFuture());\n         }\n+        if (notFoundKeys != null) {\n+            StatisticsGatheringFutureAdapter<Map<StatisticsTarget, ObjectStatistics>> notFoundFut =\n+                new StatisticsGatheringFutureAdapter<>(UUID.randomUUID(),\n+                    notFoundKeys.stream().map(StatisticsUtils::statisticsTarget).toArray(StatisticsTarget[]::new));\n \n-        return tblPartStats;\n-    }\n+            notFoundFut.onDone(new IgniteCheckedException(notFoundKeys.size() + \" target not found.\"));\n \n-    /**\n-     * Aggregate specified partition level statistics to local level statistics.\n-     *\n-     * @param keyMsg Aggregation key.\n-     * @param stats Collection of all local partition level or local level statistics by specified key to aggregate.\n-     * @return Local level aggregated statistics.\n-     */\n-    public ObjectStatisticsImpl aggregateLocalStatistics(\n-            StatsKeyMessage keyMsg,\n-            Collection<? extends ObjectStatisticsImpl> stats\n-    ) {\n-        // For now there can be only tables\n-        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n-\n-        if (tbl == null) {\n-            // remove all loaded statistics.\n-            if (log.isDebugEnabled())\n-                log.debug(String.format(\"Removing statistics for object %s.%s cause table doesn't exists.\",\n-                        keyMsg.schema(), keyMsg.obj()));\n-\n-            // Just to double check\n-            statsRepos.clearLocalPartitionsStatistics(new StatsKey(keyMsg.schema(), keyMsg.obj()));\n+            res.add(notFoundFut);\n         }\n \n-        return aggregateLocalStatistics(tbl, filterColumns(tbl.getColumns(), keyMsg.colNames()), stats);\n+        return res.toArray(new StatisticsGatheringFuture[0]);\n     }\n \n     /**\n-     * Aggregate partition level statistics to local level one.\n+     * Cancel specified statistics gathering process.\n      *\n-     * @param tbl Table to aggregate statistics by.\n-     * @param selectedCols Columns to aggregate statistics by.\n-     * @param stats Collection of partition level or local level statistics to aggregate.\n-     * @return Local level statistics.\n+     * @param gatId Gathering id to cancel.\n      */\n-    private ObjectStatisticsImpl aggregateLocalStatistics(\n-            GridH2Table tbl,\n-            Column[] selectedCols,\n-            Collection<? extends ObjectStatisticsImpl> stats\n-    ) {\n-        Map<Column, List<ColumnStatistics>> colPartStats = new HashMap<>(selectedCols.length);\n-        long rowCnt = 0;\n-        for (Column col : selectedCols)\n-            colPartStats.put(col, new ArrayList<>());\n-\n-        for (ObjectStatisticsImpl partStat : stats) {\n-            for (Column col : selectedCols) {\n-                ColumnStatistics colPartStat = partStat.columnStatistics(col.getName());\n-                if (colPartStat != null) {\n-                    colPartStats.computeIfPresent(col, (k, v) -> {\n-                        v.add(colPartStat);\n-\n-                        return v;\n-                    });\n-                }\n-            }\n-            rowCnt += partStat.rowCount();\n-        }\n+    public void cancelLocalStatisticsGathering(UUID gatId) {\n+       StatisticsGatheringContext stCtx = currColls.remove(gatId);\n+       if (stCtx != null)\n+           stCtx.doneFuture().cancel();\n+       else {\n+           if (log.isDebugEnabled())\n+               log.debug(String.format(\"Unable to cancel gathering %s. No active task with such gatId found.\", gatId));\n+       }\n+    }\n \n-        Map<String, ColumnStatistics> colStats = new HashMap<>(selectedCols.length);\n-        for (Column col : selectedCols) {\n-            ColumnStatistics stat = ColumnStatisticsCollector.aggregate(tbl::compareValues, colPartStats.get(col));\n-            colStats.put(col.getName(), stat);\n-        }\n+    /** {@inheritDoc} */\n+    @Override public boolean cancelObjectStatisticsGathering(UUID gatId) throws IgniteCheckedException {\n+        checkStatisticsSupport(\"cancel gathering\");\n \n-        ObjectStatisticsImpl tblStats = new ObjectStatisticsImpl(rowCnt, colStats);\n+        boolean res = false;\n+        StatisticsGatheringContext stCtx = currColls.get(gatId);\n+        if (stCtx != null) {\n \n-        return tblStats;\n+            res = stCtx.doneFuture().cancel();\n+            if (res)\n+                statCrawler.sendCancelGatheringAsync(gatId);\n+        }\n+        return res;\n     }\n \n     /**\n-     * Receive and handle statistics propagation message with partitions statistics.\n+     * Receive and store partition statistics object data for locals backup partition.\n      *\n-     * @param nodeId Sender node id.\n-     * @param msg Statistics propagation message with partitions statistics to handle.\n-     * @throws IgniteCheckedException In case of errors.\n+     * @param data Collection of partition level statistics of local bacup partitions.\n      */\n-    private void receivePartitionsStatistics(UUID nodeId, StatsPropagationMessage msg) throws IgniteCheckedException {\n-        UUID locNode = ctx.localNodeId();\n-        for (StatsObjectData partData : msg.data()) {\n-            StatsKey key = new StatsKey(partData.key().schema(), partData.key().obj());\n+    public void receivePartitionsStatistics(Collection<StatisticsObjectData> data) {\n+        for (StatisticsObjectData partData : data) {\n+            StatisticsKey key = new StatisticsKey(partData.key().schema(), partData.key().obj());\n \n-            assert partData.type() == StatsType.PARTITION : \"Got non partition level statistics by \" + key\n+            assert partData.type() == StatisticsType.PARTITION : \"Got non partition level statistics by \" + key\n                     + \" without request\";\n \n             if (log.isTraceEnabled())\n-                log.trace(String.format(\"Received partition statistics %s.%s:%d from node %s\", key.schema(),\n-                        key.obj(), partData.partId(), nodeId));\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d\", key.schema(), key.obj(),\n+                    partData.partId()));\n \n             GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n             if (tbl == null) {\n                 if (log.isInfoEnabled())\n-                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d from node %s\",\n-                            key.schema(), key.obj(), partData.partId(), nodeId));\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d\", key.schema(), key.obj(),\n+                        partData.partId()));\n \n                 continue;\n             }\n-            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(locNode, partData.partId());\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(ctx.localNodeId(),\n+                partData.partId());\n             if (partState != OWNING) {\n-                if (log.isInfoEnabled())\n-                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d from node %s\",\n-                            key.schema(), key.obj(), partData.partId(), nodeId));\n+                if (log.isTraceEnabled())\n+                    log.trace(String.format(\"Ignoring non local partition statistics %s.%s:%d\",\n+                            key.schema(), key.obj(), partData.partId()));\n \n                 continue;\n             }\n \n-            ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n-\n-            statsRepos.saveLocalPartitionStatistics(key, opStat);\n-        }\n-    }\n-\n-    /**\n-     * Receive and handle statistics propagation message as response for collection request.\n-     *\n-     * @param nodeId Sender node id.\n-     * @param msg Statistics propagation message with partitions statistics to handle.\n-     * @throws IgniteCheckedException In case of errors.\n-     */\n-    private void receiveLocalStatistics(UUID nodeId, StatsCollectionResponse msg) {\n-        assert msg.data().keySet().stream().noneMatch(pd -> pd.type() == StatsType.PARTITION)\n-                : \"Got partition statistics by request \" + msg.reqId();\n-\n-        currCollections.updateCollection(msg.colId(), stat -> {\n-            if (stat == null) {\n-                if (log.isDebugEnabled())\n-                    log.debug(String.format(\n-                        \"Ignoring outdated local statistics collection response from node %s to col %s req %s\",\n-                            nodeId, msg.colId(), msg.reqId()));\n-\n-                return stat;\n-            }\n-\n-            assert stat.colId().equals(msg.colId());\n-\n-            // Need syncronization here to avoid races between removing remaining reqs and adding new ones.\n-            synchronized (stat) {\n-                StatsAddrRequest<StatsCollectionRequest> req = stat.remainingCollectionReqs().remove(msg.reqId());\n-\n-                if (req == null) {\n-                    if (log.isDebugEnabled())\n-                        log.debug(String.format(\n-                                \"Ignoring unknown local statistics collection response from node %s to col %s req %s\",\n-                                nodeId, msg.colId(), msg.reqId()));\n-\n-                    return stat;\n-                }\n-\n-                stat.localStatistics().add(msg);\n-                // TODO: reschedule if not all partition collected.\n-\n-                if (stat.remainingCollectionReqs().isEmpty()) {\n-                    Map<StatsKey, ObjectStatisticsImpl> mergedGlobal = finishStatCollection(stat);\n-\n-                    stat.doneFut().onDone(null);\n-\n-                    return null;\n-                }\n-            }\n-            return stat;\n-        });\n-    }\n+            try {\n+                ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n \n-    /**\n-     * Aggregate local statistics to global one.\n-     *\n-     * @param stat Statistics collection status to aggregate.\n-     * @return Map stats key to merged global statistics.\n-     */\n-    private Map<StatsKey, ObjectStatisticsImpl> finishStatCollection(StatCollectionStatus stat) {\n-        Map<StatsKeyMessage, Collection<ObjectStatisticsImpl>> keysStats = new HashMap<>();\n-        for (StatsCollectionResponse resp : stat.localStatistics()) {\n-            for (StatsObjectData objData : resp.data().keySet()) {\n-                keysStats.compute(objData.key(), (k, v) -> {\n-                    if (v == null)\n-                        v = new ArrayList<>();\n-                    try {\n-                        ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n-\n-                        v.add(objStat);\n-                    } catch (IgniteCheckedException e) {\n-                        if (log.isInfoEnabled())\n-                            log.info(String.format(\"Unable to parse statistics for object %s from response %s\",\n-                                    objData.key(), resp.reqId()));\n-                    }\n-\n-                    return v;\n-                });\n+                statsRepos.saveLocalPartitionStatistics(key, opStat);\n             }\n-        }\n-\n-        Map<StatsKey, ObjectStatisticsImpl> res = new HashMap<>();\n-        for (Map.Entry<StatsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : keysStats.entrySet()) {\n-            StatsKeyMessage keyMsg = keyStats.getKey();\n-            GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n-            if (tbl == null) {\n+            catch (IgniteCheckedException e) {\n                 if (log.isInfoEnabled())\n-                    log.info(String.format(\"Unable to find object %s.%s to save collected statistics by.\",\n-                            keyMsg.schema(), keyMsg.obj()));\n-\n-                continue;\n+                    log.info(String.format(\"Unable to parse partition statistics for %s.%s:%d because of: %s\",\n+                        key.schema(), key.obj(), partData.partId(), e.getMessage()));\n             }\n-            ObjectStatisticsImpl globalStat = aggregateLocalStatistics(keyMsg, keyStats.getValue());\n-            StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n-            res.put(key, statsRepos.mergeGlobalStatistics(key, globalStat));\n         }\n-        return res;\n     }\n \n     /**\n-     * Send statistics by request.\n+     * Aggregate specified gathered statistics, remove it form local and complete its future.\n      *\n-     * @param nodeId Node to send statistics to.\n-     * @param msg Statistics request to process.\n-     * @throws IgniteCheckedException In case of errors.\n+     * @param stCtx Gathering to complete.\n      */\n-    private void supplyStatistics(UUID nodeId, StatsGetRequest msg) throws IgniteCheckedException {\n-        List<StatsObjectData> data = new ArrayList<>(msg.keys().size());\n-        for (StatsKeyMessage keyMsg : msg.keys()) {\n-            StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n-            ObjectStatisticsImpl objStats = statsRepos.getGlobalStatistics(key);\n-\n-            if (objStats != null)\n-                data.add(StatisticsUtils.toObjectData(keyMsg, StatsType.GLOBAL, objStats));\n-        }\n-        StatsPropagationMessage res = new StatsPropagationMessage(data);\n-        ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n-    }\n+    public void finishStatisticsCollection(StatisticsGatheringContext stCtx) {\n+        currColls.remove(stCtx.gatheringId());\n \n-    /**\n-     * Cancel local statistics collection task.\n-     *\n-     * @param nodeId Sender node id.\n-     * @param msg Cancel request.\n-     */\n-    private void cancelStatisticsCollection(UUID nodeId, CancelStatsCollectionRequest msg) {\n-        for (UUID reqId : msg.reqIds()) {\n-            currCollections.updateCollection(reqId, stat -> {\n-                if (stat == null) {\n-                    if (log.isDebugEnabled())\n-                        log.debug(String.format(\"Unable to cancel statistics collection %s by req %s from node %s\",\n-                                msg.colId(), reqId, nodeId));\n+        Map<StatisticsTarget, ObjectStatistics> targetStats = new HashMap<>();\n+        Map<StatisticsKeyMessage, ObjectStatisticsImpl> keysStats = new HashMap<>();\n+        for (Map.Entry<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : stCtx.collectedStatistics()\n+                .entrySet()) {\n+            ObjectStatisticsImpl globalCollectedStat = helper.aggregateLocalStatistics(keyStats.getKey(),\n+                keyStats.getValue());\n \n-                    return null;\n-                }\n+            StatisticsKey statsKey = new StatisticsKey(keyStats.getKey().schema(), keyStats.getKey().obj());\n+            ObjectStatisticsImpl globalStat = statsRepos.mergeGlobalStatistics(statsKey, globalCollectedStat);\n \n-                stat.doneFut().cancel();\n-\n-                if (log.isDebugEnabled())\n-                    log.debug(String.format(\"Cancelling statistics collection by colId = %s, reqId = %s from node %s\",\n-                            msg.colId(), reqId, nodeId));\n-\n-                return null;\n-            });\n+            targetStats.put(StatisticsUtils.statisticsTarget(keyStats.getKey()), globalStat);\n+            keysStats.put(keyStats.getKey(), globalStat);\n         }\n-    }\n \n-    /** {@inheritDoc} */\n-    @Override public void onMessage(UUID nodeId, Object msg, byte plc) {\n-        try {\n-            if (msg instanceof StatsPropagationMessage)\n-                receivePartitionsStatistics(nodeId, (StatsPropagationMessage) msg);\n-            else if (msg instanceof StatsCollectionResponse)\n-                receiveLocalStatistics(nodeId, (StatsCollectionResponse) msg);\n-            else if (msg instanceof StatsGetRequest)\n-                supplyStatistics(nodeId, (StatsGetRequest) msg);\n-            else if (msg instanceof StatsCollectionRequest)\n-                handleCollectionRequest(nodeId, (StatsCollectionRequest)msg);\n-            else if (msg instanceof CancelStatsCollectionRequest)\n-                cancelStatisticsCollection(nodeId, (CancelStatsCollectionRequest) msg);\n-            else if (msg instanceof StatsClearRequest)\n-                clearObjectStatistics(nodeId, (StatsClearRequest)msg);\n-            else\n-                log.warning(\"Unknown msg \" + msg +  \" in statistics topic \" + TOPIC + \" from node \" + nodeId);\n-        } catch (IgniteCheckedException e) {\n-            log.warning(\"Statistic msg from node \" + nodeId + \" processing failed\", e);\n-        }\n-    }\n+        statCrawler.sendGlobalStatAsync(keysStats);\n \n-    /**\n-     * Handle statistics clear request.\n-     *\n-     * @param nodeId UUID of request sender node.\n-     * @param msg Clear request message.\n-     */\n-    private void clearObjectStatistics(UUID nodeId, StatsClearRequest msg) {\n-        for (StatsKeyMessage key : msg.keys()) {\n-            if (log.isTraceEnabled())\n-                log.trace(String.format(\"Clearing statistics by request %s from node %s by key %s.%s\", msg.reqId(),\n-                        nodeId, key.schema(), key.obj()));\n-            statMgmtPool.submit(() -> clearObjectStatisticsLocal(key));\n-        }\n+        stCtx.doneFuture().onDone(targetStats);\n     }\n \n     /**\n-     * Collect local object statistics by specified request (possibly for a few objects) and send result back to origin\n-     * node specified. If local node id specified - process result without sending it throw the communication.\n+     * Cache global statistics.\n      *\n-     * @param req request to collect statistics by.\n+     * @param data Global statistics to cache.\n      */\n-    private void processLocal(UUID nodeId, StatsCollectionRequest req) {\n-        UUID locNode = ctx.localNodeId();\n-\n-        StatCollectionStatus stat = (nodeId.equals(locNode)) ? currCollections.getCollection(req.colId()) :\n-            currCollections.getCollection(req.reqId());\n-\n-        if (stat == null)\n-            return;\n-\n-        Map<StatsObjectData, int[]> collected = new HashMap<>(req.keys().size());\n-        for (Map.Entry<StatsKeyMessage, int[]> keyEntry : req.keys().entrySet()) {\n+    public void saveGlobalStatistics(Collection<StatisticsObjectData> data) {\n+        for (StatisticsObjectData objData : data) {\n             try {\n-                StatsKeyMessage key = keyEntry.getKey();\n-                IgniteBiTuple <ObjectStatisticsImpl, int[]> loStat = collectLocalObjectStatistics(key,\n-                        keyEntry.getValue(), () -> stat.doneFut().isCancelled());\n-                StatsKey statsKey = new StatsKey(key.schema(), key.obj());\n+                ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(this.ctx, objData);\n \n-                // TODO?\n-                statsRepos.mergeLocalStatistics(statsKey, loStat.getKey());\n-\n-                StatsObjectData objData = StatisticsUtils.toObjectData(key, StatsType.LOCAL, loStat.getKey());\n-                collected.put(objData, loStat.getValue());\n-            }\n-            catch (IgniteCheckedException e) {\n-                log.warning(String.format(\"Unable to complete request %s due to error %s\", req.reqId(), e.getMessage()));\n-                // TODO: send cancel to originator node\n-            }\n-        }\n-\n-        StatsCollectionResponse res = new StatsCollectionResponse(req.colId(), req.reqId(), collected);\n-\n-        if (locNode.equals(nodeId))\n-            receiveLocalStatistics(nodeId, res);\n-        else {\n-            try {\n-                ctx.io().sendToCustomTopic(nodeId, TOPIC, res, GridIoPolicy.QUERY_POOL);\n+                statsRepos.saveGlobalStatistics(new StatisticsKey(objData.key().schema(), objData.key().obj()), objStat);\n             }\n             catch (IgniteCheckedException e) {\n                 if (log.isDebugEnabled())\n-                    log.debug(String.format(\n-                            \"Unable to send statistics collection result to node %s in response to colId %s, reqId %s\",\n-                        nodeId, req.colId(), req.reqId()));\n+                    log.debug(String.format(\"Cannot read global statistics %s\", objData.key()));\n             }\n-\n-            // Not local collection - remove by its reqId.\n-            currCollections.updateCollection(req.reqId(), s -> null);\n-        }\n-    }\n-\n-    /**\n-     * Schedule statistics collection by specified request.\n-     *\n-     * @param nodeId request origin node.\n-     * @param msg request message.\n-     */\n-    private void handleCollectionRequest(UUID nodeId, StatsCollectionRequest msg) {\n-        assert msg.reqId() != null : \"Got statistics collection request without request id\";\n-\n-        currCollections.addActiveCollectionStatus(msg.reqId(), new StatCollectionStatus(msg.colId(), msg.keys().keySet(), null));\n-\n-        statMgmtPool.submit(() -> processLocal(nodeId, msg));\n+        };\n     }\n \n     /**\n-     * Send requests to target nodes except of local one.\n+     * Register collected statistics in task context.\n      *\n-     * @param reqs Collection of addressed requests to send.\n-     * @return Collection of addressed requests that has errors while sending or {@code null} if all requests was send\n-     * successfully.\n+     * @param gatId Gathering id.\n+     * @param data Collected statistics.\n+     * @param partsCount Count of collected partitions.\n      */\n-    private <T extends Message> Collection<StatsAddrRequest<T>> sendRequests(Collection<StatsAddrRequest<T>> reqs) {\n-        UUID locNode = ctx.localNodeId();\n-        Collection<StatsAddrRequest<T>> res = null;\n-\n-        for (StatsAddrRequest<T> req : reqs) {\n-            if (locNode.equals(req.nodeId()))\n-                continue;\n+    public void registerLocalResult(UUID gatId, Collection<StatisticsObjectData> data, int partsCount) {\n+        StatisticsGatheringContext stCtx = currColls.get(gatId);\n+        if (stCtx == null) {\n+            if (log.isDebugEnabled())\n+                log.debug(String.format(\"Unable to register outdated statistics collection result %s\", gatId));\n \n+            return;\n+        }\n+        Map<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats = new HashMap<>();\n+        for (StatisticsObjectData objData : data) {\n+            Collection<ObjectStatisticsImpl> keyObjStats = keyStats.computeIfAbsent(objData.key(), k -> new ArrayList<>());\n             try {\n-                ctx.io().sendToCustomTopic(req.nodeId(), TOPIC, req.req(), GridIoPolicy.QUERY_POOL);\n+                ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n+\n+                keyObjStats.add(objStat);\n             }\n             catch (IgniteCheckedException e) {\n-                if (res == null)\n-                    res = new ArrayList<>();\n-\n-                res.add(req);\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Cannot read local statistics %s by gathering task %s\", objData.key(),\n+                        gatId));\n             }\n         }\n \n-        return res;\n+        if (stCtx.registerCollected(keyStats, partsCount))\n+            finishStatisticsCollection(stCtx);\n     }\n \n     /**\n-     * Handle node left event:\n-     * 1) Cancel all collection tasks which expect specified node statistics result.\n-     * 2) Cancel collection task requested by node left.\n+     * Get global statistics by key.\n      *\n-     * @param nodeId leaved node id.\n+     * @param key Key to get statistics by.\n+     * @return Global statistics or {@code null} if there are no statistics for specified key.\n      */\n-    private void onNodeLeft(UUID nodeId) {\n-        Map<UUID, Map<StatsKeyMessage, int[]>> failedCollections = new HashMap<>();\n-        currCollections.updateAllCollections(colStat -> {\n-            StatsCollectionRequest[] nodeRequests = (StatsCollectionRequest[])colStat.remainingCollectionReqs()\n-                    .values().stream().filter(\n-                    addReq -> nodeId.equals(addReq.nodeId())).map(StatsAddrRequest::req).toArray();\n-            if (!F.isEmpty(nodeRequests)) {\n-                Map<StatsKeyMessage, int[]> failedKeys = IgniteStatisticsRequestCollection.extractFailed(nodeRequests);\n-                try {\n-                    Collection<StatsAddrRequest<StatsCollectionRequest>> reqs = currCollections\n-                        .generateCollectionRequests(colStat.colId(), colStat.keys(), failedKeys);\n-                    //Map<UUID, StatsCollectionRequest> msgs = reqs.stream().collect(Collectors.toMap(\n-                    //        StatsAddrRequest::nodeId, StatsAddrRequest::req));\n-                    // TODO: resend it\n-                    sendRequests(reqs);\n-                } catch (IgniteCheckedException e) {\n-                    // TODO\n-                    e.printStackTrace();\n-                }\n+   public ObjectStatisticsImpl getGlobalStatistics(StatisticsKeyMessage key) {\n+        ObjectStatisticsImpl stat = statsRepos.getGlobalStatistics(new StatisticsKey(key.schema(), key.obj()));\n+        if (stat != null && !F.isEmpty(key.colNames()))\n+            stat = IgniteStatisticsHelper.filterColumns(stat, key.colNames());\n \n-            }\n-            return null;\n-        });\n+        return stat;\n+   }\n+\n+    /** {@inheritDoc} */\n+    @Override public ObjectStatistics getGlobalStatistics(String schemaName, String objName) {\n+        return statsRepos.getGlobalStatistics(new StatisticsKey(schemaName, objName));\n     }\n \n     /**\n-     * Listener to handle nodeLeft/nodeFailed and call onNodeLeft method.\n+     * Check that all server nodes in the cluster support STATISTICS_COLLECTION feature. Throws IgniteCheckedException\n+     * in not.\n+     *\n+     * @param op Operation name.\n+     * @throws IgniteCheckedException If at least one server node doesn't support feature.\n      */\n-    private class NodeLeftListener implements GridLocalEventListener {\n-\n-        /** {@inheritDoc} */\n-        @Override public void onEvent(Event evt) {\n-            assert evt.type() == EventType.EVT_NODE_FAILED || evt.type() == EventType.EVT_NODE_LEFT;\n+   private void checkStatisticsSupport(String op) throws IgniteCheckedException {\n+       if (!isStatisticsSupport()) {\n+           throw new IgniteCheckedException(String.format(\n+               \"Unable to perform %s due to not all server nodes supports STATISTICS_COLLECTION feature.\", op));\n+       }\n+   }\n \n-            final UUID nodeId = ((DiscoveryEvent)evt).eventNode().id();\n-\n-            ctx.closure().runLocalSafe(() -> onNodeLeft(nodeId), GridIoPolicy.QUERY_POOL);\n-        }\n-    }\n+    /**\n+     * Test is statistics collection feature are supported by each server node in cluster.\n+     *\n+     * @return {@code true} if all server nodes support STATISTICS_COLLECTION feature, {@code false} - otherwise.\n+     */\n+   private boolean isStatisticsSupport() {\n+       return IgniteFeatures.allNodesSupport(ctx, IgniteFeatures.STATISTICS_COLLECTION, IgniteDiscoverySpi.SRV_NODES);\n+   }\n }\n", "next_change": {"commit": "f7c029d501ec7a9584c7ab10075e28b9c9157764", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 47277987f34..3e1b656e59e 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -114,396 +163,339 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n                 new LinkedBlockingQueue<>(),\n                 GridIoPolicy.UNDEFINED,\n                 ctx.uncaughtExceptionHandler()\n-        );\n+            );\n+        }\n+        else {\n+            gatherPool = null;\n+            mgmtPool = null;\n+        }\n+\n+        obsolescenceBusyExecutor = new BusyExecutor(\"obsolescence\", mgmtPool, ctx::log);\n \n-        boolean storeData = !(ctx.config().isClientMode() || ctx.isDaemon());\n         IgniteStatisticsStore store;\n-        if (!storeData)\n+\n+        if (!serverNode)\n             store = new IgniteStatisticsDummyStoreImpl(ctx::log);\n         else if (db == null)\n             store = new IgniteStatisticsInMemoryStoreImpl(ctx::log);\n         else\n-            store = new IgniteStatisticsPersistenceStoreImpl(ctx.internalSubscriptionProcessor(), db,\n-                (k, s) -> this.statisticsRepository().cacheLocalStatistics(k, s), ctx::log);\n+            store = new IgniteStatisticsPersistenceStoreImpl(ctx.internalSubscriptionProcessor(), db, ctx::log);\n+\n+        statsRepos = new IgniteStatisticsRepository(store, ctx.systemView(), helper, ctx::log);\n+\n+        statProc = serverNode ? new StatisticsProcessor(\n+            statsRepos,\n+            gatherPool,\n+            ctx::log\n+        ) : null;\n+\n+        statCfgMgr = new IgniteStatisticsConfigurationManager(\n+            schemaMgr,\n+            ctx.internalSubscriptionProcessor(),\n+            ctx.systemView(),\n+            ctx.state(),\n+            statProc,\n+            db != null,\n+            mgmtPool,\n+            ctx::log,\n+            serverNode\n+        );\n \n-        statsRepos = new IgniteStatisticsRepositoryImpl(store, helper, ctx::log);\n+        ctx.internalSubscriptionProcessor().registerDistributedConfigurationListener(dispatcher -> {\n+            usageState.addListener((name, oldVal, newVal) -> {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Statistics usage state was changed from %s to %s\", oldVal, newVal));\n \n-        statCrawler = new StatisticsGatheringRequestCrawlerImpl(ctx.localNodeId(), this, ctx.event(), ctx.io(),\n-            helper, msgMgmtPool, ctx::log);\n-        statGathering = new StatisticsGatheringImpl(schemaMgr, ctx.discovery(), ctx.query(), statsRepos, statCrawler,\n-            gatMgmtPool, ctx::log);\n+                lastUsageState = newVal;\n \n-    }\n+                if (oldVal == newVal)\n+                    return;\n \n-    /**\n-     * @return Statistics repository.\n-     */\n-    public IgniteStatisticsRepository statisticsRepository() {\n-        return statsRepos;\n-    }\n+                if (newVal == ON || newVal == NO_UPDATE)\n+                    tryStart();\n \n-    /** {@inheritDoc} */\n-    @Override public ObjectStatistics getLocalStatistics(String schemaName, String objName) {\n-        return statsRepos.getLocalStatistics(new StatisticsKey(schemaName, objName));\n-    }\n+                if (newVal == OFF)\n+                    tryStop();\n+            });\n \n-    /**\n-     * Clear object statistics implementation.\n-     *\n-     * @param keys Keys to clear statistics by.\n-     * @throws IgniteCheckedException In case of errors.\n-     */\n-    private void clearObjectStatistics(Collection<StatisticsKeyMessage> keys) throws IgniteCheckedException {\n-        checkStatisticsSupport(\"clear statistics\");\n+            dispatcher.registerProperty(usageState);\n+        });\n+\n+        tryStart();\n+\n+        if (serverNode) {\n+            // Use mgmt pool to work with statistics repository in busy lock to schedule some tasks.\n+            obsolescenceSchedule = ctx.timeout().schedule(() -> {\n+                obsolescenceBusyExecutor.execute(() -> processObsolescence());\n+            }, OBSOLESCENCE_INTERVAL * 1000, OBSOLESCENCE_INTERVAL * 1000);\n+        }\n \n-        statCrawler.sendClearStatisticsAsync(keys);\n+        ctx.cache().context().exchange().registerExchangeAwareComponent(exchAwareLsnr);\n     }\n \n     /**\n-     * Clear local statistics by specified keys.\n-     *\n-     * @param keys Keys to clear statistics by.\n+     * Check all preconditions and stop if started and have reason to stop.\n      */\n-    public void clearObjectsStatisticsLocal(Collection<StatisticsKeyMessage> keys) {\n-        for (StatisticsKeyMessage key : keys)\n-            clearObjectStatisticsLocal(key);\n+    private synchronized void tryStop() {\n+        StatisticsUsageState statUsageState = usageState();\n+\n+        if (!(ClusterState.ACTIVE == ctx.state().clusterState().state()\n+            && !ctx.isStopping()\n+            && (statUsageState == ON || statUsageState == NO_UPDATE))\n+            && started)\n+            stopX();\n     }\n \n     /**\n-     * Update counter to mark that statistics by some partitions where collected by remote request.\n-     *\n-     * @param gatId Gathering id.\n-     * @param parts Partitions count.\n+     * Stop all statistics related components.\n      */\n-    public void onRemoteGatheringSend(UUID gatId, int parts) {\n-        currColls.compute(gatId, (k,v) -> {\n-           if (v == null) {\n-               if (log.isDebugEnabled())\n-                   log.debug(String.format(\"Unable to mark %d partitions gathered by gathering id %s\", parts, gatId));\n+    private void stopX() {\n+        if (log.isDebugEnabled())\n+            log.debug(\"Stopping statistics subsystem\");\n \n-               return null;\n-           }\n-\n-           return v.registerCollected(Collections.emptyMap(), parts) ? null : v;\n-        });\n-    }\n+        statCfgMgr.stop();\n \n-    /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(StatisticsTarget... targets) throws IgniteCheckedException {\n-        checkStatisticsSupport(\"clear statistics\");\n+        if (statProc != null)\n+            statProc.stop();\n \n-        List<StatisticsKeyMessage> keys = Arrays.stream(targets).map(target -> new StatisticsKeyMessage(target.schema(),\n-            target.obj(), Arrays.asList(target.columns()))).collect(Collectors.toList());\n+        statsRepos.stop();\n \n-        clearObjectStatistics(keys);\n+        obsolescenceBusyExecutor.deactivate(() -> {});\n+        started = false;\n     }\n \n     /**\n-     * Actually clear local object statistics by the given key.\n-     *\n-     * @param keyMsg Key to clear statistics by.\n+     * Check all preconditions and start if stopped and all preconditions pass.\n      */\n-    private void clearObjectStatisticsLocal(StatisticsKeyMessage keyMsg) {\n-        StatisticsKey key = new StatisticsKey(keyMsg.schema(), keyMsg.obj());\n-        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n-\n-        statsRepos.clearLocalPartitionsStatistics(key, colNames);\n-        statsRepos.clearLocalStatistics(key, colNames);\n-        statsRepos.clearGlobalStatistics(key, colNames);\n+    private synchronized void tryStart() {\n+        StatisticsUsageState statUsageState = usageState();\n+\n+        if (ClusterState.ACTIVE == ctx.state().clusterState().state()\n+            && !ctx.isStopping()\n+            && (statUsageState == ON || statUsageState == NO_UPDATE)\n+            && !started)\n+            startX();\n     }\n \n     /**\n-     * Collect object statistics prepared status.\n-     *\n-     * @param status Collection status to collect statistics by.\n+     * Start all statistics related components.\n      */\n-    private void collectObjectStatistics(StatisticsGatheringContext status) {\n-        statCrawler.sendGatheringRequestsAsync(status.gatheringId(), status.keys(), null);\n-    }\n-\n-    /** {@inheritDoc} */\n-    @Override public void gatherObjectStatistics(StatisticsTarget target) throws IgniteCheckedException {\n-        checkStatisticsSupport(\"collect statistics\");\n+    private void startX() {\n+        if (log.isDebugEnabled())\n+            log.debug(\"Starting statistics subsystem...\");\n \n-        StatisticsKeyMessage keyMsg = new StatisticsKeyMessage(target.schema(), target.obj(),\n-            Arrays.asList(target.columns()));\n-        CacheGroupContext grpCtx = helper.getGroupContext(keyMsg);\n+        obsolescenceBusyExecutor.activate();\n \n-        StatisticsGatheringContext status = new StatisticsGatheringContext(UUID.randomUUID(),\n-            Collections.singleton(keyMsg), grpCtx.topology().partitions());\n+        statsRepos.start();\n \n-        currColls.put(status.gatheringId(), status);\n+        if (statProc != null)\n+            statProc.start();\n \n-        collectObjectStatistics(status);\n+        statCfgMgr.start();\n \n-        status.doneFuture().get();\n+        started = true;\n     }\n \n     /**\n-     * Ensure that local gathering context exists and schedule local statistics gathering.\n-     *\n-     * @param nodeId Initiator node id.\n-     * @param gatId Gathering id.\n-     * @param reqId Request id.\n-     * @param keys Keys to collect statistics by.\n-     * @param parts Partitions to collect statistics from.\n+     * @return Statistics repository.\n      */\n-    public void gatherLocalObjectStatisticsAsync(\n-        UUID gatId,\n-        UUID reqId,\n-        Collection<StatisticsKeyMessage> keys,\n-        int[] parts\n-    ) {\n-        int partsCnt = (int)Arrays.stream(parts).count();\n-        Set<StatisticsKeyMessage> keysSet = new HashSet<>(keys);\n-\n-        StatisticsGatheringContext gCtx = currColls.computeIfAbsent(gatId, k ->\n-            new StatisticsGatheringContext(gatId, keysSet, partsCnt));\n-\n-        statGathering.collectLocalObjectsStatisticsAsync(reqId, keysSet, parts, () -> gCtx.doneFuture().isCancelled());\n+    public IgniteStatisticsRepository statisticsRepository() {\n+        return statsRepos;\n     }\n \n     /** {@inheritDoc} */\n-    @Override public StatisticsGatheringFuture<Map<StatisticsTarget, ObjectStatistics>>[] gatherObjectStatisticsAsync(\n-        StatisticsTarget... keys\n-    ) {\n-\n-        Set<StatisticsKeyMessage> keysMsg = Arrays.stream(keys).map(StatisticsUtils::statisticsKeyMessage)\n-            .collect(Collectors.toSet());\n-\n-        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpsKeys = helper.splitByGroups(keysMsg);\n+    @Override public ObjectStatistics getLocalStatistics(StatisticsKey key) {\n+        StatisticsUsageState currState = usageState();\n \n-        if (!isStatisticsSupport()) {\n-            return grpsKeys.entrySet().stream().map(\n-                grpKeys -> new StatisticsGatheringFutureAdapter(UUID.randomUUID(),\n-                    grpKeys.getValue().stream().map(StatisticsUtils::statisticsTarget).toArray(StatisticsTarget[]::new)))\n-                .toArray(StatisticsGatheringFuture[]::new);\n-        }\n-\n-        Collection<StatisticsKeyMessage> notFoundKeys = grpsKeys.remove(null);\n+        return (currState == ON || currState == NO_UPDATE) ? statsRepos.getLocalStatistics(key) : null;\n+    }\n \n-        List<StatisticsGatheringFuture<Map<StatisticsTarget, ObjectStatistics>>> res = new ArrayList<>();\n+    /** {@inheritDoc} */\n+    @Override public void collectStatistics(StatisticsObjectConfiguration... targets) throws IgniteCheckedException {\n+        ensureActive(\"collect statistics\");\n \n-        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpKeys : grpsKeys.entrySet()) {\n-            int parts = grpKeys.getKey().topology().partitions();\n+        if (usageState() == OFF)\n+            throw new IgniteException(\"Can't gather statistics while statistics usage state is OFF.\");\n \n-            StatisticsGatheringContext status = new StatisticsGatheringContext(UUID.randomUUID(),\n-                    new HashSet<>(grpKeys.getValue()), parts);\n-            currColls.put(status.gatheringId(), status);\n+        statCfgMgr.updateStatistics(targets);\n+    }\n \n-            collectObjectStatistics(status);\n+    /** {@inheritDoc} */\n+    @Override public void dropStatistics(StatisticsTarget... targets) throws IgniteCheckedException {\n+        ensureActive(\"drop statistics\");\n \n-            res.add(status.doneFuture());\n-        }\n-        if (notFoundKeys != null) {\n-            StatisticsGatheringFutureAdapter<Map<StatisticsTarget, ObjectStatistics>> notFoundFut =\n-                new StatisticsGatheringFutureAdapter<>(UUID.randomUUID(),\n-                    notFoundKeys.stream().map(StatisticsUtils::statisticsTarget).toArray(StatisticsTarget[]::new));\n+        if (usageState() == OFF)\n+            throw new IgniteException(\"Can't drop statistics while statistics usage state is OFF.\");\n \n-            notFoundFut.onDone(new IgniteCheckedException(notFoundKeys.size() + \" target not found.\"));\n+        statCfgMgr.dropStatistics(Arrays.asList(targets), true);\n+    }\n \n-            res.add(notFoundFut);\n-        }\n+    /** {@inheritDoc} */\n+    @Override public void refreshStatistics(StatisticsTarget... targets) throws IgniteCheckedException {\n+        ensureActive(\"refresh statistics\");\n \n-        return res.toArray(new StatisticsGatheringFuture[0]);\n-    }\n+        if (usageState() == OFF)\n+            throw new IgniteException(\"Can't refresh statistics while statistics usage state is OFF.\");\n \n-    /**\n-     * Cancel specified statistics gathering process.\n-     *\n-     * @param gatId Gathering id to cancel.\n-     */\n-    public void cancelLocalStatisticsGathering(UUID gatId) {\n-       StatisticsGatheringContext stCtx = currColls.remove(gatId);\n-       if (stCtx != null)\n-           stCtx.doneFuture().cancel();\n-       else {\n-           if (log.isDebugEnabled())\n-               log.debug(String.format(\"Unable to cancel gathering %s. No active task with such gatId found.\", gatId));\n-       }\n+        statCfgMgr.refreshStatistics(Arrays.asList(targets));\n     }\n \n     /** {@inheritDoc} */\n-    @Override public boolean cancelObjectStatisticsGathering(UUID gatId) throws IgniteCheckedException {\n-        checkStatisticsSupport(\"cancel gathering\");\n-\n-        boolean res = false;\n-        StatisticsGatheringContext stCtx = currColls.get(gatId);\n-        if (stCtx != null) {\n+    @Override public void dropAll() throws IgniteCheckedException {\n+        ensureActive(\"drop all statistics\");\n \n-            res = stCtx.doneFuture().cancel();\n-            if (res)\n-                statCrawler.sendCancelGatheringAsync(gatId);\n-        }\n-        return res;\n+        statCfgMgr.dropAll();\n     }\n \n-    /**\n-     * Receive and store partition statistics object data for locals backup partition.\n-     *\n-     * @param data Collection of partition level statistics of local bacup partitions.\n-     */\n-    public void receivePartitionsStatistics(Collection<StatisticsObjectData> data) {\n-        for (StatisticsObjectData partData : data) {\n-            StatisticsKey key = new StatisticsKey(partData.key().schema(), partData.key().obj());\n+    /** {@inheritDoc} */\n+    @Override public void stop() {\n+        stopX();\n \n-            assert partData.type() == StatisticsType.PARTITION : \"Got non partition level statistics by \" + key\n-                    + \" without request\";\n+        if (obsolescenceSchedule != null)\n+            obsolescenceSchedule.close();\n \n-            if (log.isTraceEnabled())\n-                log.trace(String.format(\"Received partition statistics %s.%s:%d\", key.schema(), key.obj(),\n-                    partData.partId()));\n-\n-            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n-            if (tbl == null) {\n-                if (log.isInfoEnabled())\n-                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d\", key.schema(), key.obj(),\n-                        partData.partId()));\n+        if (gatherPool != null) {\n+            List<Runnable> unfinishedTasks = gatherPool.shutdownNow();\n \n-                continue;\n-            }\n-            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(ctx.localNodeId(),\n-                partData.partId());\n-            if (partState != OWNING) {\n-                if (log.isTraceEnabled())\n-                    log.trace(String.format(\"Ignoring non local partition statistics %s.%s:%d\",\n-                            key.schema(), key.obj(), partData.partId()));\n-\n-                continue;\n-            }\n+            if (!unfinishedTasks.isEmpty())\n+                log.warning(String.format(\"%d statistics collection cancelled.\", unfinishedTasks.size()));\n+        }\n \n-            try {\n-                ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n+        if (mgmtPool != null) {\n+            List<Runnable> unfinishedTasks = mgmtPool.shutdownNow();\n \n-                statsRepos.saveLocalPartitionStatistics(key, opStat);\n-            }\n-            catch (IgniteCheckedException e) {\n-                if (log.isInfoEnabled())\n-                    log.info(String.format(\"Unable to parse partition statistics for %s.%s:%d because of: %s\",\n-                        key.schema(), key.obj(), partData.partId(), e.getMessage()));\n+            if (!unfinishedTasks.isEmpty()) {\n+                log.warning(String.format(\"%d statistics configuration change handler cancelled.\",\n+                    unfinishedTasks.size()));\n             }\n         }\n     }\n \n     /**\n-     * Aggregate specified gathered statistics, remove it form local and complete its future.\n-     *\n-     * @param stCtx Gathering to complete.\n+     * @return Statistics configuration manager.\n      */\n-    public void finishStatisticsCollection(StatisticsGatheringContext stCtx) {\n-        currColls.remove(stCtx.gatheringId());\n-\n-        Map<StatisticsTarget, ObjectStatistics> targetStats = new HashMap<>();\n-        Map<StatisticsKeyMessage, ObjectStatisticsImpl> keysStats = new HashMap<>();\n-        for (Map.Entry<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : stCtx.collectedStatistics()\n-                .entrySet()) {\n-            ObjectStatisticsImpl globalCollectedStat = helper.aggregateLocalStatistics(keyStats.getKey(),\n-                keyStats.getValue());\n+    public IgniteStatisticsConfigurationManager statisticConfiguration() {\n+        return statCfgMgr;\n+    }\n \n-            StatisticsKey statsKey = new StatisticsKey(keyStats.getKey().schema(), keyStats.getKey().obj());\n-            ObjectStatisticsImpl globalStat = statsRepos.mergeGlobalStatistics(statsKey, globalCollectedStat);\n+    /** {@inheritDoc} */\n+    @Override public void usageState(StatisticsUsageState state) throws IgniteCheckedException {\n+        ensureActive(\"change usage state of statistics\");\n \n-            targetStats.put(StatisticsUtils.statisticsTarget(keyStats.getKey()), globalStat);\n-            keysStats.put(keyStats.getKey(), globalStat);\n+        try {\n+            usageState.propagate(state);\n         }\n+        catch (IgniteCheckedException e) {\n+            log.error(\"Unable to set usage state value due to \" + e.getMessage(), e);\n+        }\n+    }\n \n-        statCrawler.sendGlobalStatAsync(keysStats);\n-\n-        stCtx.doneFuture().onDone(targetStats);\n+    /** {@inheritDoc} */\n+    @Override public StatisticsUsageState usageState() {\n+        return (lastUsageState == null) ? DEFAULT_STATISTICS_USAGE_STATE : lastUsageState;\n     }\n \n-    /**\n-     * Cache global statistics.\n-     *\n-     * @param data Global statistics to cache.\n-     */\n-    public void saveGlobalStatistics(Collection<StatisticsObjectData> data) {\n-        for (StatisticsObjectData objData : data) {\n-            try {\n-                ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(this.ctx, objData);\n+    /** {@inheritDoc} */\n+    @Override public void onRowUpdated(String schemaName, String objName, int partId, byte[] keyBytes) {\n+        ObjectPartitionStatisticsObsolescence statObs = statsRepos.getObsolescence(\n+            new StatisticsKey(schemaName, objName), partId);\n \n-                statsRepos.saveGlobalStatistics(new StatisticsKey(objData.key().schema(), objData.key().obj()), objStat);\n-            }\n-            catch (IgniteCheckedException e) {\n-                if (log.isDebugEnabled())\n-                    log.debug(String.format(\"Cannot read global statistics %s\", objData.key()));\n-            }\n-        };\n+        if (statObs != null)\n+            statObs.onModified(keyBytes);\n     }\n \n     /**\n-     * Register collected statistics in task context.\n+     * Save dirty obsolescence info to local metastore. Check if statistics need to be refreshed and schedule it.\n      *\n-     * @param gatId Gathering id.\n-     * @param data Collected statistics.\n-     * @param partsCount Count of collected partitions.\n+     * 1) Get all dirty partition statistics.\n+     * 2) Make separate tasks for each key to avoid saving obsolescence info for removed partition (race).\n+     * 3) Check if partition should be recollected and add it to list in its tables task.\n+     * 4) Submit tasks. Actually obsolescence info will be stored during task processing.\n      */\n-    public void registerLocalResult(UUID gatId, Collection<StatisticsObjectData> data, int partsCount) {\n-        StatisticsGatheringContext stCtx = currColls.get(gatId);\n-        if (stCtx == null) {\n+    public synchronized void processObsolescence() {\n+        StatisticsUsageState usageState = usageState();\n+\n+        if (usageState != ON || ctx.isStopping()) {\n             if (log.isDebugEnabled())\n-                log.debug(String.format(\"Unable to register outdated statistics collection result %s\", gatId));\n+                log.debug(\"Skipping obsolescence processing.\");\n \n             return;\n         }\n-        Map<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats = new HashMap<>();\n-        for (StatisticsObjectData objData : data) {\n-            Collection<ObjectStatisticsImpl> keyObjStats = keyStats.computeIfAbsent(objData.key(), k -> new ArrayList<>());\n-            try {\n-                ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n \n-                keyObjStats.add(objStat);\n+        if (log.isTraceEnabled())\n+            log.trace(\"Process statistics obsolescence started.\");\n+\n+        List<StatisticsKey> keys = statsRepos.getObsolescenceKeys();\n+\n+        if (F.isEmpty(keys)) {\n+            if (log.isTraceEnabled())\n+                log.trace(\"No obsolescence info found. Finish obsolescence processing.\");\n+\n+            return;\n+        }\n+        else {\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Scheduling obsolescence savings for %d targets\", keys.size()));\n+        }\n+\n+        for (StatisticsKey key : keys) {\n+            StatisticsObjectConfiguration cfg = null;\n+            try {\n+                 cfg = statCfgMgr.config(key);\n             }\n             catch (IgniteCheckedException e) {\n+                // No-op/\n+            }\n+            Set<Integer> tasksParts = calculateObsolescencedPartitions(cfg, statsRepos.getObsolescence(key));\n+\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+\n+            if (tbl == null) {\n+                // Table can be removed earlier, but not already processed. Or somethink goes wrong. Try to reschedule.\n                 if (log.isDebugEnabled())\n-                    log.debug(String.format(\"Cannot read local statistics %s by gathering task %s\", objData.key(),\n-                        gatId));\n+                    log.debug(String.format(\"Got obsolescence statistics for unknown table %s\", key));\n             }\n-        }\n \n-        if (stCtx.registerCollected(keyStats, partsCount))\n-            finishStatisticsCollection(stCtx);\n+            LocalStatisticsGatheringContext ctx = new LocalStatisticsGatheringContext(true, tbl, cfg,\n+                tasksParts, null);\n+            statProc.updateLocalStatistics(ctx);\n+        }\n     }\n \n     /**\n-     * Get global statistics by key.\n+     * Calculate targets to refresh obsolescence statistics by map of dirty partitions and actual per partition\n+     * statistics.\n      *\n-     * @param key Key to get statistics by.\n-     * @return Global statistics or {@code null} if there are no statistics for specified key.\n+     * @param cfg Statistics configuration\n+     * @param parts  list of it's obsolescence info paritions.\n+     * @return Map of statistics cfg to partition to refresh statistics.\n      */\n-   public ObjectStatisticsImpl getGlobalStatistics(StatisticsKeyMessage key) {\n-        ObjectStatisticsImpl stat = statsRepos.getGlobalStatistics(new StatisticsKey(key.schema(), key.obj()));\n-        if (stat != null && !F.isEmpty(key.colNames()))\n-            stat = IgniteStatisticsHelper.filterColumns(stat, key.colNames());\n+    private Set<Integer> calculateObsolescencedPartitions(\n+        StatisticsObjectConfiguration cfg,\n+        IntMap<ObjectPartitionStatisticsObsolescence> parts\n+    ) {\n+        Set<Integer> res = new HashSet<>();\n \n-        return stat;\n-   }\n+        parts.forEach((k, v) -> {\n+            ObjectPartitionStatisticsImpl partStat = statsRepos.getLocalPartitionStatistics(cfg.key(), k);\n \n-    /** {@inheritDoc} */\n-    @Override public ObjectStatistics getGlobalStatistics(String schemaName, String objName) {\n-        return statsRepos.getGlobalStatistics(new StatisticsKey(schemaName, objName));\n+            if (partStat == null || partStat.rowCount() == 0 ||\n+                (double)v.modified() * 100 / partStat.rowCount() > cfg.maxPartitionObsolescencePercent())\n+                res.add(k);\n+        });\n+\n+        // Will add even empty list of partitions to recollect just to force obsolescence info to be stored.\n+        return res;\n     }\n \n     /**\n-     * Check that all server nodes in the cluster support STATISTICS_COLLECTION feature. Throws IgniteCheckedException\n-     * in not.\n+     * Check that cluster is active.\n      *\n      * @param op Operation name.\n-     * @throws IgniteCheckedException If at least one server node doesn't support feature.\n-     */\n-   private void checkStatisticsSupport(String op) throws IgniteCheckedException {\n-       if (!isStatisticsSupport()) {\n-           throw new IgniteCheckedException(String.format(\n-               \"Unable to perform %s due to not all server nodes supports STATISTICS_COLLECTION feature.\", op));\n-       }\n-   }\n-\n-    /**\n-     * Test is statistics collection feature are supported by each server node in cluster.\n-     *\n-     * @return {@code true} if all server nodes support STATISTICS_COLLECTION feature, {@code false} - otherwise.\n      */\n-   private boolean isStatisticsSupport() {\n-       return IgniteFeatures.allNodesSupport(ctx, IgniteFeatures.STATISTICS_COLLECTION, IgniteDiscoverySpi.SRV_NODES);\n-   }\n+    public void ensureActive(String op) {\n+        if (ctx.state().clusterState().state() != ClusterState.ACTIVE)\n+            throw new IgniteException(String.format(\n+                \"Unable to perform %s due to cluster state [state=%s]\", op, ctx.state().clusterState().state()));\n+    }\n }\n", "next_change": null}]}}]}, "commits_in_main": [{"oid": "baf94dd2b9a49d96b7043541aa6268320cdb908f", "message": "Merge commit", "committedDate": null}, {"oid": "4db9f6fb7e829b14ff1634fc70fbb03033365bbd", "committedDate": "2021-02-09 19:15:51 +0700", "message": "GG-18648: SQL Statistics command (#1741)"}, {"oid": "e45398f7352b78b3cdec008e09ab1dc1ad3a3cc9", "committedDate": "2021-02-26 11:41:10 +0300", "message": "GG-32420 SQL statistics: introduce statistic configuration"}, {"oid": "02ed3feb46ed771da5eb3f5a5a9f27e360bbe4bb", "committedDate": "2021-03-08 14:00:34 +0700", "message": "GG-32076: add property to disable statistics collection/usage."}, {"oid": "656a37440a870ecc25d256fbd1f49e5a1c4c7d71", "committedDate": "2021-03-25 13:28:13 +0700", "message": "GG-18641: Statistics obsolescence (#1803)"}, {"oid": "a81df187999cd0b51ea20944de98947840d578b9", "committedDate": "2021-03-25 14:43:27 +0700", "message": "GG-30750: Statistics views (#1821)"}, {"oid": "66113283571dec305736d66d38a59e6f622f5051", "committedDate": "2021-08-10 13:30:41 +0700", "message": "GG-33002 Fix DistributedMetaStoragePersistentTest.testDeactivateActivate flaky test. (#2037)"}, {"oid": "6f4bc0456765b0fa489f28684796c818d7aaffd0", "committedDate": "2021-10-05 13:38:47 +0700", "message": "GG-33621 [IGNITE-15267] A lot of spam in logs on thick client: \"Unable to save statistics obsolescence info on non server node.\""}, {"oid": "f7c029d501ec7a9584c7ab10075e28b9c9157764", "committedDate": "2021-10-28 12:55:05 +0700", "message": "GG-33636 [IGNITE-15281] New local statistics collection (#2138)"}, {"oid": "eb7a2aaa7a1a3d028802eaf18da242f362046265", "committedDate": "2022-10-17 11:46:53 +0300", "message": "GG-35765 SQL: Fix deadlock when saving statistics data to the metastorage. (#2594)"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc4NDU3Mg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546784572", "body": "doneFut is not used", "bodyText": "doneFut is not used", "bodyHTML": "<p dir=\"auto\">doneFut is not used</p>", "author": "korlov42", "createdAt": "2020-12-21T15:55:03Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -91,81 +154,344 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter(null);", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTAzMDYwNA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555030604", "bodyText": "fixed", "author": "Berkof", "createdAt": "2021-01-11T13:01:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc4NDU3Mg=="}], "type": "inlineReview", "revised_code": {"commit": "b595e90b5b480aaf80a9256558b1841334df97de", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 0f88eff3479..7fab3588e96 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -153,32 +150,50 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n         return statsRepos.getLocalStatistics(new StatsKey(schemaName, objName));\n     }\n \n+    /**\n+     * Clear object statistics implementation.\n+     *\n+     * @param keys Keys to clear statistics by.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void clearObjectStatistics(Collection<StatsKeyMessage> keys) throws IgniteCheckedException {\n+        Collection<StatsAddrRequest<StatsClearRequest>> clearReqs = currCollections.generateClearRequests(keys);\n+\n+        Collection<StatsAddrRequest<StatsClearRequest>> failedReqs = sendRequests(clearReqs);\n+        if (!F.isEmpty(failedReqs))\n+            if (log.isInfoEnabled())\n+                log.info(String.format(\"Unable to send all statistics clear requests to %d nodes for keys %s\",\n+                    failedReqs.size(), keys));\n+\n+\n+        UUID locId = ctx.localNodeId();\n+        StatsAddrRequest<StatsClearRequest> locMsg = clearReqs.stream().filter(m -> locId.equals(m.nodeId())).findAny()\n+                .orElse(null);\n+        if (null != locMsg)\n+            for (StatsKeyMessage locKey : locMsg.req().keys())\n+                clearObjectStatisticsLocal(locKey);\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void clearObjectStatistics(\n+            GridTuple3<String, String, String[]>... keys\n+    ) throws IgniteCheckedException {\n+\n+        Collection<StatsKeyMessage> keyMsgs = Arrays.stream(keys).map(k -> new StatsKeyMessage(k.get1(), k.get2(),\n+                Arrays.asList(k.get3()))).collect(Collectors.toList());\n+\n+        clearObjectStatistics(keyMsgs);\n+    }\n+\n     /** {@inheritDoc} */\n     @Override public void clearObjectStatistics(\n             String schemaName,\n             String objName,\n             String... colNames\n     ) throws IgniteCheckedException {\n-        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter(null);\n-\n-        UUID reqId = UUID.randomUUID();\n         StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n-        Collection<StatsAddrRequest<StatsClearRequest>> reqs = currCollections\n-                .generateClearRequests(Collections.singletonList(keyMsg));\n-\n-        sendRequests(reqs);\n-        Map<UUID, List<Integer>> requestNodes = null;\n-        /*try {\n-            requestNodes = nodePartitions(extractGroups(Collections.singletonList(keyMsg)), null);\n-        } catch (IgniteCheckedException e) {\n-            // TODO: handle & remove task\n-        }\n-\n-        StatsClearRequest req = new StatsClearRequest(reqId, false, Collections.singletonList(keyMsg));\n \n-        sendLocalRequests(reqId, req, requestNodes);*/\n-\n-        clearObjectStatisticsLocal(keyMsg);\n+        clearObjectStatistics(Collections.singleton(keyMsg));\n     }\n \n     /**\n", "next_change": {"commit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 7fab3588e96..f208a744d01 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -191,7 +185,7 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n             String objName,\n             String... colNames\n     ) throws IgniteCheckedException {\n-        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+        StatisticsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n \n         clearObjectStatistics(Collections.singleton(keyMsg));\n     }\n", "next_change": {"commit": "17a54090bea4d97c122cf06d6be8e60177006519", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex f208a744d01..636f380904e 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -151,43 +152,45 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n      * @throws IgniteCheckedException In case of errors.\n      */\n     private void clearObjectStatistics(Collection<StatisticsKeyMessage> keys) throws IgniteCheckedException {\n-        Collection<StatisticsAddrRequest<StatisticsClearRequest>> clearReqs = helper.generateClearRequests(keys);\n-\n-        Collection<StatisticsAddrRequest<StatisticsClearRequest>> failedReqs = sendRequests(clearReqs);\n-        if (!F.isEmpty(failedReqs))\n-            if (log.isInfoEnabled())\n-                log.info(String.format(\"Unable to send all statistics clear requests to %d nodes for keys %s\",\n-                    failedReqs.size(), keys));\n-\n+        statCrawler.sendClearStatisticsAsync(keys);\n+    }\n \n-        UUID locId = ctx.localNodeId();\n-        StatisticsAddrRequest<StatisticsClearRequest> locMsg = clearReqs.stream().filter(m -> locId.equals(m.nodeId())).findAny()\n-                .orElse(null);\n-        if (null != locMsg)\n-            for (StatisticsKeyMessage locKey : locMsg.req().keys())\n-                clearObjectStatisticsLocal(locKey);\n+    /**\n+     * Clear local statistics by specified keys.\n+     *\n+     * @param keys Keys to clear statistics by.\n+     */\n+    public void clearObjectsStatisticsLocal(Collection<StatisticsKeyMessage> keys) {\n+        for (StatisticsKeyMessage key : keys)\n+            clearObjectStatisticsLocal(key);\n     }\n \n-    /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(\n-            GridTuple3<String, String, String[]>... keys\n-    ) throws IgniteCheckedException {\n+    /**\n+     * Update counter to mark that statistics by some partitions where collected by remote request.\n+     *\n+     * @param gatId Gathering id.\n+     * @param parts Partitions count.\n+     */\n+    public void onRemoteGatheringSend(UUID gatId, int parts) {\n+        currColls.compute(gatId, (k,v) -> {\n+           if (v == null) {\n+               if (log.isDebugEnabled())\n+                   log.debug(String.format(\"Unable to mark %d partitions gathered by gathering id %s\", parts, gatId));\n \n-        Collection<StatisticsKeyMessage> keyMsgs = Arrays.stream(keys).map(k -> new StatisticsKeyMessage(k.get1(), k.get2(),\n-                Arrays.asList(k.get3()))).collect(Collectors.toList());\n+               return null;\n+           }\n \n-        clearObjectStatistics(keyMsgs);\n+           return v.registerCollected(Collections.emptyMap(), parts) ? null : v;\n+        });\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(\n-            String schemaName,\n-            String objName,\n-            String... colNames\n-    ) throws IgniteCheckedException {\n-        StatisticsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+    @Override public void clearObjectStatistics(StatisticsTarget... targets) throws IgniteCheckedException {\n \n-        clearObjectStatistics(Collections.singleton(keyMsg));\n+        List<StatisticsKeyMessage> keys = Arrays.stream(targets).map(target -> new StatisticsKeyMessage(target.schema(),\n+            target.obj(), Arrays.asList(target.columns()))).collect(Collectors.toList());\n+\n+        clearObjectStatistics(keys);\n     }\n \n     /**\n", "next_change": null}]}}, {"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 7fab3588e96..f208a744d01 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -201,8 +195,8 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n      *\n      * @param keyMsg Key to clear statistics by.\n      */\n-    private void clearObjectStatisticsLocal(StatsKeyMessage keyMsg) {\n-        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+    private void clearObjectStatisticsLocal(StatisticsKeyMessage keyMsg) {\n+        StatisticsKey key = new StatisticsKey(keyMsg.schema(), keyMsg.obj());\n         String[] colNames = keyMsg.colNames().toArray(new String[0]);\n \n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc4NzEwOA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r546787108", "body": "`sendRequests` returns a list of failed request. Think there should be retries ", "bodyText": "sendRequests returns a list of failed request. Think there should be retries", "bodyHTML": "<p dir=\"auto\"><code>sendRequests</code> returns a list of failed request. Think there should be retries</p>", "author": "korlov42", "createdAt": "2020-12-21T15:59:24Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -91,81 +154,344 @@ public IgniteStatisticsRepository statisticsRepository() {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter(null);\n+\n+        UUID reqId = UUID.randomUUID();\n+        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+        Collection<StatsAddrRequest<StatsClearRequest>> reqs = currCollections\n+                .generateClearRequests(Collections.singletonList(keyMsg));\n+\n+        sendRequests(reqs);", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTAzMTY2Nw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555031667", "bodyText": "send stand for communication wrapping only. To retry we, probably, need remap requests to new nodes.", "author": "Berkof", "createdAt": "2021-01-11T13:03:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njc4NzEwOA=="}], "type": "inlineReview", "revised_code": {"commit": "b595e90b5b480aaf80a9256558b1841334df97de", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 0f88eff3479..7fab3588e96 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -153,32 +150,50 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n         return statsRepos.getLocalStatistics(new StatsKey(schemaName, objName));\n     }\n \n+    /**\n+     * Clear object statistics implementation.\n+     *\n+     * @param keys Keys to clear statistics by.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void clearObjectStatistics(Collection<StatsKeyMessage> keys) throws IgniteCheckedException {\n+        Collection<StatsAddrRequest<StatsClearRequest>> clearReqs = currCollections.generateClearRequests(keys);\n+\n+        Collection<StatsAddrRequest<StatsClearRequest>> failedReqs = sendRequests(clearReqs);\n+        if (!F.isEmpty(failedReqs))\n+            if (log.isInfoEnabled())\n+                log.info(String.format(\"Unable to send all statistics clear requests to %d nodes for keys %s\",\n+                    failedReqs.size(), keys));\n+\n+\n+        UUID locId = ctx.localNodeId();\n+        StatsAddrRequest<StatsClearRequest> locMsg = clearReqs.stream().filter(m -> locId.equals(m.nodeId())).findAny()\n+                .orElse(null);\n+        if (null != locMsg)\n+            for (StatsKeyMessage locKey : locMsg.req().keys())\n+                clearObjectStatisticsLocal(locKey);\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void clearObjectStatistics(\n+            GridTuple3<String, String, String[]>... keys\n+    ) throws IgniteCheckedException {\n+\n+        Collection<StatsKeyMessage> keyMsgs = Arrays.stream(keys).map(k -> new StatsKeyMessage(k.get1(), k.get2(),\n+                Arrays.asList(k.get3()))).collect(Collectors.toList());\n+\n+        clearObjectStatistics(keyMsgs);\n+    }\n+\n     /** {@inheritDoc} */\n     @Override public void clearObjectStatistics(\n             String schemaName,\n             String objName,\n             String... colNames\n     ) throws IgniteCheckedException {\n-        final StatsCollectionFutureAdapter doneFut = new StatsCollectionFutureAdapter(null);\n-\n-        UUID reqId = UUID.randomUUID();\n         StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n-        Collection<StatsAddrRequest<StatsClearRequest>> reqs = currCollections\n-                .generateClearRequests(Collections.singletonList(keyMsg));\n-\n-        sendRequests(reqs);\n-        Map<UUID, List<Integer>> requestNodes = null;\n-        /*try {\n-            requestNodes = nodePartitions(extractGroups(Collections.singletonList(keyMsg)), null);\n-        } catch (IgniteCheckedException e) {\n-            // TODO: handle & remove task\n-        }\n-\n-        StatsClearRequest req = new StatsClearRequest(reqId, false, Collections.singletonList(keyMsg));\n \n-        sendLocalRequests(reqId, req, requestNodes);*/\n-\n-        clearObjectStatisticsLocal(keyMsg);\n+        clearObjectStatistics(Collections.singleton(keyMsg));\n     }\n \n     /**\n", "next_change": {"commit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 7fab3588e96..f208a744d01 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -191,7 +185,7 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n             String objName,\n             String... colNames\n     ) throws IgniteCheckedException {\n-        StatsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+        StatisticsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n \n         clearObjectStatistics(Collections.singleton(keyMsg));\n     }\n", "next_change": {"commit": "17a54090bea4d97c122cf06d6be8e60177006519", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex f208a744d01..636f380904e 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -151,43 +152,45 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n      * @throws IgniteCheckedException In case of errors.\n      */\n     private void clearObjectStatistics(Collection<StatisticsKeyMessage> keys) throws IgniteCheckedException {\n-        Collection<StatisticsAddrRequest<StatisticsClearRequest>> clearReqs = helper.generateClearRequests(keys);\n-\n-        Collection<StatisticsAddrRequest<StatisticsClearRequest>> failedReqs = sendRequests(clearReqs);\n-        if (!F.isEmpty(failedReqs))\n-            if (log.isInfoEnabled())\n-                log.info(String.format(\"Unable to send all statistics clear requests to %d nodes for keys %s\",\n-                    failedReqs.size(), keys));\n-\n+        statCrawler.sendClearStatisticsAsync(keys);\n+    }\n \n-        UUID locId = ctx.localNodeId();\n-        StatisticsAddrRequest<StatisticsClearRequest> locMsg = clearReqs.stream().filter(m -> locId.equals(m.nodeId())).findAny()\n-                .orElse(null);\n-        if (null != locMsg)\n-            for (StatisticsKeyMessage locKey : locMsg.req().keys())\n-                clearObjectStatisticsLocal(locKey);\n+    /**\n+     * Clear local statistics by specified keys.\n+     *\n+     * @param keys Keys to clear statistics by.\n+     */\n+    public void clearObjectsStatisticsLocal(Collection<StatisticsKeyMessage> keys) {\n+        for (StatisticsKeyMessage key : keys)\n+            clearObjectStatisticsLocal(key);\n     }\n \n-    /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(\n-            GridTuple3<String, String, String[]>... keys\n-    ) throws IgniteCheckedException {\n+    /**\n+     * Update counter to mark that statistics by some partitions where collected by remote request.\n+     *\n+     * @param gatId Gathering id.\n+     * @param parts Partitions count.\n+     */\n+    public void onRemoteGatheringSend(UUID gatId, int parts) {\n+        currColls.compute(gatId, (k,v) -> {\n+           if (v == null) {\n+               if (log.isDebugEnabled())\n+                   log.debug(String.format(\"Unable to mark %d partitions gathered by gathering id %s\", parts, gatId));\n \n-        Collection<StatisticsKeyMessage> keyMsgs = Arrays.stream(keys).map(k -> new StatisticsKeyMessage(k.get1(), k.get2(),\n-                Arrays.asList(k.get3()))).collect(Collectors.toList());\n+               return null;\n+           }\n \n-        clearObjectStatistics(keyMsgs);\n+           return v.registerCollected(Collections.emptyMap(), parts) ? null : v;\n+        });\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(\n-            String schemaName,\n-            String objName,\n-            String... colNames\n-    ) throws IgniteCheckedException {\n-        StatisticsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+    @Override public void clearObjectStatistics(StatisticsTarget... targets) throws IgniteCheckedException {\n \n-        clearObjectStatistics(Collections.singleton(keyMsg));\n+        List<StatisticsKeyMessage> keys = Arrays.stream(targets).map(target -> new StatisticsKeyMessage(target.schema(),\n+            target.obj(), Arrays.asList(target.columns()))).collect(Collectors.toList());\n+\n+        clearObjectStatistics(keys);\n     }\n \n     /**\n", "next_change": null}]}}, {"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 7fab3588e96..f208a744d01 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -201,8 +195,8 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager, Gri\n      *\n      * @param keyMsg Key to clear statistics by.\n      */\n-    private void clearObjectStatisticsLocal(StatsKeyMessage keyMsg) {\n-        StatsKey key = new StatsKey(keyMsg.schema(), keyMsg.obj());\n+    private void clearObjectStatisticsLocal(StatisticsKeyMessage keyMsg) {\n+        StatisticsKey key = new StatisticsKey(keyMsg.schema(), keyMsg.obj());\n         String[] colNames = keyMsg.colNames().toArray(new String[0]);\n \n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzEzODcxNw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r547138717", "body": "unnecessary change", "bodyText": "unnecessary change", "bodyHTML": "<p dir=\"auto\">unnecessary change</p>", "author": "korlov42", "createdAt": "2020-12-22T08:32:11Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/h2/CommandResult.java", "diffHunk": "@@ -20,6 +20,7 @@\n \n import java.util.List;\n \n+", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTAzMjEyMw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555032123", "bodyText": "sure, reverted", "author": "Berkof", "createdAt": "2021-01-11T13:04:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzEzODcxNw=="}], "type": "inlineReview", "revised_code": {"commit": "604f88f1b4cd375f5474ea768ce8e4fa4fd3c658", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/h2/CommandResult.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/h2/CommandResult.java\nindex 305f040e511..f76a3c99902 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/h2/CommandResult.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/h2/CommandResult.java\n", "chunk": "@@ -20,7 +20,6 @@ import org.apache.ignite.cache.query.FieldsQueryCursor;\n \n import java.util.List;\n \n-\n /**\n  * Command execution result.\n  */\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE0MDEyNA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r547140124", "body": "unused imports", "bodyText": "unused imports", "bodyHTML": "<p dir=\"auto\">unused imports</p>", "author": "korlov42", "createdAt": "2020-12-22T08:35:28Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsInMemoryStoreImpl.java", "diffHunk": "@@ -16,6 +16,19 @@\n package org.apache.ignite.internal.processors.query.stat;\n \n import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.util.collection.IntHashMap;\n+import org.apache.ignite.internal.util.collection.IntMap;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTAzMjUzNg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555032536", "bodyText": "fixed", "author": "Berkof", "createdAt": "2021-01-11T13:05:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE0MDEyNA=="}], "type": "inlineReview", "revised_code": {"commit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsInMemoryStoreImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsInMemoryStoreImpl.java\nindex 410a98bf7d5..ec72f041551 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsInMemoryStoreImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsInMemoryStoreImpl.java\n", "chunk": "@@ -19,21 +19,9 @@ import org.apache.ignite.IgniteLogger;\n import org.apache.ignite.internal.util.collection.IntHashMap;\n import org.apache.ignite.internal.util.collection.IntMap;\n \n-import java.util.ArrayList;\n import java.util.Arrays;\n import java.util.Collection;\n import java.util.Collections;\n-import java.util.HashMap;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.function.Function;\n-import java.util.stream.Collectors;\n-\n-import java.util.ArrayList;\n-import java.util.Collection;\n-import java.util.Collections;\n-import java.util.HashMap;\n import java.util.Map;\n import java.util.concurrent.ConcurrentHashMap;\n import java.util.function.Function;\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE0MTAyNA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r547141024", "body": "uncertain TODO", "bodyText": "uncertain TODO", "bodyHTML": "<p dir=\"auto\">uncertain TODO</p>", "author": "korlov42", "createdAt": "2020-12-22T08:37:27Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java", "diffHunk": "@@ -197,6 +197,7 @@ public IgniteStatisticsRepositoryImpl(\n         store.clearLocalPartitionStatistics(key, partId);\n     }\n \n+    // TODO", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTAzMjY5Nw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555032697", "bodyText": "removed", "author": "Berkof", "createdAt": "2021-01-11T13:05:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE0MTAyNA=="}], "type": "inlineReview", "revised_code": {"commit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\nindex a5f0c0c7a9b..19931b08d25 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n", "chunk": "@@ -176,30 +147,17 @@ public class IgniteStatisticsRepositoryImpl implements IgniteStatisticsRepositor\n     }\n \n     /** {@inheritDoc} */\n-    @Override public ObjectPartitionStatisticsImpl getLocalPartitionStatistics(StatsKey key, int partId) {\n-        if (store == null) {\n-            log.warning(\"Unable to get local partition statistics for \" + key + \" on non server node.\");\n-\n-            return null;\n-        }\n-\n+    @Override public ObjectPartitionStatisticsImpl getLocalPartitionStatistics(StatisticsKey key, int partId) {\n         return store.getLocalPartitionStatistics(key, partId);\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearLocalPartitionStatistics(StatsKey key, int partId) {\n-        if (store == null) {\n-            log.warning(\"Unable to clear local partition statistics for \" + key + \" on non server node.\");\n-\n-            return;\n-        }\n-\n+    @Override public void clearLocalPartitionStatistics(StatisticsKey key, int partId) {\n         store.clearLocalPartitionStatistics(key, partId);\n     }\n \n-    // TODO\n     /** {@inheritDoc} */\n-    @Override public void saveLocalStatistics(StatsKey key, ObjectStatisticsImpl statistics) {\n+    @Override public void saveLocalStatistics(StatisticsKey key, ObjectStatisticsImpl statistics) {\n         if (locStats == null) {\n             log.warning(\"Unable to save local statistics for \" + key + \" on non server node.\");\n \n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE0MzAzMQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r547143031", "body": "empty line", "bodyText": "empty line", "bodyHTML": "<p dir=\"auto\">empty line</p>", "author": "korlov42", "createdAt": "2020-12-22T08:41:38Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java", "diffHunk": "@@ -0,0 +1,381 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.lang.GridFunc;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsRequestCollection {\n+    /** Current collections, collection id to collection status map. */\n+    private final Map<UUID, StatCollectionStatus> currColls = new ConcurrentHashMap<>();\n+\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsRequestCollection(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Add new statistics collection status.\n+     *\n+     * @param id Id to save status by.\n+     * @param status status to add.\n+     */\n+    public void addActiveCollectionStatus(UUID id, StatCollectionStatus status) {\n+        currColls.put(id, status);\n+    }\n+\n+    /**\n+     * Update status of statistics gathering task.\n+     *\n+     * @param id Statistics collection task id.\n+     * @param transformation Transformation to apply, if it returns {@code null} - status will be removed.\n+     */\n+    public void updateCollection(UUID id, Function<StatCollectionStatus, StatCollectionStatus> transformation) {\n+        currColls.compute(id, (k, v) -> transformation.apply(v));\n+    }\n+\n+    /**\n+     * Get collection status.\n+     *\n+     * @param id Id to get status by.\n+     * @return Collection status.\n+     */\n+    public StatCollectionStatus getCollection(UUID id) {\n+        return currColls.get(id);\n+    }\n+\n+", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nsimilarity index 56%\nrename from modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\nrename to modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 02fce6bdf6d..f0bc33ee4ba 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -60,41 +50,10 @@ public class IgniteStatisticsRequestCollection {\n      *\n      * @param schemaMgr Schema manager.\n      */\n-    public IgniteStatisticsRequestCollection(SchemaManager schemaMgr) {\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n         this.schemaMgr = schemaMgr;\n     }\n \n-    /**\n-     * Add new statistics collection status.\n-     *\n-     * @param id Id to save status by.\n-     * @param status status to add.\n-     */\n-    public void addActiveCollectionStatus(UUID id, StatCollectionStatus status) {\n-        currColls.put(id, status);\n-    }\n-\n-    /**\n-     * Update status of statistics gathering task.\n-     *\n-     * @param id Statistics collection task id.\n-     * @param transformation Transformation to apply, if it returns {@code null} - status will be removed.\n-     */\n-    public void updateCollection(UUID id, Function<StatCollectionStatus, StatCollectionStatus> transformation) {\n-        currColls.compute(id, (k, v) -> transformation.apply(v));\n-    }\n-\n-    /**\n-     * Get collection status.\n-     *\n-     * @param id Id to get status by.\n-     * @return Collection status.\n-     */\n-    public StatCollectionStatus getCollection(UUID id) {\n-        return currColls.get(id);\n-    }\n-\n-\n     /**\n      * Extract groups of stats keys.\n      *\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE0MzM5Mw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r547143393", "body": "closing tag is not needed, I suppose", "bodyText": "closing tag is not needed, I suppose", "bodyHTML": "<p dir=\"auto\">closing tag is not needed, I suppose</p>", "author": "korlov42", "createdAt": "2020-12-22T08:42:25Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java", "diffHunk": "@@ -0,0 +1,381 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.lang.GridFunc;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsRequestCollection {\n+    /** Current collections, collection id to collection status map. */\n+    private final Map<UUID, StatCollectionStatus> currColls = new ConcurrentHashMap<>();\n+\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsRequestCollection(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Add new statistics collection status.\n+     *\n+     * @param id Id to save status by.\n+     * @param status status to add.\n+     */\n+    public void addActiveCollectionStatus(UUID id, StatCollectionStatus status) {\n+        currColls.put(id, status);\n+    }\n+\n+    /**\n+     * Update status of statistics gathering task.\n+     *\n+     * @param id Statistics collection task id.\n+     * @param transformation Transformation to apply, if it returns {@code null} - status will be removed.\n+     */\n+    public void updateCollection(UUID id, Function<StatCollectionStatus, StatCollectionStatus> transformation) {\n+        currColls.compute(id, (k, v) -> transformation.apply(v));\n+    }\n+\n+    /**\n+     * Get collection status.\n+     *\n+     * @param id Id to get status by.\n+     * @return Collection status.\n+     */\n+    public StatCollectionStatus getCollection(UUID id) {\n+        return currColls.get(id);\n+    }\n+\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nsimilarity index 56%\nrename from modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\nrename to modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 02fce6bdf6d..f0bc33ee4ba 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -60,41 +50,10 @@ public class IgniteStatisticsRequestCollection {\n      *\n      * @param schemaMgr Schema manager.\n      */\n-    public IgniteStatisticsRequestCollection(SchemaManager schemaMgr) {\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n         this.schemaMgr = schemaMgr;\n     }\n \n-    /**\n-     * Add new statistics collection status.\n-     *\n-     * @param id Id to save status by.\n-     * @param status status to add.\n-     */\n-    public void addActiveCollectionStatus(UUID id, StatCollectionStatus status) {\n-        currColls.put(id, status);\n-    }\n-\n-    /**\n-     * Update status of statistics gathering task.\n-     *\n-     * @param id Statistics collection task id.\n-     * @param transformation Transformation to apply, if it returns {@code null} - status will be removed.\n-     */\n-    public void updateCollection(UUID id, Function<StatCollectionStatus, StatCollectionStatus> transformation) {\n-        currColls.compute(id, (k, v) -> transformation.apply(v));\n-    }\n-\n-    /**\n-     * Get collection status.\n-     *\n-     * @param id Id to get status by.\n-     * @return Collection status.\n-     */\n-    public StatCollectionStatus getCollection(UUID id) {\n-        return currColls.get(id);\n-    }\n-\n-\n     /**\n      * Extract groups of stats keys.\n      *\n", "next_change": null}, {"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nsimilarity index 56%\nrename from modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\nrename to modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 02fce6bdf6d..f0bc33ee4ba 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -102,10 +61,10 @@ public class IgniteStatisticsRequestCollection {\n      * @return Map of <group ids></group> to <collection of keys in groups>\n      * @throws IgniteCheckedException In case of lack some of specified objects.\n      */\n-    protected Map<CacheGroupContext, Collection<StatsKeyMessage>> extractGroups(Collection<StatsKeyMessage> keys)\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n             throws IgniteCheckedException {\n-        Map<CacheGroupContext, Collection<StatsKeyMessage>> res = new HashMap<>(keys.size());\n-        for (StatsKeyMessage key : keys) {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n             GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n             if (tbl == null)\n                 throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE2MTQxOQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r547161419", "body": "comment in Russian ", "bodyText": "comment in Russian", "bodyHTML": "<p dir=\"auto\">comment in Russian</p>", "author": "korlov42", "createdAt": "2020-12-22T09:18:54Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java", "diffHunk": "@@ -0,0 +1,381 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.lang.GridFunc;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsRequestCollection {\n+    /** Current collections, collection id to collection status map. */\n+    private final Map<UUID, StatCollectionStatus> currColls = new ConcurrentHashMap<>();\n+\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsRequestCollection(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Add new statistics collection status.\n+     *\n+     * @param id Id to save status by.\n+     * @param status status to add.\n+     */\n+    public void addActiveCollectionStatus(UUID id, StatCollectionStatus status) {\n+        currColls.put(id, status);\n+    }\n+\n+    /**\n+     * Update status of statistics gathering task.\n+     *\n+     * @param id Statistics collection task id.\n+     * @param transformation Transformation to apply, if it returns {@code null} - status will be removed.\n+     */\n+    public void updateCollection(UUID id, Function<StatCollectionStatus, StatCollectionStatus> transformation) {\n+        currColls.compute(id, (k, v) -> transformation.apply(v));\n+    }\n+\n+    /**\n+     * Get collection status.\n+     *\n+     * @param id Id to get status by.\n+     * @return Collection status.\n+     */\n+    public StatCollectionStatus getCollection(UUID id) {\n+        return currColls.get(id);\n+    }\n+\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatsKeyMessage>> extractGroups(Collection<StatsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds)\n+            throws IgniteCheckedException {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTAzODM3Nw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555038377", "bodyText": "fired", "author": "Berkof", "createdAt": "2021-01-11T13:16:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE2MTQxOQ=="}], "type": "inlineReview", "revised_code": {"commit": "b595e90b5b480aaf80a9256558b1841334df97de", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\nindex 02fce6bdf6d..acb7c1d527e 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\n", "chunk": "@@ -129,8 +124,7 @@ public class IgniteStatisticsRequestCollection {\n      * @param partIds Partition to collect information by\n      * @return Map nodeId to array of partitions, related to node.\n      */\n-    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds)\n-            throws IgniteCheckedException {\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n         AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n         // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n         List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n", "next_change": {"commit": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\ndeleted file mode 100644\nindex acb7c1d527e..00000000000\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\n+++ /dev/null\n", "chunk": "@@ -1,366 +0,0 @@\n-/*\n- * Copyright 2020 GridGain Systems, Inc. and Contributors.\n- *\n- * Licensed under the GridGain Community Edition License (the \"License\");\n- * you may not use this file except in compliance with the License.\n- * You may obtain a copy of the License at\n- *\n- *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.ignite.internal.processors.query.stat;\n-\n-import org.apache.ignite.IgniteCheckedException;\n-import org.apache.ignite.cluster.ClusterNode;\n-import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n-import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n-import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n-import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n-import org.apache.ignite.internal.processors.query.stat.messages.StatsClearRequest;\n-import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n-import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n-import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n-import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n-import org.apache.ignite.internal.util.GridArrays;\n-import org.apache.ignite.internal.util.typedef.F;\n-\n-import java.util.ArrayList;\n-import java.util.Collection;\n-import java.util.HashMap;\n-import java.util.HashSet;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.UUID;\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.function.Function;\n-import java.util.stream.Collectors;\n-\n-/**\n- * Current statistics collections with methods to work with it's messages.\n- */\n-public class IgniteStatisticsRequestCollection {\n-    /** Current collections, collection id to collection status map. */\n-    private final Map<UUID, StatCollectionStatus> currColls = new ConcurrentHashMap<>();\n-\n-    /** Schema manager. */\n-    private final SchemaManager schemaMgr;\n-\n-    /**\n-     * Constructor.\n-     *\n-     * @param schemaMgr Schema manager.\n-     */\n-    public IgniteStatisticsRequestCollection(SchemaManager schemaMgr) {\n-        this.schemaMgr = schemaMgr;\n-    }\n-\n-    /**\n-     * Add new statistics collection status.\n-     *\n-     * @param id Id to save status by.\n-     * @param status status to add.\n-     */\n-    public void addActiveCollectionStatus(UUID id, StatCollectionStatus status) {\n-        currColls.put(id, status);\n-    }\n-\n-    /**\n-     * Update status of statistics gathering task.\n-     *\n-     * @param id Statistics collection task id.\n-     * @param transformation Transformation to apply, if it returns {@code null} - status will be removed.\n-     */\n-    public void updateCollection(UUID id, Function<StatCollectionStatus, StatCollectionStatus> transformation) {\n-        currColls.compute(id, (k, v) -> transformation.apply(v));\n-    }\n-\n-    /**\n-     * Get collection status.\n-     *\n-     * @param id Id to get status by.\n-     * @return Collection status.\n-     */\n-    public StatCollectionStatus getCollection(UUID id) {\n-        return currColls.get(id);\n-    }\n-\n-\n-    /**\n-     * Extract groups of stats keys.\n-     *\n-     * @param keys Statistics key to extract groups from.\n-     * @return Map of <group ids></group> to <collection of keys in groups>\n-     * @throws IgniteCheckedException In case of lack some of specified objects.\n-     */\n-    protected Map<CacheGroupContext, Collection<StatsKeyMessage>> extractGroups(Collection<StatsKeyMessage> keys)\n-            throws IgniteCheckedException {\n-        Map<CacheGroupContext, Collection<StatsKeyMessage>> res = new HashMap<>(keys.size());\n-        for (StatsKeyMessage key : keys) {\n-            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n-            if (tbl == null)\n-                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n-\n-            res.compute(tbl.cacheContext().group(), (k, v) -> {\n-                if (v == null)\n-                    v = new ArrayList<>();\n-\n-                v.add(key);\n-\n-                return v;\n-            });\n-        }\n-        return res;\n-    }\n-\n-    /**\n-     * Get map cluster node to it's partitions for the specified cache group.\n-     *\n-     * @param grp Cache group context to get partition information by.\n-     * @param partIds Partition to collect information by\n-     * @return Map nodeId to array of partitions, related to node.\n-     */\n-    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n-        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n-        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n-        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n-\n-        Map<UUID, List<Integer>> res = new HashMap<>();\n-        if (partIds == null)\n-            for (int i = 0; i < assignments.size(); i++)\n-                fillPartitionMaster(res, assignments, i);\n-        else\n-            for (Integer partId : partIds)\n-                fillPartitionMaster(res, assignments, partId);\n-\n-        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n-                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n-    }\n-\n-    /**\n-     * Fill map with master node of specified partition.\n-     *\n-     * @param res Map to fill.\n-     * @param assignments Partitions assignments.\n-     * @param partId Partition to process.\n-     */\n-    protected static  void fillPartitionMaster(\n-        Map<UUID, List<Integer>> res,\n-        List<List<ClusterNode>> assignments,\n-        int partId\n-    ) {\n-        assert partId < assignments.size();\n-        List<ClusterNode> partNodes = assignments.get(partId);\n-        if (F.isEmpty(partNodes))\n-            return;\n-\n-        res.compute(partNodes.get(0).id(), (k, v) -> {\n-            if (v == null)\n-                v = new ArrayList<>();\n-\n-            v.add(partId);\n-\n-            return v;\n-        });\n-    }\n-\n-    /**\n-     * Prepare statistics collection request for specified node.\n-     *\n-     * @param colId Collection id.\n-     * @param data Keys to partitions for current node.\n-     * @return Statistics collection request.\n-     */\n-    public static StatsCollectionRequest prepareRequest(UUID colId, Map<StatsKeyMessage, int[]> data) {\n-        UUID reqId = UUID.randomUUID();\n-        return new StatsCollectionRequest(colId, reqId, data);\n-    }\n-\n-    // TODO add extraction of necessary partIds by statKeyMsg\n-\n-    /**\n-     * Generate statistics collection requests by given keys.\n-     *\n-     * @param colId Collection id.\n-     * @param keys Collection of keys to collect statistics by.\n-     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n-     *            If {@code null} - requests will be\n-     * @return Collection of statistics collection addressed request.\n-     * @throws IgniteCheckedException In case of errors.\n-     */\n-    public static Collection<StatsAddrRequest<StatsCollectionRequest>> generateCollectionRequests(\n-        UUID colId,\n-        Collection<StatsKeyMessage> keys,\n-        Map<StatsKeyMessage, int[]> failedPartitions,\n-        Map<CacheGroupContext, Collection<StatsKeyMessage>> grpContexts\n-    ) {\n-\n-        // NodeId to <Key to partitions on node> map\n-        Map<UUID, Map<StatsKeyMessage, int[]>> reqMap = new HashMap<>();\n-        for (Map.Entry<CacheGroupContext, Collection<StatsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n-            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null); // TODO Null?\n-            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n-                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n-                    if (v == null)\n-                        v = new HashMap<>();\n-\n-                    Collection<StatsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n-\n-                    for (StatsKeyMessage key : grpKeys) {\n-                        int[] keyNodeParts = (failedPartitions == null) ? nodeParts.getValue() :\n-                                GridArrays.intersect(nodeParts.getValue(), failedPartitions.get(key));\n-\n-                        if (keyNodeParts.length > 0)\n-                            v.put(key, keyNodeParts);\n-                    }\n-\n-                    return v.isEmpty() ? null : v;\n-                });\n-        }\n-\n-        Collection<StatsAddrRequest<StatsCollectionRequest>> reqs = new ArrayList<>();\n-        for (Map.Entry<UUID, Map<StatsKeyMessage, int[]>> nodeGpsParts: reqMap.entrySet()) {\n-            if (nodeGpsParts.getValue().isEmpty())\n-                continue;\n-\n-            StatsCollectionRequest req = prepareRequest(colId, nodeGpsParts.getValue());\n-            reqs.add(new StatsAddrRequest<>(req, nodeGpsParts.getKey()));\n-        }\n-\n-        return reqs;\n-    }\n-\n-    /**\n-     * Get all nodes where specified cache grous located.\n-     *\n-     * @param grps Cache groups.\n-     * @return Set of node ids.\n-     */\n-    public static Map<UUID, Collection<StatsKeyMessage>> nodeKeys(Map<CacheGroupContext, Collection<StatsKeyMessage>> grps) {\n-        Map<UUID, Collection<StatsKeyMessage>> res = new HashMap<>();\n-\n-        for (Map.Entry<CacheGroupContext, Collection<StatsKeyMessage>> grpKeys : grps.entrySet()) {\n-            CacheGroupContext grp = grpKeys.getKey();\n-            AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n-            List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n-\n-            assignments.forEach(nodes -> nodes.forEach(clusterNode -> res.compute(clusterNode.id(), (k, v) -> {\n-                if (v == null)\n-                    v = new HashSet<>();\n-\n-                v.addAll(grpKeys.getValue());\n-\n-                return v;\n-            })));\n-        }\n-        return res;\n-    }\n-\n-    /**\n-     * Generate statistics clear requests.\n-     *\n-     * @param keys Keys to clean statistics by.\n-     * @return Collection of addressed statistics clear requests.\n-     * @throws IgniteCheckedException In case of errors.\n-     */\n-    public Collection<StatsAddrRequest<StatsClearRequest>> generateClearRequests(\n-        Collection<StatsKeyMessage> keys\n-    ) throws IgniteCheckedException {\n-        Map<CacheGroupContext, Collection<StatsKeyMessage>> grpContexts = extractGroups(keys);\n-        Map<UUID, Collection<StatsKeyMessage>> nodeKeys = nodeKeys(grpContexts);\n-\n-        return nodeKeys.entrySet().stream().map(node -> new StatsAddrRequest<>(\n-            new StatsClearRequest(UUID.randomUUID(), new ArrayList<>(node.getValue())), node.getKey()))\n-                .collect(Collectors.toList());\n-    }\n-\n-\n-    /**\n-     * Generate statistics collection requests by given keys.\n-     *\n-     * @param colId Collection id.\n-     * @param keys Collection of keys to collect statistics by.\n-     * @return Collection of statistics collection addressed request.\n-     * @throws IgniteCheckedException In case of errors.\n-     */\n-    protected Collection<StatsAddrRequest<StatsCollectionRequest>> generateCollectionRequests(\n-        UUID colId,\n-        Collection<StatsKeyMessage> keys,\n-        Map<StatsKeyMessage, int[]> failedPartitions\n-    ) throws IgniteCheckedException {\n-        Map<CacheGroupContext, Collection<StatsKeyMessage>> grpContexts = extractGroups(keys);\n-\n-        return generateCollectionRequests(colId, keys, failedPartitions, grpContexts);\n-    }\n-\n-    /**\n-     * Extract all partitions from specified statistics collection requests.\n-     *\n-     * @param reqs Failed request to extract partitions from.\n-     * @return Map StatisticsKeyMessage to List of corresponding partitions.\n-     */\n-    public static Map<StatsKeyMessage, int[]> extractFailed(StatsCollectionRequest[] reqs) {\n-        Map<StatsKeyMessage, List<Integer>> res = new HashMap<>();\n-\n-        UUID colId = null;\n-        for (StatsCollectionRequest req : reqs) {\n-\n-            assert colId == null || colId.equals(req.colId());\n-            colId = req.colId();\n-\n-            for (Map.Entry<StatsKeyMessage, int[]> keyEntry : req.keys().entrySet()) {\n-                res.compute(keyEntry.getKey(), (k, v) -> {\n-                    if (v == null)\n-                        v = new ArrayList<>();\n-\n-                    for (int i = 0; i < keyEntry.getValue().length; i++)\n-                        v.add(keyEntry.getValue()[i]);\n-\n-                    return v;\n-                });\n-            }\n-        }\n-\n-        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n-                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n-    }\n-\n-    /**\n-     * Get failed partitions map from request and its response.\n-     *\n-     * @param req Request to get the original requested partitions from.\n-     * @param resp Response to get actually collected partitions.\n-     * @return Map of not collected partitions.\n-     */\n-    public static Map<StatsKeyMessage, int[]> extractFailed(StatsCollectionRequest req, StatsCollectionResponse resp) {\n-        assert req.colId().equals(resp.colId());\n-\n-        Map<StatsKeyMessage, int[]> collected = new HashMap<>(resp.data().size());\n-        for (Map.Entry<StatsObjectData, int[]> data : resp.data().entrySet())\n-            collected.put(data.getKey().key(), data.getValue());\n-\n-        Map<StatsKeyMessage, int[]> res = new HashMap<>();\n-        for (Map.Entry<StatsKeyMessage, int[]> keyEntry : req.keys().entrySet()) {\n-            int[] failed = GridArrays.subtract(keyEntry.getValue(), collected.get(keyEntry.getKey()));\n-\n-            if (failed.length > 0)\n-                res.put(keyEntry.getKey(), failed);\n-        }\n-        return res;\n-    }\n-\n-    /**\n-     * Apply specified transformation to each active statistics collection status.\n-     *\n-     * @param transformation Transformation to apply.\n-     */\n-    public void updateAllCollections(Function<StatCollectionStatus, StatCollectionStatus> transformation) {\n-        currColls.keySet().forEach(k -> {\n-            currColls.computeIfPresent(k, (k1, v) -> transformation.apply(v)); // TODO sync?\n-        });\n-    }\n-}\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE2NDIyNA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r547164224", "body": "this could be simplified by generating partition ids from assignments\r\n", "bodyText": "this could be simplified by generating partition ids from assignments", "bodyHTML": "<p dir=\"auto\">this could be simplified by generating partition ids from assignments</p>", "author": "korlov42", "createdAt": "2020-12-22T09:24:31Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java", "diffHunk": "@@ -0,0 +1,381 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.lang.GridFunc;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsRequestCollection {\n+    /** Current collections, collection id to collection status map. */\n+    private final Map<UUID, StatCollectionStatus> currColls = new ConcurrentHashMap<>();\n+\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsRequestCollection(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Add new statistics collection status.\n+     *\n+     * @param id Id to save status by.\n+     * @param status status to add.\n+     */\n+    public void addActiveCollectionStatus(UUID id, StatCollectionStatus status) {\n+        currColls.put(id, status);\n+    }\n+\n+    /**\n+     * Update status of statistics gathering task.\n+     *\n+     * @param id Statistics collection task id.\n+     * @param transformation Transformation to apply, if it returns {@code null} - status will be removed.\n+     */\n+    public void updateCollection(UUID id, Function<StatCollectionStatus, StatCollectionStatus> transformation) {\n+        currColls.compute(id, (k, v) -> transformation.apply(v));\n+    }\n+\n+    /**\n+     * Get collection status.\n+     *\n+     * @param id Id to get status by.\n+     * @return Collection status.\n+     */\n+    public StatCollectionStatus getCollection(UUID id) {\n+        return currColls.get(id);\n+    }\n+\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatsKeyMessage>> extractGroups(Collection<StatsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds)\n+            throws IgniteCheckedException {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjMwMjMzMg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556302332", "bodyText": "Sometimes we need primary, sometimes - backups, sometimes - only mapping for some specied partitions... now this code located in IgniteStatisticsHelper.nodePartitions. How I can simplify it?", "author": "Berkof", "createdAt": "2021-01-13T07:06:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE2NDIyNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjMxMzc0Mg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556313742", "bodyText": "for example like this:\n`\n    if (partIds == null)\n        partIds = IntStream.range(0, assignments.size()).boxed().collect(Collectors.toList());\n\n    for (Integer partId : partIds)\n        fillPartition(res, assignments, partId, isPrimary);`", "author": "korlov42", "createdAt": "2021-01-13T07:33:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE2NDIyNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzQwMjY3MQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r557402671", "bodyText": "fixed", "author": "Berkof", "createdAt": "2021-01-14T13:42:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE2NDIyNA=="}], "type": "inlineReview", "revised_code": {"commit": "b595e90b5b480aaf80a9256558b1841334df97de", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\nindex 02fce6bdf6d..acb7c1d527e 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\n", "chunk": "@@ -129,8 +124,7 @@ public class IgniteStatisticsRequestCollection {\n      * @param partIds Partition to collect information by\n      * @return Map nodeId to array of partitions, related to node.\n      */\n-    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds)\n-            throws IgniteCheckedException {\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n         AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n         // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n         List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n", "next_change": {"commit": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\ndeleted file mode 100644\nindex acb7c1d527e..00000000000\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\n+++ /dev/null\n", "chunk": "@@ -1,366 +0,0 @@\n-/*\n- * Copyright 2020 GridGain Systems, Inc. and Contributors.\n- *\n- * Licensed under the GridGain Community Edition License (the \"License\");\n- * you may not use this file except in compliance with the License.\n- * You may obtain a copy of the License at\n- *\n- *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.ignite.internal.processors.query.stat;\n-\n-import org.apache.ignite.IgniteCheckedException;\n-import org.apache.ignite.cluster.ClusterNode;\n-import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n-import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n-import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n-import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n-import org.apache.ignite.internal.processors.query.stat.messages.StatsClearRequest;\n-import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n-import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n-import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n-import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n-import org.apache.ignite.internal.util.GridArrays;\n-import org.apache.ignite.internal.util.typedef.F;\n-\n-import java.util.ArrayList;\n-import java.util.Collection;\n-import java.util.HashMap;\n-import java.util.HashSet;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.UUID;\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.function.Function;\n-import java.util.stream.Collectors;\n-\n-/**\n- * Current statistics collections with methods to work with it's messages.\n- */\n-public class IgniteStatisticsRequestCollection {\n-    /** Current collections, collection id to collection status map. */\n-    private final Map<UUID, StatCollectionStatus> currColls = new ConcurrentHashMap<>();\n-\n-    /** Schema manager. */\n-    private final SchemaManager schemaMgr;\n-\n-    /**\n-     * Constructor.\n-     *\n-     * @param schemaMgr Schema manager.\n-     */\n-    public IgniteStatisticsRequestCollection(SchemaManager schemaMgr) {\n-        this.schemaMgr = schemaMgr;\n-    }\n-\n-    /**\n-     * Add new statistics collection status.\n-     *\n-     * @param id Id to save status by.\n-     * @param status status to add.\n-     */\n-    public void addActiveCollectionStatus(UUID id, StatCollectionStatus status) {\n-        currColls.put(id, status);\n-    }\n-\n-    /**\n-     * Update status of statistics gathering task.\n-     *\n-     * @param id Statistics collection task id.\n-     * @param transformation Transformation to apply, if it returns {@code null} - status will be removed.\n-     */\n-    public void updateCollection(UUID id, Function<StatCollectionStatus, StatCollectionStatus> transformation) {\n-        currColls.compute(id, (k, v) -> transformation.apply(v));\n-    }\n-\n-    /**\n-     * Get collection status.\n-     *\n-     * @param id Id to get status by.\n-     * @return Collection status.\n-     */\n-    public StatCollectionStatus getCollection(UUID id) {\n-        return currColls.get(id);\n-    }\n-\n-\n-    /**\n-     * Extract groups of stats keys.\n-     *\n-     * @param keys Statistics key to extract groups from.\n-     * @return Map of <group ids></group> to <collection of keys in groups>\n-     * @throws IgniteCheckedException In case of lack some of specified objects.\n-     */\n-    protected Map<CacheGroupContext, Collection<StatsKeyMessage>> extractGroups(Collection<StatsKeyMessage> keys)\n-            throws IgniteCheckedException {\n-        Map<CacheGroupContext, Collection<StatsKeyMessage>> res = new HashMap<>(keys.size());\n-        for (StatsKeyMessage key : keys) {\n-            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n-            if (tbl == null)\n-                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n-\n-            res.compute(tbl.cacheContext().group(), (k, v) -> {\n-                if (v == null)\n-                    v = new ArrayList<>();\n-\n-                v.add(key);\n-\n-                return v;\n-            });\n-        }\n-        return res;\n-    }\n-\n-    /**\n-     * Get map cluster node to it's partitions for the specified cache group.\n-     *\n-     * @param grp Cache group context to get partition information by.\n-     * @param partIds Partition to collect information by\n-     * @return Map nodeId to array of partitions, related to node.\n-     */\n-    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n-        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n-        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n-        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n-\n-        Map<UUID, List<Integer>> res = new HashMap<>();\n-        if (partIds == null)\n-            for (int i = 0; i < assignments.size(); i++)\n-                fillPartitionMaster(res, assignments, i);\n-        else\n-            for (Integer partId : partIds)\n-                fillPartitionMaster(res, assignments, partId);\n-\n-        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n-                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n-    }\n-\n-    /**\n-     * Fill map with master node of specified partition.\n-     *\n-     * @param res Map to fill.\n-     * @param assignments Partitions assignments.\n-     * @param partId Partition to process.\n-     */\n-    protected static  void fillPartitionMaster(\n-        Map<UUID, List<Integer>> res,\n-        List<List<ClusterNode>> assignments,\n-        int partId\n-    ) {\n-        assert partId < assignments.size();\n-        List<ClusterNode> partNodes = assignments.get(partId);\n-        if (F.isEmpty(partNodes))\n-            return;\n-\n-        res.compute(partNodes.get(0).id(), (k, v) -> {\n-            if (v == null)\n-                v = new ArrayList<>();\n-\n-            v.add(partId);\n-\n-            return v;\n-        });\n-    }\n-\n-    /**\n-     * Prepare statistics collection request for specified node.\n-     *\n-     * @param colId Collection id.\n-     * @param data Keys to partitions for current node.\n-     * @return Statistics collection request.\n-     */\n-    public static StatsCollectionRequest prepareRequest(UUID colId, Map<StatsKeyMessage, int[]> data) {\n-        UUID reqId = UUID.randomUUID();\n-        return new StatsCollectionRequest(colId, reqId, data);\n-    }\n-\n-    // TODO add extraction of necessary partIds by statKeyMsg\n-\n-    /**\n-     * Generate statistics collection requests by given keys.\n-     *\n-     * @param colId Collection id.\n-     * @param keys Collection of keys to collect statistics by.\n-     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n-     *            If {@code null} - requests will be\n-     * @return Collection of statistics collection addressed request.\n-     * @throws IgniteCheckedException In case of errors.\n-     */\n-    public static Collection<StatsAddrRequest<StatsCollectionRequest>> generateCollectionRequests(\n-        UUID colId,\n-        Collection<StatsKeyMessage> keys,\n-        Map<StatsKeyMessage, int[]> failedPartitions,\n-        Map<CacheGroupContext, Collection<StatsKeyMessage>> grpContexts\n-    ) {\n-\n-        // NodeId to <Key to partitions on node> map\n-        Map<UUID, Map<StatsKeyMessage, int[]>> reqMap = new HashMap<>();\n-        for (Map.Entry<CacheGroupContext, Collection<StatsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n-            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null); // TODO Null?\n-            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n-                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n-                    if (v == null)\n-                        v = new HashMap<>();\n-\n-                    Collection<StatsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n-\n-                    for (StatsKeyMessage key : grpKeys) {\n-                        int[] keyNodeParts = (failedPartitions == null) ? nodeParts.getValue() :\n-                                GridArrays.intersect(nodeParts.getValue(), failedPartitions.get(key));\n-\n-                        if (keyNodeParts.length > 0)\n-                            v.put(key, keyNodeParts);\n-                    }\n-\n-                    return v.isEmpty() ? null : v;\n-                });\n-        }\n-\n-        Collection<StatsAddrRequest<StatsCollectionRequest>> reqs = new ArrayList<>();\n-        for (Map.Entry<UUID, Map<StatsKeyMessage, int[]>> nodeGpsParts: reqMap.entrySet()) {\n-            if (nodeGpsParts.getValue().isEmpty())\n-                continue;\n-\n-            StatsCollectionRequest req = prepareRequest(colId, nodeGpsParts.getValue());\n-            reqs.add(new StatsAddrRequest<>(req, nodeGpsParts.getKey()));\n-        }\n-\n-        return reqs;\n-    }\n-\n-    /**\n-     * Get all nodes where specified cache grous located.\n-     *\n-     * @param grps Cache groups.\n-     * @return Set of node ids.\n-     */\n-    public static Map<UUID, Collection<StatsKeyMessage>> nodeKeys(Map<CacheGroupContext, Collection<StatsKeyMessage>> grps) {\n-        Map<UUID, Collection<StatsKeyMessage>> res = new HashMap<>();\n-\n-        for (Map.Entry<CacheGroupContext, Collection<StatsKeyMessage>> grpKeys : grps.entrySet()) {\n-            CacheGroupContext grp = grpKeys.getKey();\n-            AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n-            List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n-\n-            assignments.forEach(nodes -> nodes.forEach(clusterNode -> res.compute(clusterNode.id(), (k, v) -> {\n-                if (v == null)\n-                    v = new HashSet<>();\n-\n-                v.addAll(grpKeys.getValue());\n-\n-                return v;\n-            })));\n-        }\n-        return res;\n-    }\n-\n-    /**\n-     * Generate statistics clear requests.\n-     *\n-     * @param keys Keys to clean statistics by.\n-     * @return Collection of addressed statistics clear requests.\n-     * @throws IgniteCheckedException In case of errors.\n-     */\n-    public Collection<StatsAddrRequest<StatsClearRequest>> generateClearRequests(\n-        Collection<StatsKeyMessage> keys\n-    ) throws IgniteCheckedException {\n-        Map<CacheGroupContext, Collection<StatsKeyMessage>> grpContexts = extractGroups(keys);\n-        Map<UUID, Collection<StatsKeyMessage>> nodeKeys = nodeKeys(grpContexts);\n-\n-        return nodeKeys.entrySet().stream().map(node -> new StatsAddrRequest<>(\n-            new StatsClearRequest(UUID.randomUUID(), new ArrayList<>(node.getValue())), node.getKey()))\n-                .collect(Collectors.toList());\n-    }\n-\n-\n-    /**\n-     * Generate statistics collection requests by given keys.\n-     *\n-     * @param colId Collection id.\n-     * @param keys Collection of keys to collect statistics by.\n-     * @return Collection of statistics collection addressed request.\n-     * @throws IgniteCheckedException In case of errors.\n-     */\n-    protected Collection<StatsAddrRequest<StatsCollectionRequest>> generateCollectionRequests(\n-        UUID colId,\n-        Collection<StatsKeyMessage> keys,\n-        Map<StatsKeyMessage, int[]> failedPartitions\n-    ) throws IgniteCheckedException {\n-        Map<CacheGroupContext, Collection<StatsKeyMessage>> grpContexts = extractGroups(keys);\n-\n-        return generateCollectionRequests(colId, keys, failedPartitions, grpContexts);\n-    }\n-\n-    /**\n-     * Extract all partitions from specified statistics collection requests.\n-     *\n-     * @param reqs Failed request to extract partitions from.\n-     * @return Map StatisticsKeyMessage to List of corresponding partitions.\n-     */\n-    public static Map<StatsKeyMessage, int[]> extractFailed(StatsCollectionRequest[] reqs) {\n-        Map<StatsKeyMessage, List<Integer>> res = new HashMap<>();\n-\n-        UUID colId = null;\n-        for (StatsCollectionRequest req : reqs) {\n-\n-            assert colId == null || colId.equals(req.colId());\n-            colId = req.colId();\n-\n-            for (Map.Entry<StatsKeyMessage, int[]> keyEntry : req.keys().entrySet()) {\n-                res.compute(keyEntry.getKey(), (k, v) -> {\n-                    if (v == null)\n-                        v = new ArrayList<>();\n-\n-                    for (int i = 0; i < keyEntry.getValue().length; i++)\n-                        v.add(keyEntry.getValue()[i]);\n-\n-                    return v;\n-                });\n-            }\n-        }\n-\n-        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n-                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n-    }\n-\n-    /**\n-     * Get failed partitions map from request and its response.\n-     *\n-     * @param req Request to get the original requested partitions from.\n-     * @param resp Response to get actually collected partitions.\n-     * @return Map of not collected partitions.\n-     */\n-    public static Map<StatsKeyMessage, int[]> extractFailed(StatsCollectionRequest req, StatsCollectionResponse resp) {\n-        assert req.colId().equals(resp.colId());\n-\n-        Map<StatsKeyMessage, int[]> collected = new HashMap<>(resp.data().size());\n-        for (Map.Entry<StatsObjectData, int[]> data : resp.data().entrySet())\n-            collected.put(data.getKey().key(), data.getValue());\n-\n-        Map<StatsKeyMessage, int[]> res = new HashMap<>();\n-        for (Map.Entry<StatsKeyMessage, int[]> keyEntry : req.keys().entrySet()) {\n-            int[] failed = GridArrays.subtract(keyEntry.getValue(), collected.get(keyEntry.getKey()));\n-\n-            if (failed.length > 0)\n-                res.put(keyEntry.getKey(), failed);\n-        }\n-        return res;\n-    }\n-\n-    /**\n-     * Apply specified transformation to each active statistics collection status.\n-     *\n-     * @param transformation Transformation to apply.\n-     */\n-    public void updateAllCollections(Function<StatCollectionStatus, StatCollectionStatus> transformation) {\n-        currColls.keySet().forEach(k -> {\n-            currColls.computeIfPresent(k, (k1, v) -> transformation.apply(v)); // TODO sync?\n-        });\n-    }\n-}\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzE2NDcwMA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r547164700", "body": "commented code", "bodyText": "commented code", "bodyHTML": "<p dir=\"auto\">commented code</p>", "author": "korlov42", "createdAt": "2020-12-22T09:25:25Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java", "diffHunk": "@@ -0,0 +1,381 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsCollectionResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.lang.GridFunc;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.locks.ReentrantReadWriteLock;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsRequestCollection {\n+    /** Current collections, collection id to collection status map. */\n+    private final Map<UUID, StatCollectionStatus> currColls = new ConcurrentHashMap<>();\n+\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsRequestCollection(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Add new statistics collection status.\n+     *\n+     * @param id Id to save status by.\n+     * @param status status to add.\n+     */\n+    public void addActiveCollectionStatus(UUID id, StatCollectionStatus status) {\n+        currColls.put(id, status);\n+    }\n+\n+    /**\n+     * Update status of statistics gathering task.\n+     *\n+     * @param id Statistics collection task id.\n+     * @param transformation Transformation to apply, if it returns {@code null} - status will be removed.\n+     */\n+    public void updateCollection(UUID id, Function<StatCollectionStatus, StatCollectionStatus> transformation) {\n+        currColls.compute(id, (k, v) -> transformation.apply(v));\n+    }\n+\n+    /**\n+     * Get collection status.\n+     *\n+     * @param id Id to get status by.\n+     * @return Collection status.\n+     */\n+    public StatCollectionStatus getCollection(UUID id) {\n+        return currColls.get(id);\n+    }\n+\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatsKeyMessage>> extractGroups(Collection<StatsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds)\n+            throws IgniteCheckedException {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<Integer>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatsCollectionRequest prepareRequest(UUID colId, Map<StatsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatsCollectionRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n+     *            If {@code null} - requests will be\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public static Collection<StatsAddrRequest<StatsCollectionRequest>> generateCollectionRequests(\n+            UUID colId,\n+            Collection<StatsKeyMessage> keys,\n+            Map<StatsKeyMessage, int[]> failedPartitions,\n+            Map<CacheGroupContext, Collection<StatsKeyMessage>> grpContexts\n+    ) throws IgniteCheckedException {\n+        /*Map<StatsKeyMessage, CacheGroupContext> keyGroups = new HashMap<>();", "originalCommit": "671a2471ef7d2a50a01f45f09289202a9528221d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "b595e90b5b480aaf80a9256558b1841334df97de", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\nindex 02fce6bdf6d..acb7c1d527e 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\n", "chunk": "@@ -199,16 +193,12 @@ public class IgniteStatisticsRequestCollection {\n      * @throws IgniteCheckedException In case of errors.\n      */\n     public static Collection<StatsAddrRequest<StatsCollectionRequest>> generateCollectionRequests(\n-            UUID colId,\n-            Collection<StatsKeyMessage> keys,\n-            Map<StatsKeyMessage, int[]> failedPartitions,\n-            Map<CacheGroupContext, Collection<StatsKeyMessage>> grpContexts\n-    ) throws IgniteCheckedException {\n-        /*Map<StatsKeyMessage, CacheGroupContext> keyGroups = new HashMap<>();\n-        for (Map.Entry<CacheGroupContext, Collection<StatsKeyMessage>> grpKeys : grpContexts.entrySet())\n-            for(StatsKeyMessage key : grpKeys.getValue())\n-                keyGroups.put(key, grpKeys.getKey());\n-*/\n+        UUID colId,\n+        Collection<StatsKeyMessage> keys,\n+        Map<StatsKeyMessage, int[]> failedPartitions,\n+        Map<CacheGroupContext, Collection<StatsKeyMessage>> grpContexts\n+    ) {\n+\n         // NodeId to <Key to partitions on node> map\n         Map<UUID, Map<StatsKeyMessage, int[]>> reqMap = new HashMap<>();\n         for (Map.Entry<CacheGroupContext, Collection<StatsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n", "next_change": {"commit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nsimilarity index 64%\nrename from modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\nrename to modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex acb7c1d527e..f0bc33ee4ba 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRequestCollection.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -192,25 +156,25 @@ public class IgniteStatisticsRequestCollection {\n      * @return Collection of statistics collection addressed request.\n      * @throws IgniteCheckedException In case of errors.\n      */\n-    public static Collection<StatsAddrRequest<StatsCollectionRequest>> generateCollectionRequests(\n+    public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n         UUID colId,\n-        Collection<StatsKeyMessage> keys,\n-        Map<StatsKeyMessage, int[]> failedPartitions,\n-        Map<CacheGroupContext, Collection<StatsKeyMessage>> grpContexts\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions,\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts\n     ) {\n \n         // NodeId to <Key to partitions on node> map\n-        Map<UUID, Map<StatsKeyMessage, int[]>> reqMap = new HashMap<>();\n-        for (Map.Entry<CacheGroupContext, Collection<StatsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n+        Map<UUID, Map<StatisticsKeyMessage, int[]>> reqMap = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n             Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null); // TODO Null?\n             for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n                 reqMap.compute(nodeParts.getKey(), (k, v) -> {\n                     if (v == null)\n                         v = new HashMap<>();\n \n-                    Collection<StatsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n+                    Collection<StatisticsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n \n-                    for (StatsKeyMessage key : grpKeys) {\n+                    for (StatisticsKeyMessage key : grpKeys) {\n                         int[] keyNodeParts = (failedPartitions == null) ? nodeParts.getValue() :\n                                 GridArrays.intersect(nodeParts.getValue(), failedPartitions.get(key));\n \n", "next_change": null}]}}]}}, {"oid": "b595e90b5b480aaf80a9256558b1841334df97de", "url": "https://github.com/gridgain/gridgain/commit/b595e90b5b480aaf80a9256558b1841334df97de", "message": "GG-31094: fix message processing, some new tests, batch cleaning", "committedDate": "2020-12-22T11:27:24Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzIyNzE3Nw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r547227177", "body": "Actually, function return nothing.", "bodyText": "Actually, function return nothing.", "bodyHTML": "<p dir=\"auto\">Actually, function return nothing.</p>", "author": "AMashenkov", "createdAt": "2020-12-22T11:34:08Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java", "diffHunk": "@@ -28,9 +35,29 @@\n      * @param objName Object to collect statistics by.\n      * @param colNames Columns to collect statistics by.\n      * @throws IgniteCheckedException  Throws in case of errors.\n+     * @return future to get fini", "originalCommit": "b595e90b5b480aaf80a9256558b1841334df97de", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjMwMzUzMw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556303533", "bodyText": "removed", "author": "Berkof", "createdAt": "2021-01-13T07:09:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzIyNzE3Nw=="}], "type": "inlineReview", "revised_code": {"commit": "7ef165002105dd10417170217e86d65771c524bb", "changed_code": [{"header": "diff --git a/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java b/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java\nindex c85e7261757..5f685e8c929 100644\n--- a/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java\n+++ b/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java\n", "chunk": "@@ -35,7 +31,6 @@ public interface IgniteStatisticsManager {\n      * @param objName Object to collect statistics by.\n      * @param colNames Columns to collect statistics by.\n      * @throws IgniteCheckedException  Throws in case of errors.\n-     * @return future to get fini\n      */\n     public void collectObjectStatistics(String schemaName, String objName, String... colNames) throws IgniteCheckedException;\n \n", "next_change": {"commit": "17a54090bea4d97c122cf06d6be8e60177006519", "changed_code": [{"header": "diff --git a/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java b/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java\nindex 5f685e8c929..732a3118265 100644\n--- a/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java\n+++ b/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java\n", "chunk": "@@ -27,22 +27,20 @@ public interface IgniteStatisticsManager {\n     /**\n      * Collect object statistics.\n      *\n-     * @param schemaName Schema name.\n-     * @param objName Object to collect statistics by.\n-     * @param colNames Columns to collect statistics by.\n+     * @param target Target to collect statistics by.\n      * @throws IgniteCheckedException  Throws in case of errors.\n      */\n-    public void collectObjectStatistics(String schemaName, String objName, String... colNames) throws IgniteCheckedException;\n+    public void collectObjectStatistics(StatisticsTarget target) throws IgniteCheckedException;\n \n     /**\n      * Collect objects statistics.\n      *\n-     * @param keys Collection of keys to collect statistics by (schema, obj, columns).\n+     * @param targets Collection of targets to collect statistics by (schema, obj, columns).\n      * @return Array of futures, to track progress and cancel collection on each of specified cache group.\n      * @throws IgniteCheckedException In case of errors.\n      */\n-    public StatsCollectionFuture<Map<GridTuple3<String, String, String[]>, ObjectStatistics>>[] collectObjectStatisticsAsync(\n-        GridTuple3<String, String, String[]>... keys\n+    public StatisticsGatheringFuture<Map<StatisticsTarget, ObjectStatistics>>[] collectObjectStatisticsAsync(\n+        StatisticsTarget... targets\n     ) throws IgniteCheckedException;\n \n     /**\n", "next_change": {"commit": "33170812024f6c4d321f85287fea0b6c3abdb9e5", "changed_code": [{"header": "diff --git a/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java b/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java\nindex 732a3118265..d97905acbad 100644\n--- a/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java\n+++ b/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java\n", "chunk": "@@ -25,31 +25,32 @@ import java.util.UUID;\n  */\n public interface IgniteStatisticsManager {\n     /**\n-     * Collect object statistics.\n+     * Gather object statistics.\n      *\n-     * @param target Target to collect statistics by.\n+     * @param target Target to gather statistics by.\n      * @throws IgniteCheckedException  Throws in case of errors.\n      */\n-    public void collectObjectStatistics(StatisticsTarget target) throws IgniteCheckedException;\n+    public void gatherObjectStatistics(StatisticsTarget target) throws IgniteCheckedException;\n \n     /**\n-     * Collect objects statistics.\n+     * Gather objects statistics.\n      *\n-     * @param targets Collection of targets to collect statistics by (schema, obj, columns).\n+     * @param targets Gathering of targets to collect statistics by (schema, obj, columns).\n      * @return Array of futures, to track progress and cancel collection on each of specified cache group.\n      * @throws IgniteCheckedException In case of errors.\n      */\n-    public StatisticsGatheringFuture<Map<StatisticsTarget, ObjectStatistics>>[] collectObjectStatisticsAsync(\n+    public StatisticsGatheringFuture<Map<StatisticsTarget, ObjectStatistics>>[] gatherObjectStatisticsAsync(\n         StatisticsTarget... targets\n     ) throws IgniteCheckedException;\n \n     /**\n-     * Cancel object statistics collection.\n+     * Cancel object statistics gathering.\n      *\n-     * @param colId Collection id.\n-     * @return {@code true} if collection was cancelled, {@code false} if specified collection wasn't found.\n+     * @param gatId Gathering id.\n+     * @return {@code true} if gathering was cancelled, {@code false} if specified gathering wasn't found.\n+     * @throws IgniteCheckedException In case of errors (for example: unsupported feature)\n      */\n-    public boolean cancelObjectStatisticsGathering(UUID colId);\n+    public boolean cancelObjectStatisticsGathering(UUID gatId)  throws IgniteCheckedException;\n \n     /**\n      * Get local statistics by object.\n", "next_change": {"commit": "84c79eae65b6bf0fa8b36ad1c4fa09ca8d87cb6c", "changed_code": [{"header": "diff --git a/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java b/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java\nindex d97905acbad..db1bd2fefcf 100644\n--- a/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java\n+++ b/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java\n", "chunk": "@@ -50,7 +50,7 @@ public interface IgniteStatisticsManager {\n      * @return {@code true} if gathering was cancelled, {@code false} if specified gathering wasn't found.\n      * @throws IgniteCheckedException In case of errors (for example: unsupported feature)\n      */\n-    public boolean cancelObjectStatisticsGathering(UUID gatId)  throws IgniteCheckedException;\n+    public boolean cancelObjectStatisticsGathering(UUID gatId) throws IgniteCheckedException;\n \n     /**\n      * Get local statistics by object.\n", "next_change": null}]}}]}}]}}]}}, {"oid": "29e078f2df2c845f1d97ba432d2033c88bdf6464", "url": "https://github.com/gridgain/gridgain/commit/29e078f2df2c845f1d97ba432d2033c88bdf6464", "message": "GG-31094: rename classes, implement dummy statistics storage", "committedDate": "2020-12-23T13:22:00Z", "type": "commit"}, {"oid": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "url": "https://github.com/gridgain/gridgain/commit/ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "message": "GG-31094: main refactoring changes", "committedDate": "2020-12-25T14:03:45Z", "type": "commit"}, {"oid": "5ab0edf44f29bc0c45770c111905807af1982eb2", "url": "https://github.com/gridgain/gridgain/commit/5ab0edf44f29bc0c45770c111905807af1982eb2", "message": "GG-31094: refactoring of message processing", "committedDate": "2020-12-28T13:28:33Z", "type": "commit"}, {"oid": "f03f0e0216f93edace9e8347eddc6ee68388c727", "url": "https://github.com/gridgain/gridgain/commit/f03f0e0216f93edace9e8347eddc6ee68388c727", "message": "GG-31094: fixes", "committedDate": "2020-12-28T13:31:08Z", "type": "commit"}, {"oid": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "url": "https://github.com/gridgain/gridgain/commit/a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "message": "GG-31094: fix handling local statistics results (StatsGatheringResponse)", "committedDate": "2020-12-28T15:24:08Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMxNDcyMQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549314721", "body": "I don't think GridTuple3 is a correct key type for a map.\r\nActually,  (new String[]{\"1\"}).equals(new String[]{\"1\"})  will always return \"fase\".", "bodyText": "I don't think GridTuple3 is a correct key type for a map.\nActually,  (new String[]{\"1\"}).equals(new String[]{\"1\"})  will always return \"fase\".", "bodyHTML": "<p dir=\"auto\">I don't think GridTuple3 is a correct key type for a map.<br>\nActually,  (new String[]{\"1\"}).equals(new String[]{\"1\"})  will always return \"fase\".</p>", "author": "AMashenkov", "createdAt": "2020-12-28T11:30:25Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java", "diffHunk": "@@ -28,9 +35,29 @@\n      * @param objName Object to collect statistics by.\n      * @param colNames Columns to collect statistics by.\n      * @throws IgniteCheckedException  Throws in case of errors.\n+     * @return future to get fini\n      */\n     public void collectObjectStatistics(String schemaName, String objName, String... colNames) throws IgniteCheckedException;\n \n+    /**\n+     * Collect objects statistics.\n+     *\n+     * @param keys Collection of keys to collect statistics by (schema, obj, columns).\n+     * @return Future to track progress and cancel collection.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public StatsCollectionFuture<Map<GridTuple3<String, String, String[]>, ObjectStatistics>> collectObjectStatisticsAsync(", "originalCommit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjMwNDI0Mg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556304242", "bodyText": "Had to duplicate StatisticsKeyMessage as StatisticsTarget because Message shouldn't be in core interface and messages shouldn't inherit fields. Fixed", "author": "Berkof", "createdAt": "2021-01-13T07:11:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMxNDcyMQ=="}], "type": "inlineReview", "revised_code": {"commit": "7ef165002105dd10417170217e86d65771c524bb", "changed_code": [{"header": "diff --git a/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java b/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java\nindex 17f46e9ea71..5f685e8c929 100644\n--- a/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java\n+++ b/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java\n", "chunk": "@@ -43,10 +38,10 @@ public interface IgniteStatisticsManager {\n      * Collect objects statistics.\n      *\n      * @param keys Collection of keys to collect statistics by (schema, obj, columns).\n-     * @return Future to track progress and cancel collection.\n+     * @return Array of futures, to track progress and cancel collection on each of specified cache group.\n      * @throws IgniteCheckedException In case of errors.\n      */\n-    public StatsCollectionFuture<Map<GridTuple3<String, String, String[]>, ObjectStatistics>> collectObjectStatisticsAsync(\n+    public StatsCollectionFuture<Map<GridTuple3<String, String, String[]>, ObjectStatistics>>[] collectObjectStatisticsAsync(\n         GridTuple3<String, String, String[]>... keys\n     ) throws IgniteCheckedException;\n \n", "next_change": {"commit": "17a54090bea4d97c122cf06d6be8e60177006519", "changed_code": [{"header": "diff --git a/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java b/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java\nindex 5f685e8c929..732a3118265 100644\n--- a/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java\n+++ b/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java\n", "chunk": "@@ -27,22 +27,20 @@ public interface IgniteStatisticsManager {\n     /**\n      * Collect object statistics.\n      *\n-     * @param schemaName Schema name.\n-     * @param objName Object to collect statistics by.\n-     * @param colNames Columns to collect statistics by.\n+     * @param target Target to collect statistics by.\n      * @throws IgniteCheckedException  Throws in case of errors.\n      */\n-    public void collectObjectStatistics(String schemaName, String objName, String... colNames) throws IgniteCheckedException;\n+    public void collectObjectStatistics(StatisticsTarget target) throws IgniteCheckedException;\n \n     /**\n      * Collect objects statistics.\n      *\n-     * @param keys Collection of keys to collect statistics by (schema, obj, columns).\n+     * @param targets Collection of targets to collect statistics by (schema, obj, columns).\n      * @return Array of futures, to track progress and cancel collection on each of specified cache group.\n      * @throws IgniteCheckedException In case of errors.\n      */\n-    public StatsCollectionFuture<Map<GridTuple3<String, String, String[]>, ObjectStatistics>>[] collectObjectStatisticsAsync(\n-        GridTuple3<String, String, String[]>... keys\n+    public StatisticsGatheringFuture<Map<StatisticsTarget, ObjectStatistics>>[] collectObjectStatisticsAsync(\n+        StatisticsTarget... targets\n     ) throws IgniteCheckedException;\n \n     /**\n", "next_change": {"commit": "33170812024f6c4d321f85287fea0b6c3abdb9e5", "changed_code": [{"header": "diff --git a/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java b/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java\nindex 732a3118265..d97905acbad 100644\n--- a/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java\n+++ b/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java\n", "chunk": "@@ -25,31 +25,32 @@ import java.util.UUID;\n  */\n public interface IgniteStatisticsManager {\n     /**\n-     * Collect object statistics.\n+     * Gather object statistics.\n      *\n-     * @param target Target to collect statistics by.\n+     * @param target Target to gather statistics by.\n      * @throws IgniteCheckedException  Throws in case of errors.\n      */\n-    public void collectObjectStatistics(StatisticsTarget target) throws IgniteCheckedException;\n+    public void gatherObjectStatistics(StatisticsTarget target) throws IgniteCheckedException;\n \n     /**\n-     * Collect objects statistics.\n+     * Gather objects statistics.\n      *\n-     * @param targets Collection of targets to collect statistics by (schema, obj, columns).\n+     * @param targets Gathering of targets to collect statistics by (schema, obj, columns).\n      * @return Array of futures, to track progress and cancel collection on each of specified cache group.\n      * @throws IgniteCheckedException In case of errors.\n      */\n-    public StatisticsGatheringFuture<Map<StatisticsTarget, ObjectStatistics>>[] collectObjectStatisticsAsync(\n+    public StatisticsGatheringFuture<Map<StatisticsTarget, ObjectStatistics>>[] gatherObjectStatisticsAsync(\n         StatisticsTarget... targets\n     ) throws IgniteCheckedException;\n \n     /**\n-     * Cancel object statistics collection.\n+     * Cancel object statistics gathering.\n      *\n-     * @param colId Collection id.\n-     * @return {@code true} if collection was cancelled, {@code false} if specified collection wasn't found.\n+     * @param gatId Gathering id.\n+     * @return {@code true} if gathering was cancelled, {@code false} if specified gathering wasn't found.\n+     * @throws IgniteCheckedException In case of errors (for example: unsupported feature)\n      */\n-    public boolean cancelObjectStatisticsGathering(UUID colId);\n+    public boolean cancelObjectStatisticsGathering(UUID gatId)  throws IgniteCheckedException;\n \n     /**\n      * Get local statistics by object.\n", "next_change": {"commit": "84c79eae65b6bf0fa8b36ad1c4fa09ca8d87cb6c", "changed_code": [{"header": "diff --git a/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java b/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java\nindex d97905acbad..db1bd2fefcf 100644\n--- a/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java\n+++ b/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java\n", "chunk": "@@ -50,7 +50,7 @@ public interface IgniteStatisticsManager {\n      * @return {@code true} if gathering was cancelled, {@code false} if specified gathering wasn't found.\n      * @throws IgniteCheckedException In case of errors (for example: unsupported feature)\n      */\n-    public boolean cancelObjectStatisticsGathering(UUID gatId)  throws IgniteCheckedException;\n+    public boolean cancelObjectStatisticsGathering(UUID gatId) throws IgniteCheckedException;\n \n     /**\n      * Get local statistics by object.\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMxNjA5Ng==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549316096", "body": "```suggestion\r\n/**\r\n * Future to track gathering statistics task.\r\n */\r\npublic interface StatisticsGatheringTaskFuture<T> extends IgniteInternalFuture<T> {\r\n    /**\r\n     * @return Task id.\r\n     */\r\n    public UUID taskId();\r\n```\r\nActually, it is just a task future. \r\nGeneric type is not specified, I think we can use certain type here instead of generic.", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            /**\n          \n          \n            \n             * Future to track statistics collection task. Allows to get collection id immediately.\n          \n          \n            \n             * @param <T>\n          \n          \n            \n             */\n          \n          \n            \n            public interface StatsCollectionFuture<T> extends IgniteInternalFuture<T> {\n          \n          \n            \n                /**\n          \n          \n            \n                 * @return Statistics collection id.\n          \n          \n            \n                 */\n          \n          \n            \n                public UUID colId();\n          \n          \n            \n            /**\n          \n          \n            \n             * Future to track gathering statistics task.\n          \n          \n            \n             */\n          \n          \n            \n            public interface StatisticsGatheringTaskFuture<T> extends IgniteInternalFuture<T> {\n          \n          \n            \n                /**\n          \n          \n            \n                 * @return Task id.\n          \n          \n            \n                 */\n          \n          \n            \n                public UUID taskId();\n          \n      \n    \n    \n  \n\nActually, it is just a task future.\nGeneric type is not specified, I think we can use certain type here instead of generic.", "bodyHTML": "  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\"><span class=\"pl-c\"><span class=\"pl-c\">/**</span></span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\"> <span class=\"pl-k\">*</span> <span class=\"pl-smi\">Future</span> to track statistics collection task. <span class=\"pl-smi\">Allows</span> to get collection id immediately.</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\"> <span class=\"pl-k\">*</span> <span class=\"pl-k\">@param</span> <span class=\"pl-k\">&lt;</span><span class=\"pl-smi\">T</span><span class=\"pl-k\">&gt;</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\"> <span class=\"pl-k\">*/</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\"><span class=\"pl-k\">public</span> <span class=\"pl-k\">interface</span> <span class=\"pl-en\">StatsCollectionFuture</span>&lt;T&gt; <span class=\"pl-k\">extends</span> <span class=\"pl-e\">IgniteInternalFuture&lt;<span class=\"pl-smi\">T</span>&gt;</span> {</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">    <span class=\"pl-c\"><span class=\"pl-c\">/**</span></span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">     <span class=\"pl-k\">*</span> <span class=\"pl-k\">@return</span> <span class=\"pl-smi\">Statistics</span> collection id.</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">     <span class=\"pl-k\">*/</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">    <span class=\"pl-k\">public</span> <span class=\"pl-c1\">UUID</span> colId();</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\"><span class=\"pl-c\"><span class=\"pl-c\">/**</span></span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\"> <span class=\"pl-k\">*</span> <span class=\"pl-smi\">Future</span> to track gathering statistics task.</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\"> <span class=\"pl-k\">*/</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\"><span class=\"pl-k\">public</span> <span class=\"pl-k\">interface</span> <span class=\"pl-en\">StatisticsGatheringTaskFuture</span>&lt;T&gt; <span class=\"pl-k\">extends</span> <span class=\"pl-e\">IgniteInternalFuture&lt;<span class=\"pl-smi\">T</span>&gt;</span> {</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">    <span class=\"pl-c\"><span class=\"pl-c\">/**</span></span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">     <span class=\"pl-k\">*</span> <span class=\"pl-k\">@return</span> <span class=\"pl-smi\">Task</span> id.</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">     <span class=\"pl-k\">*/</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">    <span class=\"pl-k\">public</span> <span class=\"pl-c1\">UUID</span> taskId();</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n\n<p dir=\"auto\">Actually, it is just a task future.<br>\nGeneric type is not specified, I think we can use certain type here instead of generic.</p>", "author": "AMashenkov", "createdAt": "2020-12-28T11:35:32Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/StatsCollectionFuture.java", "diffHunk": "@@ -0,0 +1,32 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.internal.IgniteInternalFuture;\n+\n+import java.util.UUID;\n+\n+/**\n+ * Future to track statistics collection task. Allows to get collection id immediately.\n+ * @param <T>\n+ */\n+public interface StatsCollectionFuture<T> extends IgniteInternalFuture<T> {\n+    /**\n+     * @return Statistics collection id.\n+     */\n+    public UUID colId();", "originalCommit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjMxMzI0Ng==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556313246", "bodyText": "Committed", "author": "Berkof", "createdAt": "2021-01-13T07:32:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMxNjA5Ng=="}], "type": "inlineReview", "revised_code": {"commit": "ca1e579abf9a1382be63c0d4ba860f969041b986", "changed_code": [{"header": "diff --git a/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/StatsCollectionFuture.java b/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringFuture.java\nsimilarity index 86%\nrename from modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/StatsCollectionFuture.java\nrename to modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringFuture.java\nindex 7421f0ec681..257c089cede 100644\n--- a/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/StatsCollectionFuture.java\n+++ b/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringFuture.java\n", "chunk": "@@ -23,10 +23,10 @@ import java.util.UUID;\n  * Future to track statistics collection task. Allows to get collection id immediately.\n  * @param <T>\n  */\n-public interface StatsCollectionFuture<T> extends IgniteInternalFuture<T> {\n+public interface StatisticsCollectionFuture<T> extends IgniteInternalFuture<T> {\n     /**\n-     * @return Statistics collection id.\n+     * @return Statistics gathering id.\n      */\n-    public UUID colId();\n+    public UUID gatId();\n }\n \n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMyNDcwOQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549324709", "body": "```suggestion\r\n    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> mapToCacheGroup(Collection<StatisticsKeyMessage> keys)\r\n```", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n          \n          \n            \n                protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> mapToCacheGroup(Collection<StatisticsKeyMessage> keys)", "bodyHTML": "  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">    <span class=\"pl-k\">protected</span> <span class=\"pl-k\">Map&lt;<span class=\"pl-smi\">CacheGroupContext</span>, <span class=\"pl-k\">Collection&lt;<span class=\"pl-smi\">StatisticsKeyMessage</span>&gt;</span>&gt;</span> <span class=\"x x-first x-last\">extractGroups</span>(<span class=\"pl-k\">Collection&lt;<span class=\"pl-smi\">StatisticsKeyMessage</span>&gt;</span> keys)</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">    <span class=\"pl-k\">protected</span> <span class=\"pl-k\">Map&lt;<span class=\"pl-smi\">CacheGroupContext</span>, <span class=\"pl-k\">Collection&lt;<span class=\"pl-smi\">StatisticsKeyMessage</span>&gt;</span>&gt;</span> <span class=\"x x-first x-last\">mapToCacheGroup</span>(<span class=\"pl-k\">Collection&lt;<span class=\"pl-smi\">StatisticsKeyMessage</span>&gt;</span> keys)</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "AMashenkov", "createdAt": "2020-12-28T12:07:21Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)", "originalCommit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTU3OTY5Mw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r559579693", "bodyText": "Renamed to mapToCacheGroups", "author": "Berkof", "createdAt": "2021-01-18T13:50:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMyNDcwOQ=="}], "type": "inlineReview", "revised_code": {"commit": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex f0bc33ee4ba..86d3d41f996 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -54,6 +57,21 @@ public class IgniteStatisticsHelper {\n         this.schemaMgr = schemaMgr;\n     }\n \n+    /**\n+     * Get cache group context by specified statistics key.\n+     *\n+     * @param key Statistics key to get context by.\n+     * @return Cache group context for the given key.\n+     * @throws IgniteCheckedException If unable to find table by specified key.\n+     */\n+    public CacheGroupContext getGroupContext(StatisticsKeyMessage key) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+        return tbl.cacheContext().group();\n+    }\n+\n     /**\n      * Extract groups of stats keys.\n      *\n", "next_change": {"commit": "fc2e8cbb19ef01669beaa69a239b2c7f8fb495db", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 86d3d41f996..5f0a2f7e2d0 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -76,11 +90,12 @@ public class IgniteStatisticsHelper {\n      * Extract groups of stats keys.\n      *\n      * @param keys Statistics key to extract groups from.\n-     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @return Map of <group ids> to <collection of keys in groups>\n      * @throws IgniteCheckedException In case of lack some of specified objects.\n      */\n-    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n-            throws IgniteCheckedException {\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(\n+        Collection<StatisticsKeyMessage> keys\n+    ) throws IgniteCheckedException {\n         Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n         for (StatisticsKeyMessage key : keys) {\n             res.compute(getGroupContext(key), (k, v) -> {\n", "next_change": {"commit": "17a54090bea4d97c122cf06d6be8e60177006519", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 5f0a2f7e2d0..f53952e7a19 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -97,16 +98,9 @@ public class IgniteStatisticsHelper {\n         Collection<StatisticsKeyMessage> keys\n     ) throws IgniteCheckedException {\n         Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n-        for (StatisticsKeyMessage key : keys) {\n-            res.compute(getGroupContext(key), (k, v) -> {\n-                if (v == null)\n-                    v = new ArrayList<>();\n-\n-                v.add(key);\n+        for (StatisticsKeyMessage key : keys)\n+            res.computeIfAbsent(getGroupContext(key), k -> new ArrayList<>()).add(key);\n \n-                return v;\n-            });\n-        }\n         return res;\n     }\n \n", "next_change": {"commit": "f5aafee54b1036c09d4944ca9bf0254f8bfd2b1e", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex f53952e7a19..2aa9b4a1480 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -109,20 +179,15 @@ public class IgniteStatisticsHelper {\n      *\n      * @param keys Keys to split.\n      * @return Map cache group to collection of keys in group.\n-     * @throws IgniteCheckedException If some of specified object won't be found in schema.\n      */\n-    public Map<CacheGroupContext, Collection<StatisticsKeyMessage>> splitByGroups(\n-        Collection<StatisticsKeyMessage> keys\n-    ) throws IgniteCheckedException {\n+    public Map<CacheGroupContext, Collection<StatisticsKeyMessage>> splitByGroups(Collection<StatisticsKeyMessage> keys) {\n         Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>();\n \n         for (StatisticsKeyMessage key : keys) {\n             GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            CacheGroupContext grp = (tbl == null) ? null : tbl.cacheContext().group();\n \n-            if (tbl == null)\n-                throw new IgniteCheckedException(String.format(\"Can't  find table %s.%s\", key.schema(), key.obj()));\n-\n-            res.computeIfAbsent(tbl.cacheContext().group(), k -> new ArrayList<>()).add(key);\n+            res.computeIfAbsent(grp, k -> new ArrayList<>()).add(key);\n         }\n \n         return res;\n", "next_change": null}]}}]}}]}}, {"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex f0bc33ee4ba..86d3d41f996 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -65,11 +83,7 @@ public class IgniteStatisticsHelper {\n             throws IgniteCheckedException {\n         Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n         for (StatisticsKeyMessage key : keys) {\n-            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n-            if (tbl == null)\n-                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n-\n-            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+            res.compute(getGroupContext(key), (k, v) -> {\n                 if (v == null)\n                     v = new ArrayList<>();\n \n", "next_change": {"commit": "fc2e8cbb19ef01669beaa69a239b2c7f8fb495db", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 86d3d41f996..5f0a2f7e2d0 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -76,11 +90,12 @@ public class IgniteStatisticsHelper {\n      * Extract groups of stats keys.\n      *\n      * @param keys Statistics key to extract groups from.\n-     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @return Map of <group ids> to <collection of keys in groups>\n      * @throws IgniteCheckedException In case of lack some of specified objects.\n      */\n-    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n-            throws IgniteCheckedException {\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(\n+        Collection<StatisticsKeyMessage> keys\n+    ) throws IgniteCheckedException {\n         Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n         for (StatisticsKeyMessage key : keys) {\n             res.compute(getGroupContext(key), (k, v) -> {\n", "next_change": {"commit": "17a54090bea4d97c122cf06d6be8e60177006519", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 5f0a2f7e2d0..f53952e7a19 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -97,16 +98,9 @@ public class IgniteStatisticsHelper {\n         Collection<StatisticsKeyMessage> keys\n     ) throws IgniteCheckedException {\n         Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n-        for (StatisticsKeyMessage key : keys) {\n-            res.compute(getGroupContext(key), (k, v) -> {\n-                if (v == null)\n-                    v = new ArrayList<>();\n-\n-                v.add(key);\n+        for (StatisticsKeyMessage key : keys)\n+            res.computeIfAbsent(getGroupContext(key), k -> new ArrayList<>()).add(key);\n \n-                return v;\n-            });\n-        }\n         return res;\n     }\n \n", "next_change": {"commit": "f5aafee54b1036c09d4944ca9bf0254f8bfd2b1e", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex f53952e7a19..2aa9b4a1480 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -109,20 +179,15 @@ public class IgniteStatisticsHelper {\n      *\n      * @param keys Keys to split.\n      * @return Map cache group to collection of keys in group.\n-     * @throws IgniteCheckedException If some of specified object won't be found in schema.\n      */\n-    public Map<CacheGroupContext, Collection<StatisticsKeyMessage>> splitByGroups(\n-        Collection<StatisticsKeyMessage> keys\n-    ) throws IgniteCheckedException {\n+    public Map<CacheGroupContext, Collection<StatisticsKeyMessage>> splitByGroups(Collection<StatisticsKeyMessage> keys) {\n         Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>();\n \n         for (StatisticsKeyMessage key : keys) {\n             GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            CacheGroupContext grp = (tbl == null) ? null : tbl.cacheContext().group();\n \n-            if (tbl == null)\n-                throw new IgniteCheckedException(String.format(\"Can't  find table %s.%s\", key.schema(), key.obj()));\n-\n-            res.computeIfAbsent(tbl.cacheContext().group(), k -> new ArrayList<>()).add(key);\n+            res.computeIfAbsent(grp, k -> new ArrayList<>()).add(key);\n         }\n \n         return res;\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMyNDg1Ng==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549324856", "body": "Invalid HTML tags.", "bodyText": "Invalid HTML tags.", "bodyHTML": "<p dir=\"auto\">Invalid HTML tags.</p>", "author": "AMashenkov", "createdAt": "2020-12-28T12:08:02Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>", "originalCommit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTA0NzA2OQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555047069", "bodyText": "fixed", "author": "Berkof", "createdAt": "2021-01-11T13:30:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMyNDg1Ng=="}], "type": "inlineReview", "revised_code": {"commit": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex f0bc33ee4ba..86d3d41f996 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -54,6 +57,21 @@ public class IgniteStatisticsHelper {\n         this.schemaMgr = schemaMgr;\n     }\n \n+    /**\n+     * Get cache group context by specified statistics key.\n+     *\n+     * @param key Statistics key to get context by.\n+     * @return Cache group context for the given key.\n+     * @throws IgniteCheckedException If unable to find table by specified key.\n+     */\n+    public CacheGroupContext getGroupContext(StatisticsKeyMessage key) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+        return tbl.cacheContext().group();\n+    }\n+\n     /**\n      * Extract groups of stats keys.\n      *\n", "next_change": {"commit": "fc2e8cbb19ef01669beaa69a239b2c7f8fb495db", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 86d3d41f996..5f0a2f7e2d0 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -76,11 +90,12 @@ public class IgniteStatisticsHelper {\n      * Extract groups of stats keys.\n      *\n      * @param keys Statistics key to extract groups from.\n-     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @return Map of <group ids> to <collection of keys in groups>\n      * @throws IgniteCheckedException In case of lack some of specified objects.\n      */\n-    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n-            throws IgniteCheckedException {\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(\n+        Collection<StatisticsKeyMessage> keys\n+    ) throws IgniteCheckedException {\n         Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n         for (StatisticsKeyMessage key : keys) {\n             res.compute(getGroupContext(key), (k, v) -> {\n", "next_change": {"commit": "17a54090bea4d97c122cf06d6be8e60177006519", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 5f0a2f7e2d0..f53952e7a19 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -97,16 +98,9 @@ public class IgniteStatisticsHelper {\n         Collection<StatisticsKeyMessage> keys\n     ) throws IgniteCheckedException {\n         Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n-        for (StatisticsKeyMessage key : keys) {\n-            res.compute(getGroupContext(key), (k, v) -> {\n-                if (v == null)\n-                    v = new ArrayList<>();\n-\n-                v.add(key);\n+        for (StatisticsKeyMessage key : keys)\n+            res.computeIfAbsent(getGroupContext(key), k -> new ArrayList<>()).add(key);\n \n-                return v;\n-            });\n-        }\n         return res;\n     }\n \n", "next_change": {"commit": "f5aafee54b1036c09d4944ca9bf0254f8bfd2b1e", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex f53952e7a19..2aa9b4a1480 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -109,20 +179,15 @@ public class IgniteStatisticsHelper {\n      *\n      * @param keys Keys to split.\n      * @return Map cache group to collection of keys in group.\n-     * @throws IgniteCheckedException If some of specified object won't be found in schema.\n      */\n-    public Map<CacheGroupContext, Collection<StatisticsKeyMessage>> splitByGroups(\n-        Collection<StatisticsKeyMessage> keys\n-    ) throws IgniteCheckedException {\n+    public Map<CacheGroupContext, Collection<StatisticsKeyMessage>> splitByGroups(Collection<StatisticsKeyMessage> keys) {\n         Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>();\n \n         for (StatisticsKeyMessage key : keys) {\n             GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            CacheGroupContext grp = (tbl == null) ? null : tbl.cacheContext().group();\n \n-            if (tbl == null)\n-                throw new IgniteCheckedException(String.format(\"Can't  find table %s.%s\", key.schema(), key.obj()));\n-\n-            res.computeIfAbsent(tbl.cacheContext().group(), k -> new ArrayList<>()).add(key);\n+            res.computeIfAbsent(grp, k -> new ArrayList<>()).add(key);\n         }\n \n         return res;\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMyNTIyOQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549325229", "body": "```suggestion\r\n```", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c", "bodyHTML": "  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\"><span class=\"x x-first\">        </span><span class=\"pl-c\"><span class=\"pl-c x\">//</span><span class=\"x x-last\"> \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c</span></span></td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "AMashenkov", "createdAt": "2020-12-28T12:09:27Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c", "originalCommit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex f0bc33ee4ba..86d3d41f996 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -81,14 +95,36 @@ public class IgniteStatisticsHelper {\n         return res;\n     }\n \n+    /**\n+     * Return all nodes where specified cache group located.\n+     *\n+     * @param grp Cache group context to locate.\n+     * @return Set of node ids where group located.\n+     */\n+    public static Set<UUID> nodes(CacheGroupContext grp) {\n+        Set<UUID> res = new HashSet<>();\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        assignments.forEach(pnodes -> pnodes.forEach(cn -> res.add(cn.id())));\n+\n+        return res;\n+    }\n+\n     /**\n      * Get map cluster node to it's partitions for the specified cache group.\n      *\n      * @param grp Cache group context to get partition information by.\n      * @param partIds Partition to collect information by\n+     * @param isPrimary if {@code true} - only master partitions will be selected, if {@code false} - only backups.\n      * @return Map nodeId to array of partitions, related to node.\n      */\n-    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+    public static Map<UUID, int[]> nodePartitions(\n+        CacheGroupContext grp,\n+        Collection<Integer> partIds,\n+        boolean isPrimary\n+    ) {\n         AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n         // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n         List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n", "next_change": {"commit": "fc2e8cbb19ef01669beaa69a239b2c7f8fb495db", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 86d3d41f996..5f0a2f7e2d0 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -126,7 +164,6 @@ public class IgniteStatisticsHelper {\n         boolean isPrimary\n     ) {\n         AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n-        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n         List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n \n         Map<UUID, List<Integer>> res = new HashMap<>();\n", "next_change": {"commit": "17a54090bea4d97c122cf06d6be8e60177006519", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 5f0a2f7e2d0..f53952e7a19 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -166,44 +163,29 @@ public class IgniteStatisticsHelper {\n         AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n         List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n \n-        Map<UUID, List<Integer>> res = new HashMap<>();\n         if (partIds == null)\n-            for (int i = 0; i < assignments.size(); i++)\n-                fillPartition(res, assignments, i, isPrimary);\n-        else\n-            for (Integer partId : partIds)\n-                fillPartition(res, assignments, partId, isPrimary);\n+            partIds = IntStream.range(0, assignments.size()).boxed().collect(Collectors.toList());\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        for (Integer partId : partIds) {\n+            assert partId < assignments.size();\n+\n+            List<ClusterNode> partNodes = assignments.get(partId);\n+            if (F.isEmpty(partNodes))\n+                continue;\n+\n+            if (isPrimary)\n+                res.computeIfAbsent(partNodes.get(0).id(), k -> new ArrayList<>()).add(partId);\n+            else {\n+                for (int i = 1; i < partNodes.size(); i++)\n+                    res.computeIfAbsent(partNodes.get(i).id(), k -> new ArrayList<>()).add(partId);\n+            }\n+        }\n \n         return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n                 v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n     }\n \n-    /**\n-     * Fill map with master or backups node of specified partition.\n-     *\n-     * @param res Map to fill.\n-     * @param assignments Partitions assignments.\n-     * @param partId Partition to process.\n-     * @param isPrimary if {@code true} only primary nodes will be choosen, if {@code false} - only backups.\n-     */\n-    protected static void fillPartition(\n-        Map<UUID, List<Integer>> res,\n-        List<List<ClusterNode>> assignments,\n-        int partId,\n-        boolean isPrimary\n-    ) {\n-        assert partId < assignments.size();\n-        List<ClusterNode> partNodes = assignments.get(partId);\n-        if (F.isEmpty(partNodes))\n-            return;\n-\n-        if (isPrimary)\n-            res.computeIfAbsent(partNodes.get(0).id(), k -> new ArrayList<>()).add(partId);\n-        else\n-            for (int i = 1; i < partNodes.size() - 1; i++)\n-                res.computeIfAbsent(partNodes.get(i).id(), k -> new ArrayList<>()).add(partId);\n-    }\n-\n     /**\n      * Get all nodes where specified cache groups located.\n      *\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMyNTM2OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549325368", "body": "Braces.", "bodyText": "Braces.", "bodyHTML": "<p dir=\"auto\">Braces.</p>", "author": "AMashenkov", "createdAt": "2020-12-28T12:09:54Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)", "originalCommit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQxNTk3MA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556415970", "bodyText": "added", "author": "Berkof", "createdAt": "2021-01-13T10:26:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMyNTM2OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ2NDc3NQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556464775", "bodyText": "added", "author": "Berkof", "createdAt": "2021-01-13T11:52:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMyNTM2OA=="}], "type": "inlineReview", "revised_code": {"commit": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex f0bc33ee4ba..86d3d41f996 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -81,14 +95,36 @@ public class IgniteStatisticsHelper {\n         return res;\n     }\n \n+    /**\n+     * Return all nodes where specified cache group located.\n+     *\n+     * @param grp Cache group context to locate.\n+     * @return Set of node ids where group located.\n+     */\n+    public static Set<UUID> nodes(CacheGroupContext grp) {\n+        Set<UUID> res = new HashSet<>();\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        assignments.forEach(pnodes -> pnodes.forEach(cn -> res.add(cn.id())));\n+\n+        return res;\n+    }\n+\n     /**\n      * Get map cluster node to it's partitions for the specified cache group.\n      *\n      * @param grp Cache group context to get partition information by.\n      * @param partIds Partition to collect information by\n+     * @param isPrimary if {@code true} - only master partitions will be selected, if {@code false} - only backups.\n      * @return Map nodeId to array of partitions, related to node.\n      */\n-    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+    public static Map<UUID, int[]> nodePartitions(\n+        CacheGroupContext grp,\n+        Collection<Integer> partIds,\n+        boolean isPrimary\n+    ) {\n         AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n         // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n         List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n", "next_change": {"commit": "fc2e8cbb19ef01669beaa69a239b2c7f8fb495db", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 86d3d41f996..5f0a2f7e2d0 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -126,7 +164,6 @@ public class IgniteStatisticsHelper {\n         boolean isPrimary\n     ) {\n         AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n-        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n         List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n \n         Map<UUID, List<Integer>> res = new HashMap<>();\n", "next_change": {"commit": "17a54090bea4d97c122cf06d6be8e60177006519", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 5f0a2f7e2d0..f53952e7a19 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -166,44 +163,29 @@ public class IgniteStatisticsHelper {\n         AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n         List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n \n-        Map<UUID, List<Integer>> res = new HashMap<>();\n         if (partIds == null)\n-            for (int i = 0; i < assignments.size(); i++)\n-                fillPartition(res, assignments, i, isPrimary);\n-        else\n-            for (Integer partId : partIds)\n-                fillPartition(res, assignments, partId, isPrimary);\n+            partIds = IntStream.range(0, assignments.size()).boxed().collect(Collectors.toList());\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        for (Integer partId : partIds) {\n+            assert partId < assignments.size();\n+\n+            List<ClusterNode> partNodes = assignments.get(partId);\n+            if (F.isEmpty(partNodes))\n+                continue;\n+\n+            if (isPrimary)\n+                res.computeIfAbsent(partNodes.get(0).id(), k -> new ArrayList<>()).add(partId);\n+            else {\n+                for (int i = 1; i < partNodes.size(); i++)\n+                    res.computeIfAbsent(partNodes.get(i).id(), k -> new ArrayList<>()).add(partId);\n+            }\n+        }\n \n         return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n                 v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n     }\n \n-    /**\n-     * Fill map with master or backups node of specified partition.\n-     *\n-     * @param res Map to fill.\n-     * @param assignments Partitions assignments.\n-     * @param partId Partition to process.\n-     * @param isPrimary if {@code true} only primary nodes will be choosen, if {@code false} - only backups.\n-     */\n-    protected static void fillPartition(\n-        Map<UUID, List<Integer>> res,\n-        List<List<ClusterNode>> assignments,\n-        int partId,\n-        boolean isPrimary\n-    ) {\n-        assert partId < assignments.size();\n-        List<ClusterNode> partNodes = assignments.get(partId);\n-        if (F.isEmpty(partNodes))\n-            return;\n-\n-        if (isPrimary)\n-            res.computeIfAbsent(partNodes.get(0).id(), k -> new ArrayList<>()).add(partId);\n-        else\n-            for (int i = 1; i < partNodes.size() - 1; i++)\n-                res.computeIfAbsent(partNodes.get(i).id(), k -> new ArrayList<>()).add(partId);\n-    }\n-\n     /**\n      * Get all nodes where specified cache groups located.\n      *\n", "next_change": null}]}}]}}, {"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex f0bc33ee4ba..86d3d41f996 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -96,40 +132,53 @@ public class IgniteStatisticsHelper {\n         Map<UUID, List<Integer>> res = new HashMap<>();\n         if (partIds == null)\n             for (int i = 0; i < assignments.size(); i++)\n-                fillPartitionMaster(res, assignments, i);\n+                fillPartition(res, assignments, i, isPrimary);\n         else\n             for (Integer partId : partIds)\n-                fillPartitionMaster(res, assignments, partId);\n+                fillPartition(res, assignments, partId, isPrimary);\n \n         return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n                 v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n     }\n \n     /**\n-     * Fill map with master node of specified partition.\n+     * Fill map with master or backups node of specified partition.\n      *\n      * @param res Map to fill.\n      * @param assignments Partitions assignments.\n      * @param partId Partition to process.\n+     * @param isPrimary if {@code true} only primary nodes will be choosen, if {@code false} - only backups.\n      */\n-    protected static  void fillPartitionMaster(\n+    protected static  void fillPartition(\n         Map<UUID, List<Integer>> res,\n         List<List<ClusterNode>> assignments,\n-        int partId\n+        int partId,\n+        boolean isPrimary\n     ) {\n         assert partId < assignments.size();\n         List<ClusterNode> partNodes = assignments.get(partId);\n         if (F.isEmpty(partNodes))\n             return;\n \n-        res.compute(partNodes.get(0).id(), (k, v) -> {\n-            if (v == null)\n-                v = new ArrayList<>();\n+        if (isPrimary)\n+            res.compute(partNodes.get(0).id(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n \n-            v.add(partId);\n+                v.add(partId);\n \n-            return v;\n-        });\n+                return v;\n+            });\n+        else\n+            for (int i = 1; i < partNodes.size() - 1; i++)\n+                res.compute(partNodes.get(i).id(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+\n+                    v.add(partId);\n+\n+                    return v;\n+                });\n     }\n \n     /**\n", "next_change": {"commit": "7ef165002105dd10417170217e86d65771c524bb", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 86d3d41f996..b215186973d 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -181,72 +202,6 @@ public class IgniteStatisticsHelper {\n                 });\n     }\n \n-    /**\n-     * Prepare statistics collection request for specified node.\n-     *\n-     * @param colId Collection id.\n-     * @param data Keys to partitions for current node.\n-     * @return Statistics collection request.\n-     */\n-    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n-        UUID reqId = UUID.randomUUID();\n-        return new StatisticsGatheringRequest(colId, reqId, data);\n-    }\n-\n-    // TODO add extraction of necessary partIds by statKeyMsg\n-\n-    /**\n-     * Generate statistics collection requests by given keys.\n-     *\n-     * @param colId Collection id.\n-     * @param locNodeId Local node id.\n-     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n-     *            If {@code null} - requests will be\n-     * @return Collection of statistics collection addressed request.\n-     */\n-    public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n-        UUID colId,\n-        UUID locNodeId,\n-        Map<StatisticsKeyMessage, int[]> failedPartitions,\n-        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts\n-    ) {\n-        // NodeId to <Key to partitions on node> map\n-        Map<UUID, Map<StatisticsKeyMessage, int[]>> reqMap = new HashMap<>();\n-        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n-            // TODO: can we specify partitions here? from failed parts will it be effective?\n-            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null, true);\n-\n-            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n-                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n-                    if (v == null)\n-                        v = new HashMap<>();\n-\n-                    Collection<StatisticsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n-\n-                    for (StatisticsKeyMessage key : grpKeys) {\n-                        int[] keyNodeParts = (failedPartitions == null) ? nodeParts.getValue() :\n-                                GridArrays.intersect(nodeParts.getValue(), failedPartitions.get(key));\n-\n-                        if (keyNodeParts.length > 0)\n-                            v.put(key, keyNodeParts);\n-                    }\n-\n-                    return v.isEmpty() ? null : v;\n-                });\n-        }\n-\n-        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs = new ArrayList<>();\n-        for (Map.Entry<UUID, Map<StatisticsKeyMessage, int[]>> nodeGpsParts: reqMap.entrySet()) {\n-            if (nodeGpsParts.getValue().isEmpty())\n-                continue;\n-\n-            StatisticsGatheringRequest req = prepareRequest(colId, nodeGpsParts.getValue());\n-            reqs.add(new StatisticsAddrRequest<>(req, locNodeId, nodeGpsParts.getKey()));\n-        }\n-\n-        return reqs;\n-    }\n-\n     /**\n      * Get all nodes where specified cache groups located.\n      *\n", "next_change": {"commit": "fc2e8cbb19ef01669beaa69a239b2c7f8fb495db", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex b215186973d..5f0a2f7e2d0 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -182,24 +198,10 @@ public class IgniteStatisticsHelper {\n             return;\n \n         if (isPrimary)\n-            res.compute(partNodes.get(0).id(), (k, v) -> {\n-                if (v == null)\n-                    v = new ArrayList<>();\n-\n-                v.add(partId);\n-\n-                return v;\n-            });\n+            res.computeIfAbsent(partNodes.get(0).id(), k -> new ArrayList<>()).add(partId);\n         else\n             for (int i = 1; i < partNodes.size() - 1; i++)\n-                res.compute(partNodes.get(i).id(), (k, v) -> {\n-                    if (v == null)\n-                        v = new ArrayList<>();\n-\n-                    v.add(partId);\n-\n-                    return v;\n-                });\n+                res.computeIfAbsent(partNodes.get(i).id(), k -> new ArrayList<>()).add(partId);\n     }\n \n     /**\n", "next_change": {"commit": "17a54090bea4d97c122cf06d6be8e60177006519", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 5f0a2f7e2d0..f53952e7a19 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -166,44 +163,29 @@ public class IgniteStatisticsHelper {\n         AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n         List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n \n-        Map<UUID, List<Integer>> res = new HashMap<>();\n         if (partIds == null)\n-            for (int i = 0; i < assignments.size(); i++)\n-                fillPartition(res, assignments, i, isPrimary);\n-        else\n-            for (Integer partId : partIds)\n-                fillPartition(res, assignments, partId, isPrimary);\n+            partIds = IntStream.range(0, assignments.size()).boxed().collect(Collectors.toList());\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        for (Integer partId : partIds) {\n+            assert partId < assignments.size();\n+\n+            List<ClusterNode> partNodes = assignments.get(partId);\n+            if (F.isEmpty(partNodes))\n+                continue;\n+\n+            if (isPrimary)\n+                res.computeIfAbsent(partNodes.get(0).id(), k -> new ArrayList<>()).add(partId);\n+            else {\n+                for (int i = 1; i < partNodes.size(); i++)\n+                    res.computeIfAbsent(partNodes.get(i).id(), k -> new ArrayList<>()).add(partId);\n+            }\n+        }\n \n         return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n                 v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n     }\n \n-    /**\n-     * Fill map with master or backups node of specified partition.\n-     *\n-     * @param res Map to fill.\n-     * @param assignments Partitions assignments.\n-     * @param partId Partition to process.\n-     * @param isPrimary if {@code true} only primary nodes will be choosen, if {@code false} - only backups.\n-     */\n-    protected static void fillPartition(\n-        Map<UUID, List<Integer>> res,\n-        List<List<ClusterNode>> assignments,\n-        int partId,\n-        boolean isPrimary\n-    ) {\n-        assert partId < assignments.size();\n-        List<ClusterNode> partNodes = assignments.get(partId);\n-        if (F.isEmpty(partNodes))\n-            return;\n-\n-        if (isPrimary)\n-            res.computeIfAbsent(partNodes.get(0).id(), k -> new ArrayList<>()).add(partId);\n-        else\n-            for (int i = 1; i < partNodes.size() - 1; i++)\n-                res.computeIfAbsent(partNodes.get(i).id(), k -> new ArrayList<>()).add(partId);\n-    }\n-\n     /**\n      * Get all nodes where specified cache groups located.\n      *\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMyNTM5OQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549325399", "body": "Braces", "bodyText": "Braces", "bodyHTML": "<p dir=\"auto\">Braces</p>", "author": "AMashenkov", "createdAt": "2020-12-28T12:10:02Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else", "originalCommit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQxNjA0Mw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556416043", "bodyText": "added", "author": "Berkof", "createdAt": "2021-01-13T10:27:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMyNTM5OQ=="}], "type": "inlineReview", "revised_code": {"commit": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex f0bc33ee4ba..86d3d41f996 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -96,40 +132,53 @@ public class IgniteStatisticsHelper {\n         Map<UUID, List<Integer>> res = new HashMap<>();\n         if (partIds == null)\n             for (int i = 0; i < assignments.size(); i++)\n-                fillPartitionMaster(res, assignments, i);\n+                fillPartition(res, assignments, i, isPrimary);\n         else\n             for (Integer partId : partIds)\n-                fillPartitionMaster(res, assignments, partId);\n+                fillPartition(res, assignments, partId, isPrimary);\n \n         return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n                 v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n     }\n \n     /**\n-     * Fill map with master node of specified partition.\n+     * Fill map with master or backups node of specified partition.\n      *\n      * @param res Map to fill.\n      * @param assignments Partitions assignments.\n      * @param partId Partition to process.\n+     * @param isPrimary if {@code true} only primary nodes will be choosen, if {@code false} - only backups.\n      */\n-    protected static  void fillPartitionMaster(\n+    protected static  void fillPartition(\n         Map<UUID, List<Integer>> res,\n         List<List<ClusterNode>> assignments,\n-        int partId\n+        int partId,\n+        boolean isPrimary\n     ) {\n         assert partId < assignments.size();\n         List<ClusterNode> partNodes = assignments.get(partId);\n         if (F.isEmpty(partNodes))\n             return;\n \n-        res.compute(partNodes.get(0).id(), (k, v) -> {\n-            if (v == null)\n-                v = new ArrayList<>();\n+        if (isPrimary)\n+            res.compute(partNodes.get(0).id(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n \n-            v.add(partId);\n+                v.add(partId);\n \n-            return v;\n-        });\n+                return v;\n+            });\n+        else\n+            for (int i = 1; i < partNodes.size() - 1; i++)\n+                res.compute(partNodes.get(i).id(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+\n+                    v.add(partId);\n+\n+                    return v;\n+                });\n     }\n \n     /**\n", "next_change": {"commit": "7ef165002105dd10417170217e86d65771c524bb", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 86d3d41f996..b215186973d 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -181,72 +202,6 @@ public class IgniteStatisticsHelper {\n                 });\n     }\n \n-    /**\n-     * Prepare statistics collection request for specified node.\n-     *\n-     * @param colId Collection id.\n-     * @param data Keys to partitions for current node.\n-     * @return Statistics collection request.\n-     */\n-    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n-        UUID reqId = UUID.randomUUID();\n-        return new StatisticsGatheringRequest(colId, reqId, data);\n-    }\n-\n-    // TODO add extraction of necessary partIds by statKeyMsg\n-\n-    /**\n-     * Generate statistics collection requests by given keys.\n-     *\n-     * @param colId Collection id.\n-     * @param locNodeId Local node id.\n-     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n-     *            If {@code null} - requests will be\n-     * @return Collection of statistics collection addressed request.\n-     */\n-    public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n-        UUID colId,\n-        UUID locNodeId,\n-        Map<StatisticsKeyMessage, int[]> failedPartitions,\n-        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts\n-    ) {\n-        // NodeId to <Key to partitions on node> map\n-        Map<UUID, Map<StatisticsKeyMessage, int[]>> reqMap = new HashMap<>();\n-        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n-            // TODO: can we specify partitions here? from failed parts will it be effective?\n-            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null, true);\n-\n-            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n-                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n-                    if (v == null)\n-                        v = new HashMap<>();\n-\n-                    Collection<StatisticsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n-\n-                    for (StatisticsKeyMessage key : grpKeys) {\n-                        int[] keyNodeParts = (failedPartitions == null) ? nodeParts.getValue() :\n-                                GridArrays.intersect(nodeParts.getValue(), failedPartitions.get(key));\n-\n-                        if (keyNodeParts.length > 0)\n-                            v.put(key, keyNodeParts);\n-                    }\n-\n-                    return v.isEmpty() ? null : v;\n-                });\n-        }\n-\n-        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs = new ArrayList<>();\n-        for (Map.Entry<UUID, Map<StatisticsKeyMessage, int[]>> nodeGpsParts: reqMap.entrySet()) {\n-            if (nodeGpsParts.getValue().isEmpty())\n-                continue;\n-\n-            StatisticsGatheringRequest req = prepareRequest(colId, nodeGpsParts.getValue());\n-            reqs.add(new StatisticsAddrRequest<>(req, locNodeId, nodeGpsParts.getKey()));\n-        }\n-\n-        return reqs;\n-    }\n-\n     /**\n      * Get all nodes where specified cache groups located.\n      *\n", "next_change": {"commit": "fc2e8cbb19ef01669beaa69a239b2c7f8fb495db", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex b215186973d..5f0a2f7e2d0 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -182,24 +198,10 @@ public class IgniteStatisticsHelper {\n             return;\n \n         if (isPrimary)\n-            res.compute(partNodes.get(0).id(), (k, v) -> {\n-                if (v == null)\n-                    v = new ArrayList<>();\n-\n-                v.add(partId);\n-\n-                return v;\n-            });\n+            res.computeIfAbsent(partNodes.get(0).id(), k -> new ArrayList<>()).add(partId);\n         else\n             for (int i = 1; i < partNodes.size() - 1; i++)\n-                res.compute(partNodes.get(i).id(), (k, v) -> {\n-                    if (v == null)\n-                        v = new ArrayList<>();\n-\n-                    v.add(partId);\n-\n-                    return v;\n-                });\n+                res.computeIfAbsent(partNodes.get(i).id(), k -> new ArrayList<>()).add(partId);\n     }\n \n     /**\n", "next_change": {"commit": "17a54090bea4d97c122cf06d6be8e60177006519", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 5f0a2f7e2d0..f53952e7a19 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -166,44 +163,29 @@ public class IgniteStatisticsHelper {\n         AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n         List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n \n-        Map<UUID, List<Integer>> res = new HashMap<>();\n         if (partIds == null)\n-            for (int i = 0; i < assignments.size(); i++)\n-                fillPartition(res, assignments, i, isPrimary);\n-        else\n-            for (Integer partId : partIds)\n-                fillPartition(res, assignments, partId, isPrimary);\n+            partIds = IntStream.range(0, assignments.size()).boxed().collect(Collectors.toList());\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        for (Integer partId : partIds) {\n+            assert partId < assignments.size();\n+\n+            List<ClusterNode> partNodes = assignments.get(partId);\n+            if (F.isEmpty(partNodes))\n+                continue;\n+\n+            if (isPrimary)\n+                res.computeIfAbsent(partNodes.get(0).id(), k -> new ArrayList<>()).add(partId);\n+            else {\n+                for (int i = 1; i < partNodes.size(); i++)\n+                    res.computeIfAbsent(partNodes.get(i).id(), k -> new ArrayList<>()).add(partId);\n+            }\n+        }\n \n         return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n                 v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n     }\n \n-    /**\n-     * Fill map with master or backups node of specified partition.\n-     *\n-     * @param res Map to fill.\n-     * @param assignments Partitions assignments.\n-     * @param partId Partition to process.\n-     * @param isPrimary if {@code true} only primary nodes will be choosen, if {@code false} - only backups.\n-     */\n-    protected static void fillPartition(\n-        Map<UUID, List<Integer>> res,\n-        List<List<ClusterNode>> assignments,\n-        int partId,\n-        boolean isPrimary\n-    ) {\n-        assert partId < assignments.size();\n-        List<ClusterNode> partNodes = assignments.get(partId);\n-        if (F.isEmpty(partNodes))\n-            return;\n-\n-        if (isPrimary)\n-            res.computeIfAbsent(partNodes.get(0).id(), k -> new ArrayList<>()).add(partId);\n-        else\n-            for (int i = 1; i < partNodes.size() - 1; i++)\n-                res.computeIfAbsent(partNodes.get(i).id(), k -> new ArrayList<>()).add(partId);\n-    }\n-\n     /**\n      * Get all nodes where specified cache groups located.\n      *\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMyNjg1OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549326858", "body": "\"requests will be\".. will be what?", "bodyText": "\"requests will be\".. will be what?", "bodyHTML": "<p dir=\"auto\">\"requests will be\".. will be what?</p>", "author": "AMashenkov", "createdAt": "2020-12-28T12:15:35Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatisticsGatheringRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n+     *            If {@code null} - requests will be", "originalCommit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQxNjk4MA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556416980", "bodyText": "removed", "author": "Berkof", "createdAt": "2021-01-13T10:28:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMyNjg1OA=="}], "type": "inlineReview", "revised_code": {"commit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex f0bc33ee4ba..4210ae9137b 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -150,6 +150,7 @@ public class IgniteStatisticsHelper {\n      * Generate statistics collection requests by given keys.\n      *\n      * @param colId Collection id.\n+     * @param locNodeId Local node id.\n      * @param keys Collection of keys to collect statistics by.\n      * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n      *            If {@code null} - requests will be\n", "next_change": {"commit": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 4210ae9137b..86d3d41f996 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -151,24 +200,22 @@ public class IgniteStatisticsHelper {\n      *\n      * @param colId Collection id.\n      * @param locNodeId Local node id.\n-     * @param keys Collection of keys to collect statistics by.\n      * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n      *            If {@code null} - requests will be\n      * @return Collection of statistics collection addressed request.\n-     * @throws IgniteCheckedException In case of errors.\n      */\n     public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n         UUID colId,\n         UUID locNodeId,\n-        Collection<StatisticsKeyMessage> keys,\n         Map<StatisticsKeyMessage, int[]> failedPartitions,\n         Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts\n     ) {\n-\n         // NodeId to <Key to partitions on node> map\n         Map<UUID, Map<StatisticsKeyMessage, int[]>> reqMap = new HashMap<>();\n         for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n-            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null); // TODO Null?\n+            // TODO: can we specify partitions here? from failed parts will it be effective?\n+            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null, true);\n+\n             for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n                 reqMap.compute(nodeParts.getKey(), (k, v) -> {\n                     if (v == null)\n", "next_change": {"commit": "7ef165002105dd10417170217e86d65771c524bb", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 86d3d41f996..b215186973d 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -181,72 +202,6 @@ public class IgniteStatisticsHelper {\n                 });\n     }\n \n-    /**\n-     * Prepare statistics collection request for specified node.\n-     *\n-     * @param colId Collection id.\n-     * @param data Keys to partitions for current node.\n-     * @return Statistics collection request.\n-     */\n-    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n-        UUID reqId = UUID.randomUUID();\n-        return new StatisticsGatheringRequest(colId, reqId, data);\n-    }\n-\n-    // TODO add extraction of necessary partIds by statKeyMsg\n-\n-    /**\n-     * Generate statistics collection requests by given keys.\n-     *\n-     * @param colId Collection id.\n-     * @param locNodeId Local node id.\n-     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n-     *            If {@code null} - requests will be\n-     * @return Collection of statistics collection addressed request.\n-     */\n-    public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n-        UUID colId,\n-        UUID locNodeId,\n-        Map<StatisticsKeyMessage, int[]> failedPartitions,\n-        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts\n-    ) {\n-        // NodeId to <Key to partitions on node> map\n-        Map<UUID, Map<StatisticsKeyMessage, int[]>> reqMap = new HashMap<>();\n-        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n-            // TODO: can we specify partitions here? from failed parts will it be effective?\n-            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null, true);\n-\n-            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n-                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n-                    if (v == null)\n-                        v = new HashMap<>();\n-\n-                    Collection<StatisticsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n-\n-                    for (StatisticsKeyMessage key : grpKeys) {\n-                        int[] keyNodeParts = (failedPartitions == null) ? nodeParts.getValue() :\n-                                GridArrays.intersect(nodeParts.getValue(), failedPartitions.get(key));\n-\n-                        if (keyNodeParts.length > 0)\n-                            v.put(key, keyNodeParts);\n-                    }\n-\n-                    return v.isEmpty() ? null : v;\n-                });\n-        }\n-\n-        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs = new ArrayList<>();\n-        for (Map.Entry<UUID, Map<StatisticsKeyMessage, int[]>> nodeGpsParts: reqMap.entrySet()) {\n-            if (nodeGpsParts.getValue().isEmpty())\n-                continue;\n-\n-            StatisticsGatheringRequest req = prepareRequest(colId, nodeGpsParts.getValue());\n-            reqs.add(new StatisticsAddrRequest<>(req, locNodeId, nodeGpsParts.getKey()));\n-        }\n-\n-        return reqs;\n-    }\n-\n     /**\n      * Get all nodes where specified cache groups located.\n      *\n", "next_change": {"commit": "fc2e8cbb19ef01669beaa69a239b2c7f8fb495db", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex b215186973d..5f0a2f7e2d0 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -182,24 +198,10 @@ public class IgniteStatisticsHelper {\n             return;\n \n         if (isPrimary)\n-            res.compute(partNodes.get(0).id(), (k, v) -> {\n-                if (v == null)\n-                    v = new ArrayList<>();\n-\n-                v.add(partId);\n-\n-                return v;\n-            });\n+            res.computeIfAbsent(partNodes.get(0).id(), k -> new ArrayList<>()).add(partId);\n         else\n             for (int i = 1; i < partNodes.size() - 1; i++)\n-                res.compute(partNodes.get(i).id(), (k, v) -> {\n-                    if (v == null)\n-                        v = new ArrayList<>();\n-\n-                    v.add(partId);\n-\n-                    return v;\n-                });\n+                res.computeIfAbsent(partNodes.get(i).id(), k -> new ArrayList<>()).add(partId);\n     }\n \n     /**\n", "next_change": {"commit": "17a54090bea4d97c122cf06d6be8e60177006519", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 5f0a2f7e2d0..f53952e7a19 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -166,44 +163,29 @@ public class IgniteStatisticsHelper {\n         AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n         List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n \n-        Map<UUID, List<Integer>> res = new HashMap<>();\n         if (partIds == null)\n-            for (int i = 0; i < assignments.size(); i++)\n-                fillPartition(res, assignments, i, isPrimary);\n-        else\n-            for (Integer partId : partIds)\n-                fillPartition(res, assignments, partId, isPrimary);\n+            partIds = IntStream.range(0, assignments.size()).boxed().collect(Collectors.toList());\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        for (Integer partId : partIds) {\n+            assert partId < assignments.size();\n+\n+            List<ClusterNode> partNodes = assignments.get(partId);\n+            if (F.isEmpty(partNodes))\n+                continue;\n+\n+            if (isPrimary)\n+                res.computeIfAbsent(partNodes.get(0).id(), k -> new ArrayList<>()).add(partId);\n+            else {\n+                for (int i = 1; i < partNodes.size(); i++)\n+                    res.computeIfAbsent(partNodes.get(i).id(), k -> new ArrayList<>()).add(partId);\n+            }\n+        }\n \n         return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n                 v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n     }\n \n-    /**\n-     * Fill map with master or backups node of specified partition.\n-     *\n-     * @param res Map to fill.\n-     * @param assignments Partitions assignments.\n-     * @param partId Partition to process.\n-     * @param isPrimary if {@code true} only primary nodes will be choosen, if {@code false} - only backups.\n-     */\n-    protected static void fillPartition(\n-        Map<UUID, List<Integer>> res,\n-        List<List<ClusterNode>> assignments,\n-        int partId,\n-        boolean isPrimary\n-    ) {\n-        assert partId < assignments.size();\n-        List<ClusterNode> partNodes = assignments.get(partId);\n-        if (F.isEmpty(partNodes))\n-            return;\n-\n-        if (isPrimary)\n-            res.computeIfAbsent(partNodes.get(0).id(), k -> new ArrayList<>()).add(partId);\n-        else\n-            for (int i = 1; i < partNodes.size() - 1; i++)\n-                res.computeIfAbsent(partNodes.get(i).id(), k -> new ArrayList<>()).add(partId);\n-    }\n-\n     /**\n      * Get all nodes where specified cache groups located.\n      *\n", "next_change": null}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMyODk3NA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549328974", "body": "```suggestion\r\n                    Collection<StatisticsKeyMessage> grpValues= grpEntry.getValue();\r\n```", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                Collection<StatisticsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n          \n          \n            \n                                Collection<StatisticsKeyMessage> grpValues= grpEntry.getValue();", "bodyHTML": "  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">                    <span class=\"pl-k\">Collection&lt;<span class=\"pl-smi\">StatisticsKeyMessage</span>&gt;</span> <span class=\"x x-first\">grpKeys </span><span class=\"pl-k x\">=</span><span class=\"x\"> grpContexts</span><span class=\"pl-k x\">.</span><span class=\"x x-last\">get(</span>grpEntry<span class=\"pl-k\">.</span><span class=\"x x-first x-last\">getKey()</span>);</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">                    <span class=\"pl-k\">Collection&lt;<span class=\"pl-smi\">StatisticsKeyMessage</span>&gt;</span> <span class=\"x x-first\">grpValues</span><span class=\"pl-k x\">=</span><span class=\"x x-last\"> </span>grpEntry<span class=\"pl-k\">.</span><span class=\"x x-first x-last\">getValue(</span>);</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "AMashenkov", "createdAt": "2020-12-28T12:23:16Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatisticsGatheringRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n+     *            If {@code null} - requests will be\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n+        UUID colId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions,\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts\n+    ) {\n+\n+        // NodeId to <Key to partitions on node> map\n+        Map<UUID, Map<StatisticsKeyMessage, int[]>> reqMap = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n+            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null); // TODO Null?\n+            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n+                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n+                    if (v == null)\n+                        v = new HashMap<>();\n+\n+                    Collection<StatisticsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());", "originalCommit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex f0bc33ee4ba..86d3d41f996 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -150,23 +199,23 @@ public class IgniteStatisticsHelper {\n      * Generate statistics collection requests by given keys.\n      *\n      * @param colId Collection id.\n-     * @param keys Collection of keys to collect statistics by.\n+     * @param locNodeId Local node id.\n      * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n      *            If {@code null} - requests will be\n      * @return Collection of statistics collection addressed request.\n-     * @throws IgniteCheckedException In case of errors.\n      */\n     public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n         UUID colId,\n-        Collection<StatisticsKeyMessage> keys,\n+        UUID locNodeId,\n         Map<StatisticsKeyMessage, int[]> failedPartitions,\n         Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts\n     ) {\n-\n         // NodeId to <Key to partitions on node> map\n         Map<UUID, Map<StatisticsKeyMessage, int[]>> reqMap = new HashMap<>();\n         for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n-            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null); // TODO Null?\n+            // TODO: can we specify partitions here? from failed parts will it be effective?\n+            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null, true);\n+\n             for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n                 reqMap.compute(nodeParts.getKey(), (k, v) -> {\n                     if (v == null)\n", "next_change": {"commit": "7ef165002105dd10417170217e86d65771c524bb", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 86d3d41f996..b215186973d 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -181,72 +202,6 @@ public class IgniteStatisticsHelper {\n                 });\n     }\n \n-    /**\n-     * Prepare statistics collection request for specified node.\n-     *\n-     * @param colId Collection id.\n-     * @param data Keys to partitions for current node.\n-     * @return Statistics collection request.\n-     */\n-    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n-        UUID reqId = UUID.randomUUID();\n-        return new StatisticsGatheringRequest(colId, reqId, data);\n-    }\n-\n-    // TODO add extraction of necessary partIds by statKeyMsg\n-\n-    /**\n-     * Generate statistics collection requests by given keys.\n-     *\n-     * @param colId Collection id.\n-     * @param locNodeId Local node id.\n-     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n-     *            If {@code null} - requests will be\n-     * @return Collection of statistics collection addressed request.\n-     */\n-    public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n-        UUID colId,\n-        UUID locNodeId,\n-        Map<StatisticsKeyMessage, int[]> failedPartitions,\n-        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts\n-    ) {\n-        // NodeId to <Key to partitions on node> map\n-        Map<UUID, Map<StatisticsKeyMessage, int[]>> reqMap = new HashMap<>();\n-        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n-            // TODO: can we specify partitions here? from failed parts will it be effective?\n-            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null, true);\n-\n-            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n-                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n-                    if (v == null)\n-                        v = new HashMap<>();\n-\n-                    Collection<StatisticsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n-\n-                    for (StatisticsKeyMessage key : grpKeys) {\n-                        int[] keyNodeParts = (failedPartitions == null) ? nodeParts.getValue() :\n-                                GridArrays.intersect(nodeParts.getValue(), failedPartitions.get(key));\n-\n-                        if (keyNodeParts.length > 0)\n-                            v.put(key, keyNodeParts);\n-                    }\n-\n-                    return v.isEmpty() ? null : v;\n-                });\n-        }\n-\n-        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs = new ArrayList<>();\n-        for (Map.Entry<UUID, Map<StatisticsKeyMessage, int[]>> nodeGpsParts: reqMap.entrySet()) {\n-            if (nodeGpsParts.getValue().isEmpty())\n-                continue;\n-\n-            StatisticsGatheringRequest req = prepareRequest(colId, nodeGpsParts.getValue());\n-            reqs.add(new StatisticsAddrRequest<>(req, locNodeId, nodeGpsParts.getKey()));\n-        }\n-\n-        return reqs;\n-    }\n-\n     /**\n      * Get all nodes where specified cache groups located.\n      *\n", "next_change": {"commit": "fc2e8cbb19ef01669beaa69a239b2c7f8fb495db", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex b215186973d..5f0a2f7e2d0 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -182,24 +198,10 @@ public class IgniteStatisticsHelper {\n             return;\n \n         if (isPrimary)\n-            res.compute(partNodes.get(0).id(), (k, v) -> {\n-                if (v == null)\n-                    v = new ArrayList<>();\n-\n-                v.add(partId);\n-\n-                return v;\n-            });\n+            res.computeIfAbsent(partNodes.get(0).id(), k -> new ArrayList<>()).add(partId);\n         else\n             for (int i = 1; i < partNodes.size() - 1; i++)\n-                res.compute(partNodes.get(i).id(), (k, v) -> {\n-                    if (v == null)\n-                        v = new ArrayList<>();\n-\n-                    v.add(partId);\n-\n-                    return v;\n-                });\n+                res.computeIfAbsent(partNodes.get(i).id(), k -> new ArrayList<>()).add(partId);\n     }\n \n     /**\n", "next_change": {"commit": "17a54090bea4d97c122cf06d6be8e60177006519", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 5f0a2f7e2d0..f53952e7a19 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -166,44 +163,29 @@ public class IgniteStatisticsHelper {\n         AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n         List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n \n-        Map<UUID, List<Integer>> res = new HashMap<>();\n         if (partIds == null)\n-            for (int i = 0; i < assignments.size(); i++)\n-                fillPartition(res, assignments, i, isPrimary);\n-        else\n-            for (Integer partId : partIds)\n-                fillPartition(res, assignments, partId, isPrimary);\n+            partIds = IntStream.range(0, assignments.size()).boxed().collect(Collectors.toList());\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        for (Integer partId : partIds) {\n+            assert partId < assignments.size();\n+\n+            List<ClusterNode> partNodes = assignments.get(partId);\n+            if (F.isEmpty(partNodes))\n+                continue;\n+\n+            if (isPrimary)\n+                res.computeIfAbsent(partNodes.get(0).id(), k -> new ArrayList<>()).add(partId);\n+            else {\n+                for (int i = 1; i < partNodes.size(); i++)\n+                    res.computeIfAbsent(partNodes.get(i).id(), k -> new ArrayList<>()).add(partId);\n+            }\n+        }\n \n         return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n                 v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n     }\n \n-    /**\n-     * Fill map with master or backups node of specified partition.\n-     *\n-     * @param res Map to fill.\n-     * @param assignments Partitions assignments.\n-     * @param partId Partition to process.\n-     * @param isPrimary if {@code true} only primary nodes will be choosen, if {@code false} - only backups.\n-     */\n-    protected static void fillPartition(\n-        Map<UUID, List<Integer>> res,\n-        List<List<ClusterNode>> assignments,\n-        int partId,\n-        boolean isPrimary\n-    ) {\n-        assert partId < assignments.size();\n-        List<ClusterNode> partNodes = assignments.get(partId);\n-        if (F.isEmpty(partNodes))\n-            return;\n-\n-        if (isPrimary)\n-            res.computeIfAbsent(partNodes.get(0).id(), k -> new ArrayList<>()).add(partId);\n-        else\n-            for (int i = 1; i < partNodes.size() - 1; i++)\n-                res.computeIfAbsent(partNodes.get(i).id(), k -> new ArrayList<>()).add(partId);\n-    }\n-\n     /**\n      * Get all nodes where specified cache groups located.\n      *\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMzMzIwNg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549333206", "body": "Using StatisticsKey->partitions leads to collections analyzing\\filtering\\copying that very hard to understand.\r\nMethod overall complexity is too high.\r\n\r\nCan this relation be turned into partition->StatisticKeys ? \r\nFor all keys that relates to same cache group you will do same actions that looks trivial with Partition->StatisticKeys.\r\nI thinks nodePartitions method result is useless, failedPartitions could be transformed to partition->statisticKeys, then the result can be easily mapped to nodes.", "bodyText": "Using StatisticsKey->partitions leads to collections analyzing\\filtering\\copying that very hard to understand.\nMethod overall complexity is too high.\nCan this relation be turned into partition->StatisticKeys ?\nFor all keys that relates to same cache group you will do same actions that looks trivial with Partition->StatisticKeys.\nI thinks nodePartitions method result is useless, failedPartitions could be transformed to partition->statisticKeys, then the result can be easily mapped to nodes.", "bodyHTML": "<p dir=\"auto\">Using StatisticsKey-&gt;partitions leads to collections analyzing\\filtering\\copying that very hard to understand.<br>\nMethod overall complexity is too high.</p>\n<p dir=\"auto\">Can this relation be turned into partition-&gt;StatisticKeys ?<br>\nFor all keys that relates to same cache group you will do same actions that looks trivial with Partition-&gt;StatisticKeys.<br>\nI thinks nodePartitions method result is useless, failedPartitions could be transformed to partition-&gt;statisticKeys, then the result can be easily mapped to nodes.</p>", "author": "AMashenkov", "createdAt": "2020-12-28T12:38:15Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatisticsGatheringRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n+     *            If {@code null} - requests will be\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n+        UUID colId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions,", "originalCommit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQxODY4Nw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556418687", "bodyText": "replaced with gathering task per cache group, so now there is only one partitions collection.", "author": "Berkof", "createdAt": "2021-01-13T10:31:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTMzMzIwNg=="}], "type": "inlineReview", "revised_code": {"commit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex f0bc33ee4ba..4210ae9137b 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -158,6 +159,7 @@ public class IgniteStatisticsHelper {\n      */\n     public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n         UUID colId,\n+        UUID locNodeId,\n         Collection<StatisticsKeyMessage> keys,\n         Map<StatisticsKeyMessage, int[]> failedPartitions,\n         Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts\n", "next_change": {"commit": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 4210ae9137b..86d3d41f996 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -151,24 +200,22 @@ public class IgniteStatisticsHelper {\n      *\n      * @param colId Collection id.\n      * @param locNodeId Local node id.\n-     * @param keys Collection of keys to collect statistics by.\n      * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n      *            If {@code null} - requests will be\n      * @return Collection of statistics collection addressed request.\n-     * @throws IgniteCheckedException In case of errors.\n      */\n     public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n         UUID colId,\n         UUID locNodeId,\n-        Collection<StatisticsKeyMessage> keys,\n         Map<StatisticsKeyMessage, int[]> failedPartitions,\n         Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts\n     ) {\n-\n         // NodeId to <Key to partitions on node> map\n         Map<UUID, Map<StatisticsKeyMessage, int[]>> reqMap = new HashMap<>();\n         for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n-            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null); // TODO Null?\n+            // TODO: can we specify partitions here? from failed parts will it be effective?\n+            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null, true);\n+\n             for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n                 reqMap.compute(nodeParts.getKey(), (k, v) -> {\n                     if (v == null)\n", "next_change": {"commit": "7ef165002105dd10417170217e86d65771c524bb", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 86d3d41f996..b215186973d 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -181,72 +202,6 @@ public class IgniteStatisticsHelper {\n                 });\n     }\n \n-    /**\n-     * Prepare statistics collection request for specified node.\n-     *\n-     * @param colId Collection id.\n-     * @param data Keys to partitions for current node.\n-     * @return Statistics collection request.\n-     */\n-    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n-        UUID reqId = UUID.randomUUID();\n-        return new StatisticsGatheringRequest(colId, reqId, data);\n-    }\n-\n-    // TODO add extraction of necessary partIds by statKeyMsg\n-\n-    /**\n-     * Generate statistics collection requests by given keys.\n-     *\n-     * @param colId Collection id.\n-     * @param locNodeId Local node id.\n-     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n-     *            If {@code null} - requests will be\n-     * @return Collection of statistics collection addressed request.\n-     */\n-    public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n-        UUID colId,\n-        UUID locNodeId,\n-        Map<StatisticsKeyMessage, int[]> failedPartitions,\n-        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts\n-    ) {\n-        // NodeId to <Key to partitions on node> map\n-        Map<UUID, Map<StatisticsKeyMessage, int[]>> reqMap = new HashMap<>();\n-        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n-            // TODO: can we specify partitions here? from failed parts will it be effective?\n-            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null, true);\n-\n-            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n-                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n-                    if (v == null)\n-                        v = new HashMap<>();\n-\n-                    Collection<StatisticsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n-\n-                    for (StatisticsKeyMessage key : grpKeys) {\n-                        int[] keyNodeParts = (failedPartitions == null) ? nodeParts.getValue() :\n-                                GridArrays.intersect(nodeParts.getValue(), failedPartitions.get(key));\n-\n-                        if (keyNodeParts.length > 0)\n-                            v.put(key, keyNodeParts);\n-                    }\n-\n-                    return v.isEmpty() ? null : v;\n-                });\n-        }\n-\n-        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs = new ArrayList<>();\n-        for (Map.Entry<UUID, Map<StatisticsKeyMessage, int[]>> nodeGpsParts: reqMap.entrySet()) {\n-            if (nodeGpsParts.getValue().isEmpty())\n-                continue;\n-\n-            StatisticsGatheringRequest req = prepareRequest(colId, nodeGpsParts.getValue());\n-            reqs.add(new StatisticsAddrRequest<>(req, locNodeId, nodeGpsParts.getKey()));\n-        }\n-\n-        return reqs;\n-    }\n-\n     /**\n      * Get all nodes where specified cache groups located.\n      *\n", "next_change": {"commit": "fc2e8cbb19ef01669beaa69a239b2c7f8fb495db", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex b215186973d..5f0a2f7e2d0 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -182,24 +198,10 @@ public class IgniteStatisticsHelper {\n             return;\n \n         if (isPrimary)\n-            res.compute(partNodes.get(0).id(), (k, v) -> {\n-                if (v == null)\n-                    v = new ArrayList<>();\n-\n-                v.add(partId);\n-\n-                return v;\n-            });\n+            res.computeIfAbsent(partNodes.get(0).id(), k -> new ArrayList<>()).add(partId);\n         else\n             for (int i = 1; i < partNodes.size() - 1; i++)\n-                res.compute(partNodes.get(i).id(), (k, v) -> {\n-                    if (v == null)\n-                        v = new ArrayList<>();\n-\n-                    v.add(partId);\n-\n-                    return v;\n-                });\n+                res.computeIfAbsent(partNodes.get(i).id(), k -> new ArrayList<>()).add(partId);\n     }\n \n     /**\n", "next_change": {"commit": "17a54090bea4d97c122cf06d6be8e60177006519", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 5f0a2f7e2d0..f53952e7a19 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -166,44 +163,29 @@ public class IgniteStatisticsHelper {\n         AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n         List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n \n-        Map<UUID, List<Integer>> res = new HashMap<>();\n         if (partIds == null)\n-            for (int i = 0; i < assignments.size(); i++)\n-                fillPartition(res, assignments, i, isPrimary);\n-        else\n-            for (Integer partId : partIds)\n-                fillPartition(res, assignments, partId, isPrimary);\n+            partIds = IntStream.range(0, assignments.size()).boxed().collect(Collectors.toList());\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        for (Integer partId : partIds) {\n+            assert partId < assignments.size();\n+\n+            List<ClusterNode> partNodes = assignments.get(partId);\n+            if (F.isEmpty(partNodes))\n+                continue;\n+\n+            if (isPrimary)\n+                res.computeIfAbsent(partNodes.get(0).id(), k -> new ArrayList<>()).add(partId);\n+            else {\n+                for (int i = 1; i < partNodes.size(); i++)\n+                    res.computeIfAbsent(partNodes.get(i).id(), k -> new ArrayList<>()).add(partId);\n+            }\n+        }\n \n         return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n                 v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n     }\n \n-    /**\n-     * Fill map with master or backups node of specified partition.\n-     *\n-     * @param res Map to fill.\n-     * @param assignments Partitions assignments.\n-     * @param partId Partition to process.\n-     * @param isPrimary if {@code true} only primary nodes will be choosen, if {@code false} - only backups.\n-     */\n-    protected static void fillPartition(\n-        Map<UUID, List<Integer>> res,\n-        List<List<ClusterNode>> assignments,\n-        int partId,\n-        boolean isPrimary\n-    ) {\n-        assert partId < assignments.size();\n-        List<ClusterNode> partNodes = assignments.get(partId);\n-        if (F.isEmpty(partNodes))\n-            return;\n-\n-        if (isPrimary)\n-            res.computeIfAbsent(partNodes.get(0).id(), k -> new ArrayList<>()).add(partId);\n-        else\n-            for (int i = 1; i < partNodes.size() - 1; i++)\n-                res.computeIfAbsent(partNodes.get(i).id(), k -> new ArrayList<>()).add(partId);\n-    }\n-\n     /**\n      * Get all nodes where specified cache groups located.\n      *\n", "next_change": null}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM0MTg4NQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549341885", "body": "Topology version is shared for all cache groups.", "bodyText": "Topology version is shared for all cache groups.", "bodyHTML": "<p dir=\"auto\">Topology version is shared for all cache groups.</p>", "author": "AMashenkov", "createdAt": "2020-12-28T13:07:49Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatisticsGatheringRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n+     *            If {@code null} - requests will be\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n+        UUID colId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions,\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts\n+    ) {\n+\n+        // NodeId to <Key to partitions on node> map\n+        Map<UUID, Map<StatisticsKeyMessage, int[]>> reqMap = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n+            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null); // TODO Null?\n+            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n+                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n+                    if (v == null)\n+                        v = new HashMap<>();\n+\n+                    Collection<StatisticsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n+\n+                    for (StatisticsKeyMessage key : grpKeys) {\n+                        int[] keyNodeParts = (failedPartitions == null) ? nodeParts.getValue() :\n+                                GridArrays.intersect(nodeParts.getValue(), failedPartitions.get(key));\n+\n+                        if (keyNodeParts.length > 0)\n+                            v.put(key, keyNodeParts);\n+                    }\n+\n+                    return v.isEmpty() ? null : v;\n+                });\n+        }\n+\n+        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs = new ArrayList<>();\n+        for (Map.Entry<UUID, Map<StatisticsKeyMessage, int[]>> nodeGpsParts: reqMap.entrySet()) {\n+            if (nodeGpsParts.getValue().isEmpty())\n+                continue;\n+\n+            StatisticsGatheringRequest req = prepareRequest(colId, nodeGpsParts.getValue());\n+            reqs.add(new StatisticsAddrRequest<>(req, nodeGpsParts.getKey()));\n+        }\n+\n+        return reqs;\n+    }\n+\n+    /**\n+     * Get all nodes where specified cache grous located.\n+     *\n+     * @param grps Cache groups.\n+     * @return Set of node ids.\n+     */\n+    public static Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys(Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grps) {\n+        Map<UUID, Collection<StatisticsKeyMessage>> res = new HashMap<>();\n+\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpKeys : grps.entrySet()) {\n+            CacheGroupContext grp = grpKeys.getKey();\n+            AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();", "originalCommit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex f0bc33ee4ba..86d3d41f996 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -192,19 +241,21 @@ public class IgniteStatisticsHelper {\n                 continue;\n \n             StatisticsGatheringRequest req = prepareRequest(colId, nodeGpsParts.getValue());\n-            reqs.add(new StatisticsAddrRequest<>(req, nodeGpsParts.getKey()));\n+            reqs.add(new StatisticsAddrRequest<>(req, locNodeId, nodeGpsParts.getKey()));\n         }\n \n         return reqs;\n     }\n \n     /**\n-     * Get all nodes where specified cache grous located.\n+     * Get all nodes where specified cache groups located.\n      *\n      * @param grps Cache groups.\n      * @return Set of node ids.\n      */\n-    public static Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys(Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grps) {\n+    public static Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys(\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grps\n+    ) {\n         Map<UUID, Collection<StatisticsKeyMessage>> res = new HashMap<>();\n \n         for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpKeys : grps.entrySet()) {\n", "next_change": {"commit": "fc2e8cbb19ef01669beaa69a239b2c7f8fb495db", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 86d3d41f996..5f0a2f7e2d0 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -263,14 +220,9 @@ public class IgniteStatisticsHelper {\n             AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n             List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n \n-            assignments.forEach(nodes -> nodes.forEach(clusterNode -> res.compute(clusterNode.id(), (k, v) -> {\n-                if (v == null)\n-                    v = new HashSet<>();\n-\n-                v.addAll(grpKeys.getValue());\n-\n-                return v;\n-            })));\n+            for (List<ClusterNode> partNodes : assignments)\n+                for (ClusterNode node : partNodes)\n+                    res.computeIfAbsent(node.id(), k -> new HashSet<>()).addAll(grpKeys.getValue());\n         }\n         return res;\n     }\n", "next_change": {"commit": "17a54090bea4d97c122cf06d6be8e60177006519", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 5f0a2f7e2d0..f53952e7a19 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -215,14 +197,14 @@ public class IgniteStatisticsHelper {\n     ) {\n         Map<UUID, Collection<StatisticsKeyMessage>> res = new HashMap<>();\n \n+        AffinityTopologyVersion topVer = grps.keySet().iterator().next().shared().exchange().readyAffinityVersion();\n         for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpKeys : grps.entrySet()) {\n-            CacheGroupContext grp = grpKeys.getKey();\n-            AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n-            List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+            List<List<ClusterNode>> assignments = grpKeys.getKey().affinity().assignments(topVer);\n \n-            for (List<ClusterNode> partNodes : assignments)\n+            for (List<ClusterNode> partNodes : assignments) {\n                 for (ClusterNode node : partNodes)\n                     res.computeIfAbsent(node.id(), k -> new HashSet<>()).addAll(grpKeys.getValue());\n+            }\n         }\n         return res;\n     }\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM0MjIyOA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549342228", "body": "Javadoc is not actual.", "bodyText": "Javadoc is not actual.", "bodyHTML": "<p dir=\"auto\">Javadoc is not actual.</p>", "author": "AMashenkov", "createdAt": "2020-12-28T13:08:52Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatisticsGatheringRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n+     *            If {@code null} - requests will be\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n+        UUID colId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions,\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts\n+    ) {\n+\n+        // NodeId to <Key to partitions on node> map\n+        Map<UUID, Map<StatisticsKeyMessage, int[]>> reqMap = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n+            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null); // TODO Null?\n+            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n+                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n+                    if (v == null)\n+                        v = new HashMap<>();\n+\n+                    Collection<StatisticsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n+\n+                    for (StatisticsKeyMessage key : grpKeys) {\n+                        int[] keyNodeParts = (failedPartitions == null) ? nodeParts.getValue() :\n+                                GridArrays.intersect(nodeParts.getValue(), failedPartitions.get(key));\n+\n+                        if (keyNodeParts.length > 0)\n+                            v.put(key, keyNodeParts);\n+                    }\n+\n+                    return v.isEmpty() ? null : v;\n+                });\n+        }\n+\n+        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs = new ArrayList<>();\n+        for (Map.Entry<UUID, Map<StatisticsKeyMessage, int[]>> nodeGpsParts: reqMap.entrySet()) {\n+            if (nodeGpsParts.getValue().isEmpty())\n+                continue;\n+\n+            StatisticsGatheringRequest req = prepareRequest(colId, nodeGpsParts.getValue());\n+            reqs.add(new StatisticsAddrRequest<>(req, nodeGpsParts.getKey()));\n+        }\n+\n+        return reqs;\n+    }\n+\n+    /**\n+     * Get all nodes where specified cache grous located.\n+     *\n+     * @param grps Cache groups.\n+     * @return Set of node ids.\n+     */\n+    public static Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys(Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grps) {", "originalCommit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex f0bc33ee4ba..86d3d41f996 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -192,19 +241,21 @@ public class IgniteStatisticsHelper {\n                 continue;\n \n             StatisticsGatheringRequest req = prepareRequest(colId, nodeGpsParts.getValue());\n-            reqs.add(new StatisticsAddrRequest<>(req, nodeGpsParts.getKey()));\n+            reqs.add(new StatisticsAddrRequest<>(req, locNodeId, nodeGpsParts.getKey()));\n         }\n \n         return reqs;\n     }\n \n     /**\n-     * Get all nodes where specified cache grous located.\n+     * Get all nodes where specified cache groups located.\n      *\n      * @param grps Cache groups.\n      * @return Set of node ids.\n      */\n-    public static Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys(Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grps) {\n+    public static Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys(\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grps\n+    ) {\n         Map<UUID, Collection<StatisticsKeyMessage>> res = new HashMap<>();\n \n         for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpKeys : grps.entrySet()) {\n", "next_change": {"commit": "fc2e8cbb19ef01669beaa69a239b2c7f8fb495db", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 86d3d41f996..5f0a2f7e2d0 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -263,14 +220,9 @@ public class IgniteStatisticsHelper {\n             AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n             List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n \n-            assignments.forEach(nodes -> nodes.forEach(clusterNode -> res.compute(clusterNode.id(), (k, v) -> {\n-                if (v == null)\n-                    v = new HashSet<>();\n-\n-                v.addAll(grpKeys.getValue());\n-\n-                return v;\n-            })));\n+            for (List<ClusterNode> partNodes : assignments)\n+                for (ClusterNode node : partNodes)\n+                    res.computeIfAbsent(node.id(), k -> new HashSet<>()).addAll(grpKeys.getValue());\n         }\n         return res;\n     }\n", "next_change": {"commit": "17a54090bea4d97c122cf06d6be8e60177006519", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 5f0a2f7e2d0..f53952e7a19 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -215,14 +197,14 @@ public class IgniteStatisticsHelper {\n     ) {\n         Map<UUID, Collection<StatisticsKeyMessage>> res = new HashMap<>();\n \n+        AffinityTopologyVersion topVer = grps.keySet().iterator().next().shared().exchange().readyAffinityVersion();\n         for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpKeys : grps.entrySet()) {\n-            CacheGroupContext grp = grpKeys.getKey();\n-            AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n-            List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+            List<List<ClusterNode>> assignments = grpKeys.getKey().affinity().assignments(topVer);\n \n-            for (List<ClusterNode> partNodes : assignments)\n+            for (List<ClusterNode> partNodes : assignments) {\n                 for (ClusterNode node : partNodes)\n                     res.computeIfAbsent(node.id(), k -> new HashSet<>()).addAll(grpKeys.getValue());\n+            }\n         }\n         return res;\n     }\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM0MjU0Mw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549342543", "body": "empty line", "bodyText": "empty line", "bodyHTML": "<p dir=\"auto\">empty line</p>", "author": "AMashenkov", "createdAt": "2020-12-28T13:09:53Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatisticsGatheringRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n+     *            If {@code null} - requests will be\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n+        UUID colId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions,\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts\n+    ) {\n+\n+        // NodeId to <Key to partitions on node> map\n+        Map<UUID, Map<StatisticsKeyMessage, int[]>> reqMap = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n+            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null); // TODO Null?\n+            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n+                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n+                    if (v == null)\n+                        v = new HashMap<>();\n+\n+                    Collection<StatisticsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n+\n+                    for (StatisticsKeyMessage key : grpKeys) {\n+                        int[] keyNodeParts = (failedPartitions == null) ? nodeParts.getValue() :\n+                                GridArrays.intersect(nodeParts.getValue(), failedPartitions.get(key));\n+\n+                        if (keyNodeParts.length > 0)\n+                            v.put(key, keyNodeParts);\n+                    }\n+\n+                    return v.isEmpty() ? null : v;\n+                });\n+        }\n+\n+        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs = new ArrayList<>();\n+        for (Map.Entry<UUID, Map<StatisticsKeyMessage, int[]>> nodeGpsParts: reqMap.entrySet()) {\n+            if (nodeGpsParts.getValue().isEmpty())\n+                continue;\n+\n+            StatisticsGatheringRequest req = prepareRequest(colId, nodeGpsParts.getValue());\n+            reqs.add(new StatisticsAddrRequest<>(req, nodeGpsParts.getKey()));\n+        }\n+\n+        return reqs;\n+    }\n+\n+    /**\n+     * Get all nodes where specified cache grous located.\n+     *\n+     * @param grps Cache groups.\n+     * @return Set of node ids.\n+     */\n+    public static Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys(Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grps) {\n+        Map<UUID, Collection<StatisticsKeyMessage>> res = new HashMap<>();\n+\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpKeys : grps.entrySet()) {\n+            CacheGroupContext grp = grpKeys.getKey();\n+            AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+            List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+            assignments.forEach(nodes -> nodes.forEach(clusterNode -> res.compute(clusterNode.id(), (k, v) -> {\n+                if (v == null)\n+                    v = new HashSet<>();\n+\n+                v.addAll(grpKeys.getValue());\n+\n+                return v;\n+            })));\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Generate statistics clear requests.\n+     *\n+     * @param keys Keys to clean statistics by.\n+     * @return Collection of addressed statistics clear requests.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public Collection<StatisticsAddrRequest<StatisticsClearRequest>> generateClearRequests(\n+        Collection<StatisticsKeyMessage> keys\n+    ) throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts = extractGroups(keys);\n+        Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys = nodeKeys(grpContexts);\n+\n+        return nodeKeys.entrySet().stream().map(node -> new StatisticsAddrRequest<>(\n+            new StatisticsClearRequest(UUID.randomUUID(), new ArrayList<>(node.getValue())), node.getKey()))\n+                .collect(Collectors.toList());\n+    }\n+\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param gatId Gathering id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    protected Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n+        UUID gatId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions\n+    ) throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts = extractGroups(keys);\n+\n+        return generateCollectionRequests(gatId, keys, failedPartitions, grpContexts);\n+    }\n+\n+    /**\n+     * Extract all partitions from specified statistics collection requests.\n+     *\n+     * @param reqs Failed request to extract partitions from.\n+     * @return Map StatisticsKeyMessage to List of corresponding partitions.\n+     */\n+    public static Map<StatisticsKeyMessage, int[]> extractFailed(StatisticsGatheringRequest[] reqs) {\n+        Map<StatisticsKeyMessage, List<Integer>> res = new HashMap<>();\n+\n+        UUID colId = null;\n+        for (StatisticsGatheringRequest req : reqs) {\n+", "originalCommit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7ef165002105dd10417170217e86d65771c524bb", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex f0bc33ee4ba..b215186973d 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -227,70 +233,124 @@ public class IgniteStatisticsHelper {\n     /**\n      * Generate statistics clear requests.\n      *\n+     * @param locNodeId Local node id.\n      * @param keys Keys to clean statistics by.\n      * @return Collection of addressed statistics clear requests.\n      * @throws IgniteCheckedException In case of errors.\n      */\n     public Collection<StatisticsAddrRequest<StatisticsClearRequest>> generateClearRequests(\n+        UUID locNodeId,\n         Collection<StatisticsKeyMessage> keys\n     ) throws IgniteCheckedException {\n         Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts = extractGroups(keys);\n         Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys = nodeKeys(grpContexts);\n \n         return nodeKeys.entrySet().stream().map(node -> new StatisticsAddrRequest<>(\n-            new StatisticsClearRequest(UUID.randomUUID(), new ArrayList<>(node.getValue())), node.getKey()))\n+            new StatisticsClearRequest(UUID.randomUUID(), new ArrayList<>(node.getValue())), locNodeId, node.getKey()))\n                 .collect(Collectors.toList());\n     }\n \n+    /**\n+     * Generate collection of statistics propagation messages to send collected partiton level statistics to backup\n+     * nodes. Can be called for single cache group and partition statistics only.\n+     *\n+     * @param locNodeId Local node id.\n+     * @param key Statistics key by which it was collected.\n+     * @param objStats Collection of object statistics (for the same partition).\n+     * @return Collection of propagation messages.\n+     */\n+    public Collection<StatisticsAddrRequest<StatisticsPropagationMessage>> generatePropagationMessages(\n+        UUID locNodeId,\n+        StatisticsKeyMessage key,\n+        Collection<ObjectPartitionStatisticsImpl> objStats\n+    ) throws IgniteCheckedException {\n+        List<StatisticsObjectData> objData = new ArrayList<>(objStats.size());\n+        objStats.forEach(ops -> {\n+            try {\n+                objData.add(StatisticsUtils.toObjectData(key, StatisticsType.PARTITION, ops));\n+            }\n+            catch (IgniteCheckedException e) {\n+                // TODO: log\n+            }\n+        });\n+\n+        StatisticsPropagationMessage msg = new StatisticsPropagationMessage(objData);\n+\n+        int partId = objStats.iterator().next().partId();\n+        CacheGroupContext grpCtx = getGroupContext(key);\n+        Map<UUID, int[]> nodePartitions = nodePartitions(grpCtx, Collections.singleton(partId), false);\n+\n+        return nodePartitions.keySet().stream().map(nodeId -> new StatisticsAddrRequest(msg, locNodeId, nodeId))\n+            .collect(Collectors.toList());\n+    }\n+\n+    public Collection<StatisticsAddrRequest<StatisticsPropagationMessage>> generateGlobalPropagationMessages(\n+        UUID locNodeId,\n+        Map<StatisticsKeyMessage, ObjectStatisticsImpl> objStats\n+    ) throws IgniteCheckedException {\n+        Map<StatisticsKeyMessage, StatisticsObjectData> objData = new HashMap<>(objStats.size());\n+        objStats.forEach((k, v) -> {\n+            try {\n+                objData.put(k, StatisticsUtils.toObjectData(k, StatisticsType.GLOBAL, v));\n+            }\n+            catch (IgniteCheckedException e) {\n+                // TODO: log\n+            }\n+        });\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpsKeys = extractGroups(objStats.keySet());\n+        Map<CacheGroupContext, Collection<StatisticsObjectData>> grpsData = new HashMap<>(grpsKeys.size());\n+\n+        grpsKeys.forEach((gpr, keys) -> {\n+            Collection<StatisticsObjectData> stats = keys.stream().map(objData::get).collect(Collectors.toList());\n+            grpsData.put(gpr, stats);\n+        });\n+\n+        Map<UUID, Collection<StatisticsObjectData>> reqMap = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsObjectData>> grpKeys : grpsData.entrySet()) {\n+            Set<UUID> grpNodes = nodes(grpKeys.getKey());\n+            grpNodes.forEach(node -> reqMap.compute(node, (k, v) -> {\n+                if (v == null)\n+                    v = new HashSet<>();\n+\n+                v.addAll(grpKeys.getValue());\n+                return v;\n+            }));\n+        }\n+\n+        return reqMap.entrySet().stream().map(e -> new StatisticsAddrRequest(\n+            new StatisticsPropagationMessage(new ArrayList<>(e.getValue())), locNodeId, e.getKey()))\n+                .collect(Collectors.toList());\n+    }\n \n     /**\n      * Generate statistics collection requests by given keys.\n      *\n      * @param gatId Gathering id.\n+     * @param locNodeId Local node id.\n      * @param keys Collection of keys to collect statistics by.\n      * @return Collection of statistics collection addressed request.\n      * @throws IgniteCheckedException In case of errors.\n      */\n     protected Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n-        UUID gatId,\n-        Collection<StatisticsKeyMessage> keys,\n-        Map<StatisticsKeyMessage, int[]> failedPartitions\n+            UUID gatId,\n+            UUID locNodeId,\n+            Collection<StatisticsKeyMessage> keys,\n+            Collection<Integer> failedPartitions\n     ) throws IgniteCheckedException {\n-        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts = extractGroups(keys);\n-\n-        return generateCollectionRequests(gatId, keys, failedPartitions, grpContexts);\n-    }\n-\n-    /**\n-     * Extract all partitions from specified statistics collection requests.\n-     *\n-     * @param reqs Failed request to extract partitions from.\n-     * @return Map StatisticsKeyMessage to List of corresponding partitions.\n-     */\n-    public static Map<StatisticsKeyMessage, int[]> extractFailed(StatisticsGatheringRequest[] reqs) {\n-        Map<StatisticsKeyMessage, List<Integer>> res = new HashMap<>();\n-\n-        UUID colId = null;\n-        for (StatisticsGatheringRequest req : reqs) {\n-\n-            assert colId == null || colId.equals(req.gatId());\n-            colId = req.gatId();\n+        Map<UUID, Map<StatisticsKeyMessage, int[]>> reqMap = new HashMap<>();\n+        CacheGroupContext grpCtx = getGroupContext(keys.iterator().next());\n \n-            for (Map.Entry<StatisticsKeyMessage, int[]> keyEntry : req.keys().entrySet()) {\n-                res.compute(keyEntry.getKey(), (k, v) -> {\n-                    if (v == null)\n-                        v = new ArrayList<>();\n+        Map<UUID, int[]> reqNodes = nodePartitions(grpCtx, failedPartitions, true);\n \n-                    for (int i = 0; i < keyEntry.getValue().length; i++)\n-                        v.add(keyEntry.getValue()[i]);\n+        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs = new ArrayList<>();\n \n-                    return v;\n-                });\n-            }\n+        for (Map.Entry<UUID, int[]> nodeParts: reqNodes.entrySet()) {\n+            StatisticsGatheringRequest req = new StatisticsGatheringRequest(gatId, UUID.randomUUID(),\n+                new HashSet<>(keys), nodeParts.getValue());\n+            reqs.add(new StatisticsAddrRequest<>(req, locNodeId, nodeParts.getKey()));\n         }\n \n-        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n-                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+        return reqs;\n     }\n \n     /**\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM0MjY0Mg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549342642", "body": "Javadoc missed.", "bodyText": "Javadoc missed.", "bodyHTML": "<p dir=\"auto\">Javadoc missed.</p>", "author": "AMashenkov", "createdAt": "2020-12-28T13:10:18Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatisticsGatheringRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n+     *            If {@code null} - requests will be\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n+        UUID colId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions,\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts\n+    ) {\n+\n+        // NodeId to <Key to partitions on node> map\n+        Map<UUID, Map<StatisticsKeyMessage, int[]>> reqMap = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n+            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null); // TODO Null?\n+            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n+                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n+                    if (v == null)\n+                        v = new HashMap<>();\n+\n+                    Collection<StatisticsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n+\n+                    for (StatisticsKeyMessage key : grpKeys) {\n+                        int[] keyNodeParts = (failedPartitions == null) ? nodeParts.getValue() :\n+                                GridArrays.intersect(nodeParts.getValue(), failedPartitions.get(key));\n+\n+                        if (keyNodeParts.length > 0)\n+                            v.put(key, keyNodeParts);\n+                    }\n+\n+                    return v.isEmpty() ? null : v;\n+                });\n+        }\n+\n+        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs = new ArrayList<>();\n+        for (Map.Entry<UUID, Map<StatisticsKeyMessage, int[]>> nodeGpsParts: reqMap.entrySet()) {\n+            if (nodeGpsParts.getValue().isEmpty())\n+                continue;\n+\n+            StatisticsGatheringRequest req = prepareRequest(colId, nodeGpsParts.getValue());\n+            reqs.add(new StatisticsAddrRequest<>(req, nodeGpsParts.getKey()));\n+        }\n+\n+        return reqs;\n+    }\n+\n+    /**\n+     * Get all nodes where specified cache grous located.\n+     *\n+     * @param grps Cache groups.\n+     * @return Set of node ids.\n+     */\n+    public static Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys(Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grps) {\n+        Map<UUID, Collection<StatisticsKeyMessage>> res = new HashMap<>();\n+\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpKeys : grps.entrySet()) {\n+            CacheGroupContext grp = grpKeys.getKey();\n+            AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+            List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+            assignments.forEach(nodes -> nodes.forEach(clusterNode -> res.compute(clusterNode.id(), (k, v) -> {\n+                if (v == null)\n+                    v = new HashSet<>();\n+\n+                v.addAll(grpKeys.getValue());\n+\n+                return v;\n+            })));\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Generate statistics clear requests.\n+     *\n+     * @param keys Keys to clean statistics by.\n+     * @return Collection of addressed statistics clear requests.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public Collection<StatisticsAddrRequest<StatisticsClearRequest>> generateClearRequests(\n+        Collection<StatisticsKeyMessage> keys\n+    ) throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts = extractGroups(keys);\n+        Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys = nodeKeys(grpContexts);\n+\n+        return nodeKeys.entrySet().stream().map(node -> new StatisticsAddrRequest<>(\n+            new StatisticsClearRequest(UUID.randomUUID(), new ArrayList<>(node.getValue())), node.getKey()))\n+                .collect(Collectors.toList());\n+    }\n+\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param gatId Gathering id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    protected Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n+        UUID gatId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions", "originalCommit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex f0bc33ee4ba..4210ae9137b 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -247,18 +251,20 @@ public class IgniteStatisticsHelper {\n      * Generate statistics collection requests by given keys.\n      *\n      * @param gatId Gathering id.\n+     * @param locNodeId Local node id.\n      * @param keys Collection of keys to collect statistics by.\n      * @return Collection of statistics collection addressed request.\n      * @throws IgniteCheckedException In case of errors.\n      */\n     protected Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n         UUID gatId,\n+        UUID locNodeId,\n         Collection<StatisticsKeyMessage> keys,\n         Map<StatisticsKeyMessage, int[]> failedPartitions\n     ) throws IgniteCheckedException {\n         Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts = extractGroups(keys);\n \n-        return generateCollectionRequests(gatId, keys, failedPartitions, grpContexts);\n+        return generateCollectionRequests(gatId, locNodeId, keys, failedPartitions, grpContexts);\n     }\n \n     /**\n", "next_change": {"commit": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 4210ae9137b..86d3d41f996 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -246,27 +295,80 @@ public class IgniteStatisticsHelper {\n                 .collect(Collectors.toList());\n     }\n \n-\n     /**\n-     * Generate statistics collection requests by given keys.\n+     * Generate collection of statistics propagation messages to send collected partiton level statistics to backup\n+     * nodes. Can be called for single cache group and partition statistics only.\n      *\n-     * @param gatId Gathering id.\n      * @param locNodeId Local node id.\n-     * @param keys Collection of keys to collect statistics by.\n-     * @return Collection of statistics collection addressed request.\n-     * @throws IgniteCheckedException In case of errors.\n+     * @param key Statistics key by which it was collected.\n+     * @param objStats Collection of object statistics (for the same partition).\n+     * @return Collection of propagation messages.\n      */\n-    protected Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n-        UUID gatId,\n+    public Collection<StatisticsAddrRequest<StatisticsPropagationMessage>> generatePropagationMessages(\n         UUID locNodeId,\n-        Collection<StatisticsKeyMessage> keys,\n-        Map<StatisticsKeyMessage, int[]> failedPartitions\n+        StatisticsKeyMessage key,\n+        Collection<ObjectPartitionStatisticsImpl> objStats\n     ) throws IgniteCheckedException {\n-        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts = extractGroups(keys);\n+        List<StatisticsObjectData> objData = new ArrayList<>(objStats.size());\n+        objStats.forEach(ops -> {\n+            try {\n+                objData.add(StatisticsUtils.toObjectData(key, StatisticsType.PARTITION, ops));\n+            }\n+            catch (IgniteCheckedException e) {\n+                // TODO: log\n+            }\n+        });\n+\n+        StatisticsPropagationMessage msg = new StatisticsPropagationMessage(objData);\n \n-        return generateCollectionRequests(gatId, locNodeId, keys, failedPartitions, grpContexts);\n+        int partId = objStats.iterator().next().partId();\n+        CacheGroupContext grpCtx = getGroupContext(key);\n+        Map<UUID, int[]> nodePartitions = nodePartitions(grpCtx, Collections.singleton(partId), false);\n+\n+        return nodePartitions.keySet().stream().map(nodeId -> new StatisticsAddrRequest(msg, locNodeId, nodeId))\n+            .collect(Collectors.toList());\n     }\n \n+    public Collection<StatisticsAddrRequest<StatisticsPropagationMessage>> generateGlobalPropagationMessages(\n+        UUID locNodeId,\n+        Map<StatisticsKeyMessage, ObjectStatisticsImpl> objStats\n+    ) throws IgniteCheckedException {\n+        Map<StatisticsKeyMessage, StatisticsObjectData> objData = new HashMap<>(objStats.size());\n+        objStats.forEach((k, v) -> {\n+            try {\n+                objData.put(k, StatisticsUtils.toObjectData(k, StatisticsType.GLOBAL, v));\n+            }\n+            catch (IgniteCheckedException e) {\n+                // TODO: log\n+            }\n+        });\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpsKeys = extractGroups(objStats.keySet());\n+        Map<CacheGroupContext, Collection<StatisticsObjectData>> grpsData = new HashMap<>(grpsKeys.size());\n+\n+        grpsKeys.forEach((gpr, keys) -> {\n+            Collection<StatisticsObjectData> stats = keys.stream().map(objData::get).collect(Collectors.toList());\n+            grpsData.put(gpr, stats);\n+        });\n+\n+        Map<UUID, Collection<StatisticsObjectData>> reqMap = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsObjectData>> grpKeys : grpsData.entrySet()) {\n+            Set<UUID> grpNodes = nodes(grpKeys.getKey());\n+            grpNodes.forEach(node -> reqMap.compute(node, (k, v) -> {\n+                if (v == null)\n+                    v = new HashSet<>();\n+\n+                v.addAll(grpKeys.getValue());\n+                return v;\n+            }));\n+        }\n+\n+        return reqMap.entrySet().stream().map(e -> new StatisticsAddrRequest(\n+            new StatisticsPropagationMessage(new ArrayList<>(e.getValue())), locNodeId, e.getKey()))\n+                .collect(Collectors.toList());\n+    }\n+\n+\n+\n     /**\n      * Extract all partitions from specified statistics collection requests.\n      *\n", "next_change": {"commit": "7ef165002105dd10417170217e86d65771c524bb", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 86d3d41f996..b215186973d 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -367,40 +322,6 @@ public class IgniteStatisticsHelper {\n                 .collect(Collectors.toList());\n     }\n \n-\n-\n-    /**\n-     * Extract all partitions from specified statistics collection requests.\n-     *\n-     * @param reqs Failed request to extract partitions from.\n-     * @return Map StatisticsKeyMessage to List of corresponding partitions.\n-     */\n-    public static Map<StatisticsKeyMessage, int[]> extractFailed(StatisticsGatheringRequest[] reqs) {\n-        Map<StatisticsKeyMessage, List<Integer>> res = new HashMap<>();\n-\n-        UUID colId = null;\n-        for (StatisticsGatheringRequest req : reqs) {\n-\n-            assert colId == null || colId.equals(req.gatId());\n-            colId = req.gatId();\n-\n-            for (Map.Entry<StatisticsKeyMessage, int[]> keyEntry : req.keys().entrySet()) {\n-                res.compute(keyEntry.getKey(), (k, v) -> {\n-                    if (v == null)\n-                        v = new ArrayList<>();\n-\n-                    for (int i = 0; i < keyEntry.getValue().length; i++)\n-                        v.add(keyEntry.getValue()[i]);\n-\n-                    return v;\n-                });\n-            }\n-        }\n-\n-        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n-                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n-    }\n-\n     /**\n      * Generate statistics collection requests by given keys.\n      *\n", "next_change": {"commit": "05b732cd7e8840c429c48f5561e7c98e0289bcf6", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex b215186973d..9cf548264e4 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -317,30 +336,33 @@ public class IgniteStatisticsHelper {\n             }));\n         }\n \n-        return reqMap.entrySet().stream().map(e -> new StatisticsAddrRequest(\n-            new StatisticsPropagationMessage(new ArrayList<>(e.getValue())), locNodeId, e.getKey()))\n-                .collect(Collectors.toList());\n+        List<StatisticsAddrRequest<StatisticsPropagationMessage>> res = new ArrayList<>(reqMap.size());\n+        for (Map.Entry<UUID, Collection<StatisticsObjectData>> nodeReq : reqMap.entrySet()) {\n+            StatisticsPropagationMessage msg = new StatisticsPropagationMessage(new ArrayList<>(nodeReq.getValue()));\n+            res.add(new StatisticsAddrRequest<>(msg, locNodeId, nodeReq.getKey()));\n+        }\n+\n+        return res;\n     }\n \n     /**\n      * Generate statistics collection requests by given keys.\n      *\n      * @param gatId Gathering id.\n-     * @param locNodeId Local node id.\n      * @param keys Collection of keys to collect statistics by.\n+     * @param partitions Partitions to collect statistics by.\n      * @return Collection of statistics collection addressed request.\n      * @throws IgniteCheckedException In case of errors.\n      */\n     protected Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n             UUID gatId,\n-            UUID locNodeId,\n             Collection<StatisticsKeyMessage> keys,\n-            Collection<Integer> failedPartitions\n+            Collection<Integer> partitions\n     ) throws IgniteCheckedException {\n         Map<UUID, Map<StatisticsKeyMessage, int[]>> reqMap = new HashMap<>();\n         CacheGroupContext grpCtx = getGroupContext(keys.iterator().next());\n \n-        Map<UUID, int[]> reqNodes = nodePartitions(grpCtx, failedPartitions, true);\n+        Map<UUID, int[]> reqNodes = nodePartitions(grpCtx, partitions, true);\n \n         Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs = new ArrayList<>();\n \n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM0MjkwMQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549342901", "body": "Arrays.asList() ?", "bodyText": "Arrays.asList() ?", "bodyHTML": "<p dir=\"auto\">Arrays.asList() ?</p>", "author": "AMashenkov", "createdAt": "2020-12-28T13:11:26Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatisticsGatheringRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n+     *            If {@code null} - requests will be\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n+        UUID colId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions,\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts\n+    ) {\n+\n+        // NodeId to <Key to partitions on node> map\n+        Map<UUID, Map<StatisticsKeyMessage, int[]>> reqMap = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n+            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null); // TODO Null?\n+            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n+                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n+                    if (v == null)\n+                        v = new HashMap<>();\n+\n+                    Collection<StatisticsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n+\n+                    for (StatisticsKeyMessage key : grpKeys) {\n+                        int[] keyNodeParts = (failedPartitions == null) ? nodeParts.getValue() :\n+                                GridArrays.intersect(nodeParts.getValue(), failedPartitions.get(key));\n+\n+                        if (keyNodeParts.length > 0)\n+                            v.put(key, keyNodeParts);\n+                    }\n+\n+                    return v.isEmpty() ? null : v;\n+                });\n+        }\n+\n+        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs = new ArrayList<>();\n+        for (Map.Entry<UUID, Map<StatisticsKeyMessage, int[]>> nodeGpsParts: reqMap.entrySet()) {\n+            if (nodeGpsParts.getValue().isEmpty())\n+                continue;\n+\n+            StatisticsGatheringRequest req = prepareRequest(colId, nodeGpsParts.getValue());\n+            reqs.add(new StatisticsAddrRequest<>(req, nodeGpsParts.getKey()));\n+        }\n+\n+        return reqs;\n+    }\n+\n+    /**\n+     * Get all nodes where specified cache grous located.\n+     *\n+     * @param grps Cache groups.\n+     * @return Set of node ids.\n+     */\n+    public static Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys(Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grps) {\n+        Map<UUID, Collection<StatisticsKeyMessage>> res = new HashMap<>();\n+\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpKeys : grps.entrySet()) {\n+            CacheGroupContext grp = grpKeys.getKey();\n+            AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+            List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+            assignments.forEach(nodes -> nodes.forEach(clusterNode -> res.compute(clusterNode.id(), (k, v) -> {\n+                if (v == null)\n+                    v = new HashSet<>();\n+\n+                v.addAll(grpKeys.getValue());\n+\n+                return v;\n+            })));\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Generate statistics clear requests.\n+     *\n+     * @param keys Keys to clean statistics by.\n+     * @return Collection of addressed statistics clear requests.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public Collection<StatisticsAddrRequest<StatisticsClearRequest>> generateClearRequests(\n+        Collection<StatisticsKeyMessage> keys\n+    ) throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts = extractGroups(keys);\n+        Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys = nodeKeys(grpContexts);\n+\n+        return nodeKeys.entrySet().stream().map(node -> new StatisticsAddrRequest<>(\n+            new StatisticsClearRequest(UUID.randomUUID(), new ArrayList<>(node.getValue())), node.getKey()))\n+                .collect(Collectors.toList());\n+    }\n+\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param gatId Gathering id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    protected Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n+        UUID gatId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions\n+    ) throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts = extractGroups(keys);\n+\n+        return generateCollectionRequests(gatId, keys, failedPartitions, grpContexts);\n+    }\n+\n+    /**\n+     * Extract all partitions from specified statistics collection requests.\n+     *\n+     * @param reqs Failed request to extract partitions from.\n+     * @return Map StatisticsKeyMessage to List of corresponding partitions.\n+     */\n+    public static Map<StatisticsKeyMessage, int[]> extractFailed(StatisticsGatheringRequest[] reqs) {\n+        Map<StatisticsKeyMessage, List<Integer>> res = new HashMap<>();\n+\n+        UUID colId = null;\n+        for (StatisticsGatheringRequest req : reqs) {\n+\n+            assert colId == null || colId.equals(req.gatId());\n+            colId = req.gatId();\n+\n+            for (Map.Entry<StatisticsKeyMessage, int[]> keyEntry : req.keys().entrySet()) {\n+                res.compute(keyEntry.getKey(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+\n+                    for (int i = 0; i < keyEntry.getValue().length; i++)\n+                        v.add(keyEntry.getValue()[i]);", "originalCommit": "ec535bcea1a8f2a494b1085f6fbdbeb761edb98d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7ef165002105dd10417170217e86d65771c524bb", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex f0bc33ee4ba..b215186973d 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -227,70 +233,124 @@ public class IgniteStatisticsHelper {\n     /**\n      * Generate statistics clear requests.\n      *\n+     * @param locNodeId Local node id.\n      * @param keys Keys to clean statistics by.\n      * @return Collection of addressed statistics clear requests.\n      * @throws IgniteCheckedException In case of errors.\n      */\n     public Collection<StatisticsAddrRequest<StatisticsClearRequest>> generateClearRequests(\n+        UUID locNodeId,\n         Collection<StatisticsKeyMessage> keys\n     ) throws IgniteCheckedException {\n         Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts = extractGroups(keys);\n         Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys = nodeKeys(grpContexts);\n \n         return nodeKeys.entrySet().stream().map(node -> new StatisticsAddrRequest<>(\n-            new StatisticsClearRequest(UUID.randomUUID(), new ArrayList<>(node.getValue())), node.getKey()))\n+            new StatisticsClearRequest(UUID.randomUUID(), new ArrayList<>(node.getValue())), locNodeId, node.getKey()))\n                 .collect(Collectors.toList());\n     }\n \n+    /**\n+     * Generate collection of statistics propagation messages to send collected partiton level statistics to backup\n+     * nodes. Can be called for single cache group and partition statistics only.\n+     *\n+     * @param locNodeId Local node id.\n+     * @param key Statistics key by which it was collected.\n+     * @param objStats Collection of object statistics (for the same partition).\n+     * @return Collection of propagation messages.\n+     */\n+    public Collection<StatisticsAddrRequest<StatisticsPropagationMessage>> generatePropagationMessages(\n+        UUID locNodeId,\n+        StatisticsKeyMessage key,\n+        Collection<ObjectPartitionStatisticsImpl> objStats\n+    ) throws IgniteCheckedException {\n+        List<StatisticsObjectData> objData = new ArrayList<>(objStats.size());\n+        objStats.forEach(ops -> {\n+            try {\n+                objData.add(StatisticsUtils.toObjectData(key, StatisticsType.PARTITION, ops));\n+            }\n+            catch (IgniteCheckedException e) {\n+                // TODO: log\n+            }\n+        });\n+\n+        StatisticsPropagationMessage msg = new StatisticsPropagationMessage(objData);\n+\n+        int partId = objStats.iterator().next().partId();\n+        CacheGroupContext grpCtx = getGroupContext(key);\n+        Map<UUID, int[]> nodePartitions = nodePartitions(grpCtx, Collections.singleton(partId), false);\n+\n+        return nodePartitions.keySet().stream().map(nodeId -> new StatisticsAddrRequest(msg, locNodeId, nodeId))\n+            .collect(Collectors.toList());\n+    }\n+\n+    public Collection<StatisticsAddrRequest<StatisticsPropagationMessage>> generateGlobalPropagationMessages(\n+        UUID locNodeId,\n+        Map<StatisticsKeyMessage, ObjectStatisticsImpl> objStats\n+    ) throws IgniteCheckedException {\n+        Map<StatisticsKeyMessage, StatisticsObjectData> objData = new HashMap<>(objStats.size());\n+        objStats.forEach((k, v) -> {\n+            try {\n+                objData.put(k, StatisticsUtils.toObjectData(k, StatisticsType.GLOBAL, v));\n+            }\n+            catch (IgniteCheckedException e) {\n+                // TODO: log\n+            }\n+        });\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpsKeys = extractGroups(objStats.keySet());\n+        Map<CacheGroupContext, Collection<StatisticsObjectData>> grpsData = new HashMap<>(grpsKeys.size());\n+\n+        grpsKeys.forEach((gpr, keys) -> {\n+            Collection<StatisticsObjectData> stats = keys.stream().map(objData::get).collect(Collectors.toList());\n+            grpsData.put(gpr, stats);\n+        });\n+\n+        Map<UUID, Collection<StatisticsObjectData>> reqMap = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsObjectData>> grpKeys : grpsData.entrySet()) {\n+            Set<UUID> grpNodes = nodes(grpKeys.getKey());\n+            grpNodes.forEach(node -> reqMap.compute(node, (k, v) -> {\n+                if (v == null)\n+                    v = new HashSet<>();\n+\n+                v.addAll(grpKeys.getValue());\n+                return v;\n+            }));\n+        }\n+\n+        return reqMap.entrySet().stream().map(e -> new StatisticsAddrRequest(\n+            new StatisticsPropagationMessage(new ArrayList<>(e.getValue())), locNodeId, e.getKey()))\n+                .collect(Collectors.toList());\n+    }\n \n     /**\n      * Generate statistics collection requests by given keys.\n      *\n      * @param gatId Gathering id.\n+     * @param locNodeId Local node id.\n      * @param keys Collection of keys to collect statistics by.\n      * @return Collection of statistics collection addressed request.\n      * @throws IgniteCheckedException In case of errors.\n      */\n     protected Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n-        UUID gatId,\n-        Collection<StatisticsKeyMessage> keys,\n-        Map<StatisticsKeyMessage, int[]> failedPartitions\n+            UUID gatId,\n+            UUID locNodeId,\n+            Collection<StatisticsKeyMessage> keys,\n+            Collection<Integer> failedPartitions\n     ) throws IgniteCheckedException {\n-        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts = extractGroups(keys);\n-\n-        return generateCollectionRequests(gatId, keys, failedPartitions, grpContexts);\n-    }\n-\n-    /**\n-     * Extract all partitions from specified statistics collection requests.\n-     *\n-     * @param reqs Failed request to extract partitions from.\n-     * @return Map StatisticsKeyMessage to List of corresponding partitions.\n-     */\n-    public static Map<StatisticsKeyMessage, int[]> extractFailed(StatisticsGatheringRequest[] reqs) {\n-        Map<StatisticsKeyMessage, List<Integer>> res = new HashMap<>();\n-\n-        UUID colId = null;\n-        for (StatisticsGatheringRequest req : reqs) {\n-\n-            assert colId == null || colId.equals(req.gatId());\n-            colId = req.gatId();\n+        Map<UUID, Map<StatisticsKeyMessage, int[]>> reqMap = new HashMap<>();\n+        CacheGroupContext grpCtx = getGroupContext(keys.iterator().next());\n \n-            for (Map.Entry<StatisticsKeyMessage, int[]> keyEntry : req.keys().entrySet()) {\n-                res.compute(keyEntry.getKey(), (k, v) -> {\n-                    if (v == null)\n-                        v = new ArrayList<>();\n+        Map<UUID, int[]> reqNodes = nodePartitions(grpCtx, failedPartitions, true);\n \n-                    for (int i = 0; i < keyEntry.getValue().length; i++)\n-                        v.add(keyEntry.getValue()[i]);\n+        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs = new ArrayList<>();\n \n-                    return v;\n-                });\n-            }\n+        for (Map.Entry<UUID, int[]> nodeParts: reqNodes.entrySet()) {\n+            StatisticsGatheringRequest req = new StatisticsGatheringRequest(gatId, UUID.randomUUID(),\n+                new HashSet<>(keys), nodeParts.getValue());\n+            reqs.add(new StatisticsAddrRequest<>(req, locNodeId, nodeParts.getKey()));\n         }\n \n-        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n-                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+        return reqs;\n     }\n \n     /**\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM1NzAzNA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549357034", "body": "```suggestion\r\n        else if (!GridCacheUtils.isPersistenceEnabled(ctx.config()))\r\n            store = new IgniteStatisticsInMemoryStoreImpl(ctx::log);\r\n        else\r\n            store = new IgniteStatisticsPersistenceStoreImpl(ctx.internalSubscriptionProcessor(),  ctx.cache().context().database(), ctx::log);\r\n```", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    else if (db == null)\n          \n          \n            \n                        store = new IgniteStatisticsInMemoryStoreImpl(ctx::log);\n          \n          \n            \n                    else\n          \n          \n            \n                        store = new IgniteStatisticsPersistenceStoreImpl(ctx.internalSubscriptionProcessor(), db, ctx::log);\n          \n          \n            \n                    else if (!GridCacheUtils.isPersistenceEnabled(ctx.config()))\n          \n          \n            \n                        store = new IgniteStatisticsInMemoryStoreImpl(ctx::log);\n          \n          \n            \n                    else\n          \n          \n            \n                        store = new IgniteStatisticsPersistenceStoreImpl(ctx.internalSubscriptionProcessor(),  ctx.cache().context().database(), ctx::log);", "bodyHTML": "  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">        <span class=\"pl-k\">else</span> <span class=\"pl-k\">if</span> (<span class=\"x x-first\">db </span><span class=\"pl-k x\">==</span><span class=\"x\"> </span><span class=\"pl-c1 x x-last\">null</span>)</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">            store <span class=\"pl-k\">=</span> <span class=\"pl-k\">new</span> <span class=\"pl-smi\">IgniteStatisticsInMemoryStoreImpl</span>(ctx<span class=\"pl-k\">::</span>log);</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">        <span class=\"pl-k\">else</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">            store <span class=\"pl-k\">=</span> <span class=\"pl-k\">new</span> <span class=\"pl-smi\">IgniteStatisticsPersistenceStoreImpl</span>(ctx<span class=\"pl-k\">.</span>internalSubscriptionProcessor(), <span class=\"x x-first x-last\">db</span>, ctx<span class=\"pl-k\">::</span>log);</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">        <span class=\"pl-k\">else</span> <span class=\"pl-k\">if</span> (<span class=\"pl-k x x-first\">!</span><span class=\"pl-smi x\">GridCacheUtils</span><span class=\"pl-k x\">.</span><span class=\"x\">isPersistenceEnabled(ctx</span><span class=\"pl-k x\">.</span><span class=\"x x-last\">config())</span>)</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">            store <span class=\"pl-k\">=</span> <span class=\"pl-k\">new</span> <span class=\"pl-smi\">IgniteStatisticsInMemoryStoreImpl</span>(ctx<span class=\"pl-k\">::</span>log);</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">        <span class=\"pl-k\">else</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">            store <span class=\"pl-k\">=</span> <span class=\"pl-k\">new</span> <span class=\"pl-smi\">IgniteStatisticsPersistenceStoreImpl</span>(ctx<span class=\"pl-k\">.</span>internalSubscriptionProcessor(), <span class=\"x x-first\"> ctx</span><span class=\"pl-k x\">.</span><span class=\"x\">cache()</span><span class=\"pl-k x\">.</span><span class=\"x\">context()</span><span class=\"pl-k x\">.</span><span class=\"x x-last\">database()</span>, ctx<span class=\"pl-k\">::</span>log);</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "AMashenkov", "createdAt": "2020-12-28T13:57:56Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -68,14 +89,52 @@\n     public IgniteStatisticsManagerImpl(GridKernalContext ctx, SchemaManager schemaMgr) {\n         this.ctx = ctx;\n         this.schemaMgr = schemaMgr;\n+        helper = new IgniteStatisticsHelper(schemaMgr);\n \n         log = ctx.log(IgniteStatisticsManagerImpl.class);\n \n-        boolean storeData = !(ctx.config().isClientMode() || ctx.isDaemon());\n         IgniteCacheDatabaseSharedManager db = (GridCacheUtils.isPersistenceEnabled(ctx.config())) ?\n                 ctx.cache().context().database() : null;\n-        statsRepos = new IgniteStatisticsRepositoryImpl(storeData, db, ctx.internalSubscriptionProcessor(), this,\n-                ctx::log);\n+\n+\n+        // nodeLeftLsnr = new NodeLeftListener();\n+        IgniteThreadPoolExecutor gatMgmtPool = new IgniteThreadPoolExecutor(\"stat-gat-mgmt-pool\",\n+                ctx.igniteInstanceName(),\n+                0,\n+                STATS_POOL_SIZE,\n+                IgniteConfiguration.DFLT_THREAD_KEEP_ALIVE_TIME,\n+                new LinkedBlockingQueue<>(),\n+                GridIoPolicy.UNDEFINED,\n+                ctx.uncaughtExceptionHandler()\n+        );\n+\n+        IgniteThreadPoolExecutor msgMgmtPool = new IgniteThreadPoolExecutor(\"stat-msg-mgmt-pool\",\n+                ctx.igniteInstanceName(),\n+                0,\n+                1,\n+                IgniteConfiguration.DFLT_THREAD_KEEP_ALIVE_TIME,\n+                new LinkedBlockingQueue<>(),\n+                GridIoPolicy.UNDEFINED,\n+                ctx.uncaughtExceptionHandler()\n+        );\n+        statCrawler = new StatisticsGatheringRequestCrawlerImpl(ctx.localNodeId(), this, ctx.event(), ctx.io(),\n+            helper, msgMgmtPool, ctx::log);\n+        statGathering = new StatisticsGatheringImpl(schemaMgr, ctx.discovery(), ctx.query(), statCrawler, gatMgmtPool,\n+            ctx::log);\n+\n+        boolean storeData = !(ctx.config().isClientMode() || ctx.isDaemon());\n+        IgniteStatisticsStore store;\n+        if (!storeData)\n+            store = new IgniteStatisticsDummyStoreImpl(ctx::log);\n+        else if (db == null)\n+            store = new IgniteStatisticsInMemoryStoreImpl(ctx::log);\n+        else\n+            store = new IgniteStatisticsPersistenceStoreImpl(ctx.internalSubscriptionProcessor(), db, ctx::log);", "originalCommit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "05b732cd7e8840c429c48f5561e7c98e0289bcf6", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 1f98ad5ca73..ab2c41eca80 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -133,7 +130,7 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n \n         statsRepos = new IgniteStatisticsRepositoryImpl(store, this, statGathering, ctx::log);\n \n-        store.setRepository(statsRepos);\n+        store.repository(statsRepos);\n \n     }\n \n", "next_change": {"commit": "b385286d37cb759a2a308a055b12f32c5c22a976", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex ab2c41eca80..d68901451dd 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -131,6 +131,7 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n         statsRepos = new IgniteStatisticsRepositoryImpl(store, this, statGathering, ctx::log);\n \n         store.repository(statsRepos);\n+        statGathering.repository(statsRepos);\n \n     }\n \n", "next_change": {"commit": "17a54090bea4d97c122cf06d6be8e60177006519", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex d68901451dd..636f380904e 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -132,7 +131,6 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n \n         store.repository(statsRepos);\n         statGathering.repository(statsRepos);\n-\n     }\n \n     /**\n", "next_change": {"commit": "efd6b5e9f1f91625c2e6106b4c75522dada68b46", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 636f380904e..8f406905473 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -127,7 +127,7 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n         else\n             store = new IgniteStatisticsPersistenceStoreImpl(ctx.internalSubscriptionProcessor(), db, ctx::log);\n \n-        statsRepos = new IgniteStatisticsRepositoryImpl(store, this, statGathering, ctx::log);\n+        statsRepos = new IgniteStatisticsRepositoryImpl(store, statGathering, ctx::log);\n \n         store.repository(statsRepos);\n         statGathering.repository(statsRepos);\n", "next_change": {"commit": "48b736c4cf138d5db12978e2004c446e26e1f097", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 8f406905473..e81fccec5de 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -125,12 +121,16 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n         else if (db == null)\n             store = new IgniteStatisticsInMemoryStoreImpl(ctx::log);\n         else\n-            store = new IgniteStatisticsPersistenceStoreImpl(ctx.internalSubscriptionProcessor(), db, ctx::log);\n+            store = new IgniteStatisticsPersistenceStoreImpl(ctx.internalSubscriptionProcessor(), db,\n+                (k, s) -> this.statisticsRepository().cacheLocalStatistics(k, s), ctx::log);\n+\n+        statsRepos = new IgniteStatisticsRepositoryImpl(store, helper, ctx::log);\n \n-        statsRepos = new IgniteStatisticsRepositoryImpl(store, statGathering, ctx::log);\n+        statCrawler = new StatisticsGatheringRequestCrawlerImpl(ctx.localNodeId(), this, ctx.event(), ctx.io(),\n+            helper, msgMgmtPool, ctx::log);\n+        statGathering = new StatisticsGatheringImpl(schemaMgr, ctx.discovery(), ctx.query(), statsRepos, statCrawler,\n+            gatMgmtPool, ctx::log);\n \n-        store.repository(statsRepos);\n-        statGathering.repository(statsRepos);\n     }\n \n     /**\n", "next_change": null}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM3MTMxMA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549371310", "body": "Javadoc", "bodyText": "Javadoc", "bodyHTML": "<p dir=\"auto\">Javadoc</p>", "author": "AMashenkov", "createdAt": "2020-12-28T14:41:31Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java", "diffHunk": "@@ -0,0 +1,554 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.events.DiscoveryEvent;\n+import org.apache.ignite.events.Event;\n+import org.apache.ignite.events.EventType;\n+import org.apache.ignite.internal.GridTopic;\n+import org.apache.ignite.internal.managers.communication.GridIoManager;\n+import org.apache.ignite.internal.managers.communication.GridIoPolicy;\n+import org.apache.ignite.internal.managers.communication.GridMessageListener;\n+import org.apache.ignite.internal.managers.eventstorage.GridEventStorageManager;\n+import org.apache.ignite.internal.managers.eventstorage.GridLocalEventListener;\n+import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionTopology;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.CancelStatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGetRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGetResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsPropagationMessage;\n+import org.apache.ignite.internal.util.typedef.F;\n+import org.apache.ignite.lang.IgniteBiTuple;\n+import org.apache.ignite.plugin.extensions.communication.Message;\n+import org.apache.ignite.thread.IgniteThreadPoolExecutor;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.function.Function;\n+\n+public class StatisticsGatheringRequestCrawlerImpl implements StatisticsGatheringRequestCrawler, GridLocalEventListener,", "originalCommit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTA1MTg1OQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555051859", "bodyText": "done", "author": "Berkof", "createdAt": "2021-01-11T13:38:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM3MTMxMA=="}], "type": "inlineReview", "revised_code": {"commit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java\nindex e5d14a65efd..433db173b48 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java\n", "chunk": "@@ -39,6 +39,9 @@ import java.util.concurrent.ConcurrentHashMap;\n import java.util.concurrent.ConcurrentMap;\n import java.util.function.Function;\n \n+/**\n+ * Implementation of Statistics gathering request crawler with addition event and message listeners handling.\n+ */\n public class StatisticsGatheringRequestCrawlerImpl implements StatisticsGatheringRequestCrawler, GridLocalEventListener,\n         GridMessageListener {\n     /** Statistics related messages topic name. */\n", "next_change": {"commit": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java\nindex 433db173b48..dab4dff9ab3 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java\n", "chunk": "@@ -38,6 +35,7 @@ import java.util.UUID;\n import java.util.concurrent.ConcurrentHashMap;\n import java.util.concurrent.ConcurrentMap;\n import java.util.function.Function;\n+import java.util.stream.Collectors;\n \n /**\n  * Implementation of Statistics gathering request crawler with addition event and message listeners handling.\n", "next_change": {"commit": "7ef165002105dd10417170217e86d65771c524bb", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java\nindex dab4dff9ab3..bf0f1855bca 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java\n", "chunk": "@@ -20,31 +19,30 @@ import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGetRe\n import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n import org.apache.ignite.internal.processors.query.stat.messages.StatisticsPropagationMessage;\n+import org.apache.ignite.internal.util.GridArrays;\n import org.apache.ignite.internal.util.typedef.F;\n import org.apache.ignite.lang.IgniteBiTuple;\n import org.apache.ignite.plugin.extensions.communication.Message;\n import org.apache.ignite.thread.IgniteThreadPoolExecutor;\n-\n import java.util.ArrayList;\n import java.util.Arrays;\n import java.util.Collection;\n import java.util.HashMap;\n+import java.util.HashSet;\n import java.util.List;\n import java.util.Map;\n+import java.util.Set;\n import java.util.UUID;\n import java.util.concurrent.ConcurrentHashMap;\n import java.util.concurrent.ConcurrentMap;\n import java.util.function.Function;\n-import java.util.stream.Collectors;\n+import static org.apache.ignite.internal.GridTopic.TOPIC_STATISTICS;\n \n /**\n  * Implementation of Statistics gathering request crawler with addition event and message listeners handling.\n  */\n public class StatisticsGatheringRequestCrawlerImpl implements StatisticsGatheringRequestCrawler, GridLocalEventListener,\n         GridMessageListener {\n-    /** Statistics related messages topic name. */\n-    private static final Object TOPIC = GridTopic.TOPIC_CACHE.topic(\"statistics\");\n-\n     /** Logger. */\n     private final IgniteLogger log;\n \n", "next_change": {"commit": "48b736c4cf138d5db12978e2004c446e26e1f097", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java\nindex bf0f1855bca..f0b456e06b7 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java\n", "chunk": "@@ -43,6 +43,9 @@ import static org.apache.ignite.internal.GridTopic.TOPIC_STATISTICS;\n  */\n public class StatisticsGatheringRequestCrawlerImpl implements StatisticsGatheringRequestCrawler, GridLocalEventListener,\n         GridMessageListener {\n+    /** Maximum number of attempts to send statistics gathering requests. */\n+    public static final int MAX_SEND_RETRIES = 10;\n+\n     /** Logger. */\n     private final IgniteLogger log;\n \n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM3MzAxNw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549373017", "body": "Is it expected request will be processed in Query Pool?", "bodyText": "Is it expected request will be processed in Query Pool?", "bodyHTML": "<p dir=\"auto\">Is it expected request will be processed in Query Pool?</p>", "author": "AMashenkov", "createdAt": "2020-12-28T14:46:47Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java", "diffHunk": "@@ -0,0 +1,554 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.events.DiscoveryEvent;\n+import org.apache.ignite.events.Event;\n+import org.apache.ignite.events.EventType;\n+import org.apache.ignite.internal.GridTopic;\n+import org.apache.ignite.internal.managers.communication.GridIoManager;\n+import org.apache.ignite.internal.managers.communication.GridIoPolicy;\n+import org.apache.ignite.internal.managers.communication.GridMessageListener;\n+import org.apache.ignite.internal.managers.eventstorage.GridEventStorageManager;\n+import org.apache.ignite.internal.managers.eventstorage.GridLocalEventListener;\n+import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionTopology;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.CancelStatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGetRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGetResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsPropagationMessage;\n+import org.apache.ignite.internal.util.typedef.F;\n+import org.apache.ignite.lang.IgniteBiTuple;\n+import org.apache.ignite.plugin.extensions.communication.Message;\n+import org.apache.ignite.thread.IgniteThreadPoolExecutor;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.function.Function;\n+\n+public class StatisticsGatheringRequestCrawlerImpl implements StatisticsGatheringRequestCrawler, GridLocalEventListener,\n+        GridMessageListener {\n+    /** Statistics related messages topic name. */\n+    private static final Object TOPIC = GridTopic.TOPIC_CACHE.topic(\"statistics\");\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** Local node id. */\n+    private final UUID locNodeId;\n+\n+    /** Statistics manager. */\n+    private final IgniteStatisticsManagerImpl statMgr;\n+\n+    /** Event manager. */\n+    private final GridEventStorageManager eventMgr;\n+\n+    /** IO manager. */\n+    private final GridIoManager ioMgr;\n+\n+    /** Message management pool */\n+    private final IgniteThreadPoolExecutor msgMgmtPool;\n+\n+    /** Ignite statistics helper. */\n+    private final IgniteStatisticsHelper helper;\n+\n+    /** Remaining requests map reqId -> Request. Contains incoming requests too. */\n+    private final ConcurrentMap<UUID, StatisticsAddrRequest<StatisticsGatheringRequest>> remainingRequests =\n+            new ConcurrentHashMap<>();\n+\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param locNodeId Local node id.\n+     * @param statMgr Statistics manager.\n+     * @param eventMgr Event storage manager.\n+     * @param ioMgr Io manager.\n+     * @param helper Statistics helper.\n+     * @param msgMgmtPool Message processing thread pool.\n+     * @param logSupplier Log supplier.\n+     */\n+    public StatisticsGatheringRequestCrawlerImpl(\n+        UUID locNodeId,\n+        IgniteStatisticsManagerImpl statMgr,\n+        GridEventStorageManager eventMgr,\n+        GridIoManager ioMgr,\n+        IgniteStatisticsHelper helper,\n+        IgniteThreadPoolExecutor msgMgmtPool,\n+        Function<Class<?>, IgniteLogger> logSupplier\n+    ) {\n+        this.log = logSupplier.apply(StatisticsGatheringRequestCrawlerImpl.class);\n+        this.locNodeId = locNodeId;\n+        this.statMgr = statMgr;\n+        this.eventMgr = eventMgr;\n+        this.ioMgr = ioMgr;\n+        this.helper = helper;\n+        this.msgMgmtPool = msgMgmtPool;\n+\n+        eventMgr.addLocalEventListener(this, EventType.EVT_NODE_FAILED, EventType.EVT_NODE_LEFT);\n+        ioMgr.addMessageListener(TOPIC, this);\n+    }\n+\n+    /**\n+     * Stop request crawler manager.\n+     */\n+    public void stop() {\n+        if (msgMgmtPool != null) {\n+            List<Runnable> unfinishedTasks = msgMgmtPool.shutdownNow();\n+            if (!unfinishedTasks.isEmpty())\n+                log.warning(String.format(\"%d statistics collection request cancelled.\", unfinishedTasks.size()));\n+        }\n+    }\n+\n+    /**\n+     * Convert collection of addressed gathering request to map reqId to addressed request.\n+     *\n+     * @param reqs Collection of request to convert.\n+     * @return Map request id to request.\n+     */\n+    private Map<UUID, StatisticsAddrRequest<StatisticsGatheringRequest>> toReqIdMap(\n+        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs\n+    ) {\n+        Map<UUID, StatisticsAddrRequest<StatisticsGatheringRequest>> res = new HashMap<>();\n+\n+        reqs.forEach(r -> res.put(r.req().reqId(), r));\n+\n+        return res;\n+    }\n+\n+    /**\n+     * Send gathering requests by specified keys and gathering id:\n+     * 1) Generate requests by keys and failed partitions.\n+     * 2) Put generated request into remaining map and increment gathering counter.\n+     * 2) \"Send\" or schedule local request execution (if exists) - can't fail to send local one.\n+     * 3) Send remove requests\n+     *\n+     *\n+     * @param gatId Gathering id.\n+     * @param keys Keys to generate and send requests by.\n+     * @param failedPartitions Collection of failed partitions to resend or\n+     *     {@code null} if it need to send request to all partitions.\n+     */\n+    private void sendGatheringRequests(\n+        UUID gatId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions\n+    ) {\n+        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs = null;\n+        int cnt = 0;\n+        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> failedMsgs;\n+        do {\n+            try {\n+                reqs = helper.generateCollectionRequests(gatId, keys, failedPartitions);\n+            }\n+            catch (IgniteCheckedException e) {\n+                statMgr.cancelObjectStatisticsGathering(gatId);\n+\n+                return;\n+            }\n+\n+            Map<UUID, StatisticsAddrRequest<StatisticsGatheringRequest>> reqsMap = toReqIdMap(reqs);\n+\n+            remainingRequests.putAll(reqsMap);\n+\n+            // Process local request\n+            StatisticsAddrRequest<StatisticsGatheringRequest> locReq = reqs.stream().filter(\n+                    r -> locNodeId.equals(r.targetNodeId())).findAny().orElse(null);\n+            if (locReq != null)\n+                statMgr.gatherLocalObjectStatisticsAsync(gatId, locReq.req().reqId(), locReq.req().keys());\n+\n+            // Process remote requests\n+            failedMsgs = sendRequests(reqs);\n+\n+            if (F.isEmpty(failedMsgs))\n+                failedPartitions = null;\n+            else {\n+                failedMsgs.forEach(r -> remainingRequests.remove(r.req().reqId()));\n+\n+                failedPartitions = helper.extractFailed(failedMsgs.stream().map(StatisticsAddrRequest::req)\n+                        .toArray(StatisticsGatheringRequest[]::new));\n+            }\n+\n+\n+            if (cnt++ > 10) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Unable to send gathering requests for 10 times, cancel gathering %s\", gatId));\n+\n+                statMgr.cancelObjectStatisticsGathering(gatId);\n+            }\n+        }\n+        while (failedPartitions != null);\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void sendGatheringRequestsAsync(UUID gatId, Collection<StatisticsKeyMessage> keys) {\n+        msgMgmtPool.submit(() -> sendGatheringRequests(gatId, keys, null));\n+    }\n+\n+    /**\n+     * Send response to given request.\n+     *\n+     * @param reqId Request id to response to.\n+     * @param statistics Collected statistics.\n+     */\n+    private void sendGatheringResponse(\n+        UUID reqId,\n+        Map<IgniteBiTuple<StatisticsKeyMessage, ObjectStatisticsImpl>, int[]> statistics\n+    ) {\n+        StatisticsAddrRequest<StatisticsGatheringRequest> req =  remainingRequests.remove(reqId);\n+        if (req == null) {\n+            if (log.isDebugEnabled())\n+                log.debug(String.format(\"Dropping results to cancelled collection request %s\", reqId));\n+\n+            return;\n+        }\n+        UUID gatId = req.req().gatId();\n+\n+        Map<StatisticsObjectData, int[]> dataParts = new HashMap<>(statistics.size());\n+        statistics.forEach((k,v) -> {\n+            try {\n+                StatisticsObjectData data = StatisticsUtils.toObjectData(k.getKey(), StatisticsType.LOCAL, k.getValue());\n+\n+                dataParts.put(data, v);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Unable to format statistics %s.%s by request=%s gathering=%s\",\n+                            k.getKey().schema(), k.getKey().obj(), reqId, gatId));\n+\n+            }\n+        });\n+\n+\n+        if (locNodeId.equals(req.senderNodeId()))\n+            statMgr.registerLocalResult(gatId, dataParts);\n+        else {\n+            int parts = dataParts.values().stream().mapToInt(l -> l.length).sum();\n+            statMgr.onRemoteGatheringSend(gatid, parts);\n+            StatisticsGatheringResponse resp = new StatisticsGatheringResponse(req.req().gatId(), reqId, dataParts);\n+            safeSend(req.senderNodeId(), resp);\n+        }\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void sendGatheringResponseAsync(\n+        UUID reqId,\n+        Map<IgniteBiTuple<StatisticsKeyMessage, ObjectStatisticsImpl>, int[]> statistics\n+    ) {\n+        msgMgmtPool.submit(() -> sendGatheringResponse(reqId, statistics));\n+    }\n+\n+    /**\n+     * Send requests to target nodes (except of local one).\n+     *\n+     * @param reqs Collection of addressed requests to send.\n+     * @return Collection of addressed requests that has errors while sending or {@code null} if all requests was send\n+     * successfully.\n+     */\n+    private <T extends Message> Collection<StatisticsAddrRequest<T>> sendRequests(\n+        Collection<StatisticsAddrRequest<T>> reqs\n+    ) {\n+        Collection<StatisticsAddrRequest<T>> res = null;\n+\n+        for (StatisticsAddrRequest<T> req : reqs) {\n+            if (locNodeId.equals(req.targetNodeId()))\n+                continue;\n+\n+            try {\n+                ioMgr.sendToCustomTopic(req.targetNodeId(), TOPIC, req.req(), GridIoPolicy.QUERY_POOL);", "originalCommit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzQwOTEyOQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r557409129", "bodyText": "No, any request will be processed in separate statistics pools (messages or gathering)", "author": "Berkof", "createdAt": "2021-01-14T13:52:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM3MzAxNw=="}], "type": "inlineReview", "revised_code": {"commit": "7ef165002105dd10417170217e86d65771c524bb", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java\nindex e5d14a65efd..bf0f1855bca 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java\n", "chunk": "@@ -268,7 +358,7 @@ public class StatisticsGatheringRequestCrawlerImpl implements StatisticsGatherin\n                 continue;\n \n             try {\n-                ioMgr.sendToCustomTopic(req.targetNodeId(), TOPIC, req.req(), GridIoPolicy.QUERY_POOL);\n+                ioMgr.sendToCustomTopic(req.targetNodeId(), TOPIC_STATISTICS, req.req(), GridIoPolicy.MANAGEMENT_POOL);\n             }\n             catch (IgniteCheckedException e) {\n                 if (res == null)\n", "next_change": {"commit": "efd6b5e9f1f91625c2e6106b4c75522dada68b46", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java\nindex bf0f1855bca..aa6fe4c5763 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java\n", "chunk": "@@ -358,7 +365,7 @@ public class StatisticsGatheringRequestCrawlerImpl implements StatisticsGatherin\n                 continue;\n \n             try {\n-                ioMgr.sendToCustomTopic(req.targetNodeId(), TOPIC_STATISTICS, req.req(), GridIoPolicy.MANAGEMENT_POOL);\n+                send(req.targetNodeId(), req.req());\n             }\n             catch (IgniteCheckedException e) {\n                 if (res == null)\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM3NTA5OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549375098", "body": "Let's move constant to static final field.", "bodyText": "Let's move constant to static final field.", "bodyHTML": "<p dir=\"auto\">Let's move constant to static final field.</p>", "author": "AMashenkov", "createdAt": "2020-12-28T14:53:23Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java", "diffHunk": "@@ -0,0 +1,554 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.events.DiscoveryEvent;\n+import org.apache.ignite.events.Event;\n+import org.apache.ignite.events.EventType;\n+import org.apache.ignite.internal.GridTopic;\n+import org.apache.ignite.internal.managers.communication.GridIoManager;\n+import org.apache.ignite.internal.managers.communication.GridIoPolicy;\n+import org.apache.ignite.internal.managers.communication.GridMessageListener;\n+import org.apache.ignite.internal.managers.eventstorage.GridEventStorageManager;\n+import org.apache.ignite.internal.managers.eventstorage.GridLocalEventListener;\n+import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionTopology;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.CancelStatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGetRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGetResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsPropagationMessage;\n+import org.apache.ignite.internal.util.typedef.F;\n+import org.apache.ignite.lang.IgniteBiTuple;\n+import org.apache.ignite.plugin.extensions.communication.Message;\n+import org.apache.ignite.thread.IgniteThreadPoolExecutor;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.function.Function;\n+\n+public class StatisticsGatheringRequestCrawlerImpl implements StatisticsGatheringRequestCrawler, GridLocalEventListener,\n+        GridMessageListener {\n+    /** Statistics related messages topic name. */\n+    private static final Object TOPIC = GridTopic.TOPIC_CACHE.topic(\"statistics\");\n+\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** Local node id. */\n+    private final UUID locNodeId;\n+\n+    /** Statistics manager. */\n+    private final IgniteStatisticsManagerImpl statMgr;\n+\n+    /** Event manager. */\n+    private final GridEventStorageManager eventMgr;\n+\n+    /** IO manager. */\n+    private final GridIoManager ioMgr;\n+\n+    /** Message management pool */\n+    private final IgniteThreadPoolExecutor msgMgmtPool;\n+\n+    /** Ignite statistics helper. */\n+    private final IgniteStatisticsHelper helper;\n+\n+    /** Remaining requests map reqId -> Request. Contains incoming requests too. */\n+    private final ConcurrentMap<UUID, StatisticsAddrRequest<StatisticsGatheringRequest>> remainingRequests =\n+            new ConcurrentHashMap<>();\n+\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param locNodeId Local node id.\n+     * @param statMgr Statistics manager.\n+     * @param eventMgr Event storage manager.\n+     * @param ioMgr Io manager.\n+     * @param helper Statistics helper.\n+     * @param msgMgmtPool Message processing thread pool.\n+     * @param logSupplier Log supplier.\n+     */\n+    public StatisticsGatheringRequestCrawlerImpl(\n+        UUID locNodeId,\n+        IgniteStatisticsManagerImpl statMgr,\n+        GridEventStorageManager eventMgr,\n+        GridIoManager ioMgr,\n+        IgniteStatisticsHelper helper,\n+        IgniteThreadPoolExecutor msgMgmtPool,\n+        Function<Class<?>, IgniteLogger> logSupplier\n+    ) {\n+        this.log = logSupplier.apply(StatisticsGatheringRequestCrawlerImpl.class);\n+        this.locNodeId = locNodeId;\n+        this.statMgr = statMgr;\n+        this.eventMgr = eventMgr;\n+        this.ioMgr = ioMgr;\n+        this.helper = helper;\n+        this.msgMgmtPool = msgMgmtPool;\n+\n+        eventMgr.addLocalEventListener(this, EventType.EVT_NODE_FAILED, EventType.EVT_NODE_LEFT);\n+        ioMgr.addMessageListener(TOPIC, this);\n+    }\n+\n+    /**\n+     * Stop request crawler manager.\n+     */\n+    public void stop() {\n+        if (msgMgmtPool != null) {\n+            List<Runnable> unfinishedTasks = msgMgmtPool.shutdownNow();\n+            if (!unfinishedTasks.isEmpty())\n+                log.warning(String.format(\"%d statistics collection request cancelled.\", unfinishedTasks.size()));\n+        }\n+    }\n+\n+    /**\n+     * Convert collection of addressed gathering request to map reqId to addressed request.\n+     *\n+     * @param reqs Collection of request to convert.\n+     * @return Map request id to request.\n+     */\n+    private Map<UUID, StatisticsAddrRequest<StatisticsGatheringRequest>> toReqIdMap(\n+        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs\n+    ) {\n+        Map<UUID, StatisticsAddrRequest<StatisticsGatheringRequest>> res = new HashMap<>();\n+\n+        reqs.forEach(r -> res.put(r.req().reqId(), r));\n+\n+        return res;\n+    }\n+\n+    /**\n+     * Send gathering requests by specified keys and gathering id:\n+     * 1) Generate requests by keys and failed partitions.\n+     * 2) Put generated request into remaining map and increment gathering counter.\n+     * 2) \"Send\" or schedule local request execution (if exists) - can't fail to send local one.\n+     * 3) Send remove requests\n+     *\n+     *\n+     * @param gatId Gathering id.\n+     * @param keys Keys to generate and send requests by.\n+     * @param failedPartitions Collection of failed partitions to resend or\n+     *     {@code null} if it need to send request to all partitions.\n+     */\n+    private void sendGatheringRequests(\n+        UUID gatId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions\n+    ) {\n+        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs = null;\n+        int cnt = 0;\n+        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> failedMsgs;\n+        do {\n+            try {\n+                reqs = helper.generateCollectionRequests(gatId, keys, failedPartitions);\n+            }\n+            catch (IgniteCheckedException e) {\n+                statMgr.cancelObjectStatisticsGathering(gatId);\n+\n+                return;\n+            }\n+\n+            Map<UUID, StatisticsAddrRequest<StatisticsGatheringRequest>> reqsMap = toReqIdMap(reqs);\n+\n+            remainingRequests.putAll(reqsMap);\n+\n+            // Process local request\n+            StatisticsAddrRequest<StatisticsGatheringRequest> locReq = reqs.stream().filter(\n+                    r -> locNodeId.equals(r.targetNodeId())).findAny().orElse(null);\n+            if (locReq != null)\n+                statMgr.gatherLocalObjectStatisticsAsync(gatId, locReq.req().reqId(), locReq.req().keys());\n+\n+            // Process remote requests\n+            failedMsgs = sendRequests(reqs);\n+\n+            if (F.isEmpty(failedMsgs))\n+                failedPartitions = null;\n+            else {\n+                failedMsgs.forEach(r -> remainingRequests.remove(r.req().reqId()));\n+\n+                failedPartitions = helper.extractFailed(failedMsgs.stream().map(StatisticsAddrRequest::req)\n+                        .toArray(StatisticsGatheringRequest[]::new));\n+            }\n+\n+\n+            if (cnt++ > 10) {", "originalCommit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzQxMDY4MQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r557410681", "bodyText": "modex to MAX_SEND_RETRIES", "author": "Berkof", "createdAt": "2021-01-14T13:54:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM3NTA5OA=="}], "type": "inlineReview", "revised_code": {"commit": "7ef165002105dd10417170217e86d65771c524bb", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java\nindex e5d14a65efd..bf0f1855bca 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java\n", "chunk": "@@ -176,10 +178,12 @@ public class StatisticsGatheringRequestCrawlerImpl implements StatisticsGatherin\n             if (F.isEmpty(failedMsgs))\n                 failedPartitions = null;\n             else {\n-                failedMsgs.forEach(r -> remainingRequests.remove(r.req().reqId()));\n+                failedPartitions = new ArrayList<>();\n+                for (StatisticsAddrRequest<StatisticsGatheringRequest> msg : failedMsgs) {\n+                    remainingRequests.remove(msg.req().reqId());\n \n-                failedPartitions = helper.extractFailed(failedMsgs.stream().map(StatisticsAddrRequest::req)\n-                        .toArray(StatisticsGatheringRequest[]::new));\n+                    failedPartitions.addAll(GridArrays.list(msg.req().parts()));\n+                }\n             }\n \n \n", "next_change": {"commit": "05b732cd7e8840c429c48f5561e7c98e0289bcf6", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java\nindex bf0f1855bca..0e666f760b2 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java\n", "chunk": "@@ -186,7 +186,6 @@ public class StatisticsGatheringRequestCrawlerImpl implements StatisticsGatherin\n                 }\n             }\n \n-\n             if (cnt++ > 10) {\n                 if (log.isInfoEnabled())\n                     log.info(String.format(\"Unable to send gathering requests for 10 times, cancel gathering %s\", gatId));\n", "next_change": {"commit": "48b736c4cf138d5db12978e2004c446e26e1f097", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java\nindex 0e666f760b2..f0b456e06b7 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java\n", "chunk": "@@ -186,7 +188,7 @@ public class StatisticsGatheringRequestCrawlerImpl implements StatisticsGatherin\n                 }\n             }\n \n-            if (cnt++ > 10) {\n+            if (cnt++ > MAX_SEND_RETRIES) {\n                 if (log.isInfoEnabled())\n                     log.info(String.format(\"Unable to send gathering requests for 10 times, cancel gathering %s\", gatId));\n \n", "next_change": {"commit": "33170812024f6c4d321f85287fea0b6c3abdb9e5", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java\nindex f0b456e06b7..d68adfed407 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java\n", "chunk": "@@ -192,7 +212,13 @@ public class StatisticsGatheringRequestCrawlerImpl implements StatisticsGatherin\n                 if (log.isInfoEnabled())\n                     log.info(String.format(\"Unable to send gathering requests for 10 times, cancel gathering %s\", gatId));\n \n-                statMgr.cancelObjectStatisticsGathering(gatId);\n+                try {\n+                    statMgr.cancelObjectStatisticsGathering(gatId);\n+                }\n+                catch (IgniteCheckedException e) {\n+                    log.warning(\"Unable to cancel statistics gathering \" + gatId + \" after max retries due to: \"\n+                        + e.getMessage());\n+                }\n             }\n         }\n         while (!F.isEmpty(failedPartitions));\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM3NzY1Nw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549377657", "body": "I don't like this object with hardcoded set of fields is a part of protocol.\r\nThis approach is not flexible, we can't change the content of message that may depends on user needs.\r\nAlso versioning will be a headache in a future if we will need to change format.\r\n\r\nCustom versioned (de)serializer will be better.", "bodyText": "I don't like this object with hardcoded set of fields is a part of protocol.\nThis approach is not flexible, we can't change the content of message that may depends on user needs.\nAlso versioning will be a headache in a future if we will need to change format.\nCustom versioned (de)serializer will be better.", "bodyHTML": "<p dir=\"auto\">I don't like this object with hardcoded set of fields is a part of protocol.<br>\nThis approach is not flexible, we can't change the content of message that may depends on user needs.<br>\nAlso versioning will be a headache in a future if we will need to change format.</p>\n<p dir=\"auto\">Custom versioned (de)serializer will be better.</p>", "author": "AMashenkov", "createdAt": "2020-12-28T15:00:21Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsColumnData.java", "diffHunk": "@@ -0,0 +1,282 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat.messages;\n+\n+import org.apache.ignite.internal.processors.query.h2.twostep.msg.GridH2ValueMessage;\n+import org.apache.ignite.plugin.extensions.communication.Message;\n+import org.apache.ignite.plugin.extensions.communication.MessageReader;\n+import org.apache.ignite.plugin.extensions.communication.MessageWriter;\n+\n+import java.nio.ByteBuffer;\n+\n+/**\n+ * Statistics by column (or by set of columns, if they collected together)\n+ */\n+public class StatisticsColumnData implements Message {", "originalCommit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTU3ODA1NA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r559578054", "bodyText": "Discussed on the meeting, for now it'll be as is.", "author": "Berkof", "createdAt": "2021-01-18T13:47:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM3NzY1Nw=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM4NjUzOQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549386539", "body": "Test missed.", "bodyText": "Test missed.", "bodyHTML": "<p dir=\"auto\">Test missed.</p>", "author": "AMashenkov", "createdAt": "2020-12-28T15:25:50Z", "path": "modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryTest.java", "diffHunk": "@@ -183,4 +202,61 @@ public void testRepositoryGlobal(IgniteStatisticsRepositoryImpl repo) {\n \n         assertEquals(2L, repo.getGlobalStatistics(K1).rowCount());\n     }\n+\n+    /**\n+     * Test object statistics add:\n+     *\n+     * 1) Add statistics with partially the same columns.\n+     * 2) Add statistics with new columns.\n+     * 3) Add statistics with the same columns.\n+     */\n+    @Test\n+    public void addTest() {\n+        // 1) Add statistics with partially the same columns.\n+        HashMap<String, ColumnStatistics> colStat1 = new HashMap<>();\n+        colStat1.put(\"col1\", cs1);\n+        colStat1.put(\"col2\", cs2);\n+\n+        HashMap<String, ColumnStatistics> colStat2 = new HashMap<>();\n+        colStat2.put(\"col2\", cs3);\n+        colStat2.put(\"col3\", cs4);\n+\n+        ObjectStatisticsImpl os1 = new ObjectStatisticsImpl(100, colStat1);\n+        ObjectStatisticsImpl os2 = new ObjectStatisticsImpl(101, colStat2);\n+\n+        ObjectStatisticsImpl sumStat1 = IgniteStatisticsRepositoryImpl.add(os1, os2);\n+\n+        assertEquals(101, sumStat1.rowCount());\n+        assertEquals(3, sumStat1.columnsStatistics().size());\n+        assertEquals(cs3, sumStat1.columnStatistics(\"col2\"));\n+\n+        // 2) Add statistics with new columns.\n+        ObjectStatisticsImpl os3 = new ObjectStatisticsImpl(101, Collections.singletonMap(\"col3\", cs3));\n+\n+        ObjectStatisticsImpl sumStat2 = IgniteStatisticsRepositoryImpl.add(os1, os3);\n+\n+        assertEquals(3, sumStat2.columnsStatistics().size());\n+\n+        // 3) Add statistics with the same columns.\n+        HashMap<String, ColumnStatistics> colStat3 = new HashMap<>();\n+        colStat2.put(\"col1\", cs3);\n+        colStat2.put(\"col2\", cs4);\n+\n+        ObjectStatisticsImpl os4 = new ObjectStatisticsImpl(99, colStat1);\n+\n+        ObjectStatisticsImpl sumStat3 = IgniteStatisticsRepositoryImpl.add(os1, os4);\n+\n+        assertEquals(99, sumStat3.rowCount());\n+        assertEquals(2, sumStat3.columnsStatistics().size());\n+        assertEquals(cs3, sumStat3.columnStatistics(\"col1\"));\n+\n+    }\n+\n+    /**\n+     *\n+     */\n+    @Test\n+    public void subtractTest() {", "originalCommit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTU3NzQ0Ng==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r559577446", "bodyText": "implemented", "author": "Berkof", "createdAt": "2021-01-18T13:47:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM4NjUzOQ=="}], "type": "inlineReview", "revised_code": {"commit": "7ef165002105dd10417170217e86d65771c524bb", "changed_code": [{"header": "diff --git a/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryTest.java b/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryTest.java\nindex 3ea1d0bcd69..a1d727e2341 100644\n--- a/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryTest.java\n+++ b/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryTest.java\n", "chunk": "@@ -31,232 +31,232 @@ import java.util.HashMap;\n  * Test for statistics repository.\n  */\n public class IgniteStatisticsRepositoryTest extends StatisticsAbstractTest {\n-    /** First default key. */\n-    private static final StatisticsKey K1 = new StatisticsKey(\"PUBLIC\", \"tab1\");\n-\n-    /** Second default key. */\n-    private static final StatisticsKey K2 = new StatisticsKey(\"PUBLIC\", \"tab2\");\n-\n-    /** Column statistics with 100 nulls. */\n-    ColumnStatistics cs1 = new ColumnStatistics(null, null, 100, 0, 100,\n-            0, new byte[0]);\n-\n-    /** Column statistics with 100 integers 0-100. */\n-    ColumnStatistics cs2 = new ColumnStatistics(ValueInt.get(0), ValueInt.get(100), 0, 100, 100,\n-            4, new byte[0]);\n-\n-    /** Column statistics with 0 rows. */\n-    ColumnStatistics cs3 = new ColumnStatistics(null, null, 0, 0, 0, 0, new byte[0]);\n-\n-    /** Column statistics with 100 integers 0-10. */\n-    ColumnStatistics cs4 = new ColumnStatistics(ValueInt.get(0), ValueInt.get(10), 0, 10, 100,\n-            4, new byte[0]);\n-\n-\n-    /**\n-     * Test ignite statistics repository on client node without persistence.\n-     */\n-    @Test\n-    public void testClientNode() {\n-        IgniteStatisticsRepositoryImpl statsRepos = new IgniteStatisticsRepositoryImpl(false, null,\n-                null, null, cls -> log);\n-\n-        testRepositoryGlobal(statsRepos);\n-    }\n-\n-    /**\n-     * Test ignite statistics repository on server node without persistence.\n-     */\n-    @Test\n-    public void testServerWithoutPersistence() {\n-        IgniteStatisticsRepositoryImpl statsRepos = new IgniteStatisticsRepositoryImpl(true, null,\n-                null, null, cls -> log);\n-\n-        testRepositoryGlobal(statsRepos);\n-        testRepositoryLocal(statsRepos);\n-        testRepositoryPartitions(statsRepos);\n-    }\n-\n-    /**\n-     * Test ignite statistics repository on server node with persistence.\n-     */\n-    @Test\n-    public void testServerWithPersistence() throws IgniteCheckedException {\n-        MetastorageLifecycleListener lsnr[] = new MetastorageLifecycleListener[1];\n-\n-        GridInternalSubscriptionProcessor subscriptionProcessor = Mockito.mock(GridInternalSubscriptionProcessor.class);\n-        Mockito.doAnswer(invocation -> lsnr[0] = invocation.getArgument(0))\n-                .when(subscriptionProcessor).registerMetastorageListener(Mockito.any(MetastorageLifecycleListener.class));\n-\n-        IgniteStatisticsRepositoryImpl statsRepos = new IgniteStatisticsRepositoryImpl(true,\n-                new IgniteCacheDatabaseSharedManager(), subscriptionProcessor, null, cls -> log);\n-\n-        ReadWriteMetaStorageMock metastorage = new ReadWriteMetaStorageMock();\n-        lsnr[0].onReadyForReadWrite(metastorage);\n-\n-        testRepositoryGlobal(statsRepos);\n-        testRepositoryLocal(statsRepos);\n-        testRepositoryPartitions(statsRepos);\n-    }\n-\n-    /**\n-     * Test specified statistics repository with partitions statistics.\n-     *\n-     * 1) Generate two object key and few partition statistics.\n-     * 2) Check that there are no statistics before tests.\n-     * 3) Put local partition statistics.\n-     * 4) Read and check partition statistics one by one.\n-     * 5) Read all partition statistics by object and check its size.\n-     * 6) Save few partition statistics at once.\n-     * 7) Real all partition statistics by object and check its size.\n-     *\n-     * @param repo Ignite statistics repository to test.\n-     */\n-    public void testRepositoryPartitions(IgniteStatisticsRepositoryImpl repo) {\n-        ObjectPartitionStatisticsImpl stat1 = getPartitionStatistics(1);\n-        ObjectPartitionStatisticsImpl stat10 = getPartitionStatistics(10);\n-        ObjectPartitionStatisticsImpl stat100 = getPartitionStatistics(100);\n-\n-        ObjectPartitionStatisticsImpl stat1_2 = getPartitionStatistics(1);\n-\n-        assertTrue(repo.getLocalPartitionsStatistics(K1).isEmpty());\n-        assertTrue(repo.getLocalPartitionsStatistics(K2).isEmpty());\n-\n-        repo.saveLocalPartitionStatistics(K1, stat1);\n-        repo.saveLocalPartitionStatistics(K1, stat10);\n-        repo.saveLocalPartitionStatistics(K2, stat1_2);\n-\n-        ObjectPartitionStatisticsImpl stat1Readed = repo.getLocalPartitionStatistics(K1, 1);\n-        assertNotNull(stat1Readed);\n-        assertEquals(1, stat1Readed.partId());\n-\n-        ObjectPartitionStatisticsImpl stat10Readed = repo.getLocalPartitionStatistics(K1, 10);\n-        assertNotNull(stat10Readed);\n-        assertEquals(10, stat10Readed.partId());\n-\n-        assertNull(repo.getLocalPartitionStatistics(K1, 2));\n-\n-        assertEquals(2, repo.getLocalPartitionsStatistics(K1).size());\n-        assertEquals(1, repo.getLocalPartitionsStatistics(K2).size());\n-\n-        repo.saveLocalPartitionsStatistics(K1, Arrays.asList(stat10, stat100));\n-\n-        assertEquals(2, repo.getLocalPartitionsStatistics(K1).size());\n-    }\n-\n-    /**\n-     * Test specified repository with local statistics:\n-     *\n-     * 1) Check that repository doesn't contains test table statistics.\n-     * 2) Save local statistics.\n-     * 3) Check that it doesn't available by wrong key and available by right one.\n-     * 4) Merge local statistics and check that new version available.\n-     *\n-     * @param repo Ignite statistics repository to test.\n-     */\n-    public void testRepositoryLocal(IgniteStatisticsRepositoryImpl repo) {\n-        assertNull(repo.getLocalStatistics(K1));\n-        assertNull(repo.getLocalStatistics(K2));\n-\n-        ObjectStatisticsImpl stat1 = getStatistics(1);\n-\n-        repo.saveLocalStatistics(K1, stat1);\n-        assertNull(repo.getLocalStatistics(K2));\n-\n-        assertEquals(1L, repo.getLocalStatistics(K1).rowCount());\n-\n-        ObjectStatisticsImpl stat2 = getStatistics(2);\n-\n-        repo.mergeLocalStatistics(K1, stat2);\n-\n-        assertNull(repo.getLocalStatistics(K2));\n-        assertEquals(2L, repo.getLocalStatistics(K1).rowCount());\n-    }\n-\n-    /**\n-     * Test specified repository with global statistics:\n-     *\n-     * 1) Clear empty statistics (whole object and only one column).\n-     * 2) Save global statistics.\n-     * 3) Check that it doesn't available by wrong key and available by right key.\n-     * 4) Merge global statistics and check that new version available.\n-     *\n-     * @param repo Ignite statistics repository to test.\n-     */\n-    public void testRepositoryGlobal(IgniteStatisticsRepositoryImpl repo) {\n-        assertNull(repo.getGlobalStatistics(K1));\n-        repo.clearGlobalStatistics(K1);\n-        repo.clearGlobalStatistics(K1, \"col10\");\n-\n-        ObjectStatisticsImpl tab1Statistics = getStatistics(1);\n-\n-        repo.saveGlobalStatistics(K1, tab1Statistics);\n-\n-        assertNull(repo.getGlobalStatistics(K2));\n-\n-        assertEquals(1L, repo.getGlobalStatistics(K1).rowCount());\n-\n-        ObjectStatisticsImpl tab1Statistics2 = getStatistics(2);\n-\n-        repo.mergeGlobalStatistics(K1, tab1Statistics2);\n-\n-        assertEquals(2L, repo.getGlobalStatistics(K1).rowCount());\n-    }\n-\n-    /**\n-     * Test object statistics add:\n-     *\n-     * 1) Add statistics with partially the same columns.\n-     * 2) Add statistics with new columns.\n-     * 3) Add statistics with the same columns.\n-     */\n-    @Test\n-    public void addTest() {\n-        // 1) Add statistics with partially the same columns.\n-        HashMap<String, ColumnStatistics> colStat1 = new HashMap<>();\n-        colStat1.put(\"col1\", cs1);\n-        colStat1.put(\"col2\", cs2);\n-\n-        HashMap<String, ColumnStatistics> colStat2 = new HashMap<>();\n-        colStat2.put(\"col2\", cs3);\n-        colStat2.put(\"col3\", cs4);\n-\n-        ObjectStatisticsImpl os1 = new ObjectStatisticsImpl(100, colStat1);\n-        ObjectStatisticsImpl os2 = new ObjectStatisticsImpl(101, colStat2);\n-\n-        ObjectStatisticsImpl sumStat1 = IgniteStatisticsRepositoryImpl.add(os1, os2);\n-\n-        assertEquals(101, sumStat1.rowCount());\n-        assertEquals(3, sumStat1.columnsStatistics().size());\n-        assertEquals(cs3, sumStat1.columnStatistics(\"col2\"));\n-\n-        // 2) Add statistics with new columns.\n-        ObjectStatisticsImpl os3 = new ObjectStatisticsImpl(101, Collections.singletonMap(\"col3\", cs3));\n-\n-        ObjectStatisticsImpl sumStat2 = IgniteStatisticsRepositoryImpl.add(os1, os3);\n-\n-        assertEquals(3, sumStat2.columnsStatistics().size());\n-\n-        // 3) Add statistics with the same columns.\n-        HashMap<String, ColumnStatistics> colStat3 = new HashMap<>();\n-        colStat2.put(\"col1\", cs3);\n-        colStat2.put(\"col2\", cs4);\n-\n-        ObjectStatisticsImpl os4 = new ObjectStatisticsImpl(99, colStat1);\n-\n-        ObjectStatisticsImpl sumStat3 = IgniteStatisticsRepositoryImpl.add(os1, os4);\n-\n-        assertEquals(99, sumStat3.rowCount());\n-        assertEquals(2, sumStat3.columnsStatistics().size());\n-        assertEquals(cs3, sumStat3.columnStatistics(\"col1\"));\n-\n-    }\n-\n-    /**\n-     *\n-     */\n-    @Test\n-    public void subtractTest() {\n-\n-    }\n+//    /** First default key. */\n+//    private static final StatisticsKey K1 = new StatisticsKey(\"PUBLIC\", \"tab1\");\n+//\n+//    /** Second default key. */\n+//    private static final StatisticsKey K2 = new StatisticsKey(\"PUBLIC\", \"tab2\");\n+//\n+//    /** Column statistics with 100 nulls. */\n+//    ColumnStatistics cs1 = new ColumnStatistics(null, null, 100, 0, 100,\n+//            0, new byte[0]);\n+//\n+//    /** Column statistics with 100 integers 0-100. */\n+//    ColumnStatistics cs2 = new ColumnStatistics(ValueInt.get(0), ValueInt.get(100), 0, 100, 100,\n+//            4, new byte[0]);\n+//\n+//    /** Column statistics with 0 rows. */\n+//    ColumnStatistics cs3 = new ColumnStatistics(null, null, 0, 0, 0, 0, new byte[0]);\n+//\n+//    /** Column statistics with 100 integers 0-10. */\n+//    ColumnStatistics cs4 = new ColumnStatistics(ValueInt.get(0), ValueInt.get(10), 0, 10, 100,\n+//            4, new byte[0]);\n+//\n+//\n+//    /**\n+//     * Test ignite statistics repository on client node without persistence.\n+//     */\n+//    @Test\n+//    public void testClientNode() {\n+//        IgniteStatisticsRepositoryImpl statsRepos = new IgniteStatisticsRepositoryImpl(false, null,\n+//                null, null, cls -> log);\n+//\n+//        testRepositoryGlobal(statsRepos);\n+//    }\n+//\n+//    /**\n+//     * Test ignite statistics repository on server node without persistence.\n+//     */\n+//    @Test\n+//    public void testServerWithoutPersistence() {\n+//        IgniteStatisticsRepositoryImpl statsRepos = new IgniteStatisticsRepositoryImpl(true, null,\n+//                null, null, cls -> log);\n+//\n+//        testRepositoryGlobal(statsRepos);\n+//        testRepositoryLocal(statsRepos);\n+//        testRepositoryPartitions(statsRepos);\n+//    }\n+//\n+//    /**\n+//     * Test ignite statistics repository on server node with persistence.\n+//     */\n+//    @Test\n+//    public void testServerWithPersistence() throws IgniteCheckedException {\n+//        MetastorageLifecycleListener lsnr[] = new MetastorageLifecycleListener[1];\n+//\n+//        GridInternalSubscriptionProcessor subscriptionProcessor = Mockito.mock(GridInternalSubscriptionProcessor.class);\n+//        Mockito.doAnswer(invocation -> lsnr[0] = invocation.getArgument(0))\n+//                .when(subscriptionProcessor).registerMetastorageListener(Mockito.any(MetastorageLifecycleListener.class));\n+//\n+//        IgniteStatisticsRepositoryImpl statsRepos = new IgniteStatisticsRepositoryImpl(true,\n+//                new IgniteCacheDatabaseSharedManager(), subscriptionProcessor, null, cls -> log);\n+//\n+//        ReadWriteMetaStorageMock metastorage = new ReadWriteMetaStorageMock();\n+//        lsnr[0].onReadyForReadWrite(metastorage);\n+//\n+//        testRepositoryGlobal(statsRepos);\n+//        testRepositoryLocal(statsRepos);\n+//        testRepositoryPartitions(statsRepos);\n+//    }\n+//\n+//    /**\n+//     * Test specified statistics repository with partitions statistics.\n+//     *\n+//     * 1) Generate two object key and few partition statistics.\n+//     * 2) Check that there are no statistics before tests.\n+//     * 3) Put local partition statistics.\n+//     * 4) Read and check partition statistics one by one.\n+//     * 5) Read all partition statistics by object and check its size.\n+//     * 6) Save few partition statistics at once.\n+//     * 7) Real all partition statistics by object and check its size.\n+//     *\n+//     * @param repo Ignite statistics repository to test.\n+//     */\n+//    public void testRepositoryPartitions(IgniteStatisticsRepositoryImpl repo) {\n+//        ObjectPartitionStatisticsImpl stat1 = getPartitionStatistics(1);\n+//        ObjectPartitionStatisticsImpl stat10 = getPartitionStatistics(10);\n+//        ObjectPartitionStatisticsImpl stat100 = getPartitionStatistics(100);\n+//\n+//        ObjectPartitionStatisticsImpl stat1_2 = getPartitionStatistics(1);\n+//\n+//        assertTrue(repo.getLocalPartitionsStatistics(K1).isEmpty());\n+//        assertTrue(repo.getLocalPartitionsStatistics(K2).isEmpty());\n+//\n+//        repo.saveLocalPartitionStatistics(K1, stat1);\n+//        repo.saveLocalPartitionStatistics(K1, stat10);\n+//        repo.saveLocalPartitionStatistics(K2, stat1_2);\n+//\n+//        ObjectPartitionStatisticsImpl stat1Readed = repo.getLocalPartitionStatistics(K1, 1);\n+//        assertNotNull(stat1Readed);\n+//        assertEquals(1, stat1Readed.partId());\n+//\n+//        ObjectPartitionStatisticsImpl stat10Readed = repo.getLocalPartitionStatistics(K1, 10);\n+//        assertNotNull(stat10Readed);\n+//        assertEquals(10, stat10Readed.partId());\n+//\n+//        assertNull(repo.getLocalPartitionStatistics(K1, 2));\n+//\n+//        assertEquals(2, repo.getLocalPartitionsStatistics(K1).size());\n+//        assertEquals(1, repo.getLocalPartitionsStatistics(K2).size());\n+//\n+//        repo.saveLocalPartitionsStatistics(K1, Arrays.asList(stat10, stat100));\n+//\n+//        assertEquals(2, repo.getLocalPartitionsStatistics(K1).size());\n+//    }\n+//\n+//    /**\n+//     * Test specified repository with local statistics:\n+//     *\n+//     * 1) Check that repository doesn't contains test table statistics.\n+//     * 2) Save local statistics.\n+//     * 3) Check that it doesn't available by wrong key and available by right one.\n+//     * 4) Merge local statistics and check that new version available.\n+//     *\n+//     * @param repo Ignite statistics repository to test.\n+//     */\n+//    public void testRepositoryLocal(IgniteStatisticsRepositoryImpl repo) {\n+//        assertNull(repo.getLocalStatistics(K1));\n+//        assertNull(repo.getLocalStatistics(K2));\n+//\n+//        ObjectStatisticsImpl stat1 = getStatistics(1);\n+//\n+//        repo.saveLocalStatistics(K1, stat1);\n+//        assertNull(repo.getLocalStatistics(K2));\n+//\n+//        assertEquals(1L, repo.getLocalStatistics(K1).rowCount());\n+//\n+//        ObjectStatisticsImpl stat2 = getStatistics(2);\n+//\n+//        repo.mergeLocalStatistics(K1, stat2);\n+//\n+//        assertNull(repo.getLocalStatistics(K2));\n+//        assertEquals(2L, repo.getLocalStatistics(K1).rowCount());\n+//    }\n+//\n+//    /**\n+//     * Test specified repository with global statistics:\n+//     *\n+//     * 1) Clear empty statistics (whole object and only one column).\n+//     * 2) Save global statistics.\n+//     * 3) Check that it doesn't available by wrong key and available by right key.\n+//     * 4) Merge global statistics and check that new version available.\n+//     *\n+//     * @param repo Ignite statistics repository to test.\n+//     */\n+//    public void testRepositoryGlobal(IgniteStatisticsRepositoryImpl repo) {\n+//        assertNull(repo.getGlobalStatistics(K1));\n+//        repo.clearGlobalStatistics(K1);\n+//        repo.clearGlobalStatistics(K1, \"col10\");\n+//\n+//        ObjectStatisticsImpl tab1Statistics = getStatistics(1);\n+//\n+//        repo.saveGlobalStatistics(K1, tab1Statistics);\n+//\n+//        assertNull(repo.getGlobalStatistics(K2));\n+//\n+//        assertEquals(1L, repo.getGlobalStatistics(K1).rowCount());\n+//\n+//        ObjectStatisticsImpl tab1Statistics2 = getStatistics(2);\n+//\n+//        repo.mergeGlobalStatistics(K1, tab1Statistics2);\n+//\n+//        assertEquals(2L, repo.getGlobalStatistics(K1).rowCount());\n+//    }\n+//\n+//    /**\n+//     * Test object statistics add:\n+//     *\n+//     * 1) Add statistics with partially the same columns.\n+//     * 2) Add statistics with new columns.\n+//     * 3) Add statistics with the same columns.\n+//     */\n+//    @Test\n+//    public void addTest() {\n+//        // 1) Add statistics with partially the same columns.\n+//        HashMap<String, ColumnStatistics> colStat1 = new HashMap<>();\n+//        colStat1.put(\"col1\", cs1);\n+//        colStat1.put(\"col2\", cs2);\n+//\n+//        HashMap<String, ColumnStatistics> colStat2 = new HashMap<>();\n+//        colStat2.put(\"col2\", cs3);\n+//        colStat2.put(\"col3\", cs4);\n+//\n+//        ObjectStatisticsImpl os1 = new ObjectStatisticsImpl(100, colStat1);\n+//        ObjectStatisticsImpl os2 = new ObjectStatisticsImpl(101, colStat2);\n+//\n+//        ObjectStatisticsImpl sumStat1 = IgniteStatisticsRepositoryImpl.add(os1, os2);\n+//\n+//        assertEquals(101, sumStat1.rowCount());\n+//        assertEquals(3, sumStat1.columnsStatistics().size());\n+//        assertEquals(cs3, sumStat1.columnStatistics(\"col2\"));\n+//\n+//        // 2) Add statistics with new columns.\n+//        ObjectStatisticsImpl os3 = new ObjectStatisticsImpl(101, Collections.singletonMap(\"col3\", cs3));\n+//\n+//        ObjectStatisticsImpl sumStat2 = IgniteStatisticsRepositoryImpl.add(os1, os3);\n+//\n+//        assertEquals(3, sumStat2.columnsStatistics().size());\n+//\n+//        // 3) Add statistics with the same columns.\n+//        HashMap<String, ColumnStatistics> colStat3 = new HashMap<>();\n+//        colStat2.put(\"col1\", cs3);\n+//        colStat2.put(\"col2\", cs4);\n+//\n+//        ObjectStatisticsImpl os4 = new ObjectStatisticsImpl(99, colStat1);\n+//\n+//        ObjectStatisticsImpl sumStat3 = IgniteStatisticsRepositoryImpl.add(os1, os4);\n+//\n+//        assertEquals(99, sumStat3.rowCount());\n+//        assertEquals(2, sumStat3.columnsStatistics().size());\n+//        assertEquals(cs3, sumStat3.columnStatistics(\"col1\"));\n+//\n+//    }\n+//\n+//    /**\n+//     *\n+//     */\n+//    @Test\n+//    public void subtractTest() {\n+//\n+//    }\n }\n", "next_change": {"commit": "48b736c4cf138d5db12978e2004c446e26e1f097", "changed_code": [{"header": "diff --git a/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryTest.java b/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryTest.java\nindex a1d727e2341..5df801f62dd 100644\n--- a/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryTest.java\n+++ b/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryTest.java\n", "chunk": "@@ -31,232 +31,256 @@ import java.util.HashMap;\n  * Test for statistics repository.\n  */\n public class IgniteStatisticsRepositoryTest extends StatisticsAbstractTest {\n-//    /** First default key. */\n-//    private static final StatisticsKey K1 = new StatisticsKey(\"PUBLIC\", \"tab1\");\n-//\n-//    /** Second default key. */\n-//    private static final StatisticsKey K2 = new StatisticsKey(\"PUBLIC\", \"tab2\");\n-//\n-//    /** Column statistics with 100 nulls. */\n-//    ColumnStatistics cs1 = new ColumnStatistics(null, null, 100, 0, 100,\n-//            0, new byte[0]);\n-//\n-//    /** Column statistics with 100 integers 0-100. */\n-//    ColumnStatistics cs2 = new ColumnStatistics(ValueInt.get(0), ValueInt.get(100), 0, 100, 100,\n-//            4, new byte[0]);\n-//\n-//    /** Column statistics with 0 rows. */\n-//    ColumnStatistics cs3 = new ColumnStatistics(null, null, 0, 0, 0, 0, new byte[0]);\n-//\n-//    /** Column statistics with 100 integers 0-10. */\n-//    ColumnStatistics cs4 = new ColumnStatistics(ValueInt.get(0), ValueInt.get(10), 0, 10, 100,\n-//            4, new byte[0]);\n-//\n-//\n-//    /**\n-//     * Test ignite statistics repository on client node without persistence.\n-//     */\n-//    @Test\n-//    public void testClientNode() {\n-//        IgniteStatisticsRepositoryImpl statsRepos = new IgniteStatisticsRepositoryImpl(false, null,\n-//                null, null, cls -> log);\n-//\n-//        testRepositoryGlobal(statsRepos);\n-//    }\n-//\n-//    /**\n-//     * Test ignite statistics repository on server node without persistence.\n-//     */\n-//    @Test\n-//    public void testServerWithoutPersistence() {\n-//        IgniteStatisticsRepositoryImpl statsRepos = new IgniteStatisticsRepositoryImpl(true, null,\n-//                null, null, cls -> log);\n-//\n-//        testRepositoryGlobal(statsRepos);\n-//        testRepositoryLocal(statsRepos);\n-//        testRepositoryPartitions(statsRepos);\n-//    }\n-//\n-//    /**\n-//     * Test ignite statistics repository on server node with persistence.\n-//     */\n-//    @Test\n-//    public void testServerWithPersistence() throws IgniteCheckedException {\n-//        MetastorageLifecycleListener lsnr[] = new MetastorageLifecycleListener[1];\n-//\n-//        GridInternalSubscriptionProcessor subscriptionProcessor = Mockito.mock(GridInternalSubscriptionProcessor.class);\n-//        Mockito.doAnswer(invocation -> lsnr[0] = invocation.getArgument(0))\n-//                .when(subscriptionProcessor).registerMetastorageListener(Mockito.any(MetastorageLifecycleListener.class));\n-//\n-//        IgniteStatisticsRepositoryImpl statsRepos = new IgniteStatisticsRepositoryImpl(true,\n-//                new IgniteCacheDatabaseSharedManager(), subscriptionProcessor, null, cls -> log);\n-//\n-//        ReadWriteMetaStorageMock metastorage = new ReadWriteMetaStorageMock();\n-//        lsnr[0].onReadyForReadWrite(metastorage);\n-//\n-//        testRepositoryGlobal(statsRepos);\n-//        testRepositoryLocal(statsRepos);\n-//        testRepositoryPartitions(statsRepos);\n-//    }\n-//\n-//    /**\n-//     * Test specified statistics repository with partitions statistics.\n-//     *\n-//     * 1) Generate two object key and few partition statistics.\n-//     * 2) Check that there are no statistics before tests.\n-//     * 3) Put local partition statistics.\n-//     * 4) Read and check partition statistics one by one.\n-//     * 5) Read all partition statistics by object and check its size.\n-//     * 6) Save few partition statistics at once.\n-//     * 7) Real all partition statistics by object and check its size.\n-//     *\n-//     * @param repo Ignite statistics repository to test.\n-//     */\n-//    public void testRepositoryPartitions(IgniteStatisticsRepositoryImpl repo) {\n-//        ObjectPartitionStatisticsImpl stat1 = getPartitionStatistics(1);\n-//        ObjectPartitionStatisticsImpl stat10 = getPartitionStatistics(10);\n-//        ObjectPartitionStatisticsImpl stat100 = getPartitionStatistics(100);\n-//\n-//        ObjectPartitionStatisticsImpl stat1_2 = getPartitionStatistics(1);\n-//\n-//        assertTrue(repo.getLocalPartitionsStatistics(K1).isEmpty());\n-//        assertTrue(repo.getLocalPartitionsStatistics(K2).isEmpty());\n-//\n-//        repo.saveLocalPartitionStatistics(K1, stat1);\n-//        repo.saveLocalPartitionStatistics(K1, stat10);\n-//        repo.saveLocalPartitionStatistics(K2, stat1_2);\n-//\n-//        ObjectPartitionStatisticsImpl stat1Readed = repo.getLocalPartitionStatistics(K1, 1);\n-//        assertNotNull(stat1Readed);\n-//        assertEquals(1, stat1Readed.partId());\n-//\n-//        ObjectPartitionStatisticsImpl stat10Readed = repo.getLocalPartitionStatistics(K1, 10);\n-//        assertNotNull(stat10Readed);\n-//        assertEquals(10, stat10Readed.partId());\n-//\n-//        assertNull(repo.getLocalPartitionStatistics(K1, 2));\n-//\n-//        assertEquals(2, repo.getLocalPartitionsStatistics(K1).size());\n-//        assertEquals(1, repo.getLocalPartitionsStatistics(K2).size());\n-//\n-//        repo.saveLocalPartitionsStatistics(K1, Arrays.asList(stat10, stat100));\n-//\n-//        assertEquals(2, repo.getLocalPartitionsStatistics(K1).size());\n-//    }\n-//\n-//    /**\n-//     * Test specified repository with local statistics:\n-//     *\n-//     * 1) Check that repository doesn't contains test table statistics.\n-//     * 2) Save local statistics.\n-//     * 3) Check that it doesn't available by wrong key and available by right one.\n-//     * 4) Merge local statistics and check that new version available.\n-//     *\n-//     * @param repo Ignite statistics repository to test.\n-//     */\n-//    public void testRepositoryLocal(IgniteStatisticsRepositoryImpl repo) {\n-//        assertNull(repo.getLocalStatistics(K1));\n-//        assertNull(repo.getLocalStatistics(K2));\n-//\n-//        ObjectStatisticsImpl stat1 = getStatistics(1);\n-//\n-//        repo.saveLocalStatistics(K1, stat1);\n-//        assertNull(repo.getLocalStatistics(K2));\n-//\n-//        assertEquals(1L, repo.getLocalStatistics(K1).rowCount());\n-//\n-//        ObjectStatisticsImpl stat2 = getStatistics(2);\n-//\n-//        repo.mergeLocalStatistics(K1, stat2);\n-//\n-//        assertNull(repo.getLocalStatistics(K2));\n-//        assertEquals(2L, repo.getLocalStatistics(K1).rowCount());\n-//    }\n-//\n-//    /**\n-//     * Test specified repository with global statistics:\n-//     *\n-//     * 1) Clear empty statistics (whole object and only one column).\n-//     * 2) Save global statistics.\n-//     * 3) Check that it doesn't available by wrong key and available by right key.\n-//     * 4) Merge global statistics and check that new version available.\n-//     *\n-//     * @param repo Ignite statistics repository to test.\n-//     */\n-//    public void testRepositoryGlobal(IgniteStatisticsRepositoryImpl repo) {\n-//        assertNull(repo.getGlobalStatistics(K1));\n-//        repo.clearGlobalStatistics(K1);\n-//        repo.clearGlobalStatistics(K1, \"col10\");\n-//\n-//        ObjectStatisticsImpl tab1Statistics = getStatistics(1);\n-//\n-//        repo.saveGlobalStatistics(K1, tab1Statistics);\n-//\n-//        assertNull(repo.getGlobalStatistics(K2));\n-//\n-//        assertEquals(1L, repo.getGlobalStatistics(K1).rowCount());\n-//\n-//        ObjectStatisticsImpl tab1Statistics2 = getStatistics(2);\n-//\n-//        repo.mergeGlobalStatistics(K1, tab1Statistics2);\n-//\n-//        assertEquals(2L, repo.getGlobalStatistics(K1).rowCount());\n-//    }\n-//\n-//    /**\n-//     * Test object statistics add:\n-//     *\n-//     * 1) Add statistics with partially the same columns.\n-//     * 2) Add statistics with new columns.\n-//     * 3) Add statistics with the same columns.\n-//     */\n-//    @Test\n-//    public void addTest() {\n-//        // 1) Add statistics with partially the same columns.\n-//        HashMap<String, ColumnStatistics> colStat1 = new HashMap<>();\n-//        colStat1.put(\"col1\", cs1);\n-//        colStat1.put(\"col2\", cs2);\n-//\n-//        HashMap<String, ColumnStatistics> colStat2 = new HashMap<>();\n-//        colStat2.put(\"col2\", cs3);\n-//        colStat2.put(\"col3\", cs4);\n-//\n-//        ObjectStatisticsImpl os1 = new ObjectStatisticsImpl(100, colStat1);\n-//        ObjectStatisticsImpl os2 = new ObjectStatisticsImpl(101, colStat2);\n-//\n-//        ObjectStatisticsImpl sumStat1 = IgniteStatisticsRepositoryImpl.add(os1, os2);\n-//\n-//        assertEquals(101, sumStat1.rowCount());\n-//        assertEquals(3, sumStat1.columnsStatistics().size());\n-//        assertEquals(cs3, sumStat1.columnStatistics(\"col2\"));\n-//\n-//        // 2) Add statistics with new columns.\n-//        ObjectStatisticsImpl os3 = new ObjectStatisticsImpl(101, Collections.singletonMap(\"col3\", cs3));\n-//\n-//        ObjectStatisticsImpl sumStat2 = IgniteStatisticsRepositoryImpl.add(os1, os3);\n-//\n-//        assertEquals(3, sumStat2.columnsStatistics().size());\n-//\n-//        // 3) Add statistics with the same columns.\n-//        HashMap<String, ColumnStatistics> colStat3 = new HashMap<>();\n-//        colStat2.put(\"col1\", cs3);\n-//        colStat2.put(\"col2\", cs4);\n-//\n-//        ObjectStatisticsImpl os4 = new ObjectStatisticsImpl(99, colStat1);\n-//\n-//        ObjectStatisticsImpl sumStat3 = IgniteStatisticsRepositoryImpl.add(os1, os4);\n-//\n-//        assertEquals(99, sumStat3.rowCount());\n-//        assertEquals(2, sumStat3.columnsStatistics().size());\n-//        assertEquals(cs3, sumStat3.columnStatistics(\"col1\"));\n-//\n-//    }\n-//\n-//    /**\n-//     *\n-//     */\n-//    @Test\n-//    public void subtractTest() {\n-//\n-//    }\n+    /** First default key. */\n+    private static final StatisticsKey K1 = new StatisticsKey(\"PUBLIC\", \"tab1\");\n+\n+    /** Second default key. */\n+    private static final StatisticsKey K2 = new StatisticsKey(\"PUBLIC\", \"tab2\");\n+\n+    /** Column statistics with 100 nulls. */\n+    ColumnStatistics cs1 = new ColumnStatistics(null, null, 100, 0, 100,\n+        0, new byte[0]);\n+\n+    /** Column statistics with 100 integers 0-100. */\n+    ColumnStatistics cs2 = new ColumnStatistics(ValueInt.get(0), ValueInt.get(100), 0, 100, 100,\n+        4, new byte[0]);\n+\n+    /** Column statistics with 0 rows. */\n+    ColumnStatistics cs3 = new ColumnStatistics(null, null, 0, 0, 0, 0, new byte[0]);\n+\n+    /** Column statistics with 100 integers 0-10. */\n+    ColumnStatistics cs4 = new ColumnStatistics(ValueInt.get(0), ValueInt.get(10), 0, 10, 100,\n+            4, new byte[0]);\n+\n+    /**\n+     * Test ignite statistics repository on client node without persistence.\n+     */\n+    @Test\n+    public void testClientNode() {\n+        IgniteStatisticsDummyStoreImpl dummyStore = new IgniteStatisticsDummyStoreImpl(cls -> log);\n+        IgniteStatisticsRepositoryImpl statsRepos = new IgniteStatisticsRepositoryImpl(dummyStore, null, cls -> log);\n+\n+        testRepositoryGlobal(statsRepos);\n+    }\n+\n+    /**\n+     * Test ignite statistics repository on server node without persistence.\n+     */\n+    @Test\n+    public void testServerWithoutPersistence() {\n+        IgniteStatisticsStore store = new IgniteStatisticsInMemoryStoreImpl(cls -> log);\n+        IgniteStatisticsRepositoryImpl statsRepos = new IgniteStatisticsRepositoryImpl(store, null, cls -> log);\n+\n+        testRepositoryGlobal(statsRepos);\n+        testRepositoryLocal(statsRepos);\n+        testRepositoryPartitions(statsRepos);\n+    }\n+\n+    /**\n+     * Test ignite statistics repository on server node with persistence.\n+     */\n+    @Test\n+    public void testServerWithPersistence() throws IgniteCheckedException {\n+        MetastorageLifecycleListener lsnr[] = new MetastorageLifecycleListener[1];\n+\n+        GridInternalSubscriptionProcessor subscriptionProcessor = Mockito.mock(GridInternalSubscriptionProcessor.class);\n+        Mockito.doAnswer(invocation -> lsnr[0] = invocation.getArgument(0))\n+            .when(subscriptionProcessor).registerMetastorageListener(Mockito.any(MetastorageLifecycleListener.class));\n+        IgniteCacheDatabaseSharedManager db = Mockito.mock(IgniteCacheDatabaseSharedManager.class);\n+\n+        IgniteStatisticsRepositoryImpl statsRepos[] = new IgniteStatisticsRepositoryImpl[1];\n+        IgniteStatisticsStore store = new IgniteStatisticsPersistenceStoreImpl(subscriptionProcessor, db,\n+            statsRepos[0]::cacheLocalStatistics, cls -> log);\n+        IgniteStatisticsHelper helper = Mockito.mock(IgniteStatisticsHelper.class);\n+        statsRepos[0] = new IgniteStatisticsRepositoryImpl(store, helper, cls -> log);\n+\n+        ReadWriteMetaStorageMock metastorage = new ReadWriteMetaStorageMock();\n+        lsnr[0].onReadyForReadWrite(metastorage);\n+\n+        testRepositoryGlobal(statsRepos[0]);\n+        testRepositoryLocal(statsRepos[0]);\n+        testRepositoryPartitions(statsRepos[0]);\n+    }\n+\n+    /**\n+     * Test specified statistics repository with partitions statistics.\n+     *\n+     * 1) Generate two object key and few partition statistics.\n+     * 2) Check that there are no statistics before tests.\n+     * 3) Put local partition statistics.\n+     * 4) Read and check partition statistics one by one.\n+     * 5) Read all partition statistics by object and check its size.\n+     * 6) Save few partition statistics at once.\n+     * 7) Real all partition statistics by object and check its size.\n+     *\n+     * @param repo Ignite statistics repository to test.\n+     */\n+    public void testRepositoryPartitions(IgniteStatisticsRepositoryImpl repo) {\n+        ObjectPartitionStatisticsImpl stat1 = getPartitionStatistics(1);\n+        ObjectPartitionStatisticsImpl stat10 = getPartitionStatistics(10);\n+        ObjectPartitionStatisticsImpl stat100 = getPartitionStatistics(100);\n+\n+        ObjectPartitionStatisticsImpl stat1_2 = getPartitionStatistics(1);\n+\n+        assertTrue(repo.getLocalPartitionsStatistics(K1).isEmpty());\n+        assertTrue(repo.getLocalPartitionsStatistics(K2).isEmpty());\n+\n+        repo.saveLocalPartitionStatistics(K1, stat1);\n+        repo.saveLocalPartitionStatistics(K1, stat10);\n+        repo.saveLocalPartitionStatistics(K2, stat1_2);\n+\n+        ObjectPartitionStatisticsImpl stat1Readed = repo.getLocalPartitionStatistics(K1, 1);\n+        assertNotNull(stat1Readed);\n+        assertEquals(1, stat1Readed.partId());\n+\n+        ObjectPartitionStatisticsImpl stat10Readed = repo.getLocalPartitionStatistics(K1, 10);\n+        assertNotNull(stat10Readed);\n+        assertEquals(10, stat10Readed.partId());\n+\n+        assertNull(repo.getLocalPartitionStatistics(K1, 2));\n+\n+        assertEquals(2, repo.getLocalPartitionsStatistics(K1).size());\n+        assertEquals(1, repo.getLocalPartitionsStatistics(K2).size());\n+\n+        repo.saveLocalPartitionsStatistics(K1, Arrays.asList(stat10, stat100));\n+\n+        assertEquals(2, repo.getLocalPartitionsStatistics(K1).size());\n+    }\n+\n+    /**\n+     * Test specified repository with local statistics:\n+     *\n+     * 1) Check that repository doesn't contains test table statistics.\n+     * 2) Save local statistics.\n+     * 3) Check that it doesn't available by wrong key and available by right one.\n+     * 4) Merge local statistics and check that new version available.\n+     *\n+     * @param repo Ignite statistics repository to test.\n+     */\n+    public void testRepositoryLocal(IgniteStatisticsRepositoryImpl repo) {\n+        assertNull(repo.getLocalStatistics(K1));\n+        assertNull(repo.getLocalStatistics(K2));\n+\n+        ObjectStatisticsImpl stat1 = getStatistics(1);\n+\n+        repo.saveLocalStatistics(K1, stat1);\n+        assertNull(repo.getLocalStatistics(K2));\n+\n+        assertEquals(1L, repo.getLocalStatistics(K1).rowCount());\n+\n+        ObjectStatisticsImpl stat2 = getStatistics(2);\n+\n+        repo.mergeLocalStatistics(K1, stat2);\n+\n+        assertNull(repo.getLocalStatistics(K2));\n+        assertEquals(2L, repo.getLocalStatistics(K1).rowCount());\n+    }\n+\n+    /**\n+     * Test specified repository with global statistics:\n+     *\n+     * 1) Clear empty statistics (whole object and only one column).\n+     * 2) Save global statistics.\n+     * 3) Check that it doesn't available by wrong key and available by right key.\n+     * 4) Merge global statistics and check that new version available.\n+     *\n+     * @param repo Ignite statistics repository to test.\n+     */\n+    public void testRepositoryGlobal(IgniteStatisticsRepositoryImpl repo) {\n+        assertNull(repo.getGlobalStatistics(K1));\n+        repo.clearGlobalStatistics(K1);\n+        repo.clearGlobalStatistics(K1, \"col10\");\n+\n+        ObjectStatisticsImpl tab1Statistics = getStatistics(1);\n+\n+        repo.saveGlobalStatistics(K1, tab1Statistics);\n+\n+        assertNull(repo.getGlobalStatistics(K2));\n+\n+        assertEquals(1L, repo.getGlobalStatistics(K1).rowCount());\n+\n+        ObjectStatisticsImpl tab1Statistics2 = getStatistics(2);\n+\n+        repo.mergeGlobalStatistics(K1, tab1Statistics2);\n+\n+        assertEquals(2L, repo.getGlobalStatistics(K1).rowCount());\n+    }\n+\n+    /**\n+     * Test object statistics add:\n+     *\n+     * 1) Add statistics with partially the same columns.\n+     * 2) Add statistics with new columns.\n+     * 3) Add statistics with the same columns.\n+     */\n+    @Test\n+    public void addTest() {\n+        // 1) Add statistics with partially the same columns.\n+        HashMap<String, ColumnStatistics> colStat1 = new HashMap<>();\n+        colStat1.put(\"col1\", cs1);\n+        colStat1.put(\"col2\", cs2);\n+\n+        HashMap<String, ColumnStatistics> colStat2 = new HashMap<>();\n+        colStat2.put(\"col2\", cs3);\n+        colStat2.put(\"col3\", cs4);\n+\n+        ObjectStatisticsImpl os1 = new ObjectStatisticsImpl(100, colStat1);\n+        ObjectStatisticsImpl os2 = new ObjectStatisticsImpl(101, colStat2);\n+\n+        ObjectStatisticsImpl sumStat1 = IgniteStatisticsRepositoryImpl.add(os1, os2);\n+\n+        assertEquals(101, sumStat1.rowCount());\n+        assertEquals(3, sumStat1.columnsStatistics().size());\n+        assertEquals(cs3, sumStat1.columnStatistics(\"col2\"));\n+\n+        // 2) Add statistics with new columns.\n+        ObjectStatisticsImpl os3 = new ObjectStatisticsImpl(101, Collections.singletonMap(\"col3\", cs3));\n+\n+        ObjectStatisticsImpl sumStat2 = IgniteStatisticsRepositoryImpl.add(os1, os3);\n+\n+        assertEquals(3, sumStat2.columnsStatistics().size());\n+\n+        // 3) Add statistics with the same columns.\n+        HashMap<String, ColumnStatistics> colStat3 = new HashMap<>();\n+        colStat3.put(\"col1\", cs3);\n+        colStat3.put(\"col2\", cs4);\n+\n+        ObjectStatisticsImpl os4 = new ObjectStatisticsImpl(99, colStat3);\n+\n+        ObjectStatisticsImpl sumStat3 = IgniteStatisticsRepositoryImpl.add(os1, os4);\n+\n+        assertEquals(99, sumStat3.rowCount());\n+        assertEquals(2, sumStat3.columnsStatistics().size());\n+        assertEquals(cs3, sumStat3.columnStatistics(\"col1\"));\n+    }\n+\n+    /**\n+     * 1) Remove not existing column.\n+     * 2) Remove some columns.\n+     * 3) Remove all columns.\n+     */\n+    @Test\n+    public void subtractTest() {\n+        HashMap<String, ColumnStatistics> colStat1 = new HashMap<>();\n+        colStat1.put(\"col1\", cs1);\n+        colStat1.put(\"col2\", cs2);\n+\n+        ObjectStatisticsImpl os = new ObjectStatisticsImpl(100, colStat1);\n+\n+        // 1) Remove not existing column.\n+        ObjectStatisticsImpl os1 = IgniteStatisticsRepositoryImpl.subtract(os, new String[]{\"col0\"});\n+\n+        assertEquals(os, os1);\n+\n+        // 2) Remove some columns.\n+        ObjectStatisticsImpl os2 = IgniteStatisticsRepositoryImpl.subtract(os, new String[]{\"col1\"});\n+\n+        assertEquals(1, os2.columnsStatistics().size());\n+        assertEquals(cs2, os2.columnStatistics(\"col2\"));\n+\n+        // 3) Remove all columns.\n+        ObjectStatisticsImpl os3 = IgniteStatisticsRepositoryImpl.subtract(os, new String[]{\"col2\",\"col1\"});\n+\n+        assertTrue(os3.columnsStatistics().isEmpty());\n+    }\n }\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM2ODQ1MQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549368451", "body": "there is no need in circular dependency Store <--> Repo. So let's preserve only Repo --> Store", "bodyText": "there is no need in circular dependency Store <--> Repo. So let's preserve only Repo --> Store", "bodyHTML": "<p dir=\"auto\">there is no need in circular dependency Store &lt;--&gt; Repo. So let's preserve only Repo --&gt; Store</p>", "author": "korlov42", "createdAt": "2020-12-28T14:33:06Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsPersistenceStoreImpl.java", "diffHunk": "@@ -56,7 +56,7 @@\n     private final IgniteCacheDatabaseSharedManager db;\n \n     /** Statistics repository. */\n-    private final IgniteStatisticsRepository repo;\n+    private IgniteStatisticsRepository repo;", "originalCommit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTU3NzIwOA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r559577208", "bodyText": "Replaced with handler.", "author": "Berkof", "createdAt": "2021-01-18T13:46:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM2ODQ1MQ=="}], "type": "inlineReview", "revised_code": {"commit": "48b736c4cf138d5db12978e2004c446e26e1f097", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsPersistenceStoreImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsPersistenceStoreImpl.java\nindex 6e667ec2f41..51e4dade5ab 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsPersistenceStoreImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsPersistenceStoreImpl.java\n", "chunk": "@@ -49,14 +49,23 @@ public class IgniteStatisticsPersistenceStoreImpl implements IgniteStatisticsSto\n     /** Local metastore statistics prefix. */\n     private static final String META_STAT_PREFIX = \"stats\";\n \n+    /** Statistics data keys prefix. */\n+    private static final String STAT_DATA_PREFIX = META_STAT_PREFIX + META_SEPARATOR + \"data\";\n+\n+    /** Key to store version of stored statistics. */\n+    private static final String META_VERSION_KEY = META_STAT_PREFIX + META_SEPARATOR + \"version\";\n+\n+    /** Actual statistics version. */\n+    private static final Integer VERSION = 1;\n+\n     /** Logger. */\n     private final IgniteLogger log;\n \n     /** Database shared manager. */\n     private final IgniteCacheDatabaseSharedManager db;\n \n-    /** Statistics repository. */\n-    private IgniteStatisticsRepository repo;\n+    /** Handler to process loaded on start statistics. */\n+    private BiConsumer<StatisticsKey, List<ObjectPartitionStatisticsImpl>> loadHnd;\n \n     /** Metastorage. */\n     private volatile ReadWriteMetastorage metastore;\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM3NDUzMw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549374533", "body": "`return locStats.compute(key, (k, v) -> (v == null) ? statistics : add(v, statistics));`", "bodyText": "return locStats.compute(key, (k, v) -> (v == null) ? statistics : add(v, statistics));", "bodyHTML": "<p dir=\"auto\"><code>return locStats.compute(key, (k, v) -&gt; (v == null) ? statistics : add(v, statistics));</code></p>", "author": "korlov42", "createdAt": "2020-12-28T14:51:36Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java", "diffHunk": "@@ -209,37 +173,45 @@ public IgniteStatisticsRepositoryImpl(\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void mergeLocalStatistics(StatsKey key, ObjectStatisticsImpl statistics) {\n+    @Override public ObjectStatisticsImpl mergeLocalStatistics(StatisticsKey key, ObjectStatisticsImpl statistics) {\n         if (locStats == null) {\n             log.warning(\"Unable to merge local statistics for \" + key + \" on non server node.\");\n \n-            return;\n+            return null;\n         }\n+        ObjectStatisticsImpl[] res = new ObjectStatisticsImpl[1];\n+        locStats.compute(key, (k, v) -> {\n+            v = (v == null) ? statistics : add(v, statistics);\n+\n+            res[0] = v;\n \n-        locStats.compute(key, (k, v) -> (v == null) ? statistics : add(v, statistics));\n+            return v;\n+        });\n+        return res[0];", "originalCommit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM3NDg0OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549374848", "bodyText": "please fix also other places with such pattern", "author": "korlov42", "createdAt": "2020-12-28T14:52:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM3NDUzMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzA1Mjg0Mw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r557052843", "bodyText": "fixed", "author": "Berkof", "createdAt": "2021-01-14T05:31:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM3NDUzMw=="}], "type": "inlineReview", "revised_code": {"commit": "efd6b5e9f1f91625c2e6106b4c75522dada68b46", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\nindex 7cd002fe85c..aa46a02fd10 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n", "chunk": "@@ -179,15 +162,7 @@ public class IgniteStatisticsRepositoryImpl implements IgniteStatisticsRepositor\n \n             return null;\n         }\n-        ObjectStatisticsImpl[] res = new ObjectStatisticsImpl[1];\n-        locStats.compute(key, (k, v) -> {\n-            v = (v == null) ? statistics : add(v, statistics);\n-\n-            res[0] = v;\n-\n-            return v;\n-        });\n-        return res[0];\n+        return locStats.compute(key, (k, v) -> (v == null) ? statistics : add(v, statistics));\n     }\n \n     /** {@inheritDoc} */\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM3NTEyNA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549375124", "body": "missed space", "bodyText": "missed space", "bodyHTML": "<p dir=\"auto\">missed space</p>", "author": "korlov42", "createdAt": "2020-12-28T14:53:28Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java", "diffHunk": "@@ -256,22 +228,30 @@ public IgniteStatisticsRepositoryImpl(\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void saveGlobalStatistics(StatsKey key, ObjectStatisticsImpl statistics) {\n+    @Override public void saveGlobalStatistics(StatisticsKey key, ObjectStatisticsImpl statistics) {\n         globalStats.put(key, statistics);\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void mergeGlobalStatistics(StatsKey key, ObjectStatisticsImpl statistics) {\n-        globalStats.compute(key, (k,v) -> (v == null) ? statistics : add(v, statistics));\n+    @Override public ObjectStatisticsImpl mergeGlobalStatistics(StatisticsKey key, ObjectStatisticsImpl statistics) {\n+        ObjectStatisticsImpl[] res = new ObjectStatisticsImpl[1];\n+        globalStats.compute(key, (k,v) -> {", "originalCommit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "efd6b5e9f1f91625c2e6106b4c75522dada68b46", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\nindex 7cd002fe85c..aa46a02fd10 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n", "chunk": "@@ -234,15 +209,7 @@ public class IgniteStatisticsRepositoryImpl implements IgniteStatisticsRepositor\n \n     /** {@inheritDoc} */\n     @Override public ObjectStatisticsImpl mergeGlobalStatistics(StatisticsKey key, ObjectStatisticsImpl statistics) {\n-        ObjectStatisticsImpl[] res = new ObjectStatisticsImpl[1];\n-        globalStats.compute(key, (k,v) -> {\n-            v = (v == null) ? statistics : add(v, statistics);\n-\n-            res[0] = v;\n-\n-            return v;\n-        });\n-        return res[0];\n+        return globalStats.compute(key, (k, v) -> (v == null) ? statistics : add(v, statistics));\n     }\n \n     /** {@inheritDoc} */\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM4MDg4Ng==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549380886", "body": "mgr is not used anymore", "bodyText": "mgr is not used anymore", "bodyHTML": "<p dir=\"auto\">mgr is not used anymore</p>", "author": "korlov42", "createdAt": "2020-12-28T15:10:00Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java", "diffHunk": "@@ -71,38 +73,29 @@ public IgniteStatisticsRepositoryImpl(\n         }\n         else {\n             // Cache only global statistics, no store\n-            store = null;\n+            store = new IgniteStatisticsDummyStoreImpl(logSupplier);\n             locStats = null;\n-        }\n+        }*/\n+        this.store = store;\n+        this.locStats = new ConcurrentHashMap<>();\n         this.statisticsMgr = statisticsMgr;", "originalCommit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7ef165002105dd10417170217e86d65771c524bb", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\nindex 7cd002fe85c..a85ac18622b 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n", "chunk": "@@ -64,18 +64,6 @@ public class IgniteStatisticsRepositoryImpl implements IgniteStatisticsRepositor\n             StatisticsGathering statisticsGathering,\n             Function<Class<?>, IgniteLogger> logSupplier\n     ) {\n-        /*if (storeData) {\n-            // Persistence store\n-            store = (db == null) ? new IgniteStatisticsInMemoryStoreImpl(logSupplier) :\n-                    new IgniteStatisticsPersistenceStoreImpl(subscriptionProcessor, db, this, logSupplier);\n-\n-            locStats = new ConcurrentHashMap<>();\n-        }\n-        else {\n-            // Cache only global statistics, no store\n-            store = new IgniteStatisticsDummyStoreImpl(logSupplier);\n-            locStats = null;\n-        }*/\n         this.store = store;\n         this.locStats = new ConcurrentHashMap<>();\n         this.statisticsMgr = statisticsMgr;\n", "next_change": {"commit": "efd6b5e9f1f91625c2e6106b4c75522dada68b46", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\nindex a85ac18622b..aa46a02fd10 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n", "chunk": "@@ -52,21 +48,17 @@ public class IgniteStatisticsRepositoryImpl implements IgniteStatisticsRepositor\n     /**\n      * Constructor.\n      *\n-     * @param db Database to use in storage if persistence enabled.\n-     * @param subscriptionProcessor Subscription processor.\n-     * @param statisticsMgr Ignite statistics manager.\n+     * @param store Ignite statistics store to use.\n      * @param statisticsGathering Statistics gathering.\n      * @param logSupplier Ignite logger supplier to get logger from.\n      */\n     public IgniteStatisticsRepositoryImpl(\n             IgniteStatisticsStore store,\n-            IgniteStatisticsManagerImpl statisticsMgr,\n             StatisticsGathering statisticsGathering,\n             Function<Class<?>, IgniteLogger> logSupplier\n     ) {\n         this.store = store;\n         this.locStats = new ConcurrentHashMap<>();\n-        this.statisticsMgr = statisticsMgr;\n         this.statisticsGathering = statisticsGathering;\n         this.log = logSupplier.apply(IgniteStatisticsRepositoryImpl.class);\n     }\n", "next_change": {"commit": "48b736c4cf138d5db12978e2004c446e26e1f097", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\nindex aa46a02fd10..a869c30ad41 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n", "chunk": "@@ -49,17 +49,17 @@ public class IgniteStatisticsRepositoryImpl implements IgniteStatisticsRepositor\n      * Constructor.\n      *\n      * @param store Ignite statistics store to use.\n-     * @param statisticsGathering Statistics gathering.\n+     * @param helper IgniteStatisticsHelper.\n      * @param logSupplier Ignite logger supplier to get logger from.\n      */\n     public IgniteStatisticsRepositoryImpl(\n             IgniteStatisticsStore store,\n-            StatisticsGathering statisticsGathering,\n+            IgniteStatisticsHelper helper,\n             Function<Class<?>, IgniteLogger> logSupplier\n     ) {\n         this.store = store;\n         this.locStats = new ConcurrentHashMap<>();\n-        this.statisticsGathering = statisticsGathering;\n+        this.helper = helper;\n         this.log = logSupplier.apply(IgniteStatisticsRepositoryImpl.class);\n     }\n \n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM4NDAyOQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549384029", "body": "store should not know about repo", "bodyText": "store should not know about repo", "bodyHTML": "<p dir=\"auto\">store should not know about repo</p>", "author": "korlov42", "createdAt": "2020-12-28T15:18:23Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsStore.java", "diffHunk": "@@ -56,29 +56,36 @@\n      * @param partId Partition id.\n      * @return Object partition statistics or {@code null} if there are no statistics collected for such partition.\n      */\n-    public ObjectPartitionStatisticsImpl getLocalPartitionStatistics(StatsKey key, int partId);\n+    public ObjectPartitionStatisticsImpl getLocalPartitionStatistics(StatisticsKey key, int partId);\n \n     /**\n      * Clear partition statistics.\n      *\n      * @param key Object which statistics needs to be cleaned.\n      * @param partId Partition id.\n      */\n-    public void clearLocalPartitionStatistics(StatsKey key, int partId);\n+    public void clearLocalPartitionStatistics(StatisticsKey key, int partId);\n \n     /**\n      * Clear partitions statistics.\n      *\n      * @param key Object which statistics need to be cleaned.\n      * @param partIds Collection of partition ids.\n      */\n-    public void clearLocalPartitionsStatistics(StatsKey key, Collection<Integer> partIds);\n+    public void clearLocalPartitionsStatistics(StatisticsKey key, Collection<Integer> partIds);\n \n     /**\n      * Save partition statistics.\n      *\n      * @param key Object which partition statistics belongs to.\n      * @param statistics Statistics to save.\n      */\n-    public void saveLocalPartitionStatistics(StatsKey key, ObjectPartitionStatisticsImpl statistics);\n+    public void saveLocalPartitionStatistics(StatisticsKey key, ObjectPartitionStatisticsImpl statistics);\n+\n+    /**\n+     * Set statistics repository.\n+     *\n+     * @param repository Ignite statistics repository.\n+     */\n+    public void setRepository(IgniteStatisticsRepository repository);", "originalCommit": "f03f0e0216f93edace9e8347eddc6ee68388c727", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjU0MTU0Nw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556541547", "bodyText": "Do you prefer passing some handler to process existing statistics while it will be available?", "author": "Berkof", "createdAt": "2021-01-13T14:03:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM4NDAyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzUxMTc4MA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r557511780", "bodyText": "yep", "author": "korlov42", "createdAt": "2021-01-14T16:10:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM4NDAyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTU3Njc3OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r559576778", "bodyText": "done", "author": "Berkof", "createdAt": "2021-01-18T13:45:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTM4NDAyOQ=="}], "type": "inlineReview", "revised_code": {"commit": "05b732cd7e8840c429c48f5561e7c98e0289bcf6", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsStore.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsStore.java\nindex 28eadcf9023..e7effdcc655 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsStore.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsStore.java\n", "chunk": "@@ -87,5 +87,5 @@ public interface IgniteStatisticsStore {\n      *\n      * @param repository Ignite statistics repository.\n      */\n-    public void setRepository(IgniteStatisticsRepository repository);\n+    public void repository(IgniteStatisticsRepository repository);\n }\n", "next_change": {"commit": "48b736c4cf138d5db12978e2004c446e26e1f097", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsStore.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsStore.java\nindex e7effdcc655..b80ee1fc152 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsStore.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsStore.java\n", "chunk": "@@ -81,11 +81,4 @@ public interface IgniteStatisticsStore {\n      * @param statistics Statistics to save.\n      */\n     public void saveLocalPartitionStatistics(StatisticsKey key, ObjectPartitionStatisticsImpl statistics);\n-\n-    /**\n-     * Set statistics repository.\n-     *\n-     * @param repository Ignite statistics repository.\n-     */\n-    public void repository(IgniteStatisticsRepository repository);\n }\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYxNjk1Mg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549616952", "body": "I don't think we need a method to collect statistics by several objects at all", "bodyText": "I don't think we need a method to collect statistics by several objects at all", "bodyHTML": "<p dir=\"auto\">I don't think we need a method to collect statistics by several objects at all</p>", "author": "korlov42", "createdAt": "2020-12-29T08:35:12Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java", "diffHunk": "@@ -28,9 +35,29 @@\n      * @param objName Object to collect statistics by.\n      * @param colNames Columns to collect statistics by.\n      * @throws IgniteCheckedException  Throws in case of errors.\n+     * @return future to get fini\n      */\n     public void collectObjectStatistics(String schemaName, String objName, String... colNames) throws IgniteCheckedException;\n \n+    /**\n+     * Collect objects statistics.\n+     *\n+     * @param keys Collection of keys to collect statistics by (schema, obj, columns).\n+     * @return Future to track progress and cancel collection.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public StatsCollectionFuture<Map<GridTuple3<String, String, String[]>, ObjectStatistics>> collectObjectStatisticsAsync(", "originalCommit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjU0MDY5NQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556540695", "bodyText": "We discussed it - we need to collect statistics by several tables in the same cache group in single query.", "author": "Berkof", "createdAt": "2021-01-13T14:02:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYxNjk1Mg=="}], "type": "inlineReview", "revised_code": {"commit": "7ef165002105dd10417170217e86d65771c524bb", "changed_code": [{"header": "diff --git a/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java b/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java\nindex 17f46e9ea71..5f685e8c929 100644\n--- a/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java\n+++ b/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java\n", "chunk": "@@ -43,10 +38,10 @@ public interface IgniteStatisticsManager {\n      * Collect objects statistics.\n      *\n      * @param keys Collection of keys to collect statistics by (schema, obj, columns).\n-     * @return Future to track progress and cancel collection.\n+     * @return Array of futures, to track progress and cancel collection on each of specified cache group.\n      * @throws IgniteCheckedException In case of errors.\n      */\n-    public StatsCollectionFuture<Map<GridTuple3<String, String, String[]>, ObjectStatistics>> collectObjectStatisticsAsync(\n+    public StatsCollectionFuture<Map<GridTuple3<String, String, String[]>, ObjectStatistics>>[] collectObjectStatisticsAsync(\n         GridTuple3<String, String, String[]>... keys\n     ) throws IgniteCheckedException;\n \n", "next_change": {"commit": "17a54090bea4d97c122cf06d6be8e60177006519", "changed_code": [{"header": "diff --git a/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java b/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java\nindex 5f685e8c929..732a3118265 100644\n--- a/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java\n+++ b/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java\n", "chunk": "@@ -27,22 +27,20 @@ public interface IgniteStatisticsManager {\n     /**\n      * Collect object statistics.\n      *\n-     * @param schemaName Schema name.\n-     * @param objName Object to collect statistics by.\n-     * @param colNames Columns to collect statistics by.\n+     * @param target Target to collect statistics by.\n      * @throws IgniteCheckedException  Throws in case of errors.\n      */\n-    public void collectObjectStatistics(String schemaName, String objName, String... colNames) throws IgniteCheckedException;\n+    public void collectObjectStatistics(StatisticsTarget target) throws IgniteCheckedException;\n \n     /**\n      * Collect objects statistics.\n      *\n-     * @param keys Collection of keys to collect statistics by (schema, obj, columns).\n+     * @param targets Collection of targets to collect statistics by (schema, obj, columns).\n      * @return Array of futures, to track progress and cancel collection on each of specified cache group.\n      * @throws IgniteCheckedException In case of errors.\n      */\n-    public StatsCollectionFuture<Map<GridTuple3<String, String, String[]>, ObjectStatistics>>[] collectObjectStatisticsAsync(\n-        GridTuple3<String, String, String[]>... keys\n+    public StatisticsGatheringFuture<Map<StatisticsTarget, ObjectStatistics>>[] collectObjectStatisticsAsync(\n+        StatisticsTarget... targets\n     ) throws IgniteCheckedException;\n \n     /**\n", "next_change": {"commit": "33170812024f6c4d321f85287fea0b6c3abdb9e5", "changed_code": [{"header": "diff --git a/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java b/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java\nindex 732a3118265..d97905acbad 100644\n--- a/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java\n+++ b/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java\n", "chunk": "@@ -25,31 +25,32 @@ import java.util.UUID;\n  */\n public interface IgniteStatisticsManager {\n     /**\n-     * Collect object statistics.\n+     * Gather object statistics.\n      *\n-     * @param target Target to collect statistics by.\n+     * @param target Target to gather statistics by.\n      * @throws IgniteCheckedException  Throws in case of errors.\n      */\n-    public void collectObjectStatistics(StatisticsTarget target) throws IgniteCheckedException;\n+    public void gatherObjectStatistics(StatisticsTarget target) throws IgniteCheckedException;\n \n     /**\n-     * Collect objects statistics.\n+     * Gather objects statistics.\n      *\n-     * @param targets Collection of targets to collect statistics by (schema, obj, columns).\n+     * @param targets Gathering of targets to collect statistics by (schema, obj, columns).\n      * @return Array of futures, to track progress and cancel collection on each of specified cache group.\n      * @throws IgniteCheckedException In case of errors.\n      */\n-    public StatisticsGatheringFuture<Map<StatisticsTarget, ObjectStatistics>>[] collectObjectStatisticsAsync(\n+    public StatisticsGatheringFuture<Map<StatisticsTarget, ObjectStatistics>>[] gatherObjectStatisticsAsync(\n         StatisticsTarget... targets\n     ) throws IgniteCheckedException;\n \n     /**\n-     * Cancel object statistics collection.\n+     * Cancel object statistics gathering.\n      *\n-     * @param colId Collection id.\n-     * @return {@code true} if collection was cancelled, {@code false} if specified collection wasn't found.\n+     * @param gatId Gathering id.\n+     * @return {@code true} if gathering was cancelled, {@code false} if specified gathering wasn't found.\n+     * @throws IgniteCheckedException In case of errors (for example: unsupported feature)\n      */\n-    public boolean cancelObjectStatisticsGathering(UUID colId);\n+    public boolean cancelObjectStatisticsGathering(UUID gatId)  throws IgniteCheckedException;\n \n     /**\n      * Get local statistics by object.\n", "next_change": {"commit": "84c79eae65b6bf0fa8b36ad1c4fa09ca8d87cb6c", "changed_code": [{"header": "diff --git a/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java b/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java\nindex d97905acbad..db1bd2fefcf 100644\n--- a/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java\n+++ b/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java\n", "chunk": "@@ -50,7 +50,7 @@ public interface IgniteStatisticsManager {\n      * @return {@code true} if gathering was cancelled, {@code false} if specified gathering wasn't found.\n      * @throws IgniteCheckedException In case of errors (for example: unsupported feature)\n      */\n-    public boolean cancelObjectStatisticsGathering(UUID gatId)  throws IgniteCheckedException;\n+    public boolean cancelObjectStatisticsGathering(UUID gatId) throws IgniteCheckedException;\n \n     /**\n      * Get local statistics by object.\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYxNzI5Ng==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549617296", "body": "the same as for collection by several objects", "bodyText": "the same as for collection by several objects", "bodyHTML": "<p dir=\"auto\">the same as for collection by several objects</p>", "author": "korlov42", "createdAt": "2020-12-29T08:36:19Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java", "diffHunk": "@@ -46,6 +73,15 @@\n      * @param schemaName Schema name.\n      * @param objName Object to collect statistics by.\n      * @param colNames Columns to remove statistics by.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public void clearObjectStatistics(String schemaName, String objName, String... colNames) throws IgniteCheckedException;\n+\n+    /**\n+     * Clear object statistics.\n+     *\n+     * @param keys Collection of keys to collect statistics by (schema, obj, columns).\n+     * @throws IgniteCheckedException In case of errors.\n      */\n-    public void clearObjectStatistics(String schemaName, String objName, String... colNames);\n+    public void clearObjectStatistics(GridTuple3<String, String, String[]>... keys) throws IgniteCheckedException;", "originalCommit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "17a54090bea4d97c122cf06d6be8e60177006519", "changed_code": [{"header": "diff --git a/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java b/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java\nindex 17f46e9ea71..732a3118265 100644\n--- a/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java\n+++ b/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java\n", "chunk": "@@ -70,18 +63,8 @@ public interface IgniteStatisticsManager {\n     /**\n      * Clear object statistics.\n      *\n-     * @param schemaName Schema name.\n-     * @param objName Object to collect statistics by.\n-     * @param colNames Columns to remove statistics by.\n-     * @throws IgniteCheckedException In case of errors.\n-     */\n-    public void clearObjectStatistics(String schemaName, String objName, String... colNames) throws IgniteCheckedException;\n-\n-    /**\n-     * Clear object statistics.\n-     *\n-     * @param keys Collection of keys to collect statistics by (schema, obj, columns).\n+     * @param targets Collection of target to collect statistics by (schema, obj, columns).\n      * @throws IgniteCheckedException In case of errors.\n      */\n-    public void clearObjectStatistics(GridTuple3<String, String, String[]>... keys) throws IgniteCheckedException;\n+    public void clearObjectStatistics(StatisticsTarget... targets) throws IgniteCheckedException;\n }\n", "next_change": {"commit": "33170812024f6c4d321f85287fea0b6c3abdb9e5", "changed_code": [{"header": "diff --git a/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java b/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java\nindex 732a3118265..d97905acbad 100644\n--- a/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java\n+++ b/modules/core/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManager.java\n", "chunk": "@@ -60,11 +61,21 @@ public interface IgniteStatisticsManager {\n      */\n     public ObjectStatistics getLocalStatistics(String schemaName, String objName);\n \n+    /**\n+     * Get global statistics by object.\n+     *\n+     * @param schemaName Schema name.\n+     * @param objName Object to collect statistics by.\n+     * @return Object statistics or {@code null} if there are no available statistics by specified object.\n+     * @throws IgniteCheckedException In case of errors (for example: unsupported feature)\n+     */\n+    public ObjectStatistics getGlobalStatistics(String schemaName, String objName) throws IgniteCheckedException;\n+\n     /**\n      * Clear object statistics.\n      *\n      * @param targets Collection of target to collect statistics by (schema, obj, columns).\n-     * @throws IgniteCheckedException In case of errors.\n+     * @throws IgniteCheckedException In case of errors (for example: unsupported feature)\n      */\n     public void clearObjectStatistics(StatisticsTarget... targets) throws IgniteCheckedException;\n }\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYxODI3NA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549618274", "body": "please add empty lines", "bodyText": "please add empty lines", "bodyHTML": "<p dir=\"auto\">please add empty lines</p>", "author": "korlov42", "createdAt": "2020-12-29T08:39:23Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/util/GridArrays.java", "diffHunk": "@@ -111,4 +115,38 @@ public static void clearTail(Object[] arr, int fromIdx) {\n         while (fromIdx < arr.length && arr[fromIdx] != null)\n             arr[fromIdx++] = null;\n     }\n+\n+    /**\n+     * Intersect two specified arrays.\n+     *\n+     * @param a First array or {@code null}.\n+     * @param b Second array or {@code null}.\n+     * @return Arrays intersection.\n+     */\n+    public static int[] intersect(int[] a, int[] b) {", "originalCommit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTgxNjYzMw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555816633", "bodyText": "this is not used anymore", "author": "korlov42", "createdAt": "2021-01-12T14:35:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYxODI3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUzOTcxMQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556539711", "bodyText": "removed", "author": "Berkof", "createdAt": "2021-01-13T14:00:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYxODI3NA=="}], "type": "inlineReview", "revised_code": {"commit": "17a54090bea4d97c122cf06d6be8e60177006519", "changed_code": [{"header": "diff --git a/modules/core/src/main/java/org/apache/ignite/internal/util/GridArrays.java b/modules/core/src/main/java/org/apache/ignite/internal/util/GridArrays.java\nindex 52dfbee26e9..96df802e708 100644\n--- a/modules/core/src/main/java/org/apache/ignite/internal/util/GridArrays.java\n+++ b/modules/core/src/main/java/org/apache/ignite/internal/util/GridArrays.java\n", "chunk": "@@ -116,24 +119,6 @@ public final class GridArrays {\n             arr[fromIdx++] = null;\n     }\n \n-    /**\n-     * Intersect two specified arrays.\n-     *\n-     * @param a First array or {@code null}.\n-     * @param b Second array or {@code null}.\n-     * @return Arrays intersection.\n-     */\n-    public static int[] intersect(int[] a, int[] b) {\n-        if (a == null || b == null)\n-            return new int[0];\n-        Set<Integer> aSet = Arrays.stream(a).boxed().collect(Collectors.toSet());\n-        List<Integer> res = new ArrayList<>();\n-        for (int bVal : b)\n-            if (aSet.contains(bVal))\n-                res.add(bVal);\n-        return res.stream().mapToInt(Integer::intValue).toArray();\n-    }\n-\n     /**\n      * Subtract b array from a array.\n      *\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYxODM2Mg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549618362", "body": "null handling", "bodyText": "null handling", "bodyHTML": "<p dir=\"auto\">null handling</p>", "author": "korlov42", "createdAt": "2020-12-29T08:39:41Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/util/GridArrays.java", "diffHunk": "@@ -111,4 +115,38 @@ public static void clearTail(Object[] arr, int fromIdx) {\n         while (fromIdx < arr.length && arr[fromIdx] != null)\n             arr[fromIdx++] = null;\n     }\n+\n+    /**\n+     * Intersect two specified arrays.\n+     *\n+     * @param a First array or {@code null}.\n+     * @param b Second array or {@code null}.\n+     * @return Arrays intersection.\n+     */\n+    public static int[] intersect(int[] a, int[] b) {\n+        if (a == null || b == null)\n+            return new int[0];\n+        Set<Integer> aSet = Arrays.stream(a).boxed().collect(Collectors.toSet());\n+        List<Integer> res = new ArrayList<>();\n+        for (int bVal : b)\n+            if (aSet.contains(bVal))\n+                res.add(bVal);\n+        return res.stream().mapToInt(Integer::intValue).toArray();\n+    }\n+\n+    /**\n+     * Subtract b array from a array.\n+     *\n+     * @param a Base array.\n+     * @param b Array to subtract from the base one.\n+     * @return Subtraction result.\n+     */\n+    public static int[] subtract(int[] a, int[] b) {\n+        Set<Integer> bSet = Arrays.stream(b).boxed().collect(Collectors.toSet());", "originalCommit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUzOTE2MA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556539160", "bodyText": "Why should I handle null arrays here? In javadoc no option with null array.", "author": "Berkof", "createdAt": "2021-01-13T14:00:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYxODM2Mg=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYyMDI3OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549620278", "body": "dot", "bodyText": "dot", "bodyHTML": "<p dir=\"auto\">dot</p>", "author": "korlov42", "createdAt": "2020-12-29T08:46:09Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,344 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by", "originalCommit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjMxNDU1Ng==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556314556", "bodyText": "fixed", "author": "Berkof", "createdAt": "2021-01-13T07:35:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYyMDI3OA=="}], "type": "inlineReview", "revised_code": {"commit": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 4210ae9137b..86d3d41f996 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -81,14 +95,36 @@ public class IgniteStatisticsHelper {\n         return res;\n     }\n \n+    /**\n+     * Return all nodes where specified cache group located.\n+     *\n+     * @param grp Cache group context to locate.\n+     * @return Set of node ids where group located.\n+     */\n+    public static Set<UUID> nodes(CacheGroupContext grp) {\n+        Set<UUID> res = new HashSet<>();\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        assignments.forEach(pnodes -> pnodes.forEach(cn -> res.add(cn.id())));\n+\n+        return res;\n+    }\n+\n     /**\n      * Get map cluster node to it's partitions for the specified cache group.\n      *\n      * @param grp Cache group context to get partition information by.\n      * @param partIds Partition to collect information by\n+     * @param isPrimary if {@code true} - only master partitions will be selected, if {@code false} - only backups.\n      * @return Map nodeId to array of partitions, related to node.\n      */\n-    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+    public static Map<UUID, int[]> nodePartitions(\n+        CacheGroupContext grp,\n+        Collection<Integer> partIds,\n+        boolean isPrimary\n+    ) {\n         AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n         // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n         List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n", "next_change": {"commit": "fc2e8cbb19ef01669beaa69a239b2c7f8fb495db", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 86d3d41f996..5f0a2f7e2d0 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -126,7 +164,6 @@ public class IgniteStatisticsHelper {\n         boolean isPrimary\n     ) {\n         AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n-        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n         List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n \n         Map<UUID, List<Integer>> res = new HashMap<>();\n", "next_change": {"commit": "17a54090bea4d97c122cf06d6be8e60177006519", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 5f0a2f7e2d0..f53952e7a19 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -166,44 +163,29 @@ public class IgniteStatisticsHelper {\n         AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n         List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n \n-        Map<UUID, List<Integer>> res = new HashMap<>();\n         if (partIds == null)\n-            for (int i = 0; i < assignments.size(); i++)\n-                fillPartition(res, assignments, i, isPrimary);\n-        else\n-            for (Integer partId : partIds)\n-                fillPartition(res, assignments, partId, isPrimary);\n+            partIds = IntStream.range(0, assignments.size()).boxed().collect(Collectors.toList());\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        for (Integer partId : partIds) {\n+            assert partId < assignments.size();\n+\n+            List<ClusterNode> partNodes = assignments.get(partId);\n+            if (F.isEmpty(partNodes))\n+                continue;\n+\n+            if (isPrimary)\n+                res.computeIfAbsent(partNodes.get(0).id(), k -> new ArrayList<>()).add(partId);\n+            else {\n+                for (int i = 1; i < partNodes.size(); i++)\n+                    res.computeIfAbsent(partNodes.get(i).id(), k -> new ArrayList<>()).add(partId);\n+            }\n+        }\n \n         return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n                 v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n     }\n \n-    /**\n-     * Fill map with master or backups node of specified partition.\n-     *\n-     * @param res Map to fill.\n-     * @param assignments Partitions assignments.\n-     * @param partId Partition to process.\n-     * @param isPrimary if {@code true} only primary nodes will be choosen, if {@code false} - only backups.\n-     */\n-    protected static void fillPartition(\n-        Map<UUID, List<Integer>> res,\n-        List<List<ClusterNode>> assignments,\n-        int partId,\n-        boolean isPrimary\n-    ) {\n-        assert partId < assignments.size();\n-        List<ClusterNode> partNodes = assignments.get(partId);\n-        if (F.isEmpty(partNodes))\n-            return;\n-\n-        if (isPrimary)\n-            res.computeIfAbsent(partNodes.get(0).id(), k -> new ArrayList<>()).add(partId);\n-        else\n-            for (int i = 1; i < partNodes.size() - 1; i++)\n-                res.computeIfAbsent(partNodes.get(i).id(), k -> new ArrayList<>()).add(partId);\n-    }\n-\n     /**\n      * Get all nodes where specified cache groups located.\n      *\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYyMDYwNw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549620607", "body": "space", "bodyText": "space", "bodyHTML": "<p dir=\"auto\">space</p>", "author": "korlov42", "createdAt": "2020-12-29T08:47:07Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,344 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(", "originalCommit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUzNzMwNQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556537305", "bodyText": "outdated", "author": "Berkof", "createdAt": "2021-01-13T13:57:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYyMDYwNw=="}], "type": "inlineReview", "revised_code": {"commit": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 4210ae9137b..86d3d41f996 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -96,40 +132,53 @@ public class IgniteStatisticsHelper {\n         Map<UUID, List<Integer>> res = new HashMap<>();\n         if (partIds == null)\n             for (int i = 0; i < assignments.size(); i++)\n-                fillPartitionMaster(res, assignments, i);\n+                fillPartition(res, assignments, i, isPrimary);\n         else\n             for (Integer partId : partIds)\n-                fillPartitionMaster(res, assignments, partId);\n+                fillPartition(res, assignments, partId, isPrimary);\n \n         return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n                 v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n     }\n \n     /**\n-     * Fill map with master node of specified partition.\n+     * Fill map with master or backups node of specified partition.\n      *\n      * @param res Map to fill.\n      * @param assignments Partitions assignments.\n      * @param partId Partition to process.\n+     * @param isPrimary if {@code true} only primary nodes will be choosen, if {@code false} - only backups.\n      */\n-    protected static  void fillPartitionMaster(\n+    protected static  void fillPartition(\n         Map<UUID, List<Integer>> res,\n         List<List<ClusterNode>> assignments,\n-        int partId\n+        int partId,\n+        boolean isPrimary\n     ) {\n         assert partId < assignments.size();\n         List<ClusterNode> partNodes = assignments.get(partId);\n         if (F.isEmpty(partNodes))\n             return;\n \n-        res.compute(partNodes.get(0).id(), (k, v) -> {\n-            if (v == null)\n-                v = new ArrayList<>();\n+        if (isPrimary)\n+            res.compute(partNodes.get(0).id(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n \n-            v.add(partId);\n+                v.add(partId);\n \n-            return v;\n-        });\n+                return v;\n+            });\n+        else\n+            for (int i = 1; i < partNodes.size() - 1; i++)\n+                res.compute(partNodes.get(i).id(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+\n+                    v.add(partId);\n+\n+                    return v;\n+                });\n     }\n \n     /**\n", "next_change": {"commit": "7ef165002105dd10417170217e86d65771c524bb", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 86d3d41f996..b215186973d 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -181,72 +202,6 @@ public class IgniteStatisticsHelper {\n                 });\n     }\n \n-    /**\n-     * Prepare statistics collection request for specified node.\n-     *\n-     * @param colId Collection id.\n-     * @param data Keys to partitions for current node.\n-     * @return Statistics collection request.\n-     */\n-    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n-        UUID reqId = UUID.randomUUID();\n-        return new StatisticsGatheringRequest(colId, reqId, data);\n-    }\n-\n-    // TODO add extraction of necessary partIds by statKeyMsg\n-\n-    /**\n-     * Generate statistics collection requests by given keys.\n-     *\n-     * @param colId Collection id.\n-     * @param locNodeId Local node id.\n-     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n-     *            If {@code null} - requests will be\n-     * @return Collection of statistics collection addressed request.\n-     */\n-    public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n-        UUID colId,\n-        UUID locNodeId,\n-        Map<StatisticsKeyMessage, int[]> failedPartitions,\n-        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts\n-    ) {\n-        // NodeId to <Key to partitions on node> map\n-        Map<UUID, Map<StatisticsKeyMessage, int[]>> reqMap = new HashMap<>();\n-        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n-            // TODO: can we specify partitions here? from failed parts will it be effective?\n-            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null, true);\n-\n-            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n-                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n-                    if (v == null)\n-                        v = new HashMap<>();\n-\n-                    Collection<StatisticsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n-\n-                    for (StatisticsKeyMessage key : grpKeys) {\n-                        int[] keyNodeParts = (failedPartitions == null) ? nodeParts.getValue() :\n-                                GridArrays.intersect(nodeParts.getValue(), failedPartitions.get(key));\n-\n-                        if (keyNodeParts.length > 0)\n-                            v.put(key, keyNodeParts);\n-                    }\n-\n-                    return v.isEmpty() ? null : v;\n-                });\n-        }\n-\n-        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs = new ArrayList<>();\n-        for (Map.Entry<UUID, Map<StatisticsKeyMessage, int[]>> nodeGpsParts: reqMap.entrySet()) {\n-            if (nodeGpsParts.getValue().isEmpty())\n-                continue;\n-\n-            StatisticsGatheringRequest req = prepareRequest(colId, nodeGpsParts.getValue());\n-            reqs.add(new StatisticsAddrRequest<>(req, locNodeId, nodeGpsParts.getKey()));\n-        }\n-\n-        return reqs;\n-    }\n-\n     /**\n      * Get all nodes where specified cache groups located.\n      *\n", "next_change": {"commit": "fc2e8cbb19ef01669beaa69a239b2c7f8fb495db", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex b215186973d..5f0a2f7e2d0 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -182,24 +198,10 @@ public class IgniteStatisticsHelper {\n             return;\n \n         if (isPrimary)\n-            res.compute(partNodes.get(0).id(), (k, v) -> {\n-                if (v == null)\n-                    v = new ArrayList<>();\n-\n-                v.add(partId);\n-\n-                return v;\n-            });\n+            res.computeIfAbsent(partNodes.get(0).id(), k -> new ArrayList<>()).add(partId);\n         else\n             for (int i = 1; i < partNodes.size() - 1; i++)\n-                res.compute(partNodes.get(i).id(), (k, v) -> {\n-                    if (v == null)\n-                        v = new ArrayList<>();\n-\n-                    v.add(partId);\n-\n-                    return v;\n-                });\n+                res.computeIfAbsent(partNodes.get(i).id(), k -> new ArrayList<>()).add(partId);\n     }\n \n     /**\n", "next_change": {"commit": "17a54090bea4d97c122cf06d6be8e60177006519", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 5f0a2f7e2d0..f53952e7a19 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -166,44 +163,29 @@ public class IgniteStatisticsHelper {\n         AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n         List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n \n-        Map<UUID, List<Integer>> res = new HashMap<>();\n         if (partIds == null)\n-            for (int i = 0; i < assignments.size(); i++)\n-                fillPartition(res, assignments, i, isPrimary);\n-        else\n-            for (Integer partId : partIds)\n-                fillPartition(res, assignments, partId, isPrimary);\n+            partIds = IntStream.range(0, assignments.size()).boxed().collect(Collectors.toList());\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        for (Integer partId : partIds) {\n+            assert partId < assignments.size();\n+\n+            List<ClusterNode> partNodes = assignments.get(partId);\n+            if (F.isEmpty(partNodes))\n+                continue;\n+\n+            if (isPrimary)\n+                res.computeIfAbsent(partNodes.get(0).id(), k -> new ArrayList<>()).add(partId);\n+            else {\n+                for (int i = 1; i < partNodes.size(); i++)\n+                    res.computeIfAbsent(partNodes.get(i).id(), k -> new ArrayList<>()).add(partId);\n+            }\n+        }\n \n         return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n                 v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n     }\n \n-    /**\n-     * Fill map with master or backups node of specified partition.\n-     *\n-     * @param res Map to fill.\n-     * @param assignments Partitions assignments.\n-     * @param partId Partition to process.\n-     * @param isPrimary if {@code true} only primary nodes will be choosen, if {@code false} - only backups.\n-     */\n-    protected static void fillPartition(\n-        Map<UUID, List<Integer>> res,\n-        List<List<ClusterNode>> assignments,\n-        int partId,\n-        boolean isPrimary\n-    ) {\n-        assert partId < assignments.size();\n-        List<ClusterNode> partNodes = assignments.get(partId);\n-        if (F.isEmpty(partNodes))\n-            return;\n-\n-        if (isPrimary)\n-            res.computeIfAbsent(partNodes.get(0).id(), k -> new ArrayList<>()).add(partId);\n-        else\n-            for (int i = 1; i < partNodes.size() - 1; i++)\n-                res.computeIfAbsent(partNodes.get(i).id(), k -> new ArrayList<>()).add(partId);\n-    }\n-\n     /**\n      * Get all nodes where specified cache groups located.\n      *\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYyMDc5NQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549620795", "body": "we use 'primary' term", "bodyText": "we use 'primary' term", "bodyHTML": "<p dir=\"auto\">we use 'primary' term</p>", "author": "korlov42", "createdAt": "2020-12-29T08:47:47Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,344 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(", "originalCommit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUzNjg0OQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556536849", "bodyText": "renamed", "author": "Berkof", "createdAt": "2021-01-13T13:56:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYyMDc5NQ=="}], "type": "inlineReview", "revised_code": {"commit": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 4210ae9137b..86d3d41f996 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -96,40 +132,53 @@ public class IgniteStatisticsHelper {\n         Map<UUID, List<Integer>> res = new HashMap<>();\n         if (partIds == null)\n             for (int i = 0; i < assignments.size(); i++)\n-                fillPartitionMaster(res, assignments, i);\n+                fillPartition(res, assignments, i, isPrimary);\n         else\n             for (Integer partId : partIds)\n-                fillPartitionMaster(res, assignments, partId);\n+                fillPartition(res, assignments, partId, isPrimary);\n \n         return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n                 v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n     }\n \n     /**\n-     * Fill map with master node of specified partition.\n+     * Fill map with master or backups node of specified partition.\n      *\n      * @param res Map to fill.\n      * @param assignments Partitions assignments.\n      * @param partId Partition to process.\n+     * @param isPrimary if {@code true} only primary nodes will be choosen, if {@code false} - only backups.\n      */\n-    protected static  void fillPartitionMaster(\n+    protected static  void fillPartition(\n         Map<UUID, List<Integer>> res,\n         List<List<ClusterNode>> assignments,\n-        int partId\n+        int partId,\n+        boolean isPrimary\n     ) {\n         assert partId < assignments.size();\n         List<ClusterNode> partNodes = assignments.get(partId);\n         if (F.isEmpty(partNodes))\n             return;\n \n-        res.compute(partNodes.get(0).id(), (k, v) -> {\n-            if (v == null)\n-                v = new ArrayList<>();\n+        if (isPrimary)\n+            res.compute(partNodes.get(0).id(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n \n-            v.add(partId);\n+                v.add(partId);\n \n-            return v;\n-        });\n+                return v;\n+            });\n+        else\n+            for (int i = 1; i < partNodes.size() - 1; i++)\n+                res.compute(partNodes.get(i).id(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+\n+                    v.add(partId);\n+\n+                    return v;\n+                });\n     }\n \n     /**\n", "next_change": {"commit": "7ef165002105dd10417170217e86d65771c524bb", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 86d3d41f996..b215186973d 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -181,72 +202,6 @@ public class IgniteStatisticsHelper {\n                 });\n     }\n \n-    /**\n-     * Prepare statistics collection request for specified node.\n-     *\n-     * @param colId Collection id.\n-     * @param data Keys to partitions for current node.\n-     * @return Statistics collection request.\n-     */\n-    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n-        UUID reqId = UUID.randomUUID();\n-        return new StatisticsGatheringRequest(colId, reqId, data);\n-    }\n-\n-    // TODO add extraction of necessary partIds by statKeyMsg\n-\n-    /**\n-     * Generate statistics collection requests by given keys.\n-     *\n-     * @param colId Collection id.\n-     * @param locNodeId Local node id.\n-     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n-     *            If {@code null} - requests will be\n-     * @return Collection of statistics collection addressed request.\n-     */\n-    public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n-        UUID colId,\n-        UUID locNodeId,\n-        Map<StatisticsKeyMessage, int[]> failedPartitions,\n-        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts\n-    ) {\n-        // NodeId to <Key to partitions on node> map\n-        Map<UUID, Map<StatisticsKeyMessage, int[]>> reqMap = new HashMap<>();\n-        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n-            // TODO: can we specify partitions here? from failed parts will it be effective?\n-            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null, true);\n-\n-            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n-                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n-                    if (v == null)\n-                        v = new HashMap<>();\n-\n-                    Collection<StatisticsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n-\n-                    for (StatisticsKeyMessage key : grpKeys) {\n-                        int[] keyNodeParts = (failedPartitions == null) ? nodeParts.getValue() :\n-                                GridArrays.intersect(nodeParts.getValue(), failedPartitions.get(key));\n-\n-                        if (keyNodeParts.length > 0)\n-                            v.put(key, keyNodeParts);\n-                    }\n-\n-                    return v.isEmpty() ? null : v;\n-                });\n-        }\n-\n-        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs = new ArrayList<>();\n-        for (Map.Entry<UUID, Map<StatisticsKeyMessage, int[]>> nodeGpsParts: reqMap.entrySet()) {\n-            if (nodeGpsParts.getValue().isEmpty())\n-                continue;\n-\n-            StatisticsGatheringRequest req = prepareRequest(colId, nodeGpsParts.getValue());\n-            reqs.add(new StatisticsAddrRequest<>(req, locNodeId, nodeGpsParts.getKey()));\n-        }\n-\n-        return reqs;\n-    }\n-\n     /**\n      * Get all nodes where specified cache groups located.\n      *\n", "next_change": {"commit": "fc2e8cbb19ef01669beaa69a239b2c7f8fb495db", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex b215186973d..5f0a2f7e2d0 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -182,24 +198,10 @@ public class IgniteStatisticsHelper {\n             return;\n \n         if (isPrimary)\n-            res.compute(partNodes.get(0).id(), (k, v) -> {\n-                if (v == null)\n-                    v = new ArrayList<>();\n-\n-                v.add(partId);\n-\n-                return v;\n-            });\n+            res.computeIfAbsent(partNodes.get(0).id(), k -> new ArrayList<>()).add(partId);\n         else\n             for (int i = 1; i < partNodes.size() - 1; i++)\n-                res.compute(partNodes.get(i).id(), (k, v) -> {\n-                    if (v == null)\n-                        v = new ArrayList<>();\n-\n-                    v.add(partId);\n-\n-                    return v;\n-                });\n+                res.computeIfAbsent(partNodes.get(i).id(), k -> new ArrayList<>()).add(partId);\n     }\n \n     /**\n", "next_change": {"commit": "17a54090bea4d97c122cf06d6be8e60177006519", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 5f0a2f7e2d0..f53952e7a19 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -166,44 +163,29 @@ public class IgniteStatisticsHelper {\n         AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n         List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n \n-        Map<UUID, List<Integer>> res = new HashMap<>();\n         if (partIds == null)\n-            for (int i = 0; i < assignments.size(); i++)\n-                fillPartition(res, assignments, i, isPrimary);\n-        else\n-            for (Integer partId : partIds)\n-                fillPartition(res, assignments, partId, isPrimary);\n+            partIds = IntStream.range(0, assignments.size()).boxed().collect(Collectors.toList());\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        for (Integer partId : partIds) {\n+            assert partId < assignments.size();\n+\n+            List<ClusterNode> partNodes = assignments.get(partId);\n+            if (F.isEmpty(partNodes))\n+                continue;\n+\n+            if (isPrimary)\n+                res.computeIfAbsent(partNodes.get(0).id(), k -> new ArrayList<>()).add(partId);\n+            else {\n+                for (int i = 1; i < partNodes.size(); i++)\n+                    res.computeIfAbsent(partNodes.get(i).id(), k -> new ArrayList<>()).add(partId);\n+            }\n+        }\n \n         return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n                 v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n     }\n \n-    /**\n-     * Fill map with master or backups node of specified partition.\n-     *\n-     * @param res Map to fill.\n-     * @param assignments Partitions assignments.\n-     * @param partId Partition to process.\n-     * @param isPrimary if {@code true} only primary nodes will be choosen, if {@code false} - only backups.\n-     */\n-    protected static void fillPartition(\n-        Map<UUID, List<Integer>> res,\n-        List<List<ClusterNode>> assignments,\n-        int partId,\n-        boolean isPrimary\n-    ) {\n-        assert partId < assignments.size();\n-        List<ClusterNode> partNodes = assignments.get(partId);\n-        if (F.isEmpty(partNodes))\n-            return;\n-\n-        if (isPrimary)\n-            res.computeIfAbsent(partNodes.get(0).id(), k -> new ArrayList<>()).add(partId);\n-        else\n-            for (int i = 1; i < partNodes.size() - 1; i++)\n-                res.computeIfAbsent(partNodes.get(i).id(), k -> new ArrayList<>()).add(partId);\n-    }\n-\n     /**\n      * Get all nodes where specified cache groups located.\n      *\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYyMTI1OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549621258", "body": "todo", "bodyText": "todo", "bodyHTML": "<p dir=\"auto\">todo</p>", "author": "korlov42", "createdAt": "2020-12-29T08:49:29Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,344 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatisticsGatheringRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg", "originalCommit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUzNjQyMQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556536421", "bodyText": "removed", "author": "Berkof", "createdAt": "2021-01-13T13:56:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYyMTI1OA=="}], "type": "inlineReview", "revised_code": {"commit": "7ef165002105dd10417170217e86d65771c524bb", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 4210ae9137b..b215186973d 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -96,117 +153,64 @@ public class IgniteStatisticsHelper {\n         Map<UUID, List<Integer>> res = new HashMap<>();\n         if (partIds == null)\n             for (int i = 0; i < assignments.size(); i++)\n-                fillPartitionMaster(res, assignments, i);\n+                fillPartition(res, assignments, i, isPrimary);\n         else\n             for (Integer partId : partIds)\n-                fillPartitionMaster(res, assignments, partId);\n+                fillPartition(res, assignments, partId, isPrimary);\n \n         return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n                 v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n     }\n \n     /**\n-     * Fill map with master node of specified partition.\n+     * Fill map with master or backups node of specified partition.\n      *\n      * @param res Map to fill.\n      * @param assignments Partitions assignments.\n      * @param partId Partition to process.\n+     * @param isPrimary if {@code true} only primary nodes will be choosen, if {@code false} - only backups.\n      */\n-    protected static  void fillPartitionMaster(\n+    protected static  void fillPartition(\n         Map<UUID, List<Integer>> res,\n         List<List<ClusterNode>> assignments,\n-        int partId\n+        int partId,\n+        boolean isPrimary\n     ) {\n         assert partId < assignments.size();\n         List<ClusterNode> partNodes = assignments.get(partId);\n         if (F.isEmpty(partNodes))\n             return;\n \n-        res.compute(partNodes.get(0).id(), (k, v) -> {\n-            if (v == null)\n-                v = new ArrayList<>();\n-\n-            v.add(partId);\n-\n-            return v;\n-        });\n-    }\n-\n-    /**\n-     * Prepare statistics collection request for specified node.\n-     *\n-     * @param colId Collection id.\n-     * @param data Keys to partitions for current node.\n-     * @return Statistics collection request.\n-     */\n-    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n-        UUID reqId = UUID.randomUUID();\n-        return new StatisticsGatheringRequest(colId, reqId, data);\n-    }\n-\n-    // TODO add extraction of necessary partIds by statKeyMsg\n+        if (isPrimary)\n+            res.compute(partNodes.get(0).id(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n \n-    /**\n-     * Generate statistics collection requests by given keys.\n-     *\n-     * @param colId Collection id.\n-     * @param locNodeId Local node id.\n-     * @param keys Collection of keys to collect statistics by.\n-     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n-     *            If {@code null} - requests will be\n-     * @return Collection of statistics collection addressed request.\n-     * @throws IgniteCheckedException In case of errors.\n-     */\n-    public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n-        UUID colId,\n-        UUID locNodeId,\n-        Collection<StatisticsKeyMessage> keys,\n-        Map<StatisticsKeyMessage, int[]> failedPartitions,\n-        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts\n-    ) {\n+                v.add(partId);\n \n-        // NodeId to <Key to partitions on node> map\n-        Map<UUID, Map<StatisticsKeyMessage, int[]>> reqMap = new HashMap<>();\n-        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n-            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null); // TODO Null?\n-            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n-                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n+                return v;\n+            });\n+        else\n+            for (int i = 1; i < partNodes.size() - 1; i++)\n+                res.compute(partNodes.get(i).id(), (k, v) -> {\n                     if (v == null)\n-                        v = new HashMap<>();\n-\n-                    Collection<StatisticsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n-\n-                    for (StatisticsKeyMessage key : grpKeys) {\n-                        int[] keyNodeParts = (failedPartitions == null) ? nodeParts.getValue() :\n-                                GridArrays.intersect(nodeParts.getValue(), failedPartitions.get(key));\n+                        v = new ArrayList<>();\n \n-                        if (keyNodeParts.length > 0)\n-                            v.put(key, keyNodeParts);\n-                    }\n+                    v.add(partId);\n \n-                    return v.isEmpty() ? null : v;\n+                    return v;\n                 });\n-        }\n-\n-        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs = new ArrayList<>();\n-        for (Map.Entry<UUID, Map<StatisticsKeyMessage, int[]>> nodeGpsParts: reqMap.entrySet()) {\n-            if (nodeGpsParts.getValue().isEmpty())\n-                continue;\n-\n-            StatisticsGatheringRequest req = prepareRequest(colId, nodeGpsParts.getValue());\n-            reqs.add(new StatisticsAddrRequest<>(req, locNodeId, nodeGpsParts.getKey()));\n-        }\n-\n-        return reqs;\n     }\n \n     /**\n-     * Get all nodes where specified cache grous located.\n+     * Get all nodes where specified cache groups located.\n      *\n      * @param grps Cache groups.\n      * @return Set of node ids.\n      */\n-    public static Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys(Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grps) {\n+    public static Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys(\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grps\n+    ) {\n         Map<UUID, Collection<StatisticsKeyMessage>> res = new HashMap<>();\n \n         for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpKeys : grps.entrySet()) {\n", "next_change": {"commit": "fc2e8cbb19ef01669beaa69a239b2c7f8fb495db", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex b215186973d..5f0a2f7e2d0 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -218,14 +220,9 @@ public class IgniteStatisticsHelper {\n             AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n             List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n \n-            assignments.forEach(nodes -> nodes.forEach(clusterNode -> res.compute(clusterNode.id(), (k, v) -> {\n-                if (v == null)\n-                    v = new HashSet<>();\n-\n-                v.addAll(grpKeys.getValue());\n-\n-                return v;\n-            })));\n+            for (List<ClusterNode> partNodes : assignments)\n+                for (ClusterNode node : partNodes)\n+                    res.computeIfAbsent(node.id(), k -> new HashSet<>()).addAll(grpKeys.getValue());\n         }\n         return res;\n     }\n", "next_change": {"commit": "17a54090bea4d97c122cf06d6be8e60177006519", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 5f0a2f7e2d0..f53952e7a19 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -215,14 +197,14 @@ public class IgniteStatisticsHelper {\n     ) {\n         Map<UUID, Collection<StatisticsKeyMessage>> res = new HashMap<>();\n \n+        AffinityTopologyVersion topVer = grps.keySet().iterator().next().shared().exchange().readyAffinityVersion();\n         for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpKeys : grps.entrySet()) {\n-            CacheGroupContext grp = grpKeys.getKey();\n-            AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n-            List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+            List<List<ClusterNode>> assignments = grpKeys.getKey().affinity().assignments(topVer);\n \n-            for (List<ClusterNode> partNodes : assignments)\n+            for (List<ClusterNode> partNodes : assignments) {\n                 for (ClusterNode node : partNodes)\n                     res.computeIfAbsent(node.id(), k -> new HashSet<>()).addAll(grpKeys.getValue());\n+            }\n         }\n         return res;\n     }\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYyMjExOQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549622119", "body": "please do it with tradition for-each loop", "bodyText": "please do it with tradition for-each loop", "bodyHTML": "<p dir=\"auto\">please do it with tradition for-each loop</p>", "author": "korlov42", "createdAt": "2020-12-29T08:52:26Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,344 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatisticsGatheringRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param locNodeId Local node id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n+     *            If {@code null} - requests will be\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n+        UUID colId,\n+        UUID locNodeId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions,\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts\n+    ) {\n+\n+        // NodeId to <Key to partitions on node> map\n+        Map<UUID, Map<StatisticsKeyMessage, int[]>> reqMap = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n+            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null); // TODO Null?\n+            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n+                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n+                    if (v == null)\n+                        v = new HashMap<>();\n+\n+                    Collection<StatisticsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n+\n+                    for (StatisticsKeyMessage key : grpKeys) {\n+                        int[] keyNodeParts = (failedPartitions == null) ? nodeParts.getValue() :\n+                                GridArrays.intersect(nodeParts.getValue(), failedPartitions.get(key));\n+\n+                        if (keyNodeParts.length > 0)\n+                            v.put(key, keyNodeParts);\n+                    }\n+\n+                    return v.isEmpty() ? null : v;\n+                });\n+        }\n+\n+        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs = new ArrayList<>();\n+        for (Map.Entry<UUID, Map<StatisticsKeyMessage, int[]>> nodeGpsParts: reqMap.entrySet()) {\n+            if (nodeGpsParts.getValue().isEmpty())\n+                continue;\n+\n+            StatisticsGatheringRequest req = prepareRequest(colId, nodeGpsParts.getValue());\n+            reqs.add(new StatisticsAddrRequest<>(req, locNodeId, nodeGpsParts.getKey()));\n+        }\n+\n+        return reqs;\n+    }\n+\n+    /**\n+     * Get all nodes where specified cache grous located.\n+     *\n+     * @param grps Cache groups.\n+     * @return Set of node ids.\n+     */\n+    public static Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys(Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grps) {\n+        Map<UUID, Collection<StatisticsKeyMessage>> res = new HashMap<>();\n+\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpKeys : grps.entrySet()) {\n+            CacheGroupContext grp = grpKeys.getKey();\n+            AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+            List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+            assignments.forEach(nodes -> nodes.forEach(clusterNode -> res.compute(clusterNode.id(), (k, v) -> {", "originalCommit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUzNjA3NQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556536075", "bodyText": "done", "author": "Berkof", "createdAt": "2021-01-13T13:55:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYyMjExOQ=="}], "type": "inlineReview", "revised_code": {"commit": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 4210ae9137b..86d3d41f996 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -201,12 +248,14 @@ public class IgniteStatisticsHelper {\n     }\n \n     /**\n-     * Get all nodes where specified cache grous located.\n+     * Get all nodes where specified cache groups located.\n      *\n      * @param grps Cache groups.\n      * @return Set of node ids.\n      */\n-    public static Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys(Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grps) {\n+    public static Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys(\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grps\n+    ) {\n         Map<UUID, Collection<StatisticsKeyMessage>> res = new HashMap<>();\n \n         for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpKeys : grps.entrySet()) {\n", "next_change": {"commit": "fc2e8cbb19ef01669beaa69a239b2c7f8fb495db", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 86d3d41f996..5f0a2f7e2d0 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -263,14 +220,9 @@ public class IgniteStatisticsHelper {\n             AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n             List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n \n-            assignments.forEach(nodes -> nodes.forEach(clusterNode -> res.compute(clusterNode.id(), (k, v) -> {\n-                if (v == null)\n-                    v = new HashSet<>();\n-\n-                v.addAll(grpKeys.getValue());\n-\n-                return v;\n-            })));\n+            for (List<ClusterNode> partNodes : assignments)\n+                for (ClusterNode node : partNodes)\n+                    res.computeIfAbsent(node.id(), k -> new HashSet<>()).addAll(grpKeys.getValue());\n         }\n         return res;\n     }\n", "next_change": {"commit": "17a54090bea4d97c122cf06d6be8e60177006519", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 5f0a2f7e2d0..f53952e7a19 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -215,14 +197,14 @@ public class IgniteStatisticsHelper {\n     ) {\n         Map<UUID, Collection<StatisticsKeyMessage>> res = new HashMap<>();\n \n+        AffinityTopologyVersion topVer = grps.keySet().iterator().next().shared().exchange().readyAffinityVersion();\n         for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpKeys : grps.entrySet()) {\n-            CacheGroupContext grp = grpKeys.getKey();\n-            AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n-            List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+            List<List<ClusterNode>> assignments = grpKeys.getKey().affinity().assignments(topVer);\n \n-            for (List<ClusterNode> partNodes : assignments)\n+            for (List<ClusterNode> partNodes : assignments) {\n                 for (ClusterNode node : partNodes)\n                     res.computeIfAbsent(node.id(), k -> new HashSet<>()).addAll(grpKeys.getValue());\n+            }\n         }\n         return res;\n     }\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYyMjE5OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549622198", "body": "indentation ", "bodyText": "indentation", "bodyHTML": "<p dir=\"auto\">indentation</p>", "author": "korlov42", "createdAt": "2020-12-29T08:52:48Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,344 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatisticsGatheringRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param locNodeId Local node id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n+     *            If {@code null} - requests will be\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n+        UUID colId,\n+        UUID locNodeId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions,\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts\n+    ) {\n+\n+        // NodeId to <Key to partitions on node> map\n+        Map<UUID, Map<StatisticsKeyMessage, int[]>> reqMap = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n+            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null); // TODO Null?\n+            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n+                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n+                    if (v == null)\n+                        v = new HashMap<>();\n+\n+                    Collection<StatisticsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n+\n+                    for (StatisticsKeyMessage key : grpKeys) {\n+                        int[] keyNodeParts = (failedPartitions == null) ? nodeParts.getValue() :\n+                                GridArrays.intersect(nodeParts.getValue(), failedPartitions.get(key));\n+\n+                        if (keyNodeParts.length > 0)\n+                            v.put(key, keyNodeParts);\n+                    }\n+\n+                    return v.isEmpty() ? null : v;\n+                });\n+        }\n+\n+        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs = new ArrayList<>();\n+        for (Map.Entry<UUID, Map<StatisticsKeyMessage, int[]>> nodeGpsParts: reqMap.entrySet()) {\n+            if (nodeGpsParts.getValue().isEmpty())\n+                continue;\n+\n+            StatisticsGatheringRequest req = prepareRequest(colId, nodeGpsParts.getValue());\n+            reqs.add(new StatisticsAddrRequest<>(req, locNodeId, nodeGpsParts.getKey()));\n+        }\n+\n+        return reqs;\n+    }\n+\n+    /**\n+     * Get all nodes where specified cache grous located.\n+     *\n+     * @param grps Cache groups.\n+     * @return Set of node ids.\n+     */\n+    public static Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys(Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grps) {\n+        Map<UUID, Collection<StatisticsKeyMessage>> res = new HashMap<>();\n+\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpKeys : grps.entrySet()) {\n+            CacheGroupContext grp = grpKeys.getKey();\n+            AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+            List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+            assignments.forEach(nodes -> nodes.forEach(clusterNode -> res.compute(clusterNode.id(), (k, v) -> {\n+                if (v == null)\n+                    v = new HashSet<>();\n+\n+                v.addAll(grpKeys.getValue());\n+\n+                return v;\n+            })));\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Generate statistics clear requests.\n+     *\n+     * @param locNodeId Local node id.\n+     * @param keys Keys to clean statistics by.\n+     * @return Collection of addressed statistics clear requests.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public Collection<StatisticsAddrRequest<StatisticsClearRequest>> generateClearRequests(\n+            UUID locNodeId,", "originalCommit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUzNDI3Nw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556534277", "bodyText": "fixed", "author": "Berkof", "createdAt": "2021-01-13T13:53:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYyMjE5OA=="}], "type": "inlineReview", "revised_code": {"commit": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 4210ae9137b..86d3d41f996 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -235,7 +284,7 @@ public class IgniteStatisticsHelper {\n      * @throws IgniteCheckedException In case of errors.\n      */\n     public Collection<StatisticsAddrRequest<StatisticsClearRequest>> generateClearRequests(\n-            UUID locNodeId,\n+        UUID locNodeId,\n         Collection<StatisticsKeyMessage> keys\n     ) throws IgniteCheckedException {\n         Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts = extractGroups(keys);\n", "next_change": {"commit": "05b732cd7e8840c429c48f5561e7c98e0289bcf6", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 86d3d41f996..9cf548264e4 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -278,13 +249,11 @@ public class IgniteStatisticsHelper {\n     /**\n      * Generate statistics clear requests.\n      *\n-     * @param locNodeId Local node id.\n      * @param keys Keys to clean statistics by.\n      * @return Collection of addressed statistics clear requests.\n      * @throws IgniteCheckedException In case of errors.\n      */\n     public Collection<StatisticsAddrRequest<StatisticsClearRequest>> generateClearRequests(\n-        UUID locNodeId,\n         Collection<StatisticsKeyMessage> keys\n     ) throws IgniteCheckedException {\n         Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts = extractGroups(keys);\n", "next_change": {"commit": "23afcfd0b070646af24a1572418edbec1d4b5605", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 9cf548264e4..f4bc67303b2 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -256,7 +289,7 @@ public class IgniteStatisticsHelper {\n     public Collection<StatisticsAddrRequest<StatisticsClearRequest>> generateClearRequests(\n         Collection<StatisticsKeyMessage> keys\n     ) throws IgniteCheckedException {\n-        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts = extractGroups(keys);\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts = mapToCacheGroups(keys);\n         Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys = nodeKeys(grpContexts);\n \n         return nodeKeys.entrySet().stream().map(node -> new StatisticsAddrRequest<>(\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYyNDY1MQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549624651", "body": "for-each loop", "bodyText": "for-each loop", "bodyHTML": "<p dir=\"auto\">for-each loop</p>", "author": "korlov42", "createdAt": "2020-12-29T09:00:55Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,344 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+            res.compute(tbl.cacheContext().group(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(CacheGroupContext grp, Collection<Integer> partIds) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartitionMaster(res, assignments, i);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartitionMaster(res, assignments, partId);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     */\n+    protected static  void fillPartitionMaster(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        res.compute(partNodes.get(0).id(), (k, v) -> {\n+            if (v == null)\n+                v = new ArrayList<>();\n+\n+            v.add(partId);\n+\n+            return v;\n+        });\n+    }\n+\n+    /**\n+     * Prepare statistics collection request for specified node.\n+     *\n+     * @param colId Collection id.\n+     * @param data Keys to partitions for current node.\n+     * @return Statistics collection request.\n+     */\n+    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n+        UUID reqId = UUID.randomUUID();\n+        return new StatisticsGatheringRequest(colId, reqId, data);\n+    }\n+\n+    // TODO add extraction of necessary partIds by statKeyMsg\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param colId Collection id.\n+     * @param locNodeId Local node id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n+     *            If {@code null} - requests will be\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n+        UUID colId,\n+        UUID locNodeId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions,\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts\n+    ) {\n+\n+        // NodeId to <Key to partitions on node> map\n+        Map<UUID, Map<StatisticsKeyMessage, int[]>> reqMap = new HashMap<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n+            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null); // TODO Null?\n+            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n+                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n+                    if (v == null)\n+                        v = new HashMap<>();\n+\n+                    Collection<StatisticsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n+\n+                    for (StatisticsKeyMessage key : grpKeys) {\n+                        int[] keyNodeParts = (failedPartitions == null) ? nodeParts.getValue() :\n+                                GridArrays.intersect(nodeParts.getValue(), failedPartitions.get(key));\n+\n+                        if (keyNodeParts.length > 0)\n+                            v.put(key, keyNodeParts);\n+                    }\n+\n+                    return v.isEmpty() ? null : v;\n+                });\n+        }\n+\n+        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs = new ArrayList<>();\n+        for (Map.Entry<UUID, Map<StatisticsKeyMessage, int[]>> nodeGpsParts: reqMap.entrySet()) {\n+            if (nodeGpsParts.getValue().isEmpty())\n+                continue;\n+\n+            StatisticsGatheringRequest req = prepareRequest(colId, nodeGpsParts.getValue());\n+            reqs.add(new StatisticsAddrRequest<>(req, locNodeId, nodeGpsParts.getKey()));\n+        }\n+\n+        return reqs;\n+    }\n+\n+    /**\n+     * Get all nodes where specified cache grous located.\n+     *\n+     * @param grps Cache groups.\n+     * @return Set of node ids.\n+     */\n+    public static Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys(Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grps) {\n+        Map<UUID, Collection<StatisticsKeyMessage>> res = new HashMap<>();\n+\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpKeys : grps.entrySet()) {\n+            CacheGroupContext grp = grpKeys.getKey();\n+            AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+            List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+            assignments.forEach(nodes -> nodes.forEach(clusterNode -> res.compute(clusterNode.id(), (k, v) -> {\n+                if (v == null)\n+                    v = new HashSet<>();\n+\n+                v.addAll(grpKeys.getValue());\n+\n+                return v;\n+            })));\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Generate statistics clear requests.\n+     *\n+     * @param locNodeId Local node id.\n+     * @param keys Keys to clean statistics by.\n+     * @return Collection of addressed statistics clear requests.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    public Collection<StatisticsAddrRequest<StatisticsClearRequest>> generateClearRequests(\n+            UUID locNodeId,\n+        Collection<StatisticsKeyMessage> keys\n+    ) throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts = extractGroups(keys);\n+        Map<UUID, Collection<StatisticsKeyMessage>> nodeKeys = nodeKeys(grpContexts);\n+\n+        return nodeKeys.entrySet().stream().map(node -> new StatisticsAddrRequest<>(\n+            new StatisticsClearRequest(UUID.randomUUID(), new ArrayList<>(node.getValue())), locNodeId, node.getKey()))\n+                .collect(Collectors.toList());\n+    }\n+\n+\n+    /**\n+     * Generate statistics collection requests by given keys.\n+     *\n+     * @param gatId Gathering id.\n+     * @param locNodeId Local node id.\n+     * @param keys Collection of keys to collect statistics by.\n+     * @return Collection of statistics collection addressed request.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    protected Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n+        UUID gatId,\n+        UUID locNodeId,\n+        Collection<StatisticsKeyMessage> keys,\n+        Map<StatisticsKeyMessage, int[]> failedPartitions\n+    ) throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts = extractGroups(keys);\n+\n+        return generateCollectionRequests(gatId, locNodeId, keys, failedPartitions, grpContexts);\n+    }\n+\n+    /**\n+     * Extract all partitions from specified statistics collection requests.\n+     *\n+     * @param reqs Failed request to extract partitions from.\n+     * @return Map StatisticsKeyMessage to List of corresponding partitions.\n+     */\n+    public static Map<StatisticsKeyMessage, int[]> extractFailed(StatisticsGatheringRequest[] reqs) {\n+        Map<StatisticsKeyMessage, List<Integer>> res = new HashMap<>();\n+\n+        UUID colId = null;\n+        for (StatisticsGatheringRequest req : reqs) {\n+\n+            assert colId == null || colId.equals(req.gatId());\n+            colId = req.gatId();\n+\n+            for (Map.Entry<StatisticsKeyMessage, int[]> keyEntry : req.keys().entrySet()) {\n+                res.compute(keyEntry.getKey(), (k, v) -> {\n+                    if (v == null)\n+                        v = new ArrayList<>();\n+\n+                    for (int i = 0; i < keyEntry.getValue().length; i++)\n+                        v.add(keyEntry.getValue()[i]);\n+\n+                    return v;\n+                });\n+            }\n+        }\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Filter columns from specified statistics.\n+     *\n+     * @param stat Statistics to filter columns from.\n+     * @param cols Column names to return in result object.\n+     * @return Statistics with only specified columns.\n+     */\n+    public static ObjectStatisticsImpl filterColumns(ObjectStatisticsImpl stat, Collection<String> cols) {\n+        ObjectStatisticsImpl res = stat.clone();\n+        res.columnsStatistics().clear();\n+        cols.forEach(col -> {", "originalCommit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUzMzYwNg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556533606", "bodyText": "done", "author": "Berkof", "createdAt": "2021-01-13T13:51:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTYyNDY1MQ=="}], "type": "inlineReview", "revised_code": {"commit": "fc2e8cbb19ef01669beaa69a239b2c7f8fb495db", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 4210ae9137b..5f0a2f7e2d0 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -309,36 +372,13 @@ public class IgniteStatisticsHelper {\n     public static ObjectStatisticsImpl filterColumns(ObjectStatisticsImpl stat, Collection<String> cols) {\n         ObjectStatisticsImpl res = stat.clone();\n         res.columnsStatistics().clear();\n-        cols.forEach(col -> {\n-            ColumnStatistics colStat = stat.columnStatistics(col);\n-            if (colStat != null)\n-                res.columnsStatistics().put(col, colStat);\n-        });\n-\n-        return res;\n-    }\n-\n-    /**\n-     * Get failed partitions map from request and its response.\n-     *\n-     * @param req Request to get the original requested partitions from.\n-     * @param resp Response to get actually collected partitions.\n-     * @return Map of not collected partitions.\n-     */\n-    public static Map<StatisticsKeyMessage, int[]> extractFailed(StatisticsGatheringRequest req, StatisticsGatheringResponse resp) {\n-        assert req.gatId().equals(resp.gatId());\n \n-        Map<StatisticsKeyMessage, int[]> collected = new HashMap<>(resp.data().size());\n-        for (Map.Entry<StatisticsObjectData, int[]> data : resp.data().entrySet())\n-            collected.put(data.getKey().key(), data.getValue());\n-\n-        Map<StatisticsKeyMessage, int[]> res = new HashMap<>();\n-        for (Map.Entry<StatisticsKeyMessage, int[]> keyEntry : req.keys().entrySet()) {\n-            int[] failed = GridArrays.subtract(keyEntry.getValue(), collected.get(keyEntry.getKey()));\n-\n-            if (failed.length > 0)\n-                res.put(keyEntry.getKey(), failed);\n+        for (String column : cols) {\n+            ColumnStatistics colStat = stat.columnStatistics(column);\n+            if (colStat != null)\n+                res.columnsStatistics().put(column, colStat);\n         }\n+\n         return res;\n     }\n }\n", "next_change": {"commit": "48b736c4cf138d5db12978e2004c446e26e1f097", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 5f0a2f7e2d0..8ec059e1251 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -381,4 +428,20 @@ public class IgniteStatisticsHelper {\n \n         return res;\n     }\n+\n+    /**\n+     * Filter columns by specified names.\n+     *\n+     * @param cols Columns to filter.\n+     * @param colNames Column names.\n+     * @return Column with specified names.\n+     */\n+    public static Column[] filterColumns(Column[] cols, @Nullable Collection<String> colNames) {\n+        if (F.isEmpty(colNames))\n+            return cols;\n+\n+        Set<String> colNamesSet = new HashSet<>(colNames);\n+\n+        return Arrays.stream(cols).filter(c -> colNamesSet.contains(c.getName())).toArray(Column[]::new);\n+    }\n }\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY1NjUwMg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549656502", "body": "I would prefer to have it final, cause it prevent from having issues in case of multithreaded modification", "bodyText": "I would prefer to have it final, cause it prevent from having issues in case of multithreaded modification", "bodyHTML": "<p dir=\"auto\">I would prefer to have it final, cause it prevent from having issues in case of multithreaded modification</p>", "author": "korlov42", "createdAt": "2020-12-29T10:40:41Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/ObjectStatisticsImpl.java", "diffHunk": "@@ -24,7 +24,7 @@\n  */\n public class ObjectStatisticsImpl implements Cloneable, ObjectStatistics {\n     /** Total number of rows in object. */\n-    private final long rowsCnt;", "originalCommit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUzMzA1MA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556533050", "bodyText": "It used in the merge process where we can clone an initial object (to save all previously collected statistics) and set newly collected data. I'll think about how to fix it.", "author": "Berkof", "createdAt": "2021-01-13T13:51:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY1NjUwMg=="}], "type": "inlineReview", "revised_code": {"commit": "efd6b5e9f1f91625c2e6106b4c75522dada68b46", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/ObjectStatisticsImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/ObjectStatisticsImpl.java\nindex 0018f1e1b70..b964f083e68 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/ObjectStatisticsImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/ObjectStatisticsImpl.java\n", "chunk": "@@ -24,7 +24,7 @@ import java.util.Objects;\n  */\n public class ObjectStatisticsImpl implements Cloneable, ObjectStatistics {\n     /** Total number of rows in object. */\n-    private long rowsCnt;\n+    private final long rowsCnt;\n \n     /** Map columnKey to its statistic. */\n     private final Map<String, ColumnStatistics> colNameToStat;\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY2MjI1NQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549662255", "body": "empty line and commented code", "bodyText": "empty line and commented code", "bodyHTML": "<p dir=\"auto\">empty line and commented code</p>", "author": "korlov42", "createdAt": "2020-12-29T10:59:49Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -68,14 +89,52 @@\n     public IgniteStatisticsManagerImpl(GridKernalContext ctx, SchemaManager schemaMgr) {\n         this.ctx = ctx;\n         this.schemaMgr = schemaMgr;\n+        helper = new IgniteStatisticsHelper(schemaMgr);\n \n         log = ctx.log(IgniteStatisticsManagerImpl.class);\n \n-        boolean storeData = !(ctx.config().isClientMode() || ctx.isDaemon());\n         IgniteCacheDatabaseSharedManager db = (GridCacheUtils.isPersistenceEnabled(ctx.config())) ?\n                 ctx.cache().context().database() : null;\n-        statsRepos = new IgniteStatisticsRepositoryImpl(storeData, db, ctx.internalSubscriptionProcessor(), this,\n-                ctx::log);\n+\n+\n+        // nodeLeftLsnr = new NodeLeftListener();", "originalCommit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUyODY3OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556528678", "bodyText": "outdated", "author": "Berkof", "createdAt": "2021-01-13T13:44:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY2MjI1NQ=="}], "type": "inlineReview", "revised_code": {"commit": "05b732cd7e8840c429c48f5561e7c98e0289bcf6", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 1f98ad5ca73..ab2c41eca80 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -89,15 +88,13 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n     public IgniteStatisticsManagerImpl(GridKernalContext ctx, SchemaManager schemaMgr) {\n         this.ctx = ctx;\n         this.schemaMgr = schemaMgr;\n-        helper = new IgniteStatisticsHelper(schemaMgr);\n+        helper = new IgniteStatisticsHelper(ctx.localNodeId(), schemaMgr, ctx::log);\n \n         log = ctx.log(IgniteStatisticsManagerImpl.class);\n \n         IgniteCacheDatabaseSharedManager db = (GridCacheUtils.isPersistenceEnabled(ctx.config())) ?\n                 ctx.cache().context().database() : null;\n \n-\n-        // nodeLeftLsnr = new NodeLeftListener();\n         IgniteThreadPoolExecutor gatMgmtPool = new IgniteThreadPoolExecutor(\"stat-gat-mgmt-pool\",\n                 ctx.igniteInstanceName(),\n                 0,\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY2MjM2OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549662368", "body": "empty line", "bodyText": "empty line", "bodyHTML": "<p dir=\"auto\">empty line</p>", "author": "korlov42", "createdAt": "2020-12-29T11:00:15Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -68,14 +89,52 @@\n     public IgniteStatisticsManagerImpl(GridKernalContext ctx, SchemaManager schemaMgr) {\n         this.ctx = ctx;\n         this.schemaMgr = schemaMgr;\n+        helper = new IgniteStatisticsHelper(schemaMgr);\n \n         log = ctx.log(IgniteStatisticsManagerImpl.class);\n \n-        boolean storeData = !(ctx.config().isClientMode() || ctx.isDaemon());\n         IgniteCacheDatabaseSharedManager db = (GridCacheUtils.isPersistenceEnabled(ctx.config())) ?\n                 ctx.cache().context().database() : null;\n-        statsRepos = new IgniteStatisticsRepositoryImpl(storeData, db, ctx.internalSubscriptionProcessor(), this,\n-                ctx::log);\n+\n+\n+        // nodeLeftLsnr = new NodeLeftListener();\n+        IgniteThreadPoolExecutor gatMgmtPool = new IgniteThreadPoolExecutor(\"stat-gat-mgmt-pool\",\n+                ctx.igniteInstanceName(),\n+                0,\n+                STATS_POOL_SIZE,\n+                IgniteConfiguration.DFLT_THREAD_KEEP_ALIVE_TIME,\n+                new LinkedBlockingQueue<>(),\n+                GridIoPolicy.UNDEFINED,\n+                ctx.uncaughtExceptionHandler()\n+        );\n+\n+        IgniteThreadPoolExecutor msgMgmtPool = new IgniteThreadPoolExecutor(\"stat-msg-mgmt-pool\",\n+                ctx.igniteInstanceName(),\n+                0,\n+                1,\n+                IgniteConfiguration.DFLT_THREAD_KEEP_ALIVE_TIME,\n+                new LinkedBlockingQueue<>(),\n+                GridIoPolicy.UNDEFINED,\n+                ctx.uncaughtExceptionHandler()\n+        );\n+        statCrawler = new StatisticsGatheringRequestCrawlerImpl(ctx.localNodeId(), this, ctx.event(), ctx.io(),\n+            helper, msgMgmtPool, ctx::log);\n+        statGathering = new StatisticsGatheringImpl(schemaMgr, ctx.discovery(), ctx.query(), statCrawler, gatMgmtPool,\n+            ctx::log);\n+\n+        boolean storeData = !(ctx.config().isClientMode() || ctx.isDaemon());\n+        IgniteStatisticsStore store;\n+        if (!storeData)\n+            store = new IgniteStatisticsDummyStoreImpl(ctx::log);\n+        else if (db == null)\n+            store = new IgniteStatisticsInMemoryStoreImpl(ctx::log);\n+        else\n+            store = new IgniteStatisticsPersistenceStoreImpl(ctx.internalSubscriptionProcessor(), db, ctx::log);\n+\n+        statsRepos = new IgniteStatisticsRepositoryImpl(store, this, statGathering, ctx::log);\n+\n+        store.setRepository(statsRepos);\n+", "originalCommit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUwODE4NQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556508185", "bodyText": "removed", "author": "Berkof", "createdAt": "2021-01-13T13:11:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY2MjM2OA=="}], "type": "inlineReview", "revised_code": {"commit": "05b732cd7e8840c429c48f5561e7c98e0289bcf6", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 1f98ad5ca73..ab2c41eca80 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -133,7 +130,7 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n \n         statsRepos = new IgniteStatisticsRepositoryImpl(store, this, statGathering, ctx::log);\n \n-        store.setRepository(statsRepos);\n+        store.repository(statsRepos);\n \n     }\n \n", "next_change": {"commit": "b385286d37cb759a2a308a055b12f32c5c22a976", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex ab2c41eca80..d68901451dd 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -131,6 +131,7 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n         statsRepos = new IgniteStatisticsRepositoryImpl(store, this, statGathering, ctx::log);\n \n         store.repository(statsRepos);\n+        statGathering.repository(statsRepos);\n \n     }\n \n", "next_change": {"commit": "17a54090bea4d97c122cf06d6be8e60177006519", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex d68901451dd..636f380904e 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -132,7 +131,6 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n \n         store.repository(statsRepos);\n         statGathering.repository(statsRepos);\n-\n     }\n \n     /**\n", "next_change": {"commit": "efd6b5e9f1f91625c2e6106b4c75522dada68b46", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 636f380904e..8f406905473 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -127,7 +127,7 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n         else\n             store = new IgniteStatisticsPersistenceStoreImpl(ctx.internalSubscriptionProcessor(), db, ctx::log);\n \n-        statsRepos = new IgniteStatisticsRepositoryImpl(store, this, statGathering, ctx::log);\n+        statsRepos = new IgniteStatisticsRepositoryImpl(store, statGathering, ctx::log);\n \n         store.repository(statsRepos);\n         statGathering.repository(statsRepos);\n", "next_change": {"commit": "48b736c4cf138d5db12978e2004c446e26e1f097", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 8f406905473..e81fccec5de 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -125,12 +121,16 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n         else if (db == null)\n             store = new IgniteStatisticsInMemoryStoreImpl(ctx::log);\n         else\n-            store = new IgniteStatisticsPersistenceStoreImpl(ctx.internalSubscriptionProcessor(), db, ctx::log);\n+            store = new IgniteStatisticsPersistenceStoreImpl(ctx.internalSubscriptionProcessor(), db,\n+                (k, s) -> this.statisticsRepository().cacheLocalStatistics(k, s), ctx::log);\n+\n+        statsRepos = new IgniteStatisticsRepositoryImpl(store, helper, ctx::log);\n \n-        statsRepos = new IgniteStatisticsRepositoryImpl(store, statGathering, ctx::log);\n+        statCrawler = new StatisticsGatheringRequestCrawlerImpl(ctx.localNodeId(), this, ctx.event(), ctx.io(),\n+            helper, msgMgmtPool, ctx::log);\n+        statGathering = new StatisticsGatheringImpl(schemaMgr, ctx.discovery(), ctx.query(), statsRepos, statCrawler,\n+            gatMgmtPool, ctx::log);\n \n-        store.repository(statsRepos);\n-        statGathering.repository(statsRepos);\n     }\n \n     /**\n", "next_change": null}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY2MjU2Mw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549662563", "body": "commented code", "bodyText": "commented code", "bodyHTML": "<p dir=\"auto\">commented code</p>", "author": "korlov42", "createdAt": "2020-12-29T11:01:03Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -87,195 +146,420 @@ public IgniteStatisticsRepository statisticsRepository() {\n \n     /** {@inheritDoc} */\n     @Override public ObjectStatistics getLocalStatistics(String schemaName, String objName) {\n-        return statsRepos.getLocalStatistics(new StatsKey(schemaName, objName));\n+        return statsRepos.getLocalStatistics(new StatisticsKey(schemaName, objName));\n+    }\n+\n+    /**\n+     * Clear object statistics implementation.\n+     *\n+     * @param keys Keys to clear statistics by.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void clearObjectStatistics(Collection<StatisticsKeyMessage> keys) throws IgniteCheckedException {\n+        statCrawler.sendClearStatisticsAsync(keys);\n+        /*Collection<StatisticsAddrRequest<StatisticsClearRequest>> clearReqs = helper.generateClearRequests(keys);", "originalCommit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUwODc4Ng==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556508786", "bodyText": "removed", "author": "Berkof", "createdAt": "2021-01-13T13:12:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY2MjU2Mw=="}], "type": "inlineReview", "revised_code": {"commit": "604f88f1b4cd375f5474ea768ce8e4fa4fd3c658", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 1f98ad5ca73..6b29a99fe7a 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -157,21 +154,16 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n      */\n     private void clearObjectStatistics(Collection<StatisticsKeyMessage> keys) throws IgniteCheckedException {\n         statCrawler.sendClearStatisticsAsync(keys);\n-        /*Collection<StatisticsAddrRequest<StatisticsClearRequest>> clearReqs = helper.generateClearRequests(keys);\n-\n-        Collection<StatisticsAddrRequest<StatisticsClearRequest>> failedReqs = sendRequests(clearReqs);\n-        if (!F.isEmpty(failedReqs))\n-            if (log.isInfoEnabled())\n-                log.info(String.format(\"Unable to send all statistics clear requests to %d nodes for keys %s\",\n-                    failedReqs.size(), keys));\n-\n+    }\n \n-        UUID locId = ctx.localNodeId();\n-        StatisticsAddrRequest<StatisticsClearRequest> locMsg = clearReqs.stream().filter(m -> locId.equals(m.targetNodeId())).findAny()\n-                .orElse(null);\n-        if (null != locMsg)\n-            for (StatisticsKeyMessage locKey : locMsg.req().keys())\n-                clearObjectStatisticsLocal(locKey);*/\n+    /**\n+     * Clear local statistics by specified keys.\n+     *\n+     * @param keys Keys to clear statistics by.\n+     */\n+    public void clearObjectsStatisticsLocal(Collection<StatisticsKeyMessage> keys) {\n+        for (StatisticsKeyMessage key : keys)\n+            clearObjectStatisticsLocal(key);\n     }\n \n     /**\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY2ODIzMg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549668232", "body": "```suggestion\r\n        StatisticsGatheringContext ctxs = currColls.computeIfAbsent(gatId, \r\n            k -> new StatisticsGatheringContext(gatId, keys.keySet(), parts));\r\n```", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    StatisticsGatheringContext[] ctxs = new StatisticsGatheringContext[1];\n          \n          \n            \n                    currColls.compute(gatId, (k, v) -> {\n          \n          \n            \n                        if (v == null)\n          \n          \n            \n                            v = new StatisticsGatheringContext(gatId, keys.keySet(), parts);\n          \n          \n            \n            \n          \n          \n            \n                        ctxs[0] = v;\n          \n          \n            \n            \n          \n          \n            \n                        return v;\n          \n          \n            \n                    });\n          \n          \n            \n                    StatisticsGatheringContext ctxs = currColls.computeIfAbsent(gatId, \n          \n          \n            \n                        k -> new StatisticsGatheringContext(gatId, keys.keySet(), parts));", "bodyHTML": "  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">        <span class=\"pl-k\">StatisticsGatheringContext</span>[] ctxs <span class=\"pl-k\">=</span> <span class=\"pl-k\">new</span> <span class=\"pl-smi\">StatisticsGatheringContext</span>[<span class=\"pl-c1\">1</span>];</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">        currColls<span class=\"pl-k\">.</span>compute(gatId, (k, v) <span class=\"pl-k\">-</span><span class=\"pl-k\">&gt;</span> {</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">            <span class=\"pl-k\">if</span> (v <span class=\"pl-k\">==</span> <span class=\"pl-c1\">null</span>)</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">                v <span class=\"pl-k\">=</span> <span class=\"pl-k\">new</span> <span class=\"pl-smi\">StatisticsGatheringContext</span>(gatId, keys<span class=\"pl-k\">.</span>keySet(), parts);</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\"></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">            ctxs[<span class=\"pl-c1\">0</span>] <span class=\"pl-k\">=</span> v;</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\"></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">            <span class=\"pl-k\">return</span> v;</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">        });</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">        <span class=\"pl-smi\">StatisticsGatheringContext</span> ctxs <span class=\"pl-k\">=</span> currColls<span class=\"pl-k\">.</span>computeIfAbsent(gatId, </td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">            k <span class=\"pl-k\">-</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-k\">new</span> <span class=\"pl-smi\">StatisticsGatheringContext</span>(gatId, keys<span class=\"pl-k\">.</span>keySet(), parts));</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "korlov42", "createdAt": "2020-12-29T11:21:08Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -87,195 +146,420 @@ public IgniteStatisticsRepository statisticsRepository() {\n \n     /** {@inheritDoc} */\n     @Override public ObjectStatistics getLocalStatistics(String schemaName, String objName) {\n-        return statsRepos.getLocalStatistics(new StatsKey(schemaName, objName));\n+        return statsRepos.getLocalStatistics(new StatisticsKey(schemaName, objName));\n+    }\n+\n+    /**\n+     * Clear object statistics implementation.\n+     *\n+     * @param keys Keys to clear statistics by.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void clearObjectStatistics(Collection<StatisticsKeyMessage> keys) throws IgniteCheckedException {\n+        statCrawler.sendClearStatisticsAsync(keys);\n+        /*Collection<StatisticsAddrRequest<StatisticsClearRequest>> clearReqs = helper.generateClearRequests(keys);\n+\n+        Collection<StatisticsAddrRequest<StatisticsClearRequest>> failedReqs = sendRequests(clearReqs);\n+        if (!F.isEmpty(failedReqs))\n+            if (log.isInfoEnabled())\n+                log.info(String.format(\"Unable to send all statistics clear requests to %d nodes for keys %s\",\n+                    failedReqs.size(), keys));\n+\n+\n+        UUID locId = ctx.localNodeId();\n+        StatisticsAddrRequest<StatisticsClearRequest> locMsg = clearReqs.stream().filter(m -> locId.equals(m.targetNodeId())).findAny()\n+                .orElse(null);\n+        if (null != locMsg)\n+            for (StatisticsKeyMessage locKey : locMsg.req().keys())\n+                clearObjectStatisticsLocal(locKey);*/\n+    }\n+\n+    /**\n+     * Update counter to mark that statistics by some partitions where collected by remote request.\n+     *\n+     * @param gatId Gathering id.\n+     * @param parts Partitions count.\n+     */\n+    public void onRemoteGatheringSend(UUID gatId, int parts) {\n+        currColls.compute(gatId, (k,v) -> {\n+           if (v == null) {\n+               if (log.isDebugEnabled())\n+                   log.debug(String.format(\"Unable to mark %d partitions gathered by gathering id %s\", parts, gatId));\n+\n+               return null;\n+           }\n+\n+           return v.registerCollected(Collections.emptyMap(), parts) ? null : v;\n+        });\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void clearObjectStatistics(\n+            final GridTuple3<String, String, String[]>... keys\n+    ) throws IgniteCheckedException {\n+        Collection<StatisticsKeyMessage> keyMsgs = Arrays.stream(keys).map(k -> new StatisticsKeyMessage(k.get1(), k.get2(),\n+                Arrays.asList(k.get3()))).collect(Collectors.toList());\n+\n+        clearObjectStatistics(keyMsgs);\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        StatisticsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        clearObjectStatistics(Collections.singleton(keyMsg));\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatisticsKeyMessage keyMsg) {\n+        StatisticsKey key = new StatisticsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n     /**\n-     * Filter columns by specified names.\n+     * Collect object statistics prepared status.\n      *\n-     * @param cols Columns to filter.\n-     * @param colNames Column names.\n-     * @return Column with specified names.\n+     * @param status Collection status to collect statistics by.\n+     * @throws IgniteCheckedException In case of errors.\n      */\n-    private Column[] filterColumns(Column[] cols, String... colNames) {\n-        if (F.isEmpty(colNames))\n-            return cols;\n-\n-        Set<String> colNamesSet = new HashSet(Arrays.asList(colNames));\n-        List<Column> resList = new ArrayList<>(colNames.length);\n-\n-        for (Column col : cols)\n-            if (colNamesSet.contains(col.getName()))\n-                resList.add(col);\n+    private void collectObjectStatistics(StatisticsGatheringContext status) throws IgniteCheckedException {\n+        statCrawler.sendGatheringRequestsAsync(status.gatId(), status.keys());\n+    }\n \n-        return resList.toArray(new Column[resList.size()]);\n+    /**\n+     * Calculate total partitions count for all keys in gathering task.\n+     *\n+     * @param keys Collection of keys to calculate partitions by.\n+     * @return Total number of partitions in all tasks keys.\n+     */\n+    private Integer calculatePartitions(Collection<StatisticsKeyMessage> keys) {\n+        int res = 0;\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                return null;\n+\n+            res += tbl.cacheContext().topology().partitions();\n+        }\n+        return res;\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void collectObjectStatistics(String schemaName, String objName, String... colNames)\n-            throws IgniteCheckedException {\n-        GridH2Table tbl = schemaMgr.dataTable(schemaName, objName);\n-        if (tbl == null)\n-            throw new IllegalArgumentException(String.format(\"Can't find table %s.%s\", schemaName, objName));\n-\n-        if (log.isDebugEnabled())\n-            log.debug(String.format(\"Starting statistics collection by %s.%s object\", schemaName, objName));\n-\n-        Column[] selectedCols;\n-        boolean fullStat = F.isEmpty(colNames);\n-        selectedCols = filterColumns(tbl.getColumns(), colNames);\n-\n-        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, selectedCols);\n-        StatsKey key = new StatsKey(tbl.identifier().schema(), tbl.identifier().table());\n-        if (fullStat)\n-            statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n-        else\n-            statsRepos.mergeLocalPartitionsStatistics(key, partsStats);\n+    @Override public void collectObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        StatisticsKeyMessage keyMsg = new StatisticsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        StatisticsGatheringContext status = new StatisticsGatheringContext(Collections.singleton(keyMsg));\n+        currColls.put(status.gatId(), status);\n+        collectObjectStatistics(status);\n \n-        ObjectStatisticsImpl objStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n-        if (fullStat)\n-            statsRepos.saveLocalStatistics(key, objStats);\n-        else\n-            statsRepos.mergeLocalStatistics(key, objStats);\n-        if (log.isDebugEnabled())\n-            log.debug(String.format(\"Statistics collection by %s.%s object is finished.\", schemaName, objName));\n+        status.doneFut().get();\n     }\n \n     /**\n-     * Collect partition level statistics.\n+     * Ensure that local gathering context exists and schedule local statistics gathering.\n      *\n-     * @param tbl Table to collect statistics by.\n-     * @param selectedCols Columns to collect statistics by.\n-     * @return Collection of partition level statistics by local primary partitions.\n-     * @throws IgniteCheckedException in case of error.\n+     * @param nodeId Initiator node id.\n+     * @param gatId Gathering id.\n+     * @param reqId Request id.\n+     * @param keys Keys to collect statistics by.\n      */\n-    private Collection<ObjectPartitionStatisticsImpl> collectPartitionStatistics(\n-            GridH2Table tbl,\n-            Column[] selectedCols\n+    public void gatherLocalObjectStatisticsAsync(UUID gatId, UUID reqId, Map<StatisticsKeyMessage, int[]> keys) {\n+        int parts = keys.values().stream().mapToInt(arr -> arr.length).sum();\n+\n+        StatisticsGatheringContext[] ctxs = new StatisticsGatheringContext[1];\n+        currColls.compute(gatId, (k, v) -> {\n+            if (v == null)\n+                v = new StatisticsGatheringContext(gatId, keys.keySet(), parts);\n+\n+            ctxs[0] = v;\n+\n+            return v;\n+        });", "originalCommit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzA2Nzg2Mw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r557067863", "bodyText": "rewriten", "author": "Berkof", "createdAt": "2021-01-14T06:24:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY2ODIzMg=="}], "type": "inlineReview", "revised_code": {"commit": "7ef165002105dd10417170217e86d65771c524bb", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 1f98ad5ca73..4e5949c6399 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -277,36 +282,38 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n      * @param gatId Gathering id.\n      * @param reqId Request id.\n      * @param keys Keys to collect statistics by.\n+     * @param parts Partitions to collect statistics from.\n      */\n-    public void gatherLocalObjectStatisticsAsync(UUID gatId, UUID reqId, Map<StatisticsKeyMessage, int[]> keys) {\n-        int parts = keys.values().stream().mapToInt(arr -> arr.length).sum();\n+    public void gatherLocalObjectStatisticsAsync(UUID gatId, UUID reqId, Set<StatisticsKeyMessage> keys, int[] parts) {\n+        int partsCount = Arrays.stream(parts).sum();\n \n-        StatisticsGatheringContext[] ctxs = new StatisticsGatheringContext[1];\n-        currColls.compute(gatId, (k, v) -> {\n-            if (v == null)\n-                v = new StatisticsGatheringContext(gatId, keys.keySet(), parts);\n-\n-            ctxs[0] = v;\n-\n-            return v;\n-        });\n+        StatisticsGatheringContext gCtx = currColls.computeIfAbsent(gatId, k ->\n+            new StatisticsGatheringContext(gatId, keys, partsCount));\n \n-        statGathering.collectLocalObjectsStatisticsAsync(reqId, keys, () -> ctxs[0].doneFut().isCancelled());\n+        statGathering.collectLocalObjectsStatisticsAsync(reqId, keys, parts, () -> gCtx.doneFut().isCancelled());\n     }\n \n     /** {@inheritDoc} */\n-    @Override public StatsCollectionFuture<Map<GridTuple3<String, String, String[]>, ObjectStatistics>>\n+    @Override public StatsCollectionFuture<Map<GridTuple3<String, String, String[]>, ObjectStatistics>>[]\n     collectObjectStatisticsAsync(\n         GridTuple3<String, String, String[]>... keys\n     ) throws IgniteCheckedException {\n         Set<StatisticsKeyMessage> keysMsg = Arrays.stream(keys).map(\n                 k -> new StatisticsKeyMessage(k.get1(), k.get2(), Arrays.asList(k.get3()))).collect(Collectors.toSet());\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpsKeys = helper.splitByGroups(keysMsg);\n \n-        StatisticsGatheringContext status = new StatisticsGatheringContext(keysMsg);\n+        List<StatsCollectionFuture<Map<GridTuple3<String, String, String[]>, ObjectStatistics>>> res = new ArrayList<>();\n+        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpKeys : grpsKeys.entrySet()) {\n+            int parts = grpKeys.getKey().topology().partitions();\n \n-        collectObjectStatistics(status);\n+            StatisticsGatheringContext status = new StatisticsGatheringContext(UUID.randomUUID(),\n+                    new HashSet<>(grpKeys.getValue()), parts);\n+\n+            collectObjectStatistics(status);\n \n-        return status.doneFut();\n+            res.add(status.doneFut());\n+        }\n+        return res.toArray(new StatsCollectionFuture[0]);\n     }\n \n     /**\n", "next_change": {"commit": "604f88f1b4cd375f5474ea768ce8e4fa4fd3c658", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 4e5949c6399..6b29a99fe7a 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -321,7 +320,7 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n      *\n      * @param gatId Gathering id to cancel.\n      */\n-    public void cancelLocalStatisticsGathering(UUID gatId){\n+    public void cancelLocalStatisticsGathering(UUID gatId) {\n        StatisticsGatheringContext stCtx = currColls.remove(gatId);\n        if (stCtx != null)\n            stCtx.doneFut().cancel();\n", "next_change": {"commit": "48b736c4cf138d5db12978e2004c446e26e1f097", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 6b29a99fe7a..e81fccec5de 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -324,12 +292,16 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n        StatisticsGatheringContext stCtx = currColls.remove(gatId);\n        if (stCtx != null)\n            stCtx.doneFut().cancel();\n+       else {\n+           if (log.isDebugEnabled())\n+               log.debug(String.format(\"Unable to cancel gathering %s. No active task with such gatId found.\", gatId));\n+       }\n     }\n \n     /** {@inheritDoc} */\n     @Override public boolean cancelObjectStatisticsGathering(UUID gatId) {\n         boolean res = false;\n-        StatisticsGatheringContext stCtx = currColls.remove(gatId);\n+        StatisticsGatheringContext stCtx = currColls.get(gatId);\n         if (stCtx != null) {\n \n             res = stCtx.doneFut().cancel();\n", "next_change": {"commit": "33170812024f6c4d321f85287fea0b6c3abdb9e5", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex e81fccec5de..5011b1a87a5 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -299,12 +307,14 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public boolean cancelObjectStatisticsGathering(UUID gatId) {\n+    @Override public boolean cancelObjectStatisticsGathering(UUID gatId) throws IgniteCheckedException {\n+        checkSupport(\"cancel gathering\");\n+\n         boolean res = false;\n         StatisticsGatheringContext stCtx = currColls.get(gatId);\n         if (stCtx != null) {\n \n-            res = stCtx.doneFut().cancel();\n+            res = stCtx.doneFuture().cancel();\n             if (res)\n                 statCrawler.sendCancelGatheringAsync(gatId);\n         }\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY4NTEzNg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549685136", "body": "it's better to check this after every N rows processed", "bodyText": "it's better to check this after every N rows processed", "bodyHTML": "<p dir=\"auto\">it's better to check this after every N rows processed</p>", "author": "korlov42", "createdAt": "2020-12-29T12:24:38Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringImpl.java", "diffHunk": "@@ -0,0 +1,347 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.managers.discovery.GridDiscoveryManager;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtLocalPartition;\n+import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionTopology;\n+import org.apache.ignite.internal.processors.cache.persistence.CacheDataRow;\n+import org.apache.ignite.internal.processors.query.GridQueryProcessor;\n+import org.apache.ignite.internal.processors.query.GridQueryTypeDescriptor;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2RowDescriptor;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.h2.opt.H2Row;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.util.typedef.F;\n+import org.apache.ignite.lang.IgniteBiTuple;\n+import org.apache.ignite.thread.IgniteThreadPoolExecutor;\n+import org.gridgain.internal.h2.table.Column;\n+import org.jetbrains.annotations.Nullable;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionState.OWNING;\n+\n+/**\n+ * Implementation of statistic collector.\n+ */\n+public class StatisticsGatheringImpl implements StatisticsGathering {\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /** Discovery manager. */\n+    private final GridDiscoveryManager discoMgr;\n+\n+    /** Query processor */\n+    private final GridQueryProcessor qryProcessor;\n+\n+    /** Statistics request router. */\n+    private final StatisticsGatheringRequestCrawler statRouter;\n+\n+    /** Ignite Thread pool executor to do statistics collection tasks. */\n+    private final IgniteThreadPoolExecutor gatMgmtPool;\n+\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     * @param discoMgr Discovery manager.\n+     * @param qryProcessor Query processor.\n+     * @param statCrawler Statistics request crawler.\n+     * @param gatMgmtPool Thread pool to gather statistics in.\n+     * @param logSupplier Log supplier function.\n+     */\n+    public StatisticsGatheringImpl(\n+        SchemaManager schemaMgr,\n+        GridDiscoveryManager discoMgr,\n+        GridQueryProcessor qryProcessor,\n+        StatisticsGatheringRequestCrawler statCrawler,\n+        IgniteThreadPoolExecutor gatMgmtPool,\n+        Function<Class<?>, IgniteLogger> logSupplier\n+    ) {\n+        this.log = logSupplier.apply(StatisticsGatheringImpl.class);\n+        this.schemaMgr = schemaMgr;\n+        this.discoMgr = discoMgr;\n+        this.qryProcessor = qryProcessor;\n+        this.statRouter = statCrawler;\n+        this.gatMgmtPool = gatMgmtPool;\n+    }\n+\n+    /**\n+     * // TODO\n+     * @param keyMsg\n+     * @param partIds\n+     * @param cancelled\n+     * @return\n+     * @throws IgniteCheckedException\n+     */\n+    public Collection<ObjectPartitionStatisticsImpl> collectLocalObjectStatistics(\n+            StatisticsKeyMessage keyMsg,\n+            int[] partIds,\n+            Supplier<Boolean> cancelled\n+    ) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", keyMsg.schema(), keyMsg.obj()));\n+\n+        Column[] selectedCols = filterColumns(tbl.getColumns(), keyMsg.colNames());\n+\n+        return collectPartitionStatistics(tbl, partIds, selectedCols, cancelled);\n+        // Collection<ObjectPartitionStatisticsImpl> partsStats =\n+        /*if (partsStats == null) {\n+            assert cancelled.get() : \"Error collecting partition level statistics.\";\n+\n+            return partsStats;\n+        }*/\n+\n+        // TODO! Move back to manager\n+        //sendPartitionStatisticsToBackupNodes(tbl, partsStats);\n+\n+        //StatisticsKey key = new StatisticsKey(keyMsg.schema(), keyMsg.obj());\n+        //statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n+\n+        //ObjectStatisticsImpl tblStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n+        //statsRepos.mergeLocalStatistics(key, tblStats);\n+// partsStats.stream().map(ObjectPartitionStatisticsImpl::partId)\n+//                .mapToInt(Integer::intValue).toArray()\n+\n+        // return partsStats;\n+    }\n+\n+    /**\n+     * Filter columns by specified names.\n+     *\n+     * @param cols Columns to filter.\n+     * @param colNames Column names.\n+     * @return Column with specified names.\n+     */\n+    private Column[] filterColumns(Column[] cols, @Nullable Collection<String> colNames) {\n+        if (F.isEmpty(colNames))\n+            return cols;\n+\n+        Set<String> colNamesSet = new HashSet<>(colNames);\n+\n+        return Arrays.stream(cols).filter(c -> colNamesSet.contains(c.getName())).toArray(Column[]::new);\n+    }\n+\n+    /**\n+     * Collect partition level statistics.\n+     *\n+     * @param tbl Table to collect statistics by.\n+     * @param partIds Array of partition ids to collect statistics by.\n+     * @param selectedCols Columns to collect statistics by.\n+     * @param cancelled Supplier to check if collection was cancelled.\n+     * @return Collection of partition level statistics by local primary partitions.\n+     * @throws IgniteCheckedException in case of error.\n+     */\n+    private Collection<ObjectPartitionStatisticsImpl> collectPartitionStatistics(\n+            GridH2Table tbl,\n+            int[] partIds,\n+            Column[] selectedCols,\n+            Supplier<Boolean> cancelled\n+    ) {\n+        List<ObjectPartitionStatisticsImpl> tblPartStats = new ArrayList<>();\n+        GridH2RowDescriptor desc = tbl.rowDescriptor();\n+        String tblName = tbl.getName();\n+        GridDhtPartitionTopology top = tbl.cacheContext().topology();\n+        AffinityTopologyVersion topVer = top.readyTopologyVersion();\n+\n+        for (int partId : partIds) {\n+            GridDhtLocalPartition locPart = top.localPartition(partId, topVer, false);\n+            if (locPart == null)\n+                continue;\n+\n+            if (cancelled.get()) {", "originalCommit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUyMTc3NA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556521774", "bodyText": "done", "author": "Berkof", "createdAt": "2021-01-13T13:33:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY4NTEzNg=="}], "type": "inlineReview", "revised_code": {"commit": "7ef165002105dd10417170217e86d65771c524bb", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringImpl.java\nindex 0a968406671..7bb5a46d927 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringImpl.java\n", "chunk": "@@ -142,28 +103,29 @@ public class StatisticsGatheringImpl implements StatisticsGathering {\n     }\n \n     /**\n-     * Collect partition level statistics.\n+     * Collect single partition level statistics by the given tables.\n      *\n-     * @param tbl Table to collect statistics by.\n-     * @param partIds Array of partition ids to collect statistics by.\n-     * @param selectedCols Columns to collect statistics by.\n+     * @param targets Table to column collection to collect statistics by. All tables should be in the same cache group.\n+     * @param partId Partition id to collect statistics by.\n      * @param cancelled Supplier to check if collection was cancelled.\n-     * @return Collection of partition level statistics by local primary partitions.\n+     * @return Map of table to Collection of partition level statistics by local primary partitions.\n      * @throws IgniteCheckedException in case of error.\n      */\n-    private Collection<ObjectPartitionStatisticsImpl> collectPartitionStatistics(\n-            GridH2Table tbl,\n-            int[] partIds,\n-            Column[] selectedCols,\n+    private Map<GridH2Table, ObjectPartitionStatisticsImpl> collectPartitionStatisticsCaches(\n+            Map<GridH2Table, Column[]> targets,\n+            int partId,\n             Supplier<Boolean> cancelled\n     ) {\n-        List<ObjectPartitionStatisticsImpl> tblPartStats = new ArrayList<>();\n-        GridH2RowDescriptor desc = tbl.rowDescriptor();\n-        String tblName = tbl.getName();\n-        GridDhtPartitionTopology top = tbl.cacheContext().topology();\n-        AffinityTopologyVersion topVer = top.readyTopologyVersion();\n+        Map<GridH2Table, ObjectPartitionStatisticsImpl> res = new HashMap<>(targets.size());\n+\n+        for (Map.Entry<GridH2Table, Column[]> tblTarger : targets.entrySet()) {\n+            GridH2Table tbl = tblTarger.getKey();\n+            Column[] selectedCols = tblTarger.getValue();\n+            GridH2RowDescriptor desc = tbl.rowDescriptor();\n+            String tblName = tbl.getName();\n+            GridDhtPartitionTopology top = tbl.cacheContext().topology();\n+            AffinityTopologyVersion topVer = top.readyTopologyVersion();\n \n-        for (int partId : partIds) {\n             GridDhtLocalPartition locPart = top.localPartition(partId, topVer, false);\n             if (locPart == null)\n                 continue;\n", "next_change": {"commit": "fc2e8cbb19ef01669beaa69a239b2c7f8fb495db", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringImpl.java\nindex 7bb5a46d927..9941be19158 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringImpl.java\n", "chunk": "@@ -102,96 +117,6 @@ public class StatisticsGatheringImpl implements StatisticsGathering {\n         return Arrays.stream(cols).filter(c -> colNamesSet.contains(c.getName())).toArray(Column[]::new);\n     }\n \n-    /**\n-     * Collect single partition level statistics by the given tables.\n-     *\n-     * @param targets Table to column collection to collect statistics by. All tables should be in the same cache group.\n-     * @param partId Partition id to collect statistics by.\n-     * @param cancelled Supplier to check if collection was cancelled.\n-     * @return Map of table to Collection of partition level statistics by local primary partitions.\n-     * @throws IgniteCheckedException in case of error.\n-     */\n-    private Map<GridH2Table, ObjectPartitionStatisticsImpl> collectPartitionStatisticsCaches(\n-            Map<GridH2Table, Column[]> targets,\n-            int partId,\n-            Supplier<Boolean> cancelled\n-    ) {\n-        Map<GridH2Table, ObjectPartitionStatisticsImpl> res = new HashMap<>(targets.size());\n-\n-        for (Map.Entry<GridH2Table, Column[]> tblTarger : targets.entrySet()) {\n-            GridH2Table tbl = tblTarger.getKey();\n-            Column[] selectedCols = tblTarger.getValue();\n-            GridH2RowDescriptor desc = tbl.rowDescriptor();\n-            String tblName = tbl.getName();\n-            GridDhtPartitionTopology top = tbl.cacheContext().topology();\n-            AffinityTopologyVersion topVer = top.readyTopologyVersion();\n-\n-            GridDhtLocalPartition locPart = top.localPartition(partId, topVer, false);\n-            if (locPart == null)\n-                continue;\n-\n-            if (cancelled.get()) {\n-                if (log.isInfoEnabled())\n-                    log.info(String.format(\"Canceled collection of object %s.%s statistics.\", tbl.identifier().schema(),\n-                            tbl.identifier().table()));\n-\n-                return null;\n-            }\n-\n-            final boolean reserved = locPart.reserve();\n-\n-            try {\n-                if (!reserved || (locPart.state() != OWNING) || !locPart.primary(discoMgr.topologyVersionEx()))\n-                    continue;\n-\n-                long rowsCnt = 0;\n-\n-                List<ColumnStatisticsCollector> colStatsCollectors = new ArrayList<>(selectedCols.length);\n-\n-                for (Column col : selectedCols)\n-                    colStatsCollectors.add(new ColumnStatisticsCollector(col, tbl::compareValues));\n-\n-                for (CacheDataRow row : tbl.cacheContext().offheap().cachePartitionIterator(tbl.cacheId(), locPart.id(),\n-                        null, true)) {\n-                    GridQueryTypeDescriptor typeDesc = qryProcessor.typeByValue(tbl.cacheName(),\n-                            tbl.cacheContext().cacheObjectContext(), row.key(), row.value(), false);\n-                    if (!tblName.equals(typeDesc.tableName()))\n-                        continue;\n-\n-                    rowsCnt++;\n-\n-                    H2Row row0 = desc.createRow(row);\n-\n-                    for (ColumnStatisticsCollector colStat : colStatsCollectors)\n-                        colStat.add(row0.getValue(colStat.col().getColumnId()));\n-\n-                }\n-\n-                Map<String, ColumnStatistics> colStats = colStatsCollectors.stream().collect(Collectors.toMap(\n-                        csc -> csc.col().getName(), ColumnStatisticsCollector::finish));\n-\n-                res.put(tbl, new ObjectPartitionStatisticsImpl(locPart.id(), true, rowsCnt,\n-                        locPart.updateCounter(), colStats));\n-\n-                if (log.isTraceEnabled())\n-                    log.trace(String.format(\"Finished statistics collection on %s.%s:%d\",\n-                            tbl.identifier().schema(), tbl.identifier().table(), locPart.id()));\n-            }\n-            catch (IgniteCheckedException e) {\n-                if (log.isDebugEnabled())\n-                    log.debug(String.format(\"Unable to collect statistics by %s.%s:%d due to error %s\",\n-                            tbl.identifier().schema(), tbl.identifier().table(), partId, e.getMessage()));\n-            }\n-            finally {\n-                if (reserved)\n-                    locPart.release();\n-            }\n-        }\n-        return res;\n-    }\n-\n-\n-\n     /**\n      * Collect single partition level statistics by the given tables.\n      *\n", "next_change": {"commit": "48b736c4cf138d5db12978e2004c446e26e1f097", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringImpl.java\nindex 9941be19158..869fefdf5e8 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringImpl.java\n", "chunk": "@@ -97,26 +102,11 @@ public class StatisticsGatheringImpl implements StatisticsGathering {\n         this.schemaMgr = schemaMgr;\n         this.discoMgr = discoMgr;\n         this.qryProcessor = qryProcessor;\n+        this.statRepo = repo;\n         this.statCrawler = statCrawler;\n         this.gatMgmtPool = gatMgmtPool;\n     }\n \n-    /**\n-     * Filter columns by specified names.\n-     *\n-     * @param cols Columns to filter.\n-     * @param colNames Column names.\n-     * @return Column with specified names.\n-     */\n-    private Column[] filterColumns(Column[] cols, @Nullable Collection<String> colNames) {\n-        if (F.isEmpty(colNames))\n-            return cols;\n-\n-        Set<String> colNamesSet = new HashSet<>(colNames);\n-\n-        return Arrays.stream(cols).filter(c -> colNamesSet.contains(c.getName())).toArray(Column[]::new);\n-    }\n-\n     /**\n      * Collect single partition level statistics by the given tables.\n      *\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY5MDk4Mw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549690983", "body": "this has to be WARN", "bodyText": "this has to be WARN", "bodyHTML": "<p dir=\"auto\">this has to be WARN</p>", "author": "korlov42", "createdAt": "2020-12-29T12:44:58Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringImpl.java", "diffHunk": "@@ -0,0 +1,347 @@\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.managers.discovery.GridDiscoveryManager;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtLocalPartition;\n+import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionTopology;\n+import org.apache.ignite.internal.processors.cache.persistence.CacheDataRow;\n+import org.apache.ignite.internal.processors.query.GridQueryProcessor;\n+import org.apache.ignite.internal.processors.query.GridQueryTypeDescriptor;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2RowDescriptor;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.h2.opt.H2Row;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.util.typedef.F;\n+import org.apache.ignite.lang.IgniteBiTuple;\n+import org.apache.ignite.thread.IgniteThreadPoolExecutor;\n+import org.gridgain.internal.h2.table.Column;\n+import org.jetbrains.annotations.Nullable;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionState.OWNING;\n+\n+/**\n+ * Implementation of statistic collector.\n+ */\n+public class StatisticsGatheringImpl implements StatisticsGathering {\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /** Discovery manager. */\n+    private final GridDiscoveryManager discoMgr;\n+\n+    /** Query processor */\n+    private final GridQueryProcessor qryProcessor;\n+\n+    /** Statistics request router. */\n+    private final StatisticsGatheringRequestCrawler statRouter;\n+\n+    /** Ignite Thread pool executor to do statistics collection tasks. */\n+    private final IgniteThreadPoolExecutor gatMgmtPool;\n+\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     * @param discoMgr Discovery manager.\n+     * @param qryProcessor Query processor.\n+     * @param statCrawler Statistics request crawler.\n+     * @param gatMgmtPool Thread pool to gather statistics in.\n+     * @param logSupplier Log supplier function.\n+     */\n+    public StatisticsGatheringImpl(\n+        SchemaManager schemaMgr,\n+        GridDiscoveryManager discoMgr,\n+        GridQueryProcessor qryProcessor,\n+        StatisticsGatheringRequestCrawler statCrawler,\n+        IgniteThreadPoolExecutor gatMgmtPool,\n+        Function<Class<?>, IgniteLogger> logSupplier\n+    ) {\n+        this.log = logSupplier.apply(StatisticsGatheringImpl.class);\n+        this.schemaMgr = schemaMgr;\n+        this.discoMgr = discoMgr;\n+        this.qryProcessor = qryProcessor;\n+        this.statRouter = statCrawler;\n+        this.gatMgmtPool = gatMgmtPool;\n+    }\n+\n+    /**\n+     * // TODO\n+     * @param keyMsg\n+     * @param partIds\n+     * @param cancelled\n+     * @return\n+     * @throws IgniteCheckedException\n+     */\n+    public Collection<ObjectPartitionStatisticsImpl> collectLocalObjectStatistics(\n+            StatisticsKeyMessage keyMsg,\n+            int[] partIds,\n+            Supplier<Boolean> cancelled\n+    ) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", keyMsg.schema(), keyMsg.obj()));\n+\n+        Column[] selectedCols = filterColumns(tbl.getColumns(), keyMsg.colNames());\n+\n+        return collectPartitionStatistics(tbl, partIds, selectedCols, cancelled);\n+        // Collection<ObjectPartitionStatisticsImpl> partsStats =\n+        /*if (partsStats == null) {\n+            assert cancelled.get() : \"Error collecting partition level statistics.\";\n+\n+            return partsStats;\n+        }*/\n+\n+        // TODO! Move back to manager\n+        //sendPartitionStatisticsToBackupNodes(tbl, partsStats);\n+\n+        //StatisticsKey key = new StatisticsKey(keyMsg.schema(), keyMsg.obj());\n+        //statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n+\n+        //ObjectStatisticsImpl tblStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n+        //statsRepos.mergeLocalStatistics(key, tblStats);\n+// partsStats.stream().map(ObjectPartitionStatisticsImpl::partId)\n+//                .mapToInt(Integer::intValue).toArray()\n+\n+        // return partsStats;\n+    }\n+\n+    /**\n+     * Filter columns by specified names.\n+     *\n+     * @param cols Columns to filter.\n+     * @param colNames Column names.\n+     * @return Column with specified names.\n+     */\n+    private Column[] filterColumns(Column[] cols, @Nullable Collection<String> colNames) {\n+        if (F.isEmpty(colNames))\n+            return cols;\n+\n+        Set<String> colNamesSet = new HashSet<>(colNames);\n+\n+        return Arrays.stream(cols).filter(c -> colNamesSet.contains(c.getName())).toArray(Column[]::new);\n+    }\n+\n+    /**\n+     * Collect partition level statistics.\n+     *\n+     * @param tbl Table to collect statistics by.\n+     * @param partIds Array of partition ids to collect statistics by.\n+     * @param selectedCols Columns to collect statistics by.\n+     * @param cancelled Supplier to check if collection was cancelled.\n+     * @return Collection of partition level statistics by local primary partitions.\n+     * @throws IgniteCheckedException in case of error.\n+     */\n+    private Collection<ObjectPartitionStatisticsImpl> collectPartitionStatistics(\n+            GridH2Table tbl,\n+            int[] partIds,\n+            Column[] selectedCols,\n+            Supplier<Boolean> cancelled\n+    ) {\n+        List<ObjectPartitionStatisticsImpl> tblPartStats = new ArrayList<>();\n+        GridH2RowDescriptor desc = tbl.rowDescriptor();\n+        String tblName = tbl.getName();\n+        GridDhtPartitionTopology top = tbl.cacheContext().topology();\n+        AffinityTopologyVersion topVer = top.readyTopologyVersion();\n+\n+        for (int partId : partIds) {\n+            GridDhtLocalPartition locPart = top.localPartition(partId, topVer, false);\n+            if (locPart == null)\n+                continue;\n+\n+            if (cancelled.get()) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Canceled collection of object %s.%s statistics.\", tbl.identifier().schema(),\n+                            tbl.identifier().table()));\n+\n+                return null;\n+            }\n+\n+            final boolean reserved = locPart.reserve();\n+\n+            try {\n+                if (!reserved || (locPart.state() != OWNING) || !locPart.primary(discoMgr.topologyVersionEx()))\n+                    continue;\n+\n+                long rowsCnt = 0;\n+\n+                List<ColumnStatisticsCollector> colStatsCollectors = new ArrayList<>(selectedCols.length);\n+\n+                for (Column col : selectedCols)\n+                    colStatsCollectors.add(new ColumnStatisticsCollector(col, tbl::compareValues));\n+\n+                for (CacheDataRow row : tbl.cacheContext().offheap().cachePartitionIterator(tbl.cacheId(), locPart.id(),\n+                        null, true)) {\n+                    GridQueryTypeDescriptor typeDesc = qryProcessor.typeByValue(tbl.cacheName(),\n+                            tbl.cacheContext().cacheObjectContext(), row.key(), row.value(), false);\n+                    if (!tblName.equals(typeDesc.tableName()))\n+                        continue;\n+\n+                    rowsCnt++;\n+\n+                    H2Row row0 = desc.createRow(row);\n+\n+                    for (ColumnStatisticsCollector colStat : colStatsCollectors)\n+                        colStat.add(row0.getValue(colStat.col().getColumnId()));\n+\n+                }\n+\n+                Map<String, ColumnStatistics> colStats = colStatsCollectors.stream().collect(Collectors.toMap(\n+                        csc -> csc.col().getName(), ColumnStatisticsCollector::finish));\n+\n+                tblPartStats.add(new ObjectPartitionStatisticsImpl(locPart.id(), true, rowsCnt,\n+                        locPart.updateCounter(), colStats));\n+\n+                if (log.isTraceEnabled())\n+                    log.trace(String.format(\"Finished statistics collection on %s.%s:%d\",\n+                            tbl.identifier().schema(), tbl.identifier().table(), locPart.id()));\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Unable to collect statistics by %s.%s:%d due to error %s\",", "originalCommit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUyODIyOQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556528229", "bodyText": "done", "author": "Berkof", "createdAt": "2021-01-13T13:44:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY5MDk4Mw=="}], "type": "inlineReview", "revised_code": {"commit": "fc2e8cbb19ef01669beaa69a239b2c7f8fb495db", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringImpl.java\nindex 0a968406671..9941be19158 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringImpl.java\n", "chunk": "@@ -142,91 +118,92 @@ public class StatisticsGatheringImpl implements StatisticsGathering {\n     }\n \n     /**\n-     * Collect partition level statistics.\n+     * Collect single partition level statistics by the given tables.\n      *\n-     * @param tbl Table to collect statistics by.\n-     * @param partIds Array of partition ids to collect statistics by.\n-     * @param selectedCols Columns to collect statistics by.\n+     * @param targets Table to column collection to collect statistics by. All tables should be in the same cache group.\n+     * @param partId Partition id to collect statistics by.\n      * @param cancelled Supplier to check if collection was cancelled.\n-     * @return Collection of partition level statistics by local primary partitions.\n+     * @return Map of table to Collection of partition level statistics by local primary partitions.\n      * @throws IgniteCheckedException in case of error.\n      */\n-    private Collection<ObjectPartitionStatisticsImpl> collectPartitionStatistics(\n-            GridH2Table tbl,\n-            int[] partIds,\n-            Column[] selectedCols,\n+    private Map<GridH2Table, ObjectPartitionStatisticsImpl> collectPartitionStatistics(\n+            Map<GridH2Table, Column[]> targets,\n+            int partId,\n             Supplier<Boolean> cancelled\n     ) {\n-        List<ObjectPartitionStatisticsImpl> tblPartStats = new ArrayList<>();\n-        GridH2RowDescriptor desc = tbl.rowDescriptor();\n-        String tblName = tbl.getName();\n-        GridDhtPartitionTopology top = tbl.cacheContext().topology();\n-        AffinityTopologyVersion topVer = top.readyTopologyVersion();\n-\n-        for (int partId : partIds) {\n-            GridDhtLocalPartition locPart = top.localPartition(partId, topVer, false);\n-            if (locPart == null)\n-                continue;\n-\n-            if (cancelled.get()) {\n-                if (log.isInfoEnabled())\n-                    log.info(String.format(\"Canceled collection of object %s.%s statistics.\", tbl.identifier().schema(),\n-                            tbl.identifier().table()));\n \n+        GridH2Table ftbl = targets.keySet().iterator().next();\n+        CacheGroupContext grp = ftbl.cacheContext().group();\n+\n+        GridDhtPartitionTopology gTop = grp.topology();\n+        AffinityTopologyVersion topVer = gTop.readyTopologyVersion();\n+        GridDhtLocalPartition locPart = gTop.localPartition(partId, topVer, false);\n+        if (locPart == null)\n+            return null;\n+\n+        boolean reserved = locPart.reserve();\n+        try {\n+            if (!reserved || (locPart.state() != OWNING) || !locPart.primary(discoMgr.topologyVersionEx()))\n                 return null;\n-            }\n \n-            final boolean reserved = locPart.reserve();\n+            Map<GridH2Table, List<ColumnStatisticsCollector>> collectors = new HashMap<>(targets.size());\n+            Map<String, GridH2Table> tables = new HashMap<>(targets.size());\n+            for (Map.Entry<GridH2Table, Column[]> target : targets.entrySet()) {\n+                List<ColumnStatisticsCollector> colStatsCollectors = new ArrayList<>(target.getValue().length);\n+                for (Column col : target.getValue())\n+                    colStatsCollectors.add(new ColumnStatisticsCollector(col, target.getKey()::compareValues));\n \n-            try {\n-                if (!reserved || (locPart.state() != OWNING) || !locPart.primary(discoMgr.topologyVersionEx()))\n-                    continue;\n+                collectors.put(target.getKey(), colStatsCollectors);\n+\n+                tables.put(target.getKey().identifier().table(), target.getKey());\n+            }\n \n-                long rowsCnt = 0;\n+            Map<GridH2Table, ObjectPartitionStatisticsImpl> res = new HashMap<>(targets.size());\n \n-                List<ColumnStatisticsCollector> colStatsCollectors = new ArrayList<>(selectedCols.length);\n+            try {\n+                for (CacheDataRow row : grp.offheap().partitionIterator(partId)) {\n+                    if (cancelled.get())\n+                        return null;\n \n-                for (Column col : selectedCols)\n-                    colStatsCollectors.add(new ColumnStatisticsCollector(col, tbl::compareValues));\n+                    GridCacheContext cacheCtx = (row.cacheId() == CU.UNDEFINED_CACHE_ID) ? grp.singleCacheContext() :\n+                            grp.shared().cacheContext(row.cacheId());\n \n-                for (CacheDataRow row : tbl.cacheContext().offheap().cachePartitionIterator(tbl.cacheId(), locPart.id(),\n-                        null, true)) {\n-                    GridQueryTypeDescriptor typeDesc = qryProcessor.typeByValue(tbl.cacheName(),\n-                            tbl.cacheContext().cacheObjectContext(), row.key(), row.value(), false);\n-                    if (!tblName.equals(typeDesc.tableName()))\n+                    if (cacheCtx == null)\n                         continue;\n \n-                    rowsCnt++;\n-\n-                    H2Row row0 = desc.createRow(row);\n+                    GridQueryTypeDescriptor typeDesc = qryProcessor.typeByValue(cacheCtx.name(),\n+                        cacheCtx.cacheObjectContext(), row.key(), row.value(), false);\n+                    GridH2Table tbl = tables.get(typeDesc.tableName());\n+                    if (tbl == null)\n+                        continue;\n \n-                    for (ColumnStatisticsCollector colStat : colStatsCollectors)\n-                        colStat.add(row0.getValue(colStat.col().getColumnId()));\n+                    List<ColumnStatisticsCollector> tblColls = collectors.get(tbl);\n+                    H2Row h2row = tbl.rowDescriptor().createRow(row);\n \n+                    for (ColumnStatisticsCollector colStat : tblColls)\n+                        colStat.add(h2row.getValue(colStat.col().getColumnId()));\n                 }\n+            }\n+            catch (IgniteCheckedException igniteCheckedException) {\n+                igniteCheckedException.printStackTrace();\n+            }\n \n-                Map<String, ColumnStatistics> colStats = colStatsCollectors.stream().collect(Collectors.toMap(\n-                        csc -> csc.col().getName(), ColumnStatisticsCollector::finish));\n+            for (Map.Entry<GridH2Table, List<ColumnStatisticsCollector>> tblCollectors : collectors.entrySet()) {\n+                Map<String, ColumnStatistics> colStats = tblCollectors.getValue().stream().collect(\n+                        Collectors.toMap(csc -> csc.col().getName(), ColumnStatisticsCollector::finish));\n \n-                tblPartStats.add(new ObjectPartitionStatisticsImpl(locPart.id(), true, rowsCnt,\n-                        locPart.updateCounter(), colStats));\n+                ObjectPartitionStatisticsImpl tblStat = new ObjectPartitionStatisticsImpl(partId, true,\n+                        colStats.values().iterator().next().total(), locPart.updateCounter(), colStats);\n \n-                if (log.isTraceEnabled())\n-                    log.trace(String.format(\"Finished statistics collection on %s.%s:%d\",\n-                            tbl.identifier().schema(), tbl.identifier().table(), locPart.id()));\n+                res.put(tblCollectors.getKey(), tblStat);\n             }\n-            catch (IgniteCheckedException e) {\n-                if (log.isDebugEnabled())\n-                    log.debug(String.format(\"Unable to collect statistics by %s.%s:%d due to error %s\",\n-                            tbl.identifier().schema(), tbl.identifier().table(), partId, e.getMessage()));\n-            }\n-            finally {\n-                if (reserved)\n-                    locPart.release();\n-            }\n-        }\n \n-        return tblPartStats;\n+            return res;\n+        }\n+        finally {\n+            if (reserved)\n+                locPart.release();\n+        }\n     }\n \n     /** {@inheritDoc} */\n", "next_change": {"commit": "48b736c4cf138d5db12978e2004c446e26e1f097", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringImpl.java\nindex 9941be19158..869fefdf5e8 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringImpl.java\n", "chunk": "@@ -206,24 +205,6 @@ public class StatisticsGatheringImpl implements StatisticsGathering {\n         }\n     }\n \n-    /** {@inheritDoc} */\n-    @Override public ObjectStatisticsImpl aggregateLocalStatistics(\n-            StatisticsKeyMessage keyMsg,\n-            Collection<? extends ObjectStatisticsImpl> stats\n-    ) {\n-        // For now there can be only tables\n-        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n-\n-        if (tbl == null) {\n-            // remove all loaded statistics.\n-            if (log.isDebugEnabled())\n-                log.debug(String.format(\"Removing statistics for object %s.%s cause table doesn't exists.\",\n-                        keyMsg.schema(), keyMsg.obj()));\n-        }\n-\n-        return aggregateLocalStatistics(tbl, filterColumns(tbl.getColumns(), keyMsg.colNames()), stats);\n-    }\n-\n     /** {@inheritDoc} */\n     @Override public void collectLocalObjectsStatisticsAsync(\n         UUID reqId,\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY5NjE3MQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549696171", "body": "computeIfAbsent suits here better", "bodyText": "computeIfAbsent suits here better", "bodyHTML": "<p dir=\"auto\">computeIfAbsent suits here better</p>", "author": "korlov42", "createdAt": "2020-12-29T13:01:35Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -87,195 +146,420 @@ public IgniteStatisticsRepository statisticsRepository() {\n \n     /** {@inheritDoc} */\n     @Override public ObjectStatistics getLocalStatistics(String schemaName, String objName) {\n-        return statsRepos.getLocalStatistics(new StatsKey(schemaName, objName));\n+        return statsRepos.getLocalStatistics(new StatisticsKey(schemaName, objName));\n+    }\n+\n+    /**\n+     * Clear object statistics implementation.\n+     *\n+     * @param keys Keys to clear statistics by.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void clearObjectStatistics(Collection<StatisticsKeyMessage> keys) throws IgniteCheckedException {\n+        statCrawler.sendClearStatisticsAsync(keys);\n+        /*Collection<StatisticsAddrRequest<StatisticsClearRequest>> clearReqs = helper.generateClearRequests(keys);\n+\n+        Collection<StatisticsAddrRequest<StatisticsClearRequest>> failedReqs = sendRequests(clearReqs);\n+        if (!F.isEmpty(failedReqs))\n+            if (log.isInfoEnabled())\n+                log.info(String.format(\"Unable to send all statistics clear requests to %d nodes for keys %s\",\n+                    failedReqs.size(), keys));\n+\n+\n+        UUID locId = ctx.localNodeId();\n+        StatisticsAddrRequest<StatisticsClearRequest> locMsg = clearReqs.stream().filter(m -> locId.equals(m.targetNodeId())).findAny()\n+                .orElse(null);\n+        if (null != locMsg)\n+            for (StatisticsKeyMessage locKey : locMsg.req().keys())\n+                clearObjectStatisticsLocal(locKey);*/\n+    }\n+\n+    /**\n+     * Update counter to mark that statistics by some partitions where collected by remote request.\n+     *\n+     * @param gatId Gathering id.\n+     * @param parts Partitions count.\n+     */\n+    public void onRemoteGatheringSend(UUID gatId, int parts) {\n+        currColls.compute(gatId, (k,v) -> {\n+           if (v == null) {\n+               if (log.isDebugEnabled())\n+                   log.debug(String.format(\"Unable to mark %d partitions gathered by gathering id %s\", parts, gatId));\n+\n+               return null;\n+           }\n+\n+           return v.registerCollected(Collections.emptyMap(), parts) ? null : v;\n+        });\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void clearObjectStatistics(\n+            final GridTuple3<String, String, String[]>... keys\n+    ) throws IgniteCheckedException {\n+        Collection<StatisticsKeyMessage> keyMsgs = Arrays.stream(keys).map(k -> new StatisticsKeyMessage(k.get1(), k.get2(),\n+                Arrays.asList(k.get3()))).collect(Collectors.toList());\n+\n+        clearObjectStatistics(keyMsgs);\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        StatisticsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        clearObjectStatistics(Collections.singleton(keyMsg));\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatisticsKeyMessage keyMsg) {\n+        StatisticsKey key = new StatisticsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n     /**\n-     * Filter columns by specified names.\n+     * Collect object statistics prepared status.\n      *\n-     * @param cols Columns to filter.\n-     * @param colNames Column names.\n-     * @return Column with specified names.\n+     * @param status Collection status to collect statistics by.\n+     * @throws IgniteCheckedException In case of errors.\n      */\n-    private Column[] filterColumns(Column[] cols, String... colNames) {\n-        if (F.isEmpty(colNames))\n-            return cols;\n-\n-        Set<String> colNamesSet = new HashSet(Arrays.asList(colNames));\n-        List<Column> resList = new ArrayList<>(colNames.length);\n-\n-        for (Column col : cols)\n-            if (colNamesSet.contains(col.getName()))\n-                resList.add(col);\n+    private void collectObjectStatistics(StatisticsGatheringContext status) throws IgniteCheckedException {\n+        statCrawler.sendGatheringRequestsAsync(status.gatId(), status.keys());\n+    }\n \n-        return resList.toArray(new Column[resList.size()]);\n+    /**\n+     * Calculate total partitions count for all keys in gathering task.\n+     *\n+     * @param keys Collection of keys to calculate partitions by.\n+     * @return Total number of partitions in all tasks keys.\n+     */\n+    private Integer calculatePartitions(Collection<StatisticsKeyMessage> keys) {\n+        int res = 0;\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                return null;\n+\n+            res += tbl.cacheContext().topology().partitions();\n+        }\n+        return res;\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void collectObjectStatistics(String schemaName, String objName, String... colNames)\n-            throws IgniteCheckedException {\n-        GridH2Table tbl = schemaMgr.dataTable(schemaName, objName);\n-        if (tbl == null)\n-            throw new IllegalArgumentException(String.format(\"Can't find table %s.%s\", schemaName, objName));\n-\n-        if (log.isDebugEnabled())\n-            log.debug(String.format(\"Starting statistics collection by %s.%s object\", schemaName, objName));\n-\n-        Column[] selectedCols;\n-        boolean fullStat = F.isEmpty(colNames);\n-        selectedCols = filterColumns(tbl.getColumns(), colNames);\n-\n-        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, selectedCols);\n-        StatsKey key = new StatsKey(tbl.identifier().schema(), tbl.identifier().table());\n-        if (fullStat)\n-            statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n-        else\n-            statsRepos.mergeLocalPartitionsStatistics(key, partsStats);\n+    @Override public void collectObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        StatisticsKeyMessage keyMsg = new StatisticsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        StatisticsGatheringContext status = new StatisticsGatheringContext(Collections.singleton(keyMsg));\n+        currColls.put(status.gatId(), status);\n+        collectObjectStatistics(status);\n \n-        ObjectStatisticsImpl objStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n-        if (fullStat)\n-            statsRepos.saveLocalStatistics(key, objStats);\n-        else\n-            statsRepos.mergeLocalStatistics(key, objStats);\n-        if (log.isDebugEnabled())\n-            log.debug(String.format(\"Statistics collection by %s.%s object is finished.\", schemaName, objName));\n+        status.doneFut().get();\n     }\n \n     /**\n-     * Collect partition level statistics.\n+     * Ensure that local gathering context exists and schedule local statistics gathering.\n      *\n-     * @param tbl Table to collect statistics by.\n-     * @param selectedCols Columns to collect statistics by.\n-     * @return Collection of partition level statistics by local primary partitions.\n-     * @throws IgniteCheckedException in case of error.\n+     * @param nodeId Initiator node id.\n+     * @param gatId Gathering id.\n+     * @param reqId Request id.\n+     * @param keys Keys to collect statistics by.\n      */\n-    private Collection<ObjectPartitionStatisticsImpl> collectPartitionStatistics(\n-            GridH2Table tbl,\n-            Column[] selectedCols\n+    public void gatherLocalObjectStatisticsAsync(UUID gatId, UUID reqId, Map<StatisticsKeyMessage, int[]> keys) {\n+        int parts = keys.values().stream().mapToInt(arr -> arr.length).sum();\n+\n+        StatisticsGatheringContext[] ctxs = new StatisticsGatheringContext[1];\n+        currColls.compute(gatId, (k, v) -> {\n+            if (v == null)\n+                v = new StatisticsGatheringContext(gatId, keys.keySet(), parts);\n+\n+            ctxs[0] = v;\n+\n+            return v;\n+        });\n+\n+        statGathering.collectLocalObjectsStatisticsAsync(reqId, keys, () -> ctxs[0].doneFut().isCancelled());\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public StatsCollectionFuture<Map<GridTuple3<String, String, String[]>, ObjectStatistics>>\n+    collectObjectStatisticsAsync(\n+        GridTuple3<String, String, String[]>... keys\n     ) throws IgniteCheckedException {\n-        List<ObjectPartitionStatisticsImpl> tblPartStats = new ArrayList<>();\n-        GridH2RowDescriptor desc = tbl.rowDescriptor();\n-        String tblName = tbl.getName();\n+        Set<StatisticsKeyMessage> keysMsg = Arrays.stream(keys).map(\n+                k -> new StatisticsKeyMessage(k.get1(), k.get2(), Arrays.asList(k.get3()))).collect(Collectors.toSet());\n \n-        for (GridDhtLocalPartition locPart : tbl.cacheContext().topology().localPartitions()) {\n-            final boolean reserved = locPart.reserve();\n+        StatisticsGatheringContext status = new StatisticsGatheringContext(keysMsg);\n \n-            try {\n-                if (!reserved || (locPart.state() != OWNING && locPart.state() != MOVING)\n-                        || !locPart.primary(ctx.discovery().topologyVersionEx()))\n-                    continue;\n+        collectObjectStatistics(status);\n \n-                if (locPart.state() == MOVING)\n-                    tbl.cacheContext().preloader().syncFuture().get();\n+        return status.doneFut();\n+    }\n \n-                long rowsCnt = 0;\n+    /**\n+     * Cancel specified statistics gathering process.\n+     *\n+     * @param gatId Gathering id to cancel.\n+     */\n+    public void cancelLocalStatisticsGathering(UUID gatId){\n+       StatisticsGatheringContext stCtx = currColls.remove(gatId);\n+       if (stCtx != null)\n+           stCtx.doneFut().cancel();\n+    }\n \n-                List<ColumnStatisticsCollector> colStatsCollectors = new ArrayList<>(selectedCols.length);\n+    /** {@inheritDoc} */\n+    @Override public boolean cancelObjectStatisticsGathering(UUID gatId) {\n+        boolean res = false;\n+        StatisticsGatheringContext stCtx = currColls.remove(gatId);\n+        if (stCtx != null) {\n+\n+            res = stCtx.doneFut().cancel();\n+            if (res)\n+                statCrawler.sendCancelGatheringAsync(gatId);\n+        }\n+        return res;\n+    }\n \n-                for (Column col : selectedCols)\n-                    colStatsCollectors.add(new ColumnStatisticsCollector(col, tbl::compareValues));\n+    /**\n+     * Receive and store partition statistics object data for locals backup partition.\n+     *\n+     * @param data Collection of partition level statistics of local bacup partitions.\n+     */\n+    public void receivePartitionsStatistics(Collection<StatisticsObjectData> data) {\n+        for (StatisticsObjectData partData : data) {\n+            StatisticsKey key = new StatisticsKey(partData.key().schema(), partData.key().obj());\n \n-                for (CacheDataRow row : tbl.cacheContext().offheap().cachePartitionIterator(tbl.cacheId(), locPart.id(),\n-                        null, true)) {\n-                    GridQueryTypeDescriptor typeDesc = ctx.query().typeByValue(tbl.cacheName(),\n-                            tbl.cacheContext().cacheObjectContext(), row.key(), row.value(), false);\n-                    if (!tblName.equals(typeDesc.tableName()))\n-                        continue;\n+            assert partData.type() == StatisticsType.PARTITION : \"Got non partition level statistics by \" + key\n+                    + \" without request\";\n \n-                    rowsCnt++;\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d\", key.schema(), key.obj(),\n+                    partData.partId()));\n \n-                    H2Row row0 = desc.createRow(row);\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d\", key.schema(), key.obj(),\n+                        partData.partId()));\n \n-                    for (ColumnStatisticsCollector colStat : colStatsCollectors)\n-                        colStat.add(row0.getValue(colStat.col().getColumnId()));\n+                continue;\n+            }\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(ctx.localNodeId(), partData.partId());\n+            if (partState != OWNING) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d\",\n+                            key.schema(), key.obj(), partData.partId()));\n \n-                }\n+                continue;\n+            }\n \n-                Map<String, ColumnStatistics> colStats = colStatsCollectors.stream().collect(Collectors.toMap(\n-                        csc -> csc.col().getName(), csc -> csc.finish()\n-                ));\n+            try {\n+                ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n \n-                tblPartStats.add(new ObjectPartitionStatisticsImpl(locPart.id(), true, rowsCnt,\n-                        locPart.updateCounter(), colStats));\n+                statsRepos.saveLocalPartitionStatistics(key, opStat);\n             }\n-            finally {\n-                if (reserved)\n-                    locPart.release();\n+            catch (IgniteCheckedException e) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Unable to parse partition statistics for %s.%s:%d because of: %s\",\n+                        key.schema(), key.obj(), partData.partId(), e.getMessage()));\n             }\n         }\n-\n-        return tblPartStats;\n     }\n \n     /**\n-     * Aggregate specified partition level statistics to local level statistics.\n+     * Aggregate specified gathered statistics, remove it form local and complete its future.\n      *\n-     * @param key Aggregation key.\n-     * @param tblPartStats Collection of all local partition level statistics by specified key.\n-     * @return Local level aggregated statistics.\n+     * @param stCtx Gathering to complete.\n      */\n-    public ObjectStatisticsImpl aggregateLocalStatistics(\n-            StatsKey key,\n-            Collection<ObjectPartitionStatisticsImpl> tblPartStats\n-    ) {\n-        // For now there can be only tables\n-        GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n-\n-        if (tbl == null) {\n-            // remove all loaded statistics.\n-            log.info(\"Removing statistics for object \" + key + \" cause table doesn't exists.\");\n-            statsRepos.clearLocalPartitionsStatistics(key);\n+    public void finishStatisticsCollection(StatisticsGatheringContext stCtx) {\n+        currColls.remove(stCtx.gatId());\n+\n+        Map<StatisticsKeyMessage, ObjectStatisticsImpl> keysGlobalStats = new HashMap<>();\n+        for (Map.Entry<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : stCtx.collectedStatistics()\n+                .entrySet()) {\n+            ObjectStatisticsImpl globalCollectedStat = statGathering.aggregateLocalStatistics(keyStats.getKey(),\n+                keyStats.getValue());\n+            StatisticsKey statsKey = new StatisticsKey(keyStats.getKey().schema(), keyStats.getKey().obj());\n+            ObjectStatisticsImpl globalStat = statsRepos.mergeGlobalStatistics(statsKey, globalCollectedStat);\n+            keysGlobalStats.put(keyStats.getKey(), globalStat);\n         }\n-        return aggregateLocalStatistics(tbl, tbl.getColumns(), tblPartStats);\n+\n+        statCrawler.sendGlobalStat(keysGlobalStats);\n     }\n \n     /**\n-     * Aggregate partition level statistics to local level one.\n+     * Cache global statistics.\n      *\n-     * @param tbl Table to aggregate statistics by.\n-     * @param selectedCols Columns to aggregate statistics by.\n-     * @param tblPartStats Collection of partition level statistics.\n-     * @return Local level statistics.\n+     * @param data Global statistics to cache.\n      */\n-    private ObjectStatisticsImpl aggregateLocalStatistics(\n-            GridH2Table tbl,\n-            Column[] selectedCols,\n-            Collection<ObjectPartitionStatisticsImpl> tblPartStats\n-    ) {\n-        Map<Column, List<ColumnStatistics>> colPartStats = new HashMap<>(selectedCols.length);\n-        long rowCnt = 0;\n-        for (Column col : selectedCols)\n-            colPartStats.put(col, new ArrayList<>());\n-\n-        for (ObjectPartitionStatisticsImpl partStat : tblPartStats) {\n-            for (Column col : selectedCols) {\n-                ColumnStatistics colPartStat = partStat.columnStatistics(col.getName());\n-                if (colPartStat != null) {\n-                    colPartStats.compute(col, (k, v) -> {\n-                        v.add(colPartStat);\n-                        return v;\n-                    });\n-                }\n+    public void saveGlobalStatistics(Collection<StatisticsObjectData> data) {\n+        data.forEach(objData -> {\n+            try {\n+                ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(this.ctx, objData);\n+\n+                statsRepos.saveGlobalStatistics(new StatisticsKey(objData.key().schema(), objData.key().obj()), objStat);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Cannot read global statistics %s\", objData.key()));\n             }\n-            rowCnt += partStat.rowCount();\n+        });\n+    }\n+\n+    /**\n+     * Register\n+     *\n+     * @param gatId Gathering id.\n+     * @param data Collected statistics.\n+     */\n+    public void registerLocalResult(UUID gatId, Map<StatisticsObjectData, int[]> data) {\n+        StatisticsGatheringContext stCtx = currColls.get(gatId);\n+        if (stCtx == null) {\n+            if (log.isDebugEnabled())\n+                log.debug(String.format(\"Unable to register outdated statistics collection result %s\", gatId));\n+\n+            return;\n         }\n+        Map<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats = new HashMap<>();\n+        for (StatisticsObjectData objData : data.keySet()) {\n+            keyStats.compute(objData.key(), (k, v) -> {", "originalCommit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUxOTY5MA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556519690", "bodyText": "implemented in StatGatheringContext", "author": "Berkof", "createdAt": "2021-01-13T13:30:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY5NjE3MQ=="}], "type": "inlineReview", "revised_code": {"commit": "7ef165002105dd10417170217e86d65771c524bb", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 1f98ad5ca73..4e5949c6399 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -434,7 +442,7 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n             return;\n         }\n         Map<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats = new HashMap<>();\n-        for (StatisticsObjectData objData : data.keySet()) {\n+        for (StatisticsObjectData objData : data) {\n             keyStats.compute(objData.key(), (k, v) -> {\n                 if (v == null)\n                     v = new ArrayList<>();\n", "next_change": {"commit": "05b732cd7e8840c429c48f5561e7c98e0289bcf6", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 4e5949c6399..ab2c41eca80 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -443,23 +447,17 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n         }\n         Map<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats = new HashMap<>();\n         for (StatisticsObjectData objData : data) {\n-            keyStats.compute(objData.key(), (k, v) -> {\n-                if (v == null)\n-                    v = new ArrayList<>();\n-\n-                try {\n-                    ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n-\n-                    v.add(objStat);\n-                }\n-                catch (IgniteCheckedException e) {\n-                    if (log.isDebugEnabled())\n-                        log.debug(String.format(\"Cannot read local statistics %s by gathering task %s\", objData.key(),\n-                            gatId));\n-                }\n-\n-                return v;\n-            });\n+            Collection<ObjectStatisticsImpl> keyObjStats = keyStats.computeIfAbsent(objData.key(), k -> new ArrayList<>());\n+            try {\n+                ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n+\n+                keyObjStats.add(objStat);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Cannot read local statistics %s by gathering task %s\", objData.key(),\n+                        gatId));\n+            }\n         }\n \n         if (stCtx.registerCollected(keyStats, partsCount))\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY5NjYxMQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549696611", "body": "is there any reason to convert this insert a compute's closure?", "bodyText": "is there any reason to convert this insert a compute's closure?", "bodyHTML": "<p dir=\"auto\">is there any reason to convert this insert a compute's closure?</p>", "author": "korlov42", "createdAt": "2020-12-29T13:03:11Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -87,195 +146,420 @@ public IgniteStatisticsRepository statisticsRepository() {\n \n     /** {@inheritDoc} */\n     @Override public ObjectStatistics getLocalStatistics(String schemaName, String objName) {\n-        return statsRepos.getLocalStatistics(new StatsKey(schemaName, objName));\n+        return statsRepos.getLocalStatistics(new StatisticsKey(schemaName, objName));\n+    }\n+\n+    /**\n+     * Clear object statistics implementation.\n+     *\n+     * @param keys Keys to clear statistics by.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void clearObjectStatistics(Collection<StatisticsKeyMessage> keys) throws IgniteCheckedException {\n+        statCrawler.sendClearStatisticsAsync(keys);\n+        /*Collection<StatisticsAddrRequest<StatisticsClearRequest>> clearReqs = helper.generateClearRequests(keys);\n+\n+        Collection<StatisticsAddrRequest<StatisticsClearRequest>> failedReqs = sendRequests(clearReqs);\n+        if (!F.isEmpty(failedReqs))\n+            if (log.isInfoEnabled())\n+                log.info(String.format(\"Unable to send all statistics clear requests to %d nodes for keys %s\",\n+                    failedReqs.size(), keys));\n+\n+\n+        UUID locId = ctx.localNodeId();\n+        StatisticsAddrRequest<StatisticsClearRequest> locMsg = clearReqs.stream().filter(m -> locId.equals(m.targetNodeId())).findAny()\n+                .orElse(null);\n+        if (null != locMsg)\n+            for (StatisticsKeyMessage locKey : locMsg.req().keys())\n+                clearObjectStatisticsLocal(locKey);*/\n+    }\n+\n+    /**\n+     * Update counter to mark that statistics by some partitions where collected by remote request.\n+     *\n+     * @param gatId Gathering id.\n+     * @param parts Partitions count.\n+     */\n+    public void onRemoteGatheringSend(UUID gatId, int parts) {\n+        currColls.compute(gatId, (k,v) -> {\n+           if (v == null) {\n+               if (log.isDebugEnabled())\n+                   log.debug(String.format(\"Unable to mark %d partitions gathered by gathering id %s\", parts, gatId));\n+\n+               return null;\n+           }\n+\n+           return v.registerCollected(Collections.emptyMap(), parts) ? null : v;\n+        });\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void clearObjectStatistics(\n+            final GridTuple3<String, String, String[]>... keys\n+    ) throws IgniteCheckedException {\n+        Collection<StatisticsKeyMessage> keyMsgs = Arrays.stream(keys).map(k -> new StatisticsKeyMessage(k.get1(), k.get2(),\n+                Arrays.asList(k.get3()))).collect(Collectors.toList());\n+\n+        clearObjectStatistics(keyMsgs);\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        StatisticsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        clearObjectStatistics(Collections.singleton(keyMsg));\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatisticsKeyMessage keyMsg) {\n+        StatisticsKey key = new StatisticsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n     /**\n-     * Filter columns by specified names.\n+     * Collect object statistics prepared status.\n      *\n-     * @param cols Columns to filter.\n-     * @param colNames Column names.\n-     * @return Column with specified names.\n+     * @param status Collection status to collect statistics by.\n+     * @throws IgniteCheckedException In case of errors.\n      */\n-    private Column[] filterColumns(Column[] cols, String... colNames) {\n-        if (F.isEmpty(colNames))\n-            return cols;\n-\n-        Set<String> colNamesSet = new HashSet(Arrays.asList(colNames));\n-        List<Column> resList = new ArrayList<>(colNames.length);\n-\n-        for (Column col : cols)\n-            if (colNamesSet.contains(col.getName()))\n-                resList.add(col);\n+    private void collectObjectStatistics(StatisticsGatheringContext status) throws IgniteCheckedException {\n+        statCrawler.sendGatheringRequestsAsync(status.gatId(), status.keys());\n+    }\n \n-        return resList.toArray(new Column[resList.size()]);\n+    /**\n+     * Calculate total partitions count for all keys in gathering task.\n+     *\n+     * @param keys Collection of keys to calculate partitions by.\n+     * @return Total number of partitions in all tasks keys.\n+     */\n+    private Integer calculatePartitions(Collection<StatisticsKeyMessage> keys) {\n+        int res = 0;\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null)\n+                return null;\n+\n+            res += tbl.cacheContext().topology().partitions();\n+        }\n+        return res;\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void collectObjectStatistics(String schemaName, String objName, String... colNames)\n-            throws IgniteCheckedException {\n-        GridH2Table tbl = schemaMgr.dataTable(schemaName, objName);\n-        if (tbl == null)\n-            throw new IllegalArgumentException(String.format(\"Can't find table %s.%s\", schemaName, objName));\n-\n-        if (log.isDebugEnabled())\n-            log.debug(String.format(\"Starting statistics collection by %s.%s object\", schemaName, objName));\n-\n-        Column[] selectedCols;\n-        boolean fullStat = F.isEmpty(colNames);\n-        selectedCols = filterColumns(tbl.getColumns(), colNames);\n-\n-        Collection<ObjectPartitionStatisticsImpl> partsStats = collectPartitionStatistics(tbl, selectedCols);\n-        StatsKey key = new StatsKey(tbl.identifier().schema(), tbl.identifier().table());\n-        if (fullStat)\n-            statsRepos.saveLocalPartitionsStatistics(key, partsStats);\n-        else\n-            statsRepos.mergeLocalPartitionsStatistics(key, partsStats);\n+    @Override public void collectObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        StatisticsKeyMessage keyMsg = new StatisticsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        StatisticsGatheringContext status = new StatisticsGatheringContext(Collections.singleton(keyMsg));\n+        currColls.put(status.gatId(), status);\n+        collectObjectStatistics(status);\n \n-        ObjectStatisticsImpl objStats = aggregateLocalStatistics(tbl, selectedCols, partsStats);\n-        if (fullStat)\n-            statsRepos.saveLocalStatistics(key, objStats);\n-        else\n-            statsRepos.mergeLocalStatistics(key, objStats);\n-        if (log.isDebugEnabled())\n-            log.debug(String.format(\"Statistics collection by %s.%s object is finished.\", schemaName, objName));\n+        status.doneFut().get();\n     }\n \n     /**\n-     * Collect partition level statistics.\n+     * Ensure that local gathering context exists and schedule local statistics gathering.\n      *\n-     * @param tbl Table to collect statistics by.\n-     * @param selectedCols Columns to collect statistics by.\n-     * @return Collection of partition level statistics by local primary partitions.\n-     * @throws IgniteCheckedException in case of error.\n+     * @param nodeId Initiator node id.\n+     * @param gatId Gathering id.\n+     * @param reqId Request id.\n+     * @param keys Keys to collect statistics by.\n      */\n-    private Collection<ObjectPartitionStatisticsImpl> collectPartitionStatistics(\n-            GridH2Table tbl,\n-            Column[] selectedCols\n+    public void gatherLocalObjectStatisticsAsync(UUID gatId, UUID reqId, Map<StatisticsKeyMessage, int[]> keys) {\n+        int parts = keys.values().stream().mapToInt(arr -> arr.length).sum();\n+\n+        StatisticsGatheringContext[] ctxs = new StatisticsGatheringContext[1];\n+        currColls.compute(gatId, (k, v) -> {\n+            if (v == null)\n+                v = new StatisticsGatheringContext(gatId, keys.keySet(), parts);\n+\n+            ctxs[0] = v;\n+\n+            return v;\n+        });\n+\n+        statGathering.collectLocalObjectsStatisticsAsync(reqId, keys, () -> ctxs[0].doneFut().isCancelled());\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public StatsCollectionFuture<Map<GridTuple3<String, String, String[]>, ObjectStatistics>>\n+    collectObjectStatisticsAsync(\n+        GridTuple3<String, String, String[]>... keys\n     ) throws IgniteCheckedException {\n-        List<ObjectPartitionStatisticsImpl> tblPartStats = new ArrayList<>();\n-        GridH2RowDescriptor desc = tbl.rowDescriptor();\n-        String tblName = tbl.getName();\n+        Set<StatisticsKeyMessage> keysMsg = Arrays.stream(keys).map(\n+                k -> new StatisticsKeyMessage(k.get1(), k.get2(), Arrays.asList(k.get3()))).collect(Collectors.toSet());\n \n-        for (GridDhtLocalPartition locPart : tbl.cacheContext().topology().localPartitions()) {\n-            final boolean reserved = locPart.reserve();\n+        StatisticsGatheringContext status = new StatisticsGatheringContext(keysMsg);\n \n-            try {\n-                if (!reserved || (locPart.state() != OWNING && locPart.state() != MOVING)\n-                        || !locPart.primary(ctx.discovery().topologyVersionEx()))\n-                    continue;\n+        collectObjectStatistics(status);\n \n-                if (locPart.state() == MOVING)\n-                    tbl.cacheContext().preloader().syncFuture().get();\n+        return status.doneFut();\n+    }\n \n-                long rowsCnt = 0;\n+    /**\n+     * Cancel specified statistics gathering process.\n+     *\n+     * @param gatId Gathering id to cancel.\n+     */\n+    public void cancelLocalStatisticsGathering(UUID gatId){\n+       StatisticsGatheringContext stCtx = currColls.remove(gatId);\n+       if (stCtx != null)\n+           stCtx.doneFut().cancel();\n+    }\n \n-                List<ColumnStatisticsCollector> colStatsCollectors = new ArrayList<>(selectedCols.length);\n+    /** {@inheritDoc} */\n+    @Override public boolean cancelObjectStatisticsGathering(UUID gatId) {\n+        boolean res = false;\n+        StatisticsGatheringContext stCtx = currColls.remove(gatId);\n+        if (stCtx != null) {\n+\n+            res = stCtx.doneFut().cancel();\n+            if (res)\n+                statCrawler.sendCancelGatheringAsync(gatId);\n+        }\n+        return res;\n+    }\n \n-                for (Column col : selectedCols)\n-                    colStatsCollectors.add(new ColumnStatisticsCollector(col, tbl::compareValues));\n+    /**\n+     * Receive and store partition statistics object data for locals backup partition.\n+     *\n+     * @param data Collection of partition level statistics of local bacup partitions.\n+     */\n+    public void receivePartitionsStatistics(Collection<StatisticsObjectData> data) {\n+        for (StatisticsObjectData partData : data) {\n+            StatisticsKey key = new StatisticsKey(partData.key().schema(), partData.key().obj());\n \n-                for (CacheDataRow row : tbl.cacheContext().offheap().cachePartitionIterator(tbl.cacheId(), locPart.id(),\n-                        null, true)) {\n-                    GridQueryTypeDescriptor typeDesc = ctx.query().typeByValue(tbl.cacheName(),\n-                            tbl.cacheContext().cacheObjectContext(), row.key(), row.value(), false);\n-                    if (!tblName.equals(typeDesc.tableName()))\n-                        continue;\n+            assert partData.type() == StatisticsType.PARTITION : \"Got non partition level statistics by \" + key\n+                    + \" without request\";\n \n-                    rowsCnt++;\n+            if (log.isTraceEnabled())\n+                log.trace(String.format(\"Received partition statistics %s.%s:%d\", key.schema(), key.obj(),\n+                    partData.partId()));\n \n-                    H2Row row0 = desc.createRow(row);\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            if (tbl == null) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring outdated partition statistics %s.%s:%d\", key.schema(), key.obj(),\n+                        partData.partId()));\n \n-                    for (ColumnStatisticsCollector colStat : colStatsCollectors)\n-                        colStat.add(row0.getValue(colStat.col().getColumnId()));\n+                continue;\n+            }\n+            GridDhtPartitionState partState = tbl.cacheContext().topology().partitionState(ctx.localNodeId(), partData.partId());\n+            if (partState != OWNING) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Ignoring non local partition statistics %s.%s:%d\",\n+                            key.schema(), key.obj(), partData.partId()));\n \n-                }\n+                continue;\n+            }\n \n-                Map<String, ColumnStatistics> colStats = colStatsCollectors.stream().collect(Collectors.toMap(\n-                        csc -> csc.col().getName(), csc -> csc.finish()\n-                ));\n+            try {\n+                ObjectPartitionStatisticsImpl opStat = StatisticsUtils.toObjectPartitionStatistics(ctx, partData);\n \n-                tblPartStats.add(new ObjectPartitionStatisticsImpl(locPart.id(), true, rowsCnt,\n-                        locPart.updateCounter(), colStats));\n+                statsRepos.saveLocalPartitionStatistics(key, opStat);\n             }\n-            finally {\n-                if (reserved)\n-                    locPart.release();\n+            catch (IgniteCheckedException e) {\n+                if (log.isInfoEnabled())\n+                    log.info(String.format(\"Unable to parse partition statistics for %s.%s:%d because of: %s\",\n+                        key.schema(), key.obj(), partData.partId(), e.getMessage()));\n             }\n         }\n-\n-        return tblPartStats;\n     }\n \n     /**\n-     * Aggregate specified partition level statistics to local level statistics.\n+     * Aggregate specified gathered statistics, remove it form local and complete its future.\n      *\n-     * @param key Aggregation key.\n-     * @param tblPartStats Collection of all local partition level statistics by specified key.\n-     * @return Local level aggregated statistics.\n+     * @param stCtx Gathering to complete.\n      */\n-    public ObjectStatisticsImpl aggregateLocalStatistics(\n-            StatsKey key,\n-            Collection<ObjectPartitionStatisticsImpl> tblPartStats\n-    ) {\n-        // For now there can be only tables\n-        GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n-\n-        if (tbl == null) {\n-            // remove all loaded statistics.\n-            log.info(\"Removing statistics for object \" + key + \" cause table doesn't exists.\");\n-            statsRepos.clearLocalPartitionsStatistics(key);\n+    public void finishStatisticsCollection(StatisticsGatheringContext stCtx) {\n+        currColls.remove(stCtx.gatId());\n+\n+        Map<StatisticsKeyMessage, ObjectStatisticsImpl> keysGlobalStats = new HashMap<>();\n+        for (Map.Entry<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats : stCtx.collectedStatistics()\n+                .entrySet()) {\n+            ObjectStatisticsImpl globalCollectedStat = statGathering.aggregateLocalStatistics(keyStats.getKey(),\n+                keyStats.getValue());\n+            StatisticsKey statsKey = new StatisticsKey(keyStats.getKey().schema(), keyStats.getKey().obj());\n+            ObjectStatisticsImpl globalStat = statsRepos.mergeGlobalStatistics(statsKey, globalCollectedStat);\n+            keysGlobalStats.put(keyStats.getKey(), globalStat);\n         }\n-        return aggregateLocalStatistics(tbl, tbl.getColumns(), tblPartStats);\n+\n+        statCrawler.sendGlobalStat(keysGlobalStats);\n     }\n \n     /**\n-     * Aggregate partition level statistics to local level one.\n+     * Cache global statistics.\n      *\n-     * @param tbl Table to aggregate statistics by.\n-     * @param selectedCols Columns to aggregate statistics by.\n-     * @param tblPartStats Collection of partition level statistics.\n-     * @return Local level statistics.\n+     * @param data Global statistics to cache.\n      */\n-    private ObjectStatisticsImpl aggregateLocalStatistics(\n-            GridH2Table tbl,\n-            Column[] selectedCols,\n-            Collection<ObjectPartitionStatisticsImpl> tblPartStats\n-    ) {\n-        Map<Column, List<ColumnStatistics>> colPartStats = new HashMap<>(selectedCols.length);\n-        long rowCnt = 0;\n-        for (Column col : selectedCols)\n-            colPartStats.put(col, new ArrayList<>());\n-\n-        for (ObjectPartitionStatisticsImpl partStat : tblPartStats) {\n-            for (Column col : selectedCols) {\n-                ColumnStatistics colPartStat = partStat.columnStatistics(col.getName());\n-                if (colPartStat != null) {\n-                    colPartStats.compute(col, (k, v) -> {\n-                        v.add(colPartStat);\n-                        return v;\n-                    });\n-                }\n+    public void saveGlobalStatistics(Collection<StatisticsObjectData> data) {\n+        data.forEach(objData -> {\n+            try {\n+                ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(this.ctx, objData);\n+\n+                statsRepos.saveGlobalStatistics(new StatisticsKey(objData.key().schema(), objData.key().obj()), objStat);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Cannot read global statistics %s\", objData.key()));\n             }\n-            rowCnt += partStat.rowCount();\n+        });\n+    }\n+\n+    /**\n+     * Register\n+     *\n+     * @param gatId Gathering id.\n+     * @param data Collected statistics.\n+     */\n+    public void registerLocalResult(UUID gatId, Map<StatisticsObjectData, int[]> data) {\n+        StatisticsGatheringContext stCtx = currColls.get(gatId);\n+        if (stCtx == null) {\n+            if (log.isDebugEnabled())\n+                log.debug(String.format(\"Unable to register outdated statistics collection result %s\", gatId));\n+\n+            return;\n         }\n+        Map<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats = new HashMap<>();\n+        for (StatisticsObjectData objData : data.keySet()) {\n+            keyStats.compute(objData.key(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n \n-        Map<String, ColumnStatistics> colStats = new HashMap<>(selectedCols.length);\n-        for (Column col : selectedCols) {\n-            ColumnStatistics stat = ColumnStatisticsCollector.aggregate(tbl::compareValues, colPartStats.get(col));\n-            colStats.put(col.getName(), stat);\n+                try {\n+                    ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);", "originalCommit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUxODkwNw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556518907", "bodyText": "outdated", "author": "Berkof", "createdAt": "2021-01-13T13:29:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY5NjYxMQ=="}], "type": "inlineReview", "revised_code": {"commit": "7ef165002105dd10417170217e86d65771c524bb", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 1f98ad5ca73..4e5949c6399 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -434,7 +442,7 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n             return;\n         }\n         Map<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats = new HashMap<>();\n-        for (StatisticsObjectData objData : data.keySet()) {\n+        for (StatisticsObjectData objData : data) {\n             keyStats.compute(objData.key(), (k, v) -> {\n                 if (v == null)\n                     v = new ArrayList<>();\n", "next_change": {"commit": "05b732cd7e8840c429c48f5561e7c98e0289bcf6", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 4e5949c6399..ab2c41eca80 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -443,23 +447,17 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n         }\n         Map<StatisticsKeyMessage, Collection<ObjectStatisticsImpl>> keyStats = new HashMap<>();\n         for (StatisticsObjectData objData : data) {\n-            keyStats.compute(objData.key(), (k, v) -> {\n-                if (v == null)\n-                    v = new ArrayList<>();\n-\n-                try {\n-                    ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n-\n-                    v.add(objStat);\n-                }\n-                catch (IgniteCheckedException e) {\n-                    if (log.isDebugEnabled())\n-                        log.debug(String.format(\"Cannot read local statistics %s by gathering task %s\", objData.key(),\n-                            gatId));\n-                }\n-\n-                return v;\n-            });\n+            Collection<ObjectStatisticsImpl> keyObjStats = keyStats.computeIfAbsent(objData.key(), k -> new ArrayList<>());\n+            try {\n+                ObjectStatisticsImpl objStat = StatisticsUtils.toObjectStatistics(ctx, objData);\n+\n+                keyObjStats.add(objStat);\n+            }\n+            catch (IgniteCheckedException e) {\n+                if (log.isDebugEnabled())\n+                    log.debug(String.format(\"Cannot read local statistics %s by gathering task %s\", objData.key(),\n+                        gatId));\n+            }\n         }\n \n         if (stCtx.registerCollected(keyStats, partsCount))\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY5ODQ4MA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549698480", "body": "StatisticsObjectData has default equals and hashcode methods. IS it OK?", "bodyText": "StatisticsObjectData has default equals and hashcode methods. IS it OK?", "bodyHTML": "<p dir=\"auto\">StatisticsObjectData has default equals and hashcode methods. IS it OK?</p>", "author": "korlov42", "createdAt": "2020-12-29T13:08:49Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsGatheringResponse.java", "diffHunk": "@@ -0,0 +1,176 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat.messages;\n+\n+import org.apache.ignite.internal.GridDirectMap;\n+import org.apache.ignite.plugin.extensions.communication.Message;\n+import org.apache.ignite.plugin.extensions.communication.MessageCollectionItemType;\n+import org.apache.ignite.plugin.extensions.communication.MessageReader;\n+import org.apache.ignite.plugin.extensions.communication.MessageWriter;\n+\n+import java.io.Externalizable;\n+import java.nio.ByteBuffer;\n+import java.util.Map;\n+import java.util.UUID;\n+\n+/**\n+ * Message to send statistics.\n+ */\n+public class StatisticsGatheringResponse implements Message {\n+    /** */\n+    private static final long serialVersionUID = 0L;\n+\n+    /** */\n+    public static final short TYPE_CODE = 186;\n+\n+    /** Collection id. */\n+    private UUID gatId;\n+\n+    /** Request id. */\n+    private UUID reqId;\n+\n+    /** Map of collected local object statistics with array of included partitions. */\n+    @GridDirectMap(keyType = StatisticsObjectData.class, valueType = int[].class)\n+    private Map<StatisticsObjectData, int[]> data;", "originalCommit": "a2a8251fb92633bb823894ccc0ddd325b0cc7d6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUwNzQyMg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556507422", "bodyText": "Map removed with a sinle group per gathering task change", "author": "Berkof", "createdAt": "2021-01-13T13:09:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTY5ODQ4MA=="}], "type": "inlineReview", "revised_code": {"commit": "7ef165002105dd10417170217e86d65771c524bb", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsGatheringResponse.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsGatheringResponse.java\nindex 1f247c1864f..8641405e082 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsGatheringResponse.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsGatheringResponse.java\n", "chunk": "@@ -42,9 +44,12 @@ public class StatisticsGatheringResponse implements Message {\n     /** Request id. */\n     private UUID reqId;\n \n-    /** Map of collected local object statistics with array of included partitions. */\n-    @GridDirectMap(keyType = StatisticsObjectData.class, valueType = int[].class)\n-    private Map<StatisticsObjectData, int[]> data;\n+    /** Set of collected local object statistics. */\n+    @GridDirectCollection(StatisticsObjectData.class)\n+    private Set<StatisticsObjectData> data;\n+\n+    /** Array of included partitions. */\n+    private int[] parts;\n \n     /** {@inheritDoc} */\n     @Override public void onAckReceived() {\n", "next_change": {"commit": "05b732cd7e8840c429c48f5561e7c98e0289bcf6", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsGatheringResponse.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsGatheringResponse.java\nindex 8641405e082..32a84d4b49c 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsGatheringResponse.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsGatheringResponse.java\n", "chunk": "@@ -46,7 +44,7 @@ public class StatisticsGatheringResponse implements Message {\n \n     /** Set of collected local object statistics. */\n     @GridDirectCollection(StatisticsObjectData.class)\n-    private Set<StatisticsObjectData> data;\n+    private Collection<StatisticsObjectData> data;\n \n     /** Array of included partitions. */\n     private int[] parts;\n", "next_change": null}]}}]}}, {"oid": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "url": "https://github.com/gridgain/gridgain/commit/bbc77144eac02f5ee7e71db9e138935ee5c280a3", "message": "GG-31094: statistics clear, cancel and some fixes to collect", "committedDate": "2020-12-29T14:02:19Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc1NTk5Ng==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549755996", "body": "it's not going to work since it's possible to create column with comma in the name", "bodyText": "it's not going to work since it's possible to create column with comma in the name", "bodyHTML": "<p dir=\"auto\">it's not going to work since it's possible to create column with comma in the name</p>", "author": "korlov42", "createdAt": "2020-12-29T15:56:07Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsKeyMessage.java", "diffHunk": "@@ -0,0 +1,161 @@\n+package org.apache.ignite.internal.processors.query.stat.messages;\n+\n+import org.apache.ignite.internal.GridDirectCollection;\n+import org.apache.ignite.plugin.extensions.communication.Message;\n+import org.apache.ignite.plugin.extensions.communication.MessageCollectionItemType;\n+import org.apache.ignite.plugin.extensions.communication.MessageReader;\n+import org.apache.ignite.plugin.extensions.communication.MessageWriter;\n+\n+import java.io.Externalizable;\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+\n+/**\n+ * Key, describing the object of statistics. For example: table with some columns.\n+ */\n+public class StatisticsKeyMessage implements Message {\n+    /** */\n+    private static final long serialVersionUID = 0L;\n+\n+    /** */\n+    public static final short TYPE_CODE = 183;\n+\n+    /** Object schema. */\n+    private String schema;\n+\n+    /** Object name. */\n+    private String obj;\n+\n+    /** Optional list of columns to collect statistics by.\n+     * Each string can contain list of comma separated columns to represent multicolumn stats. */\n+    @GridDirectCollection(String.class)\n+    private List<String> colNames;", "originalCommit": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUwNjQzNQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556506435", "bodyText": "Good point. Any suggestions on how we should specify multicolumn statistics target? Just to put it into a protocol.", "author": "Berkof", "createdAt": "2021-01-13T13:07:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc1NTk5Ng=="}], "type": "inlineReview", "revised_code": {"commit": "17a54090bea4d97c122cf06d6be8e60177006519", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsKeyMessage.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsKeyMessage.java\nindex 85a34eafae0..0e2017b4c2a 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsKeyMessage.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsKeyMessage.java\n", "chunk": "@@ -26,8 +42,7 @@ public class StatisticsKeyMessage implements Message {\n     /** Object name. */\n     private String obj;\n \n-    /** Optional list of columns to collect statistics by.\n-     * Each string can contain list of comma separated columns to represent multicolumn stats. */\n+    /** Optional list of columns to collect statistics by. */\n     @GridDirectCollection(String.class)\n     private List<String> colNames;\n \n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc1NjUwNQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549756505", "body": "Message interface is partly implemented", "bodyText": "Message interface is partly implemented", "bodyHTML": "<p dir=\"auto\">Message interface is partly implemented</p>", "author": "korlov42", "createdAt": "2020-12-29T15:57:25Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsGetResponse.java", "diffHunk": "@@ -0,0 +1,84 @@\n+package org.apache.ignite.internal.processors.query.stat.messages;\n+\n+import org.apache.ignite.internal.GridDirectCollection;\n+import org.apache.ignite.plugin.extensions.communication.Message;\n+import org.apache.ignite.plugin.extensions.communication.MessageReader;\n+import org.apache.ignite.plugin.extensions.communication.MessageWriter;\n+\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.UUID;\n+\n+/**\n+ * Response with currently existing statistics.\n+ */\n+public class StatisticsGetResponse implements Message {", "originalCommit": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUwNTA5Ng==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556505096", "bodyText": "fixed", "author": "Berkof", "createdAt": "2021-01-13T13:05:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc1NjUwNQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc1OTk0MA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549759940", "body": "StatisticsKeyMessage has default equals and hashcode methods. IS it OK?", "bodyText": "StatisticsKeyMessage has default equals and hashcode methods. IS it OK?", "bodyHTML": "<p dir=\"auto\">StatisticsKeyMessage has default equals and hashcode methods. IS it OK?</p>", "author": "korlov42", "createdAt": "2020-12-29T16:07:03Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsGatheringRequest.java", "diffHunk": "@@ -0,0 +1,181 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat.messages;\n+\n+import org.apache.ignite.internal.GridDirectMap;\n+import org.apache.ignite.internal.managers.communication.GridIoPolicy;\n+import org.apache.ignite.plugin.extensions.communication.Message;\n+import org.apache.ignite.plugin.extensions.communication.MessageCollectionItemType;\n+import org.apache.ignite.plugin.extensions.communication.MessageReader;\n+import org.apache.ignite.plugin.extensions.communication.MessageWriter;\n+\n+import java.nio.ByteBuffer;\n+import java.util.Map;\n+import java.util.UUID;\n+\n+/**\n+ * Request to gather statistics message.\n+ */\n+public class StatisticsGatheringRequest implements Message {\n+    /** */\n+    private static final long serialVersionUID = 0L;\n+\n+    /** */\n+    public static final short TYPE_CODE = 179;\n+\n+    /** Gathering id. */\n+    private UUID gatId;\n+\n+    /** Request id. */\n+    private UUID reqId;\n+\n+    /** Keys to partitions to gather statistics by. */\n+    @GridDirectMap(keyType = StatisticsKeyMessage.class, valueType = int[].class)\n+    private Map<StatisticsKeyMessage, int[]> keys;", "originalCommit": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc4MDQ3Mw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549780473", "bodyText": "No, it's not, since it used here: https://github.com/gridgain/gridgain/pull/1660/files#diff-f727e80fc5250f851bb87b1f9cd9b5c159e5ca0cf094623418d515211784c82eR459", "author": "korlov42", "createdAt": "2020-12-29T17:07:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc1OTk0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUwNDEzNw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556504137", "bodyText": "HashCode&Equals implemented", "author": "Berkof", "createdAt": "2021-01-13T13:03:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc1OTk0MA=="}], "type": "inlineReview", "revised_code": {"commit": "7ef165002105dd10417170217e86d65771c524bb", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsGatheringRequest.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsGatheringRequest.java\nindex 667b10429b0..dc4abdf1872 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsGatheringRequest.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsGatheringRequest.java\n", "chunk": "@@ -43,8 +42,11 @@ public class StatisticsGatheringRequest implements Message {\n     private UUID reqId;\n \n     /** Keys to partitions to gather statistics by. */\n-    @GridDirectMap(keyType = StatisticsKeyMessage.class, valueType = int[].class)\n-    private Map<StatisticsKeyMessage, int[]> keys;\n+    @GridDirectCollection(StatisticsKeyMessage.class)\n+    private Set<StatisticsKeyMessage> keys;\n+\n+    /** Partitions to collect statistics by. */\n+    private int[] parts;\n \n     /**\n      * Default constructor.\n", "next_change": {"commit": "05b732cd7e8840c429c48f5561e7c98e0289bcf6", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsGatheringRequest.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsGatheringRequest.java\nindex dc4abdf1872..98baa85b2d2 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsGatheringRequest.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsGatheringRequest.java\n", "chunk": "@@ -43,7 +45,7 @@ public class StatisticsGatheringRequest implements Message {\n \n     /** Keys to partitions to gather statistics by. */\n     @GridDirectCollection(StatisticsKeyMessage.class)\n-    private Set<StatisticsKeyMessage> keys;\n+    private Collection<StatisticsKeyMessage> keys;\n \n     /** Partitions to collect statistics by. */\n     private int[] parts;\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc2MDg2Mg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549760862", "body": "please leave a comment inside GridIoMessageFactory with used codes", "bodyText": "please leave a comment inside GridIoMessageFactory with used codes", "bodyHTML": "<p dir=\"auto\">please leave a comment inside GridIoMessageFactory with used codes</p>", "author": "korlov42", "createdAt": "2020-12-29T16:09:44Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsGatheringRequest.java", "diffHunk": "@@ -0,0 +1,181 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat.messages;\n+\n+import org.apache.ignite.internal.GridDirectMap;\n+import org.apache.ignite.internal.managers.communication.GridIoPolicy;\n+import org.apache.ignite.plugin.extensions.communication.Message;\n+import org.apache.ignite.plugin.extensions.communication.MessageCollectionItemType;\n+import org.apache.ignite.plugin.extensions.communication.MessageReader;\n+import org.apache.ignite.plugin.extensions.communication.MessageWriter;\n+\n+import java.nio.ByteBuffer;\n+import java.util.Map;\n+import java.util.UUID;\n+\n+/**\n+ * Request to gather statistics message.\n+ */\n+public class StatisticsGatheringRequest implements Message {\n+    /** */\n+    private static final long serialVersionUID = 0L;\n+\n+    /** */\n+    public static final short TYPE_CODE = 179;", "originalCommit": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUwMzY4Mw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556503683", "bodyText": "done", "author": "Berkof", "createdAt": "2021-01-13T13:03:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc2MDg2Mg=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc3MTIxMA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549771210", "body": "wrong javadoc", "bodyText": "wrong javadoc", "bodyHTML": "<p dir=\"auto\">wrong javadoc</p>", "author": "korlov42", "createdAt": "2020-12-29T16:39:51Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,466 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsPropagationMessage;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.", "originalCommit": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ4OTg3OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556489878", "bodyText": "fixed", "author": "Berkof", "createdAt": "2021-01-13T12:38:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc3MTIxMA=="}], "type": "inlineReview", "revised_code": {"commit": "05b732cd7e8840c429c48f5561e7c98e0289bcf6", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 86d3d41f996..9cf548264e4 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -39,22 +38,37 @@ import java.util.List;\n import java.util.Map;\n import java.util.Set;\n import java.util.UUID;\n+import java.util.function.Function;\n import java.util.stream.Collectors;\n \n /**\n  * Current statistics collections with methods to work with it's messages.\n  */\n public class IgniteStatisticsHelper {\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** Local node id. */\n+    private final UUID locNodeId;\n+\n     /** Schema manager. */\n     private final SchemaManager schemaMgr;\n \n     /**\n      * Constructor.\n      *\n+     * @param locNodeId Local node id.\n      * @param schemaMgr Schema manager.\n+     * @param logSupplier Ignite logger supplier to get logger from.\n      */\n-    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+    public IgniteStatisticsHelper(\n+        UUID locNodeId,\n+        SchemaManager schemaMgr,\n+        Function<Class<?>, IgniteLogger> logSupplier\n+    ) {\n+        this.locNodeId = locNodeId;\n         this.schemaMgr = schemaMgr;\n+        this.log = logSupplier.apply(IgniteStatisticsHelper.class);\n     }\n \n     /**\n", "next_change": {"commit": "48b736c4cf138d5db12978e2004c446e26e1f097", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 9cf548264e4..8ec059e1251 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -71,6 +75,73 @@ public class IgniteStatisticsHelper {\n         this.log = logSupplier.apply(IgniteStatisticsHelper.class);\n     }\n \n+    /**\n+     * Aggregate specified partition level statistics to local level statistics.\n+     *\n+     * @param keyMsg Aggregation key.\n+     * @param stats Collection of all local partition level or local level statistics by specified key to aggregate.\n+     * @return Local level aggregated statistics.\n+     */\n+    public ObjectStatisticsImpl aggregateLocalStatistics(\n+            StatisticsKeyMessage keyMsg,\n+            Collection<? extends ObjectStatisticsImpl> stats\n+    ) {\n+        // For now there can be only tables\n+        GridH2Table tbl = schemaMgr.dataTable(keyMsg.schema(), keyMsg.obj());\n+\n+        if (tbl == null) {\n+            // remove all loaded statistics.\n+            if (log.isDebugEnabled())\n+                log.debug(String.format(\"Removing statistics for object %s.%s cause table doesn't exists.\",\n+                        keyMsg.schema(), keyMsg.obj()));\n+        }\n+\n+        return aggregateLocalStatistics(tbl, filterColumns(tbl.getColumns(), keyMsg.colNames()), stats);\n+    }\n+\n+    /**\n+     * Aggregate partition level statistics to local level one or local statistics to global one.\n+     *\n+     * @param tbl Table to aggregate statistics by.\n+     * @param selectedCols Columns to aggregate statistics by.\n+     * @param stats Collection of partition level or local level statistics to aggregate.\n+     * @return Local level statistics.\n+     */\n+    public static ObjectStatisticsImpl aggregateLocalStatistics(\n+            GridH2Table tbl,\n+            Column[] selectedCols,\n+            Collection<? extends ObjectStatisticsImpl> stats\n+    ) {\n+        Map<Column, List<ColumnStatistics>> colPartStats = new HashMap<>(selectedCols.length);\n+        long rowCnt = 0;\n+        for (Column col : selectedCols)\n+            colPartStats.put(col, new ArrayList<>());\n+\n+        for (ObjectStatisticsImpl partStat : stats) {\n+            for (Column col : selectedCols) {\n+                ColumnStatistics colPartStat = partStat.columnStatistics(col.getName());\n+                if (colPartStat != null) {\n+                    colPartStats.computeIfPresent(col, (k, v) -> {\n+                        v.add(colPartStat);\n+\n+                        return v;\n+                    });\n+                }\n+            }\n+            rowCnt += partStat.rowCount();\n+        }\n+\n+        Map<String, ColumnStatistics> colStats = new HashMap<>(selectedCols.length);\n+        for (Column col : selectedCols) {\n+            ColumnStatistics stat = ColumnStatisticsCollector.aggregate(tbl::compareValues, colPartStats.get(col));\n+            colStats.put(col.getName(), stat);\n+        }\n+\n+        ObjectStatisticsImpl tblStats = new ObjectStatisticsImpl(rowCnt, colStats);\n+\n+        return tblStats;\n+    }\n+\n     /**\n      * Get cache group context by specified statistics key.\n      *\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc3MTU1OQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549771559", "body": "computeIfAbsent", "bodyText": "computeIfAbsent", "bodyHTML": "<p dir=\"auto\">computeIfAbsent</p>", "author": "korlov42", "createdAt": "2020-12-29T16:40:56Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,466 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsPropagationMessage;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Get cache group context by specified statistics key.\n+     *\n+     * @param key Statistics key to get context by.\n+     * @return Cache group context for the given key.\n+     * @throws IgniteCheckedException If unable to find table by specified key.\n+     */\n+    public CacheGroupContext getGroupContext(StatisticsKeyMessage key) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+        return tbl.cacheContext().group();\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            res.compute(getGroupContext(key), (k, v) -> {", "originalCommit": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ4OTIyNw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556489227", "bodyText": "replaced", "author": "Berkof", "createdAt": "2021-01-13T12:37:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc3MTU1OQ=="}], "type": "inlineReview", "revised_code": {"commit": "fc2e8cbb19ef01669beaa69a239b2c7f8fb495db", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 86d3d41f996..5f0a2f7e2d0 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -76,11 +90,12 @@ public class IgniteStatisticsHelper {\n      * Extract groups of stats keys.\n      *\n      * @param keys Statistics key to extract groups from.\n-     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @return Map of <group ids> to <collection of keys in groups>\n      * @throws IgniteCheckedException In case of lack some of specified objects.\n      */\n-    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n-            throws IgniteCheckedException {\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(\n+        Collection<StatisticsKeyMessage> keys\n+    ) throws IgniteCheckedException {\n         Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n         for (StatisticsKeyMessage key : keys) {\n             res.compute(getGroupContext(key), (k, v) -> {\n", "next_change": {"commit": "17a54090bea4d97c122cf06d6be8e60177006519", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 5f0a2f7e2d0..f53952e7a19 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -97,16 +98,9 @@ public class IgniteStatisticsHelper {\n         Collection<StatisticsKeyMessage> keys\n     ) throws IgniteCheckedException {\n         Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n-        for (StatisticsKeyMessage key : keys) {\n-            res.compute(getGroupContext(key), (k, v) -> {\n-                if (v == null)\n-                    v = new ArrayList<>();\n-\n-                v.add(key);\n+        for (StatisticsKeyMessage key : keys)\n+            res.computeIfAbsent(getGroupContext(key), k -> new ArrayList<>()).add(key);\n \n-                return v;\n-            });\n-        }\n         return res;\n     }\n \n", "next_change": {"commit": "f5aafee54b1036c09d4944ca9bf0254f8bfd2b1e", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex f53952e7a19..2aa9b4a1480 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -109,20 +179,15 @@ public class IgniteStatisticsHelper {\n      *\n      * @param keys Keys to split.\n      * @return Map cache group to collection of keys in group.\n-     * @throws IgniteCheckedException If some of specified object won't be found in schema.\n      */\n-    public Map<CacheGroupContext, Collection<StatisticsKeyMessage>> splitByGroups(\n-        Collection<StatisticsKeyMessage> keys\n-    ) throws IgniteCheckedException {\n+    public Map<CacheGroupContext, Collection<StatisticsKeyMessage>> splitByGroups(Collection<StatisticsKeyMessage> keys) {\n         Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>();\n \n         for (StatisticsKeyMessage key : keys) {\n             GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            CacheGroupContext grp = (tbl == null) ? null : tbl.cacheContext().group();\n \n-            if (tbl == null)\n-                throw new IgniteCheckedException(String.format(\"Can't  find table %s.%s\", key.schema(), key.obj()));\n-\n-            res.computeIfAbsent(tbl.cacheContext().group(), k -> new ArrayList<>()).add(key);\n+            res.computeIfAbsent(grp, k -> new ArrayList<>()).add(key);\n         }\n \n         return res;\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc3MTY2Nw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549771667", "body": "comment in Russian ", "bodyText": "comment in Russian", "bodyHTML": "<p dir=\"auto\">comment in Russian</p>", "author": "korlov42", "createdAt": "2020-12-29T16:41:18Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,466 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsPropagationMessage;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Get cache group context by specified statistics key.\n+     *\n+     * @param key Statistics key to get context by.\n+     * @return Cache group context for the given key.\n+     * @throws IgniteCheckedException If unable to find table by specified key.\n+     */\n+    public CacheGroupContext getGroupContext(StatisticsKeyMessage key) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+        return tbl.cacheContext().group();\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            res.compute(getGroupContext(key), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Return all nodes where specified cache group located.\n+     *\n+     * @param grp Cache group context to locate.\n+     * @return Set of node ids where group located.\n+     */\n+    public static Set<UUID> nodes(CacheGroupContext grp) {\n+        Set<UUID> res = new HashSet<>();\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c", "originalCommit": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ3NzkyNA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556477924", "bodyText": "removed", "author": "Berkof", "createdAt": "2021-01-13T12:17:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc3MTY2Nw=="}], "type": "inlineReview", "revised_code": {"commit": "fc2e8cbb19ef01669beaa69a239b2c7f8fb495db", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 86d3d41f996..5f0a2f7e2d0 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -104,7 +143,6 @@ public class IgniteStatisticsHelper {\n     public static Set<UUID> nodes(CacheGroupContext grp) {\n         Set<UUID> res = new HashSet<>();\n         AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n-        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n         List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n \n         assignments.forEach(pnodes -> pnodes.forEach(cn -> res.add(cn.id())));\n", "next_change": {"commit": "17a54090bea4d97c122cf06d6be8e60177006519", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 5f0a2f7e2d0..f53952e7a19 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -145,7 +139,10 @@ public class IgniteStatisticsHelper {\n         AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n         List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n \n-        assignments.forEach(pnodes -> pnodes.forEach(cn -> res.add(cn.id())));\n+        for (List<ClusterNode> pnodes : assignments) {\n+            for (ClusterNode node : pnodes)\n+                res.add(node.id());\n+        }\n \n         return res;\n     }\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc3NDQyNg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549774426", "body": "```suggestion\r\n        if (partIds == null)\r\n            partIds = IntStream.range(0, assignments.size()).boxed().collect(Collectors.toList());\r\n\r\n        Map<UUID, List<Integer>> res = new HashMap<>();\r\n\r\n        for (Integer partId : partIds)\r\n            fillPartition(res, assignments, partId, isPrimary);\r\n```", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    Map<UUID, List<Integer>> res = new HashMap<>();\n          \n          \n            \n                    if (partIds == null)\n          \n          \n            \n                        for (int i = 0; i < assignments.size(); i++)\n          \n          \n            \n                            fillPartition(res, assignments, i, isPrimary);\n          \n          \n            \n                    else\n          \n          \n            \n                        for (Integer partId : partIds)\n          \n          \n            \n                            fillPartition(res, assignments, partId, isPrimary);\n          \n          \n            \n                    if (partIds == null)\n          \n          \n            \n                        partIds = IntStream.range(0, assignments.size()).boxed().collect(Collectors.toList());\n          \n          \n            \n            \n          \n          \n            \n                    Map<UUID, List<Integer>> res = new HashMap<>();\n          \n          \n            \n            \n          \n          \n            \n                    for (Integer partId : partIds)\n          \n          \n            \n                        fillPartition(res, assignments, partId, isPrimary);", "bodyHTML": "  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">        <span class=\"pl-k\"><span class=\"x x-first\">Map&lt;</span><span class=\"pl-smi x\">UUID</span><span class=\"x\">, </span><span class=\"pl-k\"><span class=\"x\">List&lt;</span><span class=\"pl-smi x\">Integer</span><span class=\"x\">&gt;</span></span><span class=\"x\">&gt;</span></span><span class=\"x\"> res </span><span class=\"pl-k x\">=</span><span class=\"x\"> </span><span class=\"pl-k x\">new</span><span class=\"x\"> </span><span class=\"pl-k x\">HashMap&lt;&gt;</span><span class=\"x x-last\">();</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">        <span class=\"pl-k x x-first\">if</span><span class=\"x x-last\"> (</span>partIds <span class=\"pl-k\">=<span class=\"x x-first\">=</span></span><span class=\"x\"> </span><span class=\"pl-c1 x\">null</span><span class=\"x x-last\">)</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\"><span class=\"x x-first\">            </span><span class=\"pl-k x\">for</span><span class=\"x\"> (</span><span class=\"pl-k x\">int</span><span class=\"x\"> i </span><span class=\"pl-k x\">=</span><span class=\"x\"> </span><span class=\"pl-c1 x\">0</span><span class=\"x\">; i </span><span class=\"pl-k x\">&lt;</span><span class=\"x\"> assignments</span><span class=\"pl-k x\">.</span><span class=\"x\">size(); i</span><span class=\"pl-k x\">++</span><span class=\"x x-last\">)</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">        <span class=\"x x-first x-last\">        fillPartition(</span>res<span class=\"x x-first x-last\">, assignments, i, isPrimary</span>);</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\"><span class=\"x x-first\">        </span><span class=\"pl-k x x-last\">else</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">        <span class=\"x x-first x-last\">    </span><span class=\"pl-k\">for</span> (<span class=\"pl-smi\">Integer</span> partId <span class=\"pl-k\">:</span> partIds)</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">            <span class=\"x x-first x-last\">    </span>fillPartition(res, assignments, partId, isPrimary);</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">        <span class=\"pl-k x x-first\">if</span><span class=\"x\"> (partIds </span><span class=\"pl-k x\">==</span><span class=\"x\"> </span><span class=\"pl-c1 x\">null</span><span class=\"x x-last\">)</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">        <span class=\"x x-first x-last\">    </span>partIds <span class=\"pl-k\">=</span><span class=\"x x-first\"> </span><span class=\"pl-smi x\">IntStream</span><span class=\"pl-k x\">.</span><span class=\"x\">range(</span><span class=\"pl-c1 x\">0</span><span class=\"x\">, assignments</span><span class=\"pl-k x\">.</span><span class=\"x\">size())</span><span class=\"pl-k x\">.</span><span class=\"x\">boxed()</span><span class=\"pl-k x\">.</span><span class=\"x\">collect(</span><span class=\"pl-smi x\">Collectors</span><span class=\"pl-k x\">.</span><span class=\"x x-last\">toList());</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\"></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">        <span class=\"pl-k\"><span class=\"x x-first\">Map&lt;</span><span class=\"pl-smi x\">UUID</span><span class=\"x\">, </span><span class=\"pl-k\"><span class=\"x\">List&lt;</span><span class=\"pl-smi x\">Integer</span><span class=\"x\">&gt;</span></span><span class=\"x\">&gt;</span></span><span class=\"x x-last\"> </span>res<span class=\"x x-first\"> </span><span class=\"pl-k x\">=</span><span class=\"x\"> </span><span class=\"pl-k x\">new</span><span class=\"x\"> </span><span class=\"pl-k x\">HashMap&lt;&gt;</span><span class=\"x x-last\">(</span>);</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\"></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">        <span class=\"pl-k\">for</span> (<span class=\"pl-smi\">Integer</span> partId <span class=\"pl-k\">:</span> partIds)</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">            fillPartition(res, assignments, partId, isPrimary);</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "korlov42", "createdAt": "2020-12-29T16:50:09Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,466 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsPropagationMessage;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Get cache group context by specified statistics key.\n+     *\n+     * @param key Statistics key to get context by.\n+     * @return Cache group context for the given key.\n+     * @throws IgniteCheckedException If unable to find table by specified key.\n+     */\n+    public CacheGroupContext getGroupContext(StatisticsKeyMessage key) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+        return tbl.cacheContext().group();\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            res.compute(getGroupContext(key), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Return all nodes where specified cache group located.\n+     *\n+     * @param grp Cache group context to locate.\n+     * @return Set of node ids where group located.\n+     */\n+    public static Set<UUID> nodes(CacheGroupContext grp) {\n+        Set<UUID> res = new HashSet<>();\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        assignments.forEach(pnodes -> pnodes.forEach(cn -> res.add(cn.id())));\n+\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @param isPrimary if {@code true} - only master partitions will be selected, if {@code false} - only backups.\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(\n+        CacheGroupContext grp,\n+        Collection<Integer> partIds,\n+        boolean isPrimary\n+    ) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartition(res, assignments, i, isPrimary);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartition(res, assignments, partId, isPrimary);", "originalCommit": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjUwMjEzMA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556502130", "bodyText": "implemented", "author": "Berkof", "createdAt": "2021-01-13T13:00:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc3NDQyNg=="}], "type": "inlineReview", "revised_code": {"commit": "17a54090bea4d97c122cf06d6be8e60177006519", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 86d3d41f996..f53952e7a19 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -126,125 +161,29 @@ public class IgniteStatisticsHelper {\n         boolean isPrimary\n     ) {\n         AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n-        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n         List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n \n-        Map<UUID, List<Integer>> res = new HashMap<>();\n         if (partIds == null)\n-            for (int i = 0; i < assignments.size(); i++)\n-                fillPartition(res, assignments, i, isPrimary);\n-        else\n-            for (Integer partId : partIds)\n-                fillPartition(res, assignments, partId, isPrimary);\n-\n-        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n-                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n-    }\n+            partIds = IntStream.range(0, assignments.size()).boxed().collect(Collectors.toList());\n \n-    /**\n-     * Fill map with master or backups node of specified partition.\n-     *\n-     * @param res Map to fill.\n-     * @param assignments Partitions assignments.\n-     * @param partId Partition to process.\n-     * @param isPrimary if {@code true} only primary nodes will be choosen, if {@code false} - only backups.\n-     */\n-    protected static  void fillPartition(\n-        Map<UUID, List<Integer>> res,\n-        List<List<ClusterNode>> assignments,\n-        int partId,\n-        boolean isPrimary\n-    ) {\n-        assert partId < assignments.size();\n-        List<ClusterNode> partNodes = assignments.get(partId);\n-        if (F.isEmpty(partNodes))\n-            return;\n-\n-        if (isPrimary)\n-            res.compute(partNodes.get(0).id(), (k, v) -> {\n-                if (v == null)\n-                    v = new ArrayList<>();\n-\n-                v.add(partId);\n-\n-                return v;\n-            });\n-        else\n-            for (int i = 1; i < partNodes.size() - 1; i++)\n-                res.compute(partNodes.get(i).id(), (k, v) -> {\n-                    if (v == null)\n-                        v = new ArrayList<>();\n-\n-                    v.add(partId);\n-\n-                    return v;\n-                });\n-    }\n-\n-    /**\n-     * Prepare statistics collection request for specified node.\n-     *\n-     * @param colId Collection id.\n-     * @param data Keys to partitions for current node.\n-     * @return Statistics collection request.\n-     */\n-    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n-        UUID reqId = UUID.randomUUID();\n-        return new StatisticsGatheringRequest(colId, reqId, data);\n-    }\n-\n-    // TODO add extraction of necessary partIds by statKeyMsg\n-\n-    /**\n-     * Generate statistics collection requests by given keys.\n-     *\n-     * @param colId Collection id.\n-     * @param locNodeId Local node id.\n-     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n-     *            If {@code null} - requests will be\n-     * @return Collection of statistics collection addressed request.\n-     */\n-    public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n-        UUID colId,\n-        UUID locNodeId,\n-        Map<StatisticsKeyMessage, int[]> failedPartitions,\n-        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts\n-    ) {\n-        // NodeId to <Key to partitions on node> map\n-        Map<UUID, Map<StatisticsKeyMessage, int[]>> reqMap = new HashMap<>();\n-        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n-            // TODO: can we specify partitions here? from failed parts will it be effective?\n-            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null, true);\n-\n-            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n-                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n-                    if (v == null)\n-                        v = new HashMap<>();\n-\n-                    Collection<StatisticsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n-\n-                    for (StatisticsKeyMessage key : grpKeys) {\n-                        int[] keyNodeParts = (failedPartitions == null) ? nodeParts.getValue() :\n-                                GridArrays.intersect(nodeParts.getValue(), failedPartitions.get(key));\n-\n-                        if (keyNodeParts.length > 0)\n-                            v.put(key, keyNodeParts);\n-                    }\n-\n-                    return v.isEmpty() ? null : v;\n-                });\n-        }\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        for (Integer partId : partIds) {\n+            assert partId < assignments.size();\n \n-        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs = new ArrayList<>();\n-        for (Map.Entry<UUID, Map<StatisticsKeyMessage, int[]>> nodeGpsParts: reqMap.entrySet()) {\n-            if (nodeGpsParts.getValue().isEmpty())\n+            List<ClusterNode> partNodes = assignments.get(partId);\n+            if (F.isEmpty(partNodes))\n                 continue;\n \n-            StatisticsGatheringRequest req = prepareRequest(colId, nodeGpsParts.getValue());\n-            reqs.add(new StatisticsAddrRequest<>(req, locNodeId, nodeGpsParts.getKey()));\n+            if (isPrimary)\n+                res.computeIfAbsent(partNodes.get(0).id(), k -> new ArrayList<>()).add(partId);\n+            else {\n+                for (int i = 1; i < partNodes.size(); i++)\n+                    res.computeIfAbsent(partNodes.get(i).id(), k -> new ArrayList<>()).add(partId);\n+            }\n         }\n \n-        return reqs;\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n     }\n \n     /**\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc3NTQxNg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549775416", "body": "why we don't count the last node?", "bodyText": "why we don't count the last node?", "bodyHTML": "<p dir=\"auto\">why we don't count the last node?</p>", "author": "korlov42", "createdAt": "2020-12-29T16:53:36Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,466 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringResponse;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsPropagationMessage;\n+import org.apache.ignite.internal.util.GridArrays;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Current statistics collections with methods to work with it's messages.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     */\n+    public IgniteStatisticsHelper(SchemaManager schemaMgr) {\n+        this.schemaMgr = schemaMgr;\n+    }\n+\n+    /**\n+     * Get cache group context by specified statistics key.\n+     *\n+     * @param key Statistics key to get context by.\n+     * @return Cache group context for the given key.\n+     * @throws IgniteCheckedException If unable to find table by specified key.\n+     */\n+    public CacheGroupContext getGroupContext(StatisticsKeyMessage key) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+        return tbl.cacheContext().group();\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids></group> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(Collection<StatisticsKeyMessage> keys)\n+            throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys) {\n+            res.compute(getGroupContext(key), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(key);\n+\n+                return v;\n+            });\n+        }\n+        return res;\n+    }\n+\n+    /**\n+     * Return all nodes where specified cache group located.\n+     *\n+     * @param grp Cache group context to locate.\n+     * @return Set of node ids where group located.\n+     */\n+    public static Set<UUID> nodes(CacheGroupContext grp) {\n+        Set<UUID> res = new HashSet<>();\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        assignments.forEach(pnodes -> pnodes.forEach(cn -> res.add(cn.id())));\n+\n+        return res;\n+    }\n+\n+    /**\n+     * Get map cluster node to it's partitions for the specified cache group.\n+     *\n+     * @param grp Cache group context to get partition information by.\n+     * @param partIds Partition to collect information by\n+     * @param isPrimary if {@code true} - only master partitions will be selected, if {@code false} - only backups.\n+     * @return Map nodeId to array of partitions, related to node.\n+     */\n+    public static Map<UUID, int[]> nodePartitions(\n+        CacheGroupContext grp,\n+        Collection<Integer> partIds,\n+        boolean isPrimary\n+    ) {\n+        AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n+        // \u041d\u0430 \u043a\u0430\u043a\u043e\u0439 \u043d\u043e\u0434\u0435 \u043d\u0430 \u043a\u0430\u043a\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u043a\u0430\u043a\u0438\u0435 \u043f\u0430\u0440\u0442\u0438\u0446\u0438\u0438 \u0441\u043e\u0431\u0438\u0440\u0430\u0442\u044c\n+        List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        if (partIds == null)\n+            for (int i = 0; i < assignments.size(); i++)\n+                fillPartition(res, assignments, i, isPrimary);\n+        else\n+            for (Integer partId : partIds)\n+                fillPartition(res, assignments, partId, isPrimary);\n+\n+        return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n+                v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n+    }\n+\n+    /**\n+     * Fill map with master or backups node of specified partition.\n+     *\n+     * @param res Map to fill.\n+     * @param assignments Partitions assignments.\n+     * @param partId Partition to process.\n+     * @param isPrimary if {@code true} only primary nodes will be choosen, if {@code false} - only backups.\n+     */\n+    protected static  void fillPartition(\n+        Map<UUID, List<Integer>> res,\n+        List<List<ClusterNode>> assignments,\n+        int partId,\n+        boolean isPrimary\n+    ) {\n+        assert partId < assignments.size();\n+        List<ClusterNode> partNodes = assignments.get(partId);\n+        if (F.isEmpty(partNodes))\n+            return;\n+\n+        if (isPrimary)\n+            res.compute(partNodes.get(0).id(), (k, v) -> {\n+                if (v == null)\n+                    v = new ArrayList<>();\n+\n+                v.add(partId);\n+\n+                return v;\n+            });\n+        else\n+            for (int i = 1; i < partNodes.size() - 1; i++)", "originalCommit": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc3NjU3Mg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549776572", "bodyText": "also braces", "author": "korlov42", "createdAt": "2020-12-29T16:56:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc3NTQxNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ3NTk1NA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556475954", "bodyText": "we should, removed -1;\nadded", "author": "Berkof", "createdAt": "2021-01-13T12:13:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc3NTQxNg=="}], "type": "inlineReview", "revised_code": {"commit": "fc2e8cbb19ef01669beaa69a239b2c7f8fb495db", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 86d3d41f996..5f0a2f7e2d0 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -161,90 +198,10 @@ public class IgniteStatisticsHelper {\n             return;\n \n         if (isPrimary)\n-            res.compute(partNodes.get(0).id(), (k, v) -> {\n-                if (v == null)\n-                    v = new ArrayList<>();\n-\n-                v.add(partId);\n-\n-                return v;\n-            });\n+            res.computeIfAbsent(partNodes.get(0).id(), k -> new ArrayList<>()).add(partId);\n         else\n             for (int i = 1; i < partNodes.size() - 1; i++)\n-                res.compute(partNodes.get(i).id(), (k, v) -> {\n-                    if (v == null)\n-                        v = new ArrayList<>();\n-\n-                    v.add(partId);\n-\n-                    return v;\n-                });\n-    }\n-\n-    /**\n-     * Prepare statistics collection request for specified node.\n-     *\n-     * @param colId Collection id.\n-     * @param data Keys to partitions for current node.\n-     * @return Statistics collection request.\n-     */\n-    public static StatisticsGatheringRequest prepareRequest(UUID colId, Map<StatisticsKeyMessage, int[]> data) {\n-        UUID reqId = UUID.randomUUID();\n-        return new StatisticsGatheringRequest(colId, reqId, data);\n-    }\n-\n-    // TODO add extraction of necessary partIds by statKeyMsg\n-\n-    /**\n-     * Generate statistics collection requests by given keys.\n-     *\n-     * @param colId Collection id.\n-     * @param locNodeId Local node id.\n-     * @param failedPartitions Map of stat key to array of failed partitions to generate requests by.\n-     *            If {@code null} - requests will be\n-     * @return Collection of statistics collection addressed request.\n-     */\n-    public static Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> generateCollectionRequests(\n-        UUID colId,\n-        UUID locNodeId,\n-        Map<StatisticsKeyMessage, int[]> failedPartitions,\n-        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpContexts\n-    ) {\n-        // NodeId to <Key to partitions on node> map\n-        Map<UUID, Map<StatisticsKeyMessage, int[]>> reqMap = new HashMap<>();\n-        for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpEntry : grpContexts.entrySet()) {\n-            // TODO: can we specify partitions here? from failed parts will it be effective?\n-            Map<UUID, int[]> reqNodes = nodePartitions(grpEntry.getKey(), null, true);\n-\n-            for (Map.Entry<UUID, int[]> nodeParts : reqNodes.entrySet())\n-                reqMap.compute(nodeParts.getKey(), (k, v) -> {\n-                    if (v == null)\n-                        v = new HashMap<>();\n-\n-                    Collection<StatisticsKeyMessage> grpKeys = grpContexts.get(grpEntry.getKey());\n-\n-                    for (StatisticsKeyMessage key : grpKeys) {\n-                        int[] keyNodeParts = (failedPartitions == null) ? nodeParts.getValue() :\n-                                GridArrays.intersect(nodeParts.getValue(), failedPartitions.get(key));\n-\n-                        if (keyNodeParts.length > 0)\n-                            v.put(key, keyNodeParts);\n-                    }\n-\n-                    return v.isEmpty() ? null : v;\n-                });\n-        }\n-\n-        Collection<StatisticsAddrRequest<StatisticsGatheringRequest>> reqs = new ArrayList<>();\n-        for (Map.Entry<UUID, Map<StatisticsKeyMessage, int[]>> nodeGpsParts: reqMap.entrySet()) {\n-            if (nodeGpsParts.getValue().isEmpty())\n-                continue;\n-\n-            StatisticsGatheringRequest req = prepareRequest(colId, nodeGpsParts.getValue());\n-            reqs.add(new StatisticsAddrRequest<>(req, locNodeId, nodeGpsParts.getKey()));\n-        }\n-\n-        return reqs;\n+                res.computeIfAbsent(partNodes.get(i).id(), k -> new ArrayList<>()).add(partId);\n     }\n \n     /**\n", "next_change": {"commit": "17a54090bea4d97c122cf06d6be8e60177006519", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex 5f0a2f7e2d0..f53952e7a19 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -166,44 +163,29 @@ public class IgniteStatisticsHelper {\n         AffinityTopologyVersion grpTopVer = grp.shared().exchange().readyAffinityVersion();\n         List<List<ClusterNode>> assignments = grp.affinity().assignments(grpTopVer);\n \n-        Map<UUID, List<Integer>> res = new HashMap<>();\n         if (partIds == null)\n-            for (int i = 0; i < assignments.size(); i++)\n-                fillPartition(res, assignments, i, isPrimary);\n-        else\n-            for (Integer partId : partIds)\n-                fillPartition(res, assignments, partId, isPrimary);\n+            partIds = IntStream.range(0, assignments.size()).boxed().collect(Collectors.toList());\n+\n+        Map<UUID, List<Integer>> res = new HashMap<>();\n+        for (Integer partId : partIds) {\n+            assert partId < assignments.size();\n+\n+            List<ClusterNode> partNodes = assignments.get(partId);\n+            if (F.isEmpty(partNodes))\n+                continue;\n+\n+            if (isPrimary)\n+                res.computeIfAbsent(partNodes.get(0).id(), k -> new ArrayList<>()).add(partId);\n+            else {\n+                for (int i = 1; i < partNodes.size(); i++)\n+                    res.computeIfAbsent(partNodes.get(i).id(), k -> new ArrayList<>()).add(partId);\n+            }\n+        }\n \n         return res.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey,\n                 v -> v.getValue().stream().mapToInt(Integer::intValue).toArray()));\n     }\n \n-    /**\n-     * Fill map with master or backups node of specified partition.\n-     *\n-     * @param res Map to fill.\n-     * @param assignments Partitions assignments.\n-     * @param partId Partition to process.\n-     * @param isPrimary if {@code true} only primary nodes will be choosen, if {@code false} - only backups.\n-     */\n-    protected static void fillPartition(\n-        Map<UUID, List<Integer>> res,\n-        List<List<ClusterNode>> assignments,\n-        int partId,\n-        boolean isPrimary\n-    ) {\n-        assert partId < assignments.size();\n-        List<ClusterNode> partNodes = assignments.get(partId);\n-        if (F.isEmpty(partNodes))\n-            return;\n-\n-        if (isPrimary)\n-            res.computeIfAbsent(partNodes.get(0).id(), k -> new ArrayList<>()).add(partId);\n-        else\n-            for (int i = 1; i < partNodes.size() - 1; i++)\n-                res.computeIfAbsent(partNodes.get(i).id(), k -> new ArrayList<>()).add(partId);\n-    }\n-\n     /**\n      * Get all nodes where specified cache groups located.\n      *\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc4Njc3MQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549786771", "body": "let's use class with meaningful name instead of GridTuple3", "bodyText": "let's use class with meaningful name instead of GridTuple3", "bodyHTML": "<p dir=\"auto\">let's use class with meaningful name instead of GridTuple3</p>", "author": "korlov42", "createdAt": "2020-12-29T17:27:22Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -87,195 +142,420 @@ public IgniteStatisticsRepository statisticsRepository() {\n \n     /** {@inheritDoc} */\n     @Override public ObjectStatistics getLocalStatistics(String schemaName, String objName) {\n-        return statsRepos.getLocalStatistics(new StatsKey(schemaName, objName));\n+        return statsRepos.getLocalStatistics(new StatisticsKey(schemaName, objName));\n+    }\n+\n+    /**\n+     * Clear object statistics implementation.\n+     *\n+     * @param keys Keys to clear statistics by.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void clearObjectStatistics(Collection<StatisticsKeyMessage> keys) throws IgniteCheckedException {\n+        statCrawler.sendClearStatisticsAsync(keys);\n+        /*Collection<StatisticsAddrRequest<StatisticsClearRequest>> clearReqs = helper.generateClearRequests(keys);\n+\n+        Collection<StatisticsAddrRequest<StatisticsClearRequest>> failedReqs = sendRequests(clearReqs);\n+        if (!F.isEmpty(failedReqs))\n+            if (log.isInfoEnabled())\n+                log.info(String.format(\"Unable to send all statistics clear requests to %d nodes for keys %s\",\n+                    failedReqs.size(), keys));\n+\n+\n+        UUID locId = ctx.localNodeId();\n+        StatisticsAddrRequest<StatisticsClearRequest> locMsg = clearReqs.stream().filter(m -> locId.equals(m.targetNodeId())).findAny()\n+                .orElse(null);\n+        if (null != locMsg)\n+            for (StatisticsKeyMessage locKey : locMsg.req().keys())\n+                clearObjectStatisticsLocal(locKey);*/\n+    }\n+\n+    /**\n+     * Update counter to mark that statistics by some partitions where collected by remote request.\n+     *\n+     * @param gatId Gathering id.\n+     * @param parts Partitions count.\n+     */\n+    public void onRemoteGatheringSend(UUID gatId, int parts) {\n+        currColls.compute(gatId, (k,v) -> {\n+           if (v == null) {\n+               if (log.isDebugEnabled())\n+                   log.debug(String.format(\"Unable to mark %d partitions gathered by gathering id %s\", parts, gatId));\n+\n+               return null;\n+           }\n+\n+           return v.registerCollected(Collections.emptyMap(), parts) ? null : v;\n+        });\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void clearObjectStatistics(\n+            final GridTuple3<String, String, String[]>... keys", "originalCommit": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ3NDI1MA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556474250", "bodyText": "I create StatisticsTarget for it.", "author": "Berkof", "createdAt": "2021-01-13T12:10:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc4Njc3MQ=="}], "type": "inlineReview", "revised_code": {"commit": "17a54090bea4d97c122cf06d6be8e60177006519", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex e9503248866..636f380904e 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -190,24 +185,12 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(\n-            final GridTuple3<String, String, String[]>... keys\n-    ) throws IgniteCheckedException {\n-        Collection<StatisticsKeyMessage> keyMsgs = Arrays.stream(keys).map(k -> new StatisticsKeyMessage(k.get1(), k.get2(),\n-                Arrays.asList(k.get3()))).collect(Collectors.toList());\n+    @Override public void clearObjectStatistics(StatisticsTarget... targets) throws IgniteCheckedException {\n \n-        clearObjectStatistics(keyMsgs);\n-    }\n+        List<StatisticsKeyMessage> keys = Arrays.stream(targets).map(target -> new StatisticsKeyMessage(target.schema(),\n+            target.obj(), Arrays.asList(target.columns()))).collect(Collectors.toList());\n \n-    /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(\n-            String schemaName,\n-            String objName,\n-            String... colNames\n-    ) throws IgniteCheckedException {\n-        StatisticsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n-\n-        clearObjectStatistics(Collections.singleton(keyMsg));\n+        clearObjectStatistics(keys);\n     }\n \n     /**\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc4NzQ3OQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549787479", "body": "this is not used", "bodyText": "this is not used", "bodyHTML": "<p dir=\"auto\">this is not used</p>", "author": "korlov42", "createdAt": "2020-12-29T17:29:42Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -87,195 +142,420 @@ public IgniteStatisticsRepository statisticsRepository() {\n \n     /** {@inheritDoc} */\n     @Override public ObjectStatistics getLocalStatistics(String schemaName, String objName) {\n-        return statsRepos.getLocalStatistics(new StatsKey(schemaName, objName));\n+        return statsRepos.getLocalStatistics(new StatisticsKey(schemaName, objName));\n+    }\n+\n+    /**\n+     * Clear object statistics implementation.\n+     *\n+     * @param keys Keys to clear statistics by.\n+     * @throws IgniteCheckedException In case of errors.\n+     */\n+    private void clearObjectStatistics(Collection<StatisticsKeyMessage> keys) throws IgniteCheckedException {\n+        statCrawler.sendClearStatisticsAsync(keys);\n+        /*Collection<StatisticsAddrRequest<StatisticsClearRequest>> clearReqs = helper.generateClearRequests(keys);\n+\n+        Collection<StatisticsAddrRequest<StatisticsClearRequest>> failedReqs = sendRequests(clearReqs);\n+        if (!F.isEmpty(failedReqs))\n+            if (log.isInfoEnabled())\n+                log.info(String.format(\"Unable to send all statistics clear requests to %d nodes for keys %s\",\n+                    failedReqs.size(), keys));\n+\n+\n+        UUID locId = ctx.localNodeId();\n+        StatisticsAddrRequest<StatisticsClearRequest> locMsg = clearReqs.stream().filter(m -> locId.equals(m.targetNodeId())).findAny()\n+                .orElse(null);\n+        if (null != locMsg)\n+            for (StatisticsKeyMessage locKey : locMsg.req().keys())\n+                clearObjectStatisticsLocal(locKey);*/\n+    }\n+\n+    /**\n+     * Update counter to mark that statistics by some partitions where collected by remote request.\n+     *\n+     * @param gatId Gathering id.\n+     * @param parts Partitions count.\n+     */\n+    public void onRemoteGatheringSend(UUID gatId, int parts) {\n+        currColls.compute(gatId, (k,v) -> {\n+           if (v == null) {\n+               if (log.isDebugEnabled())\n+                   log.debug(String.format(\"Unable to mark %d partitions gathered by gathering id %s\", parts, gatId));\n+\n+               return null;\n+           }\n+\n+           return v.registerCollected(Collections.emptyMap(), parts) ? null : v;\n+        });\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public void clearObjectStatistics(\n+            final GridTuple3<String, String, String[]>... keys\n+    ) throws IgniteCheckedException {\n+        Collection<StatisticsKeyMessage> keyMsgs = Arrays.stream(keys).map(k -> new StatisticsKeyMessage(k.get1(), k.get2(),\n+                Arrays.asList(k.get3()))).collect(Collectors.toList());\n+\n+        clearObjectStatistics(keyMsgs);\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void clearObjectStatistics(String schemaName, String objName, String... colNames) {\n-        StatsKey key = new StatsKey(schemaName, objName);\n+    @Override public void clearObjectStatistics(\n+            String schemaName,\n+            String objName,\n+            String... colNames\n+    ) throws IgniteCheckedException {\n+        StatisticsKeyMessage keyMsg = StatisticsUtils.toMessage(schemaName, objName, colNames);\n+\n+        clearObjectStatistics(Collections.singleton(keyMsg));\n+    }\n+\n+    /**\n+     * Actually clear local object statistics by the given key.\n+     *\n+     * @param keyMsg Key to clear statistics by.\n+     */\n+    private void clearObjectStatisticsLocal(StatisticsKeyMessage keyMsg) {\n+        StatisticsKey key = new StatisticsKey(keyMsg.schema(), keyMsg.obj());\n+        String[] colNames = keyMsg.colNames().toArray(new String[0]);\n+\n         statsRepos.clearLocalPartitionsStatistics(key, colNames);\n         statsRepos.clearLocalStatistics(key, colNames);\n         statsRepos.clearGlobalStatistics(key, colNames);\n     }\n \n     /**\n-     * Filter columns by specified names.\n+     * Collect object statistics prepared status.\n      *\n-     * @param cols Columns to filter.\n-     * @param colNames Column names.\n-     * @return Column with specified names.\n+     * @param status Collection status to collect statistics by.\n+     * @throws IgniteCheckedException In case of errors.\n      */\n-    private Column[] filterColumns(Column[] cols, String... colNames) {\n-        if (F.isEmpty(colNames))\n-            return cols;\n-\n-        Set<String> colNamesSet = new HashSet(Arrays.asList(colNames));\n-        List<Column> resList = new ArrayList<>(colNames.length);\n-\n-        for (Column col : cols)\n-            if (colNamesSet.contains(col.getName()))\n-                resList.add(col);\n+    private void collectObjectStatistics(StatisticsGatheringContext status) throws IgniteCheckedException {\n+        statCrawler.sendGatheringRequestsAsync(status.gatId(), status.keys(), null);\n+    }\n \n-        return resList.toArray(new Column[resList.size()]);\n+    /**\n+     * Calculate total partitions count for all keys in gathering task.\n+     *\n+     * @param keys Collection of keys to calculate partitions by.\n+     * @return Total number of partitions in all tasks keys.\n+     */\n+    private Integer calculatePartitions(Collection<StatisticsKeyMessage> keys) {", "originalCommit": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ3Mzk2NQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556473965", "bodyText": "removed", "author": "Berkof", "createdAt": "2021-01-13T12:09:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc4NzQ3OQ=="}], "type": "inlineReview", "revised_code": {"commit": "fc2e8cbb19ef01669beaa69a239b2c7f8fb495db", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex e9503248866..9b0400b2b32 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -234,33 +230,21 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n         statCrawler.sendGatheringRequestsAsync(status.gatId(), status.keys(), null);\n     }\n \n-    /**\n-     * Calculate total partitions count for all keys in gathering task.\n-     *\n-     * @param keys Collection of keys to calculate partitions by.\n-     * @return Total number of partitions in all tasks keys.\n-     */\n-    private Integer calculatePartitions(Collection<StatisticsKeyMessage> keys) {\n-        int res = 0;\n-        for (StatisticsKeyMessage key : keys) {\n-            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n-            if (tbl == null)\n-                return null;\n-\n-            res += tbl.cacheContext().topology().partitions();\n-        }\n-        return res;\n-    }\n-\n     /** {@inheritDoc} */\n     @Override public void collectObjectStatistics(\n             String schemaName,\n             String objName,\n             String... colNames\n     ) throws IgniteCheckedException {\n+\n         StatisticsKeyMessage keyMsg = new StatisticsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n-        StatisticsGatheringContext status = new StatisticsGatheringContext(Collections.singleton(keyMsg));\n+        CacheGroupContext grpCtx = helper.getGroupContext(keyMsg);\n+\n+        StatisticsGatheringContext status = new StatisticsGatheringContext(UUID.randomUUID(),\n+            Collections.singleton(keyMsg), grpCtx.topology().partitions());\n+\n         currColls.put(status.gatId(), status);\n+\n         collectObjectStatistics(status);\n \n         status.doneFut().get();\n", "next_change": {"commit": "33170812024f6c4d321f85287fea0b6c3abdb9e5", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 9b0400b2b32..5011b1a87a5 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -227,27 +219,25 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n      * @throws IgniteCheckedException In case of errors.\n      */\n     private void collectObjectStatistics(StatisticsGatheringContext status) throws IgniteCheckedException {\n-        statCrawler.sendGatheringRequestsAsync(status.gatId(), status.keys(), null);\n+        statCrawler.sendGatheringRequestsAsync(status.gatheringId(), status.keys(), null);\n     }\n \n     /** {@inheritDoc} */\n-    @Override public void collectObjectStatistics(\n-            String schemaName,\n-            String objName,\n-            String... colNames\n-    ) throws IgniteCheckedException {\n+    @Override public void gatherObjectStatistics(StatisticsTarget target) throws IgniteCheckedException {\n+        checkSupport(\"collect statistics\");\n \n-        StatisticsKeyMessage keyMsg = new StatisticsKeyMessage(schemaName, objName, Arrays.asList(colNames));\n+        StatisticsKeyMessage keyMsg = new StatisticsKeyMessage(target.schema(), target.obj(),\n+            Arrays.asList(target.columns()));\n         CacheGroupContext grpCtx = helper.getGroupContext(keyMsg);\n \n         StatisticsGatheringContext status = new StatisticsGatheringContext(UUID.randomUUID(),\n             Collections.singleton(keyMsg), grpCtx.topology().partitions());\n \n-        currColls.put(status.gatId(), status);\n+        currColls.put(status.gatheringId(), status);\n \n         collectObjectStatistics(status);\n \n-        status.doneFut().get();\n+        status.doneFuture().get();\n     }\n \n     /**\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc5MzI4NQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r549793285", "body": "looks like debug code", "bodyText": "looks like debug code", "bodyHTML": "<p dir=\"auto\">looks like debug code</p>", "author": "korlov42", "createdAt": "2020-12-29T17:49:14Z", "path": "modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/PSUStatisticPartialCollectionTest.java", "diffHunk": "@@ -81,7 +81,11 @@ public void compareSelectWithIntConditions() throws IgniteCheckedException {\n                 String.format(lo_med_select, 7, 7), noHints);\n \n         statsMgr.collectObjectStatistics(\"PUBLIC\", \"TBL_SELECT\", \"LO_SELECT\");\n-\n+        try {\n+            Thread.sleep(1000);", "originalCommit": "bbc77144eac02f5ee7e71db9e138935ee5c280a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTc4NjgxNg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555786816", "bodyText": "removed", "author": "Berkof", "createdAt": "2021-01-12T13:56:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTc5MzI4NQ=="}], "type": "inlineReview", "revised_code": {"commit": "17a54090bea4d97c122cf06d6be8e60177006519", "changed_code": [{"header": "diff --git a/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/PSUStatisticPartialCollectionTest.java b/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/PSUStatisticPartialCollectionTest.java\nindex 697a7156dcb..724630f5022 100644\n--- a/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/PSUStatisticPartialCollectionTest.java\n+++ b/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/PSUStatisticPartialCollectionTest.java\n", "chunk": "@@ -81,11 +81,7 @@ public class PSUStatisticPartialCollectionTest extends StatisticsAbstractTest {\n                 String.format(lo_med_select, 7, 7), noHints);\n \n         statsMgr.collectObjectStatistics(\"PUBLIC\", \"TBL_SELECT\", \"LO_SELECT\");\n-        try {\n-            Thread.sleep(1000);\n-        } catch (InterruptedException e) {\n-            e.printStackTrace();\n-        }\n+\n         checkOptimalPlanChosenForDifferentIndexes(grid(0), new String[]{\"TBL_SELECT_LO_IDX\"},\n                 String.format(lo_med_select, 8, 8), noHints);\n     }\n", "next_change": {"commit": "efd6b5e9f1f91625c2e6106b4c75522dada68b46", "changed_code": [{"header": "diff --git a/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/PSUStatisticPartialCollectionTest.java b/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/PSUStatisticPartialCollectionTest.java\nindex 724630f5022..a4616574825 100644\n--- a/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/PSUStatisticPartialCollectionTest.java\n+++ b/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/PSUStatisticPartialCollectionTest.java\n", "chunk": "@@ -75,12 +75,12 @@ public class PSUStatisticPartialCollectionTest extends StatisticsAbstractTest {\n                 String.format(lo_med_select, 6, 6), noHints);\n \n         IgniteStatisticsManager statsMgr = grid(0).context().query().getIndexing().statsManager();\n-        statsMgr.collectObjectStatistics(\"PUBLIC\", \"TBL_SELECT\", \"HI_SELECT\");\n+        statsMgr.collectObjectStatistics(new StatisticsTarget(\"PUBLIC\", \"TBL_SELECT\", \"HI_SELECT\"));\n \n         checkOptimalPlanChosenForDifferentIndexes(grid(0), new String[]{\"TBL_SELECT_MED_IDX\"},\n                 String.format(lo_med_select, 7, 7), noHints);\n \n-        statsMgr.collectObjectStatistics(\"PUBLIC\", \"TBL_SELECT\", \"LO_SELECT\");\n+        statsMgr.collectObjectStatistics(new StatisticsTarget(\"PUBLIC\", \"TBL_SELECT\", \"LO_SELECT\"));\n \n         checkOptimalPlanChosenForDifferentIndexes(grid(0), new String[]{\"TBL_SELECT_LO_IDX\"},\n                 String.format(lo_med_select, 8, 8), noHints);\n", "next_change": {"commit": "33170812024f6c4d321f85287fea0b6c3abdb9e5", "changed_code": [{"header": "diff --git a/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/PSUStatisticPartialCollectionTest.java b/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/PSUStatisticPartialGatheringTest.java\nsimilarity index 92%\nrename from modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/PSUStatisticPartialCollectionTest.java\nrename to modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/PSUStatisticPartialGatheringTest.java\nindex a4616574825..779a36b7c70 100644\n--- a/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/PSUStatisticPartialCollectionTest.java\n+++ b/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/PSUStatisticPartialGatheringTest.java\n", "chunk": "@@ -75,12 +75,12 @@ public class PSUStatisticPartialCollectionTest extends StatisticsAbstractTest {\n                 String.format(lo_med_select, 6, 6), noHints);\n \n         IgniteStatisticsManager statsMgr = grid(0).context().query().getIndexing().statsManager();\n-        statsMgr.collectObjectStatistics(new StatisticsTarget(\"PUBLIC\", \"TBL_SELECT\", \"HI_SELECT\"));\n+        statsMgr.gatherObjectStatistics(new StatisticsTarget(\"PUBLIC\", \"TBL_SELECT\", \"HI_SELECT\"));\n \n         checkOptimalPlanChosenForDifferentIndexes(grid(0), new String[]{\"TBL_SELECT_MED_IDX\"},\n                 String.format(lo_med_select, 7, 7), noHints);\n \n-        statsMgr.collectObjectStatistics(new StatisticsTarget(\"PUBLIC\", \"TBL_SELECT\", \"LO_SELECT\"));\n+        statsMgr.gatherObjectStatistics(new StatisticsTarget(\"PUBLIC\", \"TBL_SELECT\", \"LO_SELECT\"));\n \n         checkOptimalPlanChosenForDifferentIndexes(grid(0), new String[]{\"TBL_SELECT_LO_IDX\"},\n                 String.format(lo_med_select, 8, 8), noHints);\n", "next_change": null}]}}]}}]}}, {"oid": "7ef165002105dd10417170217e86d65771c524bb", "url": "https://github.com/gridgain/gridgain/commit/7ef165002105dd10417170217e86d65771c524bb", "message": "GG-31094: collect statistics by only one cache group by request", "committedDate": "2020-12-31T11:58:01Z", "type": "commit"}, {"oid": "05b732cd7e8840c429c48f5561e7c98e0289bcf6", "url": "https://github.com/gridgain/gridgain/commit/05b732cd7e8840c429c48f5561e7c98e0289bcf6", "message": "GG-31094: collect stats by only one cache group", "committedDate": "2021-01-11T11:24:57Z", "type": "commit"}, {"oid": "e54c934091d0917505fbe4bd919fd766a492897e", "url": "https://github.com/gridgain/gridgain/commit/e54c934091d0917505fbe4bd919fd766a492897e", "message": "GG-31094: comment, docs and codestyle", "committedDate": "2021-01-11T11:48:18Z", "type": "commit"}, {"oid": "604f88f1b4cd375f5474ea768ce8e4fa4fd3c658", "url": "https://github.com/gridgain/gridgain/commit/604f88f1b4cd375f5474ea768ce8e4fa4fd3c658", "message": "GG-31094: checkstyle", "committedDate": "2021-01-11T12:19:11Z", "type": "commit"}, {"oid": "fc2e8cbb19ef01669beaa69a239b2c7f8fb495db", "url": "https://github.com/gridgain/gridgain/commit/fc2e8cbb19ef01669beaa69a239b2c7f8fb495db", "message": "GG-31094: PR fixes", "committedDate": "2021-01-11T13:35:43Z", "type": "commit"}, {"oid": "b385286d37cb759a2a308a055b12f32c5c22a976", "url": "https://github.com/gridgain/gridgain/commit/b385286d37cb759a2a308a055b12f32c5c22a976", "message": "GG-31094: fixes in test, backup sending and local saving.", "committedDate": "2021-01-12T13:20:32Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTgyNzA2OQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555827069", "body": "```suggestion\r\n    public StatisticsObjectData(\r\n        StatisticsKeyMessage key,\r\n        long rowsCnt,\r\n        StatisticsType type,\r\n        int partId,\r\n        long updCnt,\r\n        Map<String, StatisticsColumnData> data\r\n    ) {\r\n```", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public StatisticsObjectData(\n          \n          \n            \n                        StatisticsKeyMessage key,\n          \n          \n            \n                        long rowsCnt,\n          \n          \n            \n                        StatisticsType type,\n          \n          \n            \n                        int partId,\n          \n          \n            \n                        long updCnt,\n          \n          \n            \n                        Map<String, StatisticsColumnData> data\n          \n          \n            \n                ) {\n          \n          \n            \n                public StatisticsObjectData(\n          \n          \n            \n                    StatisticsKeyMessage key,\n          \n          \n            \n                    long rowsCnt,\n          \n          \n            \n                    StatisticsType type,\n          \n          \n            \n                    int partId,\n          \n          \n            \n                    long updCnt,\n          \n          \n            \n                    Map<String, StatisticsColumnData> data\n          \n          \n            \n                ) {", "bodyHTML": "  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"75\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">    <span class=\"pl-k\">public</span> StatisticsObjectData(</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"76\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">        <span class=\"x x-first x-last\">    </span><span class=\"pl-smi\">StatisticsKeyMessage</span> key,</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"77\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">        <span class=\"x x-first x-last\">    </span><span class=\"pl-k\">long</span> rowsCnt,</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"78\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">        <span class=\"x x-first x-last\">    </span><span class=\"pl-smi\">StatisticsType</span> type,</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"79\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">        <span class=\"x x-first x-last\">    </span><span class=\"pl-k\">int</span> partId,</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"80\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">        <span class=\"x x-first x-last\">    </span><span class=\"pl-k\">long</span> updCnt,</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"81\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">        <span class=\"x x-first x-last\">    </span><span class=\"pl-k\">Map&lt;<span class=\"pl-smi\">String</span>, <span class=\"pl-smi\">StatisticsColumnData</span>&gt;</span> data</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"82\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">    ) {</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"75\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">    <span class=\"pl-k\">public</span> StatisticsObjectData(</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"76\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">        <span class=\"pl-smi\">StatisticsKeyMessage</span> key,</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"77\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">        <span class=\"pl-k\">long</span> rowsCnt,</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"78\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">        <span class=\"pl-smi\">StatisticsType</span> type,</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"79\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">        <span class=\"pl-k\">int</span> partId,</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"80\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">        <span class=\"pl-k\">long</span> updCnt,</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"81\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">        <span class=\"pl-k\">Map&lt;<span class=\"pl-smi\">String</span>, <span class=\"pl-smi\">StatisticsColumnData</span>&gt;</span> data</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"82\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">    ) {</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "korlov42", "createdAt": "2021-01-12T14:48:05Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsObjectData.java", "diffHunk": "@@ -0,0 +1,265 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat.messages;\n+\n+import org.apache.ignite.internal.GridDirectMap;\n+import org.apache.ignite.internal.processors.query.stat.StatisticsType;\n+import org.apache.ignite.plugin.extensions.communication.Message;\n+import org.apache.ignite.plugin.extensions.communication.MessageCollectionItemType;\n+import org.apache.ignite.plugin.extensions.communication.MessageReader;\n+import org.apache.ignite.plugin.extensions.communication.MessageWriter;\n+\n+import java.nio.ByteBuffer;\n+\n+import java.util.Map;\n+\n+/**\n+ * Statistics for some object (index or table) in database.\n+ */\n+public class StatisticsObjectData implements Message {\n+    /** */\n+    private static final long serialVersionUID = 0L;\n+\n+    /** */\n+    public static final short TYPE_CODE = 184;\n+\n+    /** Statistics key. */\n+    private StatisticsKeyMessage key;\n+\n+    /** Total row count in current object. */\n+    private long rowsCnt;\n+\n+    /** Type of statistics. */\n+    private StatisticsType type;\n+\n+    /** Partition id if statistics was collected by partition. */\n+    private int partId;\n+\n+    /** Update counter if statistics was collected by partition. */\n+    private long updCnt;\n+\n+    /** Columns key to statistic map. */\n+    @GridDirectMap(keyType = String.class, valueType = StatisticsColumnData.class)\n+    private Map<String, StatisticsColumnData> data;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param key Statistics key.\n+     * @param rowsCnt Total row count.\n+     * @param type Statistics type.\n+     * @param partId Partition id.\n+     * @param updCnt Partition update counter.\n+     * @param data Map of statistics column data.\n+     */\n+    public StatisticsObjectData(\n+            StatisticsKeyMessage key,\n+            long rowsCnt,\n+            StatisticsType type,\n+            int partId,\n+            long updCnt,\n+            Map<String, StatisticsColumnData> data\n+    ) {", "originalCommit": "b385286d37cb759a2a308a055b12f32c5c22a976", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ3MTgxOQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556471819", "bodyText": "intersect removed, suggestion commited", "author": "Berkof", "createdAt": "2021-01-13T12:05:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTgyNzA2OQ=="}], "type": "inlineReview", "revised_code": {"commit": "17a54090bea4d97c122cf06d6be8e60177006519", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsObjectData.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsObjectData.java\nindex d8b1d84fd63..4a0e6fb9ede 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsObjectData.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsObjectData.java\n", "chunk": "@@ -66,12 +66,12 @@ public class StatisticsObjectData implements Message {\n      * @param data Map of statistics column data.\n      */\n     public StatisticsObjectData(\n-            StatisticsKeyMessage key,\n-            long rowsCnt,\n-            StatisticsType type,\n-            int partId,\n-            long updCnt,\n-            Map<String, StatisticsColumnData> data\n+        StatisticsKeyMessage key,\n+        long rowsCnt,\n+        StatisticsType type,\n+        int partId,\n+        long updCnt,\n+        Map<String, StatisticsColumnData> data\n     ) {\n         this.key = key;\n         this.rowsCnt = rowsCnt;\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTg4MzEwNg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555883106", "body": "```suggestion\r\n    /**\r\n     * Optional list of columns to collect statistics by.\r\n     * Each string can contain list of comma separated columns to represent multicolumn stats.\r\n     */\r\n    @GridDirectCollection(String.class)\r\n```", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                /** Optional list of columns to collect statistics by.\n          \n          \n            \n                 * Each string can contain list of comma separated columns to represent multicolumn stats. */\n          \n          \n            \n                @GridDirectCollection(String.class)\n          \n          \n            \n                /**\n          \n          \n            \n                 * Optional list of columns to collect statistics by.\n          \n          \n            \n                 * Each string can contain list of comma separated columns to represent multicolumn stats.\n          \n          \n            \n                 */\n          \n          \n            \n                @GridDirectCollection(String.class)", "bodyHTML": "  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"46\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">    <span class=\"pl-c\"><span class=\"pl-c\">/*</span>* Optional list of columns to collect statistics by.</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"47\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">     <span class=\"pl-k\">*</span> <span class=\"pl-smi\">Each</span> string can contain list of comma separated columns to represent multicolumn stats. <span class=\"pl-k\">*/</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"48\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">    <span class=\"pl-k\">@GridDirectCollection</span>(<span class=\"pl-smi\">String</span><span class=\"pl-k\">.</span>class)</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"46\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">    <span class=\"pl-c\"><span class=\"pl-c\">/**</span></span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"47\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">     <span class=\"pl-k\">*</span> <span class=\"pl-smi\">Optional</span> list of columns to collect statistics by.</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"48\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">     <span class=\"pl-k\">*</span> <span class=\"pl-smi\">Each</span> string can contain list of comma separated columns to represent multicolumn stats.</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"49\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">     <span class=\"pl-k\">*/</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"50\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">    <span class=\"pl-k\">@GridDirectCollection</span>(<span class=\"pl-smi\">String</span><span class=\"pl-k\">.</span>class)</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "korlov42", "createdAt": "2021-01-12T15:57:59Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsKeyMessage.java", "diffHunk": "@@ -0,0 +1,176 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat.messages;\n+\n+import org.apache.ignite.internal.GridDirectCollection;\n+import org.apache.ignite.plugin.extensions.communication.Message;\n+import org.apache.ignite.plugin.extensions.communication.MessageCollectionItemType;\n+import org.apache.ignite.plugin.extensions.communication.MessageReader;\n+import org.apache.ignite.plugin.extensions.communication.MessageWriter;\n+\n+import java.io.Externalizable;\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+\n+/**\n+ * Key, describing the object of statistics. For example: table with some columns.\n+ */\n+public class StatisticsKeyMessage implements Message {\n+    /** */\n+    private static final long serialVersionUID = 0L;\n+\n+    /** */\n+    public static final short TYPE_CODE = 183;\n+\n+    /** Object schema. */\n+    private String schema;\n+\n+    /** Object name. */\n+    private String obj;\n+\n+    /** Optional list of columns to collect statistics by.\n+     * Each string can contain list of comma separated columns to represent multicolumn stats. */\n+    @GridDirectCollection(String.class)", "originalCommit": "b385286d37cb759a2a308a055b12f32c5c22a976", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ3MzI5OQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556473299", "bodyText": "commited", "author": "Berkof", "createdAt": "2021-01-13T12:08:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTg4MzEwNg=="}], "type": "inlineReview", "revised_code": {"commit": "17a54090bea4d97c122cf06d6be8e60177006519", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsKeyMessage.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsKeyMessage.java\nindex f95f01a4233..0e2017b4c2a 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsKeyMessage.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsKeyMessage.java\n", "chunk": "@@ -41,8 +42,7 @@ public class StatisticsKeyMessage implements Message {\n     /** Object name. */\n     private String obj;\n \n-    /** Optional list of columns to collect statistics by.\n-     * Each string can contain list of comma separated columns to represent multicolumn stats. */\n+    /** Optional list of columns to collect statistics by. */\n     @GridDirectCollection(String.class)\n     private List<String> colNames;\n \n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTg4NTUwNg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555885506", "body": "should not be 0", "bodyText": "should not be 0", "bodyHTML": "<p dir=\"auto\">should not be 0</p>", "author": "korlov42", "createdAt": "2021-01-12T16:01:00Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsGetResponse.java", "diffHunk": "@@ -0,0 +1,148 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat.messages;\n+\n+import org.apache.ignite.internal.GridDirectCollection;\n+import org.apache.ignite.plugin.extensions.communication.Message;\n+import org.apache.ignite.plugin.extensions.communication.MessageCollectionItemType;\n+import org.apache.ignite.plugin.extensions.communication.MessageReader;\n+import org.apache.ignite.plugin.extensions.communication.MessageWriter;\n+\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.UUID;\n+\n+/**\n+ * Response with currently existing statistics.\n+ */\n+public class StatisticsGetResponse implements Message {\n+    /** */\n+    private static final long serialVersionUID = 0L;\n+\n+    /** */\n+    public static final short TYPE_CODE = 188;\n+\n+    /** Request id. */\n+    private UUID reqId;\n+\n+    /** List of keys to supply statistics by. */\n+    @GridDirectCollection(StatisticsObjectData.class)\n+    private List<StatisticsObjectData> data;\n+\n+    /**\n+     * Default constructor.\n+     */\n+    public StatisticsGetResponse() {\n+    }\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param reqId Request id.\n+     * @param data Statistics data.\n+     */\n+    public StatisticsGetResponse(UUID reqId, List<StatisticsObjectData> data) {\n+        this.reqId = reqId;\n+        this.data = data;\n+    }\n+\n+    /**\n+     * @return Request id.\n+     */\n+    public UUID reqId() {\n+        return reqId;\n+    }\n+\n+    /**\n+     * @return Statistics.\n+     */\n+    public List<StatisticsObjectData> data() {\n+        return data;\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public boolean writeTo(ByteBuffer buf, MessageWriter writer) {\n+        writer.setBuffer(buf);\n+\n+        if (!writer.isHeaderWritten()) {\n+            if (!writer.writeHeader(directType(), fieldsCount()))\n+                return false;\n+\n+            writer.onHeaderWritten();\n+        }\n+\n+        switch (writer.state()) {\n+            case 0:\n+                if (!writer.writeCollection(\"data\", data, MessageCollectionItemType.MSG))\n+                    return false;\n+\n+                writer.incrementState();\n+\n+            case 1:\n+                if (!writer.writeUuid(\"reqId\", reqId))\n+                    return false;\n+\n+                writer.incrementState();\n+\n+        }\n+\n+        return true;\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public boolean readFrom(ByteBuffer buf, MessageReader reader) {\n+        reader.setBuffer(buf);\n+\n+        if (!reader.beforeMessageRead())\n+            return false;\n+\n+        switch (reader.state()) {\n+            case 0:\n+                data = reader.readCollection(\"data\", MessageCollectionItemType.MSG);\n+\n+                if (!reader.isLastRead())\n+                    return false;\n+\n+                reader.incrementState();\n+\n+            case 1:\n+                reqId = reader.readUuid(\"reqId\");\n+\n+                if (!reader.isLastRead())\n+                    return false;\n+\n+                reader.incrementState();\n+\n+        }\n+\n+        return reader.afterMessageRead(StatisticsGetResponse.class);\n+    }\n+\n+    /** {@inheritDoc} */\n+    @Override public short directType() {\n+        return 0;", "originalCommit": "b385286d37cb759a2a308a055b12f32c5c22a976", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ2ODU1Mg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556468552", "bodyText": "fixed", "author": "Berkof", "createdAt": "2021-01-13T11:59:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTg4NTUwNg=="}], "type": "inlineReview", "revised_code": {"commit": "17a54090bea4d97c122cf06d6be8e60177006519", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsGetResponse.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsGetResponse.java\nindex ff3f94d4049..ea9e8cb3025 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsGetResponse.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/messages/StatisticsGetResponse.java\n", "chunk": "@@ -133,7 +133,7 @@ public class StatisticsGetResponse implements Message {\n \n     /** {@inheritDoc} */\n     @Override public short directType() {\n-        return 0;\n+        return TYPE_CODE;\n     }\n \n     /** {@inheritDoc} */\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTkwOTEyNg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555909126", "body": "stale javadoc", "bodyText": "stale javadoc", "bodyHTML": "<p dir=\"auto\">stale javadoc</p>", "author": "korlov42", "createdAt": "2021-01-12T16:33:07Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java", "diffHunk": "@@ -41,131 +40,98 @@\n     private final IgniteStatisticsManagerImpl statisticsMgr;\n \n     /** Local (for current node) object statistics. */\n-    private final Map<StatsKey, ObjectStatisticsImpl> locStats;\n+    private final Map<StatisticsKey, ObjectStatisticsImpl> locStats;\n+\n+    /** Statistics gathering. */\n+    private final StatisticsGathering statisticsGathering;\n \n     /** Global (for whole cluster) object statistics. */\n-    private final Map<StatsKey, ObjectStatisticsImpl> globalStats = new ConcurrentHashMap<>();\n+    private final Map<StatisticsKey, ObjectStatisticsImpl> globalStats = new ConcurrentHashMap<>();\n \n     /**\n      * Constructor.\n      *\n-     * @param storeData If {@code true} - node stores data locally, {@code false} - otherwise.\n      * @param db Database to use in storage if persistence enabled.", "originalCommit": "b385286d37cb759a2a308a055b12f32c5c22a976", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ3MjYzNw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556472637", "bodyText": "fixed", "author": "Berkof", "createdAt": "2021-01-13T12:07:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTkwOTEyNg=="}], "type": "inlineReview", "revised_code": {"commit": "17a54090bea4d97c122cf06d6be8e60177006519", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\nindex a3632c4d276..1d6123a1919 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n", "chunk": "@@ -51,8 +51,7 @@ public class IgniteStatisticsRepositoryImpl implements IgniteStatisticsRepositor\n     /**\n      * Constructor.\n      *\n-     * @param db Database to use in storage if persistence enabled.\n-     * @param subscriptionProcessor Subscription processor.\n+     * @param store Ignite statistics store to use.\n      * @param statisticsMgr Ignite statistics manager.\n      * @param statisticsGathering Statistics gathering.\n      * @param logSupplier Ignite logger supplier to get logger from.\n", "next_change": {"commit": "efd6b5e9f1f91625c2e6106b4c75522dada68b46", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\nindex 1d6123a1919..aa46a02fd10 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n", "chunk": "@@ -52,19 +49,16 @@ public class IgniteStatisticsRepositoryImpl implements IgniteStatisticsRepositor\n      * Constructor.\n      *\n      * @param store Ignite statistics store to use.\n-     * @param statisticsMgr Ignite statistics manager.\n      * @param statisticsGathering Statistics gathering.\n      * @param logSupplier Ignite logger supplier to get logger from.\n      */\n     public IgniteStatisticsRepositoryImpl(\n             IgniteStatisticsStore store,\n-            IgniteStatisticsManagerImpl statisticsMgr,\n             StatisticsGathering statisticsGathering,\n             Function<Class<?>, IgniteLogger> logSupplier\n     ) {\n         this.store = store;\n         this.locStats = new ConcurrentHashMap<>();\n-        this.statisticsMgr = statisticsMgr;\n         this.statisticsGathering = statisticsGathering;\n         this.log = logSupplier.apply(IgniteStatisticsRepositoryImpl.class);\n     }\n", "next_change": {"commit": "48b736c4cf138d5db12978e2004c446e26e1f097", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\nindex aa46a02fd10..a869c30ad41 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n", "chunk": "@@ -49,17 +49,17 @@ public class IgniteStatisticsRepositoryImpl implements IgniteStatisticsRepositor\n      * Constructor.\n      *\n      * @param store Ignite statistics store to use.\n-     * @param statisticsGathering Statistics gathering.\n+     * @param helper IgniteStatisticsHelper.\n      * @param logSupplier Ignite logger supplier to get logger from.\n      */\n     public IgniteStatisticsRepositoryImpl(\n             IgniteStatisticsStore store,\n-            StatisticsGathering statisticsGathering,\n+            IgniteStatisticsHelper helper,\n             Function<Class<?>, IgniteLogger> logSupplier\n     ) {\n         this.store = store;\n         this.locStats = new ConcurrentHashMap<>();\n-        this.statisticsGathering = statisticsGathering;\n+        this.helper = helper;\n         this.log = logSupplier.apply(IgniteStatisticsRepositoryImpl.class);\n     }\n \n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTkyODM4MQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555928381", "body": "```suggestion\r\n    public void collectLocalObjectsStatisticsAsync(\r\n        UUID reqId,\r\n        Set<StatisticsKeyMessage> keys,\r\n        int[] parts,\r\n        Supplier<Boolean> cancelled\r\n    );\r\n\r\n    /**\r\n     * @param statRepo Statistics repository.\r\n     */\r\n    public void repository(IgniteStatisticsRepository statRepo);\r\n\r\n    /**\r\n     * Aggregate specified partition level statistics to local level statistics.\r\n     *\r\n     * @param keyMsg Aggregation key.\r\n     * @param stats Collection of all local partition level or local level statistics by specified key to aggregate.\r\n     * @return Local level aggregated statistics.\r\n     */\r\n    public ObjectStatisticsImpl aggregateLocalStatistics(\r\n        StatisticsKeyMessage keyMsg,\r\n        Collection<? extends ObjectStatisticsImpl> stats\r\n    );\r\n```", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public void collectLocalObjectsStatisticsAsync(\n          \n          \n            \n                        UUID reqId,\n          \n          \n            \n                        Set<StatisticsKeyMessage> keys,\n          \n          \n            \n                        int[] parts,\n          \n          \n            \n                        Supplier<Boolean> cancelled\n          \n          \n            \n                );\n          \n          \n            \n            \n          \n          \n            \n                /**\n          \n          \n            \n                 * @param statRepo Statistics repository.\n          \n          \n            \n                 */\n          \n          \n            \n                public void repository(IgniteStatisticsRepository statRepo);\n          \n          \n            \n            \n          \n          \n            \n                /**\n          \n          \n            \n                 * Aggregate specified partition level statistics to local level statistics.\n          \n          \n            \n                 *\n          \n          \n            \n                 * @param keyMsg Aggregation key.\n          \n          \n            \n                 * @param stats Collection of all local partition level or local level statistics by specified key to aggregate.\n          \n          \n            \n                 * @return Local level aggregated statistics.\n          \n          \n            \n                 */\n          \n          \n            \n                public ObjectStatisticsImpl aggregateLocalStatistics(\n          \n          \n            \n                        StatisticsKeyMessage keyMsg,\n          \n          \n            \n                        Collection<? extends ObjectStatisticsImpl> stats\n          \n          \n            \n                );\n          \n          \n            \n                public void collectLocalObjectsStatisticsAsync(\n          \n          \n            \n                    UUID reqId,\n          \n          \n            \n                    Set<StatisticsKeyMessage> keys,\n          \n          \n            \n                    int[] parts,\n          \n          \n            \n                    Supplier<Boolean> cancelled\n          \n          \n            \n                );\n          \n          \n            \n            \n          \n          \n            \n                /**\n          \n          \n            \n                 * @param statRepo Statistics repository.\n          \n          \n            \n                 */\n          \n          \n            \n                public void repository(IgniteStatisticsRepository statRepo);\n          \n          \n            \n            \n          \n          \n            \n                /**\n          \n          \n            \n                 * Aggregate specified partition level statistics to local level statistics.\n          \n          \n            \n                 *\n          \n          \n            \n                 * @param keyMsg Aggregation key.\n          \n          \n            \n                 * @param stats Collection of all local partition level or local level statistics by specified key to aggregate.\n          \n          \n            \n                 * @return Local level aggregated statistics.\n          \n          \n            \n                 */\n          \n          \n            \n                public ObjectStatisticsImpl aggregateLocalStatistics(\n          \n          \n            \n                    StatisticsKeyMessage keyMsg,\n          \n          \n            \n                    Collection<? extends ObjectStatisticsImpl> stats\n          \n          \n            \n                );", "bodyHTML": "  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"42\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">    <span class=\"pl-k\">public</span> <span class=\"pl-k\">void</span> collectLocalObjectsStatisticsAsync(</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"43\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">        <span class=\"x x-first x-last\">    </span><span class=\"pl-c1\">UUID</span> reqId,</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"44\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">        <span class=\"x x-first x-last\">    </span><span class=\"pl-k\">Set&lt;<span class=\"pl-smi\">StatisticsKeyMessage</span>&gt;</span> keys,</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"45\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">        <span class=\"x x-first x-last\">    </span><span class=\"pl-k\">int</span>[] parts,</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"46\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">        <span class=\"x x-first x-last\">    </span><span class=\"pl-k\">Supplier&lt;<span class=\"pl-smi\">Boolean</span>&gt;</span> cancelled</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"47\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">    );</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"48\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\"></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"49\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">    <span class=\"pl-c\"><span class=\"pl-c\">/**</span></span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"50\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">     <span class=\"pl-k\">*</span> <span class=\"pl-k\">@param</span> statRepo <span class=\"pl-smi\">Statistics</span> repository.</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"51\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">     <span class=\"pl-k\">*/</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"52\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">    <span class=\"pl-k\">public</span> <span class=\"pl-k\">void</span> repository(<span class=\"pl-smi\">IgniteStatisticsRepository</span> statRepo);</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"53\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\"></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"54\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">    <span class=\"pl-c\"><span class=\"pl-c\">/**</span></span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"55\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">     <span class=\"pl-k\">*</span> <span class=\"pl-smi\">Aggregate</span> specified partition level statistics to local level statistics.</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"56\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">     <span class=\"pl-k\">*</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"57\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">     <span class=\"pl-k\">*</span> <span class=\"pl-k\">@param</span> keyMsg <span class=\"pl-smi\">Aggregation</span> key.</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"58\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">     <span class=\"pl-k\">*</span> <span class=\"pl-k\">@param</span> stats <span class=\"pl-smi\">Collection</span> of all local partition level or local level statistics by specified key to aggregate.</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"59\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">     <span class=\"pl-k\">*</span> <span class=\"pl-k\">@return</span> <span class=\"pl-smi\">Local</span> level aggregated statistics.</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"60\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">     <span class=\"pl-k\">*/</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"61\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">    <span class=\"pl-k\">public</span> <span class=\"pl-smi\">ObjectStatisticsImpl</span> aggregateLocalStatistics(</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"62\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">        <span class=\"x x-first x-last\">    </span><span class=\"pl-smi\">StatisticsKeyMessage</span> keyMsg,</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"63\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">        <span class=\"x x-first x-last\">    </span><span class=\"pl-k\">Collection&lt;? extends <span class=\"pl-smi\">ObjectStatisticsImpl</span>&gt;</span> stats</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"64\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">    );</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"42\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">    <span class=\"pl-k\">public</span> <span class=\"pl-k\">void</span> collectLocalObjectsStatisticsAsync(</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"43\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">        <span class=\"pl-c1\">UUID</span> reqId,</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"44\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">        <span class=\"pl-k\">Set&lt;<span class=\"pl-smi\">StatisticsKeyMessage</span>&gt;</span> keys,</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"45\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">        <span class=\"pl-k\">int</span>[] parts,</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"46\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">        <span class=\"pl-k\">Supplier&lt;<span class=\"pl-smi\">Boolean</span>&gt;</span> cancelled</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"47\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">    );</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"48\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\"></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"49\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">    <span class=\"pl-c\"><span class=\"pl-c\">/**</span></span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"50\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">     <span class=\"pl-k\">*</span> <span class=\"pl-k\">@param</span> statRepo <span class=\"pl-smi\">Statistics</span> repository.</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"51\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">     <span class=\"pl-k\">*/</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"52\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">    <span class=\"pl-k\">public</span> <span class=\"pl-k\">void</span> repository(<span class=\"pl-smi\">IgniteStatisticsRepository</span> statRepo);</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"53\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\"></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"54\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">    <span class=\"pl-c\"><span class=\"pl-c\">/**</span></span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"55\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">     <span class=\"pl-k\">*</span> <span class=\"pl-smi\">Aggregate</span> specified partition level statistics to local level statistics.</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"56\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">     <span class=\"pl-k\">*</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"57\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">     <span class=\"pl-k\">*</span> <span class=\"pl-k\">@param</span> keyMsg <span class=\"pl-smi\">Aggregation</span> key.</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"58\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">     <span class=\"pl-k\">*</span> <span class=\"pl-k\">@param</span> stats <span class=\"pl-smi\">Collection</span> of all local partition level or local level statistics by specified key to aggregate.</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"59\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">     <span class=\"pl-k\">*</span> <span class=\"pl-k\">@return</span> <span class=\"pl-smi\">Local</span> level aggregated statistics.</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"60\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">     <span class=\"pl-k\">*/</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"61\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">    <span class=\"pl-k\">public</span> <span class=\"pl-smi\">ObjectStatisticsImpl</span> aggregateLocalStatistics(</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"62\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">        <span class=\"pl-smi\">StatisticsKeyMessage</span> keyMsg,</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"63\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">        <span class=\"pl-k\">Collection&lt;? extends <span class=\"pl-smi\">ObjectStatisticsImpl</span>&gt;</span> stats</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"64\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">    );</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "korlov42", "createdAt": "2021-01-12T16:59:35Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGathering.java", "diffHunk": "@@ -0,0 +1,61 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+\n+import java.util.Collection;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.function.Supplier;\n+\n+/**\n+ * Collector which scan local data to gather statistics.\n+ */\n+public interface StatisticsGathering {\n+    /**\n+     * Collect local statistics by specified keys and partitions\n+     * and pass it to router to send in response to specified reqId.\n+     *\n+     * @param reqId Request id.\n+     * @param keys Keys to collect statistics by.\n+     * @param parts Partitions to collect statistics by.\n+     * @param cancelled Supplier to track cancelled state.\n+     */\n+    public void collectLocalObjectsStatisticsAsync(\n+            UUID reqId,\n+            Set<StatisticsKeyMessage> keys,\n+            int[] parts,\n+            Supplier<Boolean> cancelled\n+    );\n+\n+    /**\n+     * @param statRepo Statistics repository.\n+     */\n+    public void repository(IgniteStatisticsRepository statRepo);\n+\n+    /**\n+     * Aggregate specified partition level statistics to local level statistics.\n+     *\n+     * @param keyMsg Aggregation key.\n+     * @param stats Collection of all local partition level or local level statistics by specified key to aggregate.\n+     * @return Local level aggregated statistics.\n+     */\n+    public ObjectStatisticsImpl aggregateLocalStatistics(\n+            StatisticsKeyMessage keyMsg,\n+            Collection<? extends ObjectStatisticsImpl> stats\n+    );", "originalCommit": "b385286d37cb759a2a308a055b12f32c5c22a976", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ2NzcxMQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556467711", "bodyText": "commited", "author": "Berkof", "createdAt": "2021-01-13T11:57:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTkyODM4MQ=="}], "type": "inlineReview", "revised_code": {"commit": "17a54090bea4d97c122cf06d6be8e60177006519", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGathering.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGathering.java\nindex 75e67fb7d7d..3e27f889e30 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGathering.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGathering.java\n", "chunk": "@@ -55,7 +55,7 @@ public interface StatisticsGathering {\n      * @return Local level aggregated statistics.\n      */\n     public ObjectStatisticsImpl aggregateLocalStatistics(\n-            StatisticsKeyMessage keyMsg,\n-            Collection<? extends ObjectStatisticsImpl> stats\n+        StatisticsKeyMessage keyMsg,\n+        Collection<? extends ObjectStatisticsImpl> stats\n     );\n }\n", "next_change": {"commit": "48b736c4cf138d5db12978e2004c446e26e1f097", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGathering.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGathering.java\nindex 3e27f889e30..ba268caffc2 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGathering.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGathering.java\n", "chunk": "@@ -41,21 +40,4 @@ public interface StatisticsGathering {\n         int[] parts,\n         Supplier<Boolean> cancelled\n     );\n-\n-    /**\n-     * @param statRepo Statistics repository.\n-     */\n-    public void repository(IgniteStatisticsRepository statRepo);\n-\n-    /**\n-     * Aggregate specified partition level statistics to local level statistics.\n-     *\n-     * @param keyMsg Aggregation key.\n-     * @param stats Collection of all local partition level or local level statistics by specified key to aggregate.\n-     * @return Local level aggregated statistics.\n-     */\n-    public ObjectStatisticsImpl aggregateLocalStatistics(\n-        StatisticsKeyMessage keyMsg,\n-        Collection<? extends ObjectStatisticsImpl> stats\n-    );\n }\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTkzMTkzNQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r555931935", "body": "why it can't be just a class? do you plan to collect statistics in different ways?", "bodyText": "why it can't be just a class? do you plan to collect statistics in different ways?", "bodyHTML": "<p dir=\"auto\">why it can't be just a class? do you plan to collect statistics in different ways?</p>", "author": "korlov42", "createdAt": "2021-01-12T17:04:28Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGathering.java", "diffHunk": "@@ -0,0 +1,61 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+\n+import java.util.Collection;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.function.Supplier;\n+\n+/**\n+ * Collector which scan local data to gather statistics.\n+ */\n+public interface StatisticsGathering {", "originalCommit": "b385286d37cb759a2a308a055b12f32c5c22a976", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ2NzIwOA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r556467208", "bodyText": "No, just to improve lucidity of whole process. Sometimes there are different implementation, sometimes - only single, but each important part of the system has its own interface.", "author": "Berkof", "createdAt": "2021-01-13T11:56:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTkzMTkzNQ=="}], "type": "inlineReview", "revised_code": {"commit": "48b736c4cf138d5db12978e2004c446e26e1f097", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGathering.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGathering.java\nindex 75e67fb7d7d..ba268caffc2 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGathering.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGathering.java\n", "chunk": "@@ -17,7 +17,6 @@ package org.apache.ignite.internal.processors.query.stat;\n \n import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n \n-import java.util.Collection;\n import java.util.Set;\n import java.util.UUID;\n import java.util.function.Supplier;\n", "next_change": null}]}}, {"oid": "a353b8020779dcd0e5ed0f59f1b9c348a4ec8749", "url": "https://github.com/gridgain/gridgain/commit/a353b8020779dcd0e5ed0f59f1b9c348a4ec8749", "message": "GG-31094: triple2StatTarget, minor fixes", "committedDate": "2021-01-13T06:26:03Z", "type": "commit"}, {"oid": "ca1e579abf9a1382be63c0d4ba860f969041b986", "url": "https://github.com/gridgain/gridgain/commit/ca1e579abf9a1382be63c0d4ba860f969041b986", "message": "GG-31094: PR fixes", "committedDate": "2021-01-13T13:12:36Z", "type": "commit"}, {"oid": "17a54090bea4d97c122cf06d6be8e60177006519", "url": "https://github.com/gridgain/gridgain/commit/17a54090bea4d97c122cf06d6be8e60177006519", "message": "GG-31094: PR fixes", "committedDate": "2021-01-13T14:06:01Z", "type": "commit"}, {"oid": "efd6b5e9f1f91625c2e6106b4c75522dada68b46", "url": "https://github.com/gridgain/gridgain/commit/efd6b5e9f1f91625c2e6106b4c75522dada68b46", "message": "GG-31094: tests, PR fixes", "committedDate": "2021-01-14T10:58:17Z", "type": "commit"}, {"oid": "6e9f0d7af687bcdccb862b06f6e8754ae39dc5b7", "url": "https://github.com/gridgain/gridgain/commit/6e9f0d7af687bcdccb862b06f6e8754ae39dc5b7", "message": "GG-31094: test fixes, test for clearance and cancell gathering", "committedDate": "2021-01-14T13:39:19Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzM5MzU0OQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r557393549", "body": "```suggestion\r\n                throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", key.schema(), key.obj()));\r\n```", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            throw new IgniteCheckedException(String.format(\"Can't  find table %s.%s\", key.schema(), key.obj()));\n          \n          \n            \n                            throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", key.schema(), key.obj()));", "bodyHTML": "  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">                <span class=\"pl-k\">throw</span> <span class=\"pl-k\">new</span> <span class=\"pl-smi\">IgniteCheckedException</span>(<span class=\"pl-smi\">String</span><span class=\"pl-k\">.</span>format(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Can't <span class=\"x x-first x-last\"> </span>find table %s.%s<span class=\"pl-pds\">\"</span></span>, key<span class=\"pl-k\">.</span>schema(), key<span class=\"pl-k\">.</span>obj()));</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">                <span class=\"pl-k\">throw</span> <span class=\"pl-k\">new</span> <span class=\"pl-smi\">IgniteCheckedException</span>(<span class=\"pl-smi\">String</span><span class=\"pl-k\">.</span>format(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Can't find table %s.%s<span class=\"pl-pds\">\"</span></span>, key<span class=\"pl-k\">.</span>schema(), key<span class=\"pl-k\">.</span>obj()));</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "korlov42", "createdAt": "2021-01-14T13:27:54Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -0,0 +1,361 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.cluster.ClusterNode;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsClearRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsGatheringRequest;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsObjectData;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsPropagationMessage;\n+import org.apache.ignite.internal.util.typedef.F;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import java.util.stream.IntStream;\n+\n+/**\n+ * Utility methods to statistics messages generation.\n+ */\n+public class IgniteStatisticsHelper {\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** Local node id. */\n+    private final UUID locNodeId;\n+\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param locNodeId Local node id.\n+     * @param schemaMgr Schema manager.\n+     * @param logSupplier Ignite logger supplier to get logger from.\n+     */\n+    public IgniteStatisticsHelper(\n+        UUID locNodeId,\n+        SchemaManager schemaMgr,\n+        Function<Class<?>, IgniteLogger> logSupplier\n+    ) {\n+        this.locNodeId = locNodeId;\n+        this.schemaMgr = schemaMgr;\n+        this.log = logSupplier.apply(IgniteStatisticsHelper.class);\n+    }\n+\n+    /**\n+     * Get cache group context by specified statistics key.\n+     *\n+     * @param key Statistics key to get context by.\n+     * @return Cache group context for the given key.\n+     * @throws IgniteCheckedException If unable to find table by specified key.\n+     */\n+    public CacheGroupContext getGroupContext(StatisticsKeyMessage key) throws IgniteCheckedException {\n+        GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+        if (tbl == null)\n+            throw new IgniteCheckedException(String.format(\"Can't find object %s.%s\", key.schema(), key.obj()));\n+\n+        return tbl.cacheContext().group();\n+    }\n+\n+    /**\n+     * Extract groups of stats keys.\n+     *\n+     * @param keys Statistics key to extract groups from.\n+     * @return Map of <group ids> to <collection of keys in groups>\n+     * @throws IgniteCheckedException In case of lack some of specified objects.\n+     */\n+    protected Map<CacheGroupContext, Collection<StatisticsKeyMessage>> extractGroups(\n+        Collection<StatisticsKeyMessage> keys\n+    ) throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>(keys.size());\n+        for (StatisticsKeyMessage key : keys)\n+            res.computeIfAbsent(getGroupContext(key), k -> new ArrayList<>()).add(key);\n+\n+        return res;\n+    }\n+\n+    /**\n+     * Split specified keys to cache groups.\n+     *\n+     * @param keys Keys to split.\n+     * @return Map cache group to collection of keys in group.\n+     * @throws IgniteCheckedException If some of specified object won't be found in schema.\n+     */\n+    public Map<CacheGroupContext, Collection<StatisticsKeyMessage>> splitByGroups(\n+        Collection<StatisticsKeyMessage> keys\n+    ) throws IgniteCheckedException {\n+        Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>();\n+\n+        for (StatisticsKeyMessage key : keys) {\n+            GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+\n+            if (tbl == null)\n+                throw new IgniteCheckedException(String.format(\"Can't  find table %s.%s\", key.schema(), key.obj()));", "originalCommit": "efd6b5e9f1f91625c2e6106b4c75522dada68b46", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTU3NjE5Mg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r559576192", "bodyText": "fixed", "author": "Berkof", "createdAt": "2021-01-18T13:45:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzM5MzU0OQ=="}], "type": "inlineReview", "revised_code": {"commit": "23afcfd0b070646af24a1572418edbec1d4b5605", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex f53952e7a19..f4bc67303b2 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -120,7 +190,7 @@ public class IgniteStatisticsHelper {\n             GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n \n             if (tbl == null)\n-                throw new IgniteCheckedException(String.format(\"Can't  find table %s.%s\", key.schema(), key.obj()));\n+                throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", key.schema(), key.obj()));\n \n             res.computeIfAbsent(tbl.cacheContext().group(), k -> new ArrayList<>()).add(key);\n         }\n", "next_change": {"commit": "f5aafee54b1036c09d4944ca9bf0254f8bfd2b1e", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex f4bc67303b2..2aa9b4a1480 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -179,20 +179,15 @@ public class IgniteStatisticsHelper {\n      *\n      * @param keys Keys to split.\n      * @return Map cache group to collection of keys in group.\n-     * @throws IgniteCheckedException If some of specified object won't be found in schema.\n      */\n-    public Map<CacheGroupContext, Collection<StatisticsKeyMessage>> splitByGroups(\n-        Collection<StatisticsKeyMessage> keys\n-    ) throws IgniteCheckedException {\n+    public Map<CacheGroupContext, Collection<StatisticsKeyMessage>> splitByGroups(Collection<StatisticsKeyMessage> keys) {\n         Map<CacheGroupContext, Collection<StatisticsKeyMessage>> res = new HashMap<>();\n \n         for (StatisticsKeyMessage key : keys) {\n             GridH2Table tbl = schemaMgr.dataTable(key.schema(), key.obj());\n+            CacheGroupContext grp = (tbl == null) ? null : tbl.cacheContext().group();\n \n-            if (tbl == null)\n-                throw new IgniteCheckedException(String.format(\"Can't find table %s.%s\", key.schema(), key.obj()));\n-\n-            res.computeIfAbsent(tbl.cacheContext().group(), k -> new ArrayList<>()).add(key);\n+            res.computeIfAbsent(grp, k -> new ArrayList<>()).add(key);\n         }\n \n         return res;\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzQ0MDk4NQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r557440985", "body": "wrong comment", "bodyText": "wrong comment", "bodyHTML": "<p dir=\"auto\">wrong comment</p>", "author": "korlov42", "createdAt": "2021-01-14T14:37:57Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -59,6 +66,18 @@\n     /** Statistics repository. */\n     private final IgniteStatisticsRepository statsRepos;\n \n+    /** Current statistics collections tasks. */", "originalCommit": "6e9f0d7af687bcdccb862b06f6e8754ae39dc5b7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTU3NTUwMw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r559575503", "bodyText": "fixed", "author": "Berkof", "createdAt": "2021-01-18T13:43:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzQ0MDk4NQ=="}], "type": "inlineReview", "revised_code": {"commit": "23afcfd0b070646af24a1572418edbec1d4b5605", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 8f406905473..73f01a69ccb 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -66,7 +66,7 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n     /** Statistics repository. */\n     private final IgniteStatisticsRepository statsRepos;\n \n-    /** Current statistics collections tasks. */\n+    /** Ignite statistics helper. */\n     private final IgniteStatisticsHelper helper;\n \n     /** Statistics collector. */\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzQ2NjA2NA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r557466064", "body": "commented code ", "bodyText": "commented code", "bodyHTML": "<p dir=\"auto\">commented code</p>", "author": "korlov42", "createdAt": "2021-01-14T15:10:13Z", "path": "modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryTest.java", "diffHunk": "@@ -183,4 +205,61 @@ public void testRepositoryGlobal(IgniteStatisticsRepositoryImpl repo) {\n \n         assertEquals(2L, repo.getGlobalStatistics(K1).rowCount());\n     }\n+\n+    /**\n+     * Test object statistics add:\n+     *\n+     * 1) Add statistics with partially the same columns.\n+     * 2) Add statistics with new columns.\n+     * 3) Add statistics with the same columns.\n+     */\n+    @Test\n+    public void addTest() {\n+        // 1) Add statistics with partially the same columns.\n+        HashMap<String, ColumnStatistics> colStat1 = new HashMap<>();\n+        colStat1.put(\"col1\", cs1);\n+        colStat1.put(\"col2\", cs2);\n+\n+        HashMap<String, ColumnStatistics> colStat2 = new HashMap<>();\n+        colStat2.put(\"col2\", cs3);\n+        colStat2.put(\"col3\", cs4);\n+\n+        ObjectStatisticsImpl os1 = new ObjectStatisticsImpl(100, colStat1);\n+        ObjectStatisticsImpl os2 = new ObjectStatisticsImpl(101, colStat2);\n+\n+        ObjectStatisticsImpl sumStat1 = IgniteStatisticsRepositoryImpl.add(os1, os2);\n+\n+        assertEquals(101, sumStat1.rowCount());\n+        assertEquals(3, sumStat1.columnsStatistics().size());\n+        assertEquals(cs3, sumStat1.columnStatistics(\"col2\"));\n+\n+        // 2) Add statistics with new columns.\n+        ObjectStatisticsImpl os3 = new ObjectStatisticsImpl(101, Collections.singletonMap(\"col3\", cs3));\n+\n+        ObjectStatisticsImpl sumStat2 = IgniteStatisticsRepositoryImpl.add(os1, os3);\n+\n+        assertEquals(3, sumStat2.columnsStatistics().size());\n+\n+        // 3) Add statistics with the same columns.\n+        HashMap<String, ColumnStatistics> colStat3 = new HashMap<>();\n+        colStat3.put(\"col1\", cs3);\n+        colStat3.put(\"col2\", cs4);\n+\n+        ObjectStatisticsImpl os4 = new ObjectStatisticsImpl(99, colStat3);\n+\n+        ObjectStatisticsImpl sumStat3 = IgniteStatisticsRepositoryImpl.add(os1, os4);\n+\n+        assertEquals(99, sumStat3.rowCount());\n+        assertEquals(2, sumStat3.columnsStatistics().size());\n+        assertEquals(cs3, sumStat3.columnStatistics(\"col1\"));\n+\n+    }\n+\n+//    /**", "originalCommit": "6e9f0d7af687bcdccb862b06f6e8754ae39dc5b7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTU3NDg4OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r559574888", "bodyText": "fixed", "author": "Berkof", "createdAt": "2021-01-18T13:42:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzQ2NjA2NA=="}], "type": "inlineReview", "revised_code": {"commit": "48b736c4cf138d5db12978e2004c446e26e1f097", "changed_code": [{"header": "diff --git a/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryTest.java b/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryTest.java\nindex afc2202319d..5df801f62dd 100644\n--- a/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryTest.java\n+++ b/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryTest.java\n", "chunk": "@@ -252,14 +252,35 @@ public class IgniteStatisticsRepositoryTest extends StatisticsAbstractTest {\n         assertEquals(99, sumStat3.rowCount());\n         assertEquals(2, sumStat3.columnsStatistics().size());\n         assertEquals(cs3, sumStat3.columnStatistics(\"col1\"));\n-\n     }\n \n-//    /**\n-//     *\n-//     */\n-//    @Test\n-//    public void subtractTest() {\n-//\n-//    }\n+    /**\n+     * 1) Remove not existing column.\n+     * 2) Remove some columns.\n+     * 3) Remove all columns.\n+     */\n+    @Test\n+    public void subtractTest() {\n+        HashMap<String, ColumnStatistics> colStat1 = new HashMap<>();\n+        colStat1.put(\"col1\", cs1);\n+        colStat1.put(\"col2\", cs2);\n+\n+        ObjectStatisticsImpl os = new ObjectStatisticsImpl(100, colStat1);\n+\n+        // 1) Remove not existing column.\n+        ObjectStatisticsImpl os1 = IgniteStatisticsRepositoryImpl.subtract(os, new String[]{\"col0\"});\n+\n+        assertEquals(os, os1);\n+\n+        // 2) Remove some columns.\n+        ObjectStatisticsImpl os2 = IgniteStatisticsRepositoryImpl.subtract(os, new String[]{\"col1\"});\n+\n+        assertEquals(1, os2.columnsStatistics().size());\n+        assertEquals(cs2, os2.columnStatistics(\"col2\"));\n+\n+        // 3) Remove all columns.\n+        ObjectStatisticsImpl os3 = IgniteStatisticsRepositoryImpl.subtract(os, new String[]{\"col2\",\"col1\"});\n+\n+        assertTrue(os3.columnsStatistics().isEmpty());\n+    }\n }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzQ5NDQzMA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r557494430", "body": "empty line\r\n", "bodyText": "empty line", "bodyHTML": "<p dir=\"auto\">empty line</p>", "author": "korlov42", "createdAt": "2021-01-14T15:47:39Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringImpl.java", "diffHunk": "@@ -0,0 +1,373 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.managers.discovery.GridDiscoveryManager;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.cache.GridCacheContext;\n+import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtLocalPartition;\n+import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionTopology;\n+import org.apache.ignite.internal.processors.cache.persistence.CacheDataRow;\n+import org.apache.ignite.internal.processors.query.GridQueryProcessor;\n+import org.apache.ignite.internal.processors.query.GridQueryTypeDescriptor;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.h2.opt.H2Row;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.util.typedef.CA;\n+import org.apache.ignite.internal.util.typedef.F;\n+import org.apache.ignite.internal.util.typedef.internal.CU;\n+import org.apache.ignite.thread.IgniteThreadPoolExecutor;\n+import org.gridgain.internal.h2.table.Column;\n+import org.jetbrains.annotations.Nullable;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionState.OWNING;\n+\n+/**\n+ * Implementation of statistic collector.\n+ */\n+public class StatisticsGatheringImpl implements StatisticsGathering {\n+    /** Canceled check interval. */\n+    private static final int CANCELLED_CHECK_INTERVAL = 100;\n+    /** Logger. */", "originalCommit": "6e9f0d7af687bcdccb862b06f6e8754ae39dc5b7", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "48b736c4cf138d5db12978e2004c446e26e1f097", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringImpl.java\nindex 702c5574dfd..869fefdf5e8 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringImpl.java\n", "chunk": "@@ -59,6 +55,7 @@ import static org.apache.ignite.internal.processors.cache.distributed.dht.topolo\n public class StatisticsGatheringImpl implements StatisticsGathering {\n     /** Canceled check interval. */\n     private static final int CANCELLED_CHECK_INTERVAL = 100;\n+\n     /** Logger. */\n     private final IgniteLogger log;\n \n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzQ5NTI5OQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r557495299", "body": "stale param", "bodyText": "stale param", "bodyHTML": "<p dir=\"auto\">stale param</p>", "author": "korlov42", "createdAt": "2021-01-14T15:48:45Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringImpl.java", "diffHunk": "@@ -0,0 +1,373 @@\n+/*\n+ * Copyright 2020 GridGain Systems, Inc. and Contributors.\n+ *\n+ * Licensed under the GridGain Community Edition License (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.gridgain.com/products/software/community-edition/gridgain-community-edition-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.ignite.internal.processors.query.stat;\n+\n+import org.apache.ignite.IgniteCheckedException;\n+import org.apache.ignite.IgniteLogger;\n+import org.apache.ignite.internal.managers.discovery.GridDiscoveryManager;\n+import org.apache.ignite.internal.processors.affinity.AffinityTopologyVersion;\n+import org.apache.ignite.internal.processors.cache.CacheGroupContext;\n+import org.apache.ignite.internal.processors.cache.GridCacheContext;\n+import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtLocalPartition;\n+import org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionTopology;\n+import org.apache.ignite.internal.processors.cache.persistence.CacheDataRow;\n+import org.apache.ignite.internal.processors.query.GridQueryProcessor;\n+import org.apache.ignite.internal.processors.query.GridQueryTypeDescriptor;\n+import org.apache.ignite.internal.processors.query.h2.SchemaManager;\n+import org.apache.ignite.internal.processors.query.h2.opt.GridH2Table;\n+import org.apache.ignite.internal.processors.query.h2.opt.H2Row;\n+import org.apache.ignite.internal.processors.query.stat.messages.StatisticsKeyMessage;\n+import org.apache.ignite.internal.util.typedef.CA;\n+import org.apache.ignite.internal.util.typedef.F;\n+import org.apache.ignite.internal.util.typedef.internal.CU;\n+import org.apache.ignite.thread.IgniteThreadPoolExecutor;\n+import org.gridgain.internal.h2.table.Column;\n+import org.jetbrains.annotations.Nullable;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.function.Function;\n+import java.util.function.Supplier;\n+import java.util.stream.Collectors;\n+\n+import static org.apache.ignite.internal.processors.cache.distributed.dht.topology.GridDhtPartitionState.OWNING;\n+\n+/**\n+ * Implementation of statistic collector.\n+ */\n+public class StatisticsGatheringImpl implements StatisticsGathering {\n+    /** Canceled check interval. */\n+    private static final int CANCELLED_CHECK_INTERVAL = 100;\n+    /** Logger. */\n+    private final IgniteLogger log;\n+\n+    /** Schema manager. */\n+    private final SchemaManager schemaMgr;\n+\n+    /** Discovery manager. */\n+    private final GridDiscoveryManager discoMgr;\n+\n+    /** Query processor */\n+    private final GridQueryProcessor qryProcessor;\n+\n+    /** Ignite statistics repository. */\n+    private IgniteStatisticsRepository statRepo;\n+\n+    /** Statistics crawler. */\n+    private final StatisticsGatheringRequestCrawler statCrawler;\n+\n+    /** Ignite Thread pool executor to do statistics collection tasks. */\n+    private final IgniteThreadPoolExecutor gatMgmtPool;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param schemaMgr Schema manager.\n+     * @param discoMgr Discovery manager.\n+     * @param qryProcessor Query processor.\n+     * @param cacheProcessor Grid cache processor.", "originalCommit": "6e9f0d7af687bcdccb862b06f6e8754ae39dc5b7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTU3NDQ5NQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r559574495", "bodyText": "removed", "author": "Berkof", "createdAt": "2021-01-18T13:42:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzQ5NTI5OQ=="}], "type": "inlineReview", "revised_code": {"commit": "48b736c4cf138d5db12978e2004c446e26e1f097", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringImpl.java\nindex 702c5574dfd..869fefdf5e8 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringImpl.java\n", "chunk": "@@ -86,6 +83,7 @@ public class StatisticsGatheringImpl implements StatisticsGathering {\n      * @param schemaMgr Schema manager.\n      * @param discoMgr Discovery manager.\n      * @param qryProcessor Query processor.\n+     * @param repo IgniteStatisticsRepository.\n      * @param cacheProcessor Grid cache processor.\n      * @param statCrawler Statistics request crawler.\n      * @param gatMgmtPool Thread pool to gather statistics in.\n", "next_change": {"commit": "23afcfd0b070646af24a1572418edbec1d4b5605", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringImpl.java\nindex 869fefdf5e8..36c8a347fe3 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringImpl.java\n", "chunk": "@@ -84,7 +84,6 @@ public class StatisticsGatheringImpl implements StatisticsGathering {\n      * @param discoMgr Discovery manager.\n      * @param qryProcessor Query processor.\n      * @param repo IgniteStatisticsRepository.\n-     * @param cacheProcessor Grid cache processor.\n      * @param statCrawler Statistics request crawler.\n      * @param gatMgmtPool Thread pool to gather statistics in.\n      * @param logSupplier Log supplier function.\n", "next_change": null}]}}]}}, {"oid": "48b736c4cf138d5db12978e2004c446e26e1f097", "url": "https://github.com/gridgain/gridgain/commit/48b736c4cf138d5db12978e2004c446e26e1f097", "message": "GG-31094: minor refactoring, codestyle, statistics version in metastore and collection on caches with lost partitions.", "committedDate": "2021-01-18T13:30:47Z", "type": "commit"}, {"oid": "a23eebc202da08a14cf888988d43eb62231d1189", "url": "https://github.com/gridgain/gridgain/commit/a23eebc202da08a14cf888988d43eb62231d1189", "message": "Merge remote-tracking branch 'gridgain-ce/master' into gg-31094", "committedDate": "2021-01-18T13:33:19Z", "type": "commit"}, {"oid": "23afcfd0b070646af24a1572418edbec1d4b5605", "url": "https://github.com/gridgain/gridgain/commit/23afcfd0b070646af24a1572418edbec1d4b5605", "message": "GG-31094: PR small fixes", "committedDate": "2021-01-18T13:52:49Z", "type": "commit"}, {"oid": "c4b949b7803bbb0ecd1ccc1bc840befc5fe713ff", "url": "https://github.com/gridgain/gridgain/commit/c4b949b7803bbb0ecd1ccc1bc840befc5fe713ff", "message": "GG-31094: tests fixes", "committedDate": "2021-01-19T09:40:33Z", "type": "commit"}, {"oid": "390bfd8e824301929df7b139844e3b40bd216f6d", "url": "https://github.com/gridgain/gridgain/commit/390bfd8e824301929df7b139844e3b40bd216f6d", "message": "Merge remote-tracking branch 'gridgain-ce/master' into gg-31094", "committedDate": "2021-01-19T09:46:53Z", "type": "commit"}, {"oid": "7f29d66b8a36ce398400e761327f382e93ad2957", "url": "https://github.com/gridgain/gridgain/commit/7f29d66b8a36ce398400e761327f382e93ad2957", "message": "GG-31094: licences", "committedDate": "2021-01-19T11:26:19Z", "type": "commit"}, {"oid": "fe2051cb06a7d4423864c145d20b447da276320e", "url": "https://github.com/gridgain/gridgain/commit/fe2051cb06a7d4423864c145d20b447da276320e", "message": "GG-31094: licences", "committedDate": "2021-01-19T11:30:22Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA2OTcyMQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r560069721", "body": "```suggestion\r\n     * Return map cache group to corresponding stats keys.\r\n```", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                 * Return map cache group to corrsponding stats keys.\n          \n          \n            \n                 * Return map cache group to corresponding stats keys.", "bodyHTML": "  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">     <span class=\"pl-k\">*</span> <span class=\"pl-smi\">Return</span> map cache group to <span class=\"x x-first x-last\">corrsponding</span> stats keys.</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">     <span class=\"pl-k\">*</span> <span class=\"pl-smi\">Return</span> map cache group to <span class=\"x x-first x-last\">corresponding</span> stats keys.</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "korlov42", "createdAt": "2021-01-19T10:24:29Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java", "diffHunk": "@@ -88,13 +158,13 @@ public CacheGroupContext getGroupContext(StatisticsKeyMessage key) throws Ignite\n     }\n \n     /**\n-     * Extract groups of stats keys.\n+     * Return map cache group to corrsponding stats keys.", "originalCommit": "390bfd8e824301929df7b139844e3b40bd216f6d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MTY2MzY0NA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r561663644", "bodyText": "fixed", "author": "Berkof", "createdAt": "2021-01-21T07:51:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA2OTcyMQ=="}], "type": "inlineReview", "revised_code": {"commit": "1eb42d79754cf530e8ede9439c69b74635dd022f", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\nindex f4bc67303b2..87140ca3328 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsHelper.java\n", "chunk": "@@ -158,7 +158,7 @@ public class IgniteStatisticsHelper {\n     }\n \n     /**\n-     * Return map cache group to corrsponding stats keys.\n+     * Return map cache group to corresponding stats keys.\n      *\n      * @param keys Statistics key to map.\n      * @return Map of <group ids> to <collection of keys in groups>\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA3Mjc2OQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r560072769", "body": "sout", "bodyText": "sout", "bodyHTML": "<p dir=\"auto\">sout</p>", "author": "korlov42", "createdAt": "2021-01-19T10:29:10Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java", "diffHunk": "@@ -85,6 +85,7 @@ public IgniteStatisticsRepositoryImpl(\n             res.add(newStat);\n             store.saveLocalPartitionStatistics(key, newStat);\n         }\n+        System.out.println(statistics.size() + \" partitions saved!\");", "originalCommit": "390bfd8e824301929df7b139844e3b40bd216f6d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "d0e4fd5b8e4e6602c72286250d6c61bbbb189fb0", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\nindex a869c30ad41..3a2faf40a07 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsRepositoryImpl.java\n", "chunk": "@@ -85,7 +85,7 @@ public class IgniteStatisticsRepositoryImpl implements IgniteStatisticsRepositor\n             res.add(newStat);\n             store.saveLocalPartitionStatistics(key, newStat);\n         }\n-        System.out.println(statistics.size() + \" partitions saved!\");\n+\n         return res;\n     }\n \n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA3MzkyMQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r560073921", "body": "```suggestion\r\n     * Receive gathering response and match it to request, then process these couple.\r\n```", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                 * Receive gathering response and math it to request, then process these couple.\n          \n          \n            \n                 * Receive gathering response and match it to request, then process these couple.", "bodyHTML": "  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">     <span class=\"pl-k\">*</span> <span class=\"pl-smi\">Receive</span> gathering response and <span class=\"x x-first x-last\">math</span> it to request, then process these couple.</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">     <span class=\"pl-k\">*</span> <span class=\"pl-smi\">Receive</span> gathering response and <span class=\"x x-first x-last\">match</span> it to request, then process these couple.</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "korlov42", "createdAt": "2021-01-19T10:31:06Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java", "diffHunk": "@@ -412,7 +421,7 @@ public void sendClearStatistics(Collection<StatisticsKeyMessage> keys) {\n     }\n \n     /**\n-     * Receive and handle statistics gathering response message as response for collection request.\n+     * Receive gathering response and math it to request, then process these couple.", "originalCommit": "390bfd8e824301929df7b139844e3b40bd216f6d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MTY2MzkxNw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r561663917", "bodyText": "fixed", "author": "Berkof", "createdAt": "2021-01-21T07:52:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDA3MzkyMQ=="}], "type": "inlineReview", "revised_code": {"commit": "1eb42d79754cf530e8ede9439c69b74635dd022f", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java\nindex f0b456e06b7..5d3319cfd09 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/StatisticsGatheringRequestCrawlerImpl.java\n", "chunk": "@@ -421,7 +447,7 @@ public class StatisticsGatheringRequestCrawlerImpl implements StatisticsGatherin\n     }\n \n     /**\n-     * Receive gathering response and math it to request, then process these couple.\n+     * Receive gathering response and match it to request, then process these couple.\n      *\n      * @param nodeId Sender node id.\n      * @param msg Statistics propagation message with partitions statistics to handle.\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEzNDExOA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r560134118", "body": "lockPool", "bodyText": "lockPool", "bodyHTML": "<p dir=\"auto\">lockPool</p>", "author": "korlov42", "createdAt": "2021-01-19T12:15:06Z", "path": "modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/StatisticsAbstractTest.java", "diffHunk": "@@ -307,4 +326,89 @@ protected ObjectPartitionStatisticsImpl getPartitionStatistics(int partId) {\n         return new ObjectPartitionStatisticsImpl(partId, true, 0, 0,\n                 Collections.singletonMap(\"col1\", colStatistics));\n     }\n+\n+    /**\n+     * Check that all statistics collections related tasks is empty in specified node.\n+     *\n+     * @param nodeIdx Node idx.\n+     * @throws Exception In case of errors.\n+     */\n+    protected void checkStatTasksEmpty(int nodeIdx) throws Exception {\n+        IgniteStatisticsManagerImpl statMgr = (IgniteStatisticsManagerImpl)grid(nodeIdx).context().query().getIndexing()\n+            .statsManager();\n+        StatisticsGatheringRequestCrawlerImpl crawler = readField(statMgr, \"statCrawler\");\n+\n+        ConcurrentMap<UUID, StatisticsAddrRequest<StatisticsGatheringRequest>> remainingRequests = readField(crawler,\n+            \"remainingRequests\");\n+\n+        assertTrue(remainingRequests.isEmpty());\n+\n+        IgniteThreadPoolExecutor pool = readField(crawler, \"msgMgmtPool\");\n+\n+        assertTrue(pool.getQueue().isEmpty());\n+\n+        Map<UUID, StatisticsGatheringContext> currColls = readField(statMgr, \"currColls\");\n+\n+        assertTrue(currColls.isEmpty());\n+    }\n+\n+    /**\n+     * Get nodes StatisticsGatheringRequestCrawlerImpl.msgMgmtPool lock.\n+     * Put additional task into it and return lock to complete these task.\n+     *\n+     * @param nodeIdx Node idx.\n+     * @return Lock to complete pool task and allow it to process next one.\n+     */\n+    protected Lock nodeMsgsLock(int nodeIdx) throws Exception {\n+        IgniteStatisticsManagerImpl statMgr = (IgniteStatisticsManagerImpl)grid(nodeIdx).context().query().getIndexing()\n+            .statsManager();\n+        StatisticsGatheringRequestCrawlerImpl crawler = readField(statMgr, \"statCrawler\");\n+        IgniteThreadPoolExecutor pool = readField(crawler, \"msgMgmtPool\");\n+        Lock res = new ReentrantLock();", "originalCommit": "390bfd8e824301929df7b139844e3b40bd216f6d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MTY5OTAxNA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r561699014", "bodyText": "fixed", "author": "Berkof", "createdAt": "2021-01-21T08:52:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEzNDExOA=="}], "type": "inlineReview", "revised_code": {"commit": "33170812024f6c4d321f85287fea0b6c3abdb9e5", "changed_code": [{"header": "diff --git a/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/StatisticsAbstractTest.java b/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/StatisticsAbstractTest.java\nindex 89e72b42fe4..4a714ca5bcc 100644\n--- a/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/StatisticsAbstractTest.java\n+++ b/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/StatisticsAbstractTest.java\n", "chunk": "@@ -367,6 +367,7 @@ public abstract class StatisticsAbstractTest extends GridCommonAbstractTest {\n         Lock res = new ReentrantLock();\n         res.lock();\n         pool.submit(res::lock);\n+\n         return res;\n     }\n \n", "next_change": {"commit": "1eb42d79754cf530e8ede9439c69b74635dd022f", "changed_code": [{"header": "diff --git a/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/StatisticsAbstractTest.java b/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/StatisticsAbstractTest.java\nindex 4a714ca5bcc..4f30e495214 100644\n--- a/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/StatisticsAbstractTest.java\n+++ b/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/StatisticsAbstractTest.java\n", "chunk": "@@ -362,8 +363,7 @@ public abstract class StatisticsAbstractTest extends GridCommonAbstractTest {\n     protected Lock nodeMsgsLock(int nodeIdx) throws Exception {\n         IgniteStatisticsManagerImpl statMgr = (IgniteStatisticsManagerImpl)grid(nodeIdx).context().query().getIndexing()\n             .statsManager();\n-        StatisticsGatheringRequestCrawlerImpl crawler = readField(statMgr, \"statCrawler\");\n-        IgniteThreadPoolExecutor pool = readField(crawler, \"msgMgmtPool\");\n+        IgniteThreadPoolExecutor pool = GridTestUtils.getFieldValue(statMgr, \"statCrawler\", \"msgMgmtPool\");\n         Lock res = new ReentrantLock();\n         res.lock();\n         pool.submit(res::lock);\n", "next_change": {"commit": "f5aafee54b1036c09d4944ca9bf0254f8bfd2b1e", "changed_code": [{"header": "diff --git a/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/StatisticsAbstractTest.java b/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/StatisticsAbstractTest.java\nindex 4f30e495214..73db5e422b9 100644\n--- a/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/StatisticsAbstractTest.java\n+++ b/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/StatisticsAbstractTest.java\n", "chunk": "@@ -364,11 +363,8 @@ public abstract class StatisticsAbstractTest extends GridCommonAbstractTest {\n         IgniteStatisticsManagerImpl statMgr = (IgniteStatisticsManagerImpl)grid(nodeIdx).context().query().getIndexing()\n             .statsManager();\n         IgniteThreadPoolExecutor pool = GridTestUtils.getFieldValue(statMgr, \"statCrawler\", \"msgMgmtPool\");\n-        Lock res = new ReentrantLock();\n-        res.lock();\n-        pool.submit(res::lock);\n \n-        return res;\n+        return lockPool(pool);\n     }\n \n     /**\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEzNDg2Mg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r560134862", "body": "GridTestUtils#getFieldValue(Object obj, String... fieldNames)", "bodyText": "GridTestUtils#getFieldValue(Object obj, String... fieldNames)", "bodyHTML": "<p dir=\"auto\">GridTestUtils#getFieldValue(Object obj, String... fieldNames)</p>", "author": "korlov42", "createdAt": "2021-01-19T12:16:31Z", "path": "modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/StatisticsAbstractTest.java", "diffHunk": "@@ -307,4 +326,89 @@ protected ObjectPartitionStatisticsImpl getPartitionStatistics(int partId) {\n         return new ObjectPartitionStatisticsImpl(partId, true, 0, 0,\n                 Collections.singletonMap(\"col1\", colStatistics));\n     }\n+\n+    /**\n+     * Check that all statistics collections related tasks is empty in specified node.\n+     *\n+     * @param nodeIdx Node idx.\n+     * @throws Exception In case of errors.\n+     */\n+    protected void checkStatTasksEmpty(int nodeIdx) throws Exception {\n+        IgniteStatisticsManagerImpl statMgr = (IgniteStatisticsManagerImpl)grid(nodeIdx).context().query().getIndexing()\n+            .statsManager();\n+        StatisticsGatheringRequestCrawlerImpl crawler = readField(statMgr, \"statCrawler\");\n+\n+        ConcurrentMap<UUID, StatisticsAddrRequest<StatisticsGatheringRequest>> remainingRequests = readField(crawler,\n+            \"remainingRequests\");\n+\n+        assertTrue(remainingRequests.isEmpty());\n+\n+        IgniteThreadPoolExecutor pool = readField(crawler, \"msgMgmtPool\");\n+\n+        assertTrue(pool.getQueue().isEmpty());\n+\n+        Map<UUID, StatisticsGatheringContext> currColls = readField(statMgr, \"currColls\");\n+\n+        assertTrue(currColls.isEmpty());\n+    }\n+\n+    /**\n+     * Get nodes StatisticsGatheringRequestCrawlerImpl.msgMgmtPool lock.\n+     * Put additional task into it and return lock to complete these task.\n+     *\n+     * @param nodeIdx Node idx.\n+     * @return Lock to complete pool task and allow it to process next one.\n+     */\n+    protected Lock nodeMsgsLock(int nodeIdx) throws Exception {\n+        IgniteStatisticsManagerImpl statMgr = (IgniteStatisticsManagerImpl)grid(nodeIdx).context().query().getIndexing()\n+            .statsManager();\n+        StatisticsGatheringRequestCrawlerImpl crawler = readField(statMgr, \"statCrawler\");\n+        IgniteThreadPoolExecutor pool = readField(crawler, \"msgMgmtPool\");\n+        Lock res = new ReentrantLock();\n+        res.lock();\n+        pool.submit(res::lock);\n+        return res;\n+    }\n+\n+    /**\n+     * Get nodes StatisticsGatheringImpl.gatMgmtPool lock.\n+     * Put additional task into it and return lock to complete these task.\n+     *\n+     * @param nodeIdx Node idx.\n+     * @return Lock to complete pool task and allow it to process next one.\n+     */\n+    protected Lock nodeGathLock(int nodeIdx) throws Exception {\n+        IgniteStatisticsManagerImpl statMgr = (IgniteStatisticsManagerImpl)grid(nodeIdx).context().query().getIndexing()\n+            .statsManager();\n+        StatisticsGatheringImpl crawler = readField(statMgr, \"statGathering\");\n+        IgniteThreadPoolExecutor pool = readField(crawler, \"gatMgmtPool\");\n+        return lockPool(pool);\n+    }\n+\n+    /**\n+     * Lock specified pool with task, waiting for lock release.\n+     *\n+     * @param pool Pool to block.\n+     * @return Lock.\n+     */\n+    private Lock lockPool(IgniteThreadPoolExecutor pool) {\n+        Lock res = new ReentrantLock();\n+        res.lock();\n+        pool.submit(res::lock);\n+        return res;\n+    }\n+\n+    /**\n+     * Read object field value by name.\n+     *\n+     * @param obj Object to read value from.\n+     * @param field Field name.\n+     * @return Field value.\n+     * @throws Exception If case if object doesn't contains specified field.\n+     */\n+    protected <T> T readField(Object obj, String field) throws Exception {", "originalCommit": "390bfd8e824301929df7b139844e3b40bd216f6d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MTY3NTg1OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r561675858", "bodyText": "Good point. replaced.", "author": "Berkof", "createdAt": "2021-01-21T08:14:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEzNDg2Mg=="}], "type": "inlineReview", "revised_code": {"commit": "33170812024f6c4d321f85287fea0b6c3abdb9e5", "changed_code": [{"header": "diff --git a/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/StatisticsAbstractTest.java b/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/StatisticsAbstractTest.java\nindex 89e72b42fe4..4a714ca5bcc 100644\n--- a/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/StatisticsAbstractTest.java\n+++ b/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/StatisticsAbstractTest.java\n", "chunk": "@@ -409,6 +412,7 @@ public abstract class StatisticsAbstractTest extends GridCommonAbstractTest {\n     protected <T> T readField(Object obj, String field) throws Exception {\n         Field reader = obj.getClass().getDeclaredField(field);\n         reader.setAccessible(true);\n+\n         return (T)reader.get(obj);\n     }\n }\n", "next_change": {"commit": "1eb42d79754cf530e8ede9439c69b74635dd022f", "changed_code": [{"header": "diff --git a/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/StatisticsAbstractTest.java b/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/StatisticsAbstractTest.java\nindex 4a714ca5bcc..4f30e495214 100644\n--- a/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/StatisticsAbstractTest.java\n+++ b/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/stat/StatisticsAbstractTest.java\n", "chunk": "@@ -400,19 +399,4 @@ public abstract class StatisticsAbstractTest extends GridCommonAbstractTest {\n \n         return res;\n     }\n-\n-    /**\n-     * Read object field value by name.\n-     *\n-     * @param obj Object to read value from.\n-     * @param field Field name.\n-     * @return Field value.\n-     * @throws Exception If case if object doesn't contains specified field.\n-     */\n-    protected <T> T readField(Object obj, String field) throws Exception {\n-        Field reader = obj.getClass().getDeclaredField(field);\n-        reader.setAccessible(true);\n-\n-        return (T)reader.get(obj);\n-    }\n }\n", "next_change": null}]}}]}}, {"oid": "d0e4fd5b8e4e6602c72286250d6c61bbbb189fb0", "url": "https://github.com/gridgain/gridgain/commit/d0e4fd5b8e4e6602c72286250d6c61bbbb189fb0", "message": "GG-31094: gathering tests, small refactorings", "committedDate": "2021-01-20T08:29:24Z", "type": "commit"}, {"oid": "33170812024f6c4d321f85287fea0b6c3abdb9e5", "url": "https://github.com/gridgain/gridgain/commit/33170812024f6c4d321f85287fea0b6c3abdb9e5", "message": "GG-31094: codestyle refactorings, batch gathering test.", "committedDate": "2021-01-20T11:21:27Z", "type": "commit"}, {"oid": "84c79eae65b6bf0fa8b36ad1c4fa09ca8d87cb6c", "url": "https://github.com/gridgain/gridgain/commit/84c79eae65b6bf0fa8b36ad1c4fa09ca8d87cb6c", "message": "GG-31094: checkstyle", "committedDate": "2021-01-20T11:45:58Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDkxMTQ3NQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r560911475", "body": "it's better to complete a future with this exception", "bodyText": "it's better to complete a future with this exception", "bodyHTML": "<p dir=\"auto\">it's better to complete a future with this exception</p>", "author": "korlov42", "createdAt": "2021-01-20T12:08:35Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -255,13 +261,15 @@ public void gatherLocalObjectStatisticsAsync(\n         StatisticsGatheringContext gCtx = currColls.computeIfAbsent(gatId, k ->\n             new StatisticsGatheringContext(gatId, keysSet, partsCnt));\n \n-        statGathering.collectLocalObjectsStatisticsAsync(reqId, keysSet, parts, () -> gCtx.doneFut().isCancelled());\n+        statGathering.collectLocalObjectsStatisticsAsync(reqId, keysSet, parts, () -> gCtx.doneFuture().isCancelled());\n     }\n \n     /** {@inheritDoc} */\n-    @Override public StatisticsGatheringFuture<Map<StatisticsTarget, ObjectStatistics>>[] collectObjectStatisticsAsync(\n+    @Override public StatisticsGatheringFuture<Map<StatisticsTarget, ObjectStatistics>>[] gatherObjectStatisticsAsync(\n         StatisticsTarget... keys\n     ) throws IgniteCheckedException {\n+        checkSupport(\"collect statistics async\");", "originalCommit": "84c79eae65b6bf0fa8b36ad1c4fa09ca8d87cb6c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MTY3OTIyMw==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r561679223", "bodyText": "But sometimes we'll throw exception while sometimes (as you suggest) - put the same error into the array of futures? And we still can produce IgniteChechedException while starting the task if there are no such object in scheme (now).\nFrom this point of view - what if we'll throw IgniteChechedException here if there are some node(s) without such future, but return errors about object lacks in related to such object future?", "author": "Berkof", "createdAt": "2021-01-21T08:20:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDkxMTQ3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MTgwNDI3OA==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r561804278", "bodyText": "fixed", "author": "Berkof", "createdAt": "2021-01-21T11:31:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDkxMTQ3NQ=="}], "type": "inlineReview", "revised_code": {"commit": "f5aafee54b1036c09d4944ca9bf0254f8bfd2b1e", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 5011b1a87a5..4df3ed6f1e0 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -267,14 +266,23 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n     /** {@inheritDoc} */\n     @Override public StatisticsGatheringFuture<Map<StatisticsTarget, ObjectStatistics>>[] gatherObjectStatisticsAsync(\n         StatisticsTarget... keys\n-    ) throws IgniteCheckedException {\n-        checkSupport(\"collect statistics async\");\n+    ) {\n+\n+        Set<StatisticsKeyMessage> keysMsg = Arrays.stream(keys).map(StatisticsUtils::statisticsKeyMessage)\n+            .collect(Collectors.toSet());\n \n-        Set<StatisticsKeyMessage> keysMsg = Arrays.stream(keys).map(\n-            t -> new StatisticsKeyMessage(t.schema(), t.obj(), Arrays.asList(t.columns()))).collect(Collectors.toSet());\n         Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpsKeys = helper.splitByGroups(keysMsg);\n \n-        List<StatisticsGatheringFuture<Void>> res = new ArrayList<>();\n+        if (!IgniteFeatures.allNodesSupport(ctx, IgniteFeatures.STATISTICS_COLLECTION, IgniteDiscoverySpi.SRV_NODES)) {\n+            return grpsKeys.entrySet().stream().map(\n+                grpKeys -> new StatisticsGatheringFutureAdapter(UUID.randomUUID(),\n+                    grpKeys.getValue().stream().map(StatisticsUtils::statisticsTarget).toArray(StatisticsTarget[]::new)))\n+                .toArray(StatisticsGatheringFuture[]::new);\n+        }\n+\n+        Collection<StatisticsKeyMessage> notFoundKeys = grpsKeys.remove(null);\n+\n+        List<StatisticsGatheringFuture<Map<StatisticsTarget, ObjectStatistics>>> res = new ArrayList<>();\n \n         for (Map.Entry<CacheGroupContext, Collection<StatisticsKeyMessage>> grpKeys : grpsKeys.entrySet()) {\n             int parts = grpKeys.getKey().topology().partitions();\n", "next_change": null}]}}, {"oid": "1eb42d79754cf530e8ede9439c69b74635dd022f", "url": "https://github.com/gridgain/gridgain/commit/1eb42d79754cf530e8ede9439c69b74635dd022f", "message": "GG-31094: GridTestUtils.getFieldValue usage", "committedDate": "2021-01-21T08:37:47Z", "type": "commit"}, {"oid": "f5aafee54b1036c09d4944ca9bf0254f8bfd2b1e", "url": "https://github.com/gridgain/gridgain/commit/f5aafee54b1036c09d4944ca9bf0254f8bfd2b1e", "message": "GG-31094: remove Exception from Async method, add StatisticsTarget array to the gathering future.", "committedDate": "2021-01-21T11:11:26Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MTk4Mjk4Mg==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r561982982", "body": "it's better to check this with `checkStatisticsSupport()`, but slightly modify it to take param to decide wether an exception should be thrown or not (`true` by default)\r\n\r\n```\r\n void checkStatisticsSupport(String op) {\r\n     checkStatisticsSupport(op, true)\r\n }\r\n\r\nboolean checkStatisticsSupport(String op, boolean shouldThrow) {\r\n     if (<support>)\r\n         return true;\r\n     \r\n     if (shouldThrow)\r\n         throw new Ex();\r\n\r\n     return false;\r\n } \r\n```", "bodyText": "it's better to check this with checkStatisticsSupport(), but slightly modify it to take param to decide wether an exception should be thrown or not (true by default)\n void checkStatisticsSupport(String op) {\n     checkStatisticsSupport(op, true)\n }\n\nboolean checkStatisticsSupport(String op, boolean shouldThrow) {\n     if (<support>)\n         return true;\n     \n     if (shouldThrow)\n         throw new Ex();\n\n     return false;\n }", "bodyHTML": "<p dir=\"auto\">it's better to check this with <code>checkStatisticsSupport()</code>, but slightly modify it to take param to decide wether an exception should be thrown or not (<code>true</code> by default)</p>\n<div class=\"snippet-clipboard-content position-relative overflow-auto\" data-snippet-clipboard-copy-content=\" void checkStatisticsSupport(String op) {\n     checkStatisticsSupport(op, true)\n }\n\nboolean checkStatisticsSupport(String op, boolean shouldThrow) {\n     if (&lt;support&gt;)\n         return true;\n     \n     if (shouldThrow)\n         throw new Ex();\n\n     return false;\n } \n\"><pre><code> void checkStatisticsSupport(String op) {\n     checkStatisticsSupport(op, true)\n }\n\nboolean checkStatisticsSupport(String op, boolean shouldThrow) {\n     if (&lt;support&gt;)\n         return true;\n     \n     if (shouldThrow)\n         throw new Ex();\n\n     return false;\n } \n</code></pre></div>", "author": "korlov42", "createdAt": "2021-01-21T15:42:48Z", "path": "modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java", "diffHunk": "@@ -267,14 +266,23 @@ public void gatherLocalObjectStatisticsAsync(\n     /** {@inheritDoc} */\n     @Override public StatisticsGatheringFuture<Map<StatisticsTarget, ObjectStatistics>>[] gatherObjectStatisticsAsync(\n         StatisticsTarget... keys\n-    ) throws IgniteCheckedException {\n-        checkSupport(\"collect statistics async\");\n+    ) {\n+\n+        Set<StatisticsKeyMessage> keysMsg = Arrays.stream(keys).map(StatisticsUtils::statisticsKeyMessage)\n+            .collect(Collectors.toSet());\n \n-        Set<StatisticsKeyMessage> keysMsg = Arrays.stream(keys).map(\n-            t -> new StatisticsKeyMessage(t.schema(), t.obj(), Arrays.asList(t.columns()))).collect(Collectors.toSet());\n         Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpsKeys = helper.splitByGroups(keysMsg);\n \n-        List<StatisticsGatheringFuture<Void>> res = new ArrayList<>();\n+        if (!IgniteFeatures.allNodesSupport(ctx, IgniteFeatures.STATISTICS_COLLECTION, IgniteDiscoverySpi.SRV_NODES)) {", "originalCommit": "f5aafee54b1036c09d4944ca9bf0254f8bfd2b1e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjQ3NzQyMQ==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r562477421", "bodyText": "done", "author": "Berkof", "createdAt": "2021-01-22T08:52:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MTk4Mjk4Mg=="}], "type": "inlineReview", "revised_code": {"commit": "65caf2d646409c3be32c4d00f762fcdc7ec4ceb0", "changed_code": [{"header": "diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\nindex 4df3ed6f1e0..47277987f34 100644\n--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/stat/IgniteStatisticsManagerImpl.java\n", "chunk": "@@ -273,7 +273,7 @@ public class IgniteStatisticsManagerImpl implements IgniteStatisticsManager {\n \n         Map<CacheGroupContext, Collection<StatisticsKeyMessage>> grpsKeys = helper.splitByGroups(keysMsg);\n \n-        if (!IgniteFeatures.allNodesSupport(ctx, IgniteFeatures.STATISTICS_COLLECTION, IgniteDiscoverySpi.SRV_NODES)) {\n+        if (!isStatisticsSupport()) {\n             return grpsKeys.entrySet().stream().map(\n                 grpKeys -> new StatisticsGatheringFutureAdapter(UUID.randomUUID(),\n                     grpKeys.getValue().stream().map(StatisticsUtils::statisticsTarget).toArray(StatisticsTarget[]::new)))\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MTk4OTk2Ng==", "url": "https://github.com/gridgain/gridgain/pull/1660#discussion_r561989966", "body": "BTW id=52 already reserved. Please check https://ggsystems.atlassian.net/wiki/spaces/GG/pages/1192198276/Community+edition+features+list for next feature ID. You need to reserve it first.", "bodyText": "BTW id=52 already reserved. Please check https://ggsystems.atlassian.net/wiki/spaces/GG/pages/1192198276/Community+edition+features+list for next feature ID. You need to reserve it first.", "bodyHTML": "<p dir=\"auto\">BTW id=52 already reserved. Please check <a href=\"https://ggsystems.atlassian.net/wiki/spaces/GG/pages/1192198276/Community+edition+features+list\" rel=\"nofollow\">https://ggsystems.atlassian.net/wiki/spaces/GG/pages/1192198276/Community+edition+features+list</a> for next feature ID. You need to reserve it first.</p>", "author": "korlov42", "createdAt": "2021-01-21T15:51:24Z", "path": "modules/core/src/main/java/org/apache/ignite/internal/IgniteFeatures.java", "diffHunk": "@@ -194,7 +194,10 @@\n     CACHE_GROUP_KEY_CHANGE(50),\n \n     /** Possibility to safe deactivation, take into account pure in memory caches with possible data loss.*/\n-    SAFE_CLUSTER_DEACTIVATION(51);\n+    SAFE_CLUSTER_DEACTIVATION(51),\n+\n+    /** Statistics collection. */\n+    STATISTICS_COLLECTION(52);", "originalCommit": "f5aafee54b1036c09d4944ca9bf0254f8bfd2b1e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "65caf2d646409c3be32c4d00f762fcdc7ec4ceb0", "changed_code": [{"header": "diff --git a/modules/core/src/main/java/org/apache/ignite/internal/IgniteFeatures.java b/modules/core/src/main/java/org/apache/ignite/internal/IgniteFeatures.java\nindex 20cc1892af2..b1dece80ba0 100644\n--- a/modules/core/src/main/java/org/apache/ignite/internal/IgniteFeatures.java\n+++ b/modules/core/src/main/java/org/apache/ignite/internal/IgniteFeatures.java\n", "chunk": "@@ -197,7 +197,7 @@ public enum IgniteFeatures {\n     SAFE_CLUSTER_DEACTIVATION(51),\n \n     /** Statistics collection. */\n-    STATISTICS_COLLECTION(52);\n+    STATISTICS_COLLECTION(55);\n \n     /**\n      * Unique feature identifier.\n", "next_change": {"commit": "acbdccc0496377fc2b3b7d52363aea2185d33239", "changed_code": [{"header": "diff --git a/modules/core/src/main/java/org/apache/ignite/internal/IgniteFeatures.java b/modules/core/src/main/java/org/apache/ignite/internal/IgniteFeatures.java\nindex b1dece80ba0..c1c108e1b7e 100644\n--- a/modules/core/src/main/java/org/apache/ignite/internal/IgniteFeatures.java\n+++ b/modules/core/src/main/java/org/apache/ignite/internal/IgniteFeatures.java\n", "chunk": "@@ -196,6 +196,12 @@ public enum IgniteFeatures {\n     /** Possibility to safe deactivation, take into account pure in memory caches with possible data loss.*/\n     SAFE_CLUSTER_DEACTIVATION(51),\n \n+    /** Custom snapshot operations. */\n+    CUSTOM_SNAPSHOT_OPERATIONS(53),\n+\n+    /** Point-in-time distributed property. */\n+    POINT_IN_TIME_DISTRIBUTED_PROPERTY(54),\n+\n     /** Statistics collection. */\n     STATISTICS_COLLECTION(55);\n \n", "next_change": null}]}}]}}, {"oid": "65caf2d646409c3be32c4d00f762fcdc7ec4ceb0", "url": "https://github.com/gridgain/gridgain/commit/65caf2d646409c3be32c4d00f762fcdc7ec4ceb0", "message": "GG-31094: change feature number, minor fix by PR", "committedDate": "2021-01-22T08:55:32Z", "type": "commit"}, {"oid": "acbdccc0496377fc2b3b7d52363aea2185d33239", "url": "https://github.com/gridgain/gridgain/commit/acbdccc0496377fc2b3b7d52363aea2185d33239", "message": "GG-31094: Merge remote-tracking branch 'gridgain-ce/master' into gg-31094", "committedDate": "2021-01-26T16:09:51Z", "type": "commit"}]}