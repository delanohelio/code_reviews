{"pr_number": 63461, "pr_title": "Use Pooled Byte Arrays in BlobStoreRepository Serialization", "pr_author": "original-brownbear", "pr_createdAt": "2020-10-08T10:40:30Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/63461", "timeline": [{"oid": "54186e745ca7d4566e24388712432b2e8625aaff", "url": "https://github.com/elastic/elasticsearch/commit/54186e745ca7d4566e24388712432b2e8625aaff", "message": "Use Pooled Byte Arrays in BlobStoreRepository Serialization\n\nMany of the metadata blobs we handle in the changed spots can grow\nup in size up to `O(1M)`. Not using recycled bytes when working with\nthem causes significant spikes in memory use for larger repositories.", "committedDate": "2020-10-08T10:35:04Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTYzOTQxNQ==", "url": "https://github.com/elastic/elasticsearch/pull/63461#discussion_r501639415", "body": "It's not exclusively laziness that I didn't make this path use pooled bytes now as well. Caching here turned out to be somewhat bogus in practice and needs to be changed (will do over the next few days when I find some time). I just went with the simplest possible change here for now as it doesn't really matter.", "bodyText": "It's not exclusively laziness that I didn't make this path use pooled bytes now as well. Caching here turned out to be somewhat bogus in practice and needs to be changed (will do over the next few days when I find some time). I just went with the simplest possible change here for now as it doesn't really matter.", "bodyHTML": "<p dir=\"auto\">It's not exclusively laziness that I didn't make this path use pooled bytes now as well. Caching here turned out to be somewhat bogus in practice and needs to be changed (will do over the next few days when I find some time). I just went with the simplest possible change here for now as it doesn't really matter.</p>", "author": "original-brownbear", "createdAt": "2020-10-08T11:14:40Z", "path": "server/src/main/java/org/elasticsearch/repositories/blobstore/BlobStoreRepository.java", "diffHunk": "@@ -1340,8 +1348,8 @@ private void doGetRepositoryData(ActionListener<RepositoryData> listener) {\n                     // We can cache serialized in the most recent version here without regard to the actual repository metadata version\n                     // since we're only caching the information that we just wrote and thus won't accidentally cache any information that\n                     // isn't safe\n-                    cacheRepositoryData(\n-                            BytesReference.bytes(loaded.snapshotsToXContent(XContentFactory.jsonBuilder(), Version.CURRENT)), genToLoad);\n+                    cacheRepositoryData(compressRepoDataForCache(BytesReference.bytes(", "originalCommit": "54186e745ca7d4566e24388712432b2e8625aaff", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTY0MDQ5Mw==", "url": "https://github.com/elastic/elasticsearch/pull/63461#discussion_r501640493", "body": "Creating the serialized repo data to cache here early is a win even without pooled buffers for the serialization. It wasn't necessary to keep the uncompressed version around for the duration of the below cluster state update.\r\nThis is especially true when it turns out to be very large (as in multiple MB or so) and won't be cached to begin with.", "bodyText": "Creating the serialized repo data to cache here early is a win even without pooled buffers for the serialization. It wasn't necessary to keep the uncompressed version around for the duration of the below cluster state update.\nThis is especially true when it turns out to be very large (as in multiple MB or so) and won't be cached to begin with.", "bodyHTML": "<p dir=\"auto\">Creating the serialized repo data to cache here early is a win even without pooled buffers for the serialization. It wasn't necessary to keep the uncompressed version around for the duration of the below cluster state update.<br>\nThis is especially true when it turns out to be very large (as in multiple MB or so) and won't be cached to begin with.</p>", "author": "original-brownbear", "createdAt": "2020-10-08T11:16:46Z", "path": "server/src/main/java/org/elasticsearch/repositories/blobstore/BlobStoreRepository.java", "diffHunk": "@@ -1630,9 +1648,15 @@ public void onFailure(Exception e) {\n             }\n             final String indexBlob = INDEX_FILE_PREFIX + Long.toString(newGen);\n             logger.debug(\"Repository [{}] writing new index generational blob [{}]\", metadata.name(), indexBlob);\n-            final BytesReference serializedRepoData =\n-                    BytesReference.bytes(newRepositoryData.snapshotsToXContent(XContentFactory.jsonBuilder(), version));\n-            writeAtomic(blobContainer(), indexBlob, serializedRepoData, true);\n+            final BytesReference repoDataToCache;\n+            try (ReleasableBytesStreamOutput out = new ReleasableBytesStreamOutput(bigArrays)) {\n+                try (XContentBuilder xContentBuilder = XContentFactory.jsonBuilder(Streams.noCloseStream(out))) {\n+                    newRepositoryData.snapshotsToXContent(xContentBuilder, version);\n+                }\n+                final BytesReference serializedRepoData = out.bytes();\n+                writeAtomic(blobContainer(), indexBlob, serializedRepoData, true);\n+                repoDataToCache = compressRepoDataForCache(serializedRepoData);", "originalCommit": "54186e745ca7d4566e24388712432b2e8625aaff", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTY0MTA1OA==", "url": "https://github.com/elastic/elasticsearch/pull/63461#discussion_r501641058", "body": "Gotta do the non-closing `copy` here and close the `in` via `try` because we can only close `out` once (multiple closes aren't idempotent and trip assertions.", "bodyText": "Gotta do the non-closing copy here and close the in via try because we can only close out once (multiple closes aren't idempotent and trip assertions.", "bodyHTML": "<p dir=\"auto\">Gotta do the non-closing <code>copy</code> here and close the <code>in</code> via <code>try</code> because we can only close <code>out</code> once (multiple closes aren't idempotent and trip assertions.</p>", "author": "original-brownbear", "createdAt": "2020-10-08T11:17:56Z", "path": "server/src/main/java/org/elasticsearch/repositories/blobstore/ChecksumBlobStoreFormat.java", "diffHunk": "@@ -101,9 +104,14 @@ public ChecksumBlobStoreFormat(String codec, String blobNameFormat, CheckedFunct\n      * @param name          name to be translated into\n      * @return parsed blob object\n      */\n-    public T read(BlobContainer blobContainer, String name, NamedXContentRegistry namedXContentRegistry) throws IOException {\n+    public T read(BlobContainer blobContainer, String name, NamedXContentRegistry namedXContentRegistry,\n+                  BigArrays bigArrays) throws IOException {\n         String blobName = blobName(name);\n-        return deserialize(blobName, namedXContentRegistry, Streams.readFully(blobContainer.readBlob(blobName)));\n+        try (ReleasableBytesStreamOutput out = new ReleasableBytesStreamOutput(bigArrays);\n+             InputStream in = blobContainer.readBlob(blobName)) {\n+            Streams.copy(in, out, false);", "originalCommit": "54186e745ca7d4566e24388712432b2e8625aaff", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzA5Njk2NQ==", "url": "https://github.com/elastic/elasticsearch/pull/63461#discussion_r503096965", "bodyText": "+1, bytes() should not be used once ReleasableBytesStreamOutput is closed", "author": "tlrx", "createdAt": "2020-10-12T07:41:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTY0MTA1OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzA5NTE5MA==", "url": "https://github.com/elastic/elasticsearch/pull/63461#discussion_r503095190", "body": "extra space", "bodyText": "extra space", "bodyHTML": "<p dir=\"auto\">extra space</p>", "author": "tlrx", "createdAt": "2020-10-12T07:38:25Z", "path": "server/src/main/java/org/elasticsearch/repositories/blobstore/ChecksumBlobStoreFormat.java", "diffHunk": "@@ -101,9 +104,14 @@ public ChecksumBlobStoreFormat(String codec, String blobNameFormat, CheckedFunct\n      * @param name          name to be translated into\n      * @return parsed blob object\n      */\n-    public T read(BlobContainer blobContainer, String name, NamedXContentRegistry namedXContentRegistry) throws IOException {\n+    public T read(BlobContainer blobContainer, String name, NamedXContentRegistry namedXContentRegistry,\n+                  BigArrays bigArrays) throws IOException {\n         String blobName = blobName(name);\n-        return deserialize(blobName, namedXContentRegistry, Streams.readFully(blobContainer.readBlob(blobName)));\n+        try (ReleasableBytesStreamOutput out = new ReleasableBytesStreamOutput(bigArrays);\n+             InputStream in = blobContainer.readBlob(blobName)) {", "originalCommit": "54186e745ca7d4566e24388712432b2e8625aaff", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzExNTc0MA==", "url": "https://github.com/elastic/elasticsearch/pull/63461#discussion_r503115740", "bodyText": "? where :)", "author": "original-brownbear", "createdAt": "2020-10-12T08:14:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzA5NTE5MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzExNzI4Mg==", "url": "https://github.com/elastic/elasticsearch/pull/63461#discussion_r503117282", "body": "```suggestion\r\n            InputStream in = blobContainer.readBlob(blobName)) {\r\n            Streams.copy(in, out, false);\r\n```", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                         InputStream in = blobContainer.readBlob(blobName)) {\n          \n          \n            \n                        Streams.copy(in, out, false);\n          \n          \n            \n                        InputStream in = blobContainer.readBlob(blobName)) {\n          \n          \n            \n                        Streams.copy(in, out, false);", "bodyHTML": "  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"111\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">            <span class=\"x x-first x-last\"> </span><span class=\"pl-smi\">InputStream</span> in <span class=\"pl-k\">=</span> blobContainer<span class=\"pl-k\">.</span>readBlob(blobName)) {</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"112\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">            <span class=\"pl-smi\">Streams</span><span class=\"pl-k\">.</span>copy(in, out, <span class=\"pl-c1\">false</span>);</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"111\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">            <span class=\"pl-smi\">InputStream</span> in <span class=\"pl-k\">=</span> blobContainer<span class=\"pl-k\">.</span>readBlob(blobName)) {</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"112\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">            <span class=\"pl-smi\">Streams</span><span class=\"pl-k\">.</span>copy(in, out, <span class=\"pl-c1\">false</span>);</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "tlrx", "createdAt": "2020-10-12T08:17:33Z", "path": "server/src/main/java/org/elasticsearch/repositories/blobstore/ChecksumBlobStoreFormat.java", "diffHunk": "@@ -101,9 +104,14 @@ public ChecksumBlobStoreFormat(String codec, String blobNameFormat, CheckedFunct\n      * @param name          name to be translated into\n      * @return parsed blob object\n      */\n-    public T read(BlobContainer blobContainer, String name, NamedXContentRegistry namedXContentRegistry) throws IOException {\n+    public T read(BlobContainer blobContainer, String name, NamedXContentRegistry namedXContentRegistry,\n+                  BigArrays bigArrays) throws IOException {\n         String blobName = blobName(name);\n-        return deserialize(blobName, namedXContentRegistry, Streams.readFully(blobContainer.readBlob(blobName)));\n+        try (ReleasableBytesStreamOutput out = new ReleasableBytesStreamOutput(bigArrays);\n+             InputStream in = blobContainer.readBlob(blobName)) {\n+            Streams.copy(in, out, false);", "originalCommit": "54186e745ca7d4566e24388712432b2e8625aaff", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzExODQ3OA==", "url": "https://github.com/elastic/elasticsearch/pull/63461#discussion_r503118478", "bodyText": "But InputStream in is part of the try-with-resources so it should align with the ReleasableBytesStreamOutput out above it shouldn't it?", "author": "original-brownbear", "createdAt": "2020-10-12T08:19:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzExNzI4Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzExOTM3NQ==", "url": "https://github.com/elastic/elasticsearch/pull/63461#discussion_r503119375", "bodyText": "Raaah yes, I misread this line :( Sorry for the noise.", "author": "tlrx", "createdAt": "2020-10-12T08:20:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzExNzI4Mg=="}], "type": "inlineReview"}]}