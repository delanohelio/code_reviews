{"pr_number": 55260, "pr_title": "[ML] partitions model definitions into chunks", "pr_author": "benwtrent", "pr_createdAt": "2020-04-15T19:10:14Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/55260", "timeline": [{"oid": "364b0eddc89717bfad484932e3f133f13f4ff1ea", "url": "https://github.com/elastic/elasticsearch/commit/364b0eddc89717bfad484932e3f133f13f4ff1ea", "message": "[ML] partitions model definitions into chunks", "committedDate": "2020-04-15T19:08:54Z", "type": "commit"}, {"oid": "532c236f76562c06e8eb44c7ced176936f34ee4a", "url": "https://github.com/elastic/elasticsearch/commit/532c236f76562c06e8eb44c7ced176936f34ee4a", "message": "add warning about bwc", "committedDate": "2020-04-16T11:52:30Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTMyNjkwNw==", "url": "https://github.com/elastic/elasticsearch/pull/55260#discussion_r411326907", "body": "```suggestion\r\n                \"Creating a new model requires that all nodes are at least version [{}]\",\r\n```", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            \"Creating a new model that all nodes are at least version [{}]\",\n          \n          \n            \n                            \"Creating a new model requires that all nodes are at least version [{}]\",", "bodyHTML": "  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">                <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Creating a new model that all nodes are at least version [{}]<span class=\"pl-pds\">\"</span></span>,</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">                <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Creating a new model <span class=\"x x-first x-last\">requires </span>that all nodes are at least version [{}]<span class=\"pl-pds\">\"</span></span>,</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "droberts195", "createdAt": "2020-04-20T12:12:10Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/action/TransportPutTrainedModelAction.java", "diffHunk": "@@ -82,6 +82,15 @@ protected void masterOperation(Task task,\n                                    PutTrainedModelAction.Request request,\n                                    ClusterState state,\n                                    ActionListener<Response> listener) {\n+        // 7.8.0 introduced splitting the model definition across multiple documents.\n+        // This means that new models will not be usable on nodes that cannot handle multiple definition documents\n+        if (state.nodes().getMinNodeVersion().before(Version.V_7_8_0)) {\n+            listener.onFailure(ExceptionsHelper.badRequestException(\n+                \"Creating a new model that all nodes are at least version [{}]\",", "originalCommit": "532c236f76562c06e8eb44c7ced176936f34ee4a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTMyODAzNQ==", "url": "https://github.com/elastic/elasticsearch/pull/55260#discussion_r411328035", "body": "It should `return` here.", "bodyText": "It should return here.", "bodyHTML": "<p dir=\"auto\">It should <code>return</code> here.</p>", "author": "droberts195", "createdAt": "2020-04-20T12:14:07Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/persistence/TrainedModelProvider.java", "diffHunk": "@@ -138,30 +143,40 @@ public void storeTrainedModel(TrainedModelConfig trainedModelConfig,\n     private void storeTrainedModelAndDefinition(TrainedModelConfig trainedModelConfig,\n                                                 ActionListener<Boolean> listener) {\n \n-        TrainedModelDefinitionDoc trainedModelDefinitionDoc;\n+        List<TrainedModelDefinitionDoc> trainedModelDefinitionDocs = new ArrayList<>();\n         try {\n-            // TODO should we check length against allowed stream size???\n             String compressedString = trainedModelConfig.getCompressedDefinition();\n-            trainedModelDefinitionDoc = new TrainedModelDefinitionDoc.Builder()\n-                .setDocNum(0)\n-                .setModelId(trainedModelConfig.getModelId())\n-                .setCompressedString(compressedString)\n-                .setCompressionVersion(TrainedModelConfig.CURRENT_DEFINITION_COMPRESSION_VERSION)\n-                .setDefinitionLength(compressedString.length())\n-                .setTotalDefinitionLength(compressedString.length())\n-                .build();\n+            if (compressedString.length() > MAX_COMPRESSED_STRING_SIZE) {\n+                listener.onFailure(\n+                    ExceptionsHelper.badRequestException(\n+                        \"Unable to store model as compressed definition has length [{}] the limit is [{}]\",\n+                        compressedString.length(),\n+                        MAX_COMPRESSED_STRING_SIZE));", "originalCommit": "532c236f76562c06e8eb44c7ced176936f34ee4a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTM1MTgwOA==", "url": "https://github.com/elastic/elasticsearch/pull/55260#discussion_r411351808", "body": "I am happy to merge this PR more-or-less as-is (see the two other minor comments I made).\r\n\r\nHowever, in the long term if we're expecting to deal with models whose compressed definition is of the order of a gigabyte then I think more optimisations will be needed.  For example:\r\n\r\n- Suppose this method is dealing with a `str` of length 1000000000\r\n- That requires 2000000000 bytes to store as a UTF-16 `String`\r\n- Then at the point this method returns every character has been copied into new strings but the original still exists so the memory usage at the point of return is over 4000000000 bytes\r\n\r\nSo we've gone from ~1GB of JSON model to temporarily using 4GB memory to manipulate it.\r\n\r\nSince the compressed model is Base64, if it was stored as UTF-8 then that would be 1 byte per character.  And if this was wrapped in a `BytesReference` instead of a `String` then the returned `List<String>` could be a `List<BytesReference>` where the raw data was not duplicated but just referenced in slices by the list elements.\r\n\r\nBasically, as we move from dealing with a few kilobytes of data to gigabytes we need to think much more about avoiding unnecessary duplication, most efficient character sets, etc.  But not in this PR, it can be done in a future one.", "bodyText": "I am happy to merge this PR more-or-less as-is (see the two other minor comments I made).\nHowever, in the long term if we're expecting to deal with models whose compressed definition is of the order of a gigabyte then I think more optimisations will be needed.  For example:\n\nSuppose this method is dealing with a str of length 1000000000\nThat requires 2000000000 bytes to store as a UTF-16 String\nThen at the point this method returns every character has been copied into new strings but the original still exists so the memory usage at the point of return is over 4000000000 bytes\n\nSo we've gone from ~1GB of JSON model to temporarily using 4GB memory to manipulate it.\nSince the compressed model is Base64, if it was stored as UTF-8 then that would be 1 byte per character.  And if this was wrapped in a BytesReference instead of a String then the returned List<String> could be a List<BytesReference> where the raw data was not duplicated but just referenced in slices by the list elements.\nBasically, as we move from dealing with a few kilobytes of data to gigabytes we need to think much more about avoiding unnecessary duplication, most efficient character sets, etc.  But not in this PR, it can be done in a future one.", "bodyHTML": "<p dir=\"auto\">I am happy to merge this PR more-or-less as-is (see the two other minor comments I made).</p>\n<p dir=\"auto\">However, in the long term if we're expecting to deal with models whose compressed definition is of the order of a gigabyte then I think more optimisations will be needed.  For example:</p>\n<ul dir=\"auto\">\n<li>Suppose this method is dealing with a <code>str</code> of length 1000000000</li>\n<li>That requires 2000000000 bytes to store as a UTF-16 <code>String</code></li>\n<li>Then at the point this method returns every character has been copied into new strings but the original still exists so the memory usage at the point of return is over 4000000000 bytes</li>\n</ul>\n<p dir=\"auto\">So we've gone from ~1GB of JSON model to temporarily using 4GB memory to manipulate it.</p>\n<p dir=\"auto\">Since the compressed model is Base64, if it was stored as UTF-8 then that would be 1 byte per character.  And if this was wrapped in a <code>BytesReference</code> instead of a <code>String</code> then the returned <code>List&lt;String&gt;</code> could be a <code>List&lt;BytesReference&gt;</code> where the raw data was not duplicated but just referenced in slices by the list elements.</p>\n<p dir=\"auto\">Basically, as we move from dealing with a few kilobytes of data to gigabytes we need to think much more about avoiding unnecessary duplication, most efficient character sets, etc.  But not in this PR, it can be done in a future one.</p>", "author": "droberts195", "createdAt": "2020-04-20T12:52:34Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/persistence/TrainedModelProvider.java", "diffHunk": "@@ -677,13 +709,36 @@ private static QueryBuilder buildQueryIdExpressionQuery(String[] tokens, String\n     private static <T> T handleSearchItem(MultiSearchResponse.Item item,\n                                           String resourceId,\n                                           CheckedBiFunction<BytesReference, String, T, Exception> parseLeniently) throws Exception {\n+        return handleSearchItems(item, resourceId, parseLeniently).get(0);\n+    }\n+\n+    // NOTE: This ignores any results that are in a different index than the first one seen in the search response.\n+    private static <T> List<T> handleSearchItems(MultiSearchResponse.Item item,\n+                                                 String resourceId,\n+                                                 CheckedBiFunction<BytesReference, String, T, Exception> parseLeniently) throws Exception {\n         if (item.isFailure()) {\n             throw item.getFailure();\n         }\n         if (item.getResponse().getHits().getHits().length == 0) {\n             throw new ResourceNotFoundException(resourceId);\n         }\n-        return parseLeniently.apply(item.getResponse().getHits().getHits()[0].getSourceRef(), resourceId);\n+        List<T> results = new ArrayList<>(item.getResponse().getHits().getHits().length);\n+        String initialIndex = item.getResponse().getHits().getHits()[0].getIndex();\n+        for (SearchHit hit : item.getResponse().getHits().getHits()) {\n+            // We don't want to spread across multiple backing indices\n+            if (hit.getIndex().equals(initialIndex)) {\n+                results.add(parseLeniently.apply(hit.getSourceRef(), resourceId));\n+            }\n+        }\n+        return results;\n+    }\n+\n+    static List<String> chunkStringWithSize(String str, int chunkSize) {\n+        List<String> subStrings = new ArrayList<>((int)Math.ceil(str.length()/(double)chunkSize));\n+        for (int i = 0; i < str.length();i += chunkSize) {\n+            subStrings.add(str.substring(i, Math.min(i + chunkSize, str.length())));\n+        }\n+        return subStrings;", "originalCommit": "532c236f76562c06e8eb44c7ced176936f34ee4a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTQxOTA5Mw==", "url": "https://github.com/elastic/elasticsearch/pull/55260#discussion_r411419093", "bodyText": "@droberts195 yes, I realize this is an issue. My goal with this PR is to lay the groundwork, so that at least at the data layer (how things are stored/read in/from the index) we truly support more than one doc.", "author": "benwtrent", "createdAt": "2020-04-20T14:22:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTM1MTgwOA=="}], "type": "inlineReview"}, {"oid": "ac8a3fde0ffa55209cccb23cf5fb1c37d2516acf", "url": "https://github.com/elastic/elasticsearch/commit/ac8a3fde0ffa55209cccb23cf5fb1c37d2516acf", "message": "Merge branch 'master' into feature/ml-inference-split-inference-docs", "committedDate": "2020-04-20T17:00:10Z", "type": "commit"}, {"oid": "562e0a45f456c66c3b970e96e64346c27d0b74e7", "url": "https://github.com/elastic/elasticsearch/commit/562e0a45f456c66c3b970e96e64346c27d0b74e7", "message": "addressing PR comments", "committedDate": "2020-04-20T17:01:45Z", "type": "commit"}]}