{"pr_number": 52778, "pr_title": "[ML] Parse and report memory usage for DF Analytics", "pr_author": "dimitris-athanasiou", "pr_createdAt": "2020-02-25T16:48:05Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/52778", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDQ0NjI3Nw==", "url": "https://github.com/elastic/elasticsearch/pull/52778#discussion_r384446277", "body": "There's an inconsistency here, because if the index and alias already existed when the method was called the response is `false`, but if the method is called twice concurrently such that one concurrent call creates it and the other gets a `ResourceAlreadyExistsException` then both return `true`.\r\n\r\nIf the boolean is intended to be \"did this call create the index and alias\" then one should return `false` in this case.\r\n\r\nBut it's not actually documented what the returned boolean is supposed to mean.  Doing that would be good too.", "bodyText": "There's an inconsistency here, because if the index and alias already existed when the method was called the response is false, but if the method is called twice concurrently such that one concurrent call creates it and the other gets a ResourceAlreadyExistsException then both return true.\nIf the boolean is intended to be \"did this call create the index and alias\" then one should return false in this case.\nBut it's not actually documented what the returned boolean is supposed to mean.  Doing that would be good too.", "bodyHTML": "<p dir=\"auto\">There's an inconsistency here, because if the index and alias already existed when the method was called the response is <code>false</code>, but if the method is called twice concurrently such that one concurrent call creates it and the other gets a <code>ResourceAlreadyExistsException</code> then both return <code>true</code>.</p>\n<p dir=\"auto\">If the boolean is intended to be \"did this call create the index and alias\" then one should return <code>false</code> in this case.</p>\n<p dir=\"auto\">But it's not actually documented what the returned boolean is supposed to mean.  Doing that would be good too.</p>", "author": "droberts195", "createdAt": "2020-02-26T11:55:08Z", "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/MlStatsIndex.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ml;\n+\n+import org.elasticsearch.ResourceAlreadyExistsException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.admin.indices.alias.Alias;\n+import org.elasticsearch.action.admin.indices.create.CreateIndexAction;\n+import org.elasticsearch.action.admin.indices.create.CreateIndexRequest;\n+import org.elasticsearch.action.admin.indices.create.CreateIndexResponse;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.xpack.core.ClientHelper;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.template.TemplateUtils;\n+\n+/**\n+ * Describes the indices where ML is storing various stats about the users jobs.\n+ */\n+public class MlStatsIndex {\n+\n+    public static final String TEMPLATE_NAME = \".ml-stats\";\n+\n+    private static final String MAPPINGS_VERSION_VARIABLE = \"xpack.ml.version\";\n+\n+    private MlStatsIndex() {}\n+\n+    public static String mapping() {\n+        return TemplateUtils.loadTemplate(\"/org/elasticsearch/xpack/core/ml/stats_index_mappings.json\",\n+            Version.CURRENT.toString(), MAPPINGS_VERSION_VARIABLE);\n+    }\n+\n+    public static String indexPattern() {\n+        return TEMPLATE_NAME + \"-*\";\n+    }\n+\n+    public static String writeAlias() {\n+        return \".ml-stats-write\";\n+    }\n+\n+    /**\n+     * Creates the first concrete .ml-stats-000001 index (if necessary)\n+     * Creates the .ml-stats-write alias for that index.\n+     */\n+    public static void createStatsIndexAndAliasIfNecessary(Client client, ClusterState state, ActionListener<Boolean> listener) {\n+\n+        if (state.getMetaData().getAliasAndIndexLookup().containsKey(writeAlias())) {\n+            listener.onResponse(false);\n+            return;\n+        }\n+\n+        ActionListener<CreateIndexResponse> createIndexListener = ActionListener.wrap(\n+            createIndexResponse -> listener.onResponse(true),\n+            error -> {\n+                if (ExceptionsHelper.unwrapCause(error) instanceof ResourceAlreadyExistsException) {\n+                    listener.onResponse(true);", "originalCommit": "6333b38ea14ee908d9be870ca4d0edc158a37dda", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDQ0ODcwMw==", "url": "https://github.com/elastic/elasticsearch/pull/52778#discussion_r384448703", "body": "This doesn't cover the edge case where the index exists but the write alias doesn't (presumably because a user accidentally deleted it, but maybe also due to a bug in ILM).\r\n\r\nI think this method should cover that case like `AnomalyDetectorsIndex.createStateIndexAndAliasIfNecessary()` does.  It will avoid support cases if the system can be self healing in this situation.  At present it will return `true` giving the impression that everything is good when the post conditions are that the index exists but not the alias.", "bodyText": "This doesn't cover the edge case where the index exists but the write alias doesn't (presumably because a user accidentally deleted it, but maybe also due to a bug in ILM).\nI think this method should cover that case like AnomalyDetectorsIndex.createStateIndexAndAliasIfNecessary() does.  It will avoid support cases if the system can be self healing in this situation.  At present it will return true giving the impression that everything is good when the post conditions are that the index exists but not the alias.", "bodyHTML": "<p dir=\"auto\">This doesn't cover the edge case where the index exists but the write alias doesn't (presumably because a user accidentally deleted it, but maybe also due to a bug in ILM).</p>\n<p dir=\"auto\">I think this method should cover that case like <code>AnomalyDetectorsIndex.createStateIndexAndAliasIfNecessary()</code> does.  It will avoid support cases if the system can be self healing in this situation.  At present it will return <code>true</code> giving the impression that everything is good when the post conditions are that the index exists but not the alias.</p>", "author": "droberts195", "createdAt": "2020-02-26T12:00:35Z", "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/MlStatsIndex.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ml;\n+\n+import org.elasticsearch.ResourceAlreadyExistsException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.admin.indices.alias.Alias;\n+import org.elasticsearch.action.admin.indices.create.CreateIndexAction;\n+import org.elasticsearch.action.admin.indices.create.CreateIndexRequest;\n+import org.elasticsearch.action.admin.indices.create.CreateIndexResponse;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.xpack.core.ClientHelper;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.template.TemplateUtils;\n+\n+/**\n+ * Describes the indices where ML is storing various stats about the users jobs.\n+ */\n+public class MlStatsIndex {\n+\n+    public static final String TEMPLATE_NAME = \".ml-stats\";\n+\n+    private static final String MAPPINGS_VERSION_VARIABLE = \"xpack.ml.version\";\n+\n+    private MlStatsIndex() {}\n+\n+    public static String mapping() {\n+        return TemplateUtils.loadTemplate(\"/org/elasticsearch/xpack/core/ml/stats_index_mappings.json\",\n+            Version.CURRENT.toString(), MAPPINGS_VERSION_VARIABLE);\n+    }\n+\n+    public static String indexPattern() {\n+        return TEMPLATE_NAME + \"-*\";\n+    }\n+\n+    public static String writeAlias() {\n+        return \".ml-stats-write\";\n+    }\n+\n+    /**\n+     * Creates the first concrete .ml-stats-000001 index (if necessary)\n+     * Creates the .ml-stats-write alias for that index.\n+     */\n+    public static void createStatsIndexAndAliasIfNecessary(Client client, ClusterState state, ActionListener<Boolean> listener) {\n+\n+        if (state.getMetaData().getAliasAndIndexLookup().containsKey(writeAlias())) {\n+            listener.onResponse(false);\n+            return;\n+        }\n+\n+        ActionListener<CreateIndexResponse> createIndexListener = ActionListener.wrap(\n+            createIndexResponse -> listener.onResponse(true),\n+            error -> {\n+                if (ExceptionsHelper.unwrapCause(error) instanceof ResourceAlreadyExistsException) {\n+                    listener.onResponse(true);\n+                } else {\n+                    listener.onFailure(error);\n+                }\n+            }\n+        );\n+\n+        CreateIndexRequest createIndexRequest = client.admin()\n+            .indices()\n+            .prepareCreate(TEMPLATE_NAME + \"-000001\")\n+            .addAlias(new Alias(writeAlias()).writeIndex(true))", "originalCommit": "6333b38ea14ee908d9be870ca4d0edc158a37dda", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTE3NTg0Mg==", "url": "https://github.com/elastic/elasticsearch/pull/52778#discussion_r385175842", "bodyText": "Good point. I thought the main reason we had that code for anomaly detection was because originally we were not using aliases. But I can see how being able to self-heal would help.", "author": "dimitris-athanasiou", "createdAt": "2020-02-27T15:09:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDQ0ODcwMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDQ1MzE2Ng==", "url": "https://github.com/elastic/elasticsearch/pull/52778#discussion_r384453166", "body": "I don't think it's good that we're propagating the behaviour of the old Prelert time parsing that is completely non-standard in the Elastic stack into new code:\r\n\r\n```\r\n            if (date.trim().length() <= 10) { // seconds\r\n                return epoch * 1000;\r\n            } else {\r\n                return epoch;\r\n            }\r\n```\r\n\r\nIt would have been best if we'd removed this years ago.\r\n\r\nMaybe now is a good opportunity to rename `TimeUtils.parseTimeField()` to `TimeUtils.parseTimeFieldDeprecated()` and `TimeUtils.parseTimeFieldToInstant()` to `TimeUtils.parseTimeFieldToInstantDeprecated()`, annotate both with `@Deprecated` and introduce a new method `TimeUtils.parseTimeFieldToInstant()` that can be used here that replaces `return Instant.ofEpochMilli(dateStringToEpoch(parser.text()));` with `return Instant.from(DateFieldMapper.DEFAULT_DATE_TIME_FORMATTER.parse(parser.text()));`.", "bodyText": "I don't think it's good that we're propagating the behaviour of the old Prelert time parsing that is completely non-standard in the Elastic stack into new code:\n            if (date.trim().length() <= 10) { // seconds\n                return epoch * 1000;\n            } else {\n                return epoch;\n            }\n\nIt would have been best if we'd removed this years ago.\nMaybe now is a good opportunity to rename TimeUtils.parseTimeField() to TimeUtils.parseTimeFieldDeprecated() and TimeUtils.parseTimeFieldToInstant() to TimeUtils.parseTimeFieldToInstantDeprecated(), annotate both with @Deprecated and introduce a new method TimeUtils.parseTimeFieldToInstant() that can be used here that replaces return Instant.ofEpochMilli(dateStringToEpoch(parser.text())); with return Instant.from(DateFieldMapper.DEFAULT_DATE_TIME_FORMATTER.parse(parser.text()));.", "bodyHTML": "<p dir=\"auto\">I don't think it's good that we're propagating the behaviour of the old Prelert time parsing that is completely non-standard in the Elastic stack into new code:</p>\n<div class=\"snippet-clipboard-content position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"            if (date.trim().length() &lt;= 10) { // seconds\n                return epoch * 1000;\n            } else {\n                return epoch;\n            }\"><pre><code>            if (date.trim().length() &lt;= 10) { // seconds\n                return epoch * 1000;\n            } else {\n                return epoch;\n            }\n</code></pre></div>\n<p dir=\"auto\">It would have been best if we'd removed this years ago.</p>\n<p dir=\"auto\">Maybe now is a good opportunity to rename <code>TimeUtils.parseTimeField()</code> to <code>TimeUtils.parseTimeFieldDeprecated()</code> and <code>TimeUtils.parseTimeFieldToInstant()</code> to <code>TimeUtils.parseTimeFieldToInstantDeprecated()</code>, annotate both with <code>@Deprecated</code> and introduce a new method <code>TimeUtils.parseTimeFieldToInstant()</code> that can be used here that replaces <code>return Instant.ofEpochMilli(dateStringToEpoch(parser.text()));</code> with <code>return Instant.from(DateFieldMapper.DEFAULT_DATE_TIME_FORMATTER.parse(parser.text()));</code>.</p>", "author": "droberts195", "createdAt": "2020-02-26T12:11:01Z", "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/dataframe/stats/MemoryUsage.java", "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ml.dataframe.stats;\n+\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.xpack.core.common.time.TimeUtils;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+\n+import java.io.IOException;\n+import java.time.Instant;\n+import java.util.Objects;\n+\n+public class MemoryUsage implements Writeable, ToXContentObject {\n+\n+    public static final String TYPE_VALUE = \"analytics_memory_usage\";\n+\n+    public static final ParseField TYPE = new ParseField(\"type\");\n+    public static final ParseField JOB_ID = new ParseField(\"job_id\");\n+    public static final ParseField TIMESTAMP = new ParseField(\"timestamp\");\n+    public static final ParseField PEAK_USAGE_BYTES = new ParseField(\"peak_usage_bytes\");\n+\n+    public static final ConstructingObjectParser<MemoryUsage, Void> STRICT_PARSER = createParser(false);\n+    public static final ConstructingObjectParser<MemoryUsage, Void> LENIENT_PARSER = createParser(true);\n+\n+    private static ConstructingObjectParser<MemoryUsage, Void> createParser(boolean ignoreUnknownFields) {\n+        ConstructingObjectParser<MemoryUsage, Void> parser = new ConstructingObjectParser<>(TYPE_VALUE,\n+            ignoreUnknownFields, a -> new MemoryUsage((String) a[0], (Instant) a[1], (long) a[2]));\n+\n+        parser.declareString((bucket, s) -> {}, TYPE);\n+        parser.declareString(ConstructingObjectParser.constructorArg(), JOB_ID);\n+        parser.declareField(ConstructingObjectParser.constructorArg(),\n+            p -> TimeUtils.parseTimeFieldToInstant(p, TIMESTAMP.getPreferredName()),", "originalCommit": "6333b38ea14ee908d9be870ca4d0edc158a37dda", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDQ1NDAyNg==", "url": "https://github.com/elastic/elasticsearch/pull/52778#discussion_r384454026", "body": "It would be good to add a comment that the reason for rounding to millisecond accuracy is that the XContent representation rounds to millisecond accuracy and it makes debugging hard if the internal accuracy is greater.", "bodyText": "It would be good to add a comment that the reason for rounding to millisecond accuracy is that the XContent representation rounds to millisecond accuracy and it makes debugging hard if the internal accuracy is greater.", "bodyHTML": "<p dir=\"auto\">It would be good to add a comment that the reason for rounding to millisecond accuracy is that the XContent representation rounds to millisecond accuracy and it makes debugging hard if the internal accuracy is greater.</p>", "author": "droberts195", "createdAt": "2020-02-26T12:13:09Z", "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/dataframe/stats/MemoryUsage.java", "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ml.dataframe.stats;\n+\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.xpack.core.common.time.TimeUtils;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+\n+import java.io.IOException;\n+import java.time.Instant;\n+import java.util.Objects;\n+\n+public class MemoryUsage implements Writeable, ToXContentObject {\n+\n+    public static final String TYPE_VALUE = \"analytics_memory_usage\";\n+\n+    public static final ParseField TYPE = new ParseField(\"type\");\n+    public static final ParseField JOB_ID = new ParseField(\"job_id\");\n+    public static final ParseField TIMESTAMP = new ParseField(\"timestamp\");\n+    public static final ParseField PEAK_USAGE_BYTES = new ParseField(\"peak_usage_bytes\");\n+\n+    public static final ConstructingObjectParser<MemoryUsage, Void> STRICT_PARSER = createParser(false);\n+    public static final ConstructingObjectParser<MemoryUsage, Void> LENIENT_PARSER = createParser(true);\n+\n+    private static ConstructingObjectParser<MemoryUsage, Void> createParser(boolean ignoreUnknownFields) {\n+        ConstructingObjectParser<MemoryUsage, Void> parser = new ConstructingObjectParser<>(TYPE_VALUE,\n+            ignoreUnknownFields, a -> new MemoryUsage((String) a[0], (Instant) a[1], (long) a[2]));\n+\n+        parser.declareString((bucket, s) -> {}, TYPE);\n+        parser.declareString(ConstructingObjectParser.constructorArg(), JOB_ID);\n+        parser.declareField(ConstructingObjectParser.constructorArg(),\n+            p -> TimeUtils.parseTimeFieldToInstant(p, TIMESTAMP.getPreferredName()),\n+            TIMESTAMP,\n+            ObjectParser.ValueType.VALUE);\n+        parser.declareLong(ConstructingObjectParser.constructorArg(), PEAK_USAGE_BYTES);\n+        return parser;\n+    }\n+\n+    private final String jobId;\n+    private final Instant timestamp;\n+    private final long peakUsageBytes;\n+\n+    public MemoryUsage(String jobId, Instant timestamp, long peakUsageBytes) {\n+        this.jobId = Objects.requireNonNull(jobId);\n+        this.timestamp = Instant.ofEpochMilli(ExceptionsHelper.requireNonNull(timestamp, TIMESTAMP).toEpochMilli());\n+        this.peakUsageBytes = peakUsageBytes;\n+    }\n+\n+    public MemoryUsage(StreamInput in) throws IOException {\n+        jobId = in.readString();\n+        timestamp = in.readInstant();\n+        peakUsageBytes = in.readVLong();\n+    }\n+\n+    @Override\n+    public void writeTo(StreamOutput out) throws IOException {\n+        out.writeString(jobId);\n+        out.writeInstant(timestamp);\n+        out.writeVLong(peakUsageBytes);\n+    }\n+\n+    @Override\n+    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n+        builder.startObject();\n+        if (params.paramAsBoolean(ToXContentParams.FOR_INTERNAL_STORAGE, false)) {\n+            builder.field(TYPE.getPreferredName(), TYPE_VALUE);\n+            builder.field(JOB_ID.getPreferredName(), jobId);\n+        }\n+        builder.timeField(TIMESTAMP.getPreferredName(), TIMESTAMP.getPreferredName() + \"_string\", timestamp.toEpochMilli());", "originalCommit": "6333b38ea14ee908d9be870ca4d0edc158a37dda", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDczMDY2OQ==", "url": "https://github.com/elastic/elasticsearch/pull/52778#discussion_r384730669", "body": "Why is this necessary? Presumably, the only time it is parsing `TYPE` is when it is reading from the index. In that case, it should ignore unknown fields. ", "bodyText": "Why is this necessary? Presumably, the only time it is parsing TYPE is when it is reading from the index. In that case, it should ignore unknown fields.", "bodyHTML": "<p dir=\"auto\">Why is this necessary? Presumably, the only time it is parsing <code>TYPE</code> is when it is reading from the index. In that case, it should ignore unknown fields.</p>", "author": "benwtrent", "createdAt": "2020-02-26T19:57:18Z", "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/dataframe/stats/MemoryUsage.java", "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ml.dataframe.stats;\n+\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.xpack.core.common.time.TimeUtils;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+\n+import java.io.IOException;\n+import java.time.Instant;\n+import java.util.Objects;\n+\n+public class MemoryUsage implements Writeable, ToXContentObject {\n+\n+    public static final String TYPE_VALUE = \"analytics_memory_usage\";\n+\n+    public static final ParseField TYPE = new ParseField(\"type\");\n+    public static final ParseField JOB_ID = new ParseField(\"job_id\");\n+    public static final ParseField TIMESTAMP = new ParseField(\"timestamp\");\n+    public static final ParseField PEAK_USAGE_BYTES = new ParseField(\"peak_usage_bytes\");\n+\n+    public static final ConstructingObjectParser<MemoryUsage, Void> STRICT_PARSER = createParser(false);\n+    public static final ConstructingObjectParser<MemoryUsage, Void> LENIENT_PARSER = createParser(true);\n+\n+    private static ConstructingObjectParser<MemoryUsage, Void> createParser(boolean ignoreUnknownFields) {\n+        ConstructingObjectParser<MemoryUsage, Void> parser = new ConstructingObjectParser<>(TYPE_VALUE,\n+            ignoreUnknownFields, a -> new MemoryUsage((String) a[0], (Instant) a[1], (long) a[2]));\n+\n+        parser.declareString((bucket, s) -> {}, TYPE);", "originalCommit": "6333b38ea14ee908d9be870ca4d0edc158a37dda", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTAxNzI4OA==", "url": "https://github.com/elastic/elasticsearch/pull/52778#discussion_r385017288", "bodyText": "I don't think it's that bad to include it even though it's technically redundant.  It serves partly as documentation that we expect the field to exist if somebody is looking at the parser definition to find out which fields are expected in the document in the current product version.", "author": "droberts195", "createdAt": "2020-02-27T09:50:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDczMDY2OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTYzNTA3OA==", "url": "https://github.com/elastic/elasticsearch/pull/52778#discussion_r385635078", "bodyText": "Good point!", "author": "dimitris-athanasiou", "createdAt": "2020-02-28T11:03:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDczMDY2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDczMjA3Mg==", "url": "https://github.com/elastic/elasticsearch/pull/52778#discussion_r384732072", "body": "```suggestion\r\n        return new ToXContent.MapParams(Collections.singletonMap(ToXContentParams.FOR_INTERNAL_STORAGE, Boolean.toString(lenient));\r\n```\r\nI think will work so that the empty parsing declaration for `TYPE` can go away.", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    return new ToXContent.MapParams(Collections.singletonMap(ToXContentParams.FOR_INTERNAL_STORAGE, \"true\"));\n          \n          \n            \n                    return new ToXContent.MapParams(Collections.singletonMap(ToXContentParams.FOR_INTERNAL_STORAGE, Boolean.toString(lenient));\n          \n      \n    \n    \n  \n\nI think will work so that the empty parsing declaration for TYPE can go away.", "bodyHTML": "  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"40\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">        <span class=\"pl-k\">return</span> <span class=\"pl-k\">new</span> <span class=\"pl-smi\">ToXContent</span>.<span class=\"pl-smi\">MapParams</span>(<span class=\"pl-smi\">Collections</span><span class=\"pl-k\">.</span>singletonMap(<span class=\"pl-smi\">ToXContentParams</span><span class=\"pl-c1\"><span class=\"pl-k\">.</span>FOR_INTERNAL_STORAGE</span>, <span class=\"pl-s\"><span class=\"pl-pds x x-first\">\"</span><span class=\"x\">true</span><span class=\"pl-pds x x-last\">\"</span></span>));</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"40\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">        <span class=\"pl-k\">return</span> <span class=\"pl-k\">new</span> <span class=\"pl-smi\">ToXContent</span>.<span class=\"pl-smi\">MapParams</span>(<span class=\"pl-smi\">Collections</span><span class=\"pl-k\">.</span>singletonMap(<span class=\"pl-smi\">ToXContentParams</span><span class=\"pl-c1\"><span class=\"pl-k\">.</span>FOR_INTERNAL_STORAGE</span>, <span class=\"pl-smi x x-first\">Boolean</span><span class=\"pl-k x\">.</span><span class=\"x x-last\">toString(lenient</span>));</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n\n<p dir=\"auto\">I think will work so that the empty parsing declaration for <code>TYPE</code> can go away.</p>", "author": "benwtrent", "createdAt": "2020-02-26T20:00:02Z", "path": "x-pack/plugin/core/src/test/java/org/elasticsearch/xpack/core/ml/dataframe/stats/MemoryUsageTests.java", "diffHunk": "@@ -0,0 +1,56 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.core.ml.dataframe.stats;\n+\n+import org.elasticsearch.common.io.stream.Writeable;\n+import org.elasticsearch.common.xcontent.ToXContent;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.test.AbstractSerializingTestCase;\n+import org.elasticsearch.xpack.core.ml.utils.ToXContentParams;\n+import org.junit.Before;\n+\n+import java.io.IOException;\n+import java.time.Instant;\n+import java.util.Collections;\n+\n+public class MemoryUsageTests extends AbstractSerializingTestCase<MemoryUsage> {\n+\n+    private boolean lenient;\n+\n+    @Before\n+    public void chooseStrictOrLenient() {\n+        lenient = randomBoolean();\n+    }\n+\n+    @Override\n+    protected boolean supportsUnknownFields() {\n+        return lenient;\n+    }\n+\n+    @Override\n+    protected MemoryUsage doParseInstance(XContentParser parser) throws IOException {\n+        return lenient ? MemoryUsage.LENIENT_PARSER.parse(parser, null) : MemoryUsage.STRICT_PARSER.parse(parser, null);\n+    }\n+\n+    @Override\n+    protected ToXContent.Params getToXContentParams() {\n+        return new ToXContent.MapParams(Collections.singletonMap(ToXContentParams.FOR_INTERNAL_STORAGE, \"true\"));", "originalCommit": "6333b38ea14ee908d9be870ca4d0edc158a37dda", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTY1MTU4Ng==", "url": "https://github.com/elastic/elasticsearch/pull/52778#discussion_r385651586", "bodyText": "The problem is we also only write out job_id for internal storage. Then we can't test for equality. Given that, I think I'd rather keep parsing TYPE.", "author": "dimitris-athanasiou", "createdAt": "2020-02-28T11:43:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDczMjA3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDczNzM2NA==", "url": "https://github.com/elastic/elasticsearch/pull/52778#discussion_r384737364", "body": "I wonder if we will hit scaling issues if there are 100s of stopped tasks. \r\n\r\nSeems like we could be making 100s of unbatched, search requests. ", "bodyText": "I wonder if we will hit scaling issues if there are 100s of stopped tasks.\nSeems like we could be making 100s of unbatched, search requests.", "bodyHTML": "<p dir=\"auto\">I wonder if we will hit scaling issues if there are 100s of stopped tasks.</p>\n<p dir=\"auto\">Seems like we could be making 100s of unbatched, search requests.</p>", "author": "benwtrent", "createdAt": "2020-02-26T20:09:57Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/action/TransportGetDataFrameAnalyticsStatsAction.java", "diffHunk": "@@ -157,75 +160,99 @@ void gatherStatsForStoppedTasks(List<String> expandedIds, GetDataFrameAnalyticsS\n             return;\n         }\n \n-        searchStoredProgresses(stoppedTasksIds, ActionListener.wrap(\n-            storedProgresses -> {\n-                List<Stats> stoppedStats = new ArrayList<>(stoppedTasksIds.size());\n-                for (int i = 0; i < stoppedTasksIds.size(); i++) {\n-                    String configId = stoppedTasksIds.get(i);\n-                    StoredProgress storedProgress = storedProgresses.get(i);\n-                    stoppedStats.add(buildStats(configId, storedProgress.get()));\n-                }\n-                List<Stats> allTasksStats = new ArrayList<>(runningTasksResponse.getResponse().results());\n-                allTasksStats.addAll(stoppedStats);\n-                Collections.sort(allTasksStats, Comparator.comparing(Stats::getId));\n-                listener.onResponse(new GetDataFrameAnalyticsStatsAction.Response(new QueryPage<>(\n-                    allTasksStats, allTasksStats.size(), GetDataFrameAnalyticsAction.Response.RESULTS_FIELD)));\n-            },\n-            listener::onFailure\n-        ));\n+        AtomicInteger counter = new AtomicInteger(stoppedTasksIds.size());\n+        AtomicArray<Stats> jobStats = new AtomicArray<>(stoppedTasksIds.size());\n+        for (int i = 0; i < stoppedTasksIds.size(); i++) {", "originalCommit": "6333b38ea14ee908d9be870ca4d0edc158a37dda", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTY1NjY4Nw==", "url": "https://github.com/elastic/elasticsearch/pull/52778#discussion_r385656687", "bodyText": "This is why I changed the code to make a multi-search per job. If we batch everything up, then we have jobs * stats_fields searches in a single multi-search and that to have its own problems. We do it this way for anomaly detection jobs too. Not sure there's a better way.", "author": "dimitris-athanasiou", "createdAt": "2020-02-28T11:56:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDczNzM2NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDczOTYxMw==", "url": "https://github.com/elastic/elasticsearch/pull/52778#discussion_r384739613", "body": "\u2764\ufe0f ", "bodyText": "\u2764\ufe0f", "bodyHTML": "<p dir=\"auto\"><g-emoji class=\"g-emoji\" alias=\"heart\" fallback-src=\"https://github.githubassets.com/images/icons/emoji/unicode/2764.png\">\u2764\ufe0f</g-emoji></p>", "author": "benwtrent", "createdAt": "2020-02-26T20:14:49Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/utils/persistence/MlParserUtils.java", "diffHunk": "@@ -0,0 +1,42 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.utils.persistence;\n+\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.ElasticsearchParseException;\n+import org.elasticsearch.common.bytes.BytesReference;\n+import org.elasticsearch.common.xcontent.LoggingDeprecationHandler;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.common.xcontent.XContentFactory;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.common.xcontent.XContentType;\n+import org.elasticsearch.search.SearchHit;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.function.BiFunction;\n+\n+public final class MlParserUtils {", "originalCommit": "6333b38ea14ee908d9be870ca4d0edc158a37dda", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "f9ad144a7ca71022b7936250e982cf455c495aac", "url": "https://github.com/elastic/elasticsearch/commit/f9ad144a7ca71022b7936250e982cf455c495aac", "message": "[ML] Parse and report memory usage for DF Analytics\n\nAdds reporting of memory usage for data frame analytics jobs.\nThis commit introduces a new index pattern `.ml-stats-*` whose\nfirst concrete index will be `.ml-stats-000001`. This index serves\nto store instrumentation information for those jobs.", "committedDate": "2020-02-28T13:55:22Z", "type": "commit"}, {"oid": "b31415793bda55d58f336b8500a02b5fde70abf1", "url": "https://github.com/elastic/elasticsearch/commit/b31415793bda55d58f336b8500a02b5fde70abf1", "message": "Address review comments about index creation", "committedDate": "2020-02-28T13:55:23Z", "type": "commit"}, {"oid": "1a911ebe02cf21ba6a0ea5c1a4c8659097fca1db", "url": "https://github.com/elastic/elasticsearch/commit/1a911ebe02cf21ba6a0ea5c1a4c8659097fca1db", "message": "Deprecate TimeUtils methods that handle epoch seconds", "committedDate": "2020-02-28T13:55:23Z", "type": "commit"}, {"oid": "3aba9671805ee4527f81d59684e17cb81c972bd3", "url": "https://github.com/elastic/elasticsearch/commit/3aba9671805ee4527f81d59684e17cb81c972bd3", "message": "Add comment for MemoryUsage.timestamp epoch millis rounding", "committedDate": "2020-02-28T13:55:23Z", "type": "commit"}, {"oid": "3aba9671805ee4527f81d59684e17cb81c972bd3", "url": "https://github.com/elastic/elasticsearch/commit/3aba9671805ee4527f81d59684e17cb81c972bd3", "message": "Add comment for MemoryUsage.timestamp epoch millis rounding", "committedDate": "2020-02-28T13:55:23Z", "type": "forcePushed"}]}