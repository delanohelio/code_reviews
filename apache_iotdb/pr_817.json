{"pr_number": 817, "pr_title": "[IOTDB-497] Apache Flink Connector Support", "pr_author": "vesense", "pr_createdAt": "2020-02-17T05:18:15Z", "pr_url": "https://github.com/apache/iotdb/pull/817", "timeline": [{"oid": "0afa4fec8da67852490c03af70e29ebb04e4429f", "url": "https://github.com/apache/iotdb/commit/0afa4fec8da67852490c03af70e29ebb04e4429f", "message": "[IOTDB-497] Apache Flink Connector Support", "committedDate": "2020-02-17T05:09:24Z", "type": "commit"}, {"oid": "d74e6cbb325f5fbdac7e019356eb953dcad6a427", "url": "https://github.com/apache/iotdb/commit/d74e6cbb325f5fbdac7e019356eb953dcad6a427", "message": "[IOTDB-503] Add checkTimeseriesExists for session", "committedDate": "2020-02-18T14:17:18Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDcyMDk4MQ==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r380720981", "body": "Hi, is that possible to get the datatype of the sensor?\r\nAs IoTDB compresses int/long/float/double better than text, and in some applications, users know what data type their data is.\r\n\r\nBy the way, it is recommended that using CompressionType.SNAPPY by default.  \r\n\r\n", "bodyText": "Hi, is that possible to get the datatype of the sensor?\nAs IoTDB compresses int/long/float/double better than text, and in some applications, users know what data type their data is.\nBy the way, it is recommended that using CompressionType.SNAPPY by default.", "bodyHTML": "<p dir=\"auto\">Hi, is that possible to get the datatype of the sensor?<br>\nAs IoTDB compresses int/long/float/double better than text, and in some applications, users know what data type their data is.</p>\n<p dir=\"auto\">By the way, it is recommended that using CompressionType.SNAPPY by default.</p>", "author": "jixuan1989", "createdAt": "2020-02-18T14:52:52Z", "path": "flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java", "diffHunk": "@@ -0,0 +1,155 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.iotdb.flink;\n+\n+import com.google.common.collect.Lists;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.runtime.state.FunctionInitializationContext;\n+import org.apache.flink.runtime.state.FunctionSnapshotContext;\n+import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;\n+import org.apache.flink.streaming.api.functions.sink.RichSinkFunction;\n+import org.apache.flink.streaming.api.operators.StreamingRuntimeContext;\n+import org.apache.iotdb.service.rpc.thrift.TSStatus;\n+import org.apache.iotdb.session.Session;\n+import org.apache.iotdb.tsfile.file.metadata.enums.CompressionType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSEncoding;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+public class IoTDBSink<IN> extends RichSinkFunction<IN> implements CheckpointedFunction {\n+\n+    private static final long serialVersionUID = 1L;\n+    private static final Logger LOG = LoggerFactory.getLogger(IoTDBSink.class);\n+\n+    private IoTSerializationSchema<IN> serializationSchema;\n+    private IoTDBOptions options;\n+    private transient Session session;\n+\n+    private boolean batchFlushOnCheckpoint; // false by default\n+    private int batchSize = 100;\n+    private List<Event> batchList;\n+\n+    public IoTDBSink(IoTDBOptions options, IoTSerializationSchema<IN> schema) {\n+        this.options = options;\n+        this.serializationSchema = schema;\n+    }\n+\n+    @Override\n+    public void open(Configuration parameters) throws Exception {\n+        batchList = new LinkedList<>();\n+\n+        session = new Session(options.getHost(), options.getPort(), options.getUser(), options.getPassword());\n+        session.open();\n+\n+        session.setStorageGroup(options.getStorageGroup());\n+        for (String sensor : options.getTimeseries()) {\n+            session.createTimeseries(sensor, TSDataType.TEXT, TSEncoding.PLAIN, CompressionType.UNCOMPRESSED);", "originalCommit": "0afa4fec8da67852490c03af70e29ebb04e4429f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDcyNTI1Nw==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r380725257", "bodyText": "Good idea, I will update later.", "author": "vesense", "createdAt": "2020-02-18T14:59:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDcyMDk4MQ=="}], "type": "inlineReview", "revised_code": {"commit": "115b8cec1082524ff5ef18af2e4ede53762fdc8b", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\nindex cfa01f1686..e647323cd2 100644\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n", "chunk": "@@ -63,8 +59,10 @@ public class IoTDBSink<IN> extends RichSinkFunction<IN> implements CheckpointedF\n         session.open();\n \n         session.setStorageGroup(options.getStorageGroup());\n-        for (String sensor : options.getTimeseries()) {\n-            session.createTimeseries(sensor, TSDataType.TEXT, TSEncoding.PLAIN, CompressionType.UNCOMPRESSED);\n+        for (IoTDBOptions.TimeseriesOption option : options.getTimeseriesOptionList()) {\n+            if (!session.checkTimeseriesExists(option.getPath())) {\n+                session.createTimeseries(option.getPath(), option.getDataType(), option.getEncoding(), option.getCompressor());\n+            }\n         }\n \n         if (batchFlushOnCheckpoint && !((StreamingRuntimeContext) getRuntimeContext()).isCheckpointingEnabled()) {\n", "next_change": {"commit": "2f12978cc65cfc47f659b837e174d535fe2f53af", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\ndeleted file mode 100644\nindex e647323cd2..0000000000\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n+++ /dev/null\n", "chunk": "@@ -1,153 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.iotdb.flink;\n-\n-import org.apache.flink.configuration.Configuration;\n-import org.apache.flink.runtime.state.FunctionInitializationContext;\n-import org.apache.flink.runtime.state.FunctionSnapshotContext;\n-import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;\n-import org.apache.flink.streaming.api.functions.sink.RichSinkFunction;\n-import org.apache.flink.streaming.api.operators.StreamingRuntimeContext;\n-import org.apache.iotdb.service.rpc.thrift.TSStatus;\n-import org.apache.iotdb.session.Session;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import java.util.ArrayList;\n-import java.util.LinkedList;\n-import java.util.List;\n-\n-public class IoTDBSink<IN> extends RichSinkFunction<IN> implements CheckpointedFunction {\n-\n-    private static final long serialVersionUID = 1L;\n-    private static final Logger LOG = LoggerFactory.getLogger(IoTDBSink.class);\n-\n-    private IoTSerializationSchema<IN> serializationSchema;\n-    private IoTDBOptions options;\n-    private transient Session session;\n-\n-    private boolean batchFlushOnCheckpoint; // false by default\n-    private int batchSize = 100;\n-    private List<Event> batchList;\n-\n-    public IoTDBSink(IoTDBOptions options, IoTSerializationSchema<IN> schema) {\n-        this.options = options;\n-        this.serializationSchema = schema;\n-    }\n-\n-    @Override\n-    public void open(Configuration parameters) throws Exception {\n-        batchList = new LinkedList<>();\n-\n-        session = new Session(options.getHost(), options.getPort(), options.getUser(), options.getPassword());\n-        session.open();\n-\n-        session.setStorageGroup(options.getStorageGroup());\n-        for (IoTDBOptions.TimeseriesOption option : options.getTimeseriesOptionList()) {\n-            if (!session.checkTimeseriesExists(option.getPath())) {\n-                session.createTimeseries(option.getPath(), option.getDataType(), option.getEncoding(), option.getCompressor());\n-            }\n-        }\n-\n-        if (batchFlushOnCheckpoint && !((StreamingRuntimeContext) getRuntimeContext()).isCheckpointingEnabled()) {\n-            LOG.warn(\"Flushing on checkpoint is enabled, but checkpointing is not enabled. Disabling flushing.\");\n-            batchFlushOnCheckpoint = false;\n-        }\n-    }\n-\n-    //  for testing\n-    void setSession(Session session) {\n-        this.session = session;\n-    }\n-\n-    @Override\n-    public void invoke(IN input, Context context) throws Exception {\n-        Event event = serializationSchema.serialize(input);\n-        if (event == null) {\n-            return;\n-        }\n-\n-        if (batchFlushOnCheckpoint) {\n-            batchList.add(event);\n-            if (batchList.size() >= batchSize) {\n-                flushSync();\n-            }\n-            return;\n-        }\n-\n-        TSStatus status = session.insert(event.getDevice(), event.getTimestamp(),\n-                event.getMeasurements(), event.getValues());\n-        LOG.debug(\"sync send event result: {}\", status);\n-    }\n-\n-    public IoTDBSink<IN> withBatchFlushOnCheckpoint(boolean batchFlushOnCheckpoint) {\n-        this.batchFlushOnCheckpoint = batchFlushOnCheckpoint;\n-        return this;\n-    }\n-\n-    public IoTDBSink<IN> withBatchSize(int batchSize) {\n-        this.batchSize = batchSize;\n-        return this;\n-    }\n-\n-    @Override\n-    public void close() throws Exception {\n-        if (session != null) {\n-            try {\n-                flushSync();\n-            } catch (Exception e) {\n-                LOG.error(\"flushSync failure\", e);\n-            }\n-           session.close();\n-        }\n-    }\n-\n-    private void flushSync() throws Exception {\n-        if (batchFlushOnCheckpoint) {\n-            synchronized (batchList) {\n-                if (batchList.size() > 0) {\n-                    List<String> deviceIds = new ArrayList<>();\n-                    List<Long> timestamps = new ArrayList<>();\n-                    List<List<String>> measurementsList = new ArrayList<>();\n-                    List<List<String>> valuesList = new ArrayList<>();\n-\n-                    for (Event event : batchList) {\n-                        deviceIds.add(event.getDevice());\n-                        timestamps.add(event.getTimestamp());\n-                        measurementsList.add(event.getMeasurements());\n-                        valuesList.add(event.getValues());\n-                    }\n-                    List<TSStatus> statusList = session.insertInBatch(deviceIds, timestamps, measurementsList, valuesList);\n-                    LOG.debug(\"sync send events result: {}\", statusList);\n-                    batchList.clear();\n-                }\n-            }\n-        }\n-    }\n-\n-    @Override\n-    public void snapshotState(FunctionSnapshotContext context) throws Exception {\n-        flushSync();\n-    }\n-\n-    @Override\n-    public void initializeState(FunctionInitializationContext context) throws Exception {\n-        // nothing to do\n-    }\n-}\n", "next_change": {"commit": "b10c17af87692b9992a07eabd224bf4407600937", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\nnew file mode 100644\nindex 0000000000..e647323cd2\n--- /dev/null\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n", "chunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.iotdb.flink;\n+\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.runtime.state.FunctionInitializationContext;\n+import org.apache.flink.runtime.state.FunctionSnapshotContext;\n+import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;\n+import org.apache.flink.streaming.api.functions.sink.RichSinkFunction;\n+import org.apache.flink.streaming.api.operators.StreamingRuntimeContext;\n+import org.apache.iotdb.service.rpc.thrift.TSStatus;\n+import org.apache.iotdb.session.Session;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+public class IoTDBSink<IN> extends RichSinkFunction<IN> implements CheckpointedFunction {\n+\n+    private static final long serialVersionUID = 1L;\n+    private static final Logger LOG = LoggerFactory.getLogger(IoTDBSink.class);\n+\n+    private IoTSerializationSchema<IN> serializationSchema;\n+    private IoTDBOptions options;\n+    private transient Session session;\n+\n+    private boolean batchFlushOnCheckpoint; // false by default\n+    private int batchSize = 100;\n+    private List<Event> batchList;\n+\n+    public IoTDBSink(IoTDBOptions options, IoTSerializationSchema<IN> schema) {\n+        this.options = options;\n+        this.serializationSchema = schema;\n+    }\n+\n+    @Override\n+    public void open(Configuration parameters) throws Exception {\n+        batchList = new LinkedList<>();\n+\n+        session = new Session(options.getHost(), options.getPort(), options.getUser(), options.getPassword());\n+        session.open();\n+\n+        session.setStorageGroup(options.getStorageGroup());\n+        for (IoTDBOptions.TimeseriesOption option : options.getTimeseriesOptionList()) {\n+            if (!session.checkTimeseriesExists(option.getPath())) {\n+                session.createTimeseries(option.getPath(), option.getDataType(), option.getEncoding(), option.getCompressor());\n+            }\n+        }\n+\n+        if (batchFlushOnCheckpoint && !((StreamingRuntimeContext) getRuntimeContext()).isCheckpointingEnabled()) {\n+            LOG.warn(\"Flushing on checkpoint is enabled, but checkpointing is not enabled. Disabling flushing.\");\n+            batchFlushOnCheckpoint = false;\n+        }\n+    }\n+\n+    //  for testing\n+    void setSession(Session session) {\n+        this.session = session;\n+    }\n+\n+    @Override\n+    public void invoke(IN input, Context context) throws Exception {\n+        Event event = serializationSchema.serialize(input);\n+        if (event == null) {\n+            return;\n+        }\n+\n+        if (batchFlushOnCheckpoint) {\n+            batchList.add(event);\n+            if (batchList.size() >= batchSize) {\n+                flushSync();\n+            }\n+            return;\n+        }\n+\n+        TSStatus status = session.insert(event.getDevice(), event.getTimestamp(),\n+                event.getMeasurements(), event.getValues());\n+        LOG.debug(\"sync send event result: {}\", status);\n+    }\n+\n+    public IoTDBSink<IN> withBatchFlushOnCheckpoint(boolean batchFlushOnCheckpoint) {\n+        this.batchFlushOnCheckpoint = batchFlushOnCheckpoint;\n+        return this;\n+    }\n+\n+    public IoTDBSink<IN> withBatchSize(int batchSize) {\n+        this.batchSize = batchSize;\n+        return this;\n+    }\n+\n+    @Override\n+    public void close() throws Exception {\n+        if (session != null) {\n+            try {\n+                flushSync();\n+            } catch (Exception e) {\n+                LOG.error(\"flushSync failure\", e);\n+            }\n+           session.close();\n+        }\n+    }\n+\n+    private void flushSync() throws Exception {\n+        if (batchFlushOnCheckpoint) {\n+            synchronized (batchList) {\n+                if (batchList.size() > 0) {\n+                    List<String> deviceIds = new ArrayList<>();\n+                    List<Long> timestamps = new ArrayList<>();\n+                    List<List<String>> measurementsList = new ArrayList<>();\n+                    List<List<String>> valuesList = new ArrayList<>();\n+\n+                    for (Event event : batchList) {\n+                        deviceIds.add(event.getDevice());\n+                        timestamps.add(event.getTimestamp());\n+                        measurementsList.add(event.getMeasurements());\n+                        valuesList.add(event.getValues());\n+                    }\n+                    List<TSStatus> statusList = session.insertInBatch(deviceIds, timestamps, measurementsList, valuesList);\n+                    LOG.debug(\"sync send events result: {}\", statusList);\n+                    batchList.clear();\n+                }\n+            }\n+        }\n+    }\n+\n+    @Override\n+    public void snapshotState(FunctionSnapshotContext context) throws Exception {\n+        flushSync();\n+    }\n+\n+    @Override\n+    public void initializeState(FunctionInitializationContext context) throws Exception {\n+        // nothing to do\n+    }\n+}\n", "next_change": {"commit": "83fc8b53ff4a3bdab7f7839b195ca8addb09901e", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\nindex e647323cd2..fa7d2a1f02 100644\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n", "chunk": "@@ -110,44 +128,34 @@ public class IoTDBSink<IN> extends RichSinkFunction<IN> implements CheckpointedF\n     public void close() throws Exception {\n         if (session != null) {\n             try {\n-                flushSync();\n+                flush();\n             } catch (Exception e) {\n-                LOG.error(\"flushSync failure\", e);\n+                LOG.error(\"flush error\", e);\n             }\n-           session.close();\n+            session.close();\n+        }\n+        if (scheduledExecutor != null) {\n+            scheduledExecutor.shutdown();\n         }\n     }\n \n-    private void flushSync() throws Exception {\n-        if (batchFlushOnCheckpoint) {\n-            synchronized (batchList) {\n-                if (batchList.size() > 0) {\n-                    List<String> deviceIds = new ArrayList<>();\n-                    List<Long> timestamps = new ArrayList<>();\n-                    List<List<String>> measurementsList = new ArrayList<>();\n-                    List<List<String>> valuesList = new ArrayList<>();\n-\n-                    for (Event event : batchList) {\n-                        deviceIds.add(event.getDevice());\n-                        timestamps.add(event.getTimestamp());\n-                        measurementsList.add(event.getMeasurements());\n-                        valuesList.add(event.getValues());\n-                    }\n-                    List<TSStatus> statusList = session.insertInBatch(deviceIds, timestamps, measurementsList, valuesList);\n-                    LOG.debug(\"sync send events result: {}\", statusList);\n-                    batchList.clear();\n-                }\n+    private synchronized void flush() throws Exception {\n+        if (batchSize > 0 && batchList.size() > 0) {\n+            List<String> deviceIds = new ArrayList<>();\n+            List<Long> timestamps = new ArrayList<>();\n+            List<List<String>> measurementsList = new ArrayList<>();\n+            List<List<String>> valuesList = new ArrayList<>();\n+\n+            for (Event event : batchList) {\n+                deviceIds.add(event.getDevice());\n+                timestamps.add(event.getTimestamp());\n+                measurementsList.add(event.getMeasurements());\n+                valuesList.add(event.getValues());\n             }\n+            List<TSStatus> statusList = session.insertInBatch(deviceIds, timestamps, measurementsList, valuesList);\n+            LOG.debug(\"send events result: {}\", statusList);\n+            batchList.clear();\n         }\n     }\n \n-    @Override\n-    public void snapshotState(FunctionSnapshotContext context) throws Exception {\n-        flushSync();\n-    }\n-\n-    @Override\n-    public void initializeState(FunctionInitializationContext context) throws Exception {\n-        // nothing to do\n-    }\n }\n", "next_change": {"commit": "7b693c5b6c14bb3528e0fab31aaa033a3318507d", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\nindex fa7d2a1f02..0495fac617 100644\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n", "chunk": "@@ -139,22 +148,38 @@ public class IoTDBSink<IN> extends RichSinkFunction<IN> {\n         }\n     }\n \n-    private synchronized void flush() throws Exception {\n-        if (batchSize > 0 && batchList.size() > 0) {\n-            List<String> deviceIds = new ArrayList<>();\n-            List<Long> timestamps = new ArrayList<>();\n-            List<List<String>> measurementsList = new ArrayList<>();\n-            List<List<String>> valuesList = new ArrayList<>();\n-\n-            for (Event event : batchList) {\n-                deviceIds.add(event.getDevice());\n-                timestamps.add(event.getTimestamp());\n-                measurementsList.add(event.getMeasurements());\n-                valuesList.add(event.getValues());\n+    private void convertText(String device, List<String> measurements, List<String> values) {\n+        if (device != null && measurements != null && values != null && measurements.size() == values.size()) {\n+            for (int i = 0; i < measurements.size(); i++) {\n+                String measurement = device + \".\" + measurements.get(i);\n+                IoTDBOptions.TimeseriesOption timeseriesOption = timeseriesOptionMap.get(measurement);\n+                if (timeseriesOption!= null && TSDataType.TEXT.equals(timeseriesOption.getDataType())) {\n+                    // The TEXT data type should be covered by \" or '\n+                    values.set(i, \"'\" + values.get(i) + \"'\");\n+                }\n+            }\n+        }\n+    }\n+\n+    private void flush() throws Exception {\n+        synchronized (batchList) {\n+            if (batchSize > 0 && batchList.size() > 0) {\n+                List<String> deviceIds = new ArrayList<>();\n+                List<Long> timestamps = new ArrayList<>();\n+                List<List<String>> measurementsList = new ArrayList<>();\n+                List<List<String>> valuesList = new ArrayList<>();\n+\n+                for (Event event : batchList) {\n+                    convertText(event.getDevice(), event.getMeasurements(), event.getValues());\n+                    deviceIds.add(event.getDevice());\n+                    timestamps.add(event.getTimestamp());\n+                    measurementsList.add(event.getMeasurements());\n+                    valuesList.add(event.getValues());\n+                }\n+                List<TSStatus> statusList = session.insertInBatch(deviceIds, timestamps, measurementsList, valuesList);\n+                LOG.debug(\"send events result: {}\", statusList);\n+                batchList.clear();\n             }\n-            List<TSStatus> statusList = session.insertInBatch(deviceIds, timestamps, measurementsList, valuesList);\n-            LOG.debug(\"send events result: {}\", statusList);\n-            batchList.clear();\n         }\n     }\n \n", "next_change": {"commit": "78778429d60212a6b983d855a955c07e3d93eb69", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\nindex 0495fac617..cda69c0773 100644\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n", "chunk": "@@ -162,23 +162,25 @@ public class IoTDBSink<IN> extends RichSinkFunction<IN> {\n     }\n \n     private void flush() throws Exception {\n-        synchronized (batchList) {\n-            if (batchSize > 0 && batchList.size() > 0) {\n-                List<String> deviceIds = new ArrayList<>();\n-                List<Long> timestamps = new ArrayList<>();\n-                List<List<String>> measurementsList = new ArrayList<>();\n-                List<List<String>> valuesList = new ArrayList<>();\n-\n-                for (Event event : batchList) {\n-                    convertText(event.getDevice(), event.getMeasurements(), event.getValues());\n-                    deviceIds.add(event.getDevice());\n-                    timestamps.add(event.getTimestamp());\n-                    measurementsList.add(event.getMeasurements());\n-                    valuesList.add(event.getValues());\n+        if (batchSize > 0) {\n+            synchronized (batchList) {\n+                if (batchList.size() > 0) {\n+                    List<String> deviceIds = new ArrayList<>();\n+                    List<Long> timestamps = new ArrayList<>();\n+                    List<List<String>> measurementsList = new ArrayList<>();\n+                    List<List<String>> valuesList = new ArrayList<>();\n+\n+                    for (Event event : batchList) {\n+                        convertText(event.getDevice(), event.getMeasurements(), event.getValues());\n+                        deviceIds.add(event.getDevice());\n+                        timestamps.add(event.getTimestamp());\n+                        measurementsList.add(event.getMeasurements());\n+                        valuesList.add(event.getValues());\n+                    }\n+                    List<TSStatus> statusList = session.insertInBatch(deviceIds, timestamps, measurementsList, valuesList);\n+                    LOG.debug(\"send events result: {}\", statusList);\n+                    batchList.clear();\n                 }\n-                List<TSStatus> statusList = session.insertInBatch(deviceIds, timestamps, measurementsList, valuesList);\n-                LOG.debug(\"send events result: {}\", statusList);\n-                batchList.clear();\n             }\n         }\n     }\n", "next_change": {"commit": "32f32f62f62a5fdb59fa751a00556505fb604114", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\nindex cda69c0773..1f405d631d 100644\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n", "chunk": "@@ -184,5 +184,4 @@ public class IoTDBSink<IN> extends RichSinkFunction<IN> {\n             }\n         }\n     }\n-\n }\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDcyNTY0Mw==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r380725643", "body": "In many applications, when a monitored device sends data to the server, it does not just send one data point. \r\nInstead, it sends a \"row\", i.e., several measurements and their values. (And in some applications, they even sends data with several timestamps, but it is not very common.) \r\nAs far as I know, a device may have more than 100 measurements in the industrial applications. In this case, splitting a \"row\" into many Events may burden Flink as well as IoTDB (because there are too many small TCP packets).\r\n\r\nHow do you think?\r\n\r\n ", "bodyText": "In many applications, when a monitored device sends data to the server, it does not just send one data point.\nInstead, it sends a \"row\", i.e., several measurements and their values. (And in some applications, they even sends data with several timestamps, but it is not very common.)\nAs far as I know, a device may have more than 100 measurements in the industrial applications. In this case, splitting a \"row\" into many Events may burden Flink as well as IoTDB (because there are too many small TCP packets).\nHow do you think?", "bodyHTML": "<p dir=\"auto\">In many applications, when a monitored device sends data to the server, it does not just send one data point.<br>\nInstead, it sends a \"row\", i.e., several measurements and their values. (And in some applications, they even sends data with several timestamps, but it is not very common.)<br>\nAs far as I know, a device may have more than 100 measurements in the industrial applications. In this case, splitting a \"row\" into many Events may burden Flink as well as IoTDB (because there are too many small TCP packets).</p>\n<p dir=\"auto\">How do you think?</p>", "author": "jixuan1989", "createdAt": "2020-02-18T14:59:40Z", "path": "flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/Event.java", "diffHunk": "@@ -0,0 +1,49 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.iotdb.flink;\n+\n+public class Event {\n+    private String device;\n+    private Long timestamp;\n+    private String measurement;", "originalCommit": "0afa4fec8da67852490c03af70e29ebb04e4429f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDczMzgxOQ==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r380733819", "bodyText": "Make sense. We should support most scenarios. Will update.\n@jixuan1989 Thanks for your input.", "author": "vesense", "createdAt": "2020-02-18T15:11:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDcyNTY0Mw=="}], "type": "inlineReview", "revised_code": {"commit": "115b8cec1082524ff5ef18af2e4ede53762fdc8b", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/Event.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/Event.java\nindex 28442b06ea..a03e091bcd 100644\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/Event.java\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/Event.java\n", "chunk": "@@ -18,17 +18,19 @@\n \n package org.apache.iotdb.flink;\n \n+import java.util.List;\n+\n public class Event {\n     private String device;\n     private Long timestamp;\n-    private String measurement;\n-    private String value;\n+    private List<String> measurements;\n+    private List<String> values;\n \n-    public Event(String device, Long timestamp, String measurement, String value) {\n+    public Event(String device, Long timestamp, List<String> measurements, List<String> values) {\n         this.device = device;\n         this.timestamp = timestamp;\n-        this.measurement = measurement;\n-        this.value = value;\n+        this.measurements = measurements;\n+        this.values = values;\n     }\n \n     public String getDevice() {\n", "next_change": {"commit": "2f12978cc65cfc47f659b837e174d535fe2f53af", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/Event.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/Event.java\ndeleted file mode 100644\nindex a03e091bcd..0000000000\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/Event.java\n+++ /dev/null\n", "chunk": "@@ -1,51 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.iotdb.flink;\n-\n-import java.util.List;\n-\n-public class Event {\n-    private String device;\n-    private Long timestamp;\n-    private List<String> measurements;\n-    private List<String> values;\n-\n-    public Event(String device, Long timestamp, List<String> measurements, List<String> values) {\n-        this.device = device;\n-        this.timestamp = timestamp;\n-        this.measurements = measurements;\n-        this.values = values;\n-    }\n-\n-    public String getDevice() {\n-        return device;\n-    }\n-\n-    public Long getTimestamp() {\n-        return timestamp;\n-    }\n-\n-    public List<String> getMeasurements() {\n-        return measurements;\n-    }\n-\n-    public List<String> getValues() {\n-        return values;\n-    }\n-}\n\\ No newline at end of file\n", "next_change": {"commit": "b10c17af87692b9992a07eabd224bf4407600937", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/Event.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/Event.java\nnew file mode 100644\nindex 0000000000..a03e091bcd\n--- /dev/null\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/Event.java\n", "chunk": "@@ -0,0 +1,51 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.iotdb.flink;\n+\n+import java.util.List;\n+\n+public class Event {\n+    private String device;\n+    private Long timestamp;\n+    private List<String> measurements;\n+    private List<String> values;\n+\n+    public Event(String device, Long timestamp, List<String> measurements, List<String> values) {\n+        this.device = device;\n+        this.timestamp = timestamp;\n+        this.measurements = measurements;\n+        this.values = values;\n+    }\n+\n+    public String getDevice() {\n+        return device;\n+    }\n+\n+    public Long getTimestamp() {\n+        return timestamp;\n+    }\n+\n+    public List<String> getMeasurements() {\n+        return measurements;\n+    }\n+\n+    public List<String> getValues() {\n+        return values;\n+    }\n+}\n\\ No newline at end of file\n", "next_change": {"commit": "83fc8b53ff4a3bdab7f7839b195ca8addb09901e", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/Event.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/Event.java\nindex a03e091bcd..6cccb23353 100644\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/Event.java\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/Event.java\n", "chunk": "@@ -48,4 +51,4 @@ public class Event {\n     public List<String> getValues() {\n         return values;\n     }\n-}\n\\ No newline at end of file\n+}\n", "next_change": null}]}}]}}]}}]}}, {"oid": "d2e23005a92add66988556579f4bf412741b7733", "url": "https://github.com/apache/iotdb/commit/d2e23005a92add66988556579f4bf412741b7733", "message": "[IOTDB-503] Add checkTimeseriesExists for session", "committedDate": "2020-02-20T15:27:01Z", "type": "commit"}, {"oid": "115b8cec1082524ff5ef18af2e4ede53762fdc8b", "url": "https://github.com/apache/iotdb/commit/115b8cec1082524ff5ef18af2e4ede53762fdc8b", "message": "[IOTDB-497] Addressed review comments", "committedDate": "2020-02-20T15:32:09Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg1NzQ3NA==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r382857474", "body": "Add newline at end of file.", "bodyText": "Add newline at end of file.", "bodyHTML": "<p dir=\"auto\">Add newline at end of file.</p>", "author": "sunjincheng121", "createdAt": "2020-02-21T23:50:19Z", "path": "flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java", "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.iotdb.flink;\n+\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+public class DefaultIoTSerializationSchema implements IoTSerializationSchema<Map<String,String>> {\n+    public static final String FIELD_DEVICE = \"device\";\n+    public static final String FIELD_TIMESTAMP = \"timestamp\";\n+    public static final String FIELD_MEASUREMENTS = \"measurements\";\n+    public static final String FIELD_VALUES = \"values\";\n+    public static final String DEFAULT_SEPARATOR = \",\";\n+\n+    private Map<String, IoTDBOptions.TimeseriesOption> timeseriesOptionMap;\n+\n+    public DefaultIoTSerializationSchema(IoTDBOptions ioTDBOptions) {\n+        timeseriesOptionMap = new HashMap<>();\n+        for (IoTDBOptions.TimeseriesOption timeseriesOption : ioTDBOptions.getTimeseriesOptionList()) {\n+            timeseriesOptionMap.put(timeseriesOption.getPath(), timeseriesOption);\n+        }\n+    }\n+\n+    @Override\n+    public Event serialize(Map<String,String> tuple) {\n+        if (tuple == null) {\n+            return null;\n+        }\n+\n+        String device = tuple.get(FIELD_DEVICE);\n+\n+        String ts = tuple.get(FIELD_TIMESTAMP);\n+        Long timestamp = ts == null ? System.currentTimeMillis() : Long.parseLong(ts);\n+\n+        List<String> measurements = null;\n+        if (tuple.get(FIELD_MEASUREMENTS) != null) {\n+            measurements = Arrays.asList(tuple.get(FIELD_MEASUREMENTS).split(DEFAULT_SEPARATOR));\n+        }\n+\n+        List<String> values = null;\n+        if (tuple.get(FIELD_VALUES) != null) {\n+            values = Arrays.asList(tuple.get(FIELD_VALUES).split(DEFAULT_SEPARATOR));\n+        }\n+\n+        if (device != null && measurements != null && values != null && measurements.size() == values.size()) {\n+            for (int i = 0; i < measurements.size(); i++) {\n+                String measurement = device + \".\" + measurements.get(i);\n+                IoTDBOptions.TimeseriesOption timeseriesOption = timeseriesOptionMap.get(measurement);\n+                if (timeseriesOption!= null && TSDataType.TEXT.equals(timeseriesOption.getDataType())) {\n+                    // The TEXT data type should be covered by \" or '\n+                    values.set(i, \"'\" + values.get(i) + \"'\");\n+                }\n+            }\n+        }\n+\n+        return new Event(device, timestamp, measurements, values);\n+    }\n+}", "originalCommit": "115b8cec1082524ff5ef18af2e4ede53762fdc8b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjkwNzE1OA==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r382907158", "bodyText": "Will update.", "author": "vesense", "createdAt": "2020-02-22T11:46:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg1NzQ3NA=="}], "type": "inlineReview", "revised_code": {"commit": "2f12978cc65cfc47f659b837e174d535fe2f53af", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java\ndeleted file mode 100644\nindex 0da9d8a214..0000000000\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java\n+++ /dev/null\n", "chunk": "@@ -1,78 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.iotdb.flink;\n-\n-import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n-\n-import java.util.Arrays;\n-import java.util.HashMap;\n-import java.util.List;\n-import java.util.Map;\n-\n-public class DefaultIoTSerializationSchema implements IoTSerializationSchema<Map<String,String>> {\n-    public static final String FIELD_DEVICE = \"device\";\n-    public static final String FIELD_TIMESTAMP = \"timestamp\";\n-    public static final String FIELD_MEASUREMENTS = \"measurements\";\n-    public static final String FIELD_VALUES = \"values\";\n-    public static final String DEFAULT_SEPARATOR = \",\";\n-\n-    private Map<String, IoTDBOptions.TimeseriesOption> timeseriesOptionMap;\n-\n-    public DefaultIoTSerializationSchema(IoTDBOptions ioTDBOptions) {\n-        timeseriesOptionMap = new HashMap<>();\n-        for (IoTDBOptions.TimeseriesOption timeseriesOption : ioTDBOptions.getTimeseriesOptionList()) {\n-            timeseriesOptionMap.put(timeseriesOption.getPath(), timeseriesOption);\n-        }\n-    }\n-\n-    @Override\n-    public Event serialize(Map<String,String> tuple) {\n-        if (tuple == null) {\n-            return null;\n-        }\n-\n-        String device = tuple.get(FIELD_DEVICE);\n-\n-        String ts = tuple.get(FIELD_TIMESTAMP);\n-        Long timestamp = ts == null ? System.currentTimeMillis() : Long.parseLong(ts);\n-\n-        List<String> measurements = null;\n-        if (tuple.get(FIELD_MEASUREMENTS) != null) {\n-            measurements = Arrays.asList(tuple.get(FIELD_MEASUREMENTS).split(DEFAULT_SEPARATOR));\n-        }\n-\n-        List<String> values = null;\n-        if (tuple.get(FIELD_VALUES) != null) {\n-            values = Arrays.asList(tuple.get(FIELD_VALUES).split(DEFAULT_SEPARATOR));\n-        }\n-\n-        if (device != null && measurements != null && values != null && measurements.size() == values.size()) {\n-            for (int i = 0; i < measurements.size(); i++) {\n-                String measurement = device + \".\" + measurements.get(i);\n-                IoTDBOptions.TimeseriesOption timeseriesOption = timeseriesOptionMap.get(measurement);\n-                if (timeseriesOption!= null && TSDataType.TEXT.equals(timeseriesOption.getDataType())) {\n-                    // The TEXT data type should be covered by \" or '\n-                    values.set(i, \"'\" + values.get(i) + \"'\");\n-                }\n-            }\n-        }\n-\n-        return new Event(device, timestamp, measurements, values);\n-    }\n-}\n\\ No newline at end of file\n", "next_change": {"commit": "b10c17af87692b9992a07eabd224bf4407600937", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java\nnew file mode 100644\nindex 0000000000..0da9d8a214\n--- /dev/null\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java\n", "chunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.iotdb.flink;\n+\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+public class DefaultIoTSerializationSchema implements IoTSerializationSchema<Map<String,String>> {\n+    public static final String FIELD_DEVICE = \"device\";\n+    public static final String FIELD_TIMESTAMP = \"timestamp\";\n+    public static final String FIELD_MEASUREMENTS = \"measurements\";\n+    public static final String FIELD_VALUES = \"values\";\n+    public static final String DEFAULT_SEPARATOR = \",\";\n+\n+    private Map<String, IoTDBOptions.TimeseriesOption> timeseriesOptionMap;\n+\n+    public DefaultIoTSerializationSchema(IoTDBOptions ioTDBOptions) {\n+        timeseriesOptionMap = new HashMap<>();\n+        for (IoTDBOptions.TimeseriesOption timeseriesOption : ioTDBOptions.getTimeseriesOptionList()) {\n+            timeseriesOptionMap.put(timeseriesOption.getPath(), timeseriesOption);\n+        }\n+    }\n+\n+    @Override\n+    public Event serialize(Map<String,String> tuple) {\n+        if (tuple == null) {\n+            return null;\n+        }\n+\n+        String device = tuple.get(FIELD_DEVICE);\n+\n+        String ts = tuple.get(FIELD_TIMESTAMP);\n+        Long timestamp = ts == null ? System.currentTimeMillis() : Long.parseLong(ts);\n+\n+        List<String> measurements = null;\n+        if (tuple.get(FIELD_MEASUREMENTS) != null) {\n+            measurements = Arrays.asList(tuple.get(FIELD_MEASUREMENTS).split(DEFAULT_SEPARATOR));\n+        }\n+\n+        List<String> values = null;\n+        if (tuple.get(FIELD_VALUES) != null) {\n+            values = Arrays.asList(tuple.get(FIELD_VALUES).split(DEFAULT_SEPARATOR));\n+        }\n+\n+        if (device != null && measurements != null && values != null && measurements.size() == values.size()) {\n+            for (int i = 0; i < measurements.size(); i++) {\n+                String measurement = device + \".\" + measurements.get(i);\n+                IoTDBOptions.TimeseriesOption timeseriesOption = timeseriesOptionMap.get(measurement);\n+                if (timeseriesOption!= null && TSDataType.TEXT.equals(timeseriesOption.getDataType())) {\n+                    // The TEXT data type should be covered by \" or '\n+                    values.set(i, \"'\" + values.get(i) + \"'\");\n+                }\n+            }\n+        }\n+\n+        return new Event(device, timestamp, measurements, values);\n+    }\n+}\n\\ No newline at end of file\n", "next_change": {"commit": "83fc8b53ff4a3bdab7f7839b195ca8addb09901e", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java\nindex 0da9d8a214..a439a94557 100644\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java\n", "chunk": "@@ -75,4 +79,4 @@ public class DefaultIoTSerializationSchema implements IoTSerializationSchema<Map\n \n         return new Event(device, timestamp, measurements, values);\n     }\n-}\n\\ No newline at end of file\n+}\n", "next_change": {"commit": "7b693c5b6c14bb3528e0fab31aaa033a3318507d", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java\nindex a439a94557..4ac596b5a4 100644\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java\n", "chunk": "@@ -51,32 +39,61 @@ public class DefaultIoTSerializationSchema implements IoTSerializationSchema<Map\n             return null;\n         }\n \n-        String device = tuple.get(FIELD_DEVICE);\n+        String device = tuple.get(fieldDevice);\n \n-        String ts = tuple.get(FIELD_TIMESTAMP);\n+        String ts = tuple.get(fieldTimestamp);\n         Long timestamp = ts == null ? System.currentTimeMillis() : Long.parseLong(ts);\n \n         List<String> measurements = null;\n-        if (tuple.get(FIELD_MEASUREMENTS) != null) {\n-            measurements = Arrays.asList(tuple.get(FIELD_MEASUREMENTS).split(DEFAULT_SEPARATOR));\n+        if (tuple.get(fieldMeasurements) != null) {\n+            measurements = Arrays.asList(tuple.get(fieldMeasurements).split(separator));\n         }\n \n         List<String> values = null;\n-        if (tuple.get(FIELD_VALUES) != null) {\n-            values = Arrays.asList(tuple.get(FIELD_VALUES).split(DEFAULT_SEPARATOR));\n-        }\n-\n-        if (device != null && measurements != null && values != null && measurements.size() == values.size()) {\n-            for (int i = 0; i < measurements.size(); i++) {\n-                String measurement = device + \".\" + measurements.get(i);\n-                IoTDBOptions.TimeseriesOption timeseriesOption = timeseriesOptionMap.get(measurement);\n-                if (timeseriesOption!= null && TSDataType.TEXT.equals(timeseriesOption.getDataType())) {\n-                    // The TEXT data type should be covered by \" or '\n-                    values.set(i, \"'\" + values.get(i) + \"'\");\n-                }\n-            }\n+        if (tuple.get(fieldValues) != null) {\n+            values = Arrays.asList(tuple.get(fieldValues).split(separator));\n         }\n \n         return new Event(device, timestamp, measurements, values);\n     }\n+\n+    public String getFieldDevice() {\n+        return fieldDevice;\n+    }\n+\n+    public void setFieldDevice(String fieldDevice) {\n+        this.fieldDevice = fieldDevice;\n+    }\n+\n+    public String getFieldTimestamp() {\n+        return fieldTimestamp;\n+    }\n+\n+    public void setFieldTimestamp(String fieldTimestamp) {\n+        this.fieldTimestamp = fieldTimestamp;\n+    }\n+\n+    public String getFieldMeasurements() {\n+        return fieldMeasurements;\n+    }\n+\n+    public void setFieldMeasurements(String fieldMeasurements) {\n+        this.fieldMeasurements = fieldMeasurements;\n+    }\n+\n+    public String getFieldValues() {\n+        return fieldValues;\n+    }\n+\n+    public void setFieldValues(String fieldValues) {\n+        this.fieldValues = fieldValues;\n+    }\n+\n+    public String getSeparator() {\n+        return separator;\n+    }\n+\n+    public void setSeparator(String separator) {\n+        this.separator = separator;\n+    }\n }\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg1NzUxMg==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r382857512", "body": "Add newline at end of file.", "bodyText": "Add newline at end of file.", "bodyHTML": "<p dir=\"auto\">Add newline at end of file.</p>", "author": "sunjincheng121", "createdAt": "2020-02-21T23:50:27Z", "path": "flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/Event.java", "diffHunk": "@@ -0,0 +1,51 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.iotdb.flink;\n+\n+import java.util.List;\n+\n+public class Event {\n+    private String device;\n+    private Long timestamp;\n+    private List<String> measurements;\n+    private List<String> values;\n+\n+    public Event(String device, Long timestamp, List<String> measurements, List<String> values) {\n+        this.device = device;\n+        this.timestamp = timestamp;\n+        this.measurements = measurements;\n+        this.values = values;\n+    }\n+\n+    public String getDevice() {\n+        return device;\n+    }\n+\n+    public Long getTimestamp() {\n+        return timestamp;\n+    }\n+\n+    public List<String> getMeasurements() {\n+        return measurements;\n+    }\n+\n+    public List<String> getValues() {\n+        return values;\n+    }\n+}", "originalCommit": "115b8cec1082524ff5ef18af2e4ede53762fdc8b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjkwNzE2NA==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r382907164", "bodyText": "Will update.", "author": "vesense", "createdAt": "2020-02-22T11:47:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg1NzUxMg=="}], "type": "inlineReview", "revised_code": {"commit": "2f12978cc65cfc47f659b837e174d535fe2f53af", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/Event.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/Event.java\ndeleted file mode 100644\nindex a03e091bcd..0000000000\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/Event.java\n+++ /dev/null\n", "chunk": "@@ -1,51 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.iotdb.flink;\n-\n-import java.util.List;\n-\n-public class Event {\n-    private String device;\n-    private Long timestamp;\n-    private List<String> measurements;\n-    private List<String> values;\n-\n-    public Event(String device, Long timestamp, List<String> measurements, List<String> values) {\n-        this.device = device;\n-        this.timestamp = timestamp;\n-        this.measurements = measurements;\n-        this.values = values;\n-    }\n-\n-    public String getDevice() {\n-        return device;\n-    }\n-\n-    public Long getTimestamp() {\n-        return timestamp;\n-    }\n-\n-    public List<String> getMeasurements() {\n-        return measurements;\n-    }\n-\n-    public List<String> getValues() {\n-        return values;\n-    }\n-}\n\\ No newline at end of file\n", "next_change": {"commit": "b10c17af87692b9992a07eabd224bf4407600937", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/Event.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/Event.java\nnew file mode 100644\nindex 0000000000..a03e091bcd\n--- /dev/null\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/Event.java\n", "chunk": "@@ -0,0 +1,51 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.iotdb.flink;\n+\n+import java.util.List;\n+\n+public class Event {\n+    private String device;\n+    private Long timestamp;\n+    private List<String> measurements;\n+    private List<String> values;\n+\n+    public Event(String device, Long timestamp, List<String> measurements, List<String> values) {\n+        this.device = device;\n+        this.timestamp = timestamp;\n+        this.measurements = measurements;\n+        this.values = values;\n+    }\n+\n+    public String getDevice() {\n+        return device;\n+    }\n+\n+    public Long getTimestamp() {\n+        return timestamp;\n+    }\n+\n+    public List<String> getMeasurements() {\n+        return measurements;\n+    }\n+\n+    public List<String> getValues() {\n+        return values;\n+    }\n+}\n\\ No newline at end of file\n", "next_change": {"commit": "83fc8b53ff4a3bdab7f7839b195ca8addb09901e", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/Event.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/Event.java\nindex a03e091bcd..6cccb23353 100644\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/Event.java\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/Event.java\n", "chunk": "@@ -48,4 +51,4 @@ public class Event {\n     public List<String> getValues() {\n         return values;\n     }\n-}\n\\ No newline at end of file\n+}\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg1NzYxNA==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r382857614", "body": "Add newline at end of file.", "bodyText": "Add newline at end of file.", "bodyHTML": "<p dir=\"auto\">Add newline at end of file.</p>", "author": "sunjincheng121", "createdAt": "2020-02-21T23:50:54Z", "path": "flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTSerializationSchema.java", "diffHunk": "@@ -0,0 +1,27 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.iotdb.flink;\n+\n+import java.io.Serializable;\n+\n+public interface IoTSerializationSchema<T> extends Serializable {\n+\n+    Event serialize(T tuple);\n+\n+}", "originalCommit": "115b8cec1082524ff5ef18af2e4ede53762fdc8b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjkwNzE2NQ==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r382907165", "bodyText": "Will update.", "author": "vesense", "createdAt": "2020-02-22T11:47:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg1NzYxNA=="}], "type": "inlineReview", "revised_code": {"commit": "2f12978cc65cfc47f659b837e174d535fe2f53af", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTSerializationSchema.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTSerializationSchema.java\ndeleted file mode 100644\nindex 5cc33fd528..0000000000\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTSerializationSchema.java\n+++ /dev/null\n", "chunk": "@@ -1,27 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.iotdb.flink;\n-\n-import java.io.Serializable;\n-\n-public interface IoTSerializationSchema<T> extends Serializable {\n-\n-    Event serialize(T tuple);\n-\n-}\n\\ No newline at end of file\n", "next_change": {"commit": "b10c17af87692b9992a07eabd224bf4407600937", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTSerializationSchema.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTSerializationSchema.java\nnew file mode 100644\nindex 0000000000..5cc33fd528\n--- /dev/null\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTSerializationSchema.java\n", "chunk": "@@ -0,0 +1,27 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.iotdb.flink;\n+\n+import java.io.Serializable;\n+\n+public interface IoTSerializationSchema<T> extends Serializable {\n+\n+    Event serialize(T tuple);\n+\n+}\n\\ No newline at end of file\n", "next_change": {"commit": "83fc8b53ff4a3bdab7f7839b195ca8addb09901e", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTSerializationSchema.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTSerializationSchema.java\nindex 5cc33fd528..9c9f9599fb 100644\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTSerializationSchema.java\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTSerializationSchema.java\n", "chunk": "@@ -20,8 +20,12 @@ package org.apache.iotdb.flink;\n \n import java.io.Serializable;\n \n+/**\n+ * IoTSerializationSchema serializes the input tuple data into events for inserting into IoTDB server.\n+ * @param <T>\n+ */\n public interface IoTSerializationSchema<T> extends Serializable {\n \n     Event serialize(T tuple);\n \n-}\n\\ No newline at end of file\n+}\n", "next_change": {"commit": "7b693c5b6c14bb3528e0fab31aaa033a3318507d", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTSerializationSchema.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTSerializationSchema.java\nindex 9c9f9599fb..e0b72d437d 100644\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTSerializationSchema.java\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTSerializationSchema.java\n", "chunk": "@@ -22,7 +22,7 @@ import java.io.Serializable;\n \n /**\n  * IoTSerializationSchema serializes the input tuple data into events for inserting into IoTDB server.\n- * @param <T>\n+ * @param <T> the input data type\n  */\n public interface IoTSerializationSchema<T> extends Serializable {\n \n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg1NzY1OA==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r382857658", "body": "Add newline at end of file.", "bodyText": "Add newline at end of file.", "bodyHTML": "<p dir=\"auto\">Add newline at end of file.</p>", "author": "sunjincheng121", "createdAt": "2020-02-21T23:51:03Z", "path": "flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkTest.java", "diffHunk": "@@ -0,0 +1,67 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.iotdb.flink;\n+\n+import com.google.common.collect.Lists;\n+import org.apache.iotdb.session.Session;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.mockito.Matchers.any;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.verify;\n+\n+public class IoTDBSinkTest {\n+\n+    private IoTDBSink ioTDBSink;\n+    private Session session;\n+\n+    @Before\n+    public void setUp() throws Exception {\n+        IoTDBOptions options = new IoTDBOptions();\n+        options.setTimeseriesOptionList(Lists.newArrayList(new IoTDBOptions.TimeseriesOption(\"root.sg.D01.temperature\")));\n+        ioTDBSink = new IoTDBSink(options, new DefaultIoTSerializationSchema(options));\n+\n+        session = mock(Session.class);\n+        ioTDBSink.setSession(session);\n+    }\n+\n+    @Test\n+    public void testSink() throws Exception {\n+        Map tuple = new HashMap();\n+        tuple.put(\"device\", \"root.sg.D01\");\n+        tuple.put(\"timestamp\", \"1581861293000\");\n+        tuple.put(\"measurements\", \"temperature\");\n+        tuple.put(\"values\", \"36.5\");\n+\n+        ioTDBSink.invoke(tuple, null);\n+        verify(session).insert(any(String.class), any(Long.class), any(List.class), any(List.class));\n+    }\n+\n+    @Test\n+    public void close() throws Exception {\n+        ioTDBSink.close();\n+        verify(session).close();\n+    }\n+\n+}", "originalCommit": "115b8cec1082524ff5ef18af2e4ede53762fdc8b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjkwNzE3Mg==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r382907172", "bodyText": "Will update.", "author": "vesense", "createdAt": "2020-02-22T11:47:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg1NzY1OA=="}], "type": "inlineReview", "revised_code": {"commit": "2f12978cc65cfc47f659b837e174d535fe2f53af", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkTest.java b/flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkTest.java\ndeleted file mode 100644\nindex a576f1e8c0..0000000000\n--- a/flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkTest.java\n+++ /dev/null\n", "chunk": "@@ -1,67 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.iotdb.flink;\n-\n-import com.google.common.collect.Lists;\n-import org.apache.iotdb.session.Session;\n-import org.junit.Before;\n-import org.junit.Test;\n-\n-import java.util.HashMap;\n-import java.util.List;\n-import java.util.Map;\n-\n-import static org.mockito.Matchers.any;\n-import static org.mockito.Mockito.mock;\n-import static org.mockito.Mockito.verify;\n-\n-public class IoTDBSinkTest {\n-\n-    private IoTDBSink ioTDBSink;\n-    private Session session;\n-\n-    @Before\n-    public void setUp() throws Exception {\n-        IoTDBOptions options = new IoTDBOptions();\n-        options.setTimeseriesOptionList(Lists.newArrayList(new IoTDBOptions.TimeseriesOption(\"root.sg.D01.temperature\")));\n-        ioTDBSink = new IoTDBSink(options, new DefaultIoTSerializationSchema(options));\n-\n-        session = mock(Session.class);\n-        ioTDBSink.setSession(session);\n-    }\n-\n-    @Test\n-    public void testSink() throws Exception {\n-        Map tuple = new HashMap();\n-        tuple.put(\"device\", \"root.sg.D01\");\n-        tuple.put(\"timestamp\", \"1581861293000\");\n-        tuple.put(\"measurements\", \"temperature\");\n-        tuple.put(\"values\", \"36.5\");\n-\n-        ioTDBSink.invoke(tuple, null);\n-        verify(session).insert(any(String.class), any(Long.class), any(List.class), any(List.class));\n-    }\n-\n-    @Test\n-    public void close() throws Exception {\n-        ioTDBSink.close();\n-        verify(session).close();\n-    }\n-\n-}\n\\ No newline at end of file\n", "next_change": {"commit": "b10c17af87692b9992a07eabd224bf4407600937", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkTest.java b/flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkTest.java\nnew file mode 100644\nindex 0000000000..a576f1e8c0\n--- /dev/null\n+++ b/flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkTest.java\n", "chunk": "@@ -0,0 +1,67 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.iotdb.flink;\n+\n+import com.google.common.collect.Lists;\n+import org.apache.iotdb.session.Session;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.mockito.Matchers.any;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.verify;\n+\n+public class IoTDBSinkTest {\n+\n+    private IoTDBSink ioTDBSink;\n+    private Session session;\n+\n+    @Before\n+    public void setUp() throws Exception {\n+        IoTDBOptions options = new IoTDBOptions();\n+        options.setTimeseriesOptionList(Lists.newArrayList(new IoTDBOptions.TimeseriesOption(\"root.sg.D01.temperature\")));\n+        ioTDBSink = new IoTDBSink(options, new DefaultIoTSerializationSchema(options));\n+\n+        session = mock(Session.class);\n+        ioTDBSink.setSession(session);\n+    }\n+\n+    @Test\n+    public void testSink() throws Exception {\n+        Map tuple = new HashMap();\n+        tuple.put(\"device\", \"root.sg.D01\");\n+        tuple.put(\"timestamp\", \"1581861293000\");\n+        tuple.put(\"measurements\", \"temperature\");\n+        tuple.put(\"values\", \"36.5\");\n+\n+        ioTDBSink.invoke(tuple, null);\n+        verify(session).insert(any(String.class), any(Long.class), any(List.class), any(List.class));\n+    }\n+\n+    @Test\n+    public void close() throws Exception {\n+        ioTDBSink.close();\n+        verify(session).close();\n+    }\n+\n+}\n\\ No newline at end of file\n", "next_change": {"commit": "83fc8b53ff4a3bdab7f7839b195ca8addb09901e", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkTest.java b/flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkInsertTest.java\nsimilarity index 96%\nrename from flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkTest.java\nrename to flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkInsertTest.java\nindex a576f1e8c0..7b297ffeb7 100644\n--- a/flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkTest.java\n+++ b/flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkInsertTest.java\n", "chunk": "@@ -64,4 +64,4 @@ public class IoTDBSinkTest {\n         verify(session).close();\n     }\n \n-}\n\\ No newline at end of file\n+}\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg1ODQzNQ==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r382858435", "body": "Move to previous line\uff1f", "bodyText": "Move to previous line\uff1f", "bodyHTML": "<p dir=\"auto\">Move to previous line\uff1f</p>", "author": "sunjincheng121", "createdAt": "2020-02-21T23:54:49Z", "path": "example/flink-example/src/main/java/org/apache/iotdb/flink/Example.java", "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.iotdb.flink;\n+\n+import com.google.common.collect.Lists;\n+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\n+import org.apache.flink.streaming.api.functions.source.SourceFunction;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Random;\n+\n+public class Example {\n+    public static void main(String[] args) {\n+        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n+        env.enableCheckpointing(3000);\n+\n+        IoTDBOptions options = new IoTDBOptions();\n+        options.setHost(\"127.0.0.1\");\n+        options.setPort(6667);\n+        options.setUser(\"root\");\n+        options.setPassword(\"root\");\n+        options.setStorageGroup(\"root.sg\");\n+        options.setTimeseriesOptionList(Lists.newArrayList(new IoTDBOptions.TimeseriesOption(\"root.sg.d1.s1\")));\n+\n+        IoTSerializationSchema serializationSchema = new DefaultIoTSerializationSchema(options);\n+        IoTDBSink ioTDBSink = new IoTDBSink(options, serializationSchema)\n+                // enable batching\n+                .withBatchFlushOnCheckpoint(true)\n+                .withBatchSize(10)\n+                ;", "originalCommit": "115b8cec1082524ff5ef18af2e4ede53762fdc8b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjkwNzQ3Mw==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r382907473", "bodyText": "Will update.", "author": "vesense", "createdAt": "2020-02-22T11:53:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg1ODQzNQ=="}], "type": "inlineReview", "revised_code": {"commit": "2f12978cc65cfc47f659b837e174d535fe2f53af", "changed_code": [{"header": "diff --git a/example/flink-example/src/main/java/org/apache/iotdb/flink/Example.java b/example/flink-example/src/main/java/org/apache/iotdb/flink/Example.java\ndeleted file mode 100644\nindex b4141bee6e..0000000000\n--- a/example/flink-example/src/main/java/org/apache/iotdb/flink/Example.java\n+++ /dev/null\n", "chunk": "@@ -1,87 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.iotdb.flink;\n-\n-import com.google.common.collect.Lists;\n-import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\n-import org.apache.flink.streaming.api.functions.source.SourceFunction;\n-\n-import java.util.HashMap;\n-import java.util.Map;\n-import java.util.Random;\n-\n-public class Example {\n-    public static void main(String[] args) {\n-        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n-        env.enableCheckpointing(3000);\n-\n-        IoTDBOptions options = new IoTDBOptions();\n-        options.setHost(\"127.0.0.1\");\n-        options.setPort(6667);\n-        options.setUser(\"root\");\n-        options.setPassword(\"root\");\n-        options.setStorageGroup(\"root.sg\");\n-        options.setTimeseriesOptionList(Lists.newArrayList(new IoTDBOptions.TimeseriesOption(\"root.sg.d1.s1\")));\n-\n-        IoTSerializationSchema serializationSchema = new DefaultIoTSerializationSchema(options);\n-        IoTDBSink ioTDBSink = new IoTDBSink(options, serializationSchema)\n-                // enable batching\n-                .withBatchFlushOnCheckpoint(true)\n-                .withBatchSize(10)\n-                ;\n-\n-        env.addSource(new SensorSource())\n-                .name(\"sensor-source\")\n-                .setParallelism(1)\n-\n-                .addSink(ioTDBSink)\n-                .name(\"iotdb-sink\")\n-                .setParallelism(1)\n-        ;\n-\n-        try {\n-            env.execute(\"iotdb-flink-example\");\n-        } catch (Exception e) {\n-            e.printStackTrace();\n-        }\n-    }\n-\n-    private static class SensorSource implements SourceFunction<Map<String,String>> {\n-        boolean running = true;\n-\n-        @Override\n-        public void run(SourceContext context) throws Exception {\n-            Random random = new Random();\n-            while (running) {\n-                Map tuple = new HashMap();\n-                tuple.put(\"device\", \"root.sg.d1\");\n-                tuple.put(\"timestamp\", String.valueOf(System.currentTimeMillis()));\n-                tuple.put(\"measurements\", \"s1\");\n-                tuple.put(\"values\", String.valueOf(random.nextDouble()));\n-\n-                context.collect(tuple);\n-                Thread.sleep(1000);\n-            }\n-        }\n-\n-        @Override\n-        public void cancel() {\n-            running = false;\n-        }\n-    }\n-}\n", "next_change": {"commit": "b10c17af87692b9992a07eabd224bf4407600937", "changed_code": [{"header": "diff --git a/example/flink-example/src/main/java/org/apache/iotdb/flink/Example.java b/example/flink-example/src/main/java/org/apache/iotdb/flink/Example.java\nnew file mode 100644\nindex 0000000000..b4141bee6e\n--- /dev/null\n+++ b/example/flink-example/src/main/java/org/apache/iotdb/flink/Example.java\n", "chunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.iotdb.flink;\n+\n+import com.google.common.collect.Lists;\n+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\n+import org.apache.flink.streaming.api.functions.source.SourceFunction;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Random;\n+\n+public class Example {\n+    public static void main(String[] args) {\n+        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n+        env.enableCheckpointing(3000);\n+\n+        IoTDBOptions options = new IoTDBOptions();\n+        options.setHost(\"127.0.0.1\");\n+        options.setPort(6667);\n+        options.setUser(\"root\");\n+        options.setPassword(\"root\");\n+        options.setStorageGroup(\"root.sg\");\n+        options.setTimeseriesOptionList(Lists.newArrayList(new IoTDBOptions.TimeseriesOption(\"root.sg.d1.s1\")));\n+\n+        IoTSerializationSchema serializationSchema = new DefaultIoTSerializationSchema(options);\n+        IoTDBSink ioTDBSink = new IoTDBSink(options, serializationSchema)\n+                // enable batching\n+                .withBatchFlushOnCheckpoint(true)\n+                .withBatchSize(10)\n+                ;\n+\n+        env.addSource(new SensorSource())\n+                .name(\"sensor-source\")\n+                .setParallelism(1)\n+\n+                .addSink(ioTDBSink)\n+                .name(\"iotdb-sink\")\n+                .setParallelism(1)\n+        ;\n+\n+        try {\n+            env.execute(\"iotdb-flink-example\");\n+        } catch (Exception e) {\n+            e.printStackTrace();\n+        }\n+    }\n+\n+    private static class SensorSource implements SourceFunction<Map<String,String>> {\n+        boolean running = true;\n+\n+        @Override\n+        public void run(SourceContext context) throws Exception {\n+            Random random = new Random();\n+            while (running) {\n+                Map tuple = new HashMap();\n+                tuple.put(\"device\", \"root.sg.d1\");\n+                tuple.put(\"timestamp\", String.valueOf(System.currentTimeMillis()));\n+                tuple.put(\"measurements\", \"s1\");\n+                tuple.put(\"values\", String.valueOf(random.nextDouble()));\n+\n+                context.collect(tuple);\n+                Thread.sleep(1000);\n+            }\n+        }\n+\n+        @Override\n+        public void cancel() {\n+            running = false;\n+        }\n+    }\n+}\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg2MDczNg==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r382860736", "body": "It's better to add java doc for Class :) What do you think?", "bodyText": "It's better to add java doc for Class :) What do you think?", "bodyHTML": "<p dir=\"auto\">It's better to add java doc for Class :) What do you think?</p>", "author": "sunjincheng121", "createdAt": "2020-02-22T00:06:38Z", "path": "flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java", "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.iotdb.flink;\n+\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+public class DefaultIoTSerializationSchema implements IoTSerializationSchema<Map<String,String>> {", "originalCommit": "115b8cec1082524ff5ef18af2e4ede53762fdc8b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjkyMjExMA==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r382922110", "bodyText": "Will update.", "author": "vesense", "createdAt": "2020-02-22T15:55:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg2MDczNg=="}], "type": "inlineReview", "revised_code": {"commit": "2f12978cc65cfc47f659b837e174d535fe2f53af", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java\ndeleted file mode 100644\nindex 0da9d8a214..0000000000\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java\n+++ /dev/null\n", "chunk": "@@ -1,78 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.iotdb.flink;\n-\n-import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n-\n-import java.util.Arrays;\n-import java.util.HashMap;\n-import java.util.List;\n-import java.util.Map;\n-\n-public class DefaultIoTSerializationSchema implements IoTSerializationSchema<Map<String,String>> {\n-    public static final String FIELD_DEVICE = \"device\";\n-    public static final String FIELD_TIMESTAMP = \"timestamp\";\n-    public static final String FIELD_MEASUREMENTS = \"measurements\";\n-    public static final String FIELD_VALUES = \"values\";\n-    public static final String DEFAULT_SEPARATOR = \",\";\n-\n-    private Map<String, IoTDBOptions.TimeseriesOption> timeseriesOptionMap;\n-\n-    public DefaultIoTSerializationSchema(IoTDBOptions ioTDBOptions) {\n-        timeseriesOptionMap = new HashMap<>();\n-        for (IoTDBOptions.TimeseriesOption timeseriesOption : ioTDBOptions.getTimeseriesOptionList()) {\n-            timeseriesOptionMap.put(timeseriesOption.getPath(), timeseriesOption);\n-        }\n-    }\n-\n-    @Override\n-    public Event serialize(Map<String,String> tuple) {\n-        if (tuple == null) {\n-            return null;\n-        }\n-\n-        String device = tuple.get(FIELD_DEVICE);\n-\n-        String ts = tuple.get(FIELD_TIMESTAMP);\n-        Long timestamp = ts == null ? System.currentTimeMillis() : Long.parseLong(ts);\n-\n-        List<String> measurements = null;\n-        if (tuple.get(FIELD_MEASUREMENTS) != null) {\n-            measurements = Arrays.asList(tuple.get(FIELD_MEASUREMENTS).split(DEFAULT_SEPARATOR));\n-        }\n-\n-        List<String> values = null;\n-        if (tuple.get(FIELD_VALUES) != null) {\n-            values = Arrays.asList(tuple.get(FIELD_VALUES).split(DEFAULT_SEPARATOR));\n-        }\n-\n-        if (device != null && measurements != null && values != null && measurements.size() == values.size()) {\n-            for (int i = 0; i < measurements.size(); i++) {\n-                String measurement = device + \".\" + measurements.get(i);\n-                IoTDBOptions.TimeseriesOption timeseriesOption = timeseriesOptionMap.get(measurement);\n-                if (timeseriesOption!= null && TSDataType.TEXT.equals(timeseriesOption.getDataType())) {\n-                    // The TEXT data type should be covered by \" or '\n-                    values.set(i, \"'\" + values.get(i) + \"'\");\n-                }\n-            }\n-        }\n-\n-        return new Event(device, timestamp, measurements, values);\n-    }\n-}\n\\ No newline at end of file\n", "next_change": {"commit": "b10c17af87692b9992a07eabd224bf4407600937", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java\nnew file mode 100644\nindex 0000000000..0da9d8a214\n--- /dev/null\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java\n", "chunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.iotdb.flink;\n+\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+public class DefaultIoTSerializationSchema implements IoTSerializationSchema<Map<String,String>> {\n+    public static final String FIELD_DEVICE = \"device\";\n+    public static final String FIELD_TIMESTAMP = \"timestamp\";\n+    public static final String FIELD_MEASUREMENTS = \"measurements\";\n+    public static final String FIELD_VALUES = \"values\";\n+    public static final String DEFAULT_SEPARATOR = \",\";\n+\n+    private Map<String, IoTDBOptions.TimeseriesOption> timeseriesOptionMap;\n+\n+    public DefaultIoTSerializationSchema(IoTDBOptions ioTDBOptions) {\n+        timeseriesOptionMap = new HashMap<>();\n+        for (IoTDBOptions.TimeseriesOption timeseriesOption : ioTDBOptions.getTimeseriesOptionList()) {\n+            timeseriesOptionMap.put(timeseriesOption.getPath(), timeseriesOption);\n+        }\n+    }\n+\n+    @Override\n+    public Event serialize(Map<String,String> tuple) {\n+        if (tuple == null) {\n+            return null;\n+        }\n+\n+        String device = tuple.get(FIELD_DEVICE);\n+\n+        String ts = tuple.get(FIELD_TIMESTAMP);\n+        Long timestamp = ts == null ? System.currentTimeMillis() : Long.parseLong(ts);\n+\n+        List<String> measurements = null;\n+        if (tuple.get(FIELD_MEASUREMENTS) != null) {\n+            measurements = Arrays.asList(tuple.get(FIELD_MEASUREMENTS).split(DEFAULT_SEPARATOR));\n+        }\n+\n+        List<String> values = null;\n+        if (tuple.get(FIELD_VALUES) != null) {\n+            values = Arrays.asList(tuple.get(FIELD_VALUES).split(DEFAULT_SEPARATOR));\n+        }\n+\n+        if (device != null && measurements != null && values != null && measurements.size() == values.size()) {\n+            for (int i = 0; i < measurements.size(); i++) {\n+                String measurement = device + \".\" + measurements.get(i);\n+                IoTDBOptions.TimeseriesOption timeseriesOption = timeseriesOptionMap.get(measurement);\n+                if (timeseriesOption!= null && TSDataType.TEXT.equals(timeseriesOption.getDataType())) {\n+                    // The TEXT data type should be covered by \" or '\n+                    values.set(i, \"'\" + values.get(i) + \"'\");\n+                }\n+            }\n+        }\n+\n+        return new Event(device, timestamp, measurements, values);\n+    }\n+}\n\\ No newline at end of file\n", "next_change": {"commit": "83fc8b53ff4a3bdab7f7839b195ca8addb09901e", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java\nindex 0da9d8a214..a439a94557 100644\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java\n", "chunk": "@@ -75,4 +79,4 @@ public class DefaultIoTSerializationSchema implements IoTSerializationSchema<Map\n \n         return new Event(device, timestamp, measurements, values);\n     }\n-}\n\\ No newline at end of file\n+}\n", "next_change": {"commit": "7b693c5b6c14bb3528e0fab31aaa033a3318507d", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java\nindex a439a94557..4ac596b5a4 100644\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java\n", "chunk": "@@ -51,32 +39,61 @@ public class DefaultIoTSerializationSchema implements IoTSerializationSchema<Map\n             return null;\n         }\n \n-        String device = tuple.get(FIELD_DEVICE);\n+        String device = tuple.get(fieldDevice);\n \n-        String ts = tuple.get(FIELD_TIMESTAMP);\n+        String ts = tuple.get(fieldTimestamp);\n         Long timestamp = ts == null ? System.currentTimeMillis() : Long.parseLong(ts);\n \n         List<String> measurements = null;\n-        if (tuple.get(FIELD_MEASUREMENTS) != null) {\n-            measurements = Arrays.asList(tuple.get(FIELD_MEASUREMENTS).split(DEFAULT_SEPARATOR));\n+        if (tuple.get(fieldMeasurements) != null) {\n+            measurements = Arrays.asList(tuple.get(fieldMeasurements).split(separator));\n         }\n \n         List<String> values = null;\n-        if (tuple.get(FIELD_VALUES) != null) {\n-            values = Arrays.asList(tuple.get(FIELD_VALUES).split(DEFAULT_SEPARATOR));\n-        }\n-\n-        if (device != null && measurements != null && values != null && measurements.size() == values.size()) {\n-            for (int i = 0; i < measurements.size(); i++) {\n-                String measurement = device + \".\" + measurements.get(i);\n-                IoTDBOptions.TimeseriesOption timeseriesOption = timeseriesOptionMap.get(measurement);\n-                if (timeseriesOption!= null && TSDataType.TEXT.equals(timeseriesOption.getDataType())) {\n-                    // The TEXT data type should be covered by \" or '\n-                    values.set(i, \"'\" + values.get(i) + \"'\");\n-                }\n-            }\n+        if (tuple.get(fieldValues) != null) {\n+            values = Arrays.asList(tuple.get(fieldValues).split(separator));\n         }\n \n         return new Event(device, timestamp, measurements, values);\n     }\n+\n+    public String getFieldDevice() {\n+        return fieldDevice;\n+    }\n+\n+    public void setFieldDevice(String fieldDevice) {\n+        this.fieldDevice = fieldDevice;\n+    }\n+\n+    public String getFieldTimestamp() {\n+        return fieldTimestamp;\n+    }\n+\n+    public void setFieldTimestamp(String fieldTimestamp) {\n+        this.fieldTimestamp = fieldTimestamp;\n+    }\n+\n+    public String getFieldMeasurements() {\n+        return fieldMeasurements;\n+    }\n+\n+    public void setFieldMeasurements(String fieldMeasurements) {\n+        this.fieldMeasurements = fieldMeasurements;\n+    }\n+\n+    public String getFieldValues() {\n+        return fieldValues;\n+    }\n+\n+    public void setFieldValues(String fieldValues) {\n+        this.fieldValues = fieldValues;\n+    }\n+\n+    public String getSeparator() {\n+        return separator;\n+    }\n+\n+    public void setSeparator(String separator) {\n+        this.separator = separator;\n+    }\n }\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg2ODY5Ng==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r382868696", "body": "Can we remove this flag as I think `batchSize` can express the same semantics  with \uff08`batchSize`+`batchFlushOnCheckpoint`)?", "bodyText": "Can we remove this flag as I think batchSize can express the same semantics  with \uff08batchSize+batchFlushOnCheckpoint)?", "bodyHTML": "<p dir=\"auto\">Can we remove this flag as I think <code>batchSize</code> can express the same semantics  with \uff08<code>batchSize</code>+<code>batchFlushOnCheckpoint</code>)?</p>", "author": "sunjincheng121", "createdAt": "2020-02-22T00:55:17Z", "path": "flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java", "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.iotdb.flink;\n+\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.runtime.state.FunctionInitializationContext;\n+import org.apache.flink.runtime.state.FunctionSnapshotContext;\n+import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;\n+import org.apache.flink.streaming.api.functions.sink.RichSinkFunction;\n+import org.apache.flink.streaming.api.operators.StreamingRuntimeContext;\n+import org.apache.iotdb.service.rpc.thrift.TSStatus;\n+import org.apache.iotdb.session.Session;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+public class IoTDBSink<IN> extends RichSinkFunction<IN> implements CheckpointedFunction {\n+\n+    private static final long serialVersionUID = 1L;\n+    private static final Logger LOG = LoggerFactory.getLogger(IoTDBSink.class);\n+\n+    private IoTSerializationSchema<IN> serializationSchema;\n+    private IoTDBOptions options;\n+    private transient Session session;\n+\n+    private boolean batchFlushOnCheckpoint; // false by default", "originalCommit": "115b8cec1082524ff5ef18af2e4ede53762fdc8b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg5NDk2NA==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r382894964", "bodyText": "Agree. It is a little strange.\nIf batchFlushOnCheckpoint == false, then the data will never be written into IoTDB...", "author": "jixuan1989", "createdAt": "2020-02-22T07:49:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg2ODY5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjkyMDcwNQ==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r382920705", "bodyText": "batchFlushOnCheckpoint is the switch for batch inserting.\nFalse by default, users can change by invoking withBatchFlushOnCheckpoint(true)\nThere are two parameters related to batch.\n\nbatch size (iotDBSink.withBatchSize(10))\ncheckpoint interval (timer) (env.enableCheckpointing(3000))\n\nif `batchFlushOnCheckpoint` == true\n    if batchList >= batch size || checkpoint interval arises (`snapshotState`)\n        then session.insertInBatch\n    else \n        add to batchList\nelse\n    session.insert", "author": "vesense", "createdAt": "2020-02-22T15:36:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg2ODY5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjkyNjE4Nw==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r382926187", "bodyText": "I mean that only  batchList is enough. By default batchList=0 means  we insert the data immediately(batchFlushOnCheckpoint==true), and if batchList>0 means we will insert the data in batch.  User do not need config the batchFlushOnCheckpoint, the  isCheckpointingEnabled can help us make the decision of whether buffered the data is required.\nWhat do you think?", "author": "sunjincheng121", "createdAt": "2020-02-22T16:57:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg2ODY5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk1OTkxMg==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r382959912", "bodyText": "When a user uses such a module, two things that he/she may consider:\n\nI want to reduce the network cost, therefore I will write data until I collect 1000 data points.\nHowever, if some device generates data too rarely, e.g., in 0.01Hz (i.e., generates a data point per 100 seconds),and if I have to wait for 1000 data points coming, I have to want for about 100,000 seconds. So, I want that, if I have buffered data for 3 seconds and the buffer is not full, I will send these data to IoTDB.\n\nThat is to say, batchList is for setting the buffer size, and enableCheckpointing( time interval) is for setting the acceptable latency.", "author": "jixuan1989", "createdAt": "2020-02-23T03:12:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg2ODY5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzkwMTY2Ng==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r383901666", "bodyText": "Thanks @sunjincheng121 and @jixuan1989 for your advices.\nI decided to optimize the relevant logic to avoid user harassment.\n\nuse batchsize as the batch switch(by default batchList=0  insert the data immediately, and if batchList>0  insert the data in batch)\nuse a new timer instead of checkpointing to ensure the data flush SLA.\n\nThese changes will be committed later.", "author": "vesense", "createdAt": "2020-02-25T14:11:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg2ODY5Ng=="}], "type": "inlineReview", "revised_code": {"commit": "2f12978cc65cfc47f659b837e174d535fe2f53af", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\ndeleted file mode 100644\nindex e647323cd2..0000000000\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n+++ /dev/null\n", "chunk": "@@ -1,153 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.iotdb.flink;\n-\n-import org.apache.flink.configuration.Configuration;\n-import org.apache.flink.runtime.state.FunctionInitializationContext;\n-import org.apache.flink.runtime.state.FunctionSnapshotContext;\n-import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;\n-import org.apache.flink.streaming.api.functions.sink.RichSinkFunction;\n-import org.apache.flink.streaming.api.operators.StreamingRuntimeContext;\n-import org.apache.iotdb.service.rpc.thrift.TSStatus;\n-import org.apache.iotdb.session.Session;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import java.util.ArrayList;\n-import java.util.LinkedList;\n-import java.util.List;\n-\n-public class IoTDBSink<IN> extends RichSinkFunction<IN> implements CheckpointedFunction {\n-\n-    private static final long serialVersionUID = 1L;\n-    private static final Logger LOG = LoggerFactory.getLogger(IoTDBSink.class);\n-\n-    private IoTSerializationSchema<IN> serializationSchema;\n-    private IoTDBOptions options;\n-    private transient Session session;\n-\n-    private boolean batchFlushOnCheckpoint; // false by default\n-    private int batchSize = 100;\n-    private List<Event> batchList;\n-\n-    public IoTDBSink(IoTDBOptions options, IoTSerializationSchema<IN> schema) {\n-        this.options = options;\n-        this.serializationSchema = schema;\n-    }\n-\n-    @Override\n-    public void open(Configuration parameters) throws Exception {\n-        batchList = new LinkedList<>();\n-\n-        session = new Session(options.getHost(), options.getPort(), options.getUser(), options.getPassword());\n-        session.open();\n-\n-        session.setStorageGroup(options.getStorageGroup());\n-        for (IoTDBOptions.TimeseriesOption option : options.getTimeseriesOptionList()) {\n-            if (!session.checkTimeseriesExists(option.getPath())) {\n-                session.createTimeseries(option.getPath(), option.getDataType(), option.getEncoding(), option.getCompressor());\n-            }\n-        }\n-\n-        if (batchFlushOnCheckpoint && !((StreamingRuntimeContext) getRuntimeContext()).isCheckpointingEnabled()) {\n-            LOG.warn(\"Flushing on checkpoint is enabled, but checkpointing is not enabled. Disabling flushing.\");\n-            batchFlushOnCheckpoint = false;\n-        }\n-    }\n-\n-    //  for testing\n-    void setSession(Session session) {\n-        this.session = session;\n-    }\n-\n-    @Override\n-    public void invoke(IN input, Context context) throws Exception {\n-        Event event = serializationSchema.serialize(input);\n-        if (event == null) {\n-            return;\n-        }\n-\n-        if (batchFlushOnCheckpoint) {\n-            batchList.add(event);\n-            if (batchList.size() >= batchSize) {\n-                flushSync();\n-            }\n-            return;\n-        }\n-\n-        TSStatus status = session.insert(event.getDevice(), event.getTimestamp(),\n-                event.getMeasurements(), event.getValues());\n-        LOG.debug(\"sync send event result: {}\", status);\n-    }\n-\n-    public IoTDBSink<IN> withBatchFlushOnCheckpoint(boolean batchFlushOnCheckpoint) {\n-        this.batchFlushOnCheckpoint = batchFlushOnCheckpoint;\n-        return this;\n-    }\n-\n-    public IoTDBSink<IN> withBatchSize(int batchSize) {\n-        this.batchSize = batchSize;\n-        return this;\n-    }\n-\n-    @Override\n-    public void close() throws Exception {\n-        if (session != null) {\n-            try {\n-                flushSync();\n-            } catch (Exception e) {\n-                LOG.error(\"flushSync failure\", e);\n-            }\n-           session.close();\n-        }\n-    }\n-\n-    private void flushSync() throws Exception {\n-        if (batchFlushOnCheckpoint) {\n-            synchronized (batchList) {\n-                if (batchList.size() > 0) {\n-                    List<String> deviceIds = new ArrayList<>();\n-                    List<Long> timestamps = new ArrayList<>();\n-                    List<List<String>> measurementsList = new ArrayList<>();\n-                    List<List<String>> valuesList = new ArrayList<>();\n-\n-                    for (Event event : batchList) {\n-                        deviceIds.add(event.getDevice());\n-                        timestamps.add(event.getTimestamp());\n-                        measurementsList.add(event.getMeasurements());\n-                        valuesList.add(event.getValues());\n-                    }\n-                    List<TSStatus> statusList = session.insertInBatch(deviceIds, timestamps, measurementsList, valuesList);\n-                    LOG.debug(\"sync send events result: {}\", statusList);\n-                    batchList.clear();\n-                }\n-            }\n-        }\n-    }\n-\n-    @Override\n-    public void snapshotState(FunctionSnapshotContext context) throws Exception {\n-        flushSync();\n-    }\n-\n-    @Override\n-    public void initializeState(FunctionInitializationContext context) throws Exception {\n-        // nothing to do\n-    }\n-}\n", "next_change": {"commit": "b10c17af87692b9992a07eabd224bf4407600937", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\nnew file mode 100644\nindex 0000000000..e647323cd2\n--- /dev/null\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n", "chunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.iotdb.flink;\n+\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.runtime.state.FunctionInitializationContext;\n+import org.apache.flink.runtime.state.FunctionSnapshotContext;\n+import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;\n+import org.apache.flink.streaming.api.functions.sink.RichSinkFunction;\n+import org.apache.flink.streaming.api.operators.StreamingRuntimeContext;\n+import org.apache.iotdb.service.rpc.thrift.TSStatus;\n+import org.apache.iotdb.session.Session;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+public class IoTDBSink<IN> extends RichSinkFunction<IN> implements CheckpointedFunction {\n+\n+    private static final long serialVersionUID = 1L;\n+    private static final Logger LOG = LoggerFactory.getLogger(IoTDBSink.class);\n+\n+    private IoTSerializationSchema<IN> serializationSchema;\n+    private IoTDBOptions options;\n+    private transient Session session;\n+\n+    private boolean batchFlushOnCheckpoint; // false by default\n+    private int batchSize = 100;\n+    private List<Event> batchList;\n+\n+    public IoTDBSink(IoTDBOptions options, IoTSerializationSchema<IN> schema) {\n+        this.options = options;\n+        this.serializationSchema = schema;\n+    }\n+\n+    @Override\n+    public void open(Configuration parameters) throws Exception {\n+        batchList = new LinkedList<>();\n+\n+        session = new Session(options.getHost(), options.getPort(), options.getUser(), options.getPassword());\n+        session.open();\n+\n+        session.setStorageGroup(options.getStorageGroup());\n+        for (IoTDBOptions.TimeseriesOption option : options.getTimeseriesOptionList()) {\n+            if (!session.checkTimeseriesExists(option.getPath())) {\n+                session.createTimeseries(option.getPath(), option.getDataType(), option.getEncoding(), option.getCompressor());\n+            }\n+        }\n+\n+        if (batchFlushOnCheckpoint && !((StreamingRuntimeContext) getRuntimeContext()).isCheckpointingEnabled()) {\n+            LOG.warn(\"Flushing on checkpoint is enabled, but checkpointing is not enabled. Disabling flushing.\");\n+            batchFlushOnCheckpoint = false;\n+        }\n+    }\n+\n+    //  for testing\n+    void setSession(Session session) {\n+        this.session = session;\n+    }\n+\n+    @Override\n+    public void invoke(IN input, Context context) throws Exception {\n+        Event event = serializationSchema.serialize(input);\n+        if (event == null) {\n+            return;\n+        }\n+\n+        if (batchFlushOnCheckpoint) {\n+            batchList.add(event);\n+            if (batchList.size() >= batchSize) {\n+                flushSync();\n+            }\n+            return;\n+        }\n+\n+        TSStatus status = session.insert(event.getDevice(), event.getTimestamp(),\n+                event.getMeasurements(), event.getValues());\n+        LOG.debug(\"sync send event result: {}\", status);\n+    }\n+\n+    public IoTDBSink<IN> withBatchFlushOnCheckpoint(boolean batchFlushOnCheckpoint) {\n+        this.batchFlushOnCheckpoint = batchFlushOnCheckpoint;\n+        return this;\n+    }\n+\n+    public IoTDBSink<IN> withBatchSize(int batchSize) {\n+        this.batchSize = batchSize;\n+        return this;\n+    }\n+\n+    @Override\n+    public void close() throws Exception {\n+        if (session != null) {\n+            try {\n+                flushSync();\n+            } catch (Exception e) {\n+                LOG.error(\"flushSync failure\", e);\n+            }\n+           session.close();\n+        }\n+    }\n+\n+    private void flushSync() throws Exception {\n+        if (batchFlushOnCheckpoint) {\n+            synchronized (batchList) {\n+                if (batchList.size() > 0) {\n+                    List<String> deviceIds = new ArrayList<>();\n+                    List<Long> timestamps = new ArrayList<>();\n+                    List<List<String>> measurementsList = new ArrayList<>();\n+                    List<List<String>> valuesList = new ArrayList<>();\n+\n+                    for (Event event : batchList) {\n+                        deviceIds.add(event.getDevice());\n+                        timestamps.add(event.getTimestamp());\n+                        measurementsList.add(event.getMeasurements());\n+                        valuesList.add(event.getValues());\n+                    }\n+                    List<TSStatus> statusList = session.insertInBatch(deviceIds, timestamps, measurementsList, valuesList);\n+                    LOG.debug(\"sync send events result: {}\", statusList);\n+                    batchList.clear();\n+                }\n+            }\n+        }\n+    }\n+\n+    @Override\n+    public void snapshotState(FunctionSnapshotContext context) throws Exception {\n+        flushSync();\n+    }\n+\n+    @Override\n+    public void initializeState(FunctionInitializationContext context) throws Exception {\n+        // nothing to do\n+    }\n+}\n", "next_change": {"commit": "83fc8b53ff4a3bdab7f7839b195ca8addb09901e", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\nindex e647323cd2..fa7d2a1f02 100644\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n", "chunk": "@@ -110,44 +128,34 @@ public class IoTDBSink<IN> extends RichSinkFunction<IN> implements CheckpointedF\n     public void close() throws Exception {\n         if (session != null) {\n             try {\n-                flushSync();\n+                flush();\n             } catch (Exception e) {\n-                LOG.error(\"flushSync failure\", e);\n+                LOG.error(\"flush error\", e);\n             }\n-           session.close();\n+            session.close();\n+        }\n+        if (scheduledExecutor != null) {\n+            scheduledExecutor.shutdown();\n         }\n     }\n \n-    private void flushSync() throws Exception {\n-        if (batchFlushOnCheckpoint) {\n-            synchronized (batchList) {\n-                if (batchList.size() > 0) {\n-                    List<String> deviceIds = new ArrayList<>();\n-                    List<Long> timestamps = new ArrayList<>();\n-                    List<List<String>> measurementsList = new ArrayList<>();\n-                    List<List<String>> valuesList = new ArrayList<>();\n-\n-                    for (Event event : batchList) {\n-                        deviceIds.add(event.getDevice());\n-                        timestamps.add(event.getTimestamp());\n-                        measurementsList.add(event.getMeasurements());\n-                        valuesList.add(event.getValues());\n-                    }\n-                    List<TSStatus> statusList = session.insertInBatch(deviceIds, timestamps, measurementsList, valuesList);\n-                    LOG.debug(\"sync send events result: {}\", statusList);\n-                    batchList.clear();\n-                }\n+    private synchronized void flush() throws Exception {\n+        if (batchSize > 0 && batchList.size() > 0) {\n+            List<String> deviceIds = new ArrayList<>();\n+            List<Long> timestamps = new ArrayList<>();\n+            List<List<String>> measurementsList = new ArrayList<>();\n+            List<List<String>> valuesList = new ArrayList<>();\n+\n+            for (Event event : batchList) {\n+                deviceIds.add(event.getDevice());\n+                timestamps.add(event.getTimestamp());\n+                measurementsList.add(event.getMeasurements());\n+                valuesList.add(event.getValues());\n             }\n+            List<TSStatus> statusList = session.insertInBatch(deviceIds, timestamps, measurementsList, valuesList);\n+            LOG.debug(\"send events result: {}\", statusList);\n+            batchList.clear();\n         }\n     }\n \n-    @Override\n-    public void snapshotState(FunctionSnapshotContext context) throws Exception {\n-        flushSync();\n-    }\n-\n-    @Override\n-    public void initializeState(FunctionInitializationContext context) throws Exception {\n-        // nothing to do\n-    }\n }\n", "next_change": {"commit": "7b693c5b6c14bb3528e0fab31aaa033a3318507d", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\nindex fa7d2a1f02..0495fac617 100644\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n", "chunk": "@@ -139,22 +148,38 @@ public class IoTDBSink<IN> extends RichSinkFunction<IN> {\n         }\n     }\n \n-    private synchronized void flush() throws Exception {\n-        if (batchSize > 0 && batchList.size() > 0) {\n-            List<String> deviceIds = new ArrayList<>();\n-            List<Long> timestamps = new ArrayList<>();\n-            List<List<String>> measurementsList = new ArrayList<>();\n-            List<List<String>> valuesList = new ArrayList<>();\n-\n-            for (Event event : batchList) {\n-                deviceIds.add(event.getDevice());\n-                timestamps.add(event.getTimestamp());\n-                measurementsList.add(event.getMeasurements());\n-                valuesList.add(event.getValues());\n+    private void convertText(String device, List<String> measurements, List<String> values) {\n+        if (device != null && measurements != null && values != null && measurements.size() == values.size()) {\n+            for (int i = 0; i < measurements.size(); i++) {\n+                String measurement = device + \".\" + measurements.get(i);\n+                IoTDBOptions.TimeseriesOption timeseriesOption = timeseriesOptionMap.get(measurement);\n+                if (timeseriesOption!= null && TSDataType.TEXT.equals(timeseriesOption.getDataType())) {\n+                    // The TEXT data type should be covered by \" or '\n+                    values.set(i, \"'\" + values.get(i) + \"'\");\n+                }\n+            }\n+        }\n+    }\n+\n+    private void flush() throws Exception {\n+        synchronized (batchList) {\n+            if (batchSize > 0 && batchList.size() > 0) {\n+                List<String> deviceIds = new ArrayList<>();\n+                List<Long> timestamps = new ArrayList<>();\n+                List<List<String>> measurementsList = new ArrayList<>();\n+                List<List<String>> valuesList = new ArrayList<>();\n+\n+                for (Event event : batchList) {\n+                    convertText(event.getDevice(), event.getMeasurements(), event.getValues());\n+                    deviceIds.add(event.getDevice());\n+                    timestamps.add(event.getTimestamp());\n+                    measurementsList.add(event.getMeasurements());\n+                    valuesList.add(event.getValues());\n+                }\n+                List<TSStatus> statusList = session.insertInBatch(deviceIds, timestamps, measurementsList, valuesList);\n+                LOG.debug(\"send events result: {}\", statusList);\n+                batchList.clear();\n             }\n-            List<TSStatus> statusList = session.insertInBatch(deviceIds, timestamps, measurementsList, valuesList);\n-            LOG.debug(\"send events result: {}\", statusList);\n-            batchList.clear();\n         }\n     }\n \n", "next_change": {"commit": "78778429d60212a6b983d855a955c07e3d93eb69", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\nindex 0495fac617..cda69c0773 100644\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n", "chunk": "@@ -162,23 +162,25 @@ public class IoTDBSink<IN> extends RichSinkFunction<IN> {\n     }\n \n     private void flush() throws Exception {\n-        synchronized (batchList) {\n-            if (batchSize > 0 && batchList.size() > 0) {\n-                List<String> deviceIds = new ArrayList<>();\n-                List<Long> timestamps = new ArrayList<>();\n-                List<List<String>> measurementsList = new ArrayList<>();\n-                List<List<String>> valuesList = new ArrayList<>();\n-\n-                for (Event event : batchList) {\n-                    convertText(event.getDevice(), event.getMeasurements(), event.getValues());\n-                    deviceIds.add(event.getDevice());\n-                    timestamps.add(event.getTimestamp());\n-                    measurementsList.add(event.getMeasurements());\n-                    valuesList.add(event.getValues());\n+        if (batchSize > 0) {\n+            synchronized (batchList) {\n+                if (batchList.size() > 0) {\n+                    List<String> deviceIds = new ArrayList<>();\n+                    List<Long> timestamps = new ArrayList<>();\n+                    List<List<String>> measurementsList = new ArrayList<>();\n+                    List<List<String>> valuesList = new ArrayList<>();\n+\n+                    for (Event event : batchList) {\n+                        convertText(event.getDevice(), event.getMeasurements(), event.getValues());\n+                        deviceIds.add(event.getDevice());\n+                        timestamps.add(event.getTimestamp());\n+                        measurementsList.add(event.getMeasurements());\n+                        valuesList.add(event.getValues());\n+                    }\n+                    List<TSStatus> statusList = session.insertInBatch(deviceIds, timestamps, measurementsList, valuesList);\n+                    LOG.debug(\"send events result: {}\", statusList);\n+                    batchList.clear();\n                 }\n-                List<TSStatus> statusList = session.insertInBatch(deviceIds, timestamps, measurementsList, valuesList);\n-                LOG.debug(\"send events result: {}\", statusList);\n-                batchList.clear();\n             }\n         }\n     }\n", "next_change": {"commit": "32f32f62f62a5fdb59fa751a00556505fb604114", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\nindex cda69c0773..1f405d631d 100644\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n", "chunk": "@@ -184,5 +184,4 @@ public class IoTDBSink<IN> extends RichSinkFunction<IN> {\n             }\n         }\n     }\n-\n }\n", "next_change": null}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg3Mjc5MQ==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r382872791", "body": "100->0", "bodyText": "100->0", "bodyHTML": "<p dir=\"auto\">100-&gt;0</p>", "author": "sunjincheng121", "createdAt": "2020-02-22T01:29:00Z", "path": "flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java", "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.iotdb.flink;\n+\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.runtime.state.FunctionInitializationContext;\n+import org.apache.flink.runtime.state.FunctionSnapshotContext;\n+import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;\n+import org.apache.flink.streaming.api.functions.sink.RichSinkFunction;\n+import org.apache.flink.streaming.api.operators.StreamingRuntimeContext;\n+import org.apache.iotdb.service.rpc.thrift.TSStatus;\n+import org.apache.iotdb.session.Session;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+public class IoTDBSink<IN> extends RichSinkFunction<IN> implements CheckpointedFunction {\n+\n+    private static final long serialVersionUID = 1L;\n+    private static final Logger LOG = LoggerFactory.getLogger(IoTDBSink.class);\n+\n+    private IoTSerializationSchema<IN> serializationSchema;\n+    private IoTDBOptions options;\n+    private transient Session session;\n+\n+    private boolean batchFlushOnCheckpoint; // false by default\n+    private int batchSize = 100;", "originalCommit": "115b8cec1082524ff5ef18af2e4ede53762fdc8b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjkyMDg0Mw==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r382920843", "bodyText": "This is the default batch size. Users can change by invoking withBatchSize.", "author": "vesense", "createdAt": "2020-02-22T15:38:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg3Mjc5MQ=="}], "type": "inlineReview", "revised_code": {"commit": "2f12978cc65cfc47f659b837e174d535fe2f53af", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\ndeleted file mode 100644\nindex e647323cd2..0000000000\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n+++ /dev/null\n", "chunk": "@@ -1,153 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.iotdb.flink;\n-\n-import org.apache.flink.configuration.Configuration;\n-import org.apache.flink.runtime.state.FunctionInitializationContext;\n-import org.apache.flink.runtime.state.FunctionSnapshotContext;\n-import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;\n-import org.apache.flink.streaming.api.functions.sink.RichSinkFunction;\n-import org.apache.flink.streaming.api.operators.StreamingRuntimeContext;\n-import org.apache.iotdb.service.rpc.thrift.TSStatus;\n-import org.apache.iotdb.session.Session;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import java.util.ArrayList;\n-import java.util.LinkedList;\n-import java.util.List;\n-\n-public class IoTDBSink<IN> extends RichSinkFunction<IN> implements CheckpointedFunction {\n-\n-    private static final long serialVersionUID = 1L;\n-    private static final Logger LOG = LoggerFactory.getLogger(IoTDBSink.class);\n-\n-    private IoTSerializationSchema<IN> serializationSchema;\n-    private IoTDBOptions options;\n-    private transient Session session;\n-\n-    private boolean batchFlushOnCheckpoint; // false by default\n-    private int batchSize = 100;\n-    private List<Event> batchList;\n-\n-    public IoTDBSink(IoTDBOptions options, IoTSerializationSchema<IN> schema) {\n-        this.options = options;\n-        this.serializationSchema = schema;\n-    }\n-\n-    @Override\n-    public void open(Configuration parameters) throws Exception {\n-        batchList = new LinkedList<>();\n-\n-        session = new Session(options.getHost(), options.getPort(), options.getUser(), options.getPassword());\n-        session.open();\n-\n-        session.setStorageGroup(options.getStorageGroup());\n-        for (IoTDBOptions.TimeseriesOption option : options.getTimeseriesOptionList()) {\n-            if (!session.checkTimeseriesExists(option.getPath())) {\n-                session.createTimeseries(option.getPath(), option.getDataType(), option.getEncoding(), option.getCompressor());\n-            }\n-        }\n-\n-        if (batchFlushOnCheckpoint && !((StreamingRuntimeContext) getRuntimeContext()).isCheckpointingEnabled()) {\n-            LOG.warn(\"Flushing on checkpoint is enabled, but checkpointing is not enabled. Disabling flushing.\");\n-            batchFlushOnCheckpoint = false;\n-        }\n-    }\n-\n-    //  for testing\n-    void setSession(Session session) {\n-        this.session = session;\n-    }\n-\n-    @Override\n-    public void invoke(IN input, Context context) throws Exception {\n-        Event event = serializationSchema.serialize(input);\n-        if (event == null) {\n-            return;\n-        }\n-\n-        if (batchFlushOnCheckpoint) {\n-            batchList.add(event);\n-            if (batchList.size() >= batchSize) {\n-                flushSync();\n-            }\n-            return;\n-        }\n-\n-        TSStatus status = session.insert(event.getDevice(), event.getTimestamp(),\n-                event.getMeasurements(), event.getValues());\n-        LOG.debug(\"sync send event result: {}\", status);\n-    }\n-\n-    public IoTDBSink<IN> withBatchFlushOnCheckpoint(boolean batchFlushOnCheckpoint) {\n-        this.batchFlushOnCheckpoint = batchFlushOnCheckpoint;\n-        return this;\n-    }\n-\n-    public IoTDBSink<IN> withBatchSize(int batchSize) {\n-        this.batchSize = batchSize;\n-        return this;\n-    }\n-\n-    @Override\n-    public void close() throws Exception {\n-        if (session != null) {\n-            try {\n-                flushSync();\n-            } catch (Exception e) {\n-                LOG.error(\"flushSync failure\", e);\n-            }\n-           session.close();\n-        }\n-    }\n-\n-    private void flushSync() throws Exception {\n-        if (batchFlushOnCheckpoint) {\n-            synchronized (batchList) {\n-                if (batchList.size() > 0) {\n-                    List<String> deviceIds = new ArrayList<>();\n-                    List<Long> timestamps = new ArrayList<>();\n-                    List<List<String>> measurementsList = new ArrayList<>();\n-                    List<List<String>> valuesList = new ArrayList<>();\n-\n-                    for (Event event : batchList) {\n-                        deviceIds.add(event.getDevice());\n-                        timestamps.add(event.getTimestamp());\n-                        measurementsList.add(event.getMeasurements());\n-                        valuesList.add(event.getValues());\n-                    }\n-                    List<TSStatus> statusList = session.insertInBatch(deviceIds, timestamps, measurementsList, valuesList);\n-                    LOG.debug(\"sync send events result: {}\", statusList);\n-                    batchList.clear();\n-                }\n-            }\n-        }\n-    }\n-\n-    @Override\n-    public void snapshotState(FunctionSnapshotContext context) throws Exception {\n-        flushSync();\n-    }\n-\n-    @Override\n-    public void initializeState(FunctionInitializationContext context) throws Exception {\n-        // nothing to do\n-    }\n-}\n", "next_change": {"commit": "b10c17af87692b9992a07eabd224bf4407600937", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\nnew file mode 100644\nindex 0000000000..e647323cd2\n--- /dev/null\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n", "chunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.iotdb.flink;\n+\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.runtime.state.FunctionInitializationContext;\n+import org.apache.flink.runtime.state.FunctionSnapshotContext;\n+import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;\n+import org.apache.flink.streaming.api.functions.sink.RichSinkFunction;\n+import org.apache.flink.streaming.api.operators.StreamingRuntimeContext;\n+import org.apache.iotdb.service.rpc.thrift.TSStatus;\n+import org.apache.iotdb.session.Session;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+public class IoTDBSink<IN> extends RichSinkFunction<IN> implements CheckpointedFunction {\n+\n+    private static final long serialVersionUID = 1L;\n+    private static final Logger LOG = LoggerFactory.getLogger(IoTDBSink.class);\n+\n+    private IoTSerializationSchema<IN> serializationSchema;\n+    private IoTDBOptions options;\n+    private transient Session session;\n+\n+    private boolean batchFlushOnCheckpoint; // false by default\n+    private int batchSize = 100;\n+    private List<Event> batchList;\n+\n+    public IoTDBSink(IoTDBOptions options, IoTSerializationSchema<IN> schema) {\n+        this.options = options;\n+        this.serializationSchema = schema;\n+    }\n+\n+    @Override\n+    public void open(Configuration parameters) throws Exception {\n+        batchList = new LinkedList<>();\n+\n+        session = new Session(options.getHost(), options.getPort(), options.getUser(), options.getPassword());\n+        session.open();\n+\n+        session.setStorageGroup(options.getStorageGroup());\n+        for (IoTDBOptions.TimeseriesOption option : options.getTimeseriesOptionList()) {\n+            if (!session.checkTimeseriesExists(option.getPath())) {\n+                session.createTimeseries(option.getPath(), option.getDataType(), option.getEncoding(), option.getCompressor());\n+            }\n+        }\n+\n+        if (batchFlushOnCheckpoint && !((StreamingRuntimeContext) getRuntimeContext()).isCheckpointingEnabled()) {\n+            LOG.warn(\"Flushing on checkpoint is enabled, but checkpointing is not enabled. Disabling flushing.\");\n+            batchFlushOnCheckpoint = false;\n+        }\n+    }\n+\n+    //  for testing\n+    void setSession(Session session) {\n+        this.session = session;\n+    }\n+\n+    @Override\n+    public void invoke(IN input, Context context) throws Exception {\n+        Event event = serializationSchema.serialize(input);\n+        if (event == null) {\n+            return;\n+        }\n+\n+        if (batchFlushOnCheckpoint) {\n+            batchList.add(event);\n+            if (batchList.size() >= batchSize) {\n+                flushSync();\n+            }\n+            return;\n+        }\n+\n+        TSStatus status = session.insert(event.getDevice(), event.getTimestamp(),\n+                event.getMeasurements(), event.getValues());\n+        LOG.debug(\"sync send event result: {}\", status);\n+    }\n+\n+    public IoTDBSink<IN> withBatchFlushOnCheckpoint(boolean batchFlushOnCheckpoint) {\n+        this.batchFlushOnCheckpoint = batchFlushOnCheckpoint;\n+        return this;\n+    }\n+\n+    public IoTDBSink<IN> withBatchSize(int batchSize) {\n+        this.batchSize = batchSize;\n+        return this;\n+    }\n+\n+    @Override\n+    public void close() throws Exception {\n+        if (session != null) {\n+            try {\n+                flushSync();\n+            } catch (Exception e) {\n+                LOG.error(\"flushSync failure\", e);\n+            }\n+           session.close();\n+        }\n+    }\n+\n+    private void flushSync() throws Exception {\n+        if (batchFlushOnCheckpoint) {\n+            synchronized (batchList) {\n+                if (batchList.size() > 0) {\n+                    List<String> deviceIds = new ArrayList<>();\n+                    List<Long> timestamps = new ArrayList<>();\n+                    List<List<String>> measurementsList = new ArrayList<>();\n+                    List<List<String>> valuesList = new ArrayList<>();\n+\n+                    for (Event event : batchList) {\n+                        deviceIds.add(event.getDevice());\n+                        timestamps.add(event.getTimestamp());\n+                        measurementsList.add(event.getMeasurements());\n+                        valuesList.add(event.getValues());\n+                    }\n+                    List<TSStatus> statusList = session.insertInBatch(deviceIds, timestamps, measurementsList, valuesList);\n+                    LOG.debug(\"sync send events result: {}\", statusList);\n+                    batchList.clear();\n+                }\n+            }\n+        }\n+    }\n+\n+    @Override\n+    public void snapshotState(FunctionSnapshotContext context) throws Exception {\n+        flushSync();\n+    }\n+\n+    @Override\n+    public void initializeState(FunctionInitializationContext context) throws Exception {\n+        // nothing to do\n+    }\n+}\n", "next_change": {"commit": "83fc8b53ff4a3bdab7f7839b195ca8addb09901e", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\nindex e647323cd2..fa7d2a1f02 100644\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n", "chunk": "@@ -110,44 +128,34 @@ public class IoTDBSink<IN> extends RichSinkFunction<IN> implements CheckpointedF\n     public void close() throws Exception {\n         if (session != null) {\n             try {\n-                flushSync();\n+                flush();\n             } catch (Exception e) {\n-                LOG.error(\"flushSync failure\", e);\n+                LOG.error(\"flush error\", e);\n             }\n-           session.close();\n+            session.close();\n+        }\n+        if (scheduledExecutor != null) {\n+            scheduledExecutor.shutdown();\n         }\n     }\n \n-    private void flushSync() throws Exception {\n-        if (batchFlushOnCheckpoint) {\n-            synchronized (batchList) {\n-                if (batchList.size() > 0) {\n-                    List<String> deviceIds = new ArrayList<>();\n-                    List<Long> timestamps = new ArrayList<>();\n-                    List<List<String>> measurementsList = new ArrayList<>();\n-                    List<List<String>> valuesList = new ArrayList<>();\n-\n-                    for (Event event : batchList) {\n-                        deviceIds.add(event.getDevice());\n-                        timestamps.add(event.getTimestamp());\n-                        measurementsList.add(event.getMeasurements());\n-                        valuesList.add(event.getValues());\n-                    }\n-                    List<TSStatus> statusList = session.insertInBatch(deviceIds, timestamps, measurementsList, valuesList);\n-                    LOG.debug(\"sync send events result: {}\", statusList);\n-                    batchList.clear();\n-                }\n+    private synchronized void flush() throws Exception {\n+        if (batchSize > 0 && batchList.size() > 0) {\n+            List<String> deviceIds = new ArrayList<>();\n+            List<Long> timestamps = new ArrayList<>();\n+            List<List<String>> measurementsList = new ArrayList<>();\n+            List<List<String>> valuesList = new ArrayList<>();\n+\n+            for (Event event : batchList) {\n+                deviceIds.add(event.getDevice());\n+                timestamps.add(event.getTimestamp());\n+                measurementsList.add(event.getMeasurements());\n+                valuesList.add(event.getValues());\n             }\n+            List<TSStatus> statusList = session.insertInBatch(deviceIds, timestamps, measurementsList, valuesList);\n+            LOG.debug(\"send events result: {}\", statusList);\n+            batchList.clear();\n         }\n     }\n \n-    @Override\n-    public void snapshotState(FunctionSnapshotContext context) throws Exception {\n-        flushSync();\n-    }\n-\n-    @Override\n-    public void initializeState(FunctionInitializationContext context) throws Exception {\n-        // nothing to do\n-    }\n }\n", "next_change": {"commit": "7b693c5b6c14bb3528e0fab31aaa033a3318507d", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\nindex fa7d2a1f02..0495fac617 100644\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n", "chunk": "@@ -139,22 +148,38 @@ public class IoTDBSink<IN> extends RichSinkFunction<IN> {\n         }\n     }\n \n-    private synchronized void flush() throws Exception {\n-        if (batchSize > 0 && batchList.size() > 0) {\n-            List<String> deviceIds = new ArrayList<>();\n-            List<Long> timestamps = new ArrayList<>();\n-            List<List<String>> measurementsList = new ArrayList<>();\n-            List<List<String>> valuesList = new ArrayList<>();\n-\n-            for (Event event : batchList) {\n-                deviceIds.add(event.getDevice());\n-                timestamps.add(event.getTimestamp());\n-                measurementsList.add(event.getMeasurements());\n-                valuesList.add(event.getValues());\n+    private void convertText(String device, List<String> measurements, List<String> values) {\n+        if (device != null && measurements != null && values != null && measurements.size() == values.size()) {\n+            for (int i = 0; i < measurements.size(); i++) {\n+                String measurement = device + \".\" + measurements.get(i);\n+                IoTDBOptions.TimeseriesOption timeseriesOption = timeseriesOptionMap.get(measurement);\n+                if (timeseriesOption!= null && TSDataType.TEXT.equals(timeseriesOption.getDataType())) {\n+                    // The TEXT data type should be covered by \" or '\n+                    values.set(i, \"'\" + values.get(i) + \"'\");\n+                }\n+            }\n+        }\n+    }\n+\n+    private void flush() throws Exception {\n+        synchronized (batchList) {\n+            if (batchSize > 0 && batchList.size() > 0) {\n+                List<String> deviceIds = new ArrayList<>();\n+                List<Long> timestamps = new ArrayList<>();\n+                List<List<String>> measurementsList = new ArrayList<>();\n+                List<List<String>> valuesList = new ArrayList<>();\n+\n+                for (Event event : batchList) {\n+                    convertText(event.getDevice(), event.getMeasurements(), event.getValues());\n+                    deviceIds.add(event.getDevice());\n+                    timestamps.add(event.getTimestamp());\n+                    measurementsList.add(event.getMeasurements());\n+                    valuesList.add(event.getValues());\n+                }\n+                List<TSStatus> statusList = session.insertInBatch(deviceIds, timestamps, measurementsList, valuesList);\n+                LOG.debug(\"send events result: {}\", statusList);\n+                batchList.clear();\n             }\n-            List<TSStatus> statusList = session.insertInBatch(deviceIds, timestamps, measurementsList, valuesList);\n-            LOG.debug(\"send events result: {}\", statusList);\n-            batchList.clear();\n         }\n     }\n \n", "next_change": {"commit": "78778429d60212a6b983d855a955c07e3d93eb69", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\nindex 0495fac617..cda69c0773 100644\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n", "chunk": "@@ -162,23 +162,25 @@ public class IoTDBSink<IN> extends RichSinkFunction<IN> {\n     }\n \n     private void flush() throws Exception {\n-        synchronized (batchList) {\n-            if (batchSize > 0 && batchList.size() > 0) {\n-                List<String> deviceIds = new ArrayList<>();\n-                List<Long> timestamps = new ArrayList<>();\n-                List<List<String>> measurementsList = new ArrayList<>();\n-                List<List<String>> valuesList = new ArrayList<>();\n-\n-                for (Event event : batchList) {\n-                    convertText(event.getDevice(), event.getMeasurements(), event.getValues());\n-                    deviceIds.add(event.getDevice());\n-                    timestamps.add(event.getTimestamp());\n-                    measurementsList.add(event.getMeasurements());\n-                    valuesList.add(event.getValues());\n+        if (batchSize > 0) {\n+            synchronized (batchList) {\n+                if (batchList.size() > 0) {\n+                    List<String> deviceIds = new ArrayList<>();\n+                    List<Long> timestamps = new ArrayList<>();\n+                    List<List<String>> measurementsList = new ArrayList<>();\n+                    List<List<String>> valuesList = new ArrayList<>();\n+\n+                    for (Event event : batchList) {\n+                        convertText(event.getDevice(), event.getMeasurements(), event.getValues());\n+                        deviceIds.add(event.getDevice());\n+                        timestamps.add(event.getTimestamp());\n+                        measurementsList.add(event.getMeasurements());\n+                        valuesList.add(event.getValues());\n+                    }\n+                    List<TSStatus> statusList = session.insertInBatch(deviceIds, timestamps, measurementsList, valuesList);\n+                    LOG.debug(\"send events result: {}\", statusList);\n+                    batchList.clear();\n                 }\n-                List<TSStatus> statusList = session.insertInBatch(deviceIds, timestamps, measurementsList, valuesList);\n-                LOG.debug(\"send events result: {}\", statusList);\n-                batchList.clear();\n             }\n         }\n     }\n", "next_change": {"commit": "32f32f62f62a5fdb59fa751a00556505fb604114", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\nindex cda69c0773..1f405d631d 100644\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n", "chunk": "@@ -184,5 +184,4 @@ public class IoTDBSink<IN> extends RichSinkFunction<IN> {\n             }\n         }\n     }\n-\n }\n", "next_change": null}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg3ODQ3OA==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r382878478", "body": "I think the class name `Example` is little bit not specific enough, and would be great to add a very popular word count example\uff0c What do you think\uff1f", "bodyText": "I think the class name Example is little bit not specific enough, and would be great to add a very popular word count example\uff0c What do you think\uff1f", "bodyHTML": "<p dir=\"auto\">I think the class name <code>Example</code> is little bit not specific enough, and would be great to add a very popular word count example\uff0c What do you think\uff1f</p>", "author": "sunjincheng121", "createdAt": "2020-02-22T02:31:45Z", "path": "example/flink-example/src/main/java/org/apache/iotdb/flink/Example.java", "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.iotdb.flink;\n+\n+import com.google.common.collect.Lists;\n+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\n+import org.apache.flink.streaming.api.functions.source.SourceFunction;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Random;\n+\n+public class Example {", "originalCommit": "115b8cec1082524ff5ef18af2e4ede53762fdc8b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjkyMTEyMg==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r382921122", "bodyText": "Good idea. I will change a proper name, but it may not be wordcount in IOT scenario, or just named FlinkIoTDBSink like kafka example KafkaProducer.", "author": "vesense", "createdAt": "2020-02-22T15:42:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg3ODQ3OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjkyNTEwNw==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r382925107", "bodyText": "Sure, I think meaningful name is enough for this case.", "author": "sunjincheng121", "createdAt": "2020-02-22T16:40:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg3ODQ3OA=="}], "type": "inlineReview", "revised_code": {"commit": "2f12978cc65cfc47f659b837e174d535fe2f53af", "changed_code": [{"header": "diff --git a/example/flink-example/src/main/java/org/apache/iotdb/flink/Example.java b/example/flink-example/src/main/java/org/apache/iotdb/flink/Example.java\ndeleted file mode 100644\nindex b4141bee6e..0000000000\n--- a/example/flink-example/src/main/java/org/apache/iotdb/flink/Example.java\n+++ /dev/null\n", "chunk": "@@ -1,87 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.iotdb.flink;\n-\n-import com.google.common.collect.Lists;\n-import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\n-import org.apache.flink.streaming.api.functions.source.SourceFunction;\n-\n-import java.util.HashMap;\n-import java.util.Map;\n-import java.util.Random;\n-\n-public class Example {\n-    public static void main(String[] args) {\n-        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n-        env.enableCheckpointing(3000);\n-\n-        IoTDBOptions options = new IoTDBOptions();\n-        options.setHost(\"127.0.0.1\");\n-        options.setPort(6667);\n-        options.setUser(\"root\");\n-        options.setPassword(\"root\");\n-        options.setStorageGroup(\"root.sg\");\n-        options.setTimeseriesOptionList(Lists.newArrayList(new IoTDBOptions.TimeseriesOption(\"root.sg.d1.s1\")));\n-\n-        IoTSerializationSchema serializationSchema = new DefaultIoTSerializationSchema(options);\n-        IoTDBSink ioTDBSink = new IoTDBSink(options, serializationSchema)\n-                // enable batching\n-                .withBatchFlushOnCheckpoint(true)\n-                .withBatchSize(10)\n-                ;\n-\n-        env.addSource(new SensorSource())\n-                .name(\"sensor-source\")\n-                .setParallelism(1)\n-\n-                .addSink(ioTDBSink)\n-                .name(\"iotdb-sink\")\n-                .setParallelism(1)\n-        ;\n-\n-        try {\n-            env.execute(\"iotdb-flink-example\");\n-        } catch (Exception e) {\n-            e.printStackTrace();\n-        }\n-    }\n-\n-    private static class SensorSource implements SourceFunction<Map<String,String>> {\n-        boolean running = true;\n-\n-        @Override\n-        public void run(SourceContext context) throws Exception {\n-            Random random = new Random();\n-            while (running) {\n-                Map tuple = new HashMap();\n-                tuple.put(\"device\", \"root.sg.d1\");\n-                tuple.put(\"timestamp\", String.valueOf(System.currentTimeMillis()));\n-                tuple.put(\"measurements\", \"s1\");\n-                tuple.put(\"values\", String.valueOf(random.nextDouble()));\n-\n-                context.collect(tuple);\n-                Thread.sleep(1000);\n-            }\n-        }\n-\n-        @Override\n-        public void cancel() {\n-            running = false;\n-        }\n-    }\n-}\n", "next_change": {"commit": "b10c17af87692b9992a07eabd224bf4407600937", "changed_code": [{"header": "diff --git a/example/flink-example/src/main/java/org/apache/iotdb/flink/Example.java b/example/flink-example/src/main/java/org/apache/iotdb/flink/Example.java\nnew file mode 100644\nindex 0000000000..b4141bee6e\n--- /dev/null\n+++ b/example/flink-example/src/main/java/org/apache/iotdb/flink/Example.java\n", "chunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.iotdb.flink;\n+\n+import com.google.common.collect.Lists;\n+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\n+import org.apache.flink.streaming.api.functions.source.SourceFunction;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Random;\n+\n+public class Example {\n+    public static void main(String[] args) {\n+        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n+        env.enableCheckpointing(3000);\n+\n+        IoTDBOptions options = new IoTDBOptions();\n+        options.setHost(\"127.0.0.1\");\n+        options.setPort(6667);\n+        options.setUser(\"root\");\n+        options.setPassword(\"root\");\n+        options.setStorageGroup(\"root.sg\");\n+        options.setTimeseriesOptionList(Lists.newArrayList(new IoTDBOptions.TimeseriesOption(\"root.sg.d1.s1\")));\n+\n+        IoTSerializationSchema serializationSchema = new DefaultIoTSerializationSchema(options);\n+        IoTDBSink ioTDBSink = new IoTDBSink(options, serializationSchema)\n+                // enable batching\n+                .withBatchFlushOnCheckpoint(true)\n+                .withBatchSize(10)\n+                ;\n+\n+        env.addSource(new SensorSource())\n+                .name(\"sensor-source\")\n+                .setParallelism(1)\n+\n+                .addSink(ioTDBSink)\n+                .name(\"iotdb-sink\")\n+                .setParallelism(1)\n+        ;\n+\n+        try {\n+            env.execute(\"iotdb-flink-example\");\n+        } catch (Exception e) {\n+            e.printStackTrace();\n+        }\n+    }\n+\n+    private static class SensorSource implements SourceFunction<Map<String,String>> {\n+        boolean running = true;\n+\n+        @Override\n+        public void run(SourceContext context) throws Exception {\n+            Random random = new Random();\n+            while (running) {\n+                Map tuple = new HashMap();\n+                tuple.put(\"device\", \"root.sg.d1\");\n+                tuple.put(\"timestamp\", String.valueOf(System.currentTimeMillis()));\n+                tuple.put(\"measurements\", \"s1\");\n+                tuple.put(\"values\", String.valueOf(random.nextDouble()));\n+\n+                context.collect(tuple);\n+                Thread.sleep(1000);\n+            }\n+        }\n+\n+        @Override\n+        public void cancel() {\n+            running = false;\n+        }\n+    }\n+}\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg3ODg1OA==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r382878858", "body": "Can we move this logic into example(Such as bring up a Thread for IoTDB Server), due to `IoTDB.main` is really simple to use. Even I think that starting an IoTDB server can be described in the Readme, just like Kafka's readme.[1]\r\n\r\nWhat to you think?\r\n[1] https://github.com/apache/incubator-iotdb/tree/master/example/kafka", "bodyText": "Can we move this logic into example(Such as bring up a Thread for IoTDB Server), due to IoTDB.main is really simple to use. Even I think that starting an IoTDB server can be described in the Readme, just like Kafka's readme.[1]\nWhat to you think?\n[1] https://github.com/apache/incubator-iotdb/tree/master/example/kafka", "bodyHTML": "<p dir=\"auto\">Can we move this logic into example(Such as bring up a Thread for IoTDB Server), due to <code>IoTDB.main</code> is really simple to use. Even I think that starting an IoTDB server can be described in the Readme, just like Kafka's readme.[1]</p>\n<p dir=\"auto\">What to you think?<br>\n[1] <a href=\"https://github.com/apache/incubator-iotdb/tree/master/example/kafka\">https://github.com/apache/incubator-iotdb/tree/master/example/kafka</a></p>", "author": "sunjincheng121", "createdAt": "2020-02-22T02:37:38Z", "path": "example/flink-example/src/main/java/org/apache/iotdb/flink/LocalDBServer.java", "diffHunk": "@@ -0,0 +1,26 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.iotdb.flink;\n+\n+import org.apache.iotdb.db.service.IoTDB;\n+\n+public class LocalDBServer {\n+    public static void main(String[] args) {\n+        IoTDB.main(args);", "originalCommit": "115b8cec1082524ff5ef18af2e4ede53762fdc8b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjkyMTY2OA==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r382921668", "bodyText": "This was mainly to solve the version compatibility problem during testing. I think I can delete it and update the document. Thanks.", "author": "vesense", "createdAt": "2020-02-22T15:49:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg3ODg1OA=="}], "type": "inlineReview", "revised_code": {"commit": "2f12978cc65cfc47f659b837e174d535fe2f53af", "changed_code": [{"header": "diff --git a/example/flink-example/src/main/java/org/apache/iotdb/flink/LocalDBServer.java b/example/flink-example/src/main/java/org/apache/iotdb/flink/LocalDBServer.java\ndeleted file mode 100644\nindex 626313d745..0000000000\n--- a/example/flink-example/src/main/java/org/apache/iotdb/flink/LocalDBServer.java\n+++ /dev/null\n", "chunk": "@@ -1,26 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.iotdb.flink;\n-\n-import org.apache.iotdb.db.service.IoTDB;\n-\n-public class LocalDBServer {\n-    public static void main(String[] args) {\n-        IoTDB.main(args);\n-    }\n-}\n", "next_change": {"commit": "b10c17af87692b9992a07eabd224bf4407600937", "changed_code": [{"header": "diff --git a/example/flink-example/src/main/java/org/apache/iotdb/flink/LocalDBServer.java b/example/flink-example/src/main/java/org/apache/iotdb/flink/LocalDBServer.java\nnew file mode 100644\nindex 0000000000..626313d745\n--- /dev/null\n+++ b/example/flink-example/src/main/java/org/apache/iotdb/flink/LocalDBServer.java\n", "chunk": "@@ -0,0 +1,26 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.iotdb.flink;\n+\n+import org.apache.iotdb.db.service.IoTDB;\n+\n+public class LocalDBServer {\n+    public static void main(String[] args) {\n+        IoTDB.main(args);\n+    }\n+}\n", "next_change": {"commit": "83fc8b53ff4a3bdab7f7839b195ca8addb09901e", "changed_code": [{"header": "diff --git a/example/flink-example/src/main/java/org/apache/iotdb/flink/LocalDBServer.java b/example/flink-example/src/main/java/org/apache/iotdb/flink/LocalDBServer.java\ndeleted file mode 100644\nindex 626313d745..0000000000\n--- a/example/flink-example/src/main/java/org/apache/iotdb/flink/LocalDBServer.java\n+++ /dev/null\n", "chunk": "@@ -1,26 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.iotdb.flink;\n-\n-import org.apache.iotdb.db.service.IoTDB;\n-\n-public class LocalDBServer {\n-    public static void main(String[] args) {\n-        IoTDB.main(args);\n-    }\n-}\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg3OTczMg==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r382879732", "body": "If the batch size > 0, then we need a timer for flush the buffer data.", "bodyText": "If the batch size > 0, then we need a timer for flush the buffer data.", "bodyHTML": "<p dir=\"auto\">If the batch size &gt; 0, then we need a timer for flush the buffer data.</p>", "author": "sunjincheng121", "createdAt": "2020-02-22T02:51:24Z", "path": "flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java", "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.iotdb.flink;\n+\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.runtime.state.FunctionInitializationContext;\n+import org.apache.flink.runtime.state.FunctionSnapshotContext;\n+import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;\n+import org.apache.flink.streaming.api.functions.sink.RichSinkFunction;\n+import org.apache.flink.streaming.api.operators.StreamingRuntimeContext;\n+import org.apache.iotdb.service.rpc.thrift.TSStatus;\n+import org.apache.iotdb.session.Session;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+public class IoTDBSink<IN> extends RichSinkFunction<IN> implements CheckpointedFunction {\n+\n+    private static final long serialVersionUID = 1L;\n+    private static final Logger LOG = LoggerFactory.getLogger(IoTDBSink.class);\n+\n+    private IoTSerializationSchema<IN> serializationSchema;\n+    private IoTDBOptions options;\n+    private transient Session session;\n+\n+    private boolean batchFlushOnCheckpoint; // false by default\n+    private int batchSize = 100;", "originalCommit": "115b8cec1082524ff5ef18af2e4ede53762fdc8b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjkyMTIxNQ==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r382921215", "bodyText": "The timer here is checkpoint interval.", "author": "vesense", "createdAt": "2020-02-22T15:43:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg3OTczMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk1ODU1Mg==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r382958552", "bodyText": "Some times checkpoint interval is pretty long, even may 10min or more. and the  checkpoint is ensure do not miss data when checkpointing, but not ensure the SLA(such as delayed), So in this case it's better to have opportunity to set timer for flush data.\nWhat do you think?", "author": "sunjincheng121", "createdAt": "2020-02-23T02:41:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg3OTczMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mzg5NDQ2Ng==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r383894466", "bodyText": "Make sense. Will update.", "author": "vesense", "createdAt": "2020-02-25T13:59:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg3OTczMg=="}], "type": "inlineReview", "revised_code": {"commit": "2f12978cc65cfc47f659b837e174d535fe2f53af", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\ndeleted file mode 100644\nindex e647323cd2..0000000000\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n+++ /dev/null\n", "chunk": "@@ -1,153 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.iotdb.flink;\n-\n-import org.apache.flink.configuration.Configuration;\n-import org.apache.flink.runtime.state.FunctionInitializationContext;\n-import org.apache.flink.runtime.state.FunctionSnapshotContext;\n-import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;\n-import org.apache.flink.streaming.api.functions.sink.RichSinkFunction;\n-import org.apache.flink.streaming.api.operators.StreamingRuntimeContext;\n-import org.apache.iotdb.service.rpc.thrift.TSStatus;\n-import org.apache.iotdb.session.Session;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import java.util.ArrayList;\n-import java.util.LinkedList;\n-import java.util.List;\n-\n-public class IoTDBSink<IN> extends RichSinkFunction<IN> implements CheckpointedFunction {\n-\n-    private static final long serialVersionUID = 1L;\n-    private static final Logger LOG = LoggerFactory.getLogger(IoTDBSink.class);\n-\n-    private IoTSerializationSchema<IN> serializationSchema;\n-    private IoTDBOptions options;\n-    private transient Session session;\n-\n-    private boolean batchFlushOnCheckpoint; // false by default\n-    private int batchSize = 100;\n-    private List<Event> batchList;\n-\n-    public IoTDBSink(IoTDBOptions options, IoTSerializationSchema<IN> schema) {\n-        this.options = options;\n-        this.serializationSchema = schema;\n-    }\n-\n-    @Override\n-    public void open(Configuration parameters) throws Exception {\n-        batchList = new LinkedList<>();\n-\n-        session = new Session(options.getHost(), options.getPort(), options.getUser(), options.getPassword());\n-        session.open();\n-\n-        session.setStorageGroup(options.getStorageGroup());\n-        for (IoTDBOptions.TimeseriesOption option : options.getTimeseriesOptionList()) {\n-            if (!session.checkTimeseriesExists(option.getPath())) {\n-                session.createTimeseries(option.getPath(), option.getDataType(), option.getEncoding(), option.getCompressor());\n-            }\n-        }\n-\n-        if (batchFlushOnCheckpoint && !((StreamingRuntimeContext) getRuntimeContext()).isCheckpointingEnabled()) {\n-            LOG.warn(\"Flushing on checkpoint is enabled, but checkpointing is not enabled. Disabling flushing.\");\n-            batchFlushOnCheckpoint = false;\n-        }\n-    }\n-\n-    //  for testing\n-    void setSession(Session session) {\n-        this.session = session;\n-    }\n-\n-    @Override\n-    public void invoke(IN input, Context context) throws Exception {\n-        Event event = serializationSchema.serialize(input);\n-        if (event == null) {\n-            return;\n-        }\n-\n-        if (batchFlushOnCheckpoint) {\n-            batchList.add(event);\n-            if (batchList.size() >= batchSize) {\n-                flushSync();\n-            }\n-            return;\n-        }\n-\n-        TSStatus status = session.insert(event.getDevice(), event.getTimestamp(),\n-                event.getMeasurements(), event.getValues());\n-        LOG.debug(\"sync send event result: {}\", status);\n-    }\n-\n-    public IoTDBSink<IN> withBatchFlushOnCheckpoint(boolean batchFlushOnCheckpoint) {\n-        this.batchFlushOnCheckpoint = batchFlushOnCheckpoint;\n-        return this;\n-    }\n-\n-    public IoTDBSink<IN> withBatchSize(int batchSize) {\n-        this.batchSize = batchSize;\n-        return this;\n-    }\n-\n-    @Override\n-    public void close() throws Exception {\n-        if (session != null) {\n-            try {\n-                flushSync();\n-            } catch (Exception e) {\n-                LOG.error(\"flushSync failure\", e);\n-            }\n-           session.close();\n-        }\n-    }\n-\n-    private void flushSync() throws Exception {\n-        if (batchFlushOnCheckpoint) {\n-            synchronized (batchList) {\n-                if (batchList.size() > 0) {\n-                    List<String> deviceIds = new ArrayList<>();\n-                    List<Long> timestamps = new ArrayList<>();\n-                    List<List<String>> measurementsList = new ArrayList<>();\n-                    List<List<String>> valuesList = new ArrayList<>();\n-\n-                    for (Event event : batchList) {\n-                        deviceIds.add(event.getDevice());\n-                        timestamps.add(event.getTimestamp());\n-                        measurementsList.add(event.getMeasurements());\n-                        valuesList.add(event.getValues());\n-                    }\n-                    List<TSStatus> statusList = session.insertInBatch(deviceIds, timestamps, measurementsList, valuesList);\n-                    LOG.debug(\"sync send events result: {}\", statusList);\n-                    batchList.clear();\n-                }\n-            }\n-        }\n-    }\n-\n-    @Override\n-    public void snapshotState(FunctionSnapshotContext context) throws Exception {\n-        flushSync();\n-    }\n-\n-    @Override\n-    public void initializeState(FunctionInitializationContext context) throws Exception {\n-        // nothing to do\n-    }\n-}\n", "next_change": {"commit": "b10c17af87692b9992a07eabd224bf4407600937", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\nnew file mode 100644\nindex 0000000000..e647323cd2\n--- /dev/null\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n", "chunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.iotdb.flink;\n+\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.runtime.state.FunctionInitializationContext;\n+import org.apache.flink.runtime.state.FunctionSnapshotContext;\n+import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;\n+import org.apache.flink.streaming.api.functions.sink.RichSinkFunction;\n+import org.apache.flink.streaming.api.operators.StreamingRuntimeContext;\n+import org.apache.iotdb.service.rpc.thrift.TSStatus;\n+import org.apache.iotdb.session.Session;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+\n+public class IoTDBSink<IN> extends RichSinkFunction<IN> implements CheckpointedFunction {\n+\n+    private static final long serialVersionUID = 1L;\n+    private static final Logger LOG = LoggerFactory.getLogger(IoTDBSink.class);\n+\n+    private IoTSerializationSchema<IN> serializationSchema;\n+    private IoTDBOptions options;\n+    private transient Session session;\n+\n+    private boolean batchFlushOnCheckpoint; // false by default\n+    private int batchSize = 100;\n+    private List<Event> batchList;\n+\n+    public IoTDBSink(IoTDBOptions options, IoTSerializationSchema<IN> schema) {\n+        this.options = options;\n+        this.serializationSchema = schema;\n+    }\n+\n+    @Override\n+    public void open(Configuration parameters) throws Exception {\n+        batchList = new LinkedList<>();\n+\n+        session = new Session(options.getHost(), options.getPort(), options.getUser(), options.getPassword());\n+        session.open();\n+\n+        session.setStorageGroup(options.getStorageGroup());\n+        for (IoTDBOptions.TimeseriesOption option : options.getTimeseriesOptionList()) {\n+            if (!session.checkTimeseriesExists(option.getPath())) {\n+                session.createTimeseries(option.getPath(), option.getDataType(), option.getEncoding(), option.getCompressor());\n+            }\n+        }\n+\n+        if (batchFlushOnCheckpoint && !((StreamingRuntimeContext) getRuntimeContext()).isCheckpointingEnabled()) {\n+            LOG.warn(\"Flushing on checkpoint is enabled, but checkpointing is not enabled. Disabling flushing.\");\n+            batchFlushOnCheckpoint = false;\n+        }\n+    }\n+\n+    //  for testing\n+    void setSession(Session session) {\n+        this.session = session;\n+    }\n+\n+    @Override\n+    public void invoke(IN input, Context context) throws Exception {\n+        Event event = serializationSchema.serialize(input);\n+        if (event == null) {\n+            return;\n+        }\n+\n+        if (batchFlushOnCheckpoint) {\n+            batchList.add(event);\n+            if (batchList.size() >= batchSize) {\n+                flushSync();\n+            }\n+            return;\n+        }\n+\n+        TSStatus status = session.insert(event.getDevice(), event.getTimestamp(),\n+                event.getMeasurements(), event.getValues());\n+        LOG.debug(\"sync send event result: {}\", status);\n+    }\n+\n+    public IoTDBSink<IN> withBatchFlushOnCheckpoint(boolean batchFlushOnCheckpoint) {\n+        this.batchFlushOnCheckpoint = batchFlushOnCheckpoint;\n+        return this;\n+    }\n+\n+    public IoTDBSink<IN> withBatchSize(int batchSize) {\n+        this.batchSize = batchSize;\n+        return this;\n+    }\n+\n+    @Override\n+    public void close() throws Exception {\n+        if (session != null) {\n+            try {\n+                flushSync();\n+            } catch (Exception e) {\n+                LOG.error(\"flushSync failure\", e);\n+            }\n+           session.close();\n+        }\n+    }\n+\n+    private void flushSync() throws Exception {\n+        if (batchFlushOnCheckpoint) {\n+            synchronized (batchList) {\n+                if (batchList.size() > 0) {\n+                    List<String> deviceIds = new ArrayList<>();\n+                    List<Long> timestamps = new ArrayList<>();\n+                    List<List<String>> measurementsList = new ArrayList<>();\n+                    List<List<String>> valuesList = new ArrayList<>();\n+\n+                    for (Event event : batchList) {\n+                        deviceIds.add(event.getDevice());\n+                        timestamps.add(event.getTimestamp());\n+                        measurementsList.add(event.getMeasurements());\n+                        valuesList.add(event.getValues());\n+                    }\n+                    List<TSStatus> statusList = session.insertInBatch(deviceIds, timestamps, measurementsList, valuesList);\n+                    LOG.debug(\"sync send events result: {}\", statusList);\n+                    batchList.clear();\n+                }\n+            }\n+        }\n+    }\n+\n+    @Override\n+    public void snapshotState(FunctionSnapshotContext context) throws Exception {\n+        flushSync();\n+    }\n+\n+    @Override\n+    public void initializeState(FunctionInitializationContext context) throws Exception {\n+        // nothing to do\n+    }\n+}\n", "next_change": {"commit": "83fc8b53ff4a3bdab7f7839b195ca8addb09901e", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\nindex e647323cd2..fa7d2a1f02 100644\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n", "chunk": "@@ -110,44 +128,34 @@ public class IoTDBSink<IN> extends RichSinkFunction<IN> implements CheckpointedF\n     public void close() throws Exception {\n         if (session != null) {\n             try {\n-                flushSync();\n+                flush();\n             } catch (Exception e) {\n-                LOG.error(\"flushSync failure\", e);\n+                LOG.error(\"flush error\", e);\n             }\n-           session.close();\n+            session.close();\n+        }\n+        if (scheduledExecutor != null) {\n+            scheduledExecutor.shutdown();\n         }\n     }\n \n-    private void flushSync() throws Exception {\n-        if (batchFlushOnCheckpoint) {\n-            synchronized (batchList) {\n-                if (batchList.size() > 0) {\n-                    List<String> deviceIds = new ArrayList<>();\n-                    List<Long> timestamps = new ArrayList<>();\n-                    List<List<String>> measurementsList = new ArrayList<>();\n-                    List<List<String>> valuesList = new ArrayList<>();\n-\n-                    for (Event event : batchList) {\n-                        deviceIds.add(event.getDevice());\n-                        timestamps.add(event.getTimestamp());\n-                        measurementsList.add(event.getMeasurements());\n-                        valuesList.add(event.getValues());\n-                    }\n-                    List<TSStatus> statusList = session.insertInBatch(deviceIds, timestamps, measurementsList, valuesList);\n-                    LOG.debug(\"sync send events result: {}\", statusList);\n-                    batchList.clear();\n-                }\n+    private synchronized void flush() throws Exception {\n+        if (batchSize > 0 && batchList.size() > 0) {\n+            List<String> deviceIds = new ArrayList<>();\n+            List<Long> timestamps = new ArrayList<>();\n+            List<List<String>> measurementsList = new ArrayList<>();\n+            List<List<String>> valuesList = new ArrayList<>();\n+\n+            for (Event event : batchList) {\n+                deviceIds.add(event.getDevice());\n+                timestamps.add(event.getTimestamp());\n+                measurementsList.add(event.getMeasurements());\n+                valuesList.add(event.getValues());\n             }\n+            List<TSStatus> statusList = session.insertInBatch(deviceIds, timestamps, measurementsList, valuesList);\n+            LOG.debug(\"send events result: {}\", statusList);\n+            batchList.clear();\n         }\n     }\n \n-    @Override\n-    public void snapshotState(FunctionSnapshotContext context) throws Exception {\n-        flushSync();\n-    }\n-\n-    @Override\n-    public void initializeState(FunctionInitializationContext context) throws Exception {\n-        // nothing to do\n-    }\n }\n", "next_change": {"commit": "7b693c5b6c14bb3528e0fab31aaa033a3318507d", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\nindex fa7d2a1f02..0495fac617 100644\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n", "chunk": "@@ -139,22 +148,38 @@ public class IoTDBSink<IN> extends RichSinkFunction<IN> {\n         }\n     }\n \n-    private synchronized void flush() throws Exception {\n-        if (batchSize > 0 && batchList.size() > 0) {\n-            List<String> deviceIds = new ArrayList<>();\n-            List<Long> timestamps = new ArrayList<>();\n-            List<List<String>> measurementsList = new ArrayList<>();\n-            List<List<String>> valuesList = new ArrayList<>();\n-\n-            for (Event event : batchList) {\n-                deviceIds.add(event.getDevice());\n-                timestamps.add(event.getTimestamp());\n-                measurementsList.add(event.getMeasurements());\n-                valuesList.add(event.getValues());\n+    private void convertText(String device, List<String> measurements, List<String> values) {\n+        if (device != null && measurements != null && values != null && measurements.size() == values.size()) {\n+            for (int i = 0; i < measurements.size(); i++) {\n+                String measurement = device + \".\" + measurements.get(i);\n+                IoTDBOptions.TimeseriesOption timeseriesOption = timeseriesOptionMap.get(measurement);\n+                if (timeseriesOption!= null && TSDataType.TEXT.equals(timeseriesOption.getDataType())) {\n+                    // The TEXT data type should be covered by \" or '\n+                    values.set(i, \"'\" + values.get(i) + \"'\");\n+                }\n+            }\n+        }\n+    }\n+\n+    private void flush() throws Exception {\n+        synchronized (batchList) {\n+            if (batchSize > 0 && batchList.size() > 0) {\n+                List<String> deviceIds = new ArrayList<>();\n+                List<Long> timestamps = new ArrayList<>();\n+                List<List<String>> measurementsList = new ArrayList<>();\n+                List<List<String>> valuesList = new ArrayList<>();\n+\n+                for (Event event : batchList) {\n+                    convertText(event.getDevice(), event.getMeasurements(), event.getValues());\n+                    deviceIds.add(event.getDevice());\n+                    timestamps.add(event.getTimestamp());\n+                    measurementsList.add(event.getMeasurements());\n+                    valuesList.add(event.getValues());\n+                }\n+                List<TSStatus> statusList = session.insertInBatch(deviceIds, timestamps, measurementsList, valuesList);\n+                LOG.debug(\"send events result: {}\", statusList);\n+                batchList.clear();\n             }\n-            List<TSStatus> statusList = session.insertInBatch(deviceIds, timestamps, measurementsList, valuesList);\n-            LOG.debug(\"send events result: {}\", statusList);\n-            batchList.clear();\n         }\n     }\n \n", "next_change": {"commit": "78778429d60212a6b983d855a955c07e3d93eb69", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\nindex 0495fac617..cda69c0773 100644\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n", "chunk": "@@ -162,23 +162,25 @@ public class IoTDBSink<IN> extends RichSinkFunction<IN> {\n     }\n \n     private void flush() throws Exception {\n-        synchronized (batchList) {\n-            if (batchSize > 0 && batchList.size() > 0) {\n-                List<String> deviceIds = new ArrayList<>();\n-                List<Long> timestamps = new ArrayList<>();\n-                List<List<String>> measurementsList = new ArrayList<>();\n-                List<List<String>> valuesList = new ArrayList<>();\n-\n-                for (Event event : batchList) {\n-                    convertText(event.getDevice(), event.getMeasurements(), event.getValues());\n-                    deviceIds.add(event.getDevice());\n-                    timestamps.add(event.getTimestamp());\n-                    measurementsList.add(event.getMeasurements());\n-                    valuesList.add(event.getValues());\n+        if (batchSize > 0) {\n+            synchronized (batchList) {\n+                if (batchList.size() > 0) {\n+                    List<String> deviceIds = new ArrayList<>();\n+                    List<Long> timestamps = new ArrayList<>();\n+                    List<List<String>> measurementsList = new ArrayList<>();\n+                    List<List<String>> valuesList = new ArrayList<>();\n+\n+                    for (Event event : batchList) {\n+                        convertText(event.getDevice(), event.getMeasurements(), event.getValues());\n+                        deviceIds.add(event.getDevice());\n+                        timestamps.add(event.getTimestamp());\n+                        measurementsList.add(event.getMeasurements());\n+                        valuesList.add(event.getValues());\n+                    }\n+                    List<TSStatus> statusList = session.insertInBatch(deviceIds, timestamps, measurementsList, valuesList);\n+                    LOG.debug(\"send events result: {}\", statusList);\n+                    batchList.clear();\n                 }\n-                List<TSStatus> statusList = session.insertInBatch(deviceIds, timestamps, measurementsList, valuesList);\n-                LOG.debug(\"send events result: {}\", statusList);\n-                batchList.clear();\n             }\n         }\n     }\n", "next_change": {"commit": "32f32f62f62a5fdb59fa751a00556505fb604114", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\nindex cda69c0773..1f405d631d 100644\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n", "chunk": "@@ -184,5 +184,4 @@ public class IoTDBSink<IN> extends RichSinkFunction<IN> {\n             }\n         }\n     }\n-\n }\n", "next_change": null}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg4MDI0OA==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r382880248", "body": "It's better to add more device data?", "bodyText": "It's better to add more device data?", "bodyHTML": "<p dir=\"auto\">It's better to add more device data?</p>", "author": "sunjincheng121", "createdAt": "2020-02-22T02:59:20Z", "path": "example/flink-example/src/main/java/org/apache/iotdb/flink/Example.java", "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.iotdb.flink;\n+\n+import com.google.common.collect.Lists;\n+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\n+import org.apache.flink.streaming.api.functions.source.SourceFunction;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Random;\n+\n+public class Example {\n+    public static void main(String[] args) {\n+        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n+        env.enableCheckpointing(3000);\n+\n+        IoTDBOptions options = new IoTDBOptions();\n+        options.setHost(\"127.0.0.1\");\n+        options.setPort(6667);\n+        options.setUser(\"root\");\n+        options.setPassword(\"root\");\n+        options.setStorageGroup(\"root.sg\");\n+        options.setTimeseriesOptionList(Lists.newArrayList(new IoTDBOptions.TimeseriesOption(\"root.sg.d1.s1\")));\n+\n+        IoTSerializationSchema serializationSchema = new DefaultIoTSerializationSchema(options);\n+        IoTDBSink ioTDBSink = new IoTDBSink(options, serializationSchema)\n+                // enable batching\n+                .withBatchFlushOnCheckpoint(true)\n+                .withBatchSize(10)\n+                ;\n+\n+        env.addSource(new SensorSource())\n+                .name(\"sensor-source\")\n+                .setParallelism(1)\n+\n+                .addSink(ioTDBSink)\n+                .name(\"iotdb-sink\")\n+                .setParallelism(1)\n+        ;\n+\n+        try {\n+            env.execute(\"iotdb-flink-example\");\n+        } catch (Exception e) {\n+            e.printStackTrace();\n+        }\n+    }\n+\n+    private static class SensorSource implements SourceFunction<Map<String,String>> {\n+        boolean running = true;\n+\n+        @Override\n+        public void run(SourceContext context) throws Exception {\n+            Random random = new Random();\n+            while (running) {\n+                Map tuple = new HashMap();\n+                tuple.put(\"device\", \"root.sg.d1\");", "originalCommit": "115b8cec1082524ff5ef18af2e4ede53762fdc8b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjkyMTM5Mw==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r382921393", "bodyText": "I prefer to keep the example simpler.", "author": "vesense", "createdAt": "2020-02-22T15:45:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg4MDI0OA=="}], "type": "inlineReview", "revised_code": {"commit": "2f12978cc65cfc47f659b837e174d535fe2f53af", "changed_code": [{"header": "diff --git a/example/flink-example/src/main/java/org/apache/iotdb/flink/Example.java b/example/flink-example/src/main/java/org/apache/iotdb/flink/Example.java\ndeleted file mode 100644\nindex b4141bee6e..0000000000\n--- a/example/flink-example/src/main/java/org/apache/iotdb/flink/Example.java\n+++ /dev/null\n", "chunk": "@@ -1,87 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.iotdb.flink;\n-\n-import com.google.common.collect.Lists;\n-import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\n-import org.apache.flink.streaming.api.functions.source.SourceFunction;\n-\n-import java.util.HashMap;\n-import java.util.Map;\n-import java.util.Random;\n-\n-public class Example {\n-    public static void main(String[] args) {\n-        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n-        env.enableCheckpointing(3000);\n-\n-        IoTDBOptions options = new IoTDBOptions();\n-        options.setHost(\"127.0.0.1\");\n-        options.setPort(6667);\n-        options.setUser(\"root\");\n-        options.setPassword(\"root\");\n-        options.setStorageGroup(\"root.sg\");\n-        options.setTimeseriesOptionList(Lists.newArrayList(new IoTDBOptions.TimeseriesOption(\"root.sg.d1.s1\")));\n-\n-        IoTSerializationSchema serializationSchema = new DefaultIoTSerializationSchema(options);\n-        IoTDBSink ioTDBSink = new IoTDBSink(options, serializationSchema)\n-                // enable batching\n-                .withBatchFlushOnCheckpoint(true)\n-                .withBatchSize(10)\n-                ;\n-\n-        env.addSource(new SensorSource())\n-                .name(\"sensor-source\")\n-                .setParallelism(1)\n-\n-                .addSink(ioTDBSink)\n-                .name(\"iotdb-sink\")\n-                .setParallelism(1)\n-        ;\n-\n-        try {\n-            env.execute(\"iotdb-flink-example\");\n-        } catch (Exception e) {\n-            e.printStackTrace();\n-        }\n-    }\n-\n-    private static class SensorSource implements SourceFunction<Map<String,String>> {\n-        boolean running = true;\n-\n-        @Override\n-        public void run(SourceContext context) throws Exception {\n-            Random random = new Random();\n-            while (running) {\n-                Map tuple = new HashMap();\n-                tuple.put(\"device\", \"root.sg.d1\");\n-                tuple.put(\"timestamp\", String.valueOf(System.currentTimeMillis()));\n-                tuple.put(\"measurements\", \"s1\");\n-                tuple.put(\"values\", String.valueOf(random.nextDouble()));\n-\n-                context.collect(tuple);\n-                Thread.sleep(1000);\n-            }\n-        }\n-\n-        @Override\n-        public void cancel() {\n-            running = false;\n-        }\n-    }\n-}\n", "next_change": {"commit": "b10c17af87692b9992a07eabd224bf4407600937", "changed_code": [{"header": "diff --git a/example/flink-example/src/main/java/org/apache/iotdb/flink/Example.java b/example/flink-example/src/main/java/org/apache/iotdb/flink/Example.java\nnew file mode 100644\nindex 0000000000..b4141bee6e\n--- /dev/null\n+++ b/example/flink-example/src/main/java/org/apache/iotdb/flink/Example.java\n", "chunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.iotdb.flink;\n+\n+import com.google.common.collect.Lists;\n+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\n+import org.apache.flink.streaming.api.functions.source.SourceFunction;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Random;\n+\n+public class Example {\n+    public static void main(String[] args) {\n+        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n+        env.enableCheckpointing(3000);\n+\n+        IoTDBOptions options = new IoTDBOptions();\n+        options.setHost(\"127.0.0.1\");\n+        options.setPort(6667);\n+        options.setUser(\"root\");\n+        options.setPassword(\"root\");\n+        options.setStorageGroup(\"root.sg\");\n+        options.setTimeseriesOptionList(Lists.newArrayList(new IoTDBOptions.TimeseriesOption(\"root.sg.d1.s1\")));\n+\n+        IoTSerializationSchema serializationSchema = new DefaultIoTSerializationSchema(options);\n+        IoTDBSink ioTDBSink = new IoTDBSink(options, serializationSchema)\n+                // enable batching\n+                .withBatchFlushOnCheckpoint(true)\n+                .withBatchSize(10)\n+                ;\n+\n+        env.addSource(new SensorSource())\n+                .name(\"sensor-source\")\n+                .setParallelism(1)\n+\n+                .addSink(ioTDBSink)\n+                .name(\"iotdb-sink\")\n+                .setParallelism(1)\n+        ;\n+\n+        try {\n+            env.execute(\"iotdb-flink-example\");\n+        } catch (Exception e) {\n+            e.printStackTrace();\n+        }\n+    }\n+\n+    private static class SensorSource implements SourceFunction<Map<String,String>> {\n+        boolean running = true;\n+\n+        @Override\n+        public void run(SourceContext context) throws Exception {\n+            Random random = new Random();\n+            while (running) {\n+                Map tuple = new HashMap();\n+                tuple.put(\"device\", \"root.sg.d1\");\n+                tuple.put(\"timestamp\", String.valueOf(System.currentTimeMillis()));\n+                tuple.put(\"measurements\", \"s1\");\n+                tuple.put(\"values\", String.valueOf(random.nextDouble()));\n+\n+                context.collect(tuple);\n+                Thread.sleep(1000);\n+            }\n+        }\n+\n+        @Override\n+        public void cancel() {\n+            running = false;\n+        }\n+    }\n+}\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg4MDU5MA==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r382880590", "body": "This is not necessary in this PR, right? [1]\r\nhttps://github.com/apache/incubator-iotdb/pull/824/files", "bodyText": "This is not necessary in this PR, right? [1]\nhttps://github.com/apache/incubator-iotdb/pull/824/files", "bodyHTML": "<p dir=\"auto\">This is not necessary in this PR, right? [1]<br>\n<a href=\"https://github.com/apache/incubator-iotdb/pull/824/files\">https://github.com/apache/incubator-iotdb/pull/824/files</a></p>", "author": "sunjincheng121", "createdAt": "2020-02-22T03:03:55Z", "path": "example/session/src/main/java/org/apache/iotdb/SessionExample.java", "diffHunk": "@@ -44,9 +44,15 @@ public static void main(String[] args)\n     session.open();\n \n     session.setStorageGroup(\"root.sg1\");\n-    session.createTimeseries(\"root.sg1.d1.s1\", TSDataType.INT64, TSEncoding.RLE, CompressionType.SNAPPY);\n-    session.createTimeseries(\"root.sg1.d1.s2\", TSDataType.INT64, TSEncoding.RLE, CompressionType.SNAPPY);\n-    session.createTimeseries(\"root.sg1.d1.s3\", TSDataType.INT64, TSEncoding.RLE, CompressionType.SNAPPY);\n+    if (session.checkTimeseriesExists(\"root.sg1.d1.s1\")) {\n+      session.createTimeseries(\"root.sg1.d1.s1\", TSDataType.INT64, TSEncoding.RLE, CompressionType.SNAPPY);\n+    }\n+    if (session.checkTimeseriesExists(\"root.sg1.d1.s2\")) {\n+      session.createTimeseries(\"root.sg1.d1.s2\", TSDataType.INT64, TSEncoding.RLE, CompressionType.SNAPPY);\n+    }\n+    if (session.checkTimeseriesExists(\"root.sg1.d1.s3\")) {\n+      session.createTimeseries(\"root.sg1.d1.s3\", TSDataType.INT64, TSEncoding.RLE, CompressionType.SNAPPY);\n+    }", "originalCommit": "115b8cec1082524ff5ef18af2e4ede53762fdc8b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjkwODA4NQ==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r382908085", "bodyText": "Updated.", "author": "vesense", "createdAt": "2020-02-22T12:06:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg4MDU5MA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg4MDgxMA==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r382880810", "body": "This is not necessary in this PR, right? [1]\r\nhttps://github.com/apache/incubator-iotdb/pull/824/files", "bodyText": "This is not necessary in this PR, right? [1]\nhttps://github.com/apache/incubator-iotdb/pull/824/files", "bodyHTML": "<p dir=\"auto\">This is not necessary in this PR, right? [1]<br>\n<a href=\"https://github.com/apache/incubator-iotdb/pull/824/files\">https://github.com/apache/incubator-iotdb/pull/824/files</a></p>", "author": "sunjincheng121", "createdAt": "2020-02-22T03:07:47Z", "path": "session/src/main/java/org/apache/iotdb/session/Session.java", "diffHunk": "@@ -558,6 +558,15 @@ public TSStatus createTimeseries(String path, TSDataType dataType,\n     }\n   }\n \n+  public boolean checkTimeseriesExists(String path) throws IoTDBSessionException {", "originalCommit": "115b8cec1082524ff5ef18af2e4ede53762fdc8b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjkwODEwOA==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r382908108", "bodyText": "Updated.", "author": "vesense", "createdAt": "2020-02-22T12:06:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg4MDgxMA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg4MTIxNg==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r382881216", "body": "Could you please add some Java Doc for the class :)", "bodyText": "Could you please add some Java Doc for the class :)", "bodyHTML": "<p dir=\"auto\">Could you please add some Java Doc for the class :)</p>", "author": "sunjincheng121", "createdAt": "2020-02-22T03:14:54Z", "path": "flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/Event.java", "diffHunk": "@@ -0,0 +1,51 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.iotdb.flink;\n+\n+import java.util.List;\n+\n+public class Event {", "originalCommit": "115b8cec1082524ff5ef18af2e4ede53762fdc8b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjkxODcwOQ==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r382918709", "bodyText": "Will update.", "author": "vesense", "createdAt": "2020-02-22T15:05:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg4MTIxNg=="}], "type": "inlineReview", "revised_code": {"commit": "2f12978cc65cfc47f659b837e174d535fe2f53af", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/Event.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/Event.java\ndeleted file mode 100644\nindex a03e091bcd..0000000000\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/Event.java\n+++ /dev/null\n", "chunk": "@@ -1,51 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.iotdb.flink;\n-\n-import java.util.List;\n-\n-public class Event {\n-    private String device;\n-    private Long timestamp;\n-    private List<String> measurements;\n-    private List<String> values;\n-\n-    public Event(String device, Long timestamp, List<String> measurements, List<String> values) {\n-        this.device = device;\n-        this.timestamp = timestamp;\n-        this.measurements = measurements;\n-        this.values = values;\n-    }\n-\n-    public String getDevice() {\n-        return device;\n-    }\n-\n-    public Long getTimestamp() {\n-        return timestamp;\n-    }\n-\n-    public List<String> getMeasurements() {\n-        return measurements;\n-    }\n-\n-    public List<String> getValues() {\n-        return values;\n-    }\n-}\n\\ No newline at end of file\n", "next_change": {"commit": "b10c17af87692b9992a07eabd224bf4407600937", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/Event.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/Event.java\nnew file mode 100644\nindex 0000000000..a03e091bcd\n--- /dev/null\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/Event.java\n", "chunk": "@@ -0,0 +1,51 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.iotdb.flink;\n+\n+import java.util.List;\n+\n+public class Event {\n+    private String device;\n+    private Long timestamp;\n+    private List<String> measurements;\n+    private List<String> values;\n+\n+    public Event(String device, Long timestamp, List<String> measurements, List<String> values) {\n+        this.device = device;\n+        this.timestamp = timestamp;\n+        this.measurements = measurements;\n+        this.values = values;\n+    }\n+\n+    public String getDevice() {\n+        return device;\n+    }\n+\n+    public Long getTimestamp() {\n+        return timestamp;\n+    }\n+\n+    public List<String> getMeasurements() {\n+        return measurements;\n+    }\n+\n+    public List<String> getValues() {\n+        return values;\n+    }\n+}\n\\ No newline at end of file\n", "next_change": {"commit": "83fc8b53ff4a3bdab7f7839b195ca8addb09901e", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/Event.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/Event.java\nindex a03e091bcd..6cccb23353 100644\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/Event.java\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/Event.java\n", "chunk": "@@ -48,4 +51,4 @@ public class Event {\n     public List<String> getValues() {\n         return values;\n     }\n-}\n\\ No newline at end of file\n+}\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg4MjQ4Mg==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r382882482", "body": "It's better to add test case for `batchFlushOnCheckpoint=true`?", "bodyText": "It's better to add test case for batchFlushOnCheckpoint=true?", "bodyHTML": "<p dir=\"auto\">It's better to add test case for <code>batchFlushOnCheckpoint=true</code>?</p>", "author": "sunjincheng121", "createdAt": "2020-02-22T03:36:54Z", "path": "flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkTest.java", "diffHunk": "@@ -0,0 +1,67 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.iotdb.flink;\n+\n+import com.google.common.collect.Lists;\n+import org.apache.iotdb.session.Session;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.mockito.Matchers.any;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.verify;\n+\n+public class IoTDBSinkTest {\n+\n+    private IoTDBSink ioTDBSink;\n+    private Session session;\n+\n+    @Before\n+    public void setUp() throws Exception {\n+        IoTDBOptions options = new IoTDBOptions();\n+        options.setTimeseriesOptionList(Lists.newArrayList(new IoTDBOptions.TimeseriesOption(\"root.sg.D01.temperature\")));\n+        ioTDBSink = new IoTDBSink(options, new DefaultIoTSerializationSchema(options));\n+\n+        session = mock(Session.class);\n+        ioTDBSink.setSession(session);\n+    }\n+\n+    @Test\n+    public void testSink() throws Exception {", "originalCommit": "115b8cec1082524ff5ef18af2e4ede53762fdc8b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjkyMTQyMw==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r382921423", "bodyText": "Make sense, will update.", "author": "vesense", "createdAt": "2020-02-22T15:46:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg4MjQ4Mg=="}], "type": "inlineReview", "revised_code": {"commit": "2f12978cc65cfc47f659b837e174d535fe2f53af", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkTest.java b/flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkTest.java\ndeleted file mode 100644\nindex a576f1e8c0..0000000000\n--- a/flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkTest.java\n+++ /dev/null\n", "chunk": "@@ -1,67 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.iotdb.flink;\n-\n-import com.google.common.collect.Lists;\n-import org.apache.iotdb.session.Session;\n-import org.junit.Before;\n-import org.junit.Test;\n-\n-import java.util.HashMap;\n-import java.util.List;\n-import java.util.Map;\n-\n-import static org.mockito.Matchers.any;\n-import static org.mockito.Mockito.mock;\n-import static org.mockito.Mockito.verify;\n-\n-public class IoTDBSinkTest {\n-\n-    private IoTDBSink ioTDBSink;\n-    private Session session;\n-\n-    @Before\n-    public void setUp() throws Exception {\n-        IoTDBOptions options = new IoTDBOptions();\n-        options.setTimeseriesOptionList(Lists.newArrayList(new IoTDBOptions.TimeseriesOption(\"root.sg.D01.temperature\")));\n-        ioTDBSink = new IoTDBSink(options, new DefaultIoTSerializationSchema(options));\n-\n-        session = mock(Session.class);\n-        ioTDBSink.setSession(session);\n-    }\n-\n-    @Test\n-    public void testSink() throws Exception {\n-        Map tuple = new HashMap();\n-        tuple.put(\"device\", \"root.sg.D01\");\n-        tuple.put(\"timestamp\", \"1581861293000\");\n-        tuple.put(\"measurements\", \"temperature\");\n-        tuple.put(\"values\", \"36.5\");\n-\n-        ioTDBSink.invoke(tuple, null);\n-        verify(session).insert(any(String.class), any(Long.class), any(List.class), any(List.class));\n-    }\n-\n-    @Test\n-    public void close() throws Exception {\n-        ioTDBSink.close();\n-        verify(session).close();\n-    }\n-\n-}\n\\ No newline at end of file\n", "next_change": {"commit": "b10c17af87692b9992a07eabd224bf4407600937", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkTest.java b/flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkTest.java\nnew file mode 100644\nindex 0000000000..a576f1e8c0\n--- /dev/null\n+++ b/flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkTest.java\n", "chunk": "@@ -0,0 +1,67 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.iotdb.flink;\n+\n+import com.google.common.collect.Lists;\n+import org.apache.iotdb.session.Session;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.mockito.Matchers.any;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.verify;\n+\n+public class IoTDBSinkTest {\n+\n+    private IoTDBSink ioTDBSink;\n+    private Session session;\n+\n+    @Before\n+    public void setUp() throws Exception {\n+        IoTDBOptions options = new IoTDBOptions();\n+        options.setTimeseriesOptionList(Lists.newArrayList(new IoTDBOptions.TimeseriesOption(\"root.sg.D01.temperature\")));\n+        ioTDBSink = new IoTDBSink(options, new DefaultIoTSerializationSchema(options));\n+\n+        session = mock(Session.class);\n+        ioTDBSink.setSession(session);\n+    }\n+\n+    @Test\n+    public void testSink() throws Exception {\n+        Map tuple = new HashMap();\n+        tuple.put(\"device\", \"root.sg.D01\");\n+        tuple.put(\"timestamp\", \"1581861293000\");\n+        tuple.put(\"measurements\", \"temperature\");\n+        tuple.put(\"values\", \"36.5\");\n+\n+        ioTDBSink.invoke(tuple, null);\n+        verify(session).insert(any(String.class), any(Long.class), any(List.class), any(List.class));\n+    }\n+\n+    @Test\n+    public void close() throws Exception {\n+        ioTDBSink.close();\n+        verify(session).close();\n+    }\n+\n+}\n\\ No newline at end of file\n", "next_change": {"commit": "83fc8b53ff4a3bdab7f7839b195ca8addb09901e", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkTest.java b/flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkInsertTest.java\nsimilarity index 96%\nrename from flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkTest.java\nrename to flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkInsertTest.java\nindex a576f1e8c0..7b297ffeb7 100644\n--- a/flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkTest.java\n+++ b/flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkInsertTest.java\n", "chunk": "@@ -64,4 +64,4 @@ public class IoTDBSinkTest {\n         verify(session).close();\n     }\n \n-}\n\\ No newline at end of file\n+}\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg4MjU0OQ==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r382882549", "body": "It's better to add test case for this class, What do you think? ", "bodyText": "It's better to add test case for this class, What do you think?", "bodyHTML": "<p dir=\"auto\">It's better to add test case for this class, What do you think?</p>", "author": "sunjincheng121", "createdAt": "2020-02-22T03:38:30Z", "path": "flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java", "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.iotdb.flink;\n+\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+public class DefaultIoTSerializationSchema implements IoTSerializationSchema<Map<String,String>> {", "originalCommit": "115b8cec1082524ff5ef18af2e4ede53762fdc8b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjkwODY3OA==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r382908678", "bodyText": "Will update.", "author": "vesense", "createdAt": "2020-02-22T12:17:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg4MjU0OQ=="}], "type": "inlineReview", "revised_code": {"commit": "2f12978cc65cfc47f659b837e174d535fe2f53af", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java\ndeleted file mode 100644\nindex 0da9d8a214..0000000000\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java\n+++ /dev/null\n", "chunk": "@@ -1,78 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.iotdb.flink;\n-\n-import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n-\n-import java.util.Arrays;\n-import java.util.HashMap;\n-import java.util.List;\n-import java.util.Map;\n-\n-public class DefaultIoTSerializationSchema implements IoTSerializationSchema<Map<String,String>> {\n-    public static final String FIELD_DEVICE = \"device\";\n-    public static final String FIELD_TIMESTAMP = \"timestamp\";\n-    public static final String FIELD_MEASUREMENTS = \"measurements\";\n-    public static final String FIELD_VALUES = \"values\";\n-    public static final String DEFAULT_SEPARATOR = \",\";\n-\n-    private Map<String, IoTDBOptions.TimeseriesOption> timeseriesOptionMap;\n-\n-    public DefaultIoTSerializationSchema(IoTDBOptions ioTDBOptions) {\n-        timeseriesOptionMap = new HashMap<>();\n-        for (IoTDBOptions.TimeseriesOption timeseriesOption : ioTDBOptions.getTimeseriesOptionList()) {\n-            timeseriesOptionMap.put(timeseriesOption.getPath(), timeseriesOption);\n-        }\n-    }\n-\n-    @Override\n-    public Event serialize(Map<String,String> tuple) {\n-        if (tuple == null) {\n-            return null;\n-        }\n-\n-        String device = tuple.get(FIELD_DEVICE);\n-\n-        String ts = tuple.get(FIELD_TIMESTAMP);\n-        Long timestamp = ts == null ? System.currentTimeMillis() : Long.parseLong(ts);\n-\n-        List<String> measurements = null;\n-        if (tuple.get(FIELD_MEASUREMENTS) != null) {\n-            measurements = Arrays.asList(tuple.get(FIELD_MEASUREMENTS).split(DEFAULT_SEPARATOR));\n-        }\n-\n-        List<String> values = null;\n-        if (tuple.get(FIELD_VALUES) != null) {\n-            values = Arrays.asList(tuple.get(FIELD_VALUES).split(DEFAULT_SEPARATOR));\n-        }\n-\n-        if (device != null && measurements != null && values != null && measurements.size() == values.size()) {\n-            for (int i = 0; i < measurements.size(); i++) {\n-                String measurement = device + \".\" + measurements.get(i);\n-                IoTDBOptions.TimeseriesOption timeseriesOption = timeseriesOptionMap.get(measurement);\n-                if (timeseriesOption!= null && TSDataType.TEXT.equals(timeseriesOption.getDataType())) {\n-                    // The TEXT data type should be covered by \" or '\n-                    values.set(i, \"'\" + values.get(i) + \"'\");\n-                }\n-            }\n-        }\n-\n-        return new Event(device, timestamp, measurements, values);\n-    }\n-}\n\\ No newline at end of file\n", "next_change": {"commit": "b10c17af87692b9992a07eabd224bf4407600937", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java\nnew file mode 100644\nindex 0000000000..0da9d8a214\n--- /dev/null\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java\n", "chunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.iotdb.flink;\n+\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+public class DefaultIoTSerializationSchema implements IoTSerializationSchema<Map<String,String>> {\n+    public static final String FIELD_DEVICE = \"device\";\n+    public static final String FIELD_TIMESTAMP = \"timestamp\";\n+    public static final String FIELD_MEASUREMENTS = \"measurements\";\n+    public static final String FIELD_VALUES = \"values\";\n+    public static final String DEFAULT_SEPARATOR = \",\";\n+\n+    private Map<String, IoTDBOptions.TimeseriesOption> timeseriesOptionMap;\n+\n+    public DefaultIoTSerializationSchema(IoTDBOptions ioTDBOptions) {\n+        timeseriesOptionMap = new HashMap<>();\n+        for (IoTDBOptions.TimeseriesOption timeseriesOption : ioTDBOptions.getTimeseriesOptionList()) {\n+            timeseriesOptionMap.put(timeseriesOption.getPath(), timeseriesOption);\n+        }\n+    }\n+\n+    @Override\n+    public Event serialize(Map<String,String> tuple) {\n+        if (tuple == null) {\n+            return null;\n+        }\n+\n+        String device = tuple.get(FIELD_DEVICE);\n+\n+        String ts = tuple.get(FIELD_TIMESTAMP);\n+        Long timestamp = ts == null ? System.currentTimeMillis() : Long.parseLong(ts);\n+\n+        List<String> measurements = null;\n+        if (tuple.get(FIELD_MEASUREMENTS) != null) {\n+            measurements = Arrays.asList(tuple.get(FIELD_MEASUREMENTS).split(DEFAULT_SEPARATOR));\n+        }\n+\n+        List<String> values = null;\n+        if (tuple.get(FIELD_VALUES) != null) {\n+            values = Arrays.asList(tuple.get(FIELD_VALUES).split(DEFAULT_SEPARATOR));\n+        }\n+\n+        if (device != null && measurements != null && values != null && measurements.size() == values.size()) {\n+            for (int i = 0; i < measurements.size(); i++) {\n+                String measurement = device + \".\" + measurements.get(i);\n+                IoTDBOptions.TimeseriesOption timeseriesOption = timeseriesOptionMap.get(measurement);\n+                if (timeseriesOption!= null && TSDataType.TEXT.equals(timeseriesOption.getDataType())) {\n+                    // The TEXT data type should be covered by \" or '\n+                    values.set(i, \"'\" + values.get(i) + \"'\");\n+                }\n+            }\n+        }\n+\n+        return new Event(device, timestamp, measurements, values);\n+    }\n+}\n\\ No newline at end of file\n", "next_change": {"commit": "83fc8b53ff4a3bdab7f7839b195ca8addb09901e", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java\nindex 0da9d8a214..a439a94557 100644\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java\n", "chunk": "@@ -75,4 +79,4 @@ public class DefaultIoTSerializationSchema implements IoTSerializationSchema<Map\n \n         return new Event(device, timestamp, measurements, values);\n     }\n-}\n\\ No newline at end of file\n+}\n", "next_change": {"commit": "7b693c5b6c14bb3528e0fab31aaa033a3318507d", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java\nindex a439a94557..4ac596b5a4 100644\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java\n", "chunk": "@@ -51,32 +39,61 @@ public class DefaultIoTSerializationSchema implements IoTSerializationSchema<Map\n             return null;\n         }\n \n-        String device = tuple.get(FIELD_DEVICE);\n+        String device = tuple.get(fieldDevice);\n \n-        String ts = tuple.get(FIELD_TIMESTAMP);\n+        String ts = tuple.get(fieldTimestamp);\n         Long timestamp = ts == null ? System.currentTimeMillis() : Long.parseLong(ts);\n \n         List<String> measurements = null;\n-        if (tuple.get(FIELD_MEASUREMENTS) != null) {\n-            measurements = Arrays.asList(tuple.get(FIELD_MEASUREMENTS).split(DEFAULT_SEPARATOR));\n+        if (tuple.get(fieldMeasurements) != null) {\n+            measurements = Arrays.asList(tuple.get(fieldMeasurements).split(separator));\n         }\n \n         List<String> values = null;\n-        if (tuple.get(FIELD_VALUES) != null) {\n-            values = Arrays.asList(tuple.get(FIELD_VALUES).split(DEFAULT_SEPARATOR));\n-        }\n-\n-        if (device != null && measurements != null && values != null && measurements.size() == values.size()) {\n-            for (int i = 0; i < measurements.size(); i++) {\n-                String measurement = device + \".\" + measurements.get(i);\n-                IoTDBOptions.TimeseriesOption timeseriesOption = timeseriesOptionMap.get(measurement);\n-                if (timeseriesOption!= null && TSDataType.TEXT.equals(timeseriesOption.getDataType())) {\n-                    // The TEXT data type should be covered by \" or '\n-                    values.set(i, \"'\" + values.get(i) + \"'\");\n-                }\n-            }\n+        if (tuple.get(fieldValues) != null) {\n+            values = Arrays.asList(tuple.get(fieldValues).split(separator));\n         }\n \n         return new Event(device, timestamp, measurements, values);\n     }\n+\n+    public String getFieldDevice() {\n+        return fieldDevice;\n+    }\n+\n+    public void setFieldDevice(String fieldDevice) {\n+        this.fieldDevice = fieldDevice;\n+    }\n+\n+    public String getFieldTimestamp() {\n+        return fieldTimestamp;\n+    }\n+\n+    public void setFieldTimestamp(String fieldTimestamp) {\n+        this.fieldTimestamp = fieldTimestamp;\n+    }\n+\n+    public String getFieldMeasurements() {\n+        return fieldMeasurements;\n+    }\n+\n+    public void setFieldMeasurements(String fieldMeasurements) {\n+        this.fieldMeasurements = fieldMeasurements;\n+    }\n+\n+    public String getFieldValues() {\n+        return fieldValues;\n+    }\n+\n+    public void setFieldValues(String fieldValues) {\n+        this.fieldValues = fieldValues;\n+    }\n+\n+    public String getSeparator() {\n+        return separator;\n+    }\n+\n+    public void setSeparator(String separator) {\n+        this.separator = separator;\n+    }\n }\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg4Mjg1OQ==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r382882859", "body": "It's better add Java Doc for this interface.", "bodyText": "It's better add Java Doc for this interface.", "bodyHTML": "<p dir=\"auto\">It's better add Java Doc for this interface.</p>", "author": "sunjincheng121", "createdAt": "2020-02-22T03:43:46Z", "path": "flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTSerializationSchema.java", "diffHunk": "@@ -0,0 +1,27 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.iotdb.flink;\n+\n+import java.io.Serializable;\n+\n+public interface IoTSerializationSchema<T> extends Serializable {", "originalCommit": "115b8cec1082524ff5ef18af2e4ede53762fdc8b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjkwODY3NA==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r382908674", "bodyText": "Will update.", "author": "vesense", "createdAt": "2020-02-22T12:17:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjg4Mjg1OQ=="}], "type": "inlineReview", "revised_code": {"commit": "2f12978cc65cfc47f659b837e174d535fe2f53af", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTSerializationSchema.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTSerializationSchema.java\ndeleted file mode 100644\nindex 5cc33fd528..0000000000\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTSerializationSchema.java\n+++ /dev/null\n", "chunk": "@@ -1,27 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- * http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.iotdb.flink;\n-\n-import java.io.Serializable;\n-\n-public interface IoTSerializationSchema<T> extends Serializable {\n-\n-    Event serialize(T tuple);\n-\n-}\n\\ No newline at end of file\n", "next_change": {"commit": "b10c17af87692b9992a07eabd224bf4407600937", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTSerializationSchema.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTSerializationSchema.java\nnew file mode 100644\nindex 0000000000..5cc33fd528\n--- /dev/null\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTSerializationSchema.java\n", "chunk": "@@ -0,0 +1,27 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.iotdb.flink;\n+\n+import java.io.Serializable;\n+\n+public interface IoTSerializationSchema<T> extends Serializable {\n+\n+    Event serialize(T tuple);\n+\n+}\n\\ No newline at end of file\n", "next_change": {"commit": "83fc8b53ff4a3bdab7f7839b195ca8addb09901e", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTSerializationSchema.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTSerializationSchema.java\nindex 5cc33fd528..9c9f9599fb 100644\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTSerializationSchema.java\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTSerializationSchema.java\n", "chunk": "@@ -20,8 +20,12 @@ package org.apache.iotdb.flink;\n \n import java.io.Serializable;\n \n+/**\n+ * IoTSerializationSchema serializes the input tuple data into events for inserting into IoTDB server.\n+ * @param <T>\n+ */\n public interface IoTSerializationSchema<T> extends Serializable {\n \n     Event serialize(T tuple);\n \n-}\n\\ No newline at end of file\n+}\n", "next_change": {"commit": "7b693c5b6c14bb3528e0fab31aaa033a3318507d", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTSerializationSchema.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTSerializationSchema.java\nindex 9c9f9599fb..e0b72d437d 100644\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTSerializationSchema.java\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTSerializationSchema.java\n", "chunk": "@@ -22,7 +22,7 @@ import java.io.Serializable;\n \n /**\n  * IoTSerializationSchema serializes the input tuple data into events for inserting into IoTDB server.\n- * @param <T>\n+ * @param <T> the input data type\n  */\n public interface IoTSerializationSchema<T> extends Serializable {\n \n", "next_change": null}]}}]}}]}}]}}, {"oid": "2f12978cc65cfc47f659b837e174d535fe2f53af", "url": "https://github.com/apache/iotdb/commit/2f12978cc65cfc47f659b837e174d535fe2f53af", "message": "Merge branch 'master' of https://github.com/apache/incubator-iotdb", "committedDate": "2020-02-22T11:29:01Z", "type": "commit"}, {"oid": "b10c17af87692b9992a07eabd224bf4407600937", "url": "https://github.com/apache/iotdb/commit/b10c17af87692b9992a07eabd224bf4407600937", "message": "Merge branch 'master' into flink_iotdb_connector", "committedDate": "2020-02-22T11:31:23Z", "type": "commit"}, {"oid": "83fc8b53ff4a3bdab7f7839b195ca8addb09901e", "url": "https://github.com/apache/iotdb/commit/83fc8b53ff4a3bdab7f7839b195ca8addb09901e", "message": "[IOTDB-497] Addressed review comments", "committedDate": "2020-02-25T15:52:23Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjA5MTUyOA==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r386091528", "body": "IMO the separator should be configurable because users' data may contains \",\".", "bodyText": "IMO the separator should be configurable because users' data may contains \",\".", "bodyHTML": "<p dir=\"auto\">IMO the separator should be configurable because users' data may contains \",\".</p>", "author": "WeiZhong94", "createdAt": "2020-03-01T09:23:36Z", "path": "flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java", "diffHunk": "@@ -0,0 +1,82 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.iotdb.flink;\n+\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * @inheritDoc\n+ * The default implementation of IoTSerializationSchema. Gets info from a map struct.\n+ */\n+public class DefaultIoTSerializationSchema implements IoTSerializationSchema<Map<String,String>> {\n+    public static final String FIELD_DEVICE = \"device\";\n+    public static final String FIELD_TIMESTAMP = \"timestamp\";\n+    public static final String FIELD_MEASUREMENTS = \"measurements\";\n+    public static final String FIELD_VALUES = \"values\";\n+    public static final String DEFAULT_SEPARATOR = \",\";", "originalCommit": "83fc8b53ff4a3bdab7f7839b195ca8addb09901e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzQwMjQ5Nw==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r387402497", "bodyText": "Make sense. Will update.", "author": "vesense", "createdAt": "2020-03-04T01:36:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjA5MTUyOA=="}], "type": "inlineReview", "revised_code": {"commit": "7b693c5b6c14bb3528e0fab31aaa033a3318507d", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java\nindex a439a94557..4ac596b5a4 100644\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java\n", "chunk": "@@ -30,20 +27,11 @@ import java.util.Map;\n  * The default implementation of IoTSerializationSchema. Gets info from a map struct.\n  */\n public class DefaultIoTSerializationSchema implements IoTSerializationSchema<Map<String,String>> {\n-    public static final String FIELD_DEVICE = \"device\";\n-    public static final String FIELD_TIMESTAMP = \"timestamp\";\n-    public static final String FIELD_MEASUREMENTS = \"measurements\";\n-    public static final String FIELD_VALUES = \"values\";\n-    public static final String DEFAULT_SEPARATOR = \",\";\n-\n-    private Map<String, IoTDBOptions.TimeseriesOption> timeseriesOptionMap;\n-\n-    public DefaultIoTSerializationSchema(IoTDBOptions ioTDBOptions) {\n-        timeseriesOptionMap = new HashMap<>();\n-        for (IoTDBOptions.TimeseriesOption timeseriesOption : ioTDBOptions.getTimeseriesOptionList()) {\n-            timeseriesOptionMap.put(timeseriesOption.getPath(), timeseriesOption);\n-        }\n-    }\n+    private String fieldDevice = \"device\";\n+    private String fieldTimestamp = \"timestamp\";\n+    private String fieldMeasurements = \"measurements\";\n+    private String fieldValues = \"values\";\n+    private String separator = \",\";\n \n     @Override\n     public Event serialize(Map<String,String> tuple) {\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjA5MTUzOA==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r386091538", "body": "Map -> Map<String, String> ?", "bodyText": "Map -> Map<String, String> ?", "bodyHTML": "<p dir=\"auto\">Map -&gt; Map&lt;String, String&gt; ?</p>", "author": "WeiZhong94", "createdAt": "2020-03-01T09:23:48Z", "path": "example/flink/src/main/java/org/apache/iotdb/flink/FlinkIoTDBSink.java", "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.iotdb.flink;\n+\n+import com.google.common.collect.Lists;\n+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\n+import org.apache.flink.streaming.api.functions.source.SourceFunction;\n+import org.apache.iotdb.db.service.IoTDB;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Random;\n+\n+public class FlinkIoTDBSink {\n+    public static void main(String[] args) throws Exception {\n+        // launch the local iotDB server at default port: 6667\n+        IoTDB.main(args);\n+\n+        Thread.sleep(3000);\n+\n+        // run the flink job on local mini cluster\n+        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n+        env.enableCheckpointing(3000);\n+\n+        IoTDBOptions options = new IoTDBOptions();\n+        options.setHost(\"127.0.0.1\");\n+        options.setPort(6667);\n+        options.setUser(\"root\");\n+        options.setPassword(\"root\");\n+        options.setStorageGroup(\"root.sg\");\n+        options.setTimeseriesOptionList(Lists.newArrayList(new IoTDBOptions.TimeseriesOption(\"root.sg.d1.s1\")));\n+\n+        IoTSerializationSchema serializationSchema = new DefaultIoTSerializationSchema(options);\n+        IoTDBSink ioTDBSink = new IoTDBSink(options, serializationSchema)\n+                // enable batching\n+                .withBatchSize(10);\n+\n+        env.addSource(new SensorSource())\n+                .name(\"sensor-source\")\n+                .setParallelism(1)\n+\n+                .addSink(ioTDBSink)\n+                .name(\"iotdb-sink\")\n+                .setParallelism(1);\n+\n+        env.execute(\"iotdb-flink-example\");\n+    }\n+\n+    private static class SensorSource implements SourceFunction<Map<String,String>> {\n+        boolean running = true;\n+\n+        @Override\n+        public void run(SourceContext context) throws Exception {\n+            Random random = new Random();\n+            while (running) {\n+                Map tuple = new HashMap();", "originalCommit": "83fc8b53ff4a3bdab7f7839b195ca8addb09901e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzQwMjE4Ng==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r387402186", "bodyText": "Will update.", "author": "vesense", "createdAt": "2020-03-04T01:35:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjA5MTUzOA=="}], "type": "inlineReview", "revised_code": {"commit": "7b693c5b6c14bb3528e0fab31aaa033a3318507d", "changed_code": [{"header": "diff --git a/example/flink/src/main/java/org/apache/iotdb/flink/FlinkIoTDBSink.java b/example/flink/src/main/java/org/apache/iotdb/flink/FlinkIoTDBSink.java\nindex 1a9aa72236..0d8bb2f5a7 100644\n--- a/example/flink/src/main/java/org/apache/iotdb/flink/FlinkIoTDBSink.java\n+++ b/example/flink/src/main/java/org/apache/iotdb/flink/FlinkIoTDBSink.java\n", "chunk": "@@ -68,7 +66,7 @@ public class FlinkIoTDBSink {\n         public void run(SourceContext context) throws Exception {\n             Random random = new Random();\n             while (running) {\n-                Map tuple = new HashMap();\n+                Map<String,String> tuple = new HashMap();\n                 tuple.put(\"device\", \"root.sg.d1\");\n                 tuple.put(\"timestamp\", String.valueOf(System.currentTimeMillis()));\n                 tuple.put(\"measurements\", \"s1\");\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjA5MTYyOQ==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r386091629", "body": "It looks like this method was not covered by the tests.", "bodyText": "It looks like this method was not covered by the tests.", "bodyHTML": "<p dir=\"auto\">It looks like this method was not covered by the tests.</p>", "author": "WeiZhong94", "createdAt": "2020-03-01T09:25:09Z", "path": "flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java", "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.iotdb.flink;\n+\n+import com.google.common.base.Preconditions;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.streaming.api.functions.sink.RichSinkFunction;\n+import org.apache.iotdb.service.rpc.thrift.TSStatus;\n+import org.apache.iotdb.session.Session;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+\n+/**\n+ * The `IoTDBSink` allows flink jobs to write events into IoTDB timeseries.\n+ * By default send only one event after another, but you can change to batch by invoking `withBatchSize(int)`.\n+ * @param <IN> input type\n+ */\n+public class IoTDBSink<IN> extends RichSinkFunction<IN> {\n+\n+    private static final long serialVersionUID = 1L;\n+    private static final Logger LOG = LoggerFactory.getLogger(IoTDBSink.class);\n+\n+    private IoTSerializationSchema<IN> serializationSchema;\n+    private IoTDBOptions options;\n+    private transient Session session;\n+    private transient ScheduledExecutorService scheduledExecutor;\n+\n+    private int batchSize = 0;\n+    private int flushIntervalMs = 3000;\n+    private transient List<Event> batchList;\n+\n+    public IoTDBSink(IoTDBOptions options, IoTSerializationSchema<IN> schema) {\n+        this.options = options;\n+        this.serializationSchema = schema;\n+    }\n+\n+    @Override\n+    public void open(Configuration parameters) throws Exception {\n+        batchList = new LinkedList<>();\n+\n+        session = new Session(options.getHost(), options.getPort(), options.getUser(), options.getPassword());\n+        session.open();\n+\n+        session.setStorageGroup(options.getStorageGroup());\n+        for (IoTDBOptions.TimeseriesOption option : options.getTimeseriesOptionList()) {\n+            if (!session.checkTimeseriesExists(option.getPath())) {\n+                session.createTimeseries(option.getPath(), option.getDataType(), option.getEncoding(), option.getCompressor());\n+            }\n+        }\n+\n+        if (batchSize > 0) {\n+            scheduledExecutor = Executors.newSingleThreadScheduledExecutor();\n+            scheduledExecutor.scheduleAtFixedRate(() -> {\n+                try {\n+                    flush();\n+                } catch (Exception e) {\n+                    LOG.error(\"flush error\", e);\n+                }\n+            }, flushIntervalMs, flushIntervalMs, TimeUnit.MILLISECONDS);\n+        }\n+    }\n+\n+    //  for testing\n+    void setSession(Session session) {\n+        this.session = session;\n+    }\n+\n+    void setBatchList(List<Event> batchList) {\n+        this.batchList = batchList;\n+    }\n+\n+    @Override\n+    public void invoke(IN input, Context context) throws Exception {\n+        Event event = serializationSchema.serialize(input);\n+        if (event == null) {\n+            return;\n+        }\n+\n+        if (batchSize > 0) {\n+            batchList.add(event);\n+            if (batchList.size() >= batchSize) {\n+                flush();\n+            }\n+            return;\n+        }\n+\n+        TSStatus status = session.insert(event.getDevice(), event.getTimestamp(),\n+                event.getMeasurements(), event.getValues());\n+        LOG.debug(\"send event result: {}\", status);\n+    }\n+\n+    public IoTDBSink<IN> withBatchSize(int batchSize) {\n+        Preconditions.checkArgument(batchSize >= 0);\n+        this.batchSize = batchSize;\n+        return this;\n+    }\n+\n+    public IoTDBSink<IN> withFlushIntervalMs(int flushIntervalMs) {", "originalCommit": "83fc8b53ff4a3bdab7f7839b195ca8addb09901e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzQwMjExNA==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r387402114", "bodyText": "Yep, will add.", "author": "vesense", "createdAt": "2020-03-04T01:34:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjA5MTYyOQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjA5MTYzMg==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r386091632", "body": "It would be better if we can add some description for the param T.", "bodyText": "It would be better if we can add some description for the param T.", "bodyHTML": "<p dir=\"auto\">It would be better if we can add some description for the param T.</p>", "author": "WeiZhong94", "createdAt": "2020-03-01T09:25:14Z", "path": "flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTSerializationSchema.java", "diffHunk": "@@ -0,0 +1,31 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.iotdb.flink;\n+\n+import java.io.Serializable;\n+\n+/**\n+ * IoTSerializationSchema serializes the input tuple data into events for inserting into IoTDB server.\n+ * @param <T>", "originalCommit": "83fc8b53ff4a3bdab7f7839b195ca8addb09901e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzQwMTg5OA==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r387401898", "bodyText": "Will update.", "author": "vesense", "createdAt": "2020-03-04T01:34:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjA5MTYzMg=="}], "type": "inlineReview", "revised_code": {"commit": "7b693c5b6c14bb3528e0fab31aaa033a3318507d", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTSerializationSchema.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTSerializationSchema.java\nindex 9c9f9599fb..e0b72d437d 100644\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTSerializationSchema.java\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTSerializationSchema.java\n", "chunk": "@@ -22,7 +22,7 @@ import java.io.Serializable;\n \n /**\n  * IoTSerializationSchema serializes the input tuple data into events for inserting into IoTDB server.\n- * @param <T>\n+ * @param <T> the input data type\n  */\n public interface IoTSerializationSchema<T> extends Serializable {\n \n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjA5MTgyMQ==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r386091821", "body": "IMO it would be better if we replace this class with existed class `MeasurementSchema`. They look similar.", "bodyText": "IMO it would be better if we replace this class with existed class MeasurementSchema. They look similar.", "bodyHTML": "<p dir=\"auto\">IMO it would be better if we replace this class with existed class <code>MeasurementSchema</code>. They look similar.</p>", "author": "WeiZhong94", "createdAt": "2020-03-01T09:27:40Z", "path": "flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBOptions.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.iotdb.flink;\n+\n+import org.apache.iotdb.tsfile.file.metadata.enums.CompressionType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSEncoding;\n+\n+import java.io.Serializable;\n+import java.util.List;\n+\n+/**\n+ * IoTDBOptions describes the configuration related information for IoTDB and timeseries.\n+ */\n+public class IoTDBOptions implements Serializable {\n+    private String host;\n+    private int port;\n+    private String user;\n+    private String password;\n+    private String storageGroup;\n+    private List<TimeseriesOption> timeseriesOptionList;\n+\n+    public IoTDBOptions() {\n+    }\n+\n+    public IoTDBOptions(String host, int port, String user, String password,\n+                        String storageGroup, List<TimeseriesOption> timeseriesOptionList) {\n+        this.host = host;\n+        this.port = port;\n+        this.user = user;\n+        this.password = password;\n+        this.storageGroup = storageGroup;\n+        this.timeseriesOptionList = timeseriesOptionList;\n+    }\n+\n+    public String getHost() {\n+        return host;\n+    }\n+\n+    public void setHost(String host) {\n+        this.host = host;\n+    }\n+\n+    public int getPort() {\n+        return port;\n+    }\n+\n+    public void setPort(int port) {\n+        this.port = port;\n+    }\n+\n+    public String getUser() {\n+        return user;\n+    }\n+\n+    public void setUser(String user) {\n+        this.user = user;\n+    }\n+\n+    public String getPassword() {\n+        return password;\n+    }\n+\n+    public void setPassword(String password) {\n+        this.password = password;\n+    }\n+\n+    public String getStorageGroup() {\n+        return storageGroup;\n+    }\n+\n+    public void setStorageGroup(String storageGroup) {\n+        this.storageGroup = storageGroup;\n+    }\n+\n+    public List<TimeseriesOption> getTimeseriesOptionList() {\n+        return timeseriesOptionList;\n+    }\n+\n+    public void setTimeseriesOptionList(List<TimeseriesOption> timeseriesOptionList) {\n+        this.timeseriesOptionList = timeseriesOptionList;\n+    }\n+\n+    public static class TimeseriesOption implements Serializable {", "originalCommit": "83fc8b53ff4a3bdab7f7839b195ca8addb09901e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzQzNDg0Nw==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r387434847", "bodyText": "Looks similar but different.MeasurementSchema  describes a measurement's information registered in FileSchema for ts file serializing and deserializing.  TimeseriesOption  describes a timeseries options information for Flink job configuration.\nWhat do you think? @jixuan1989", "author": "vesense", "createdAt": "2020-03-04T03:45:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjA5MTgyMQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjA5MTk2Mw==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r386091963", "body": "IMO the operations on the `batchList` also need synchronization as it is possible to read/write this object concurrently.", "bodyText": "IMO the operations on the batchList also need synchronization as it is possible to read/write this object concurrently.", "bodyHTML": "<p dir=\"auto\">IMO the operations on the <code>batchList</code> also need synchronization as it is possible to read/write this object concurrently.</p>", "author": "WeiZhong94", "createdAt": "2020-03-01T09:29:35Z", "path": "flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java", "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.iotdb.flink;\n+\n+import com.google.common.base.Preconditions;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.streaming.api.functions.sink.RichSinkFunction;\n+import org.apache.iotdb.service.rpc.thrift.TSStatus;\n+import org.apache.iotdb.session.Session;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+\n+/**\n+ * The `IoTDBSink` allows flink jobs to write events into IoTDB timeseries.\n+ * By default send only one event after another, but you can change to batch by invoking `withBatchSize(int)`.\n+ * @param <IN> input type\n+ */\n+public class IoTDBSink<IN> extends RichSinkFunction<IN> {\n+\n+    private static final long serialVersionUID = 1L;\n+    private static final Logger LOG = LoggerFactory.getLogger(IoTDBSink.class);\n+\n+    private IoTSerializationSchema<IN> serializationSchema;\n+    private IoTDBOptions options;\n+    private transient Session session;\n+    private transient ScheduledExecutorService scheduledExecutor;\n+\n+    private int batchSize = 0;\n+    private int flushIntervalMs = 3000;\n+    private transient List<Event> batchList;\n+\n+    public IoTDBSink(IoTDBOptions options, IoTSerializationSchema<IN> schema) {\n+        this.options = options;\n+        this.serializationSchema = schema;\n+    }\n+\n+    @Override\n+    public void open(Configuration parameters) throws Exception {\n+        batchList = new LinkedList<>();\n+\n+        session = new Session(options.getHost(), options.getPort(), options.getUser(), options.getPassword());\n+        session.open();\n+\n+        session.setStorageGroup(options.getStorageGroup());\n+        for (IoTDBOptions.TimeseriesOption option : options.getTimeseriesOptionList()) {\n+            if (!session.checkTimeseriesExists(option.getPath())) {\n+                session.createTimeseries(option.getPath(), option.getDataType(), option.getEncoding(), option.getCompressor());\n+            }\n+        }\n+\n+        if (batchSize > 0) {\n+            scheduledExecutor = Executors.newSingleThreadScheduledExecutor();\n+            scheduledExecutor.scheduleAtFixedRate(() -> {\n+                try {\n+                    flush();\n+                } catch (Exception e) {\n+                    LOG.error(\"flush error\", e);\n+                }\n+            }, flushIntervalMs, flushIntervalMs, TimeUnit.MILLISECONDS);\n+        }\n+    }\n+\n+    //  for testing\n+    void setSession(Session session) {\n+        this.session = session;\n+    }\n+\n+    void setBatchList(List<Event> batchList) {\n+        this.batchList = batchList;\n+    }\n+\n+    @Override\n+    public void invoke(IN input, Context context) throws Exception {\n+        Event event = serializationSchema.serialize(input);\n+        if (event == null) {\n+            return;\n+        }\n+\n+        if (batchSize > 0) {\n+            batchList.add(event);", "originalCommit": "83fc8b53ff4a3bdab7f7839b195ca8addb09901e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM4MzI1MQ==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r387383251", "bodyText": "I think this is a crucial bug, and we have to fix the concurrency problem before we merge this pr.", "author": "jixuan1989", "createdAt": "2020-03-04T00:53:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjA5MTk2Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzQwMTQ0OA==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r387401448", "bodyText": "Will update.", "author": "vesense", "createdAt": "2020-03-04T01:32:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjA5MTk2Mw=="}], "type": "inlineReview", "revised_code": {"commit": "7b693c5b6c14bb3528e0fab31aaa033a3318507d", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\nindex fa7d2a1f02..0495fac617 100644\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n", "chunk": "@@ -99,17 +105,20 @@ public class IoTDBSink<IN> extends RichSinkFunction<IN> {\n             return;\n         }\n \n-        if (batchSize > 0) {\n-            batchList.add(event);\n-            if (batchList.size() >= batchSize) {\n-                flush();\n+        synchronized (batchList) {\n+            if (batchSize > 0) {\n+                batchList.add(event);\n+                if (batchList.size() >= batchSize) {\n+                    flush();\n+                }\n+                return;\n             }\n-            return;\n-        }\n \n-        TSStatus status = session.insert(event.getDevice(), event.getTimestamp(),\n-                event.getMeasurements(), event.getValues());\n-        LOG.debug(\"send event result: {}\", status);\n+            convertText(event.getDevice(), event.getMeasurements(), event.getValues());\n+            TSStatus status = session.insert(event.getDevice(), event.getTimestamp(),\n+                    event.getMeasurements(), event.getValues());\n+            LOG.debug(\"send event result: {}\", status);\n+        }\n     }\n \n     public IoTDBSink<IN> withBatchSize(int batchSize) {\n", "next_change": {"commit": "78778429d60212a6b983d855a955c07e3d93eb69", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\nindex 0495fac617..cda69c0773 100644\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n", "chunk": "@@ -105,20 +105,20 @@ public class IoTDBSink<IN> extends RichSinkFunction<IN> {\n             return;\n         }\n \n-        synchronized (batchList) {\n-            if (batchSize > 0) {\n+        if (batchSize > 0) {\n+            synchronized (batchList) {\n                 batchList.add(event);\n                 if (batchList.size() >= batchSize) {\n                     flush();\n                 }\n                 return;\n             }\n-\n-            convertText(event.getDevice(), event.getMeasurements(), event.getValues());\n-            TSStatus status = session.insert(event.getDevice(), event.getTimestamp(),\n-                    event.getMeasurements(), event.getValues());\n-            LOG.debug(\"send event result: {}\", status);\n         }\n+\n+        convertText(event.getDevice(), event.getMeasurements(), event.getValues());\n+        TSStatus status = session.insert(event.getDevice(), event.getTimestamp(),\n+                event.getMeasurements(), event.getValues());\n+        LOG.debug(\"send event result: {}\", status);\n     }\n \n     public IoTDBSink<IN> withBatchSize(int batchSize) {\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjA5MTk4Ng==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r386091986", "body": "Map -> Map<String, String> ?", "bodyText": "Map -> Map<String, String> ?", "bodyHTML": "<p dir=\"auto\">Map -&gt; Map&lt;String, String&gt; ?</p>", "author": "WeiZhong94", "createdAt": "2020-03-01T09:30:08Z", "path": "flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/DefaultIoTSerializationSchemaTest.java", "diffHunk": "@@ -0,0 +1,49 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.iotdb.flink;\n+\n+import com.google.common.collect.Lists;\n+import org.junit.Test;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.junit.Assert.*;\n+\n+public class DefaultIoTSerializationSchemaTest {\n+\n+    @Test\n+    public void serialize() {\n+        IoTDBOptions options = new IoTDBOptions();\n+        options.setTimeseriesOptionList(Lists.newArrayList(new IoTDBOptions.TimeseriesOption(\"root.sg.D01.temperature\")));\n+        DefaultIoTSerializationSchema serializationSchema = new DefaultIoTSerializationSchema(options);\n+\n+        Map tuple = new HashMap();", "originalCommit": "83fc8b53ff4a3bdab7f7839b195ca8addb09901e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzQwMTQyOQ==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r387401429", "bodyText": "Will update.", "author": "vesense", "createdAt": "2020-03-04T01:32:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjA5MTk4Ng=="}], "type": "inlineReview", "revised_code": {"commit": "7b693c5b6c14bb3528e0fab31aaa033a3318507d", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/DefaultIoTSerializationSchemaTest.java b/flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/DefaultIoTSerializationSchemaTest.java\nindex 69df0bdd27..efb5a34f3d 100644\n--- a/flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/DefaultIoTSerializationSchemaTest.java\n+++ b/flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/DefaultIoTSerializationSchemaTest.java\n", "chunk": "@@ -32,9 +32,9 @@ public class DefaultIoTSerializationSchemaTest {\n     public void serialize() {\n         IoTDBOptions options = new IoTDBOptions();\n         options.setTimeseriesOptionList(Lists.newArrayList(new IoTDBOptions.TimeseriesOption(\"root.sg.D01.temperature\")));\n-        DefaultIoTSerializationSchema serializationSchema = new DefaultIoTSerializationSchema(options);\n+        DefaultIoTSerializationSchema serializationSchema = new DefaultIoTSerializationSchema();\n \n-        Map tuple = new HashMap();\n+        Map<String,String> tuple = new HashMap();\n         tuple.put(\"device\", \"root.sg.D01\");\n         tuple.put(\"timestamp\", \"1581861293000\");\n         tuple.put(\"measurements\", \"temperature\");\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjA5MjA0NQ==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r386092045", "body": "ditto", "bodyText": "ditto", "bodyHTML": "<p dir=\"auto\">ditto</p>", "author": "WeiZhong94", "createdAt": "2020-03-01T09:31:04Z", "path": "flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkBatchInsertTest.java", "diffHunk": "@@ -0,0 +1,105 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.iotdb.flink;\n+\n+import com.google.common.collect.Lists;\n+import org.apache.iotdb.session.Session;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.mockito.Matchers.any;\n+import static org.mockito.Mockito.*;\n+\n+public class IoTDBSinkBatchInsertTest {\n+\n+    private IoTDBSink ioTDBSink;\n+    private Session session;\n+\n+    @Before\n+    public void setUp() throws Exception {\n+        IoTDBOptions options = new IoTDBOptions();\n+        options.setTimeseriesOptionList(Lists.newArrayList(new IoTDBOptions.TimeseriesOption(\"root.sg.D01.temperature\")));\n+        ioTDBSink = new IoTDBSink(options, new DefaultIoTSerializationSchema(options));\n+        ioTDBSink.withBatchSize(3);\n+\n+        session = mock(Session.class);\n+        ioTDBSink.setSession(session);\n+        ioTDBSink.setBatchList(new ArrayList<>());\n+    }\n+\n+    @Test\n+    public void testBatchInsert() throws Exception {\n+        Map tuple = new HashMap();\n+        tuple.put(\"device\", \"root.sg.D01\");\n+        tuple.put(\"timestamp\", \"1581861293000\");\n+        tuple.put(\"measurements\", \"temperature\");\n+        tuple.put(\"values\", \"36.5\");\n+        ioTDBSink.invoke(tuple, null);\n+\n+        verifyZeroInteractions(session);\n+\n+        tuple = new HashMap();\n+        tuple.put(\"device\", \"root.sg.D01\");\n+        tuple.put(\"timestamp\", \"1581861293001\");\n+        tuple.put(\"measurements\", \"temperature\");\n+        tuple.put(\"values\", \"37.2\");\n+        ioTDBSink.invoke(tuple, null);\n+\n+        verifyZeroInteractions(session);\n+\n+        tuple = new HashMap();\n+        tuple.put(\"device\", \"root.sg.D01\");\n+        tuple.put(\"timestamp\", \"1581861293003\");\n+        tuple.put(\"measurements\", \"temperature\");\n+        tuple.put(\"values\", \"37.1\");\n+        ioTDBSink.invoke(tuple, null);\n+\n+        verify(session).insertInBatch(any(List.class), any(List.class), any(List.class), any(List.class));\n+\n+        tuple = new HashMap();\n+        tuple.put(\"device\", \"root.sg.D01\");\n+        tuple.put(\"timestamp\", \"1581861293005\");\n+        tuple.put(\"measurements\", \"temperature\");\n+        tuple.put(\"values\", \"36.5\");\n+        ioTDBSink.invoke(tuple, null);\n+\n+        verifyZeroInteractions(session);\n+    }\n+\n+    @Test\n+    public void close() throws Exception {\n+        Map tuple = new HashMap();", "originalCommit": "83fc8b53ff4a3bdab7f7839b195ca8addb09901e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzQwMTQwNA==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r387401404", "bodyText": "Will update.", "author": "vesense", "createdAt": "2020-03-04T01:32:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjA5MjA0NQ=="}], "type": "inlineReview", "revised_code": {"commit": "7b693c5b6c14bb3528e0fab31aaa033a3318507d", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkBatchInsertTest.java b/flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkBatchInsertTest.java\nindex 0af1d73a77..e6e5df7e92 100644\n--- a/flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkBatchInsertTest.java\n+++ b/flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkBatchInsertTest.java\n", "chunk": "@@ -89,7 +87,7 @@ public class IoTDBSinkBatchInsertTest {\n \n     @Test\n     public void close() throws Exception {\n-        Map tuple = new HashMap();\n+        Map<String,String> tuple = new HashMap();\n         tuple.put(\"device\", \"root.sg.D01\");\n         tuple.put(\"timestamp\", \"1581861293005\");\n         tuple.put(\"measurements\", \"temperature\");\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjA5MjczNQ==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r386092735", "body": "As this logic may be reused in other IoTSerializationSchema (user implemented or RowIoTSerializationSchema in future if we want to support IotDB in Flink Table API), IMO it would be better to move it to `IoTDBSink`.", "bodyText": "As this logic may be reused in other IoTSerializationSchema (user implemented or RowIoTSerializationSchema in future if we want to support IotDB in Flink Table API), IMO it would be better to move it to IoTDBSink.", "bodyHTML": "<p dir=\"auto\">As this logic may be reused in other IoTSerializationSchema (user implemented or RowIoTSerializationSchema in future if we want to support IotDB in Flink Table API), IMO it would be better to move it to <code>IoTDBSink</code>.</p>", "author": "WeiZhong94", "createdAt": "2020-03-01T09:40:43Z", "path": "flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java", "diffHunk": "@@ -0,0 +1,82 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.iotdb.flink;\n+\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * @inheritDoc\n+ * The default implementation of IoTSerializationSchema. Gets info from a map struct.\n+ */\n+public class DefaultIoTSerializationSchema implements IoTSerializationSchema<Map<String,String>> {\n+    public static final String FIELD_DEVICE = \"device\";\n+    public static final String FIELD_TIMESTAMP = \"timestamp\";\n+    public static final String FIELD_MEASUREMENTS = \"measurements\";\n+    public static final String FIELD_VALUES = \"values\";\n+    public static final String DEFAULT_SEPARATOR = \",\";\n+\n+    private Map<String, IoTDBOptions.TimeseriesOption> timeseriesOptionMap;\n+\n+    public DefaultIoTSerializationSchema(IoTDBOptions ioTDBOptions) {\n+        timeseriesOptionMap = new HashMap<>();\n+        for (IoTDBOptions.TimeseriesOption timeseriesOption : ioTDBOptions.getTimeseriesOptionList()) {\n+            timeseriesOptionMap.put(timeseriesOption.getPath(), timeseriesOption);\n+        }\n+    }\n+\n+    @Override\n+    public Event serialize(Map<String,String> tuple) {\n+        if (tuple == null) {\n+            return null;\n+        }\n+\n+        String device = tuple.get(FIELD_DEVICE);\n+\n+        String ts = tuple.get(FIELD_TIMESTAMP);\n+        Long timestamp = ts == null ? System.currentTimeMillis() : Long.parseLong(ts);\n+\n+        List<String> measurements = null;\n+        if (tuple.get(FIELD_MEASUREMENTS) != null) {\n+            measurements = Arrays.asList(tuple.get(FIELD_MEASUREMENTS).split(DEFAULT_SEPARATOR));\n+        }\n+\n+        List<String> values = null;\n+        if (tuple.get(FIELD_VALUES) != null) {\n+            values = Arrays.asList(tuple.get(FIELD_VALUES).split(DEFAULT_SEPARATOR));\n+        }\n+\n+        if (device != null && measurements != null && values != null && measurements.size() == values.size()) {\n+            for (int i = 0; i < measurements.size(); i++) {\n+                String measurement = device + \".\" + measurements.get(i);\n+                IoTDBOptions.TimeseriesOption timeseriesOption = timeseriesOptionMap.get(measurement);\n+                if (timeseriesOption!= null && TSDataType.TEXT.equals(timeseriesOption.getDataType())) {\n+                    // The TEXT data type should be covered by \" or '\n+                    values.set(i, \"'\" + values.get(i) + \"'\");", "originalCommit": "83fc8b53ff4a3bdab7f7839b195ca8addb09901e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzQwMTM3Mw==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r387401373", "bodyText": "Good idea, will update.", "author": "vesense", "createdAt": "2020-03-04T01:31:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjA5MjczNQ=="}], "type": "inlineReview", "revised_code": {"commit": "7b693c5b6c14bb3528e0fab31aaa033a3318507d", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java\nindex a439a94557..4ac596b5a4 100644\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java\n", "chunk": "@@ -51,32 +39,61 @@ public class DefaultIoTSerializationSchema implements IoTSerializationSchema<Map\n             return null;\n         }\n \n-        String device = tuple.get(FIELD_DEVICE);\n+        String device = tuple.get(fieldDevice);\n \n-        String ts = tuple.get(FIELD_TIMESTAMP);\n+        String ts = tuple.get(fieldTimestamp);\n         Long timestamp = ts == null ? System.currentTimeMillis() : Long.parseLong(ts);\n \n         List<String> measurements = null;\n-        if (tuple.get(FIELD_MEASUREMENTS) != null) {\n-            measurements = Arrays.asList(tuple.get(FIELD_MEASUREMENTS).split(DEFAULT_SEPARATOR));\n+        if (tuple.get(fieldMeasurements) != null) {\n+            measurements = Arrays.asList(tuple.get(fieldMeasurements).split(separator));\n         }\n \n         List<String> values = null;\n-        if (tuple.get(FIELD_VALUES) != null) {\n-            values = Arrays.asList(tuple.get(FIELD_VALUES).split(DEFAULT_SEPARATOR));\n-        }\n-\n-        if (device != null && measurements != null && values != null && measurements.size() == values.size()) {\n-            for (int i = 0; i < measurements.size(); i++) {\n-                String measurement = device + \".\" + measurements.get(i);\n-                IoTDBOptions.TimeseriesOption timeseriesOption = timeseriesOptionMap.get(measurement);\n-                if (timeseriesOption!= null && TSDataType.TEXT.equals(timeseriesOption.getDataType())) {\n-                    // The TEXT data type should be covered by \" or '\n-                    values.set(i, \"'\" + values.get(i) + \"'\");\n-                }\n-            }\n+        if (tuple.get(fieldValues) != null) {\n+            values = Arrays.asList(tuple.get(fieldValues).split(separator));\n         }\n \n         return new Event(device, timestamp, measurements, values);\n     }\n+\n+    public String getFieldDevice() {\n+        return fieldDevice;\n+    }\n+\n+    public void setFieldDevice(String fieldDevice) {\n+        this.fieldDevice = fieldDevice;\n+    }\n+\n+    public String getFieldTimestamp() {\n+        return fieldTimestamp;\n+    }\n+\n+    public void setFieldTimestamp(String fieldTimestamp) {\n+        this.fieldTimestamp = fieldTimestamp;\n+    }\n+\n+    public String getFieldMeasurements() {\n+        return fieldMeasurements;\n+    }\n+\n+    public void setFieldMeasurements(String fieldMeasurements) {\n+        this.fieldMeasurements = fieldMeasurements;\n+    }\n+\n+    public String getFieldValues() {\n+        return fieldValues;\n+    }\n+\n+    public void setFieldValues(String fieldValues) {\n+        this.fieldValues = fieldValues;\n+    }\n+\n+    public String getSeparator() {\n+        return separator;\n+    }\n+\n+    public void setSeparator(String separator) {\n+        this.separator = separator;\n+    }\n }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjA5Mjg0OA==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r386092848", "body": "It seems only the list of `TimeseriesOption` is needed. We can pass a `List<TimeseriesOption>` to this constructor directly. (or `List<MeasurementSchema>` if we replace the class `TimeseriesOption` with class `MeasurementSchema` as I suggested above)  ", "bodyText": "It seems only the list of TimeseriesOption is needed. We can pass a List<TimeseriesOption> to this constructor directly. (or List<MeasurementSchema> if we replace the class TimeseriesOption with class MeasurementSchema as I suggested above)", "bodyHTML": "<p dir=\"auto\">It seems only the list of <code>TimeseriesOption</code> is needed. We can pass a <code>List&lt;TimeseriesOption&gt;</code> to this constructor directly. (or <code>List&lt;MeasurementSchema&gt;</code> if we replace the class <code>TimeseriesOption</code> with class <code>MeasurementSchema</code> as I suggested above)</p>", "author": "WeiZhong94", "createdAt": "2020-03-01T09:41:51Z", "path": "flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java", "diffHunk": "@@ -0,0 +1,82 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.iotdb.flink;\n+\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * @inheritDoc\n+ * The default implementation of IoTSerializationSchema. Gets info from a map struct.\n+ */\n+public class DefaultIoTSerializationSchema implements IoTSerializationSchema<Map<String,String>> {\n+    public static final String FIELD_DEVICE = \"device\";\n+    public static final String FIELD_TIMESTAMP = \"timestamp\";\n+    public static final String FIELD_MEASUREMENTS = \"measurements\";\n+    public static final String FIELD_VALUES = \"values\";\n+    public static final String DEFAULT_SEPARATOR = \",\";\n+\n+    private Map<String, IoTDBOptions.TimeseriesOption> timeseriesOptionMap;\n+\n+    public DefaultIoTSerializationSchema(IoTDBOptions ioTDBOptions) {", "originalCommit": "83fc8b53ff4a3bdab7f7839b195ca8addb09901e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzQwMzYxMQ==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r387403611", "bodyText": "The DefaultIoTSerializationSchema constructor no longer needed, if we move the converting TEXT data type logic to IoTDBSink which you stated above.", "author": "vesense", "createdAt": "2020-03-04T01:40:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjA5Mjg0OA=="}], "type": "inlineReview", "revised_code": {"commit": "7b693c5b6c14bb3528e0fab31aaa033a3318507d", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java\nindex a439a94557..4ac596b5a4 100644\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/DefaultIoTSerializationSchema.java\n", "chunk": "@@ -30,20 +27,11 @@ import java.util.Map;\n  * The default implementation of IoTSerializationSchema. Gets info from a map struct.\n  */\n public class DefaultIoTSerializationSchema implements IoTSerializationSchema<Map<String,String>> {\n-    public static final String FIELD_DEVICE = \"device\";\n-    public static final String FIELD_TIMESTAMP = \"timestamp\";\n-    public static final String FIELD_MEASUREMENTS = \"measurements\";\n-    public static final String FIELD_VALUES = \"values\";\n-    public static final String DEFAULT_SEPARATOR = \",\";\n-\n-    private Map<String, IoTDBOptions.TimeseriesOption> timeseriesOptionMap;\n-\n-    public DefaultIoTSerializationSchema(IoTDBOptions ioTDBOptions) {\n-        timeseriesOptionMap = new HashMap<>();\n-        for (IoTDBOptions.TimeseriesOption timeseriesOption : ioTDBOptions.getTimeseriesOptionList()) {\n-            timeseriesOptionMap.put(timeseriesOption.getPath(), timeseriesOption);\n-        }\n-    }\n+    private String fieldDevice = \"device\";\n+    private String fieldTimestamp = \"timestamp\";\n+    private String fieldMeasurements = \"measurements\";\n+    private String fieldValues = \"values\";\n+    private String separator = \",\";\n \n     @Override\n     public Event serialize(Map<String,String> tuple) {\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjA5MzA4Ng==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r386093086", "body": "As we do not depends the checkpointing to flush data anymore, this line seems unnecessary.", "bodyText": "As we do not depends the checkpointing to flush data anymore, this line seems unnecessary.", "bodyHTML": "<p dir=\"auto\">As we do not depends the checkpointing to flush data anymore, this line seems unnecessary.</p>", "author": "WeiZhong94", "createdAt": "2020-03-01T09:45:28Z", "path": "example/flink/src/main/java/org/apache/iotdb/flink/FlinkIoTDBSink.java", "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.iotdb.flink;\n+\n+import com.google.common.collect.Lists;\n+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\n+import org.apache.flink.streaming.api.functions.source.SourceFunction;\n+import org.apache.iotdb.db.service.IoTDB;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Random;\n+\n+public class FlinkIoTDBSink {\n+    public static void main(String[] args) throws Exception {\n+        // launch the local iotDB server at default port: 6667\n+        IoTDB.main(args);\n+\n+        Thread.sleep(3000);\n+\n+        // run the flink job on local mini cluster\n+        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n+        env.enableCheckpointing(3000);", "originalCommit": "83fc8b53ff4a3bdab7f7839b195ca8addb09901e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzQwMjA3OA==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r387402078", "bodyText": "Will update.", "author": "vesense", "createdAt": "2020-03-04T01:34:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjA5MzA4Ng=="}], "type": "inlineReview", "revised_code": {"commit": "7b693c5b6c14bb3528e0fab31aaa033a3318507d", "changed_code": [{"header": "diff --git a/example/flink/src/main/java/org/apache/iotdb/flink/FlinkIoTDBSink.java b/example/flink/src/main/java/org/apache/iotdb/flink/FlinkIoTDBSink.java\nindex 1a9aa72236..0d8bb2f5a7 100644\n--- a/example/flink/src/main/java/org/apache/iotdb/flink/FlinkIoTDBSink.java\n+++ b/example/flink/src/main/java/org/apache/iotdb/flink/FlinkIoTDBSink.java\n", "chunk": "@@ -35,7 +35,6 @@ public class FlinkIoTDBSink {\n \n         // run the flink job on local mini cluster\n         StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n-        env.enableCheckpointing(3000);\n \n         IoTDBOptions options = new IoTDBOptions();\n         options.setHost(\"127.0.0.1\");\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjA5MzI5MA==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r386093290", "body": "This empty line looks strange from my side... but it's up to you.", "bodyText": "This empty line looks strange from my side... but it's up to you.", "bodyHTML": "<p dir=\"auto\">This empty line looks strange from my side... but it's up to you.</p>", "author": "WeiZhong94", "createdAt": "2020-03-01T09:48:02Z", "path": "example/flink/src/main/java/org/apache/iotdb/flink/FlinkIoTDBSink.java", "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.iotdb.flink;\n+\n+import com.google.common.collect.Lists;\n+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\n+import org.apache.flink.streaming.api.functions.source.SourceFunction;\n+import org.apache.iotdb.db.service.IoTDB;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Random;\n+\n+public class FlinkIoTDBSink {\n+    public static void main(String[] args) throws Exception {\n+        // launch the local iotDB server at default port: 6667\n+        IoTDB.main(args);\n+\n+        Thread.sleep(3000);\n+\n+        // run the flink job on local mini cluster\n+        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n+        env.enableCheckpointing(3000);\n+\n+        IoTDBOptions options = new IoTDBOptions();\n+        options.setHost(\"127.0.0.1\");\n+        options.setPort(6667);\n+        options.setUser(\"root\");\n+        options.setPassword(\"root\");\n+        options.setStorageGroup(\"root.sg\");\n+        options.setTimeseriesOptionList(Lists.newArrayList(new IoTDBOptions.TimeseriesOption(\"root.sg.d1.s1\")));\n+\n+        IoTSerializationSchema serializationSchema = new DefaultIoTSerializationSchema(options);\n+        IoTDBSink ioTDBSink = new IoTDBSink(options, serializationSchema)\n+                // enable batching\n+                .withBatchSize(10);\n+\n+        env.addSource(new SensorSource())\n+                .name(\"sensor-source\")\n+                .setParallelism(1)\n+", "originalCommit": "83fc8b53ff4a3bdab7f7839b195ca8addb09901e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzQwMDk1OQ==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r387400959", "bodyText": "Will update.", "author": "vesense", "createdAt": "2020-03-04T01:30:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjA5MzI5MA=="}], "type": "inlineReview", "revised_code": {"commit": "7b693c5b6c14bb3528e0fab31aaa033a3318507d", "changed_code": [{"header": "diff --git a/example/flink/src/main/java/org/apache/iotdb/flink/FlinkIoTDBSink.java b/example/flink/src/main/java/org/apache/iotdb/flink/FlinkIoTDBSink.java\nindex 1a9aa72236..0d8bb2f5a7 100644\n--- a/example/flink/src/main/java/org/apache/iotdb/flink/FlinkIoTDBSink.java\n+++ b/example/flink/src/main/java/org/apache/iotdb/flink/FlinkIoTDBSink.java\n", "chunk": "@@ -45,7 +44,7 @@ public class FlinkIoTDBSink {\n         options.setStorageGroup(\"root.sg\");\n         options.setTimeseriesOptionList(Lists.newArrayList(new IoTDBOptions.TimeseriesOption(\"root.sg.d1.s1\")));\n \n-        IoTSerializationSchema serializationSchema = new DefaultIoTSerializationSchema(options);\n+        IoTSerializationSchema serializationSchema = new DefaultIoTSerializationSchema();\n         IoTDBSink ioTDBSink = new IoTDBSink(options, serializationSchema)\n                 // enable batching\n                 .withBatchSize(10);\n", "next_change": null}, {"header": "diff --git a/example/flink/src/main/java/org/apache/iotdb/flink/FlinkIoTDBSink.java b/example/flink/src/main/java/org/apache/iotdb/flink/FlinkIoTDBSink.java\nindex 1a9aa72236..0d8bb2f5a7 100644\n--- a/example/flink/src/main/java/org/apache/iotdb/flink/FlinkIoTDBSink.java\n+++ b/example/flink/src/main/java/org/apache/iotdb/flink/FlinkIoTDBSink.java\n", "chunk": "@@ -53,7 +52,6 @@ public class FlinkIoTDBSink {\n         env.addSource(new SensorSource())\n                 .name(\"sensor-source\")\n                 .setParallelism(1)\n-\n                 .addSink(ioTDBSink)\n                 .name(\"iotdb-sink\")\n                 .setParallelism(1);\n", "next_change": null}]}}, {"oid": "7b693c5b6c14bb3528e0fab31aaa033a3318507d", "url": "https://github.com/apache/iotdb/commit/7b693c5b6c14bb3528e0fab31aaa033a3318507d", "message": "[IOTDB-497] Addressed review comments", "committedDate": "2020-03-04T08:19:58Z", "type": "commit"}, {"oid": "78778429d60212a6b983d855a955c07e3d93eb69", "url": "https://github.com/apache/iotdb/commit/78778429d60212a6b983d855a955c07e3d93eb69", "message": "[IOTDB-497] Addressed review comments", "committedDate": "2020-03-06T03:14:04Z", "type": "commit"}, {"oid": "b9ba5d4cc35fb6f4faaacac4077a1b7ecda6067b", "url": "https://github.com/apache/iotdb/commit/b9ba5d4cc35fb6f4faaacac4077a1b7ecda6067b", "message": "[IOTDB-497] fix ci build error", "committedDate": "2020-03-06T05:02:15Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODkyNjI4Ng==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r388926286", "body": "Unnecessary empty line.", "bodyText": "Unnecessary empty line.", "bodyHTML": "<p dir=\"auto\">Unnecessary empty line.</p>", "author": "WeiZhong94", "createdAt": "2020-03-06T14:16:48Z", "path": "flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java", "diffHunk": "@@ -0,0 +1,188 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.iotdb.flink;\n+\n+import com.google.common.base.Preconditions;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.streaming.api.functions.sink.RichSinkFunction;\n+import org.apache.iotdb.service.rpc.thrift.TSStatus;\n+import org.apache.iotdb.session.Session;\n+import org.apache.iotdb.tsfile.file.metadata.enums.TSDataType;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.util.*;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+\n+/**\n+ * The `IoTDBSink` allows flink jobs to write events into IoTDB timeseries.\n+ * By default send only one event after another, but you can change to batch by invoking `withBatchSize(int)`.\n+ * @param <IN> the input data type\n+ */\n+public class IoTDBSink<IN> extends RichSinkFunction<IN> {\n+\n+    private static final long serialVersionUID = 1L;\n+    private static final Logger LOG = LoggerFactory.getLogger(IoTDBSink.class);\n+\n+    private IoTDBOptions options;\n+    private IoTSerializationSchema<IN> serializationSchema;\n+    private Map<String, IoTDBOptions.TimeseriesOption> timeseriesOptionMap;\n+    private transient Session session;\n+    private transient ScheduledExecutorService scheduledExecutor;\n+\n+    private int batchSize = 0;\n+    private int flushIntervalMs = 3000;\n+    private List<Event> batchList;\n+\n+    public IoTDBSink(IoTDBOptions options, IoTSerializationSchema<IN> schema) {\n+        this.options = options;\n+        this.serializationSchema = schema;\n+        this.batchList = new LinkedList<>();\n+        this.timeseriesOptionMap = new HashMap<>();\n+        for (IoTDBOptions.TimeseriesOption timeseriesOption : options.getTimeseriesOptionList()) {\n+            timeseriesOptionMap.put(timeseriesOption.getPath(), timeseriesOption);\n+        }\n+    }\n+\n+    @Override\n+    public void open(Configuration parameters) throws Exception {\n+        initSession();\n+        initScheduler();\n+    }\n+\n+    void initSession() throws Exception {\n+        session = new Session(options.getHost(), options.getPort(), options.getUser(), options.getPassword());\n+        session.open();\n+\n+        session.setStorageGroup(options.getStorageGroup());\n+        for (IoTDBOptions.TimeseriesOption option : options.getTimeseriesOptionList()) {\n+            if (!session.checkTimeseriesExists(option.getPath())) {\n+                session.createTimeseries(option.getPath(), option.getDataType(), option.getEncoding(), option.getCompressor());\n+            }\n+        }\n+    }\n+\n+    void initScheduler() {\n+        if (batchSize > 0) {\n+            scheduledExecutor = Executors.newSingleThreadScheduledExecutor();\n+            scheduledExecutor.scheduleAtFixedRate(() -> {\n+                try {\n+                    flush();\n+                } catch (Exception e) {\n+                    LOG.error(\"flush error\", e);\n+                }\n+            }, flushIntervalMs, flushIntervalMs, TimeUnit.MILLISECONDS);\n+        }\n+    }\n+\n+    //  for testing\n+    void setSession(Session session) {\n+        this.session = session;\n+    }\n+\n+    @Override\n+    public void invoke(IN input, Context context) throws Exception {\n+        Event event = serializationSchema.serialize(input);\n+        if (event == null) {\n+            return;\n+        }\n+\n+        if (batchSize > 0) {\n+            synchronized (batchList) {\n+                batchList.add(event);\n+                if (batchList.size() >= batchSize) {\n+                    flush();\n+                }\n+                return;\n+            }\n+        }\n+\n+        convertText(event.getDevice(), event.getMeasurements(), event.getValues());\n+        TSStatus status = session.insert(event.getDevice(), event.getTimestamp(),\n+                event.getMeasurements(), event.getValues());\n+        LOG.debug(\"send event result: {}\", status);\n+    }\n+\n+    public IoTDBSink<IN> withBatchSize(int batchSize) {\n+        Preconditions.checkArgument(batchSize >= 0);\n+        this.batchSize = batchSize;\n+        return this;\n+    }\n+\n+    public IoTDBSink<IN> withFlushIntervalMs(int flushIntervalMs) {\n+        Preconditions.checkArgument(flushIntervalMs > 0);\n+        this.flushIntervalMs = flushIntervalMs;\n+        return this;\n+    }\n+\n+    @Override\n+    public void close() throws Exception {\n+        if (session != null) {\n+            try {\n+                flush();\n+            } catch (Exception e) {\n+                LOG.error(\"flush error\", e);\n+            }\n+            session.close();\n+        }\n+        if (scheduledExecutor != null) {\n+            scheduledExecutor.shutdown();\n+        }\n+    }\n+\n+    private void convertText(String device, List<String> measurements, List<String> values) {\n+        if (device != null && measurements != null && values != null && measurements.size() == values.size()) {\n+            for (int i = 0; i < measurements.size(); i++) {\n+                String measurement = device + \".\" + measurements.get(i);\n+                IoTDBOptions.TimeseriesOption timeseriesOption = timeseriesOptionMap.get(measurement);\n+                if (timeseriesOption!= null && TSDataType.TEXT.equals(timeseriesOption.getDataType())) {\n+                    // The TEXT data type should be covered by \" or '\n+                    values.set(i, \"'\" + values.get(i) + \"'\");\n+                }\n+            }\n+        }\n+    }\n+\n+    private void flush() throws Exception {\n+        if (batchSize > 0) {\n+            synchronized (batchList) {\n+                if (batchList.size() > 0) {\n+                    List<String> deviceIds = new ArrayList<>();\n+                    List<Long> timestamps = new ArrayList<>();\n+                    List<List<String>> measurementsList = new ArrayList<>();\n+                    List<List<String>> valuesList = new ArrayList<>();\n+\n+                    for (Event event : batchList) {\n+                        convertText(event.getDevice(), event.getMeasurements(), event.getValues());\n+                        deviceIds.add(event.getDevice());\n+                        timestamps.add(event.getTimestamp());\n+                        measurementsList.add(event.getMeasurements());\n+                        valuesList.add(event.getValues());\n+                    }\n+                    List<TSStatus> statusList = session.insertInBatch(deviceIds, timestamps, measurementsList, valuesList);\n+                    LOG.debug(\"send events result: {}\", statusList);\n+                    batchList.clear();\n+                }\n+            }\n+        }\n+    }\n+", "originalCommit": "b9ba5d4cc35fb6f4faaacac4077a1b7ecda6067b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "32f32f62f62a5fdb59fa751a00556505fb604114", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\nindex cda69c0773..1f405d631d 100644\n--- a/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n+++ b/flink-iotdb-connector/src/main/java/org/apache/iotdb/flink/IoTDBSink.java\n", "chunk": "@@ -184,5 +184,4 @@ public class IoTDBSink<IN> extends RichSinkFunction<IN> {\n             }\n         }\n     }\n-\n }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODkyNjU5Mw==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r388926593", "body": "Unnecessary empty line.", "bodyText": "Unnecessary empty line.", "bodyHTML": "<p dir=\"auto\">Unnecessary empty line.</p>", "author": "WeiZhong94", "createdAt": "2020-03-06T14:17:26Z", "path": "flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkBatchInsertTest.java", "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.iotdb.flink;\n+\n+import com.google.common.collect.Lists;\n+import org.apache.iotdb.session.Session;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.mockito.Matchers.any;\n+import static org.mockito.Mockito.*;\n+\n+public class IoTDBSinkBatchInsertTest {\n+\n+    private IoTDBSink ioTDBSink;\n+    private Session session;\n+\n+    @Before\n+    public void setUp() throws Exception {\n+        IoTDBOptions options = new IoTDBOptions();\n+        options.setTimeseriesOptionList(Lists.newArrayList(new IoTDBOptions.TimeseriesOption(\"root.sg.D01.temperature\")));\n+        ioTDBSink = new IoTDBSink(options, new DefaultIoTSerializationSchema());\n+        ioTDBSink.withBatchSize(3);\n+\n+        session = mock(Session.class);\n+        ioTDBSink.setSession(session);\n+    }\n+\n+    @Test\n+    public void testBatchInsert() throws Exception {\n+        Map<String,String> tuple = new HashMap();\n+        tuple.put(\"device\", \"root.sg.D01\");\n+        tuple.put(\"timestamp\", \"1581861293000\");\n+        tuple.put(\"measurements\", \"temperature\");\n+        tuple.put(\"values\", \"36.5\");\n+        ioTDBSink.invoke(tuple, null);\n+\n+        verifyZeroInteractions(session);\n+\n+        tuple = new HashMap();\n+        tuple.put(\"device\", \"root.sg.D01\");\n+        tuple.put(\"timestamp\", \"1581861293001\");\n+        tuple.put(\"measurements\", \"temperature\");\n+        tuple.put(\"values\", \"37.2\");\n+        ioTDBSink.invoke(tuple, null);\n+\n+        verifyZeroInteractions(session);\n+\n+        tuple = new HashMap();\n+        tuple.put(\"device\", \"root.sg.D01\");\n+        tuple.put(\"timestamp\", \"1581861293003\");\n+        tuple.put(\"measurements\", \"temperature\");\n+        tuple.put(\"values\", \"37.1\");\n+        ioTDBSink.invoke(tuple, null);\n+\n+        verify(session).insertInBatch(any(List.class), any(List.class), any(List.class), any(List.class));\n+\n+        tuple = new HashMap();\n+        tuple.put(\"device\", \"root.sg.D01\");\n+        tuple.put(\"timestamp\", \"1581861293005\");\n+        tuple.put(\"measurements\", \"temperature\");\n+        tuple.put(\"values\", \"36.5\");\n+        ioTDBSink.invoke(tuple, null);\n+\n+        verifyZeroInteractions(session);\n+    }\n+\n+    @Test\n+    public void close() throws Exception {\n+        Map<String,String> tuple = new HashMap();\n+        tuple.put(\"device\", \"root.sg.D01\");\n+        tuple.put(\"timestamp\", \"1581861293005\");\n+        tuple.put(\"measurements\", \"temperature\");\n+        tuple.put(\"values\", \"36.5\");\n+        ioTDBSink.invoke(tuple, null);\n+        verifyZeroInteractions(session);\n+\n+        ioTDBSink.close();\n+        verify(session).insertInBatch(any(List.class), any(List.class), any(List.class), any(List.class));\n+        verify(session).close();\n+    }\n+", "originalCommit": "b9ba5d4cc35fb6f4faaacac4077a1b7ecda6067b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "32f32f62f62a5fdb59fa751a00556505fb604114", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkBatchInsertTest.java b/flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkBatchInsertTest.java\nindex e6e5df7e92..3692377acf 100644\n--- a/flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkBatchInsertTest.java\n+++ b/flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkBatchInsertTest.java\n", "chunk": "@@ -99,5 +99,4 @@ public class IoTDBSinkBatchInsertTest {\n         verify(session).insertInBatch(any(List.class), any(List.class), any(List.class), any(List.class));\n         verify(session).close();\n     }\n-\n }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODkyNjgzOA==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r388926838", "body": "Unnecessary empty line.", "bodyText": "Unnecessary empty line.", "bodyHTML": "<p dir=\"auto\">Unnecessary empty line.</p>", "author": "WeiZhong94", "createdAt": "2020-03-06T14:17:50Z", "path": "flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkBatchTimerTest.java", "diffHunk": "@@ -0,0 +1,75 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.iotdb.flink;\n+\n+import com.google.common.collect.Lists;\n+import org.apache.iotdb.session.Session;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.mockito.Matchers.any;\n+import static org.mockito.Mockito.*;\n+\n+public class IoTDBSinkBatchTimerTest {\n+\n+    private IoTDBSink ioTDBSink;\n+    private Session session;\n+\n+    @Before\n+    public void setUp() throws Exception {\n+        IoTDBOptions options = new IoTDBOptions();\n+        options.setTimeseriesOptionList(Lists.newArrayList(new IoTDBOptions.TimeseriesOption(\"root.sg.D01.temperature\")));\n+        ioTDBSink = new IoTDBSink(options, new DefaultIoTSerializationSchema());\n+        ioTDBSink.withBatchSize(3);\n+        ioTDBSink.withFlushIntervalMs(1000);\n+        ioTDBSink.initScheduler();\n+\n+        session = mock(Session.class);\n+        ioTDBSink.setSession(session);\n+    }\n+\n+    @Test\n+    public void testBatchInsert() throws Exception {\n+        Map<String,String> tuple = new HashMap();\n+        tuple.put(\"device\", \"root.sg.D01\");\n+        tuple.put(\"timestamp\", \"1581861293000\");\n+        tuple.put(\"measurements\", \"temperature\");\n+        tuple.put(\"values\", \"36.5\");\n+        ioTDBSink.invoke(tuple, null);\n+\n+        Thread.sleep(2500);\n+\n+        verify(session).insertInBatch(any(List.class), any(List.class), any(List.class), any(List.class));\n+\n+        Thread.sleep(1000);\n+\n+        verifyZeroInteractions(session);\n+    }\n+\n+    @Test\n+    public void close() throws Exception {\n+        ioTDBSink.close();\n+        verify(session).close();\n+    }\n+", "originalCommit": "b9ba5d4cc35fb6f4faaacac4077a1b7ecda6067b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "32f32f62f62a5fdb59fa751a00556505fb604114", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkBatchTimerTest.java b/flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkBatchTimerTest.java\nindex c59eac82e0..226e798e89 100644\n--- a/flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkBatchTimerTest.java\n+++ b/flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkBatchTimerTest.java\n", "chunk": "@@ -71,5 +71,4 @@ public class IoTDBSinkBatchTimerTest {\n         ioTDBSink.close();\n         verify(session).close();\n     }\n-\n }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODkyNjk1MA==", "url": "https://github.com/apache/iotdb/pull/817#discussion_r388926950", "body": "Unnecessary empty line.", "bodyText": "Unnecessary empty line.", "bodyHTML": "<p dir=\"auto\">Unnecessary empty line.</p>", "author": "WeiZhong94", "createdAt": "2020-03-06T14:18:02Z", "path": "flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkInsertTest.java", "diffHunk": "@@ -0,0 +1,67 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.iotdb.flink;\n+\n+import com.google.common.collect.Lists;\n+import org.apache.iotdb.session.Session;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.mockito.Matchers.any;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.verify;\n+\n+public class IoTDBSinkInsertTest {\n+\n+    private IoTDBSink ioTDBSink;\n+    private Session session;\n+\n+    @Before\n+    public void setUp() throws Exception {\n+        IoTDBOptions options = new IoTDBOptions();\n+        options.setTimeseriesOptionList(Lists.newArrayList(new IoTDBOptions.TimeseriesOption(\"root.sg.D01.temperature\")));\n+        ioTDBSink = new IoTDBSink(options, new DefaultIoTSerializationSchema());\n+\n+        session = mock(Session.class);\n+        ioTDBSink.setSession(session);\n+    }\n+\n+    @Test\n+    public void testInsert() throws Exception {\n+        Map<String,String> tuple = new HashMap();\n+        tuple.put(\"device\", \"root.sg.D01\");\n+        tuple.put(\"timestamp\", \"1581861293000\");\n+        tuple.put(\"measurements\", \"temperature\");\n+        tuple.put(\"values\", \"36.5\");\n+\n+        ioTDBSink.invoke(tuple, null);\n+        verify(session).insert(any(String.class), any(Long.class), any(List.class), any(List.class));\n+    }\n+\n+    @Test\n+    public void close() throws Exception {\n+        ioTDBSink.close();\n+        verify(session).close();\n+    }\n+", "originalCommit": "b9ba5d4cc35fb6f4faaacac4077a1b7ecda6067b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "32f32f62f62a5fdb59fa751a00556505fb604114", "changed_code": [{"header": "diff --git a/flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkInsertTest.java b/flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkInsertTest.java\nindex cd360df339..06fe7f3897 100644\n--- a/flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkInsertTest.java\n+++ b/flink-iotdb-connector/src/test/java/org/apache/iotdb/flink/IoTDBSinkInsertTest.java\n", "chunk": "@@ -63,5 +63,4 @@ public class IoTDBSinkInsertTest {\n         ioTDBSink.close();\n         verify(session).close();\n     }\n-\n }\n", "next_change": null}]}}, {"oid": "32f32f62f62a5fdb59fa751a00556505fb604114", "url": "https://github.com/apache/iotdb/commit/32f32f62f62a5fdb59fa751a00556505fb604114", "message": "[IOTDB-497] remove unnecessary empty lines", "committedDate": "2020-03-07T03:11:08Z", "type": "commit"}]}