{"pr_number": 1248, "pr_title": "SAMZA-2410: Update ClusterBasedJobCoordinator config retrieval logic from loader.", "pr_author": "kw2542", "pr_createdAt": "2020-01-10T19:09:30Z", "pr_url": "https://github.com/apache/samza/pull/1248", "merge_commit": "5bef72595faa8c8cdc9e35b09342e36a5085c10b", "timeline": [{"oid": "754a2e1dc8c617238a454a6d6edd80c988c799f8", "url": "https://github.com/apache/samza/commit/754a2e1dc8c617238a454a6d6edd80c988c799f8", "message": "SAMZA-2410: Update ClusterBasedJobCoordinator config retrieval logic to read config from loader\n\nDesign:\nhttps://cwiki.apache.org/confluence/display/SAMZA/SEP-23%3A+Simplify+Job+Runner\n\nChanges:\n\n1. Based on the existence of ENV_SUBMISSION_CONFIG, ClusterBasedJobCoordinator will alternatively deserilize ENV_SUBMISSION_CONFIG and load full job config from config loader factory.\n2. Execute planning, create diagnostics stream and persist full job config back to coordinator stream when loading full job config from config loader.\n\nAPI Changes:\nN/A. This is part of a series PRs, detailed information will be provided in the last/main PR.\n\nUpgrade Instructions:\nN/A. This is part of a series PRs, detailed information will be provided in the last/main PR.\n\nUsage Instructions:\nN/A. This is part of a series PRs, detailed information will be provided in the last/main PR.\n\nTests:\nEnd to end tested with Hello Samza job.", "committedDate": "2020-01-10T19:04:00Z", "type": "commit"}, {"oid": "aa8e1ac3cfb9b870a95c42ea6e5a95db25812910", "url": "https://github.com/apache/samza/commit/aa8e1ac3cfb9b870a95c42ea6e5a95db25812910", "message": "Refactor the common logic to ConfigUtil, which will be used in LocalApplicationRunner as well.", "committedDate": "2020-01-11T00:22:40Z", "type": "commit"}, {"oid": "0d65377e8dacfe79f5a32b6ab196066e8a674e9f", "url": "https://github.com/apache/samza/commit/0d65377e8dacfe79f5a32b6ab196066e8a674e9f", "message": "Remove unused imports", "committedDate": "2020-01-11T00:33:39Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQ4MjI1OQ==", "url": "https://github.com/apache/samza/pull/1248#discussion_r365482259", "body": "Do we still need this method to return a list if RemoteApplicationRunner will only ever submit a single job?", "bodyText": "Do we still need this method to return a list if RemoteApplicationRunner will only ever submit a single job?", "bodyHTML": "<p dir=\"auto\">Do we still need this method to return a list if RemoteApplicationRunner will only ever submit a single job?</p>", "author": "bkonold", "createdAt": "2020-01-11T00:41:20Z", "path": "samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java", "diffHunk": "@@ -178,9 +185,35 @@\n   public ClusterBasedJobCoordinator(Config coordinatorSystemConfig) {\n     metrics = new MetricsRegistryMap();\n \n-    coordinatorStreamStore = new CoordinatorStreamStore(coordinatorSystemConfig, metrics);\n-    coordinatorStreamStore.init();\n-    config = CoordinatorStreamUtil.readConfigFromCoordinatorStream(coordinatorStreamStore);\n+    JobConfig jobConfig = new JobConfig(coordinatorSystemConfig);\n+\n+    if (jobConfig.getConfigLoaderFactory().isPresent()) {\n+      // load full job config with ConfigLoader\n+      Config originalConfig = ConfigUtil.loadConfig(coordinatorSystemConfig);\n+\n+      // Execute planning\n+      ApplicationDescriptorImpl<? extends ApplicationDescriptor>\n+          appDesc = ApplicationDescriptorUtil.getAppDescriptor(ApplicationUtil.fromConfig(originalConfig), originalConfig);\n+      RemoteJobPlanner planner = new RemoteJobPlanner(appDesc);\n+      List<JobConfig> jobConfigs = planner.prepareJobs();", "originalCommit": "0d65377e8dacfe79f5a32b6ab196066e8a674e9f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQ4NjI3MA==", "url": "https://github.com/apache/samza/pull/1248#discussion_r365486270", "bodyText": "Good question, both RemoteApplicationRunner and LocalJobPlanner themselves only works for single-job applications anyway, we may update them, but I think it is better to do it separately. It also relies on our plan to support multi job applications too.", "author": "kw2542", "createdAt": "2020-01-11T01:12:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQ4MjI1OQ=="}], "type": "inlineReview", "revised_code": {"commit": "c234721851151e9c1c3d192d98b518b59abbba2b", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex 101cda861..da4a9c81f 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -179,17 +179,17 @@ public class ClusterBasedJobCoordinator {\n    * Creates a new ClusterBasedJobCoordinator instance from a config. Invoke run() to actually\n    * run the jobcoordinator.\n    *\n-   * @param coordinatorSystemConfig the coordinator stream config that can be used to read the\n-   *                                {@link org.apache.samza.job.model.JobModel} from.\n+   * @param jobCoordinatorConfig job coordinator config that either contains coordinator stream properties\n+   *                             or config loader properties to load full job config.\n    */\n-  public ClusterBasedJobCoordinator(Config coordinatorSystemConfig) {\n+  public ClusterBasedJobCoordinator(Config jobCoordinatorConfig) {\n     metrics = new MetricsRegistryMap();\n \n-    JobConfig jobConfig = new JobConfig(coordinatorSystemConfig);\n+    JobConfig jobConfig = new JobConfig(jobCoordinatorConfig);\n \n     if (jobConfig.getConfigLoaderFactory().isPresent()) {\n       // load full job config with ConfigLoader\n-      Config originalConfig = ConfigUtil.loadConfig(coordinatorSystemConfig);\n+      Config originalConfig = ConfigUtil.loadConfig(jobCoordinatorConfig);\n \n       // Execute planning\n       ApplicationDescriptorImpl<? extends ApplicationDescriptor>\n", "next_change": {"commit": "c004a97d60e9bff9e5a39328ec9153c014174232", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex da4a9c81f..d22e694d7 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -176,64 +176,39 @@ public class ClusterBasedJobCoordinator {\n   volatile private Exception coordinatorException = null;\n \n   /**\n-   * Creates a new ClusterBasedJobCoordinator instance from a config. Invoke run() to actually\n-   * run the jobcoordinator.\n+   * Creates a new ClusterBasedJobCoordinator instance.\n+   * Invoke run() to actually run the job coordinator.\n    *\n-   * @param jobCoordinatorConfig job coordinator config that either contains coordinator stream properties\n-   *                             or config loader properties to load full job config.\n+   * @param metrics the registry for reporting metrics.\n+   * @param metadataStore metadata store to hold metadata.\n+   * @param fullJobConfig full job config.\n    */\n-  public ClusterBasedJobCoordinator(Config jobCoordinatorConfig) {\n-    metrics = new MetricsRegistryMap();\n-\n-    JobConfig jobConfig = new JobConfig(jobCoordinatorConfig);\n-\n-    if (jobConfig.getConfigLoaderFactory().isPresent()) {\n-      // load full job config with ConfigLoader\n-      Config originalConfig = ConfigUtil.loadConfig(jobCoordinatorConfig);\n-\n-      // Execute planning\n-      ApplicationDescriptorImpl<? extends ApplicationDescriptor>\n-          appDesc = ApplicationDescriptorUtil.getAppDescriptor(ApplicationUtil.fromConfig(originalConfig), originalConfig);\n-      RemoteJobPlanner planner = new RemoteJobPlanner(appDesc);\n-      List<JobConfig> jobConfigs = planner.prepareJobs();\n-\n-      if (jobConfigs.size() != 1) {\n-        throw new SamzaException(\"Only support single remote job is supported.\");\n-      }\n-\n-      config = jobConfigs.get(0);\n-      coordinatorStreamStore = new CoordinatorStreamStore(CoordinatorStreamUtil.buildCoordinatorStreamConfig(config), metrics);\n-      coordinatorStreamStore.init();\n-      CoordinatorStreamUtil.writeConfigToCoordinatorStream(config, true);\n-      DiagnosticsUtil.createDiagnosticsStream(config);\n-    } else {\n-      // TODO SAMZA-2432: Clean this up once SAMZA-2405 is completed when legacy flow is removed.\n-      coordinatorStreamStore = new CoordinatorStreamStore(jobCoordinatorConfig, metrics);\n-      coordinatorStreamStore.init();\n-      config = CoordinatorStreamUtil.readConfigFromCoordinatorStream(coordinatorStreamStore);\n-    }\n-\n+  private ClusterBasedJobCoordinator(MetricsRegistryMap metrics, MetadataStore metadataStore, Config fullJobConfig) {\n+    this.metrics = metrics;\n+    this.metadataStore = metadataStore;\n+    this.metadataStore.init();\n+    this.config = fullJobConfig;\n     // build a JobModelManager and ChangelogStreamManager and perform partition assignments.\n-    changelogStreamManager = new ChangelogStreamManager(new NamespaceAwareCoordinatorStreamStore(coordinatorStreamStore, SetChangelogMapping.TYPE));\n-    jobModelManager =\n-        JobModelManager.apply(config, changelogStreamManager.readPartitionMapping(), coordinatorStreamStore, metrics);\n+    this.changelogStreamManager = new ChangelogStreamManager(\n+        new NamespaceAwareCoordinatorStreamStore(metadataStore, SetChangelogMapping.TYPE));\n+    this.jobModelManager =\n+        JobModelManager.apply(config, changelogStreamManager.readPartitionMapping(), metadataStore, metrics);\n \n-    hasDurableStores = new StorageConfig(config).hasDurableStores();\n-    state = new SamzaApplicationState(jobModelManager);\n+    this.hasDurableStores = new StorageConfig(config).hasDurableStores();\n+    this.state = new SamzaApplicationState(jobModelManager);\n     // The systemAdmins should be started before partitionMonitor can be used. And it should be stopped when this coordinator is stopped.\n-    systemAdmins = new SystemAdmins(config);\n-    partitionMonitor = getPartitionCountMonitor(config, systemAdmins);\n+    this.systemAdmins = new SystemAdmins(config);\n+    this.partitionMonitor = getPartitionCountMonitor(config, systemAdmins);\n \n     Set<SystemStream> inputSystemStreams = JobModelUtil.getSystemStreams(jobModelManager.jobModel());\n-    inputStreamRegexMonitor = getInputRegexMonitor(config, systemAdmins, inputSystemStreams);\n-\n-    clusterManagerConfig = new ClusterManagerConfig(config);\n-    isJmxEnabled = clusterManagerConfig.getJmxEnabledOnJobCoordinator();\n+    this.inputStreamRegexMonitor = getInputRegexMonitor(config, systemAdmins, inputSystemStreams);\n \n-    jobCoordinatorSleepInterval = clusterManagerConfig.getJobCoordinatorSleepInterval();\n+    ClusterManagerConfig clusterManagerConfig = new ClusterManagerConfig(config);\n+    this.isJmxEnabled = clusterManagerConfig.getJmxEnabledOnJobCoordinator();\n+    this.jobCoordinatorSleepInterval = clusterManagerConfig.getJobCoordinatorSleepInterval();\n \n     // build a container process Manager\n-    containerProcessManager = createContainerProcessManager();\n+    this.containerProcessManager = createContainerProcessManager();\n   }\n \n   /**\n", "next_change": null}]}}]}, "revised_code_in_main": {"commit": "5bef72595faa8c8cdc9e35b09342e36a5085c10b", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex 101cda861..d97a4a1e0 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -176,66 +177,38 @@ public class ClusterBasedJobCoordinator {\n   volatile private Exception coordinatorException = null;\n \n   /**\n-   * Creates a new ClusterBasedJobCoordinator instance from a config. Invoke run() to actually\n-   * run the jobcoordinator.\n+   * Creates a new ClusterBasedJobCoordinator instance.\n+   * Invoke run() to actually run the job coordinator.\n    *\n-   * @param coordinatorSystemConfig the coordinator stream config that can be used to read the\n-   *                                {@link org.apache.samza.job.model.JobModel} from.\n+   * @param metrics the registry for reporting metrics.\n+   * @param metadataStore metadata store to hold metadata.\n+   * @param fullJobConfig full job config.\n    */\n-  public ClusterBasedJobCoordinator(Config coordinatorSystemConfig) {\n-    metrics = new MetricsRegistryMap();\n-\n-    JobConfig jobConfig = new JobConfig(coordinatorSystemConfig);\n-\n-    if (jobConfig.getConfigLoaderFactory().isPresent()) {\n-      // load full job config with ConfigLoader\n-      Config originalConfig = ConfigUtil.loadConfig(coordinatorSystemConfig);\n-\n-      // Execute planning\n-      ApplicationDescriptorImpl<? extends ApplicationDescriptor>\n-          appDesc = ApplicationDescriptorUtil.getAppDescriptor(ApplicationUtil.fromConfig(originalConfig), originalConfig);\n-      RemoteJobPlanner planner = new RemoteJobPlanner(appDesc);\n-      List<JobConfig> jobConfigs = planner.prepareJobs();\n-\n-      if (jobConfigs.size() != 1) {\n-        throw new SamzaException(\"Only support single remote job is supported.\");\n-      }\n-\n-      // Merge with default coordinator stream config\n-      config = ConfigUtil.override(jobConfigs.get(0), CoordinatorStreamUtil.buildCoordinatorStreamConfig(jobConfigs.get(0)));\n-\n-      coordinatorStreamStore = new CoordinatorStreamStore(config, metrics);\n-      coordinatorStreamStore.init();\n-      CoordinatorStreamUtil.writeConfigToCoordinatorStream(config, true);\n-      DiagnosticsUtil.createDiagnosticsStream(config);\n-    } else {\n-      // TODO: Clean this up once SAMZA-2405 is completed when legacy flow is removed.\n-      coordinatorStreamStore = new CoordinatorStreamStore(coordinatorSystemConfig, metrics);\n-      coordinatorStreamStore.init();\n-      config = CoordinatorStreamUtil.readConfigFromCoordinatorStream(coordinatorStreamStore);\n-    }\n-\n+  private ClusterBasedJobCoordinator(MetricsRegistryMap metrics, MetadataStore metadataStore, Config fullJobConfig) {\n+    this.metrics = metrics;\n+    this.metadataStore = metadataStore;\n+    this.config = fullJobConfig;\n     // build a JobModelManager and ChangelogStreamManager and perform partition assignments.\n-    changelogStreamManager = new ChangelogStreamManager(new NamespaceAwareCoordinatorStreamStore(coordinatorStreamStore, SetChangelogMapping.TYPE));\n-    jobModelManager =\n-        JobModelManager.apply(config, changelogStreamManager.readPartitionMapping(), coordinatorStreamStore, metrics);\n+    this.changelogStreamManager = new ChangelogStreamManager(\n+        new NamespaceAwareCoordinatorStreamStore(metadataStore, SetChangelogMapping.TYPE));\n+    this.jobModelManager =\n+        JobModelManager.apply(config, changelogStreamManager.readPartitionMapping(), metadataStore, metrics);\n \n-    hasDurableStores = new StorageConfig(config).hasDurableStores();\n-    state = new SamzaApplicationState(jobModelManager);\n+    this.hasDurableStores = new StorageConfig(config).hasDurableStores();\n+    this.state = new SamzaApplicationState(jobModelManager);\n     // The systemAdmins should be started before partitionMonitor can be used. And it should be stopped when this coordinator is stopped.\n-    systemAdmins = new SystemAdmins(config);\n-    partitionMonitor = getPartitionCountMonitor(config, systemAdmins);\n+    this.systemAdmins = new SystemAdmins(config);\n+    this.partitionMonitor = getPartitionCountMonitor(config, systemAdmins);\n \n     Set<SystemStream> inputSystemStreams = JobModelUtil.getSystemStreams(jobModelManager.jobModel());\n-    inputStreamRegexMonitor = getInputRegexMonitor(config, systemAdmins, inputSystemStreams);\n-\n-    clusterManagerConfig = new ClusterManagerConfig(config);\n-    isJmxEnabled = clusterManagerConfig.getJmxEnabledOnJobCoordinator();\n+    this.inputStreamRegexMonitor = getInputRegexMonitor(config, systemAdmins, inputSystemStreams);\n \n-    jobCoordinatorSleepInterval = clusterManagerConfig.getJobCoordinatorSleepInterval();\n+    ClusterManagerConfig clusterManagerConfig = new ClusterManagerConfig(config);\n+    this.isJmxEnabled = clusterManagerConfig.getJmxEnabledOnJobCoordinator();\n+    this.jobCoordinatorSleepInterval = clusterManagerConfig.getJobCoordinatorSleepInterval();\n \n     // build a container process Manager\n-    containerProcessManager = createContainerProcessManager();\n+    this.containerProcessManager = createContainerProcessManager();\n   }\n \n   /**\n", "next_change": {"commit": "b379933d62c8cb438f0599e2540bce6b63e8c014", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex d97a4a1e0..2b9636c8d 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -208,7 +218,13 @@ public class ClusterBasedJobCoordinator {\n     this.jobCoordinatorSleepInterval = clusterManagerConfig.getJobCoordinatorSleepInterval();\n \n     // build a container process Manager\n-    this.containerProcessManager = createContainerProcessManager();\n+    containerProcessManager = createContainerProcessManager();\n+\n+    // build utils related to container placements\n+    containerPlacementMetadataStore = new ContainerPlacementMetadataStore(metadataStore);\n+    containerPlacementRequestAllocator = new ContainerPlacementRequestAllocator(containerPlacementMetadataStore, containerProcessManager);\n+    this.containerPlacementRequestAllocatorThread =\n+        new Thread(containerPlacementRequestAllocator, \"Samza-\" + ContainerPlacementRequestAllocator.class.getSimpleName());\n   }\n \n   /**\n", "next_change": {"commit": "b4a9fe67238d6eb81b2c61177cafd276ade67c07", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex 2b9636c8d..f894bcff5 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -217,12 +218,16 @@ public class ClusterBasedJobCoordinator {\n     this.isJmxEnabled = clusterManagerConfig.getJmxEnabledOnJobCoordinator();\n     this.jobCoordinatorSleepInterval = clusterManagerConfig.getJobCoordinatorSleepInterval();\n \n+    // build metastore for container placement messages\n+    containerPlacementMetadataStore = new ContainerPlacementMetadataStore(metadataStore);\n+\n     // build a container process Manager\n     containerProcessManager = createContainerProcessManager();\n \n     // build utils related to container placements\n-    containerPlacementMetadataStore = new ContainerPlacementMetadataStore(metadataStore);\n-    containerPlacementRequestAllocator = new ContainerPlacementRequestAllocator(containerPlacementMetadataStore, containerProcessManager);\n+    containerPlacementRequestAllocator =\n+        new ContainerPlacementRequestAllocator(containerPlacementMetadataStore, containerProcessManager,\n+            new ApplicationConfig(config));\n     this.containerPlacementRequestAllocatorThread =\n         new Thread(containerPlacementRequestAllocator, \"Samza-\" + ContainerPlacementRequestAllocator.class.getSimpleName());\n   }\n", "next_change": null}]}}]}}]}, "commits_in_main": [{"oid": "5bef72595faa8c8cdc9e35b09342e36a5085c10b", "message": "Merge commit", "committedDate": null}, {"oid": "b379933d62c8cb438f0599e2540bce6b63e8c014", "committedDate": "2020-01-21 15:37:07 -0800", "message": "SAMZA-2404: [SEP-22] Container Placement Handler for dispatching container placement messages between metastore and JobCoordinator (#1227)"}, {"oid": "b4a9fe67238d6eb81b2c61177cafd276ade67c07", "committedDate": "2020-02-18 12:32:05 -0800", "message": "SAMZA-2402: Tie Container placement service and Container placement handler and validate placement requests (#1267)"}, {"oid": "e4eefe2a9b7d6559ee5ce236e5357d773c199816", "committedDate": "2020-03-10 13:20:39 -0700", "message": "SAMZA-2453: Update ClusterBasedJobCoordinator to support Beam jobs (#1309)"}, {"oid": "d6608714c211835c3b04caaaa49882455135158c", "committedDate": "2020-03-11 13:44:21 -0700", "message": "SAMZA-2466: [Scala cleanup] Convert ShellCommandConfig from scala to java (#1288)"}, {"oid": "b7cab952317bd4320f12e18c2cc3e3cee77770da", "committedDate": "2020-03-17 19:20:52 -0700", "message": "SAMZA-2488: Add JobCoordinatorLaunchUtil to handle common logic when launching job coordiantor. (#1318)"}, {"oid": "c527ec5a151e0da570dfdc3896c30694ac7c34f6", "committedDate": "2020-03-27 22:36:05 -0700", "message": "SAMZA-2491: AM should log uncaught exceptions and System.exit to ensure that the process dies on errors (#1325)"}, {"oid": "26d9eecac76f3b87610312d0066d96a5b36eef35", "committedDate": "2020-04-01 16:43:05 -0700", "message": "SAMZA-2501 : Optimizing startpoint manager to not make successive bootstrapMessage calls to coordinator-store (#1335)"}, {"oid": "d745e7d1cbd051002b30bfe99ae924d48ff96eaa", "committedDate": "2020-04-16 13:48:29 -0700", "message": "SAMZA-2509: New config name to represent if split deployment feature is enabled (#1342)"}, {"oid": "e86951f102c7a854d343b1f80dc2796be29c9c81", "committedDate": "2020-04-24 09:40:25 -0700", "message": "SAMZA-2514: Refactor codes to make runWithClassLoader method more generic (#1349)"}, {"oid": "5f05cdde2eea46a8cbda08dd8c9868c8f46a4e9d", "committedDate": "2020-06-22 15:52:51 -0700", "message": "SAMZA-2551: Upgrade all modules to automatically use checkstyle 6.11.2 (part 1: includes samza-core) (#1389)"}, {"oid": "f7f9f3c7905b047f262383bcc64ebb01ab73f421", "committedDate": "2020-08-26 19:39:32 -0700", "message": "SAMZA-2439: Remove LocalityManager and container location information from JobModel (#1421)"}, {"oid": "d689fd2568ea9dd457ed1c7c9cb193f4ae6fa631", "committedDate": "2020-09-02 15:10:42 -0700", "message": "SAMZA-2584: Refactor ClusterBasedJobCoordinator (#1424)"}, {"oid": "42e68e88c4dfe4c891dd601ee98f190d598decfd", "committedDate": "2020-09-15 21:50:40 -0700", "message": "SAMZA-2574 : improve flexibility of SystemFactory interface"}, {"oid": "c212cac420864d09f2663da2e51c23e4718d6812", "committedDate": "2020-11-30 23:37:21 -0800", "message": "SAMZA-2604: Datamodel change to capture physical container id for AM HA (#1445)"}, {"oid": "108768393960a893f9d202edf50bf47d2b1af590", "committedDate": "2020-12-09 09:33:11 -0800", "message": "SAMZA-2610: Handle Metadata changes for AM HA orchestration (#1450)"}, {"oid": "7cc4eaa96fff244f6dce9c18af804917db7c3b2b", "committedDate": "2021-05-25 16:00:46 -0700", "message": "SAMZA-2657: Blob Store as backend for Samza State backup and restore (#1501)"}, {"oid": "120098d6c45ca023d2a0fb144b0e333ab4e8ffe8", "committedDate": "2021-08-24 14:08:17 -0700", "message": "SAMZA-2670: Update granularity of JobCoordinatorMetadataManager.checkForMetadataChanges and epoch id extraction (#1519)"}, {"oid": "27b1495589e992cf1606ebfc2e34699077d60b73", "committedDate": "2021-08-30 14:26:40 -0700", "message": "SAMZA-2672: Extract creation of stream monitors into separate classes for reuse (#1520)"}, {"oid": "493de64bb8c0228bbda11822ae3c84c2085263bf", "committedDate": "2022-06-13 15:06:05 -0700", "message": "SAMZA-2742: [Pipeline Drain] Add Drain components and integrate them with SamzaContainer and JC (#1605)"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQ4MzQ0OA==", "url": "https://github.com/apache/samza/pull/1248#discussion_r365483448", "body": "s/submissionEnv/submissiongConfig?", "bodyText": "s/submissionEnv/submissiongConfig?", "bodyHTML": "<p dir=\"auto\">s/submissionEnv/submissiongConfig?</p>", "author": "bkonold", "createdAt": "2020-01-11T00:49:10Z", "path": "samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java", "diffHunk": "@@ -480,20 +512,41 @@ private static void executeRunClusterBasedJobCoordinatorForClass(Class<?> cluste\n    * {@link #main(String[])} so that it can be executed directly or from a separate classloader.\n    */\n   private static void runClusterBasedJobCoordinator(String[] args) {\n-    Config coordinatorSystemConfig;\n     final String coordinatorSystemEnv = System.getenv(ShellCommandConfig.ENV_COORDINATOR_SYSTEM_CONFIG());\n-    try {\n-      //Read and parse the coordinator system config.\n-      LOG.info(\"Parsing coordinator system config {}\", coordinatorSystemEnv);\n-      coordinatorSystemConfig =\n-          new MapConfig(SamzaObjectMapper.getObjectMapper().readValue(coordinatorSystemEnv, Config.class));\n-      LOG.info(\"Using the coordinator system config: {}.\", coordinatorSystemConfig);\n-    } catch (IOException e) {\n-      LOG.error(\"Exception while reading coordinator stream config\", e);\n-      throw new SamzaException(e);\n+    final String submissionEnv = System.getenv(ShellCommandConfig.ENV_SUBMISSION_CONFIG());\n+\n+    if (submissionEnv != null) {\n+      Config submissionConfig;\n+      try {\n+        //Read and parse the coordinator system config.\n+        LOG.info(\"Parsing submission config {}\", submissionEnv);\n+        submissionConfig =\n+            new MapConfig(SamzaObjectMapper.getObjectMapper().readValue(submissionEnv, Config.class));\n+        LOG.info(\"Using the submission config: {}.\", submissionEnv);", "originalCommit": "0d65377e8dacfe79f5a32b6ab196066e8a674e9f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQ4NjQ2OA==", "url": "https://github.com/apache/samza/pull/1248#discussion_r365486468", "bodyText": "Fixed.", "author": "kw2542", "createdAt": "2020-01-11T01:14:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQ4MzQ0OA=="}], "type": "inlineReview", "revised_code": {"commit": "a7b0d0f6c7b4be861fef8200040e0d8dbd67d30b", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex 101cda861..4f0f2e331 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -522,7 +520,7 @@ public class ClusterBasedJobCoordinator {\n         LOG.info(\"Parsing submission config {}\", submissionEnv);\n         submissionConfig =\n             new MapConfig(SamzaObjectMapper.getObjectMapper().readValue(submissionEnv, Config.class));\n-        LOG.info(\"Using the submission config: {}.\", submissionEnv);\n+        LOG.info(\"Using the submission config: {}.\", submissionConfig);\n       } catch (IOException e) {\n         LOG.error(\"Exception while reading submission config\", e);\n         throw new SamzaException(e);\n", "next_change": {"commit": "c004a97d60e9bff9e5a39328ec9153c014174232", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex 4f0f2e331..d22e694d7 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -526,7 +501,7 @@ public class ClusterBasedJobCoordinator {\n         throw new SamzaException(e);\n       }\n \n-      ClusterBasedJobCoordinator jc = new ClusterBasedJobCoordinator(submissionConfig);\n+      ClusterBasedJobCoordinator jc = createFromConfigLoader(submissionConfig);\n       jc.run();\n       LOG.info(\"Finished running ClusterBasedJobCoordinator\");\n     } else {\n", "next_change": null}]}}]}, "revised_code_in_main": {"commit": "5bef72595faa8c8cdc9e35b09342e36a5085c10b", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex 101cda861..d97a4a1e0 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -515,20 +488,20 @@ public class ClusterBasedJobCoordinator {\n     final String coordinatorSystemEnv = System.getenv(ShellCommandConfig.ENV_COORDINATOR_SYSTEM_CONFIG());\n     final String submissionEnv = System.getenv(ShellCommandConfig.ENV_SUBMISSION_CONFIG());\n \n-    if (submissionEnv != null) {\n+    if (!StringUtils.isBlank(submissionEnv)) {\n       Config submissionConfig;\n       try {\n         //Read and parse the coordinator system config.\n         LOG.info(\"Parsing submission config {}\", submissionEnv);\n         submissionConfig =\n             new MapConfig(SamzaObjectMapper.getObjectMapper().readValue(submissionEnv, Config.class));\n-        LOG.info(\"Using the submission config: {}.\", submissionEnv);\n+        LOG.info(\"Using the submission config: {}.\", submissionConfig);\n       } catch (IOException e) {\n         LOG.error(\"Exception while reading submission config\", e);\n         throw new SamzaException(e);\n       }\n \n-      ClusterBasedJobCoordinator jc = new ClusterBasedJobCoordinator(submissionConfig);\n+      ClusterBasedJobCoordinator jc = createFromConfigLoader(submissionConfig);\n       jc.run();\n       LOG.info(\"Finished running ClusterBasedJobCoordinator\");\n     } else {\n", "next_change": {"commit": "e4eefe2a9b7d6559ee5ce236e5357d773c199816", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex d97a4a1e0..b56cb5272 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -501,8 +553,28 @@ public class ClusterBasedJobCoordinator {\n         throw new SamzaException(e);\n       }\n \n-      ClusterBasedJobCoordinator jc = createFromConfigLoader(submissionConfig);\n-      jc.run();\n+      ApplicationConfig appConfig = new ApplicationConfig(submissionConfig);\n+\n+      /*\n+       * Invoke app.main.class with app.main.args when present.\n+       * For Beam jobs, app.main.class will be Beam's main class\n+       * and app.main.args will be Beam's pipeline options.\n+       */\n+      if (appConfig.getAppMainClass().isPresent()) {\n+        String className = appConfig.getAppMainClass().get();\n+        LOG.info(\"Invoke main {}\", className);\n+        try {\n+          Class<?> cls = Class.forName(className);\n+          Method mainMethod = cls.getMethod(\"main\", String[].class);\n+          mainMethod.invoke(null, (Object) toArgs(appConfig));\n+        } catch (Exception e) {\n+          throw new SamzaException(e);\n+        }\n+      } else {\n+        ClusterBasedJobCoordinator jc = createFromConfigLoader(submissionConfig);\n+        jc.run();\n+      }\n+\n       LOG.info(\"Finished running ClusterBasedJobCoordinator\");\n     } else {\n       // TODO: Clean this up once SAMZA-2405 is completed when legacy flow is removed.\n", "next_change": {"commit": "b7cab952317bd4320f12e18c2cc3e3cee77770da", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex b56cb5272..e7647f40f 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -571,8 +567,16 @@ public class ClusterBasedJobCoordinator {\n           throw new SamzaException(e);\n         }\n       } else {\n-        ClusterBasedJobCoordinator jc = createFromConfigLoader(submissionConfig);\n-        jc.run();\n+        JobConfig jobConfig = new JobConfig(submissionConfig);\n+\n+        if (!jobConfig.getConfigLoaderFactory().isPresent()) {\n+          throw new SamzaException(JobConfig.CONFIG_LOADER_FACTORY + \" is required to initialize job coordinator from config loader\");\n+        }\n+\n+        // load full job config with ConfigLoader\n+        Config originalConfig = ConfigUtil.loadConfig(submissionConfig);\n+\n+        JobCoordinatorLaunchUtil.run(ApplicationUtil.fromConfig(originalConfig), originalConfig);\n       }\n \n       LOG.info(\"Finished running ClusterBasedJobCoordinator\");\n", "next_change": {"commit": "d689fd2568ea9dd457ed1c7c9cb193f4ae6fa631", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex e7647f40f..6295ed6e9 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -455,196 +448,6 @@ public class ClusterBasedJobCoordinator {\n \n   @VisibleForTesting\n   ContainerProcessManager createContainerProcessManager() {\n-    return new ContainerProcessManager(config, state, metrics, containerPlacementMetadataStore);\n-  }\n-\n-  /**\n-   * The entry point for the {@link ClusterBasedJobCoordinator}.\n-   */\n-  public static void main(String[] args) {\n-    boolean dependencyIsolationEnabled = Boolean.parseBoolean(\n-        System.getenv(ShellCommandConfig.ENV_CLUSTER_BASED_JOB_COORDINATOR_DEPENDENCY_ISOLATION_ENABLED));\n-    if (!dependencyIsolationEnabled) {\n-      // no isolation enabled, so can just execute runClusterBasedJobCoordinator directly\n-      runClusterBasedJobCoordinator(args);\n-    } else {\n-      runWithClassLoader(new IsolatingClassLoaderFactory().buildClassLoader(), args);\n-    }\n-  }\n-\n-  /**\n-   * Execute the coordinator using a separate isolated classloader.\n-   * @param classLoader {@link ClassLoader} to use to load the {@link ClusterBasedJobCoordinator} which will run\n-   * @param args arguments to pass when running the {@link ClusterBasedJobCoordinator}\n-   */\n-  @VisibleForTesting\n-  static void runWithClassLoader(ClassLoader classLoader, String[] args) {\n-    // need to use the isolated classloader to load ClusterBasedJobCoordinator and then run using that new class\n-    Class<?> clusterBasedJobCoordinatorClass;\n-    try {\n-      clusterBasedJobCoordinatorClass = classLoader.loadClass(ClusterBasedJobCoordinator.class.getName());\n-    } catch (ClassNotFoundException e) {\n-      throw new SamzaException(\n-          \"Isolation was enabled, but unable to find ClusterBasedJobCoordinator in isolated classloader\", e);\n-    }\n-\n-    // save the current context classloader so it can be reset after finishing the call to runClusterBasedJobCoordinator\n-    ClassLoader previousContextClassLoader = Thread.currentThread().getContextClassLoader();\n-    // this is needed because certain libraries (e.g. log4j) use the context classloader\n-    Thread.currentThread().setContextClassLoader(classLoader);\n-\n-    try {\n-      executeRunClusterBasedJobCoordinatorForClass(clusterBasedJobCoordinatorClass, args);\n-    } finally {\n-      // reset the context class loader; it's good practice, and could be important when running a test suite\n-      Thread.currentThread().setContextClassLoader(previousContextClassLoader);\n-    }\n-  }\n-\n-  /**\n-   * Runs the {@link ClusterBasedJobCoordinator#runClusterBasedJobCoordinator(String[])} method of the given\n-   * {@code clusterBasedJobCoordinatorClass} using reflection.\n-   * @param clusterBasedJobCoordinatorClass {@link ClusterBasedJobCoordinator} {@link Class} for which to execute\n-   * {@link ClusterBasedJobCoordinator#runClusterBasedJobCoordinator(String[])}\n-   * @param args arguments to pass to {@link ClusterBasedJobCoordinator#runClusterBasedJobCoordinator(String[])}\n-   */\n-  private static void executeRunClusterBasedJobCoordinatorForClass(Class<?> clusterBasedJobCoordinatorClass,\n-      String[] args) {\n-    Method runClusterBasedJobCoordinatorMethod;\n-    try {\n-      runClusterBasedJobCoordinatorMethod =\n-          clusterBasedJobCoordinatorClass.getDeclaredMethod(\"runClusterBasedJobCoordinator\", String[].class);\n-    } catch (NoSuchMethodException e) {\n-      throw new SamzaException(\"Isolation was enabled, but unable to find runClusterBasedJobCoordinator method\", e);\n-    }\n-    // only sets accessible flag for this Method instance, not other Method instances for runClusterBasedJobCoordinator\n-    runClusterBasedJobCoordinatorMethod.setAccessible(true);\n-\n-    try {\n-      // wrapping args in object array so that args is passed as a single argument to the method\n-      runClusterBasedJobCoordinatorMethod.invoke(null, new Object[]{args});\n-    } catch (IllegalAccessException | InvocationTargetException e) {\n-      throw new SamzaException(\"Exception while executing runClusterBasedJobCoordinator method\", e);\n-    }\n-  }\n-\n-  /**\n-   * This is the actual execution for the {@link ClusterBasedJobCoordinator}. This is separated out from\n-   * {@link #main(String[])} so that it can be executed directly or from a separate classloader.\n-   */\n-  private static void runClusterBasedJobCoordinator(String[] args) {\n-    final String coordinatorSystemEnv = System.getenv(ShellCommandConfig.ENV_COORDINATOR_SYSTEM_CONFIG);\n-    final String submissionEnv = System.getenv(ShellCommandConfig.ENV_SUBMISSION_CONFIG);\n-\n-    if (!StringUtils.isBlank(submissionEnv)) {\n-      Config submissionConfig;\n-      try {\n-        //Read and parse the coordinator system config.\n-        LOG.info(\"Parsing submission config {}\", submissionEnv);\n-        submissionConfig =\n-            new MapConfig(SamzaObjectMapper.getObjectMapper().readValue(submissionEnv, Config.class));\n-        LOG.info(\"Using the submission config: {}.\", submissionConfig);\n-      } catch (IOException e) {\n-        LOG.error(\"Exception while reading submission config\", e);\n-        throw new SamzaException(e);\n-      }\n-\n-      ApplicationConfig appConfig = new ApplicationConfig(submissionConfig);\n-\n-      /*\n-       * Invoke app.main.class with app.main.args when present.\n-       * For Beam jobs, app.main.class will be Beam's main class\n-       * and app.main.args will be Beam's pipeline options.\n-       */\n-      if (appConfig.getAppMainClass().isPresent()) {\n-        String className = appConfig.getAppMainClass().get();\n-        LOG.info(\"Invoke main {}\", className);\n-        try {\n-          Class<?> cls = Class.forName(className);\n-          Method mainMethod = cls.getMethod(\"main\", String[].class);\n-          mainMethod.invoke(null, (Object) toArgs(appConfig));\n-        } catch (Exception e) {\n-          throw new SamzaException(e);\n-        }\n-      } else {\n-        JobConfig jobConfig = new JobConfig(submissionConfig);\n-\n-        if (!jobConfig.getConfigLoaderFactory().isPresent()) {\n-          throw new SamzaException(JobConfig.CONFIG_LOADER_FACTORY + \" is required to initialize job coordinator from config loader\");\n-        }\n-\n-        // load full job config with ConfigLoader\n-        Config originalConfig = ConfigUtil.loadConfig(submissionConfig);\n-\n-        JobCoordinatorLaunchUtil.run(ApplicationUtil.fromConfig(originalConfig), originalConfig);\n-      }\n-\n-      LOG.info(\"Finished running ClusterBasedJobCoordinator\");\n-    } else {\n-      // TODO: Clean this up once SAMZA-2405 is completed when legacy flow is removed.\n-      Config coordinatorSystemConfig;\n-      try {\n-        //Read and parse the coordinator system config.\n-        LOG.info(\"Parsing coordinator system config {}\", coordinatorSystemEnv);\n-        coordinatorSystemConfig =\n-            new MapConfig(SamzaObjectMapper.getObjectMapper().readValue(coordinatorSystemEnv, Config.class));\n-        LOG.info(\"Using the coordinator system config: {}.\", coordinatorSystemConfig);\n-      } catch (IOException e) {\n-        LOG.error(\"Exception while reading coordinator stream config\", e);\n-        throw new SamzaException(e);\n-      }\n-      ClusterBasedJobCoordinator jc = createFromMetadataStore(coordinatorSystemConfig);\n-      jc.run();\n-      LOG.info(\"Finished running ClusterBasedJobCoordinator\");\n-    }\n-  }\n-\n-  /**\n-   * Initialize {@link ClusterBasedJobCoordinator} with coordinator stream config, full job config will be fetched from\n-   * coordinator stream.\n-   *\n-   * @param metadataStoreConfig to initialize {@link MetadataStore}\n-   * @return {@link ClusterBasedJobCoordinator}\n-   */\n-  // TODO SAMZA-2432: Clean this up once SAMZA-2405 is completed when legacy flow is removed.\n-  @VisibleForTesting\n-  static ClusterBasedJobCoordinator createFromMetadataStore(Config metadataStoreConfig) {\n-    MetricsRegistryMap metrics = new MetricsRegistryMap();\n-\n-    CoordinatorStreamStore coordinatorStreamStore = new CoordinatorStreamStore(metadataStoreConfig, metrics);\n-    coordinatorStreamStore.init();\n-    Config config = CoordinatorStreamUtil.readConfigFromCoordinatorStream(coordinatorStreamStore);\n-\n-    return new ClusterBasedJobCoordinator(metrics, coordinatorStreamStore, config);\n-  }\n-\n-  /**\n-   * Convert Samza config to command line arguments to invoke app.main.class\n-   *\n-   * @param config Samza config to convert.\n-   * @return converted command line arguments.\n-   */\n-  @VisibleForTesting\n-  static String[] toArgs(ApplicationConfig config) {\n-    List<String> args = new ArrayList<>(config.size() * 2);\n-\n-    config.forEach((key, value) -> {\n-        if (key.equals(ApplicationConfig.APP_MAIN_ARGS)) {\n-          /*\n-           * Converts native beam pipeline options such as\n-           * --runner=SamzaRunner --maxSourceParallelism=1024\n-           */\n-          args.addAll(Arrays.asList(value.split(\"\\\\s\")));\n-        } else {\n-          /*\n-           * Converts native Samza configs to config override format such as\n-           * --config job.name=test\n-           */\n-          args.add(\"--config\");\n-          args.add(String.format(\"%s=%s\", key, value));\n-        }\n-      });\n-\n-    return args.toArray(new String[0]);\n+    return new ContainerProcessManager(config, state, metrics, containerPlacementMetadataStore, localityManager);\n   }\n }\n", "next_change": {"commit": "108768393960a893f9d202edf50bf47d2b1af590", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex 6295ed6e9..08bcfda8f 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -448,6 +485,39 @@ public class ClusterBasedJobCoordinator {\n \n   @VisibleForTesting\n   ContainerProcessManager createContainerProcessManager() {\n-    return new ContainerProcessManager(config, state, metrics, containerPlacementMetadataStore, localityManager);\n+    return new ContainerProcessManager(config, state, metrics, containerPlacementMetadataStore, localityManager,\n+        metadataChangedAcrossAttempts);\n+  }\n+\n+  @VisibleForTesting\n+  JobCoordinatorMetadataManager createJobCoordinatorMetadataManager() {\n+    return new JobCoordinatorMetadataManager(new NamespaceAwareCoordinatorStreamStore(metadataStore,\n+        SetJobCoordinatorMetadataMessage.TYPE), JobCoordinatorMetadataManager.ClusterType.YARN, metrics);\n+  }\n+\n+  @VisibleForTesting\n+  boolean isApplicationMasterHighAvailabilityEnabled() {\n+    return new JobConfig(config).getApplicationMasterHighAvailabilityEnabled();\n+  }\n+\n+  @VisibleForTesting\n+  boolean isMetadataChangedAcrossAttempts() {\n+    return metadataChangedAcrossAttempts;\n+  }\n+\n+  /**\n+   * We only fanout startpoint if and only if\n+   *  1. Startpoint is enabled\n+   *  2. If AM HA is enabled, fanout only if startpoint enabled and job coordinator metadata changed\n+   *\n+   * @return true if it satisfies above conditions, false otherwise\n+   */\n+  @VisibleForTesting\n+  boolean shouldFanoutStartpoint() {\n+    JobConfig jobConfig = new JobConfig(config);\n+    boolean startpointEnabled = jobConfig.getStartpointEnabled();\n+\n+    return isApplicationMasterHighAvailabilityEnabled() ?\n+        startpointEnabled && isMetadataChangedAcrossAttempts() : startpointEnabled;\n   }\n }\n", "next_change": null}]}}]}}]}}]}}]}, "commits_in_main": [{"oid": "5bef72595faa8c8cdc9e35b09342e36a5085c10b", "message": "Merge commit", "committedDate": null}, {"oid": "b379933d62c8cb438f0599e2540bce6b63e8c014", "committedDate": "2020-01-21 15:37:07 -0800", "message": "SAMZA-2404: [SEP-22] Container Placement Handler for dispatching container placement messages between metastore and JobCoordinator (#1227)"}, {"oid": "b4a9fe67238d6eb81b2c61177cafd276ade67c07", "committedDate": "2020-02-18 12:32:05 -0800", "message": "SAMZA-2402: Tie Container placement service and Container placement handler and validate placement requests (#1267)"}, {"oid": "e4eefe2a9b7d6559ee5ce236e5357d773c199816", "committedDate": "2020-03-10 13:20:39 -0700", "message": "SAMZA-2453: Update ClusterBasedJobCoordinator to support Beam jobs (#1309)"}, {"oid": "d6608714c211835c3b04caaaa49882455135158c", "committedDate": "2020-03-11 13:44:21 -0700", "message": "SAMZA-2466: [Scala cleanup] Convert ShellCommandConfig from scala to java (#1288)"}, {"oid": "b7cab952317bd4320f12e18c2cc3e3cee77770da", "committedDate": "2020-03-17 19:20:52 -0700", "message": "SAMZA-2488: Add JobCoordinatorLaunchUtil to handle common logic when launching job coordiantor. (#1318)"}, {"oid": "c527ec5a151e0da570dfdc3896c30694ac7c34f6", "committedDate": "2020-03-27 22:36:05 -0700", "message": "SAMZA-2491: AM should log uncaught exceptions and System.exit to ensure that the process dies on errors (#1325)"}, {"oid": "26d9eecac76f3b87610312d0066d96a5b36eef35", "committedDate": "2020-04-01 16:43:05 -0700", "message": "SAMZA-2501 : Optimizing startpoint manager to not make successive bootstrapMessage calls to coordinator-store (#1335)"}, {"oid": "d745e7d1cbd051002b30bfe99ae924d48ff96eaa", "committedDate": "2020-04-16 13:48:29 -0700", "message": "SAMZA-2509: New config name to represent if split deployment feature is enabled (#1342)"}, {"oid": "e86951f102c7a854d343b1f80dc2796be29c9c81", "committedDate": "2020-04-24 09:40:25 -0700", "message": "SAMZA-2514: Refactor codes to make runWithClassLoader method more generic (#1349)"}, {"oid": "5f05cdde2eea46a8cbda08dd8c9868c8f46a4e9d", "committedDate": "2020-06-22 15:52:51 -0700", "message": "SAMZA-2551: Upgrade all modules to automatically use checkstyle 6.11.2 (part 1: includes samza-core) (#1389)"}, {"oid": "f7f9f3c7905b047f262383bcc64ebb01ab73f421", "committedDate": "2020-08-26 19:39:32 -0700", "message": "SAMZA-2439: Remove LocalityManager and container location information from JobModel (#1421)"}, {"oid": "d689fd2568ea9dd457ed1c7c9cb193f4ae6fa631", "committedDate": "2020-09-02 15:10:42 -0700", "message": "SAMZA-2584: Refactor ClusterBasedJobCoordinator (#1424)"}, {"oid": "42e68e88c4dfe4c891dd601ee98f190d598decfd", "committedDate": "2020-09-15 21:50:40 -0700", "message": "SAMZA-2574 : improve flexibility of SystemFactory interface"}, {"oid": "c212cac420864d09f2663da2e51c23e4718d6812", "committedDate": "2020-11-30 23:37:21 -0800", "message": "SAMZA-2604: Datamodel change to capture physical container id for AM HA (#1445)"}, {"oid": "108768393960a893f9d202edf50bf47d2b1af590", "committedDate": "2020-12-09 09:33:11 -0800", "message": "SAMZA-2610: Handle Metadata changes for AM HA orchestration (#1450)"}, {"oid": "7cc4eaa96fff244f6dce9c18af804917db7c3b2b", "committedDate": "2021-05-25 16:00:46 -0700", "message": "SAMZA-2657: Blob Store as backend for Samza State backup and restore (#1501)"}, {"oid": "120098d6c45ca023d2a0fb144b0e333ab4e8ffe8", "committedDate": "2021-08-24 14:08:17 -0700", "message": "SAMZA-2670: Update granularity of JobCoordinatorMetadataManager.checkForMetadataChanges and epoch id extraction (#1519)"}, {"oid": "27b1495589e992cf1606ebfc2e34699077d60b73", "committedDate": "2021-08-30 14:26:40 -0700", "message": "SAMZA-2672: Extract creation of stream monitors into separate classes for reuse (#1520)"}, {"oid": "493de64bb8c0228bbda11822ae3c84c2085263bf", "committedDate": "2022-06-13 15:06:05 -0700", "message": "SAMZA-2742: [Pipeline Drain] Add Drain components and integrate them with SamzaContainer and JC (#1605)"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQ4NDcxMg==", "url": "https://github.com/apache/samza/pull/1248#discussion_r365484712", "body": "Why are we merging these config keys in? From what I see these were not being written to the coordinator stream previously but only built and sent along with the submission to the RM", "bodyText": "Why are we merging these config keys in? From what I see these were not being written to the coordinator stream previously but only built and sent along with the submission to the RM", "bodyHTML": "<p dir=\"auto\">Why are we merging these config keys in? From what I see these were not being written to the coordinator stream previously but only built and sent along with the submission to the RM</p>", "author": "bkonold", "createdAt": "2020-01-11T00:58:45Z", "path": "samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java", "diffHunk": "@@ -178,9 +185,35 @@\n   public ClusterBasedJobCoordinator(Config coordinatorSystemConfig) {\n     metrics = new MetricsRegistryMap();\n \n-    coordinatorStreamStore = new CoordinatorStreamStore(coordinatorSystemConfig, metrics);\n-    coordinatorStreamStore.init();\n-    config = CoordinatorStreamUtil.readConfigFromCoordinatorStream(coordinatorStreamStore);\n+    JobConfig jobConfig = new JobConfig(coordinatorSystemConfig);\n+\n+    if (jobConfig.getConfigLoaderFactory().isPresent()) {\n+      // load full job config with ConfigLoader\n+      Config originalConfig = ConfigUtil.loadConfig(coordinatorSystemConfig);\n+\n+      // Execute planning\n+      ApplicationDescriptorImpl<? extends ApplicationDescriptor>\n+          appDesc = ApplicationDescriptorUtil.getAppDescriptor(ApplicationUtil.fromConfig(originalConfig), originalConfig);\n+      RemoteJobPlanner planner = new RemoteJobPlanner(appDesc);\n+      List<JobConfig> jobConfigs = planner.prepareJobs();\n+\n+      if (jobConfigs.size() != 1) {\n+        throw new SamzaException(\"Only support single remote job is supported.\");\n+      }\n+\n+      // Merge with default coordinator stream config\n+      config = ConfigUtil.override(jobConfigs.get(0), CoordinatorStreamUtil.buildCoordinatorStreamConfig(jobConfigs.get(0)));", "originalCommit": "0d65377e8dacfe79f5a32b6ab196066e8a674e9f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQ4NzA3MQ==", "url": "https://github.com/apache/samza/pull/1248#discussion_r365487071", "bodyText": "Good question, you are right, we should not need to merge it with the full job config, we only need to build it from the full job config and initialize CoordinatorStreamStore.", "author": "kw2542", "createdAt": "2020-01-11T01:21:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQ4NDcxMg=="}], "type": "inlineReview", "revised_code": {"commit": "a7b0d0f6c7b4be861fef8200040e0d8dbd67d30b", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex 101cda861..4f0f2e331 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -201,10 +201,8 @@ public class ClusterBasedJobCoordinator {\n         throw new SamzaException(\"Only support single remote job is supported.\");\n       }\n \n-      // Merge with default coordinator stream config\n-      config = ConfigUtil.override(jobConfigs.get(0), CoordinatorStreamUtil.buildCoordinatorStreamConfig(jobConfigs.get(0)));\n-\n-      coordinatorStreamStore = new CoordinatorStreamStore(config, metrics);\n+      config = jobConfigs.get(0);\n+      coordinatorStreamStore = new CoordinatorStreamStore(CoordinatorStreamUtil.buildCoordinatorStreamConfig(config), metrics);\n       coordinatorStreamStore.init();\n       CoordinatorStreamUtil.writeConfigToCoordinatorStream(config, true);\n       DiagnosticsUtil.createDiagnosticsStream(config);\n", "next_change": {"commit": "86032a6feaa1e25db3e18e18a1dd1f019ec473b7", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex 4f0f2e331..cb51ab666 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -207,7 +207,7 @@ public class ClusterBasedJobCoordinator {\n       CoordinatorStreamUtil.writeConfigToCoordinatorStream(config, true);\n       DiagnosticsUtil.createDiagnosticsStream(config);\n     } else {\n-      // TODO: Clean this up once SAMZA-2405 is completed when legacy flow is removed.\n+      // TODO SAMZA-2432: Clean this up once SAMZA-2405 is completed when legacy flow is removed.\n       coordinatorStreamStore = new CoordinatorStreamStore(coordinatorSystemConfig, metrics);\n       coordinatorStreamStore.init();\n       config = CoordinatorStreamUtil.readConfigFromCoordinatorStream(coordinatorStreamStore);\n", "next_change": {"commit": "c234721851151e9c1c3d192d98b518b59abbba2b", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex cb51ab666..da4a9c81f 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -208,7 +208,7 @@ public class ClusterBasedJobCoordinator {\n       DiagnosticsUtil.createDiagnosticsStream(config);\n     } else {\n       // TODO SAMZA-2432: Clean this up once SAMZA-2405 is completed when legacy flow is removed.\n-      coordinatorStreamStore = new CoordinatorStreamStore(coordinatorSystemConfig, metrics);\n+      coordinatorStreamStore = new CoordinatorStreamStore(jobCoordinatorConfig, metrics);\n       coordinatorStreamStore.init();\n       config = CoordinatorStreamUtil.readConfigFromCoordinatorStream(coordinatorStreamStore);\n     }\n", "next_change": {"commit": "c004a97d60e9bff9e5a39328ec9153c014174232", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex da4a9c81f..d22e694d7 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -176,64 +176,39 @@ public class ClusterBasedJobCoordinator {\n   volatile private Exception coordinatorException = null;\n \n   /**\n-   * Creates a new ClusterBasedJobCoordinator instance from a config. Invoke run() to actually\n-   * run the jobcoordinator.\n+   * Creates a new ClusterBasedJobCoordinator instance.\n+   * Invoke run() to actually run the job coordinator.\n    *\n-   * @param jobCoordinatorConfig job coordinator config that either contains coordinator stream properties\n-   *                             or config loader properties to load full job config.\n+   * @param metrics the registry for reporting metrics.\n+   * @param metadataStore metadata store to hold metadata.\n+   * @param fullJobConfig full job config.\n    */\n-  public ClusterBasedJobCoordinator(Config jobCoordinatorConfig) {\n-    metrics = new MetricsRegistryMap();\n-\n-    JobConfig jobConfig = new JobConfig(jobCoordinatorConfig);\n-\n-    if (jobConfig.getConfigLoaderFactory().isPresent()) {\n-      // load full job config with ConfigLoader\n-      Config originalConfig = ConfigUtil.loadConfig(jobCoordinatorConfig);\n-\n-      // Execute planning\n-      ApplicationDescriptorImpl<? extends ApplicationDescriptor>\n-          appDesc = ApplicationDescriptorUtil.getAppDescriptor(ApplicationUtil.fromConfig(originalConfig), originalConfig);\n-      RemoteJobPlanner planner = new RemoteJobPlanner(appDesc);\n-      List<JobConfig> jobConfigs = planner.prepareJobs();\n-\n-      if (jobConfigs.size() != 1) {\n-        throw new SamzaException(\"Only support single remote job is supported.\");\n-      }\n-\n-      config = jobConfigs.get(0);\n-      coordinatorStreamStore = new CoordinatorStreamStore(CoordinatorStreamUtil.buildCoordinatorStreamConfig(config), metrics);\n-      coordinatorStreamStore.init();\n-      CoordinatorStreamUtil.writeConfigToCoordinatorStream(config, true);\n-      DiagnosticsUtil.createDiagnosticsStream(config);\n-    } else {\n-      // TODO SAMZA-2432: Clean this up once SAMZA-2405 is completed when legacy flow is removed.\n-      coordinatorStreamStore = new CoordinatorStreamStore(jobCoordinatorConfig, metrics);\n-      coordinatorStreamStore.init();\n-      config = CoordinatorStreamUtil.readConfigFromCoordinatorStream(coordinatorStreamStore);\n-    }\n-\n+  private ClusterBasedJobCoordinator(MetricsRegistryMap metrics, MetadataStore metadataStore, Config fullJobConfig) {\n+    this.metrics = metrics;\n+    this.metadataStore = metadataStore;\n+    this.metadataStore.init();\n+    this.config = fullJobConfig;\n     // build a JobModelManager and ChangelogStreamManager and perform partition assignments.\n-    changelogStreamManager = new ChangelogStreamManager(new NamespaceAwareCoordinatorStreamStore(coordinatorStreamStore, SetChangelogMapping.TYPE));\n-    jobModelManager =\n-        JobModelManager.apply(config, changelogStreamManager.readPartitionMapping(), coordinatorStreamStore, metrics);\n+    this.changelogStreamManager = new ChangelogStreamManager(\n+        new NamespaceAwareCoordinatorStreamStore(metadataStore, SetChangelogMapping.TYPE));\n+    this.jobModelManager =\n+        JobModelManager.apply(config, changelogStreamManager.readPartitionMapping(), metadataStore, metrics);\n \n-    hasDurableStores = new StorageConfig(config).hasDurableStores();\n-    state = new SamzaApplicationState(jobModelManager);\n+    this.hasDurableStores = new StorageConfig(config).hasDurableStores();\n+    this.state = new SamzaApplicationState(jobModelManager);\n     // The systemAdmins should be started before partitionMonitor can be used. And it should be stopped when this coordinator is stopped.\n-    systemAdmins = new SystemAdmins(config);\n-    partitionMonitor = getPartitionCountMonitor(config, systemAdmins);\n+    this.systemAdmins = new SystemAdmins(config);\n+    this.partitionMonitor = getPartitionCountMonitor(config, systemAdmins);\n \n     Set<SystemStream> inputSystemStreams = JobModelUtil.getSystemStreams(jobModelManager.jobModel());\n-    inputStreamRegexMonitor = getInputRegexMonitor(config, systemAdmins, inputSystemStreams);\n-\n-    clusterManagerConfig = new ClusterManagerConfig(config);\n-    isJmxEnabled = clusterManagerConfig.getJmxEnabledOnJobCoordinator();\n+    this.inputStreamRegexMonitor = getInputRegexMonitor(config, systemAdmins, inputSystemStreams);\n \n-    jobCoordinatorSleepInterval = clusterManagerConfig.getJobCoordinatorSleepInterval();\n+    ClusterManagerConfig clusterManagerConfig = new ClusterManagerConfig(config);\n+    this.isJmxEnabled = clusterManagerConfig.getJmxEnabledOnJobCoordinator();\n+    this.jobCoordinatorSleepInterval = clusterManagerConfig.getJobCoordinatorSleepInterval();\n \n     // build a container process Manager\n-    containerProcessManager = createContainerProcessManager();\n+    this.containerProcessManager = createContainerProcessManager();\n   }\n \n   /**\n", "next_change": null}]}}]}}]}}]}, "revised_code_in_main": {"commit": "5bef72595faa8c8cdc9e35b09342e36a5085c10b", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex 101cda861..d97a4a1e0 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -176,66 +177,38 @@ public class ClusterBasedJobCoordinator {\n   volatile private Exception coordinatorException = null;\n \n   /**\n-   * Creates a new ClusterBasedJobCoordinator instance from a config. Invoke run() to actually\n-   * run the jobcoordinator.\n+   * Creates a new ClusterBasedJobCoordinator instance.\n+   * Invoke run() to actually run the job coordinator.\n    *\n-   * @param coordinatorSystemConfig the coordinator stream config that can be used to read the\n-   *                                {@link org.apache.samza.job.model.JobModel} from.\n+   * @param metrics the registry for reporting metrics.\n+   * @param metadataStore metadata store to hold metadata.\n+   * @param fullJobConfig full job config.\n    */\n-  public ClusterBasedJobCoordinator(Config coordinatorSystemConfig) {\n-    metrics = new MetricsRegistryMap();\n-\n-    JobConfig jobConfig = new JobConfig(coordinatorSystemConfig);\n-\n-    if (jobConfig.getConfigLoaderFactory().isPresent()) {\n-      // load full job config with ConfigLoader\n-      Config originalConfig = ConfigUtil.loadConfig(coordinatorSystemConfig);\n-\n-      // Execute planning\n-      ApplicationDescriptorImpl<? extends ApplicationDescriptor>\n-          appDesc = ApplicationDescriptorUtil.getAppDescriptor(ApplicationUtil.fromConfig(originalConfig), originalConfig);\n-      RemoteJobPlanner planner = new RemoteJobPlanner(appDesc);\n-      List<JobConfig> jobConfigs = planner.prepareJobs();\n-\n-      if (jobConfigs.size() != 1) {\n-        throw new SamzaException(\"Only support single remote job is supported.\");\n-      }\n-\n-      // Merge with default coordinator stream config\n-      config = ConfigUtil.override(jobConfigs.get(0), CoordinatorStreamUtil.buildCoordinatorStreamConfig(jobConfigs.get(0)));\n-\n-      coordinatorStreamStore = new CoordinatorStreamStore(config, metrics);\n-      coordinatorStreamStore.init();\n-      CoordinatorStreamUtil.writeConfigToCoordinatorStream(config, true);\n-      DiagnosticsUtil.createDiagnosticsStream(config);\n-    } else {\n-      // TODO: Clean this up once SAMZA-2405 is completed when legacy flow is removed.\n-      coordinatorStreamStore = new CoordinatorStreamStore(coordinatorSystemConfig, metrics);\n-      coordinatorStreamStore.init();\n-      config = CoordinatorStreamUtil.readConfigFromCoordinatorStream(coordinatorStreamStore);\n-    }\n-\n+  private ClusterBasedJobCoordinator(MetricsRegistryMap metrics, MetadataStore metadataStore, Config fullJobConfig) {\n+    this.metrics = metrics;\n+    this.metadataStore = metadataStore;\n+    this.config = fullJobConfig;\n     // build a JobModelManager and ChangelogStreamManager and perform partition assignments.\n-    changelogStreamManager = new ChangelogStreamManager(new NamespaceAwareCoordinatorStreamStore(coordinatorStreamStore, SetChangelogMapping.TYPE));\n-    jobModelManager =\n-        JobModelManager.apply(config, changelogStreamManager.readPartitionMapping(), coordinatorStreamStore, metrics);\n+    this.changelogStreamManager = new ChangelogStreamManager(\n+        new NamespaceAwareCoordinatorStreamStore(metadataStore, SetChangelogMapping.TYPE));\n+    this.jobModelManager =\n+        JobModelManager.apply(config, changelogStreamManager.readPartitionMapping(), metadataStore, metrics);\n \n-    hasDurableStores = new StorageConfig(config).hasDurableStores();\n-    state = new SamzaApplicationState(jobModelManager);\n+    this.hasDurableStores = new StorageConfig(config).hasDurableStores();\n+    this.state = new SamzaApplicationState(jobModelManager);\n     // The systemAdmins should be started before partitionMonitor can be used. And it should be stopped when this coordinator is stopped.\n-    systemAdmins = new SystemAdmins(config);\n-    partitionMonitor = getPartitionCountMonitor(config, systemAdmins);\n+    this.systemAdmins = new SystemAdmins(config);\n+    this.partitionMonitor = getPartitionCountMonitor(config, systemAdmins);\n \n     Set<SystemStream> inputSystemStreams = JobModelUtil.getSystemStreams(jobModelManager.jobModel());\n-    inputStreamRegexMonitor = getInputRegexMonitor(config, systemAdmins, inputSystemStreams);\n-\n-    clusterManagerConfig = new ClusterManagerConfig(config);\n-    isJmxEnabled = clusterManagerConfig.getJmxEnabledOnJobCoordinator();\n+    this.inputStreamRegexMonitor = getInputRegexMonitor(config, systemAdmins, inputSystemStreams);\n \n-    jobCoordinatorSleepInterval = clusterManagerConfig.getJobCoordinatorSleepInterval();\n+    ClusterManagerConfig clusterManagerConfig = new ClusterManagerConfig(config);\n+    this.isJmxEnabled = clusterManagerConfig.getJmxEnabledOnJobCoordinator();\n+    this.jobCoordinatorSleepInterval = clusterManagerConfig.getJobCoordinatorSleepInterval();\n \n     // build a container process Manager\n-    containerProcessManager = createContainerProcessManager();\n+    this.containerProcessManager = createContainerProcessManager();\n   }\n \n   /**\n", "next_change": {"commit": "b379933d62c8cb438f0599e2540bce6b63e8c014", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex d97a4a1e0..2b9636c8d 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -208,7 +218,13 @@ public class ClusterBasedJobCoordinator {\n     this.jobCoordinatorSleepInterval = clusterManagerConfig.getJobCoordinatorSleepInterval();\n \n     // build a container process Manager\n-    this.containerProcessManager = createContainerProcessManager();\n+    containerProcessManager = createContainerProcessManager();\n+\n+    // build utils related to container placements\n+    containerPlacementMetadataStore = new ContainerPlacementMetadataStore(metadataStore);\n+    containerPlacementRequestAllocator = new ContainerPlacementRequestAllocator(containerPlacementMetadataStore, containerProcessManager);\n+    this.containerPlacementRequestAllocatorThread =\n+        new Thread(containerPlacementRequestAllocator, \"Samza-\" + ContainerPlacementRequestAllocator.class.getSimpleName());\n   }\n \n   /**\n", "next_change": {"commit": "b4a9fe67238d6eb81b2c61177cafd276ade67c07", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex 2b9636c8d..f894bcff5 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -217,12 +218,16 @@ public class ClusterBasedJobCoordinator {\n     this.isJmxEnabled = clusterManagerConfig.getJmxEnabledOnJobCoordinator();\n     this.jobCoordinatorSleepInterval = clusterManagerConfig.getJobCoordinatorSleepInterval();\n \n+    // build metastore for container placement messages\n+    containerPlacementMetadataStore = new ContainerPlacementMetadataStore(metadataStore);\n+\n     // build a container process Manager\n     containerProcessManager = createContainerProcessManager();\n \n     // build utils related to container placements\n-    containerPlacementMetadataStore = new ContainerPlacementMetadataStore(metadataStore);\n-    containerPlacementRequestAllocator = new ContainerPlacementRequestAllocator(containerPlacementMetadataStore, containerProcessManager);\n+    containerPlacementRequestAllocator =\n+        new ContainerPlacementRequestAllocator(containerPlacementMetadataStore, containerProcessManager,\n+            new ApplicationConfig(config));\n     this.containerPlacementRequestAllocatorThread =\n         new Thread(containerPlacementRequestAllocator, \"Samza-\" + ContainerPlacementRequestAllocator.class.getSimpleName());\n   }\n", "next_change": null}]}}]}}]}, "commits_in_main": [{"oid": "5bef72595faa8c8cdc9e35b09342e36a5085c10b", "message": "Merge commit", "committedDate": null}, {"oid": "b379933d62c8cb438f0599e2540bce6b63e8c014", "committedDate": "2020-01-21 15:37:07 -0800", "message": "SAMZA-2404: [SEP-22] Container Placement Handler for dispatching container placement messages between metastore and JobCoordinator (#1227)"}, {"oid": "b4a9fe67238d6eb81b2c61177cafd276ade67c07", "committedDate": "2020-02-18 12:32:05 -0800", "message": "SAMZA-2402: Tie Container placement service and Container placement handler and validate placement requests (#1267)"}, {"oid": "e4eefe2a9b7d6559ee5ce236e5357d773c199816", "committedDate": "2020-03-10 13:20:39 -0700", "message": "SAMZA-2453: Update ClusterBasedJobCoordinator to support Beam jobs (#1309)"}, {"oid": "d6608714c211835c3b04caaaa49882455135158c", "committedDate": "2020-03-11 13:44:21 -0700", "message": "SAMZA-2466: [Scala cleanup] Convert ShellCommandConfig from scala to java (#1288)"}, {"oid": "b7cab952317bd4320f12e18c2cc3e3cee77770da", "committedDate": "2020-03-17 19:20:52 -0700", "message": "SAMZA-2488: Add JobCoordinatorLaunchUtil to handle common logic when launching job coordiantor. (#1318)"}, {"oid": "c527ec5a151e0da570dfdc3896c30694ac7c34f6", "committedDate": "2020-03-27 22:36:05 -0700", "message": "SAMZA-2491: AM should log uncaught exceptions and System.exit to ensure that the process dies on errors (#1325)"}, {"oid": "26d9eecac76f3b87610312d0066d96a5b36eef35", "committedDate": "2020-04-01 16:43:05 -0700", "message": "SAMZA-2501 : Optimizing startpoint manager to not make successive bootstrapMessage calls to coordinator-store (#1335)"}, {"oid": "d745e7d1cbd051002b30bfe99ae924d48ff96eaa", "committedDate": "2020-04-16 13:48:29 -0700", "message": "SAMZA-2509: New config name to represent if split deployment feature is enabled (#1342)"}, {"oid": "e86951f102c7a854d343b1f80dc2796be29c9c81", "committedDate": "2020-04-24 09:40:25 -0700", "message": "SAMZA-2514: Refactor codes to make runWithClassLoader method more generic (#1349)"}, {"oid": "5f05cdde2eea46a8cbda08dd8c9868c8f46a4e9d", "committedDate": "2020-06-22 15:52:51 -0700", "message": "SAMZA-2551: Upgrade all modules to automatically use checkstyle 6.11.2 (part 1: includes samza-core) (#1389)"}, {"oid": "f7f9f3c7905b047f262383bcc64ebb01ab73f421", "committedDate": "2020-08-26 19:39:32 -0700", "message": "SAMZA-2439: Remove LocalityManager and container location information from JobModel (#1421)"}, {"oid": "d689fd2568ea9dd457ed1c7c9cb193f4ae6fa631", "committedDate": "2020-09-02 15:10:42 -0700", "message": "SAMZA-2584: Refactor ClusterBasedJobCoordinator (#1424)"}, {"oid": "42e68e88c4dfe4c891dd601ee98f190d598decfd", "committedDate": "2020-09-15 21:50:40 -0700", "message": "SAMZA-2574 : improve flexibility of SystemFactory interface"}, {"oid": "c212cac420864d09f2663da2e51c23e4718d6812", "committedDate": "2020-11-30 23:37:21 -0800", "message": "SAMZA-2604: Datamodel change to capture physical container id for AM HA (#1445)"}, {"oid": "108768393960a893f9d202edf50bf47d2b1af590", "committedDate": "2020-12-09 09:33:11 -0800", "message": "SAMZA-2610: Handle Metadata changes for AM HA orchestration (#1450)"}, {"oid": "7cc4eaa96fff244f6dce9c18af804917db7c3b2b", "committedDate": "2021-05-25 16:00:46 -0700", "message": "SAMZA-2657: Blob Store as backend for Samza State backup and restore (#1501)"}, {"oid": "120098d6c45ca023d2a0fb144b0e333ab4e8ffe8", "committedDate": "2021-08-24 14:08:17 -0700", "message": "SAMZA-2670: Update granularity of JobCoordinatorMetadataManager.checkForMetadataChanges and epoch id extraction (#1519)"}, {"oid": "27b1495589e992cf1606ebfc2e34699077d60b73", "committedDate": "2021-08-30 14:26:40 -0700", "message": "SAMZA-2672: Extract creation of stream monitors into separate classes for reuse (#1520)"}, {"oid": "493de64bb8c0228bbda11822ae3c84c2085263bf", "committedDate": "2022-06-13 15:06:05 -0700", "message": "SAMZA-2742: [Pipeline Drain] Add Drain components and integrate them with SamzaContainer and JC (#1605)"}]}, {"oid": "a7b0d0f6c7b4be861fef8200040e0d8dbd67d30b", "url": "https://github.com/apache/samza/commit/a7b0d0f6c7b4be861fef8200040e0d8dbd67d30b", "message": "Update ConfigUtil to handle config overrides, update ClusterBasedJobCoordinator not to merge final config with coordinator stream config to keep consistent with before.", "committedDate": "2020-01-11T01:26:34Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTk5MDAwNQ==", "url": "https://github.com/apache/samza/pull/1248#discussion_r365990005", "body": "Is it an exceptional case for ConfigLoaderFactory to not be present here?", "bodyText": "Is it an exceptional case for ConfigLoaderFactory to not be present here?", "bodyHTML": "<p dir=\"auto\">Is it an exceptional case for ConfigLoaderFactory to not be present here?</p>", "author": "bkonold", "createdAt": "2020-01-13T19:37:13Z", "path": "samza-core/src/main/java/org/apache/samza/util/ConfigUtil.java", "diffHunk": "@@ -67,4 +72,42 @@ public static Config applyRewriter(Config config, String rewriterName) {\n     LOG.info(\"Re-writing config with {}\", rewriter);\n     return rewriter.rewrite(rewriterName, config);\n   }\n+\n+  /**\n+   * Load full job config with {@link ConfigLoaderFactory} when present.\n+   *\n+   * @param original config\n+   * @return full job config\n+   */\n+  public static Config loadConfig(Config original) {\n+    JobConfig jobConfig = new JobConfig(original);\n+    Config fullConfig = original;\n+\n+    if (jobConfig.getConfigLoaderFactory().isPresent()) {\n+      ConfigLoaderFactory factory = ReflectionUtil.getObj(jobConfig.getConfigLoaderFactory().get(), ConfigLoaderFactory.class);\n+      ConfigLoader loader = factory.getLoader(original.subset(ConfigLoaderFactory.CONFIG_LOADER_PROPERTIES_PREFIX));\n+      // overrides config loaded with original config, which may contain overridden values.\n+      fullConfig = override(ConfigUtil.rewriteConfig(loader.getConfig()), original);\n+    }", "originalCommit": "a7b0d0f6c7b4be861fef8200040e0d8dbd67d30b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTk5MzE4OQ==", "url": "https://github.com/apache/samza/pull/1248#discussion_r365993189", "bodyText": "Eventually Yes, but during the migration, there will be cases where jobs are still following the legacy submission flow, but still goes to this new method in code.\nFor example, this util will be called by LocalApplicationRunner too, which will first support both legacy and new flow.", "author": "kw2542", "createdAt": "2020-01-13T19:44:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTk5MDAwNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzA1NTQwNw==", "url": "https://github.com/apache/samza/pull/1248#discussion_r367055407", "bodyText": "The method name loadConfig is a bit misleading if it just might return the config that is passed in. If you still prefer to allow this to succeed when ConfigLoaderFactory is not present, then maybe at least rename the method to help clarify what it might do, so that someone doesn't accidentally call it in an unexpected way.", "author": "cameronlee314", "createdAt": "2020-01-15T19:10:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTk5MDAwNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA3MDAyMQ==", "url": "https://github.com/apache/samza/pull/1248#discussion_r368070021", "bodyText": "Is there something you can do to clarify that this may not actually load any additional configs?", "author": "cameronlee314", "createdAt": "2020-01-17T18:16:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTk5MDAwNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA3Njc2NQ==", "url": "https://github.com/apache/samza/pull/1248#discussion_r368076765", "bodyText": "Updated to disallow the case when ConfigLoaderFactory is not present.", "author": "kw2542", "createdAt": "2020-01-17T18:33:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTk5MDAwNQ=="}], "type": "inlineReview", "revised_code": {"commit": "a90387a1a7c89abf58ad84875dade3f9fe2e5361", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/util/ConfigUtil.java b/samza-core/src/main/java/org/apache/samza/util/ConfigUtil.java\nindex a3cc3fa1e..86a5f52b5 100644\n--- a/samza-core/src/main/java/org/apache/samza/util/ConfigUtil.java\n+++ b/samza-core/src/main/java/org/apache/samza/util/ConfigUtil.java\n", "chunk": "@@ -87,7 +87,7 @@ public class ConfigUtil {\n       ConfigLoaderFactory factory = ReflectionUtil.getObj(jobConfig.getConfigLoaderFactory().get(), ConfigLoaderFactory.class);\n       ConfigLoader loader = factory.getLoader(original.subset(ConfigLoaderFactory.CONFIG_LOADER_PROPERTIES_PREFIX));\n       // overrides config loaded with original config, which may contain overridden values.\n-      fullConfig = override(ConfigUtil.rewriteConfig(loader.getConfig()), original);\n+      fullConfig = ConfigUtil.rewriteConfig(override(loader.getConfig(), original));\n     }\n \n     return fullConfig;\n", "next_change": {"commit": "27210d8aa49b6497400604aab47d722563ff59b4", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/util/ConfigUtil.java b/samza-core/src/main/java/org/apache/samza/util/ConfigUtil.java\nindex 86a5f52b5..7206fe284 100644\n--- a/samza-core/src/main/java/org/apache/samza/util/ConfigUtil.java\n+++ b/samza-core/src/main/java/org/apache/samza/util/ConfigUtil.java\n", "chunk": "@@ -81,16 +82,15 @@ public class ConfigUtil {\n    */\n   public static Config loadConfig(Config original) {\n     JobConfig jobConfig = new JobConfig(original);\n-    Config fullConfig = original;\n \n-    if (jobConfig.getConfigLoaderFactory().isPresent()) {\n-      ConfigLoaderFactory factory = ReflectionUtil.getObj(jobConfig.getConfigLoaderFactory().get(), ConfigLoaderFactory.class);\n-      ConfigLoader loader = factory.getLoader(original.subset(ConfigLoaderFactory.CONFIG_LOADER_PROPERTIES_PREFIX));\n-      // overrides config loaded with original config, which may contain overridden values.\n-      fullConfig = ConfigUtil.rewriteConfig(override(loader.getConfig(), original));\n+    if (!jobConfig.getConfigLoaderFactory().isPresent()) {\n+      throw new ConfigException(\"Missing key \" + JobConfig.CONFIG_LOADER_FACTORY + \".\");\n     }\n \n-    return fullConfig;\n+    ConfigLoaderFactory factory = ReflectionUtil.getObj(jobConfig.getConfigLoaderFactory().get(), ConfigLoaderFactory.class);\n+    ConfigLoader loader = factory.getLoader(original.subset(ConfigLoaderFactory.CONFIG_LOADER_PROPERTIES_PREFIX));\n+    // overrides config loaded with original config, which may contain overridden values.\n+    return rewriteConfig(override(loader.getConfig(), original));\n   }\n \n   /**\n", "next_change": null}]}}]}, "revised_code_in_main": {"commit": "5bef72595faa8c8cdc9e35b09342e36a5085c10b", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/util/ConfigUtil.java b/samza-core/src/main/java/org/apache/samza/util/ConfigUtil.java\nindex a3cc3fa1e..7206fe284 100644\n--- a/samza-core/src/main/java/org/apache/samza/util/ConfigUtil.java\n+++ b/samza-core/src/main/java/org/apache/samza/util/ConfigUtil.java\n", "chunk": "@@ -81,16 +82,15 @@ public class ConfigUtil {\n    */\n   public static Config loadConfig(Config original) {\n     JobConfig jobConfig = new JobConfig(original);\n-    Config fullConfig = original;\n \n-    if (jobConfig.getConfigLoaderFactory().isPresent()) {\n-      ConfigLoaderFactory factory = ReflectionUtil.getObj(jobConfig.getConfigLoaderFactory().get(), ConfigLoaderFactory.class);\n-      ConfigLoader loader = factory.getLoader(original.subset(ConfigLoaderFactory.CONFIG_LOADER_PROPERTIES_PREFIX));\n-      // overrides config loaded with original config, which may contain overridden values.\n-      fullConfig = override(ConfigUtil.rewriteConfig(loader.getConfig()), original);\n+    if (!jobConfig.getConfigLoaderFactory().isPresent()) {\n+      throw new ConfigException(\"Missing key \" + JobConfig.CONFIG_LOADER_FACTORY + \".\");\n     }\n \n-    return fullConfig;\n+    ConfigLoaderFactory factory = ReflectionUtil.getObj(jobConfig.getConfigLoaderFactory().get(), ConfigLoaderFactory.class);\n+    ConfigLoader loader = factory.getLoader(original.subset(ConfigLoaderFactory.CONFIG_LOADER_PROPERTIES_PREFIX));\n+    // overrides config loaded with original config, which may contain overridden values.\n+    return rewriteConfig(override(loader.getConfig(), original));\n   }\n \n   /**\n", "next_change": null}]}, "commits_in_main": [{"oid": "5bef72595faa8c8cdc9e35b09342e36a5085c10b", "message": "Merge commit", "committedDate": null}]}, {"oid": "86032a6feaa1e25db3e18e18a1dd1f019ec473b7", "url": "https://github.com/apache/samza/commit/86032a6feaa1e25db3e18e18a1dd1f019ec473b7", "message": "Add ticket for clean up", "committedDate": "2020-01-14T20:31:11Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYxMDAwNA==", "url": "https://github.com/apache/samza/pull/1248#discussion_r366610004", "body": "Should we rename this to something more general now that it won't always be just the coordinator system configs?", "bodyText": "Should we rename this to something more general now that it won't always be just the coordinator system configs?", "bodyHTML": "<p dir=\"auto\">Should we rename this to something more general now that it won't always be just the coordinator system configs?</p>", "author": "bkonold", "createdAt": "2020-01-14T22:37:53Z", "path": "samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java", "diffHunk": "@@ -178,9 +185,33 @@\n   public ClusterBasedJobCoordinator(Config coordinatorSystemConfig) {", "originalCommit": "86032a6feaa1e25db3e18e18a1dd1f019ec473b7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYxMDc3OA==", "url": "https://github.com/apache/samza/pull/1248#discussion_r366610778", "bodyText": "I was planning to rename this variable when cleaning up the legacy flow, but we can choose a generic name in the mid now as well, what do you think?", "author": "kw2542", "createdAt": "2020-01-14T22:39:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYxMDAwNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYxNDIwMA==", "url": "https://github.com/apache/samza/pull/1248#discussion_r366614200", "bodyText": "I think changing it now would be less misleading in the interim. \"jobCoordinatorConfig\"?", "author": "bkonold", "createdAt": "2020-01-14T22:49:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYxMDAwNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYyNDg4Mw==", "url": "https://github.com/apache/samza/pull/1248#discussion_r366624883", "bodyText": "Renamed to jobCoordinatorConfig and updated the javadoc as well.", "author": "kw2542", "createdAt": "2020-01-14T23:21:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjYxMDAwNA=="}], "type": "inlineReview", "revised_code": {"commit": "c234721851151e9c1c3d192d98b518b59abbba2b", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex cb51ab666..da4a9c81f 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -179,17 +179,17 @@ public class ClusterBasedJobCoordinator {\n    * Creates a new ClusterBasedJobCoordinator instance from a config. Invoke run() to actually\n    * run the jobcoordinator.\n    *\n-   * @param coordinatorSystemConfig the coordinator stream config that can be used to read the\n-   *                                {@link org.apache.samza.job.model.JobModel} from.\n+   * @param jobCoordinatorConfig job coordinator config that either contains coordinator stream properties\n+   *                             or config loader properties to load full job config.\n    */\n-  public ClusterBasedJobCoordinator(Config coordinatorSystemConfig) {\n+  public ClusterBasedJobCoordinator(Config jobCoordinatorConfig) {\n     metrics = new MetricsRegistryMap();\n \n-    JobConfig jobConfig = new JobConfig(coordinatorSystemConfig);\n+    JobConfig jobConfig = new JobConfig(jobCoordinatorConfig);\n \n     if (jobConfig.getConfigLoaderFactory().isPresent()) {\n       // load full job config with ConfigLoader\n-      Config originalConfig = ConfigUtil.loadConfig(coordinatorSystemConfig);\n+      Config originalConfig = ConfigUtil.loadConfig(jobCoordinatorConfig);\n \n       // Execute planning\n       ApplicationDescriptorImpl<? extends ApplicationDescriptor>\n", "next_change": {"commit": "c004a97d60e9bff9e5a39328ec9153c014174232", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex da4a9c81f..d22e694d7 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -176,64 +176,39 @@ public class ClusterBasedJobCoordinator {\n   volatile private Exception coordinatorException = null;\n \n   /**\n-   * Creates a new ClusterBasedJobCoordinator instance from a config. Invoke run() to actually\n-   * run the jobcoordinator.\n+   * Creates a new ClusterBasedJobCoordinator instance.\n+   * Invoke run() to actually run the job coordinator.\n    *\n-   * @param jobCoordinatorConfig job coordinator config that either contains coordinator stream properties\n-   *                             or config loader properties to load full job config.\n+   * @param metrics the registry for reporting metrics.\n+   * @param metadataStore metadata store to hold metadata.\n+   * @param fullJobConfig full job config.\n    */\n-  public ClusterBasedJobCoordinator(Config jobCoordinatorConfig) {\n-    metrics = new MetricsRegistryMap();\n-\n-    JobConfig jobConfig = new JobConfig(jobCoordinatorConfig);\n-\n-    if (jobConfig.getConfigLoaderFactory().isPresent()) {\n-      // load full job config with ConfigLoader\n-      Config originalConfig = ConfigUtil.loadConfig(jobCoordinatorConfig);\n-\n-      // Execute planning\n-      ApplicationDescriptorImpl<? extends ApplicationDescriptor>\n-          appDesc = ApplicationDescriptorUtil.getAppDescriptor(ApplicationUtil.fromConfig(originalConfig), originalConfig);\n-      RemoteJobPlanner planner = new RemoteJobPlanner(appDesc);\n-      List<JobConfig> jobConfigs = planner.prepareJobs();\n-\n-      if (jobConfigs.size() != 1) {\n-        throw new SamzaException(\"Only support single remote job is supported.\");\n-      }\n-\n-      config = jobConfigs.get(0);\n-      coordinatorStreamStore = new CoordinatorStreamStore(CoordinatorStreamUtil.buildCoordinatorStreamConfig(config), metrics);\n-      coordinatorStreamStore.init();\n-      CoordinatorStreamUtil.writeConfigToCoordinatorStream(config, true);\n-      DiagnosticsUtil.createDiagnosticsStream(config);\n-    } else {\n-      // TODO SAMZA-2432: Clean this up once SAMZA-2405 is completed when legacy flow is removed.\n-      coordinatorStreamStore = new CoordinatorStreamStore(jobCoordinatorConfig, metrics);\n-      coordinatorStreamStore.init();\n-      config = CoordinatorStreamUtil.readConfigFromCoordinatorStream(coordinatorStreamStore);\n-    }\n-\n+  private ClusterBasedJobCoordinator(MetricsRegistryMap metrics, MetadataStore metadataStore, Config fullJobConfig) {\n+    this.metrics = metrics;\n+    this.metadataStore = metadataStore;\n+    this.metadataStore.init();\n+    this.config = fullJobConfig;\n     // build a JobModelManager and ChangelogStreamManager and perform partition assignments.\n-    changelogStreamManager = new ChangelogStreamManager(new NamespaceAwareCoordinatorStreamStore(coordinatorStreamStore, SetChangelogMapping.TYPE));\n-    jobModelManager =\n-        JobModelManager.apply(config, changelogStreamManager.readPartitionMapping(), coordinatorStreamStore, metrics);\n+    this.changelogStreamManager = new ChangelogStreamManager(\n+        new NamespaceAwareCoordinatorStreamStore(metadataStore, SetChangelogMapping.TYPE));\n+    this.jobModelManager =\n+        JobModelManager.apply(config, changelogStreamManager.readPartitionMapping(), metadataStore, metrics);\n \n-    hasDurableStores = new StorageConfig(config).hasDurableStores();\n-    state = new SamzaApplicationState(jobModelManager);\n+    this.hasDurableStores = new StorageConfig(config).hasDurableStores();\n+    this.state = new SamzaApplicationState(jobModelManager);\n     // The systemAdmins should be started before partitionMonitor can be used. And it should be stopped when this coordinator is stopped.\n-    systemAdmins = new SystemAdmins(config);\n-    partitionMonitor = getPartitionCountMonitor(config, systemAdmins);\n+    this.systemAdmins = new SystemAdmins(config);\n+    this.partitionMonitor = getPartitionCountMonitor(config, systemAdmins);\n \n     Set<SystemStream> inputSystemStreams = JobModelUtil.getSystemStreams(jobModelManager.jobModel());\n-    inputStreamRegexMonitor = getInputRegexMonitor(config, systemAdmins, inputSystemStreams);\n-\n-    clusterManagerConfig = new ClusterManagerConfig(config);\n-    isJmxEnabled = clusterManagerConfig.getJmxEnabledOnJobCoordinator();\n+    this.inputStreamRegexMonitor = getInputRegexMonitor(config, systemAdmins, inputSystemStreams);\n \n-    jobCoordinatorSleepInterval = clusterManagerConfig.getJobCoordinatorSleepInterval();\n+    ClusterManagerConfig clusterManagerConfig = new ClusterManagerConfig(config);\n+    this.isJmxEnabled = clusterManagerConfig.getJmxEnabledOnJobCoordinator();\n+    this.jobCoordinatorSleepInterval = clusterManagerConfig.getJobCoordinatorSleepInterval();\n \n     // build a container process Manager\n-    containerProcessManager = createContainerProcessManager();\n+    this.containerProcessManager = createContainerProcessManager();\n   }\n \n   /**\n", "next_change": null}]}}]}, "revised_code_in_main": {"commit": "5bef72595faa8c8cdc9e35b09342e36a5085c10b", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex cb51ab666..d97a4a1e0 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -176,64 +177,38 @@ public class ClusterBasedJobCoordinator {\n   volatile private Exception coordinatorException = null;\n \n   /**\n-   * Creates a new ClusterBasedJobCoordinator instance from a config. Invoke run() to actually\n-   * run the jobcoordinator.\n+   * Creates a new ClusterBasedJobCoordinator instance.\n+   * Invoke run() to actually run the job coordinator.\n    *\n-   * @param coordinatorSystemConfig the coordinator stream config that can be used to read the\n-   *                                {@link org.apache.samza.job.model.JobModel} from.\n+   * @param metrics the registry for reporting metrics.\n+   * @param metadataStore metadata store to hold metadata.\n+   * @param fullJobConfig full job config.\n    */\n-  public ClusterBasedJobCoordinator(Config coordinatorSystemConfig) {\n-    metrics = new MetricsRegistryMap();\n-\n-    JobConfig jobConfig = new JobConfig(coordinatorSystemConfig);\n-\n-    if (jobConfig.getConfigLoaderFactory().isPresent()) {\n-      // load full job config with ConfigLoader\n-      Config originalConfig = ConfigUtil.loadConfig(coordinatorSystemConfig);\n-\n-      // Execute planning\n-      ApplicationDescriptorImpl<? extends ApplicationDescriptor>\n-          appDesc = ApplicationDescriptorUtil.getAppDescriptor(ApplicationUtil.fromConfig(originalConfig), originalConfig);\n-      RemoteJobPlanner planner = new RemoteJobPlanner(appDesc);\n-      List<JobConfig> jobConfigs = planner.prepareJobs();\n-\n-      if (jobConfigs.size() != 1) {\n-        throw new SamzaException(\"Only support single remote job is supported.\");\n-      }\n-\n-      config = jobConfigs.get(0);\n-      coordinatorStreamStore = new CoordinatorStreamStore(CoordinatorStreamUtil.buildCoordinatorStreamConfig(config), metrics);\n-      coordinatorStreamStore.init();\n-      CoordinatorStreamUtil.writeConfigToCoordinatorStream(config, true);\n-      DiagnosticsUtil.createDiagnosticsStream(config);\n-    } else {\n-      // TODO SAMZA-2432: Clean this up once SAMZA-2405 is completed when legacy flow is removed.\n-      coordinatorStreamStore = new CoordinatorStreamStore(coordinatorSystemConfig, metrics);\n-      coordinatorStreamStore.init();\n-      config = CoordinatorStreamUtil.readConfigFromCoordinatorStream(coordinatorStreamStore);\n-    }\n-\n+  private ClusterBasedJobCoordinator(MetricsRegistryMap metrics, MetadataStore metadataStore, Config fullJobConfig) {\n+    this.metrics = metrics;\n+    this.metadataStore = metadataStore;\n+    this.config = fullJobConfig;\n     // build a JobModelManager and ChangelogStreamManager and perform partition assignments.\n-    changelogStreamManager = new ChangelogStreamManager(new NamespaceAwareCoordinatorStreamStore(coordinatorStreamStore, SetChangelogMapping.TYPE));\n-    jobModelManager =\n-        JobModelManager.apply(config, changelogStreamManager.readPartitionMapping(), coordinatorStreamStore, metrics);\n+    this.changelogStreamManager = new ChangelogStreamManager(\n+        new NamespaceAwareCoordinatorStreamStore(metadataStore, SetChangelogMapping.TYPE));\n+    this.jobModelManager =\n+        JobModelManager.apply(config, changelogStreamManager.readPartitionMapping(), metadataStore, metrics);\n \n-    hasDurableStores = new StorageConfig(config).hasDurableStores();\n-    state = new SamzaApplicationState(jobModelManager);\n+    this.hasDurableStores = new StorageConfig(config).hasDurableStores();\n+    this.state = new SamzaApplicationState(jobModelManager);\n     // The systemAdmins should be started before partitionMonitor can be used. And it should be stopped when this coordinator is stopped.\n-    systemAdmins = new SystemAdmins(config);\n-    partitionMonitor = getPartitionCountMonitor(config, systemAdmins);\n+    this.systemAdmins = new SystemAdmins(config);\n+    this.partitionMonitor = getPartitionCountMonitor(config, systemAdmins);\n \n     Set<SystemStream> inputSystemStreams = JobModelUtil.getSystemStreams(jobModelManager.jobModel());\n-    inputStreamRegexMonitor = getInputRegexMonitor(config, systemAdmins, inputSystemStreams);\n+    this.inputStreamRegexMonitor = getInputRegexMonitor(config, systemAdmins, inputSystemStreams);\n \n-    clusterManagerConfig = new ClusterManagerConfig(config);\n-    isJmxEnabled = clusterManagerConfig.getJmxEnabledOnJobCoordinator();\n-\n-    jobCoordinatorSleepInterval = clusterManagerConfig.getJobCoordinatorSleepInterval();\n+    ClusterManagerConfig clusterManagerConfig = new ClusterManagerConfig(config);\n+    this.isJmxEnabled = clusterManagerConfig.getJmxEnabledOnJobCoordinator();\n+    this.jobCoordinatorSleepInterval = clusterManagerConfig.getJobCoordinatorSleepInterval();\n \n     // build a container process Manager\n-    containerProcessManager = createContainerProcessManager();\n+    this.containerProcessManager = createContainerProcessManager();\n   }\n \n   /**\n", "next_change": {"commit": "b379933d62c8cb438f0599e2540bce6b63e8c014", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex d97a4a1e0..2b9636c8d 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -208,7 +218,13 @@ public class ClusterBasedJobCoordinator {\n     this.jobCoordinatorSleepInterval = clusterManagerConfig.getJobCoordinatorSleepInterval();\n \n     // build a container process Manager\n-    this.containerProcessManager = createContainerProcessManager();\n+    containerProcessManager = createContainerProcessManager();\n+\n+    // build utils related to container placements\n+    containerPlacementMetadataStore = new ContainerPlacementMetadataStore(metadataStore);\n+    containerPlacementRequestAllocator = new ContainerPlacementRequestAllocator(containerPlacementMetadataStore, containerProcessManager);\n+    this.containerPlacementRequestAllocatorThread =\n+        new Thread(containerPlacementRequestAllocator, \"Samza-\" + ContainerPlacementRequestAllocator.class.getSimpleName());\n   }\n \n   /**\n", "next_change": {"commit": "b4a9fe67238d6eb81b2c61177cafd276ade67c07", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex 2b9636c8d..f894bcff5 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -217,12 +218,16 @@ public class ClusterBasedJobCoordinator {\n     this.isJmxEnabled = clusterManagerConfig.getJmxEnabledOnJobCoordinator();\n     this.jobCoordinatorSleepInterval = clusterManagerConfig.getJobCoordinatorSleepInterval();\n \n+    // build metastore for container placement messages\n+    containerPlacementMetadataStore = new ContainerPlacementMetadataStore(metadataStore);\n+\n     // build a container process Manager\n     containerProcessManager = createContainerProcessManager();\n \n     // build utils related to container placements\n-    containerPlacementMetadataStore = new ContainerPlacementMetadataStore(metadataStore);\n-    containerPlacementRequestAllocator = new ContainerPlacementRequestAllocator(containerPlacementMetadataStore, containerProcessManager);\n+    containerPlacementRequestAllocator =\n+        new ContainerPlacementRequestAllocator(containerPlacementMetadataStore, containerProcessManager,\n+            new ApplicationConfig(config));\n     this.containerPlacementRequestAllocatorThread =\n         new Thread(containerPlacementRequestAllocator, \"Samza-\" + ContainerPlacementRequestAllocator.class.getSimpleName());\n   }\n", "next_change": null}]}}]}}]}, "commits_in_main": [{"oid": "5bef72595faa8c8cdc9e35b09342e36a5085c10b", "message": "Merge commit", "committedDate": null}, {"oid": "b379933d62c8cb438f0599e2540bce6b63e8c014", "committedDate": "2020-01-21 15:37:07 -0800", "message": "SAMZA-2404: [SEP-22] Container Placement Handler for dispatching container placement messages between metastore and JobCoordinator (#1227)"}, {"oid": "b4a9fe67238d6eb81b2c61177cafd276ade67c07", "committedDate": "2020-02-18 12:32:05 -0800", "message": "SAMZA-2402: Tie Container placement service and Container placement handler and validate placement requests (#1267)"}, {"oid": "e4eefe2a9b7d6559ee5ce236e5357d773c199816", "committedDate": "2020-03-10 13:20:39 -0700", "message": "SAMZA-2453: Update ClusterBasedJobCoordinator to support Beam jobs (#1309)"}, {"oid": "d6608714c211835c3b04caaaa49882455135158c", "committedDate": "2020-03-11 13:44:21 -0700", "message": "SAMZA-2466: [Scala cleanup] Convert ShellCommandConfig from scala to java (#1288)"}, {"oid": "b7cab952317bd4320f12e18c2cc3e3cee77770da", "committedDate": "2020-03-17 19:20:52 -0700", "message": "SAMZA-2488: Add JobCoordinatorLaunchUtil to handle common logic when launching job coordiantor. (#1318)"}, {"oid": "c527ec5a151e0da570dfdc3896c30694ac7c34f6", "committedDate": "2020-03-27 22:36:05 -0700", "message": "SAMZA-2491: AM should log uncaught exceptions and System.exit to ensure that the process dies on errors (#1325)"}, {"oid": "26d9eecac76f3b87610312d0066d96a5b36eef35", "committedDate": "2020-04-01 16:43:05 -0700", "message": "SAMZA-2501 : Optimizing startpoint manager to not make successive bootstrapMessage calls to coordinator-store (#1335)"}, {"oid": "d745e7d1cbd051002b30bfe99ae924d48ff96eaa", "committedDate": "2020-04-16 13:48:29 -0700", "message": "SAMZA-2509: New config name to represent if split deployment feature is enabled (#1342)"}, {"oid": "e86951f102c7a854d343b1f80dc2796be29c9c81", "committedDate": "2020-04-24 09:40:25 -0700", "message": "SAMZA-2514: Refactor codes to make runWithClassLoader method more generic (#1349)"}, {"oid": "5f05cdde2eea46a8cbda08dd8c9868c8f46a4e9d", "committedDate": "2020-06-22 15:52:51 -0700", "message": "SAMZA-2551: Upgrade all modules to automatically use checkstyle 6.11.2 (part 1: includes samza-core) (#1389)"}, {"oid": "f7f9f3c7905b047f262383bcc64ebb01ab73f421", "committedDate": "2020-08-26 19:39:32 -0700", "message": "SAMZA-2439: Remove LocalityManager and container location information from JobModel (#1421)"}, {"oid": "d689fd2568ea9dd457ed1c7c9cb193f4ae6fa631", "committedDate": "2020-09-02 15:10:42 -0700", "message": "SAMZA-2584: Refactor ClusterBasedJobCoordinator (#1424)"}, {"oid": "42e68e88c4dfe4c891dd601ee98f190d598decfd", "committedDate": "2020-09-15 21:50:40 -0700", "message": "SAMZA-2574 : improve flexibility of SystemFactory interface"}, {"oid": "c212cac420864d09f2663da2e51c23e4718d6812", "committedDate": "2020-11-30 23:37:21 -0800", "message": "SAMZA-2604: Datamodel change to capture physical container id for AM HA (#1445)"}, {"oid": "108768393960a893f9d202edf50bf47d2b1af590", "committedDate": "2020-12-09 09:33:11 -0800", "message": "SAMZA-2610: Handle Metadata changes for AM HA orchestration (#1450)"}, {"oid": "7cc4eaa96fff244f6dce9c18af804917db7c3b2b", "committedDate": "2021-05-25 16:00:46 -0700", "message": "SAMZA-2657: Blob Store as backend for Samza State backup and restore (#1501)"}, {"oid": "120098d6c45ca023d2a0fb144b0e333ab4e8ffe8", "committedDate": "2021-08-24 14:08:17 -0700", "message": "SAMZA-2670: Update granularity of JobCoordinatorMetadataManager.checkForMetadataChanges and epoch id extraction (#1519)"}, {"oid": "27b1495589e992cf1606ebfc2e34699077d60b73", "committedDate": "2021-08-30 14:26:40 -0700", "message": "SAMZA-2672: Extract creation of stream monitors into separate classes for reuse (#1520)"}, {"oid": "493de64bb8c0228bbda11822ae3c84c2085263bf", "committedDate": "2022-06-13 15:06:05 -0700", "message": "SAMZA-2742: [Pipeline Drain] Add Drain components and integrate them with SamzaContainer and JC (#1605)"}]}, {"oid": "c234721851151e9c1c3d192d98b518b59abbba2b", "url": "https://github.com/apache/samza/commit/c234721851151e9c1c3d192d98b518b59abbba2b", "message": "Rename coordinatorSystemConfig to jobCoordinatorConfig to be more generic as it may contain config loader properties instead.", "committedDate": "2020-01-14T23:21:35Z", "type": "commit"}, {"oid": "5d381c46c2b7e55631d744e835feed934f63c27d", "url": "https://github.com/apache/samza/commit/5d381c46c2b7e55631d744e835feed934f63c27d", "message": "Merge branch 'master' of https://github.com/apache/samza into SAMZA-2410", "committedDate": "2020-01-15T00:36:15Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzA0Mzc0Mg==", "url": "https://github.com/apache/samza/pull/1248#discussion_r367043742", "body": "Does this need to match the set-up done in `JobRunner.run`? Maybe it would be good to put a comment in here and in `JobRunner` to make sure they are consistent. I know it will be cleaned up eventually, but there will be some time in which both flows exist.", "bodyText": "Does this need to match the set-up done in JobRunner.run? Maybe it would be good to put a comment in here and in JobRunner to make sure they are consistent. I know it will be cleaned up eventually, but there will be some time in which both flows exist.", "bodyHTML": "<p dir=\"auto\">Does this need to match the set-up done in <code>JobRunner.run</code>? Maybe it would be good to put a comment in here and in <code>JobRunner</code> to make sure they are consistent. I know it will be cleaned up eventually, but there will be some time in which both flows exist.</p>", "author": "cameronlee314", "createdAt": "2020-01-15T18:44:45Z", "path": "samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java", "diffHunk": "@@ -172,15 +179,39 @@\n    * Creates a new ClusterBasedJobCoordinator instance from a config. Invoke run() to actually\n    * run the jobcoordinator.\n    *\n-   * @param coordinatorSystemConfig the coordinator stream config that can be used to read the\n-   *                                {@link org.apache.samza.job.model.JobModel} from.\n+   * @param jobCoordinatorConfig job coordinator config that either contains coordinator stream properties\n+   *                             or config loader properties to load full job config.\n    */\n-  public ClusterBasedJobCoordinator(Config coordinatorSystemConfig) {\n+  public ClusterBasedJobCoordinator(Config jobCoordinatorConfig) {\n     metrics = new MetricsRegistryMap();\n \n-    coordinatorStreamStore = new CoordinatorStreamStore(coordinatorSystemConfig, metrics);\n-    coordinatorStreamStore.init();\n-    config = CoordinatorStreamUtil.readConfigFromCoordinatorStream(coordinatorStreamStore);\n+    JobConfig jobConfig = new JobConfig(jobCoordinatorConfig);\n+\n+    if (jobConfig.getConfigLoaderFactory().isPresent()) {\n+      // load full job config with ConfigLoader\n+      Config originalConfig = ConfigUtil.loadConfig(jobCoordinatorConfig);\n+\n+      // Execute planning\n+      ApplicationDescriptorImpl<? extends ApplicationDescriptor>\n+          appDesc = ApplicationDescriptorUtil.getAppDescriptor(ApplicationUtil.fromConfig(originalConfig), originalConfig);\n+      RemoteJobPlanner planner = new RemoteJobPlanner(appDesc);\n+      List<JobConfig> jobConfigs = planner.prepareJobs();\n+\n+      if (jobConfigs.size() != 1) {\n+        throw new SamzaException(\"Only support single remote job is supported.\");\n+      }\n+\n+      config = jobConfigs.get(0);\n+      coordinatorStreamStore = new CoordinatorStreamStore(CoordinatorStreamUtil.buildCoordinatorStreamConfig(config), metrics);\n+      coordinatorStreamStore.init();\n+      CoordinatorStreamUtil.writeConfigToCoordinatorStream(config, true);\n+      DiagnosticsUtil.createDiagnosticsStream(config);", "originalCommit": "5d381c46c2b7e55631d744e835feed934f63c27d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzEzODMwOA==", "url": "https://github.com/apache/samza/pull/1248#discussion_r367138308", "bodyText": "Added a comment", "author": "kw2542", "createdAt": "2020-01-15T22:21:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzA0Mzc0Mg=="}], "type": "inlineReview", "revised_code": {"commit": "a90387a1a7c89abf58ad84875dade3f9fe2e5361", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex da4a9c81f..28e1cdbe8 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -204,6 +204,8 @@ public class ClusterBasedJobCoordinator {\n       config = jobConfigs.get(0);\n       coordinatorStreamStore = new CoordinatorStreamStore(CoordinatorStreamUtil.buildCoordinatorStreamConfig(config), metrics);\n       coordinatorStreamStore.init();\n+\n+      // This needs to be consistent with RemoteApplicationRunner#run where JobRunner#submit to be called instead of JobRunner#run\n       CoordinatorStreamUtil.writeConfigToCoordinatorStream(config, true);\n       DiagnosticsUtil.createDiagnosticsStream(config);\n     } else {\n", "next_change": {"commit": "c004a97d60e9bff9e5a39328ec9153c014174232", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex 28e1cdbe8..d22e694d7 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -176,66 +176,39 @@ public class ClusterBasedJobCoordinator {\n   volatile private Exception coordinatorException = null;\n \n   /**\n-   * Creates a new ClusterBasedJobCoordinator instance from a config. Invoke run() to actually\n-   * run the jobcoordinator.\n+   * Creates a new ClusterBasedJobCoordinator instance.\n+   * Invoke run() to actually run the job coordinator.\n    *\n-   * @param jobCoordinatorConfig job coordinator config that either contains coordinator stream properties\n-   *                             or config loader properties to load full job config.\n+   * @param metrics the registry for reporting metrics.\n+   * @param metadataStore metadata store to hold metadata.\n+   * @param fullJobConfig full job config.\n    */\n-  public ClusterBasedJobCoordinator(Config jobCoordinatorConfig) {\n-    metrics = new MetricsRegistryMap();\n-\n-    JobConfig jobConfig = new JobConfig(jobCoordinatorConfig);\n-\n-    if (jobConfig.getConfigLoaderFactory().isPresent()) {\n-      // load full job config with ConfigLoader\n-      Config originalConfig = ConfigUtil.loadConfig(jobCoordinatorConfig);\n-\n-      // Execute planning\n-      ApplicationDescriptorImpl<? extends ApplicationDescriptor>\n-          appDesc = ApplicationDescriptorUtil.getAppDescriptor(ApplicationUtil.fromConfig(originalConfig), originalConfig);\n-      RemoteJobPlanner planner = new RemoteJobPlanner(appDesc);\n-      List<JobConfig> jobConfigs = planner.prepareJobs();\n-\n-      if (jobConfigs.size() != 1) {\n-        throw new SamzaException(\"Only support single remote job is supported.\");\n-      }\n-\n-      config = jobConfigs.get(0);\n-      coordinatorStreamStore = new CoordinatorStreamStore(CoordinatorStreamUtil.buildCoordinatorStreamConfig(config), metrics);\n-      coordinatorStreamStore.init();\n-\n-      // This needs to be consistent with RemoteApplicationRunner#run where JobRunner#submit to be called instead of JobRunner#run\n-      CoordinatorStreamUtil.writeConfigToCoordinatorStream(config, true);\n-      DiagnosticsUtil.createDiagnosticsStream(config);\n-    } else {\n-      // TODO SAMZA-2432: Clean this up once SAMZA-2405 is completed when legacy flow is removed.\n-      coordinatorStreamStore = new CoordinatorStreamStore(jobCoordinatorConfig, metrics);\n-      coordinatorStreamStore.init();\n-      config = CoordinatorStreamUtil.readConfigFromCoordinatorStream(coordinatorStreamStore);\n-    }\n-\n+  private ClusterBasedJobCoordinator(MetricsRegistryMap metrics, MetadataStore metadataStore, Config fullJobConfig) {\n+    this.metrics = metrics;\n+    this.metadataStore = metadataStore;\n+    this.metadataStore.init();\n+    this.config = fullJobConfig;\n     // build a JobModelManager and ChangelogStreamManager and perform partition assignments.\n-    changelogStreamManager = new ChangelogStreamManager(new NamespaceAwareCoordinatorStreamStore(coordinatorStreamStore, SetChangelogMapping.TYPE));\n-    jobModelManager =\n-        JobModelManager.apply(config, changelogStreamManager.readPartitionMapping(), coordinatorStreamStore, metrics);\n+    this.changelogStreamManager = new ChangelogStreamManager(\n+        new NamespaceAwareCoordinatorStreamStore(metadataStore, SetChangelogMapping.TYPE));\n+    this.jobModelManager =\n+        JobModelManager.apply(config, changelogStreamManager.readPartitionMapping(), metadataStore, metrics);\n \n-    hasDurableStores = new StorageConfig(config).hasDurableStores();\n-    state = new SamzaApplicationState(jobModelManager);\n+    this.hasDurableStores = new StorageConfig(config).hasDurableStores();\n+    this.state = new SamzaApplicationState(jobModelManager);\n     // The systemAdmins should be started before partitionMonitor can be used. And it should be stopped when this coordinator is stopped.\n-    systemAdmins = new SystemAdmins(config);\n-    partitionMonitor = getPartitionCountMonitor(config, systemAdmins);\n+    this.systemAdmins = new SystemAdmins(config);\n+    this.partitionMonitor = getPartitionCountMonitor(config, systemAdmins);\n \n     Set<SystemStream> inputSystemStreams = JobModelUtil.getSystemStreams(jobModelManager.jobModel());\n-    inputStreamRegexMonitor = getInputRegexMonitor(config, systemAdmins, inputSystemStreams);\n-\n-    clusterManagerConfig = new ClusterManagerConfig(config);\n-    isJmxEnabled = clusterManagerConfig.getJmxEnabledOnJobCoordinator();\n+    this.inputStreamRegexMonitor = getInputRegexMonitor(config, systemAdmins, inputSystemStreams);\n \n-    jobCoordinatorSleepInterval = clusterManagerConfig.getJobCoordinatorSleepInterval();\n+    ClusterManagerConfig clusterManagerConfig = new ClusterManagerConfig(config);\n+    this.isJmxEnabled = clusterManagerConfig.getJmxEnabledOnJobCoordinator();\n+    this.jobCoordinatorSleepInterval = clusterManagerConfig.getJobCoordinatorSleepInterval();\n \n     // build a container process Manager\n-    containerProcessManager = createContainerProcessManager();\n+    this.containerProcessManager = createContainerProcessManager();\n   }\n \n   /**\n", "next_change": null}]}}]}, "revised_code_in_main": {"commit": "5bef72595faa8c8cdc9e35b09342e36a5085c10b", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex da4a9c81f..d97a4a1e0 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -176,64 +177,38 @@ public class ClusterBasedJobCoordinator {\n   volatile private Exception coordinatorException = null;\n \n   /**\n-   * Creates a new ClusterBasedJobCoordinator instance from a config. Invoke run() to actually\n-   * run the jobcoordinator.\n+   * Creates a new ClusterBasedJobCoordinator instance.\n+   * Invoke run() to actually run the job coordinator.\n    *\n-   * @param jobCoordinatorConfig job coordinator config that either contains coordinator stream properties\n-   *                             or config loader properties to load full job config.\n+   * @param metrics the registry for reporting metrics.\n+   * @param metadataStore metadata store to hold metadata.\n+   * @param fullJobConfig full job config.\n    */\n-  public ClusterBasedJobCoordinator(Config jobCoordinatorConfig) {\n-    metrics = new MetricsRegistryMap();\n-\n-    JobConfig jobConfig = new JobConfig(jobCoordinatorConfig);\n-\n-    if (jobConfig.getConfigLoaderFactory().isPresent()) {\n-      // load full job config with ConfigLoader\n-      Config originalConfig = ConfigUtil.loadConfig(jobCoordinatorConfig);\n-\n-      // Execute planning\n-      ApplicationDescriptorImpl<? extends ApplicationDescriptor>\n-          appDesc = ApplicationDescriptorUtil.getAppDescriptor(ApplicationUtil.fromConfig(originalConfig), originalConfig);\n-      RemoteJobPlanner planner = new RemoteJobPlanner(appDesc);\n-      List<JobConfig> jobConfigs = planner.prepareJobs();\n-\n-      if (jobConfigs.size() != 1) {\n-        throw new SamzaException(\"Only support single remote job is supported.\");\n-      }\n-\n-      config = jobConfigs.get(0);\n-      coordinatorStreamStore = new CoordinatorStreamStore(CoordinatorStreamUtil.buildCoordinatorStreamConfig(config), metrics);\n-      coordinatorStreamStore.init();\n-      CoordinatorStreamUtil.writeConfigToCoordinatorStream(config, true);\n-      DiagnosticsUtil.createDiagnosticsStream(config);\n-    } else {\n-      // TODO SAMZA-2432: Clean this up once SAMZA-2405 is completed when legacy flow is removed.\n-      coordinatorStreamStore = new CoordinatorStreamStore(jobCoordinatorConfig, metrics);\n-      coordinatorStreamStore.init();\n-      config = CoordinatorStreamUtil.readConfigFromCoordinatorStream(coordinatorStreamStore);\n-    }\n-\n+  private ClusterBasedJobCoordinator(MetricsRegistryMap metrics, MetadataStore metadataStore, Config fullJobConfig) {\n+    this.metrics = metrics;\n+    this.metadataStore = metadataStore;\n+    this.config = fullJobConfig;\n     // build a JobModelManager and ChangelogStreamManager and perform partition assignments.\n-    changelogStreamManager = new ChangelogStreamManager(new NamespaceAwareCoordinatorStreamStore(coordinatorStreamStore, SetChangelogMapping.TYPE));\n-    jobModelManager =\n-        JobModelManager.apply(config, changelogStreamManager.readPartitionMapping(), coordinatorStreamStore, metrics);\n+    this.changelogStreamManager = new ChangelogStreamManager(\n+        new NamespaceAwareCoordinatorStreamStore(metadataStore, SetChangelogMapping.TYPE));\n+    this.jobModelManager =\n+        JobModelManager.apply(config, changelogStreamManager.readPartitionMapping(), metadataStore, metrics);\n \n-    hasDurableStores = new StorageConfig(config).hasDurableStores();\n-    state = new SamzaApplicationState(jobModelManager);\n+    this.hasDurableStores = new StorageConfig(config).hasDurableStores();\n+    this.state = new SamzaApplicationState(jobModelManager);\n     // The systemAdmins should be started before partitionMonitor can be used. And it should be stopped when this coordinator is stopped.\n-    systemAdmins = new SystemAdmins(config);\n-    partitionMonitor = getPartitionCountMonitor(config, systemAdmins);\n+    this.systemAdmins = new SystemAdmins(config);\n+    this.partitionMonitor = getPartitionCountMonitor(config, systemAdmins);\n \n     Set<SystemStream> inputSystemStreams = JobModelUtil.getSystemStreams(jobModelManager.jobModel());\n-    inputStreamRegexMonitor = getInputRegexMonitor(config, systemAdmins, inputSystemStreams);\n+    this.inputStreamRegexMonitor = getInputRegexMonitor(config, systemAdmins, inputSystemStreams);\n \n-    clusterManagerConfig = new ClusterManagerConfig(config);\n-    isJmxEnabled = clusterManagerConfig.getJmxEnabledOnJobCoordinator();\n-\n-    jobCoordinatorSleepInterval = clusterManagerConfig.getJobCoordinatorSleepInterval();\n+    ClusterManagerConfig clusterManagerConfig = new ClusterManagerConfig(config);\n+    this.isJmxEnabled = clusterManagerConfig.getJmxEnabledOnJobCoordinator();\n+    this.jobCoordinatorSleepInterval = clusterManagerConfig.getJobCoordinatorSleepInterval();\n \n     // build a container process Manager\n-    containerProcessManager = createContainerProcessManager();\n+    this.containerProcessManager = createContainerProcessManager();\n   }\n \n   /**\n", "next_change": {"commit": "b379933d62c8cb438f0599e2540bce6b63e8c014", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex d97a4a1e0..2b9636c8d 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -208,7 +218,13 @@ public class ClusterBasedJobCoordinator {\n     this.jobCoordinatorSleepInterval = clusterManagerConfig.getJobCoordinatorSleepInterval();\n \n     // build a container process Manager\n-    this.containerProcessManager = createContainerProcessManager();\n+    containerProcessManager = createContainerProcessManager();\n+\n+    // build utils related to container placements\n+    containerPlacementMetadataStore = new ContainerPlacementMetadataStore(metadataStore);\n+    containerPlacementRequestAllocator = new ContainerPlacementRequestAllocator(containerPlacementMetadataStore, containerProcessManager);\n+    this.containerPlacementRequestAllocatorThread =\n+        new Thread(containerPlacementRequestAllocator, \"Samza-\" + ContainerPlacementRequestAllocator.class.getSimpleName());\n   }\n \n   /**\n", "next_change": {"commit": "b4a9fe67238d6eb81b2c61177cafd276ade67c07", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex 2b9636c8d..f894bcff5 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -217,12 +218,16 @@ public class ClusterBasedJobCoordinator {\n     this.isJmxEnabled = clusterManagerConfig.getJmxEnabledOnJobCoordinator();\n     this.jobCoordinatorSleepInterval = clusterManagerConfig.getJobCoordinatorSleepInterval();\n \n+    // build metastore for container placement messages\n+    containerPlacementMetadataStore = new ContainerPlacementMetadataStore(metadataStore);\n+\n     // build a container process Manager\n     containerProcessManager = createContainerProcessManager();\n \n     // build utils related to container placements\n-    containerPlacementMetadataStore = new ContainerPlacementMetadataStore(metadataStore);\n-    containerPlacementRequestAllocator = new ContainerPlacementRequestAllocator(containerPlacementMetadataStore, containerProcessManager);\n+    containerPlacementRequestAllocator =\n+        new ContainerPlacementRequestAllocator(containerPlacementMetadataStore, containerProcessManager,\n+            new ApplicationConfig(config));\n     this.containerPlacementRequestAllocatorThread =\n         new Thread(containerPlacementRequestAllocator, \"Samza-\" + ContainerPlacementRequestAllocator.class.getSimpleName());\n   }\n", "next_change": null}]}}]}}]}, "commits_in_main": [{"oid": "5bef72595faa8c8cdc9e35b09342e36a5085c10b", "message": "Merge commit", "committedDate": null}, {"oid": "b379933d62c8cb438f0599e2540bce6b63e8c014", "committedDate": "2020-01-21 15:37:07 -0800", "message": "SAMZA-2404: [SEP-22] Container Placement Handler for dispatching container placement messages between metastore and JobCoordinator (#1227)"}, {"oid": "b4a9fe67238d6eb81b2c61177cafd276ade67c07", "committedDate": "2020-02-18 12:32:05 -0800", "message": "SAMZA-2402: Tie Container placement service and Container placement handler and validate placement requests (#1267)"}, {"oid": "e4eefe2a9b7d6559ee5ce236e5357d773c199816", "committedDate": "2020-03-10 13:20:39 -0700", "message": "SAMZA-2453: Update ClusterBasedJobCoordinator to support Beam jobs (#1309)"}, {"oid": "d6608714c211835c3b04caaaa49882455135158c", "committedDate": "2020-03-11 13:44:21 -0700", "message": "SAMZA-2466: [Scala cleanup] Convert ShellCommandConfig from scala to java (#1288)"}, {"oid": "b7cab952317bd4320f12e18c2cc3e3cee77770da", "committedDate": "2020-03-17 19:20:52 -0700", "message": "SAMZA-2488: Add JobCoordinatorLaunchUtil to handle common logic when launching job coordiantor. (#1318)"}, {"oid": "c527ec5a151e0da570dfdc3896c30694ac7c34f6", "committedDate": "2020-03-27 22:36:05 -0700", "message": "SAMZA-2491: AM should log uncaught exceptions and System.exit to ensure that the process dies on errors (#1325)"}, {"oid": "26d9eecac76f3b87610312d0066d96a5b36eef35", "committedDate": "2020-04-01 16:43:05 -0700", "message": "SAMZA-2501 : Optimizing startpoint manager to not make successive bootstrapMessage calls to coordinator-store (#1335)"}, {"oid": "d745e7d1cbd051002b30bfe99ae924d48ff96eaa", "committedDate": "2020-04-16 13:48:29 -0700", "message": "SAMZA-2509: New config name to represent if split deployment feature is enabled (#1342)"}, {"oid": "e86951f102c7a854d343b1f80dc2796be29c9c81", "committedDate": "2020-04-24 09:40:25 -0700", "message": "SAMZA-2514: Refactor codes to make runWithClassLoader method more generic (#1349)"}, {"oid": "5f05cdde2eea46a8cbda08dd8c9868c8f46a4e9d", "committedDate": "2020-06-22 15:52:51 -0700", "message": "SAMZA-2551: Upgrade all modules to automatically use checkstyle 6.11.2 (part 1: includes samza-core) (#1389)"}, {"oid": "f7f9f3c7905b047f262383bcc64ebb01ab73f421", "committedDate": "2020-08-26 19:39:32 -0700", "message": "SAMZA-2439: Remove LocalityManager and container location information from JobModel (#1421)"}, {"oid": "d689fd2568ea9dd457ed1c7c9cb193f4ae6fa631", "committedDate": "2020-09-02 15:10:42 -0700", "message": "SAMZA-2584: Refactor ClusterBasedJobCoordinator (#1424)"}, {"oid": "42e68e88c4dfe4c891dd601ee98f190d598decfd", "committedDate": "2020-09-15 21:50:40 -0700", "message": "SAMZA-2574 : improve flexibility of SystemFactory interface"}, {"oid": "c212cac420864d09f2663da2e51c23e4718d6812", "committedDate": "2020-11-30 23:37:21 -0800", "message": "SAMZA-2604: Datamodel change to capture physical container id for AM HA (#1445)"}, {"oid": "108768393960a893f9d202edf50bf47d2b1af590", "committedDate": "2020-12-09 09:33:11 -0800", "message": "SAMZA-2610: Handle Metadata changes for AM HA orchestration (#1450)"}, {"oid": "7cc4eaa96fff244f6dce9c18af804917db7c3b2b", "committedDate": "2021-05-25 16:00:46 -0700", "message": "SAMZA-2657: Blob Store as backend for Samza State backup and restore (#1501)"}, {"oid": "120098d6c45ca023d2a0fb144b0e333ab4e8ffe8", "committedDate": "2021-08-24 14:08:17 -0700", "message": "SAMZA-2670: Update granularity of JobCoordinatorMetadataManager.checkForMetadataChanges and epoch id extraction (#1519)"}, {"oid": "27b1495589e992cf1606ebfc2e34699077d60b73", "committedDate": "2021-08-30 14:26:40 -0700", "message": "SAMZA-2672: Extract creation of stream monitors into separate classes for reuse (#1520)"}, {"oid": "493de64bb8c0228bbda11822ae3c84c2085263bf", "committedDate": "2022-06-13 15:06:05 -0700", "message": "SAMZA-2742: [Pipeline Drain] Add Drain components and integrate them with SamzaContainer and JC (#1605)"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzA0NDY5NA==", "url": "https://github.com/apache/samza/pull/1248#discussion_r367044694", "body": "Should this check for a blank string instead of just null? It might be easier since it might sometimes be hard to fill in `null` for an env variable (easier to put the empty string).", "bodyText": "Should this check for a blank string instead of just null? It might be easier since it might sometimes be hard to fill in null for an env variable (easier to put the empty string).", "bodyHTML": "<p dir=\"auto\">Should this check for a blank string instead of just null? It might be easier since it might sometimes be hard to fill in <code>null</code> for an env variable (easier to put the empty string).</p>", "author": "cameronlee314", "createdAt": "2020-01-15T18:46:53Z", "path": "samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java", "diffHunk": "@@ -480,20 +510,41 @@ private static void executeRunClusterBasedJobCoordinatorForClass(Class<?> cluste\n    * {@link #main(String[])} so that it can be executed directly or from a separate classloader.\n    */\n   private static void runClusterBasedJobCoordinator(String[] args) {\n-    Config coordinatorSystemConfig;\n     final String coordinatorSystemEnv = System.getenv(ShellCommandConfig.ENV_COORDINATOR_SYSTEM_CONFIG());\n-    try {\n-      //Read and parse the coordinator system config.\n-      LOG.info(\"Parsing coordinator system config {}\", coordinatorSystemEnv);\n-      coordinatorSystemConfig =\n-          new MapConfig(SamzaObjectMapper.getObjectMapper().readValue(coordinatorSystemEnv, Config.class));\n-      LOG.info(\"Using the coordinator system config: {}.\", coordinatorSystemConfig);\n-    } catch (IOException e) {\n-      LOG.error(\"Exception while reading coordinator stream config\", e);\n-      throw new SamzaException(e);\n+    final String submissionEnv = System.getenv(ShellCommandConfig.ENV_SUBMISSION_CONFIG());\n+\n+    if (submissionEnv != null) {", "originalCommit": "5d381c46c2b7e55631d744e835feed934f63c27d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzEzNjEwMQ==", "url": "https://github.com/apache/samza/pull/1248#discussion_r367136101", "bodyText": "Good catch. Updated.", "author": "kw2542", "createdAt": "2020-01-15T22:15:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzA0NDY5NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA2NzAzMQ==", "url": "https://github.com/apache/samza/pull/1248#discussion_r368067031", "bodyText": "The comment was resolved, but it looks like you are still just checking for null. Did you intend to check for blank string too?", "author": "cameronlee314", "createdAt": "2020-01-17T18:09:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzA0NDY5NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA3NDQ5OA==", "url": "https://github.com/apache/samza/pull/1248#discussion_r368074498", "bodyText": "My bad, changes are lost during updates. Updated again.", "author": "kw2542", "createdAt": "2020-01-17T18:27:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzA0NDY5NA=="}], "type": "inlineReview", "revised_code": {"commit": "b00cb06351e29501269ac03ca702fba16131590e", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex da4a9c81f..da4d899c6 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -513,7 +489,7 @@ public class ClusterBasedJobCoordinator {\n     final String coordinatorSystemEnv = System.getenv(ShellCommandConfig.ENV_COORDINATOR_SYSTEM_CONFIG());\n     final String submissionEnv = System.getenv(ShellCommandConfig.ENV_SUBMISSION_CONFIG());\n \n-    if (submissionEnv != null) {\n+    if (!StringUtils.isBlank(submissionEnv)) {\n       Config submissionConfig;\n       try {\n         //Read and parse the coordinator system config.\n", "next_change": null}]}, "revised_code_in_main": {"commit": "5bef72595faa8c8cdc9e35b09342e36a5085c10b", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex da4a9c81f..d97a4a1e0 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -513,7 +488,7 @@ public class ClusterBasedJobCoordinator {\n     final String coordinatorSystemEnv = System.getenv(ShellCommandConfig.ENV_COORDINATOR_SYSTEM_CONFIG());\n     final String submissionEnv = System.getenv(ShellCommandConfig.ENV_SUBMISSION_CONFIG());\n \n-    if (submissionEnv != null) {\n+    if (!StringUtils.isBlank(submissionEnv)) {\n       Config submissionConfig;\n       try {\n         //Read and parse the coordinator system config.\n", "next_change": {"commit": "d6608714c211835c3b04caaaa49882455135158c", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex d97a4a1e0..b9d054b3a 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -485,8 +537,8 @@ public class ClusterBasedJobCoordinator {\n    * {@link #main(String[])} so that it can be executed directly or from a separate classloader.\n    */\n   private static void runClusterBasedJobCoordinator(String[] args) {\n-    final String coordinatorSystemEnv = System.getenv(ShellCommandConfig.ENV_COORDINATOR_SYSTEM_CONFIG());\n-    final String submissionEnv = System.getenv(ShellCommandConfig.ENV_SUBMISSION_CONFIG());\n+    final String coordinatorSystemEnv = System.getenv(ShellCommandConfig.ENV_COORDINATOR_SYSTEM_CONFIG);\n+    final String submissionEnv = System.getenv(ShellCommandConfig.ENV_SUBMISSION_CONFIG);\n \n     if (!StringUtils.isBlank(submissionEnv)) {\n       Config submissionConfig;\n", "next_change": {"commit": "d689fd2568ea9dd457ed1c7c9cb193f4ae6fa631", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex b9d054b3a..6295ed6e9 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -459,231 +448,6 @@ public class ClusterBasedJobCoordinator {\n \n   @VisibleForTesting\n   ContainerProcessManager createContainerProcessManager() {\n-    return new ContainerProcessManager(config, state, metrics, containerPlacementMetadataStore);\n-  }\n-\n-  /**\n-   * The entry point for the {@link ClusterBasedJobCoordinator}.\n-   */\n-  public static void main(String[] args) {\n-    boolean dependencyIsolationEnabled = Boolean.parseBoolean(\n-        System.getenv(ShellCommandConfig.ENV_CLUSTER_BASED_JOB_COORDINATOR_DEPENDENCY_ISOLATION_ENABLED));\n-    if (!dependencyIsolationEnabled) {\n-      // no isolation enabled, so can just execute runClusterBasedJobCoordinator directly\n-      runClusterBasedJobCoordinator(args);\n-    } else {\n-      runWithClassLoader(new IsolatingClassLoaderFactory().buildClassLoader(), args);\n-    }\n-  }\n-\n-  /**\n-   * Execute the coordinator using a separate isolated classloader.\n-   * @param classLoader {@link ClassLoader} to use to load the {@link ClusterBasedJobCoordinator} which will run\n-   * @param args arguments to pass when running the {@link ClusterBasedJobCoordinator}\n-   */\n-  @VisibleForTesting\n-  static void runWithClassLoader(ClassLoader classLoader, String[] args) {\n-    // need to use the isolated classloader to load ClusterBasedJobCoordinator and then run using that new class\n-    Class<?> clusterBasedJobCoordinatorClass;\n-    try {\n-      clusterBasedJobCoordinatorClass = classLoader.loadClass(ClusterBasedJobCoordinator.class.getName());\n-    } catch (ClassNotFoundException e) {\n-      throw new SamzaException(\n-          \"Isolation was enabled, but unable to find ClusterBasedJobCoordinator in isolated classloader\", e);\n-    }\n-\n-    // save the current context classloader so it can be reset after finishing the call to runClusterBasedJobCoordinator\n-    ClassLoader previousContextClassLoader = Thread.currentThread().getContextClassLoader();\n-    // this is needed because certain libraries (e.g. log4j) use the context classloader\n-    Thread.currentThread().setContextClassLoader(classLoader);\n-\n-    try {\n-      executeRunClusterBasedJobCoordinatorForClass(clusterBasedJobCoordinatorClass, args);\n-    } finally {\n-      // reset the context class loader; it's good practice, and could be important when running a test suite\n-      Thread.currentThread().setContextClassLoader(previousContextClassLoader);\n-    }\n-  }\n-\n-  /**\n-   * Runs the {@link ClusterBasedJobCoordinator#runClusterBasedJobCoordinator(String[])} method of the given\n-   * {@code clusterBasedJobCoordinatorClass} using reflection.\n-   * @param clusterBasedJobCoordinatorClass {@link ClusterBasedJobCoordinator} {@link Class} for which to execute\n-   * {@link ClusterBasedJobCoordinator#runClusterBasedJobCoordinator(String[])}\n-   * @param args arguments to pass to {@link ClusterBasedJobCoordinator#runClusterBasedJobCoordinator(String[])}\n-   */\n-  private static void executeRunClusterBasedJobCoordinatorForClass(Class<?> clusterBasedJobCoordinatorClass,\n-      String[] args) {\n-    Method runClusterBasedJobCoordinatorMethod;\n-    try {\n-      runClusterBasedJobCoordinatorMethod =\n-          clusterBasedJobCoordinatorClass.getDeclaredMethod(\"runClusterBasedJobCoordinator\", String[].class);\n-    } catch (NoSuchMethodException e) {\n-      throw new SamzaException(\"Isolation was enabled, but unable to find runClusterBasedJobCoordinator method\", e);\n-    }\n-    // only sets accessible flag for this Method instance, not other Method instances for runClusterBasedJobCoordinator\n-    runClusterBasedJobCoordinatorMethod.setAccessible(true);\n-\n-    try {\n-      // wrapping args in object array so that args is passed as a single argument to the method\n-      runClusterBasedJobCoordinatorMethod.invoke(null, new Object[]{args});\n-    } catch (IllegalAccessException | InvocationTargetException e) {\n-      throw new SamzaException(\"Exception while executing runClusterBasedJobCoordinator method\", e);\n-    }\n-  }\n-\n-  /**\n-   * This is the actual execution for the {@link ClusterBasedJobCoordinator}. This is separated out from\n-   * {@link #main(String[])} so that it can be executed directly or from a separate classloader.\n-   */\n-  private static void runClusterBasedJobCoordinator(String[] args) {\n-    final String coordinatorSystemEnv = System.getenv(ShellCommandConfig.ENV_COORDINATOR_SYSTEM_CONFIG);\n-    final String submissionEnv = System.getenv(ShellCommandConfig.ENV_SUBMISSION_CONFIG);\n-\n-    if (!StringUtils.isBlank(submissionEnv)) {\n-      Config submissionConfig;\n-      try {\n-        //Read and parse the coordinator system config.\n-        LOG.info(\"Parsing submission config {}\", submissionEnv);\n-        submissionConfig =\n-            new MapConfig(SamzaObjectMapper.getObjectMapper().readValue(submissionEnv, Config.class));\n-        LOG.info(\"Using the submission config: {}.\", submissionConfig);\n-      } catch (IOException e) {\n-        LOG.error(\"Exception while reading submission config\", e);\n-        throw new SamzaException(e);\n-      }\n-\n-      ApplicationConfig appConfig = new ApplicationConfig(submissionConfig);\n-\n-      /*\n-       * Invoke app.main.class with app.main.args when present.\n-       * For Beam jobs, app.main.class will be Beam's main class\n-       * and app.main.args will be Beam's pipeline options.\n-       */\n-      if (appConfig.getAppMainClass().isPresent()) {\n-        String className = appConfig.getAppMainClass().get();\n-        LOG.info(\"Invoke main {}\", className);\n-        try {\n-          Class<?> cls = Class.forName(className);\n-          Method mainMethod = cls.getMethod(\"main\", String[].class);\n-          mainMethod.invoke(null, (Object) toArgs(appConfig));\n-        } catch (Exception e) {\n-          throw new SamzaException(e);\n-        }\n-      } else {\n-        ClusterBasedJobCoordinator jc = createFromConfigLoader(submissionConfig);\n-        jc.run();\n-      }\n-\n-      LOG.info(\"Finished running ClusterBasedJobCoordinator\");\n-    } else {\n-      // TODO: Clean this up once SAMZA-2405 is completed when legacy flow is removed.\n-      Config coordinatorSystemConfig;\n-      try {\n-        //Read and parse the coordinator system config.\n-        LOG.info(\"Parsing coordinator system config {}\", coordinatorSystemEnv);\n-        coordinatorSystemConfig =\n-            new MapConfig(SamzaObjectMapper.getObjectMapper().readValue(coordinatorSystemEnv, Config.class));\n-        LOG.info(\"Using the coordinator system config: {}.\", coordinatorSystemConfig);\n-      } catch (IOException e) {\n-        LOG.error(\"Exception while reading coordinator stream config\", e);\n-        throw new SamzaException(e);\n-      }\n-      ClusterBasedJobCoordinator jc = createFromMetadataStore(coordinatorSystemConfig);\n-      jc.run();\n-      LOG.info(\"Finished running ClusterBasedJobCoordinator\");\n-    }\n-  }\n-\n-  /**\n-   * Initialize {@link ClusterBasedJobCoordinator} with coordinator stream config, full job config will be fetched from\n-   * coordinator stream.\n-   *\n-   * @param metadataStoreConfig to initialize {@link MetadataStore}\n-   * @return {@link ClusterBasedJobCoordinator}\n-   */\n-  // TODO SAMZA-2432: Clean this up once SAMZA-2405 is completed when legacy flow is removed.\n-  @VisibleForTesting\n-  static ClusterBasedJobCoordinator createFromMetadataStore(Config metadataStoreConfig) {\n-    MetricsRegistryMap metrics = new MetricsRegistryMap();\n-\n-    CoordinatorStreamStore coordinatorStreamStore = new CoordinatorStreamStore(metadataStoreConfig, metrics);\n-    coordinatorStreamStore.init();\n-    Config config = CoordinatorStreamUtil.readConfigFromCoordinatorStream(coordinatorStreamStore);\n-\n-    return new ClusterBasedJobCoordinator(metrics, coordinatorStreamStore, config);\n-  }\n-\n-  /**\n-   * Initialize {@link ClusterBasedJobCoordinator} with submission config, full job config will be fetched using\n-   * specified {@link org.apache.samza.config.ConfigLoaderFactory}\n-   *\n-   * @param submissionConfig specifies {@link org.apache.samza.config.ConfigLoaderFactory}\n-   * @return {@link ClusterBasedJobCoordinator}\n-   */\n-  @VisibleForTesting\n-  static ClusterBasedJobCoordinator createFromConfigLoader(Config submissionConfig) {\n-    JobConfig jobConfig = new JobConfig(submissionConfig);\n-\n-    if (!jobConfig.getConfigLoaderFactory().isPresent()) {\n-      throw new SamzaException(JobConfig.CONFIG_LOADER_FACTORY + \" is required to initialize job coordinator from config loader\");\n-    }\n-\n-    MetricsRegistryMap metrics = new MetricsRegistryMap();\n-    // load full job config with ConfigLoader\n-    Config originalConfig = ConfigUtil.loadConfig(submissionConfig);\n-\n-    // Execute planning\n-    ApplicationDescriptorImpl<? extends ApplicationDescriptor>\n-        appDesc = ApplicationDescriptorUtil.getAppDescriptor(ApplicationUtil.fromConfig(originalConfig), originalConfig);\n-    RemoteJobPlanner planner = new RemoteJobPlanner(appDesc);\n-    List<JobConfig> jobConfigs = planner.prepareJobs();\n-\n-    if (jobConfigs.size() != 1) {\n-      throw new SamzaException(\"Only support single remote job is supported.\");\n-    }\n-\n-    Config config = jobConfigs.get(0);\n-\n-    // This needs to be consistent with RemoteApplicationRunner#run where JobRunner#submit to be called instead of JobRunner#run\n-    CoordinatorStreamUtil.writeConfigToCoordinatorStream(config, true);\n-    DiagnosticsUtil.createDiagnosticsStream(config);\n-    MetadataStore metadataStore = new CoordinatorStreamStore(CoordinatorStreamUtil.buildCoordinatorStreamConfig(config), metrics);\n-    metadataStore.init();\n-\n-    return new ClusterBasedJobCoordinator(\n-        metrics,\n-        metadataStore,\n-        config);\n-  }\n-\n-  /**\n-   * Convert Samza config to command line arguments to invoke app.main.class\n-   *\n-   * @param config Samza config to convert.\n-   * @return converted command line arguments.\n-   */\n-  @VisibleForTesting\n-  static String[] toArgs(ApplicationConfig config) {\n-    List<String> args = new ArrayList<>(config.size() * 2);\n-\n-    config.forEach((key, value) -> {\n-        if (key.equals(ApplicationConfig.APP_MAIN_ARGS)) {\n-          /*\n-           * Converts native beam pipeline options such as\n-           * --runner=SamzaRunner --maxSourceParallelism=1024\n-           */\n-          args.addAll(Arrays.asList(value.split(\"\\\\s\")));\n-        } else {\n-          /*\n-           * Converts native Samza configs to config override format such as\n-           * --config job.name=test\n-           */\n-          args.add(\"--config\");\n-          args.add(String.format(\"%s=%s\", key, value));\n-        }\n-      });\n-\n-    return args.toArray(new String[0]);\n+    return new ContainerProcessManager(config, state, metrics, containerPlacementMetadataStore, localityManager);\n   }\n }\n", "next_change": {"commit": "108768393960a893f9d202edf50bf47d2b1af590", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex 6295ed6e9..08bcfda8f 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -448,6 +485,39 @@ public class ClusterBasedJobCoordinator {\n \n   @VisibleForTesting\n   ContainerProcessManager createContainerProcessManager() {\n-    return new ContainerProcessManager(config, state, metrics, containerPlacementMetadataStore, localityManager);\n+    return new ContainerProcessManager(config, state, metrics, containerPlacementMetadataStore, localityManager,\n+        metadataChangedAcrossAttempts);\n+  }\n+\n+  @VisibleForTesting\n+  JobCoordinatorMetadataManager createJobCoordinatorMetadataManager() {\n+    return new JobCoordinatorMetadataManager(new NamespaceAwareCoordinatorStreamStore(metadataStore,\n+        SetJobCoordinatorMetadataMessage.TYPE), JobCoordinatorMetadataManager.ClusterType.YARN, metrics);\n+  }\n+\n+  @VisibleForTesting\n+  boolean isApplicationMasterHighAvailabilityEnabled() {\n+    return new JobConfig(config).getApplicationMasterHighAvailabilityEnabled();\n+  }\n+\n+  @VisibleForTesting\n+  boolean isMetadataChangedAcrossAttempts() {\n+    return metadataChangedAcrossAttempts;\n+  }\n+\n+  /**\n+   * We only fanout startpoint if and only if\n+   *  1. Startpoint is enabled\n+   *  2. If AM HA is enabled, fanout only if startpoint enabled and job coordinator metadata changed\n+   *\n+   * @return true if it satisfies above conditions, false otherwise\n+   */\n+  @VisibleForTesting\n+  boolean shouldFanoutStartpoint() {\n+    JobConfig jobConfig = new JobConfig(config);\n+    boolean startpointEnabled = jobConfig.getStartpointEnabled();\n+\n+    return isApplicationMasterHighAvailabilityEnabled() ?\n+        startpointEnabled && isMetadataChangedAcrossAttempts() : startpointEnabled;\n   }\n }\n", "next_change": null}]}}]}}]}}]}, "commits_in_main": [{"oid": "5bef72595faa8c8cdc9e35b09342e36a5085c10b", "message": "Merge commit", "committedDate": null}, {"oid": "b379933d62c8cb438f0599e2540bce6b63e8c014", "committedDate": "2020-01-21 15:37:07 -0800", "message": "SAMZA-2404: [SEP-22] Container Placement Handler for dispatching container placement messages between metastore and JobCoordinator (#1227)"}, {"oid": "b4a9fe67238d6eb81b2c61177cafd276ade67c07", "committedDate": "2020-02-18 12:32:05 -0800", "message": "SAMZA-2402: Tie Container placement service and Container placement handler and validate placement requests (#1267)"}, {"oid": "e4eefe2a9b7d6559ee5ce236e5357d773c199816", "committedDate": "2020-03-10 13:20:39 -0700", "message": "SAMZA-2453: Update ClusterBasedJobCoordinator to support Beam jobs (#1309)"}, {"oid": "d6608714c211835c3b04caaaa49882455135158c", "committedDate": "2020-03-11 13:44:21 -0700", "message": "SAMZA-2466: [Scala cleanup] Convert ShellCommandConfig from scala to java (#1288)"}, {"oid": "b7cab952317bd4320f12e18c2cc3e3cee77770da", "committedDate": "2020-03-17 19:20:52 -0700", "message": "SAMZA-2488: Add JobCoordinatorLaunchUtil to handle common logic when launching job coordiantor. (#1318)"}, {"oid": "c527ec5a151e0da570dfdc3896c30694ac7c34f6", "committedDate": "2020-03-27 22:36:05 -0700", "message": "SAMZA-2491: AM should log uncaught exceptions and System.exit to ensure that the process dies on errors (#1325)"}, {"oid": "26d9eecac76f3b87610312d0066d96a5b36eef35", "committedDate": "2020-04-01 16:43:05 -0700", "message": "SAMZA-2501 : Optimizing startpoint manager to not make successive bootstrapMessage calls to coordinator-store (#1335)"}, {"oid": "d745e7d1cbd051002b30bfe99ae924d48ff96eaa", "committedDate": "2020-04-16 13:48:29 -0700", "message": "SAMZA-2509: New config name to represent if split deployment feature is enabled (#1342)"}, {"oid": "e86951f102c7a854d343b1f80dc2796be29c9c81", "committedDate": "2020-04-24 09:40:25 -0700", "message": "SAMZA-2514: Refactor codes to make runWithClassLoader method more generic (#1349)"}, {"oid": "5f05cdde2eea46a8cbda08dd8c9868c8f46a4e9d", "committedDate": "2020-06-22 15:52:51 -0700", "message": "SAMZA-2551: Upgrade all modules to automatically use checkstyle 6.11.2 (part 1: includes samza-core) (#1389)"}, {"oid": "f7f9f3c7905b047f262383bcc64ebb01ab73f421", "committedDate": "2020-08-26 19:39:32 -0700", "message": "SAMZA-2439: Remove LocalityManager and container location information from JobModel (#1421)"}, {"oid": "d689fd2568ea9dd457ed1c7c9cb193f4ae6fa631", "committedDate": "2020-09-02 15:10:42 -0700", "message": "SAMZA-2584: Refactor ClusterBasedJobCoordinator (#1424)"}, {"oid": "42e68e88c4dfe4c891dd601ee98f190d598decfd", "committedDate": "2020-09-15 21:50:40 -0700", "message": "SAMZA-2574 : improve flexibility of SystemFactory interface"}, {"oid": "c212cac420864d09f2663da2e51c23e4718d6812", "committedDate": "2020-11-30 23:37:21 -0800", "message": "SAMZA-2604: Datamodel change to capture physical container id for AM HA (#1445)"}, {"oid": "108768393960a893f9d202edf50bf47d2b1af590", "committedDate": "2020-12-09 09:33:11 -0800", "message": "SAMZA-2610: Handle Metadata changes for AM HA orchestration (#1450)"}, {"oid": "7cc4eaa96fff244f6dce9c18af804917db7c3b2b", "committedDate": "2021-05-25 16:00:46 -0700", "message": "SAMZA-2657: Blob Store as backend for Samza State backup and restore (#1501)"}, {"oid": "120098d6c45ca023d2a0fb144b0e333ab4e8ffe8", "committedDate": "2021-08-24 14:08:17 -0700", "message": "SAMZA-2670: Update granularity of JobCoordinatorMetadataManager.checkForMetadataChanges and epoch id extraction (#1519)"}, {"oid": "27b1495589e992cf1606ebfc2e34699077d60b73", "committedDate": "2021-08-30 14:26:40 -0700", "message": "SAMZA-2672: Extract creation of stream monitors into separate classes for reuse (#1520)"}, {"oid": "493de64bb8c0228bbda11822ae3c84c2085263bf", "committedDate": "2022-06-13 15:06:05 -0700", "message": "SAMZA-2742: [Pipeline Drain] Add Drain components and integrate them with SamzaContainer and JC (#1605)"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzA0OTUxNw==", "url": "https://github.com/apache/samza/pull/1248#discussion_r367049517", "body": "I think the config rewriter sometimes overrides existing configs, so I don't think you want to re-override back to the original.\r\nDoes the existing flow do this override flow with the original config?", "bodyText": "I think the config rewriter sometimes overrides existing configs, so I don't think you want to re-override back to the original.\nDoes the existing flow do this override flow with the original config?", "bodyHTML": "<p dir=\"auto\">I think the config rewriter sometimes overrides existing configs, so I don't think you want to re-override back to the original.<br>\nDoes the existing flow do this override flow with the original config?</p>", "author": "cameronlee314", "createdAt": "2020-01-15T18:57:12Z", "path": "samza-core/src/main/java/org/apache/samza/util/ConfigUtil.java", "diffHunk": "@@ -67,4 +72,42 @@ public static Config applyRewriter(Config config, String rewriterName) {\n     LOG.info(\"Re-writing config with {}\", rewriter);\n     return rewriter.rewrite(rewriterName, config);\n   }\n+\n+  /**\n+   * Load full job config with {@link ConfigLoaderFactory} when present.\n+   *\n+   * @param original config\n+   * @return full job config\n+   */\n+  public static Config loadConfig(Config original) {\n+    JobConfig jobConfig = new JobConfig(original);\n+    Config fullConfig = original;\n+\n+    if (jobConfig.getConfigLoaderFactory().isPresent()) {\n+      ConfigLoaderFactory factory = ReflectionUtil.getObj(jobConfig.getConfigLoaderFactory().get(), ConfigLoaderFactory.class);\n+      ConfigLoader loader = factory.getLoader(original.subset(ConfigLoaderFactory.CONFIG_LOADER_PROPERTIES_PREFIX));\n+      // overrides config loaded with original config, which may contain overridden values.\n+      fullConfig = override(ConfigUtil.rewriteConfig(loader.getConfig()), original);", "originalCommit": "5d381c46c2b7e55631d744e835feed934f63c27d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE0Njk1OA==", "url": "https://github.com/apache/samza/pull/1248#discussion_r367146958", "bodyText": "Good point, we should override the original config with provided overrides and then invoke config rewriters.\nUpdated.", "author": "kw2542", "createdAt": "2020-01-15T22:44:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzA0OTUxNw=="}], "type": "inlineReview", "revised_code": {"commit": "a90387a1a7c89abf58ad84875dade3f9fe2e5361", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/util/ConfigUtil.java b/samza-core/src/main/java/org/apache/samza/util/ConfigUtil.java\nindex a3cc3fa1e..86a5f52b5 100644\n--- a/samza-core/src/main/java/org/apache/samza/util/ConfigUtil.java\n+++ b/samza-core/src/main/java/org/apache/samza/util/ConfigUtil.java\n", "chunk": "@@ -87,7 +87,7 @@ public class ConfigUtil {\n       ConfigLoaderFactory factory = ReflectionUtil.getObj(jobConfig.getConfigLoaderFactory().get(), ConfigLoaderFactory.class);\n       ConfigLoader loader = factory.getLoader(original.subset(ConfigLoaderFactory.CONFIG_LOADER_PROPERTIES_PREFIX));\n       // overrides config loaded with original config, which may contain overridden values.\n-      fullConfig = override(ConfigUtil.rewriteConfig(loader.getConfig()), original);\n+      fullConfig = ConfigUtil.rewriteConfig(override(loader.getConfig(), original));\n     }\n \n     return fullConfig;\n", "next_change": {"commit": "27210d8aa49b6497400604aab47d722563ff59b4", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/util/ConfigUtil.java b/samza-core/src/main/java/org/apache/samza/util/ConfigUtil.java\nindex 86a5f52b5..7206fe284 100644\n--- a/samza-core/src/main/java/org/apache/samza/util/ConfigUtil.java\n+++ b/samza-core/src/main/java/org/apache/samza/util/ConfigUtil.java\n", "chunk": "@@ -81,16 +82,15 @@ public class ConfigUtil {\n    */\n   public static Config loadConfig(Config original) {\n     JobConfig jobConfig = new JobConfig(original);\n-    Config fullConfig = original;\n \n-    if (jobConfig.getConfigLoaderFactory().isPresent()) {\n-      ConfigLoaderFactory factory = ReflectionUtil.getObj(jobConfig.getConfigLoaderFactory().get(), ConfigLoaderFactory.class);\n-      ConfigLoader loader = factory.getLoader(original.subset(ConfigLoaderFactory.CONFIG_LOADER_PROPERTIES_PREFIX));\n-      // overrides config loaded with original config, which may contain overridden values.\n-      fullConfig = ConfigUtil.rewriteConfig(override(loader.getConfig(), original));\n+    if (!jobConfig.getConfigLoaderFactory().isPresent()) {\n+      throw new ConfigException(\"Missing key \" + JobConfig.CONFIG_LOADER_FACTORY + \".\");\n     }\n \n-    return fullConfig;\n+    ConfigLoaderFactory factory = ReflectionUtil.getObj(jobConfig.getConfigLoaderFactory().get(), ConfigLoaderFactory.class);\n+    ConfigLoader loader = factory.getLoader(original.subset(ConfigLoaderFactory.CONFIG_LOADER_PROPERTIES_PREFIX));\n+    // overrides config loaded with original config, which may contain overridden values.\n+    return rewriteConfig(override(loader.getConfig(), original));\n   }\n \n   /**\n", "next_change": null}]}}]}, "revised_code_in_main": {"commit": "5bef72595faa8c8cdc9e35b09342e36a5085c10b", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/util/ConfigUtil.java b/samza-core/src/main/java/org/apache/samza/util/ConfigUtil.java\nindex a3cc3fa1e..7206fe284 100644\n--- a/samza-core/src/main/java/org/apache/samza/util/ConfigUtil.java\n+++ b/samza-core/src/main/java/org/apache/samza/util/ConfigUtil.java\n", "chunk": "@@ -81,16 +82,15 @@ public class ConfigUtil {\n    */\n   public static Config loadConfig(Config original) {\n     JobConfig jobConfig = new JobConfig(original);\n-    Config fullConfig = original;\n \n-    if (jobConfig.getConfigLoaderFactory().isPresent()) {\n-      ConfigLoaderFactory factory = ReflectionUtil.getObj(jobConfig.getConfigLoaderFactory().get(), ConfigLoaderFactory.class);\n-      ConfigLoader loader = factory.getLoader(original.subset(ConfigLoaderFactory.CONFIG_LOADER_PROPERTIES_PREFIX));\n-      // overrides config loaded with original config, which may contain overridden values.\n-      fullConfig = override(ConfigUtil.rewriteConfig(loader.getConfig()), original);\n+    if (!jobConfig.getConfigLoaderFactory().isPresent()) {\n+      throw new ConfigException(\"Missing key \" + JobConfig.CONFIG_LOADER_FACTORY + \".\");\n     }\n \n-    return fullConfig;\n+    ConfigLoaderFactory factory = ReflectionUtil.getObj(jobConfig.getConfigLoaderFactory().get(), ConfigLoaderFactory.class);\n+    ConfigLoader loader = factory.getLoader(original.subset(ConfigLoaderFactory.CONFIG_LOADER_PROPERTIES_PREFIX));\n+    // overrides config loaded with original config, which may contain overridden values.\n+    return rewriteConfig(override(loader.getConfig(), original));\n   }\n \n   /**\n", "next_change": null}]}, "commits_in_main": [{"oid": "5bef72595faa8c8cdc9e35b09342e36a5085c10b", "message": "Merge commit", "committedDate": null}]}, {"oid": "a90387a1a7c89abf58ad84875dade3f9fe2e5361", "url": "https://github.com/apache/samza/commit/a90387a1a7c89abf58ad84875dade3f9fe2e5361", "message": "Add extra comments\nOverride config first before applying config rewriters", "committedDate": "2020-01-15T23:54:01Z", "type": "commit"}, {"oid": "c004a97d60e9bff9e5a39328ec9153c014174232", "url": "https://github.com/apache/samza/commit/c004a97d60e9bff9e5a39328ec9153c014174232", "message": "Add unit tests\nRefactor ClusterBasedJobCoordinator to be testable", "committedDate": "2020-01-16T02:26:36Z", "type": "commit"}, {"oid": "4ec226c3359d4e6d0da01ce7bc436b686bc59083", "url": "https://github.com/apache/samza/commit/4ec226c3359d4e6d0da01ce7bc436b686bc59083", "message": "Merge branch 'master' of https://github.com/apache/samza into SAMZA-2410", "committedDate": "2020-01-16T18:13:54Z", "type": "commit"}, {"oid": "de8ed411e5118dce7ce4f6587379fb29a36495ef", "url": "https://github.com/apache/samza/commit/de8ed411e5118dce7ce4f6587379fb29a36495ef", "message": "Fix style issue in test", "committedDate": "2020-01-16T18:48:13Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA2NzkxMw==", "url": "https://github.com/apache/samza/pull/1248#discussion_r368067913", "body": "It looks like you already call `init` in the shared constructor. Please call it only once.", "bodyText": "It looks like you already call init in the shared constructor. Please call it only once.", "bodyHTML": "<p dir=\"auto\">It looks like you already call <code>init</code> in the shared constructor. Please call it only once.</p>", "author": "cameronlee314", "createdAt": "2020-01-17T18:11:13Z", "path": "samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java", "diffHunk": "@@ -480,20 +485,101 @@ private static void executeRunClusterBasedJobCoordinatorForClass(Class<?> cluste\n    * {@link #main(String[])} so that it can be executed directly or from a separate classloader.\n    */\n   private static void runClusterBasedJobCoordinator(String[] args) {\n-    Config coordinatorSystemConfig;\n     final String coordinatorSystemEnv = System.getenv(ShellCommandConfig.ENV_COORDINATOR_SYSTEM_CONFIG());\n-    try {\n-      //Read and parse the coordinator system config.\n-      LOG.info(\"Parsing coordinator system config {}\", coordinatorSystemEnv);\n-      coordinatorSystemConfig =\n-          new MapConfig(SamzaObjectMapper.getObjectMapper().readValue(coordinatorSystemEnv, Config.class));\n-      LOG.info(\"Using the coordinator system config: {}.\", coordinatorSystemConfig);\n-    } catch (IOException e) {\n-      LOG.error(\"Exception while reading coordinator stream config\", e);\n-      throw new SamzaException(e);\n+    final String submissionEnv = System.getenv(ShellCommandConfig.ENV_SUBMISSION_CONFIG());\n+\n+    if (submissionEnv != null) {\n+      Config submissionConfig;\n+      try {\n+        //Read and parse the coordinator system config.\n+        LOG.info(\"Parsing submission config {}\", submissionEnv);\n+        submissionConfig =\n+            new MapConfig(SamzaObjectMapper.getObjectMapper().readValue(submissionEnv, Config.class));\n+        LOG.info(\"Using the submission config: {}.\", submissionConfig);\n+      } catch (IOException e) {\n+        LOG.error(\"Exception while reading submission config\", e);\n+        throw new SamzaException(e);\n+      }\n+\n+      ClusterBasedJobCoordinator jc = createFromConfigLoader(submissionConfig);\n+      jc.run();\n+      LOG.info(\"Finished running ClusterBasedJobCoordinator\");\n+    } else {\n+      // TODO: Clean this up once SAMZA-2405 is completed when legacy flow is removed.\n+      Config coordinatorSystemConfig;\n+      try {\n+        //Read and parse the coordinator system config.\n+        LOG.info(\"Parsing coordinator system config {}\", coordinatorSystemEnv);\n+        coordinatorSystemConfig =\n+            new MapConfig(SamzaObjectMapper.getObjectMapper().readValue(coordinatorSystemEnv, Config.class));\n+        LOG.info(\"Using the coordinator system config: {}.\", coordinatorSystemConfig);\n+      } catch (IOException e) {\n+        LOG.error(\"Exception while reading coordinator stream config\", e);\n+        throw new SamzaException(e);\n+      }\n+      ClusterBasedJobCoordinator jc = createFromMetadataStore(coordinatorSystemConfig);\n+      jc.run();\n+      LOG.info(\"Finished running ClusterBasedJobCoordinator\");\n+    }\n+  }\n+\n+  /**\n+   * Initialize {@link ClusterBasedJobCoordinator} with coordinator stream config, full job config will be fetched from\n+   * coordinator stream.\n+   *\n+   * @param metadataStoreConfig to initialize {@link MetadataStore}\n+   * @return {@link ClusterBasedJobCoordinator}\n+   */\n+  // TODO SAMZA-2432: Clean this up once SAMZA-2405 is completed when legacy flow is removed.\n+  public static ClusterBasedJobCoordinator createFromMetadataStore(Config metadataStoreConfig) {\n+    MetricsRegistryMap metrics = new MetricsRegistryMap();\n+\n+    CoordinatorStreamStore coordinatorStreamStore = new CoordinatorStreamStore(metadataStoreConfig, metrics);\n+    coordinatorStreamStore.init();", "originalCommit": "de8ed411e5118dce7ce4f6587379fb29a36495ef", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA3NzQ1MQ==", "url": "https://github.com/apache/samza/pull/1248#discussion_r368077451", "bodyText": "Update to call outside constructor as we need it to be initialized before we can read full job config from it in the legacy flow.", "author": "kw2542", "createdAt": "2020-01-17T18:34:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA2NzkxMw=="}], "type": "inlineReview", "revised_code": {"commit": "27210d8aa49b6497400604aab47d722563ff59b4", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex d22e694d7..5dd3a64e4 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -531,7 +531,8 @@ public class ClusterBasedJobCoordinator {\n    * @return {@link ClusterBasedJobCoordinator}\n    */\n   // TODO SAMZA-2432: Clean this up once SAMZA-2405 is completed when legacy flow is removed.\n-  public static ClusterBasedJobCoordinator createFromMetadataStore(Config metadataStoreConfig) {\n+  @VisibleForTesting\n+  static ClusterBasedJobCoordinator createFromMetadataStore(Config metadataStoreConfig) {\n     MetricsRegistryMap metrics = new MetricsRegistryMap();\n \n     CoordinatorStreamStore coordinatorStreamStore = new CoordinatorStreamStore(metadataStoreConfig, metrics);\n", "next_change": null}]}, "revised_code_in_main": {"commit": "5bef72595faa8c8cdc9e35b09342e36a5085c10b", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex d22e694d7..d97a4a1e0 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -531,7 +531,8 @@ public class ClusterBasedJobCoordinator {\n    * @return {@link ClusterBasedJobCoordinator}\n    */\n   // TODO SAMZA-2432: Clean this up once SAMZA-2405 is completed when legacy flow is removed.\n-  public static ClusterBasedJobCoordinator createFromMetadataStore(Config metadataStoreConfig) {\n+  @VisibleForTesting\n+  static ClusterBasedJobCoordinator createFromMetadataStore(Config metadataStoreConfig) {\n     MetricsRegistryMap metrics = new MetricsRegistryMap();\n \n     CoordinatorStreamStore coordinatorStreamStore = new CoordinatorStreamStore(metadataStoreConfig, metrics);\n", "next_change": {"commit": "d689fd2568ea9dd457ed1c7c9cb193f4ae6fa631", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex d97a4a1e0..6295ed6e9 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -407,181 +448,6 @@ public class ClusterBasedJobCoordinator {\n \n   @VisibleForTesting\n   ContainerProcessManager createContainerProcessManager() {\n-    return new ContainerProcessManager(config, state, metrics);\n-  }\n-\n-  /**\n-   * The entry point for the {@link ClusterBasedJobCoordinator}.\n-   */\n-  public static void main(String[] args) {\n-    boolean dependencyIsolationEnabled = Boolean.parseBoolean(\n-        System.getenv(ShellCommandConfig.ENV_CLUSTER_BASED_JOB_COORDINATOR_DEPENDENCY_ISOLATION_ENABLED()));\n-    if (!dependencyIsolationEnabled) {\n-      // no isolation enabled, so can just execute runClusterBasedJobCoordinator directly\n-      runClusterBasedJobCoordinator(args);\n-    } else {\n-      runWithClassLoader(new IsolatingClassLoaderFactory().buildClassLoader(), args);\n-    }\n-  }\n-\n-  /**\n-   * Execute the coordinator using a separate isolated classloader.\n-   * @param classLoader {@link ClassLoader} to use to load the {@link ClusterBasedJobCoordinator} which will run\n-   * @param args arguments to pass when running the {@link ClusterBasedJobCoordinator}\n-   */\n-  @VisibleForTesting\n-  static void runWithClassLoader(ClassLoader classLoader, String[] args) {\n-    // need to use the isolated classloader to load ClusterBasedJobCoordinator and then run using that new class\n-    Class<?> clusterBasedJobCoordinatorClass;\n-    try {\n-      clusterBasedJobCoordinatorClass = classLoader.loadClass(ClusterBasedJobCoordinator.class.getName());\n-    } catch (ClassNotFoundException e) {\n-      throw new SamzaException(\n-          \"Isolation was enabled, but unable to find ClusterBasedJobCoordinator in isolated classloader\", e);\n-    }\n-\n-    // save the current context classloader so it can be reset after finishing the call to runClusterBasedJobCoordinator\n-    ClassLoader previousContextClassLoader = Thread.currentThread().getContextClassLoader();\n-    // this is needed because certain libraries (e.g. log4j) use the context classloader\n-    Thread.currentThread().setContextClassLoader(classLoader);\n-\n-    try {\n-      executeRunClusterBasedJobCoordinatorForClass(clusterBasedJobCoordinatorClass, args);\n-    } finally {\n-      // reset the context class loader; it's good practice, and could be important when running a test suite\n-      Thread.currentThread().setContextClassLoader(previousContextClassLoader);\n-    }\n-  }\n-\n-  /**\n-   * Runs the {@link ClusterBasedJobCoordinator#runClusterBasedJobCoordinator(String[])} method of the given\n-   * {@code clusterBasedJobCoordinatorClass} using reflection.\n-   * @param clusterBasedJobCoordinatorClass {@link ClusterBasedJobCoordinator} {@link Class} for which to execute\n-   * {@link ClusterBasedJobCoordinator#runClusterBasedJobCoordinator(String[])}\n-   * @param args arguments to pass to {@link ClusterBasedJobCoordinator#runClusterBasedJobCoordinator(String[])}\n-   */\n-  private static void executeRunClusterBasedJobCoordinatorForClass(Class<?> clusterBasedJobCoordinatorClass,\n-      String[] args) {\n-    Method runClusterBasedJobCoordinatorMethod;\n-    try {\n-      runClusterBasedJobCoordinatorMethod =\n-          clusterBasedJobCoordinatorClass.getDeclaredMethod(\"runClusterBasedJobCoordinator\", String[].class);\n-    } catch (NoSuchMethodException e) {\n-      throw new SamzaException(\"Isolation was enabled, but unable to find runClusterBasedJobCoordinator method\", e);\n-    }\n-    // only sets accessible flag for this Method instance, not other Method instances for runClusterBasedJobCoordinator\n-    runClusterBasedJobCoordinatorMethod.setAccessible(true);\n-\n-    try {\n-      // wrapping args in object array so that args is passed as a single argument to the method\n-      runClusterBasedJobCoordinatorMethod.invoke(null, new Object[]{args});\n-    } catch (IllegalAccessException | InvocationTargetException e) {\n-      throw new SamzaException(\"Exception while executing runClusterBasedJobCoordinator method\", e);\n-    }\n-  }\n-\n-  /**\n-   * This is the actual execution for the {@link ClusterBasedJobCoordinator}. This is separated out from\n-   * {@link #main(String[])} so that it can be executed directly or from a separate classloader.\n-   */\n-  private static void runClusterBasedJobCoordinator(String[] args) {\n-    final String coordinatorSystemEnv = System.getenv(ShellCommandConfig.ENV_COORDINATOR_SYSTEM_CONFIG());\n-    final String submissionEnv = System.getenv(ShellCommandConfig.ENV_SUBMISSION_CONFIG());\n-\n-    if (!StringUtils.isBlank(submissionEnv)) {\n-      Config submissionConfig;\n-      try {\n-        //Read and parse the coordinator system config.\n-        LOG.info(\"Parsing submission config {}\", submissionEnv);\n-        submissionConfig =\n-            new MapConfig(SamzaObjectMapper.getObjectMapper().readValue(submissionEnv, Config.class));\n-        LOG.info(\"Using the submission config: {}.\", submissionConfig);\n-      } catch (IOException e) {\n-        LOG.error(\"Exception while reading submission config\", e);\n-        throw new SamzaException(e);\n-      }\n-\n-      ClusterBasedJobCoordinator jc = createFromConfigLoader(submissionConfig);\n-      jc.run();\n-      LOG.info(\"Finished running ClusterBasedJobCoordinator\");\n-    } else {\n-      // TODO: Clean this up once SAMZA-2405 is completed when legacy flow is removed.\n-      Config coordinatorSystemConfig;\n-      try {\n-        //Read and parse the coordinator system config.\n-        LOG.info(\"Parsing coordinator system config {}\", coordinatorSystemEnv);\n-        coordinatorSystemConfig =\n-            new MapConfig(SamzaObjectMapper.getObjectMapper().readValue(coordinatorSystemEnv, Config.class));\n-        LOG.info(\"Using the coordinator system config: {}.\", coordinatorSystemConfig);\n-      } catch (IOException e) {\n-        LOG.error(\"Exception while reading coordinator stream config\", e);\n-        throw new SamzaException(e);\n-      }\n-      ClusterBasedJobCoordinator jc = createFromMetadataStore(coordinatorSystemConfig);\n-      jc.run();\n-      LOG.info(\"Finished running ClusterBasedJobCoordinator\");\n-    }\n-  }\n-\n-  /**\n-   * Initialize {@link ClusterBasedJobCoordinator} with coordinator stream config, full job config will be fetched from\n-   * coordinator stream.\n-   *\n-   * @param metadataStoreConfig to initialize {@link MetadataStore}\n-   * @return {@link ClusterBasedJobCoordinator}\n-   */\n-  // TODO SAMZA-2432: Clean this up once SAMZA-2405 is completed when legacy flow is removed.\n-  @VisibleForTesting\n-  static ClusterBasedJobCoordinator createFromMetadataStore(Config metadataStoreConfig) {\n-    MetricsRegistryMap metrics = new MetricsRegistryMap();\n-\n-    CoordinatorStreamStore coordinatorStreamStore = new CoordinatorStreamStore(metadataStoreConfig, metrics);\n-    coordinatorStreamStore.init();\n-    Config config = CoordinatorStreamUtil.readConfigFromCoordinatorStream(coordinatorStreamStore);\n-\n-    return new ClusterBasedJobCoordinator(metrics, coordinatorStreamStore, config);\n-  }\n-\n-  /**\n-   * Initialize {@link ClusterBasedJobCoordinator} with submission config, full job config will be fetched using\n-   * specified {@link org.apache.samza.config.ConfigLoaderFactory}\n-   *\n-   * @param submissionConfig specifies {@link org.apache.samza.config.ConfigLoaderFactory}\n-   * @return {@link ClusterBasedJobCoordinator}\n-   */\n-  @VisibleForTesting\n-  static ClusterBasedJobCoordinator createFromConfigLoader(Config submissionConfig) {\n-    JobConfig jobConfig = new JobConfig(submissionConfig);\n-\n-    if (!jobConfig.getConfigLoaderFactory().isPresent()) {\n-      throw new SamzaException(JobConfig.CONFIG_LOADER_FACTORY + \" is required to initialize job coordinator from config loader\");\n-    }\n-\n-    MetricsRegistryMap metrics = new MetricsRegistryMap();\n-    // load full job config with ConfigLoader\n-    Config originalConfig = ConfigUtil.loadConfig(submissionConfig);\n-\n-    // Execute planning\n-    ApplicationDescriptorImpl<? extends ApplicationDescriptor>\n-        appDesc = ApplicationDescriptorUtil.getAppDescriptor(ApplicationUtil.fromConfig(originalConfig), originalConfig);\n-    RemoteJobPlanner planner = new RemoteJobPlanner(appDesc);\n-    List<JobConfig> jobConfigs = planner.prepareJobs();\n-\n-    if (jobConfigs.size() != 1) {\n-      throw new SamzaException(\"Only support single remote job is supported.\");\n-    }\n-\n-    Config config = jobConfigs.get(0);\n-\n-    // This needs to be consistent with RemoteApplicationRunner#run where JobRunner#submit to be called instead of JobRunner#run\n-    CoordinatorStreamUtil.writeConfigToCoordinatorStream(config, true);\n-    DiagnosticsUtil.createDiagnosticsStream(config);\n-    MetadataStore metadataStore = new CoordinatorStreamStore(CoordinatorStreamUtil.buildCoordinatorStreamConfig(config), metrics);\n-    metadataStore.init();\n-\n-    return new ClusterBasedJobCoordinator(\n-        metrics,\n-        metadataStore,\n-        config);\n+    return new ContainerProcessManager(config, state, metrics, containerPlacementMetadataStore, localityManager);\n   }\n }\n", "next_change": {"commit": "108768393960a893f9d202edf50bf47d2b1af590", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex 6295ed6e9..08bcfda8f 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -448,6 +485,39 @@ public class ClusterBasedJobCoordinator {\n \n   @VisibleForTesting\n   ContainerProcessManager createContainerProcessManager() {\n-    return new ContainerProcessManager(config, state, metrics, containerPlacementMetadataStore, localityManager);\n+    return new ContainerProcessManager(config, state, metrics, containerPlacementMetadataStore, localityManager,\n+        metadataChangedAcrossAttempts);\n+  }\n+\n+  @VisibleForTesting\n+  JobCoordinatorMetadataManager createJobCoordinatorMetadataManager() {\n+    return new JobCoordinatorMetadataManager(new NamespaceAwareCoordinatorStreamStore(metadataStore,\n+        SetJobCoordinatorMetadataMessage.TYPE), JobCoordinatorMetadataManager.ClusterType.YARN, metrics);\n+  }\n+\n+  @VisibleForTesting\n+  boolean isApplicationMasterHighAvailabilityEnabled() {\n+    return new JobConfig(config).getApplicationMasterHighAvailabilityEnabled();\n+  }\n+\n+  @VisibleForTesting\n+  boolean isMetadataChangedAcrossAttempts() {\n+    return metadataChangedAcrossAttempts;\n+  }\n+\n+  /**\n+   * We only fanout startpoint if and only if\n+   *  1. Startpoint is enabled\n+   *  2. If AM HA is enabled, fanout only if startpoint enabled and job coordinator metadata changed\n+   *\n+   * @return true if it satisfies above conditions, false otherwise\n+   */\n+  @VisibleForTesting\n+  boolean shouldFanoutStartpoint() {\n+    JobConfig jobConfig = new JobConfig(config);\n+    boolean startpointEnabled = jobConfig.getStartpointEnabled();\n+\n+    return isApplicationMasterHighAvailabilityEnabled() ?\n+        startpointEnabled && isMetadataChangedAcrossAttempts() : startpointEnabled;\n   }\n }\n", "next_change": null}]}}]}}]}, "commits_in_main": [{"oid": "5bef72595faa8c8cdc9e35b09342e36a5085c10b", "message": "Merge commit", "committedDate": null}, {"oid": "b379933d62c8cb438f0599e2540bce6b63e8c014", "committedDate": "2020-01-21 15:37:07 -0800", "message": "SAMZA-2404: [SEP-22] Container Placement Handler for dispatching container placement messages between metastore and JobCoordinator (#1227)"}, {"oid": "b4a9fe67238d6eb81b2c61177cafd276ade67c07", "committedDate": "2020-02-18 12:32:05 -0800", "message": "SAMZA-2402: Tie Container placement service and Container placement handler and validate placement requests (#1267)"}, {"oid": "e4eefe2a9b7d6559ee5ce236e5357d773c199816", "committedDate": "2020-03-10 13:20:39 -0700", "message": "SAMZA-2453: Update ClusterBasedJobCoordinator to support Beam jobs (#1309)"}, {"oid": "d6608714c211835c3b04caaaa49882455135158c", "committedDate": "2020-03-11 13:44:21 -0700", "message": "SAMZA-2466: [Scala cleanup] Convert ShellCommandConfig from scala to java (#1288)"}, {"oid": "b7cab952317bd4320f12e18c2cc3e3cee77770da", "committedDate": "2020-03-17 19:20:52 -0700", "message": "SAMZA-2488: Add JobCoordinatorLaunchUtil to handle common logic when launching job coordiantor. (#1318)"}, {"oid": "c527ec5a151e0da570dfdc3896c30694ac7c34f6", "committedDate": "2020-03-27 22:36:05 -0700", "message": "SAMZA-2491: AM should log uncaught exceptions and System.exit to ensure that the process dies on errors (#1325)"}, {"oid": "26d9eecac76f3b87610312d0066d96a5b36eef35", "committedDate": "2020-04-01 16:43:05 -0700", "message": "SAMZA-2501 : Optimizing startpoint manager to not make successive bootstrapMessage calls to coordinator-store (#1335)"}, {"oid": "d745e7d1cbd051002b30bfe99ae924d48ff96eaa", "committedDate": "2020-04-16 13:48:29 -0700", "message": "SAMZA-2509: New config name to represent if split deployment feature is enabled (#1342)"}, {"oid": "e86951f102c7a854d343b1f80dc2796be29c9c81", "committedDate": "2020-04-24 09:40:25 -0700", "message": "SAMZA-2514: Refactor codes to make runWithClassLoader method more generic (#1349)"}, {"oid": "5f05cdde2eea46a8cbda08dd8c9868c8f46a4e9d", "committedDate": "2020-06-22 15:52:51 -0700", "message": "SAMZA-2551: Upgrade all modules to automatically use checkstyle 6.11.2 (part 1: includes samza-core) (#1389)"}, {"oid": "f7f9f3c7905b047f262383bcc64ebb01ab73f421", "committedDate": "2020-08-26 19:39:32 -0700", "message": "SAMZA-2439: Remove LocalityManager and container location information from JobModel (#1421)"}, {"oid": "d689fd2568ea9dd457ed1c7c9cb193f4ae6fa631", "committedDate": "2020-09-02 15:10:42 -0700", "message": "SAMZA-2584: Refactor ClusterBasedJobCoordinator (#1424)"}, {"oid": "42e68e88c4dfe4c891dd601ee98f190d598decfd", "committedDate": "2020-09-15 21:50:40 -0700", "message": "SAMZA-2574 : improve flexibility of SystemFactory interface"}, {"oid": "c212cac420864d09f2663da2e51c23e4718d6812", "committedDate": "2020-11-30 23:37:21 -0800", "message": "SAMZA-2604: Datamodel change to capture physical container id for AM HA (#1445)"}, {"oid": "108768393960a893f9d202edf50bf47d2b1af590", "committedDate": "2020-12-09 09:33:11 -0800", "message": "SAMZA-2610: Handle Metadata changes for AM HA orchestration (#1450)"}, {"oid": "7cc4eaa96fff244f6dce9c18af804917db7c3b2b", "committedDate": "2021-05-25 16:00:46 -0700", "message": "SAMZA-2657: Blob Store as backend for Samza State backup and restore (#1501)"}, {"oid": "120098d6c45ca023d2a0fb144b0e333ab4e8ffe8", "committedDate": "2021-08-24 14:08:17 -0700", "message": "SAMZA-2670: Update granularity of JobCoordinatorMetadataManager.checkForMetadataChanges and epoch id extraction (#1519)"}, {"oid": "27b1495589e992cf1606ebfc2e34699077d60b73", "committedDate": "2021-08-30 14:26:40 -0700", "message": "SAMZA-2672: Extract creation of stream monitors into separate classes for reuse (#1520)"}, {"oid": "493de64bb8c0228bbda11822ae3c84c2085263bf", "committedDate": "2022-06-13 15:06:05 -0700", "message": "SAMZA-2742: [Pipeline Drain] Add Drain components and integrate them with SamzaContainer and JC (#1605)"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA2ODUyMg==", "url": "https://github.com/apache/samza/pull/1248#discussion_r368068522", "body": "Does this need to be public? If you need in tests, could you make it package private and mark as `VisibleForTesting`?", "bodyText": "Does this need to be public? If you need in tests, could you make it package private and mark as VisibleForTesting?", "bodyHTML": "<p dir=\"auto\">Does this need to be public? If you need in tests, could you make it package private and mark as <code>VisibleForTesting</code>?</p>", "author": "cameronlee314", "createdAt": "2020-01-17T18:12:48Z", "path": "samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java", "diffHunk": "@@ -480,20 +485,101 @@ private static void executeRunClusterBasedJobCoordinatorForClass(Class<?> cluste\n    * {@link #main(String[])} so that it can be executed directly or from a separate classloader.\n    */\n   private static void runClusterBasedJobCoordinator(String[] args) {\n-    Config coordinatorSystemConfig;\n     final String coordinatorSystemEnv = System.getenv(ShellCommandConfig.ENV_COORDINATOR_SYSTEM_CONFIG());\n-    try {\n-      //Read and parse the coordinator system config.\n-      LOG.info(\"Parsing coordinator system config {}\", coordinatorSystemEnv);\n-      coordinatorSystemConfig =\n-          new MapConfig(SamzaObjectMapper.getObjectMapper().readValue(coordinatorSystemEnv, Config.class));\n-      LOG.info(\"Using the coordinator system config: {}.\", coordinatorSystemConfig);\n-    } catch (IOException e) {\n-      LOG.error(\"Exception while reading coordinator stream config\", e);\n-      throw new SamzaException(e);\n+    final String submissionEnv = System.getenv(ShellCommandConfig.ENV_SUBMISSION_CONFIG());\n+\n+    if (submissionEnv != null) {\n+      Config submissionConfig;\n+      try {\n+        //Read and parse the coordinator system config.\n+        LOG.info(\"Parsing submission config {}\", submissionEnv);\n+        submissionConfig =\n+            new MapConfig(SamzaObjectMapper.getObjectMapper().readValue(submissionEnv, Config.class));\n+        LOG.info(\"Using the submission config: {}.\", submissionConfig);\n+      } catch (IOException e) {\n+        LOG.error(\"Exception while reading submission config\", e);\n+        throw new SamzaException(e);\n+      }\n+\n+      ClusterBasedJobCoordinator jc = createFromConfigLoader(submissionConfig);\n+      jc.run();\n+      LOG.info(\"Finished running ClusterBasedJobCoordinator\");\n+    } else {\n+      // TODO: Clean this up once SAMZA-2405 is completed when legacy flow is removed.\n+      Config coordinatorSystemConfig;\n+      try {\n+        //Read and parse the coordinator system config.\n+        LOG.info(\"Parsing coordinator system config {}\", coordinatorSystemEnv);\n+        coordinatorSystemConfig =\n+            new MapConfig(SamzaObjectMapper.getObjectMapper().readValue(coordinatorSystemEnv, Config.class));\n+        LOG.info(\"Using the coordinator system config: {}.\", coordinatorSystemConfig);\n+      } catch (IOException e) {\n+        LOG.error(\"Exception while reading coordinator stream config\", e);\n+        throw new SamzaException(e);\n+      }\n+      ClusterBasedJobCoordinator jc = createFromMetadataStore(coordinatorSystemConfig);\n+      jc.run();\n+      LOG.info(\"Finished running ClusterBasedJobCoordinator\");\n+    }\n+  }\n+\n+  /**\n+   * Initialize {@link ClusterBasedJobCoordinator} with coordinator stream config, full job config will be fetched from\n+   * coordinator stream.\n+   *\n+   * @param metadataStoreConfig to initialize {@link MetadataStore}\n+   * @return {@link ClusterBasedJobCoordinator}\n+   */\n+  // TODO SAMZA-2432: Clean this up once SAMZA-2405 is completed when legacy flow is removed.\n+  public static ClusterBasedJobCoordinator createFromMetadataStore(Config metadataStoreConfig) {", "originalCommit": "de8ed411e5118dce7ce4f6587379fb29a36495ef", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA3NzY3OA==", "url": "https://github.com/apache/samza/pull/1248#discussion_r368077678", "bodyText": "Update to private.", "author": "kw2542", "createdAt": "2020-01-17T18:35:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA2ODUyMg=="}], "type": "inlineReview", "revised_code": {"commit": "27210d8aa49b6497400604aab47d722563ff59b4", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex d22e694d7..5dd3a64e4 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -531,7 +531,8 @@ public class ClusterBasedJobCoordinator {\n    * @return {@link ClusterBasedJobCoordinator}\n    */\n   // TODO SAMZA-2432: Clean this up once SAMZA-2405 is completed when legacy flow is removed.\n-  public static ClusterBasedJobCoordinator createFromMetadataStore(Config metadataStoreConfig) {\n+  @VisibleForTesting\n+  static ClusterBasedJobCoordinator createFromMetadataStore(Config metadataStoreConfig) {\n     MetricsRegistryMap metrics = new MetricsRegistryMap();\n \n     CoordinatorStreamStore coordinatorStreamStore = new CoordinatorStreamStore(metadataStoreConfig, metrics);\n", "next_change": null}]}, "revised_code_in_main": {"commit": "5bef72595faa8c8cdc9e35b09342e36a5085c10b", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex d22e694d7..d97a4a1e0 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -531,7 +531,8 @@ public class ClusterBasedJobCoordinator {\n    * @return {@link ClusterBasedJobCoordinator}\n    */\n   // TODO SAMZA-2432: Clean this up once SAMZA-2405 is completed when legacy flow is removed.\n-  public static ClusterBasedJobCoordinator createFromMetadataStore(Config metadataStoreConfig) {\n+  @VisibleForTesting\n+  static ClusterBasedJobCoordinator createFromMetadataStore(Config metadataStoreConfig) {\n     MetricsRegistryMap metrics = new MetricsRegistryMap();\n \n     CoordinatorStreamStore coordinatorStreamStore = new CoordinatorStreamStore(metadataStoreConfig, metrics);\n", "next_change": {"commit": "d689fd2568ea9dd457ed1c7c9cb193f4ae6fa631", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex d97a4a1e0..6295ed6e9 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -407,181 +448,6 @@ public class ClusterBasedJobCoordinator {\n \n   @VisibleForTesting\n   ContainerProcessManager createContainerProcessManager() {\n-    return new ContainerProcessManager(config, state, metrics);\n-  }\n-\n-  /**\n-   * The entry point for the {@link ClusterBasedJobCoordinator}.\n-   */\n-  public static void main(String[] args) {\n-    boolean dependencyIsolationEnabled = Boolean.parseBoolean(\n-        System.getenv(ShellCommandConfig.ENV_CLUSTER_BASED_JOB_COORDINATOR_DEPENDENCY_ISOLATION_ENABLED()));\n-    if (!dependencyIsolationEnabled) {\n-      // no isolation enabled, so can just execute runClusterBasedJobCoordinator directly\n-      runClusterBasedJobCoordinator(args);\n-    } else {\n-      runWithClassLoader(new IsolatingClassLoaderFactory().buildClassLoader(), args);\n-    }\n-  }\n-\n-  /**\n-   * Execute the coordinator using a separate isolated classloader.\n-   * @param classLoader {@link ClassLoader} to use to load the {@link ClusterBasedJobCoordinator} which will run\n-   * @param args arguments to pass when running the {@link ClusterBasedJobCoordinator}\n-   */\n-  @VisibleForTesting\n-  static void runWithClassLoader(ClassLoader classLoader, String[] args) {\n-    // need to use the isolated classloader to load ClusterBasedJobCoordinator and then run using that new class\n-    Class<?> clusterBasedJobCoordinatorClass;\n-    try {\n-      clusterBasedJobCoordinatorClass = classLoader.loadClass(ClusterBasedJobCoordinator.class.getName());\n-    } catch (ClassNotFoundException e) {\n-      throw new SamzaException(\n-          \"Isolation was enabled, but unable to find ClusterBasedJobCoordinator in isolated classloader\", e);\n-    }\n-\n-    // save the current context classloader so it can be reset after finishing the call to runClusterBasedJobCoordinator\n-    ClassLoader previousContextClassLoader = Thread.currentThread().getContextClassLoader();\n-    // this is needed because certain libraries (e.g. log4j) use the context classloader\n-    Thread.currentThread().setContextClassLoader(classLoader);\n-\n-    try {\n-      executeRunClusterBasedJobCoordinatorForClass(clusterBasedJobCoordinatorClass, args);\n-    } finally {\n-      // reset the context class loader; it's good practice, and could be important when running a test suite\n-      Thread.currentThread().setContextClassLoader(previousContextClassLoader);\n-    }\n-  }\n-\n-  /**\n-   * Runs the {@link ClusterBasedJobCoordinator#runClusterBasedJobCoordinator(String[])} method of the given\n-   * {@code clusterBasedJobCoordinatorClass} using reflection.\n-   * @param clusterBasedJobCoordinatorClass {@link ClusterBasedJobCoordinator} {@link Class} for which to execute\n-   * {@link ClusterBasedJobCoordinator#runClusterBasedJobCoordinator(String[])}\n-   * @param args arguments to pass to {@link ClusterBasedJobCoordinator#runClusterBasedJobCoordinator(String[])}\n-   */\n-  private static void executeRunClusterBasedJobCoordinatorForClass(Class<?> clusterBasedJobCoordinatorClass,\n-      String[] args) {\n-    Method runClusterBasedJobCoordinatorMethod;\n-    try {\n-      runClusterBasedJobCoordinatorMethod =\n-          clusterBasedJobCoordinatorClass.getDeclaredMethod(\"runClusterBasedJobCoordinator\", String[].class);\n-    } catch (NoSuchMethodException e) {\n-      throw new SamzaException(\"Isolation was enabled, but unable to find runClusterBasedJobCoordinator method\", e);\n-    }\n-    // only sets accessible flag for this Method instance, not other Method instances for runClusterBasedJobCoordinator\n-    runClusterBasedJobCoordinatorMethod.setAccessible(true);\n-\n-    try {\n-      // wrapping args in object array so that args is passed as a single argument to the method\n-      runClusterBasedJobCoordinatorMethod.invoke(null, new Object[]{args});\n-    } catch (IllegalAccessException | InvocationTargetException e) {\n-      throw new SamzaException(\"Exception while executing runClusterBasedJobCoordinator method\", e);\n-    }\n-  }\n-\n-  /**\n-   * This is the actual execution for the {@link ClusterBasedJobCoordinator}. This is separated out from\n-   * {@link #main(String[])} so that it can be executed directly or from a separate classloader.\n-   */\n-  private static void runClusterBasedJobCoordinator(String[] args) {\n-    final String coordinatorSystemEnv = System.getenv(ShellCommandConfig.ENV_COORDINATOR_SYSTEM_CONFIG());\n-    final String submissionEnv = System.getenv(ShellCommandConfig.ENV_SUBMISSION_CONFIG());\n-\n-    if (!StringUtils.isBlank(submissionEnv)) {\n-      Config submissionConfig;\n-      try {\n-        //Read and parse the coordinator system config.\n-        LOG.info(\"Parsing submission config {}\", submissionEnv);\n-        submissionConfig =\n-            new MapConfig(SamzaObjectMapper.getObjectMapper().readValue(submissionEnv, Config.class));\n-        LOG.info(\"Using the submission config: {}.\", submissionConfig);\n-      } catch (IOException e) {\n-        LOG.error(\"Exception while reading submission config\", e);\n-        throw new SamzaException(e);\n-      }\n-\n-      ClusterBasedJobCoordinator jc = createFromConfigLoader(submissionConfig);\n-      jc.run();\n-      LOG.info(\"Finished running ClusterBasedJobCoordinator\");\n-    } else {\n-      // TODO: Clean this up once SAMZA-2405 is completed when legacy flow is removed.\n-      Config coordinatorSystemConfig;\n-      try {\n-        //Read and parse the coordinator system config.\n-        LOG.info(\"Parsing coordinator system config {}\", coordinatorSystemEnv);\n-        coordinatorSystemConfig =\n-            new MapConfig(SamzaObjectMapper.getObjectMapper().readValue(coordinatorSystemEnv, Config.class));\n-        LOG.info(\"Using the coordinator system config: {}.\", coordinatorSystemConfig);\n-      } catch (IOException e) {\n-        LOG.error(\"Exception while reading coordinator stream config\", e);\n-        throw new SamzaException(e);\n-      }\n-      ClusterBasedJobCoordinator jc = createFromMetadataStore(coordinatorSystemConfig);\n-      jc.run();\n-      LOG.info(\"Finished running ClusterBasedJobCoordinator\");\n-    }\n-  }\n-\n-  /**\n-   * Initialize {@link ClusterBasedJobCoordinator} with coordinator stream config, full job config will be fetched from\n-   * coordinator stream.\n-   *\n-   * @param metadataStoreConfig to initialize {@link MetadataStore}\n-   * @return {@link ClusterBasedJobCoordinator}\n-   */\n-  // TODO SAMZA-2432: Clean this up once SAMZA-2405 is completed when legacy flow is removed.\n-  @VisibleForTesting\n-  static ClusterBasedJobCoordinator createFromMetadataStore(Config metadataStoreConfig) {\n-    MetricsRegistryMap metrics = new MetricsRegistryMap();\n-\n-    CoordinatorStreamStore coordinatorStreamStore = new CoordinatorStreamStore(metadataStoreConfig, metrics);\n-    coordinatorStreamStore.init();\n-    Config config = CoordinatorStreamUtil.readConfigFromCoordinatorStream(coordinatorStreamStore);\n-\n-    return new ClusterBasedJobCoordinator(metrics, coordinatorStreamStore, config);\n-  }\n-\n-  /**\n-   * Initialize {@link ClusterBasedJobCoordinator} with submission config, full job config will be fetched using\n-   * specified {@link org.apache.samza.config.ConfigLoaderFactory}\n-   *\n-   * @param submissionConfig specifies {@link org.apache.samza.config.ConfigLoaderFactory}\n-   * @return {@link ClusterBasedJobCoordinator}\n-   */\n-  @VisibleForTesting\n-  static ClusterBasedJobCoordinator createFromConfigLoader(Config submissionConfig) {\n-    JobConfig jobConfig = new JobConfig(submissionConfig);\n-\n-    if (!jobConfig.getConfigLoaderFactory().isPresent()) {\n-      throw new SamzaException(JobConfig.CONFIG_LOADER_FACTORY + \" is required to initialize job coordinator from config loader\");\n-    }\n-\n-    MetricsRegistryMap metrics = new MetricsRegistryMap();\n-    // load full job config with ConfigLoader\n-    Config originalConfig = ConfigUtil.loadConfig(submissionConfig);\n-\n-    // Execute planning\n-    ApplicationDescriptorImpl<? extends ApplicationDescriptor>\n-        appDesc = ApplicationDescriptorUtil.getAppDescriptor(ApplicationUtil.fromConfig(originalConfig), originalConfig);\n-    RemoteJobPlanner planner = new RemoteJobPlanner(appDesc);\n-    List<JobConfig> jobConfigs = planner.prepareJobs();\n-\n-    if (jobConfigs.size() != 1) {\n-      throw new SamzaException(\"Only support single remote job is supported.\");\n-    }\n-\n-    Config config = jobConfigs.get(0);\n-\n-    // This needs to be consistent with RemoteApplicationRunner#run where JobRunner#submit to be called instead of JobRunner#run\n-    CoordinatorStreamUtil.writeConfigToCoordinatorStream(config, true);\n-    DiagnosticsUtil.createDiagnosticsStream(config);\n-    MetadataStore metadataStore = new CoordinatorStreamStore(CoordinatorStreamUtil.buildCoordinatorStreamConfig(config), metrics);\n-    metadataStore.init();\n-\n-    return new ClusterBasedJobCoordinator(\n-        metrics,\n-        metadataStore,\n-        config);\n+    return new ContainerProcessManager(config, state, metrics, containerPlacementMetadataStore, localityManager);\n   }\n }\n", "next_change": {"commit": "108768393960a893f9d202edf50bf47d2b1af590", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex 6295ed6e9..08bcfda8f 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -448,6 +485,39 @@ public class ClusterBasedJobCoordinator {\n \n   @VisibleForTesting\n   ContainerProcessManager createContainerProcessManager() {\n-    return new ContainerProcessManager(config, state, metrics, containerPlacementMetadataStore, localityManager);\n+    return new ContainerProcessManager(config, state, metrics, containerPlacementMetadataStore, localityManager,\n+        metadataChangedAcrossAttempts);\n+  }\n+\n+  @VisibleForTesting\n+  JobCoordinatorMetadataManager createJobCoordinatorMetadataManager() {\n+    return new JobCoordinatorMetadataManager(new NamespaceAwareCoordinatorStreamStore(metadataStore,\n+        SetJobCoordinatorMetadataMessage.TYPE), JobCoordinatorMetadataManager.ClusterType.YARN, metrics);\n+  }\n+\n+  @VisibleForTesting\n+  boolean isApplicationMasterHighAvailabilityEnabled() {\n+    return new JobConfig(config).getApplicationMasterHighAvailabilityEnabled();\n+  }\n+\n+  @VisibleForTesting\n+  boolean isMetadataChangedAcrossAttempts() {\n+    return metadataChangedAcrossAttempts;\n+  }\n+\n+  /**\n+   * We only fanout startpoint if and only if\n+   *  1. Startpoint is enabled\n+   *  2. If AM HA is enabled, fanout only if startpoint enabled and job coordinator metadata changed\n+   *\n+   * @return true if it satisfies above conditions, false otherwise\n+   */\n+  @VisibleForTesting\n+  boolean shouldFanoutStartpoint() {\n+    JobConfig jobConfig = new JobConfig(config);\n+    boolean startpointEnabled = jobConfig.getStartpointEnabled();\n+\n+    return isApplicationMasterHighAvailabilityEnabled() ?\n+        startpointEnabled && isMetadataChangedAcrossAttempts() : startpointEnabled;\n   }\n }\n", "next_change": null}]}}]}}]}, "commits_in_main": [{"oid": "5bef72595faa8c8cdc9e35b09342e36a5085c10b", "message": "Merge commit", "committedDate": null}, {"oid": "b379933d62c8cb438f0599e2540bce6b63e8c014", "committedDate": "2020-01-21 15:37:07 -0800", "message": "SAMZA-2404: [SEP-22] Container Placement Handler for dispatching container placement messages between metastore and JobCoordinator (#1227)"}, {"oid": "b4a9fe67238d6eb81b2c61177cafd276ade67c07", "committedDate": "2020-02-18 12:32:05 -0800", "message": "SAMZA-2402: Tie Container placement service and Container placement handler and validate placement requests (#1267)"}, {"oid": "e4eefe2a9b7d6559ee5ce236e5357d773c199816", "committedDate": "2020-03-10 13:20:39 -0700", "message": "SAMZA-2453: Update ClusterBasedJobCoordinator to support Beam jobs (#1309)"}, {"oid": "d6608714c211835c3b04caaaa49882455135158c", "committedDate": "2020-03-11 13:44:21 -0700", "message": "SAMZA-2466: [Scala cleanup] Convert ShellCommandConfig from scala to java (#1288)"}, {"oid": "b7cab952317bd4320f12e18c2cc3e3cee77770da", "committedDate": "2020-03-17 19:20:52 -0700", "message": "SAMZA-2488: Add JobCoordinatorLaunchUtil to handle common logic when launching job coordiantor. (#1318)"}, {"oid": "c527ec5a151e0da570dfdc3896c30694ac7c34f6", "committedDate": "2020-03-27 22:36:05 -0700", "message": "SAMZA-2491: AM should log uncaught exceptions and System.exit to ensure that the process dies on errors (#1325)"}, {"oid": "26d9eecac76f3b87610312d0066d96a5b36eef35", "committedDate": "2020-04-01 16:43:05 -0700", "message": "SAMZA-2501 : Optimizing startpoint manager to not make successive bootstrapMessage calls to coordinator-store (#1335)"}, {"oid": "d745e7d1cbd051002b30bfe99ae924d48ff96eaa", "committedDate": "2020-04-16 13:48:29 -0700", "message": "SAMZA-2509: New config name to represent if split deployment feature is enabled (#1342)"}, {"oid": "e86951f102c7a854d343b1f80dc2796be29c9c81", "committedDate": "2020-04-24 09:40:25 -0700", "message": "SAMZA-2514: Refactor codes to make runWithClassLoader method more generic (#1349)"}, {"oid": "5f05cdde2eea46a8cbda08dd8c9868c8f46a4e9d", "committedDate": "2020-06-22 15:52:51 -0700", "message": "SAMZA-2551: Upgrade all modules to automatically use checkstyle 6.11.2 (part 1: includes samza-core) (#1389)"}, {"oid": "f7f9f3c7905b047f262383bcc64ebb01ab73f421", "committedDate": "2020-08-26 19:39:32 -0700", "message": "SAMZA-2439: Remove LocalityManager and container location information from JobModel (#1421)"}, {"oid": "d689fd2568ea9dd457ed1c7c9cb193f4ae6fa631", "committedDate": "2020-09-02 15:10:42 -0700", "message": "SAMZA-2584: Refactor ClusterBasedJobCoordinator (#1424)"}, {"oid": "42e68e88c4dfe4c891dd601ee98f190d598decfd", "committedDate": "2020-09-15 21:50:40 -0700", "message": "SAMZA-2574 : improve flexibility of SystemFactory interface"}, {"oid": "c212cac420864d09f2663da2e51c23e4718d6812", "committedDate": "2020-11-30 23:37:21 -0800", "message": "SAMZA-2604: Datamodel change to capture physical container id for AM HA (#1445)"}, {"oid": "108768393960a893f9d202edf50bf47d2b1af590", "committedDate": "2020-12-09 09:33:11 -0800", "message": "SAMZA-2610: Handle Metadata changes for AM HA orchestration (#1450)"}, {"oid": "7cc4eaa96fff244f6dce9c18af804917db7c3b2b", "committedDate": "2021-05-25 16:00:46 -0700", "message": "SAMZA-2657: Blob Store as backend for Samza State backup and restore (#1501)"}, {"oid": "120098d6c45ca023d2a0fb144b0e333ab4e8ffe8", "committedDate": "2021-08-24 14:08:17 -0700", "message": "SAMZA-2670: Update granularity of JobCoordinatorMetadataManager.checkForMetadataChanges and epoch id extraction (#1519)"}, {"oid": "27b1495589e992cf1606ebfc2e34699077d60b73", "committedDate": "2021-08-30 14:26:40 -0700", "message": "SAMZA-2672: Extract creation of stream monitors into separate classes for reuse (#1520)"}, {"oid": "493de64bb8c0228bbda11822ae3c84c2085263bf", "committedDate": "2022-06-13 15:06:05 -0700", "message": "SAMZA-2742: [Pipeline Drain] Add Drain components and integrate them with SamzaContainer and JC (#1605)"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA2ODU1MQ==", "url": "https://github.com/apache/samza/pull/1248#discussion_r368068551", "body": "Does this need to be public? If you need in tests, could you make it package private and mark as `VisibleForTesting`?", "bodyText": "Does this need to be public? If you need in tests, could you make it package private and mark as VisibleForTesting?", "bodyHTML": "<p dir=\"auto\">Does this need to be public? If you need in tests, could you make it package private and mark as <code>VisibleForTesting</code>?</p>", "author": "cameronlee314", "createdAt": "2020-01-17T18:12:53Z", "path": "samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java", "diffHunk": "@@ -480,20 +485,101 @@ private static void executeRunClusterBasedJobCoordinatorForClass(Class<?> cluste\n    * {@link #main(String[])} so that it can be executed directly or from a separate classloader.\n    */\n   private static void runClusterBasedJobCoordinator(String[] args) {\n-    Config coordinatorSystemConfig;\n     final String coordinatorSystemEnv = System.getenv(ShellCommandConfig.ENV_COORDINATOR_SYSTEM_CONFIG());\n-    try {\n-      //Read and parse the coordinator system config.\n-      LOG.info(\"Parsing coordinator system config {}\", coordinatorSystemEnv);\n-      coordinatorSystemConfig =\n-          new MapConfig(SamzaObjectMapper.getObjectMapper().readValue(coordinatorSystemEnv, Config.class));\n-      LOG.info(\"Using the coordinator system config: {}.\", coordinatorSystemConfig);\n-    } catch (IOException e) {\n-      LOG.error(\"Exception while reading coordinator stream config\", e);\n-      throw new SamzaException(e);\n+    final String submissionEnv = System.getenv(ShellCommandConfig.ENV_SUBMISSION_CONFIG());\n+\n+    if (submissionEnv != null) {\n+      Config submissionConfig;\n+      try {\n+        //Read and parse the coordinator system config.\n+        LOG.info(\"Parsing submission config {}\", submissionEnv);\n+        submissionConfig =\n+            new MapConfig(SamzaObjectMapper.getObjectMapper().readValue(submissionEnv, Config.class));\n+        LOG.info(\"Using the submission config: {}.\", submissionConfig);\n+      } catch (IOException e) {\n+        LOG.error(\"Exception while reading submission config\", e);\n+        throw new SamzaException(e);\n+      }\n+\n+      ClusterBasedJobCoordinator jc = createFromConfigLoader(submissionConfig);\n+      jc.run();\n+      LOG.info(\"Finished running ClusterBasedJobCoordinator\");\n+    } else {\n+      // TODO: Clean this up once SAMZA-2405 is completed when legacy flow is removed.\n+      Config coordinatorSystemConfig;\n+      try {\n+        //Read and parse the coordinator system config.\n+        LOG.info(\"Parsing coordinator system config {}\", coordinatorSystemEnv);\n+        coordinatorSystemConfig =\n+            new MapConfig(SamzaObjectMapper.getObjectMapper().readValue(coordinatorSystemEnv, Config.class));\n+        LOG.info(\"Using the coordinator system config: {}.\", coordinatorSystemConfig);\n+      } catch (IOException e) {\n+        LOG.error(\"Exception while reading coordinator stream config\", e);\n+        throw new SamzaException(e);\n+      }\n+      ClusterBasedJobCoordinator jc = createFromMetadataStore(coordinatorSystemConfig);\n+      jc.run();\n+      LOG.info(\"Finished running ClusterBasedJobCoordinator\");\n+    }\n+  }\n+\n+  /**\n+   * Initialize {@link ClusterBasedJobCoordinator} with coordinator stream config, full job config will be fetched from\n+   * coordinator stream.\n+   *\n+   * @param metadataStoreConfig to initialize {@link MetadataStore}\n+   * @return {@link ClusterBasedJobCoordinator}\n+   */\n+  // TODO SAMZA-2432: Clean this up once SAMZA-2405 is completed when legacy flow is removed.\n+  public static ClusterBasedJobCoordinator createFromMetadataStore(Config metadataStoreConfig) {\n+    MetricsRegistryMap metrics = new MetricsRegistryMap();\n+\n+    CoordinatorStreamStore coordinatorStreamStore = new CoordinatorStreamStore(metadataStoreConfig, metrics);\n+    coordinatorStreamStore.init();\n+    Config config = CoordinatorStreamUtil.readConfigFromCoordinatorStream(coordinatorStreamStore);\n+\n+    return new ClusterBasedJobCoordinator(metrics, coordinatorStreamStore, config);\n+  }\n+\n+  /**\n+   * Initialize {@link ClusterBasedJobCoordinator} with submission config, full job config will be fetched using\n+   * specified {@link org.apache.samza.config.ConfigLoaderFactory}\n+   *\n+   * @param submissionConfig specifies {@link org.apache.samza.config.ConfigLoaderFactory}\n+   * @return {@link ClusterBasedJobCoordinator}\n+   */\n+  public static ClusterBasedJobCoordinator createFromConfigLoader(Config submissionConfig) {", "originalCommit": "de8ed411e5118dce7ce4f6587379fb29a36495ef", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA3ODAyNA==", "url": "https://github.com/apache/samza/pull/1248#discussion_r368078024", "bodyText": "Update to package private and mark as VisibleForTesting", "author": "kw2542", "createdAt": "2020-01-17T18:36:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA2ODU1MQ=="}], "type": "inlineReview", "revised_code": {"commit": "27210d8aa49b6497400604aab47d722563ff59b4", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex d22e694d7..5dd3a64e4 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -548,7 +549,8 @@ public class ClusterBasedJobCoordinator {\n    * @param submissionConfig specifies {@link org.apache.samza.config.ConfigLoaderFactory}\n    * @return {@link ClusterBasedJobCoordinator}\n    */\n-  public static ClusterBasedJobCoordinator createFromConfigLoader(Config submissionConfig) {\n+  @VisibleForTesting\n+  static ClusterBasedJobCoordinator createFromConfigLoader(Config submissionConfig) {\n     JobConfig jobConfig = new JobConfig(submissionConfig);\n \n     if (!jobConfig.getConfigLoaderFactory().isPresent()) {\n", "next_change": {"commit": "762fa7de922655c2479e44d8f9470f5944d774c4", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex 5dd3a64e4..d97a4a1e0 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -559,7 +559,19 @@ public class ClusterBasedJobCoordinator {\n \n     MetricsRegistryMap metrics = new MetricsRegistryMap();\n     // load full job config with ConfigLoader\n-    Config config = prepareJob(ConfigUtil.loadConfig(submissionConfig));\n+    Config originalConfig = ConfigUtil.loadConfig(submissionConfig);\n+\n+    // Execute planning\n+    ApplicationDescriptorImpl<? extends ApplicationDescriptor>\n+        appDesc = ApplicationDescriptorUtil.getAppDescriptor(ApplicationUtil.fromConfig(originalConfig), originalConfig);\n+    RemoteJobPlanner planner = new RemoteJobPlanner(appDesc);\n+    List<JobConfig> jobConfigs = planner.prepareJobs();\n+\n+    if (jobConfigs.size() != 1) {\n+      throw new SamzaException(\"Only support single remote job is supported.\");\n+    }\n+\n+    Config config = jobConfigs.get(0);\n \n     // This needs to be consistent with RemoteApplicationRunner#run where JobRunner#submit to be called instead of JobRunner#run\n     CoordinatorStreamUtil.writeConfigToCoordinatorStream(config, true);\n", "next_change": null}]}}]}, "revised_code_in_main": {"commit": "5bef72595faa8c8cdc9e35b09342e36a5085c10b", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex d22e694d7..d97a4a1e0 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -548,7 +549,8 @@ public class ClusterBasedJobCoordinator {\n    * @param submissionConfig specifies {@link org.apache.samza.config.ConfigLoaderFactory}\n    * @return {@link ClusterBasedJobCoordinator}\n    */\n-  public static ClusterBasedJobCoordinator createFromConfigLoader(Config submissionConfig) {\n+  @VisibleForTesting\n+  static ClusterBasedJobCoordinator createFromConfigLoader(Config submissionConfig) {\n     JobConfig jobConfig = new JobConfig(submissionConfig);\n \n     if (!jobConfig.getConfigLoaderFactory().isPresent()) {\n", "next_change": {"commit": "b7cab952317bd4320f12e18c2cc3e3cee77770da", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex d97a4a1e0..e7647f40f 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -543,45 +619,32 @@ public class ClusterBasedJobCoordinator {\n   }\n \n   /**\n-   * Initialize {@link ClusterBasedJobCoordinator} with submission config, full job config will be fetched using\n-   * specified {@link org.apache.samza.config.ConfigLoaderFactory}\n+   * Convert Samza config to command line arguments to invoke app.main.class\n    *\n-   * @param submissionConfig specifies {@link org.apache.samza.config.ConfigLoaderFactory}\n-   * @return {@link ClusterBasedJobCoordinator}\n+   * @param config Samza config to convert.\n+   * @return converted command line arguments.\n    */\n   @VisibleForTesting\n-  static ClusterBasedJobCoordinator createFromConfigLoader(Config submissionConfig) {\n-    JobConfig jobConfig = new JobConfig(submissionConfig);\n-\n-    if (!jobConfig.getConfigLoaderFactory().isPresent()) {\n-      throw new SamzaException(JobConfig.CONFIG_LOADER_FACTORY + \" is required to initialize job coordinator from config loader\");\n-    }\n-\n-    MetricsRegistryMap metrics = new MetricsRegistryMap();\n-    // load full job config with ConfigLoader\n-    Config originalConfig = ConfigUtil.loadConfig(submissionConfig);\n-\n-    // Execute planning\n-    ApplicationDescriptorImpl<? extends ApplicationDescriptor>\n-        appDesc = ApplicationDescriptorUtil.getAppDescriptor(ApplicationUtil.fromConfig(originalConfig), originalConfig);\n-    RemoteJobPlanner planner = new RemoteJobPlanner(appDesc);\n-    List<JobConfig> jobConfigs = planner.prepareJobs();\n-\n-    if (jobConfigs.size() != 1) {\n-      throw new SamzaException(\"Only support single remote job is supported.\");\n-    }\n-\n-    Config config = jobConfigs.get(0);\n-\n-    // This needs to be consistent with RemoteApplicationRunner#run where JobRunner#submit to be called instead of JobRunner#run\n-    CoordinatorStreamUtil.writeConfigToCoordinatorStream(config, true);\n-    DiagnosticsUtil.createDiagnosticsStream(config);\n-    MetadataStore metadataStore = new CoordinatorStreamStore(CoordinatorStreamUtil.buildCoordinatorStreamConfig(config), metrics);\n-    metadataStore.init();\n+  static String[] toArgs(ApplicationConfig config) {\n+    List<String> args = new ArrayList<>(config.size() * 2);\n+\n+    config.forEach((key, value) -> {\n+        if (key.equals(ApplicationConfig.APP_MAIN_ARGS)) {\n+          /*\n+           * Converts native beam pipeline options such as\n+           * --runner=SamzaRunner --maxSourceParallelism=1024\n+           */\n+          args.addAll(Arrays.asList(value.split(\"\\\\s\")));\n+        } else {\n+          /*\n+           * Converts native Samza configs to config override format such as\n+           * --config job.name=test\n+           */\n+          args.add(\"--config\");\n+          args.add(String.format(\"%s=%s\", key, value));\n+        }\n+      });\n \n-    return new ClusterBasedJobCoordinator(\n-        metrics,\n-        metadataStore,\n-        config);\n+    return args.toArray(new String[0]);\n   }\n }\n", "next_change": {"commit": "5f05cdde2eea46a8cbda08dd8c9868c8f46a4e9d", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex e7647f40f..8482a3bbb 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -629,21 +579,21 @@ public class ClusterBasedJobCoordinator {\n     List<String> args = new ArrayList<>(config.size() * 2);\n \n     config.forEach((key, value) -> {\n-        if (key.equals(ApplicationConfig.APP_MAIN_ARGS)) {\n-          /*\n-           * Converts native beam pipeline options such as\n-           * --runner=SamzaRunner --maxSourceParallelism=1024\n-           */\n-          args.addAll(Arrays.asList(value.split(\"\\\\s\")));\n-        } else {\n-          /*\n-           * Converts native Samza configs to config override format such as\n-           * --config job.name=test\n-           */\n-          args.add(\"--config\");\n-          args.add(String.format(\"%s=%s\", key, value));\n-        }\n-      });\n+      if (key.equals(ApplicationConfig.APP_MAIN_ARGS)) {\n+        /*\n+         * Converts native beam pipeline options such as\n+         * --runner=SamzaRunner --maxSourceParallelism=1024\n+         */\n+        args.addAll(Arrays.asList(value.split(\"\\\\s\")));\n+      } else {\n+        /*\n+         * Converts native Samza configs to config override format such as\n+         * --config job.name=test\n+         */\n+        args.add(\"--config\");\n+        args.add(String.format(\"%s=%s\", key, value));\n+      }\n+    });\n \n     return args.toArray(new String[0]);\n   }\n", "next_change": {"commit": "d689fd2568ea9dd457ed1c7c9cb193f4ae6fa631", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex 8482a3bbb..6295ed6e9 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -457,144 +448,6 @@ public class ClusterBasedJobCoordinator {\n \n   @VisibleForTesting\n   ContainerProcessManager createContainerProcessManager() {\n-    return new ContainerProcessManager(config, state, metrics, containerPlacementMetadataStore);\n-  }\n-\n-  /**\n-   * The entry point for the {@link ClusterBasedJobCoordinator}.\n-   */\n-  public static void main(String[] args) {\n-    Thread.setDefaultUncaughtExceptionHandler((thread, exception) -> {\n-      LOG.error(\"Uncaught exception in ClusterBasedJobCoordinator::main. Exiting job coordinator\", exception);\n-      System.exit(1);\n-    });\n-    if (!SplitDeploymentUtil.isSplitDeploymentEnabled()) {\n-      // no isolation enabled, so can just execute runClusterBasedJobCoordinator directly\n-      runClusterBasedJobCoordinator(args);\n-    } else {\n-      SplitDeploymentUtil.runWithClassLoader(new IsolatingClassLoaderFactory().buildClassLoader(),\n-          ClusterBasedJobCoordinator.class, \"runClusterBasedJobCoordinator\", args);\n-    }\n-    System.exit(0);\n-  }\n-\n-  /**\n-   * This is the actual execution for the {@link ClusterBasedJobCoordinator}. This is separated out from\n-   * {@link #main(String[])} so that it can be executed directly or from a separate classloader.\n-   */\n-  private static void runClusterBasedJobCoordinator(String[] args) {\n-    final String coordinatorSystemEnv = System.getenv(ShellCommandConfig.ENV_COORDINATOR_SYSTEM_CONFIG);\n-    final String submissionEnv = System.getenv(ShellCommandConfig.ENV_SUBMISSION_CONFIG);\n-\n-    if (!StringUtils.isBlank(submissionEnv)) {\n-      Config submissionConfig;\n-      try {\n-        //Read and parse the coordinator system config.\n-        LOG.info(\"Parsing submission config {}\", submissionEnv);\n-        submissionConfig =\n-            new MapConfig(SamzaObjectMapper.getObjectMapper().readValue(submissionEnv, Config.class));\n-        LOG.info(\"Using the submission config: {}.\", submissionConfig);\n-      } catch (IOException e) {\n-        LOG.error(\"Exception while reading submission config\", e);\n-        throw new SamzaException(e);\n-      }\n-\n-      ApplicationConfig appConfig = new ApplicationConfig(submissionConfig);\n-\n-      /*\n-       * Invoke app.main.class with app.main.args when present.\n-       * For Beam jobs, app.main.class will be Beam's main class\n-       * and app.main.args will be Beam's pipeline options.\n-       */\n-      if (appConfig.getAppMainClass().isPresent()) {\n-        String className = appConfig.getAppMainClass().get();\n-        LOG.info(\"Invoke main {}\", className);\n-        try {\n-          Class<?> cls = Class.forName(className);\n-          Method mainMethod = cls.getMethod(\"main\", String[].class);\n-          mainMethod.invoke(null, (Object) toArgs(appConfig));\n-        } catch (Exception e) {\n-          throw new SamzaException(e);\n-        }\n-      } else {\n-        JobConfig jobConfig = new JobConfig(submissionConfig);\n-\n-        if (!jobConfig.getConfigLoaderFactory().isPresent()) {\n-          throw new SamzaException(JobConfig.CONFIG_LOADER_FACTORY + \" is required to initialize job coordinator from config loader\");\n-        }\n-\n-        // load full job config with ConfigLoader\n-        Config originalConfig = ConfigUtil.loadConfig(submissionConfig);\n-\n-        JobCoordinatorLaunchUtil.run(ApplicationUtil.fromConfig(originalConfig), originalConfig);\n-      }\n-\n-      LOG.info(\"Finished running ClusterBasedJobCoordinator\");\n-    } else {\n-      // TODO: Clean this up once SAMZA-2405 is completed when legacy flow is removed.\n-      Config coordinatorSystemConfig;\n-      try {\n-        //Read and parse the coordinator system config.\n-        LOG.info(\"Parsing coordinator system config {}\", coordinatorSystemEnv);\n-        coordinatorSystemConfig =\n-            new MapConfig(SamzaObjectMapper.getObjectMapper().readValue(coordinatorSystemEnv, Config.class));\n-        LOG.info(\"Using the coordinator system config: {}.\", coordinatorSystemConfig);\n-      } catch (IOException e) {\n-        LOG.error(\"Exception while reading coordinator stream config\", e);\n-        throw new SamzaException(e);\n-      }\n-      ClusterBasedJobCoordinator jc = createFromMetadataStore(coordinatorSystemConfig);\n-      jc.run();\n-      LOG.info(\"Finished running ClusterBasedJobCoordinator\");\n-    }\n-  }\n-\n-  /**\n-   * Initialize {@link ClusterBasedJobCoordinator} with coordinator stream config, full job config will be fetched from\n-   * coordinator stream.\n-   *\n-   * @param metadataStoreConfig to initialize {@link MetadataStore}\n-   * @return {@link ClusterBasedJobCoordinator}\n-   */\n-  // TODO SAMZA-2432: Clean this up once SAMZA-2405 is completed when legacy flow is removed.\n-  @VisibleForTesting\n-  static ClusterBasedJobCoordinator createFromMetadataStore(Config metadataStoreConfig) {\n-    MetricsRegistryMap metrics = new MetricsRegistryMap();\n-\n-    CoordinatorStreamStore coordinatorStreamStore = new CoordinatorStreamStore(metadataStoreConfig, metrics);\n-    coordinatorStreamStore.init();\n-    Config config = CoordinatorStreamUtil.readConfigFromCoordinatorStream(coordinatorStreamStore);\n-\n-    return new ClusterBasedJobCoordinator(metrics, coordinatorStreamStore, config);\n-  }\n-\n-  /**\n-   * Convert Samza config to command line arguments to invoke app.main.class\n-   *\n-   * @param config Samza config to convert.\n-   * @return converted command line arguments.\n-   */\n-  @VisibleForTesting\n-  static String[] toArgs(ApplicationConfig config) {\n-    List<String> args = new ArrayList<>(config.size() * 2);\n-\n-    config.forEach((key, value) -> {\n-      if (key.equals(ApplicationConfig.APP_MAIN_ARGS)) {\n-        /*\n-         * Converts native beam pipeline options such as\n-         * --runner=SamzaRunner --maxSourceParallelism=1024\n-         */\n-        args.addAll(Arrays.asList(value.split(\"\\\\s\")));\n-      } else {\n-        /*\n-         * Converts native Samza configs to config override format such as\n-         * --config job.name=test\n-         */\n-        args.add(\"--config\");\n-        args.add(String.format(\"%s=%s\", key, value));\n-      }\n-    });\n-\n-    return args.toArray(new String[0]);\n+    return new ContainerProcessManager(config, state, metrics, containerPlacementMetadataStore, localityManager);\n   }\n }\n", "next_change": {"commit": "108768393960a893f9d202edf50bf47d2b1af590", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\nindex 6295ed6e9..08bcfda8f 100644\n--- a/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n+++ b/samza-core/src/main/java/org/apache/samza/clustermanager/ClusterBasedJobCoordinator.java\n", "chunk": "@@ -448,6 +485,39 @@ public class ClusterBasedJobCoordinator {\n \n   @VisibleForTesting\n   ContainerProcessManager createContainerProcessManager() {\n-    return new ContainerProcessManager(config, state, metrics, containerPlacementMetadataStore, localityManager);\n+    return new ContainerProcessManager(config, state, metrics, containerPlacementMetadataStore, localityManager,\n+        metadataChangedAcrossAttempts);\n+  }\n+\n+  @VisibleForTesting\n+  JobCoordinatorMetadataManager createJobCoordinatorMetadataManager() {\n+    return new JobCoordinatorMetadataManager(new NamespaceAwareCoordinatorStreamStore(metadataStore,\n+        SetJobCoordinatorMetadataMessage.TYPE), JobCoordinatorMetadataManager.ClusterType.YARN, metrics);\n+  }\n+\n+  @VisibleForTesting\n+  boolean isApplicationMasterHighAvailabilityEnabled() {\n+    return new JobConfig(config).getApplicationMasterHighAvailabilityEnabled();\n+  }\n+\n+  @VisibleForTesting\n+  boolean isMetadataChangedAcrossAttempts() {\n+    return metadataChangedAcrossAttempts;\n+  }\n+\n+  /**\n+   * We only fanout startpoint if and only if\n+   *  1. Startpoint is enabled\n+   *  2. If AM HA is enabled, fanout only if startpoint enabled and job coordinator metadata changed\n+   *\n+   * @return true if it satisfies above conditions, false otherwise\n+   */\n+  @VisibleForTesting\n+  boolean shouldFanoutStartpoint() {\n+    JobConfig jobConfig = new JobConfig(config);\n+    boolean startpointEnabled = jobConfig.getStartpointEnabled();\n+\n+    return isApplicationMasterHighAvailabilityEnabled() ?\n+        startpointEnabled && isMetadataChangedAcrossAttempts() : startpointEnabled;\n   }\n }\n", "next_change": null}]}}]}}]}}]}}]}, "commits_in_main": [{"oid": "5bef72595faa8c8cdc9e35b09342e36a5085c10b", "message": "Merge commit", "committedDate": null}, {"oid": "b379933d62c8cb438f0599e2540bce6b63e8c014", "committedDate": "2020-01-21 15:37:07 -0800", "message": "SAMZA-2404: [SEP-22] Container Placement Handler for dispatching container placement messages between metastore and JobCoordinator (#1227)"}, {"oid": "b4a9fe67238d6eb81b2c61177cafd276ade67c07", "committedDate": "2020-02-18 12:32:05 -0800", "message": "SAMZA-2402: Tie Container placement service and Container placement handler and validate placement requests (#1267)"}, {"oid": "e4eefe2a9b7d6559ee5ce236e5357d773c199816", "committedDate": "2020-03-10 13:20:39 -0700", "message": "SAMZA-2453: Update ClusterBasedJobCoordinator to support Beam jobs (#1309)"}, {"oid": "d6608714c211835c3b04caaaa49882455135158c", "committedDate": "2020-03-11 13:44:21 -0700", "message": "SAMZA-2466: [Scala cleanup] Convert ShellCommandConfig from scala to java (#1288)"}, {"oid": "b7cab952317bd4320f12e18c2cc3e3cee77770da", "committedDate": "2020-03-17 19:20:52 -0700", "message": "SAMZA-2488: Add JobCoordinatorLaunchUtil to handle common logic when launching job coordiantor. (#1318)"}, {"oid": "c527ec5a151e0da570dfdc3896c30694ac7c34f6", "committedDate": "2020-03-27 22:36:05 -0700", "message": "SAMZA-2491: AM should log uncaught exceptions and System.exit to ensure that the process dies on errors (#1325)"}, {"oid": "26d9eecac76f3b87610312d0066d96a5b36eef35", "committedDate": "2020-04-01 16:43:05 -0700", "message": "SAMZA-2501 : Optimizing startpoint manager to not make successive bootstrapMessage calls to coordinator-store (#1335)"}, {"oid": "d745e7d1cbd051002b30bfe99ae924d48ff96eaa", "committedDate": "2020-04-16 13:48:29 -0700", "message": "SAMZA-2509: New config name to represent if split deployment feature is enabled (#1342)"}, {"oid": "e86951f102c7a854d343b1f80dc2796be29c9c81", "committedDate": "2020-04-24 09:40:25 -0700", "message": "SAMZA-2514: Refactor codes to make runWithClassLoader method more generic (#1349)"}, {"oid": "5f05cdde2eea46a8cbda08dd8c9868c8f46a4e9d", "committedDate": "2020-06-22 15:52:51 -0700", "message": "SAMZA-2551: Upgrade all modules to automatically use checkstyle 6.11.2 (part 1: includes samza-core) (#1389)"}, {"oid": "f7f9f3c7905b047f262383bcc64ebb01ab73f421", "committedDate": "2020-08-26 19:39:32 -0700", "message": "SAMZA-2439: Remove LocalityManager and container location information from JobModel (#1421)"}, {"oid": "d689fd2568ea9dd457ed1c7c9cb193f4ae6fa631", "committedDate": "2020-09-02 15:10:42 -0700", "message": "SAMZA-2584: Refactor ClusterBasedJobCoordinator (#1424)"}, {"oid": "42e68e88c4dfe4c891dd601ee98f190d598decfd", "committedDate": "2020-09-15 21:50:40 -0700", "message": "SAMZA-2574 : improve flexibility of SystemFactory interface"}, {"oid": "c212cac420864d09f2663da2e51c23e4718d6812", "committedDate": "2020-11-30 23:37:21 -0800", "message": "SAMZA-2604: Datamodel change to capture physical container id for AM HA (#1445)"}, {"oid": "108768393960a893f9d202edf50bf47d2b1af590", "committedDate": "2020-12-09 09:33:11 -0800", "message": "SAMZA-2610: Handle Metadata changes for AM HA orchestration (#1450)"}, {"oid": "7cc4eaa96fff244f6dce9c18af804917db7c3b2b", "committedDate": "2021-05-25 16:00:46 -0700", "message": "SAMZA-2657: Blob Store as backend for Samza State backup and restore (#1501)"}, {"oid": "120098d6c45ca023d2a0fb144b0e333ab4e8ffe8", "committedDate": "2021-08-24 14:08:17 -0700", "message": "SAMZA-2670: Update granularity of JobCoordinatorMetadataManager.checkForMetadataChanges and epoch id extraction (#1519)"}, {"oid": "27b1495589e992cf1606ebfc2e34699077d60b73", "committedDate": "2021-08-30 14:26:40 -0700", "message": "SAMZA-2672: Extract creation of stream monitors into separate classes for reuse (#1520)"}, {"oid": "493de64bb8c0228bbda11822ae3c84c2085263bf", "committedDate": "2022-06-13 15:06:05 -0700", "message": "SAMZA-2742: [Pipeline Drain] Add Drain components and integrate them with SamzaContainer and JC (#1605)"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA3MTg3Mw==", "url": "https://github.com/apache/samza/pull/1248#discussion_r368071873", "body": "Is it practical to do any more-specific validation on the arguments here?", "bodyText": "Is it practical to do any more-specific validation on the arguments here?", "bodyHTML": "<p dir=\"auto\">Is it practical to do any more-specific validation on the arguments here?</p>", "author": "cameronlee314", "createdAt": "2020-01-17T18:21:00Z", "path": "samza-core/src/test/java/org/apache/samza/clustermanager/TestClusterBasedJobCoordinator.java", "diffHunk": "@@ -198,4 +203,31 @@ public void testRunWithClassLoader() throws Exception {\n     // make sure runClusterBasedJobCoordinator only got called once\n     verifyPrivate(ClusterBasedJobCoordinator.class).invoke(\"runClusterBasedJobCoordinator\", new Object[]{aryEq(args)});\n   }\n+\n+  @Test(expected = SamzaException.class)\n+  public void testCreateFromConfigLoaderWithoutConfigLoaderFactory() {\n+    ClusterBasedJobCoordinator.createFromConfigLoader(new MapConfig());\n+  }\n+\n+  @Test\n+  public void testCreateFromConfigLoader() throws Exception {\n+    // partially mock ClusterBasedJobCoordinator (mock prepareJob method only)\n+    PowerMockito.spy(ClusterBasedJobCoordinator.class);\n+\n+    Map<String, String> config = new HashMap<>();\n+    config.put(ApplicationConfig.APP_CLASS, MockStreamApplication.class.getCanonicalName());\n+    config.put(JobConfig.CONFIG_LOADER_FACTORY, PropertiesConfigLoaderFactory.class.getCanonicalName());\n+    config.put(PropertiesConfigLoaderFactory.CONFIG_LOADER_PROPERTIES_PREFIX + \"path\",\n+        getClass().getResource(\"/test.properties\").getPath());\n+\n+    PowerMockito.doAnswer(invocation -> invocation.getArgumentAt(0, Config.class))\n+        .when(ClusterBasedJobCoordinator.class, \"prepareJob\", any());\n+    PowerMockito.whenNew(ClusterBasedJobCoordinator.class).withAnyArguments().thenReturn(mock(ClusterBasedJobCoordinator.class));\n+    PowerMockito.whenNew(CoordinatorStreamStore.class).withAnyArguments().thenReturn(mock(CoordinatorStreamStore.class));\n+\n+    ClusterBasedJobCoordinator.createFromConfigLoader(new MapConfig(config));\n+\n+    verifyPrivate(ClusterBasedJobCoordinator.class).invoke(\"prepareJob\", any());\n+    verifyNew(ClusterBasedJobCoordinator.class).withArguments(any(), any(), any());", "originalCommit": "de8ed411e5118dce7ce4f6587379fb29a36495ef", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwNzUzMg==", "url": "https://github.com/apache/samza/pull/1248#discussion_r368107532", "bodyText": "Updated the unit test have to explicit validation on arguments.", "author": "kw2542", "createdAt": "2020-01-17T19:47:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA3MTg3Mw=="}], "type": "inlineReview", "revised_code": {"commit": "762fa7de922655c2479e44d8f9470f5944d774c4", "changed_code": [{"header": "diff --git a/samza-core/src/test/java/org/apache/samza/clustermanager/TestClusterBasedJobCoordinator.java b/samza-core/src/test/java/org/apache/samza/clustermanager/TestClusterBasedJobCoordinator.java\nindex 377d6b940..3a0292873 100644\n--- a/samza-core/src/test/java/org/apache/samza/clustermanager/TestClusterBasedJobCoordinator.java\n+++ b/samza-core/src/test/java/org/apache/samza/clustermanager/TestClusterBasedJobCoordinator.java\n", "chunk": "@@ -211,23 +221,25 @@ public class TestClusterBasedJobCoordinator {\n \n   @Test\n   public void testCreateFromConfigLoader() throws Exception {\n-    // partially mock ClusterBasedJobCoordinator (mock prepareJob method only)\n-    PowerMockito.spy(ClusterBasedJobCoordinator.class);\n-\n     Map<String, String> config = new HashMap<>();\n     config.put(ApplicationConfig.APP_CLASS, MockStreamApplication.class.getCanonicalName());\n     config.put(JobConfig.CONFIG_LOADER_FACTORY, PropertiesConfigLoaderFactory.class.getCanonicalName());\n     config.put(PropertiesConfigLoaderFactory.CONFIG_LOADER_PROPERTIES_PREFIX + \"path\",\n         getClass().getResource(\"/test.properties\").getPath());\n+    Config submissionConfig = new MapConfig(config);\n+    JobConfig fullJobConfig = new JobConfig(ConfigUtil.loadConfig(submissionConfig));\n+\n+    RemoteJobPlanner mockJobPlanner = mock(RemoteJobPlanner.class);\n+    CoordinatorStreamStore mockCoordinatorStreamStore = mock(CoordinatorStreamStore.class);\n \n-    PowerMockito.doAnswer(invocation -> invocation.getArgumentAt(0, Config.class))\n-        .when(ClusterBasedJobCoordinator.class, \"prepareJob\", any());\n     PowerMockito.whenNew(ClusterBasedJobCoordinator.class).withAnyArguments().thenReturn(mock(ClusterBasedJobCoordinator.class));\n-    PowerMockito.whenNew(CoordinatorStreamStore.class).withAnyArguments().thenReturn(mock(CoordinatorStreamStore.class));\n+    PowerMockito.doReturn(new MapConfig()).when(CoordinatorStreamUtil.class, \"buildCoordinatorStreamConfig\", any());\n+    PowerMockito.whenNew(CoordinatorStreamStore.class).withAnyArguments().thenReturn(mockCoordinatorStreamStore);\n+    PowerMockito.whenNew(RemoteJobPlanner.class).withAnyArguments().thenReturn(mockJobPlanner);\n+    when(mockJobPlanner.prepareJobs()).thenReturn(Collections.singletonList(fullJobConfig));\n \n-    ClusterBasedJobCoordinator.createFromConfigLoader(new MapConfig(config));\n+    ClusterBasedJobCoordinator.createFromConfigLoader(submissionConfig);\n \n-    verifyPrivate(ClusterBasedJobCoordinator.class).invoke(\"prepareJob\", any());\n-    verifyNew(ClusterBasedJobCoordinator.class).withArguments(any(), any(), any());\n+    verifyNew(ClusterBasedJobCoordinator.class).withArguments(any(MetricsRegistryMap.class), eq(mockCoordinatorStreamStore), eq(fullJobConfig));\n   }\n }\n", "next_change": null}]}, "revised_code_in_main": {"commit": "5bef72595faa8c8cdc9e35b09342e36a5085c10b", "changed_code": [{"header": "diff --git a/samza-core/src/test/java/org/apache/samza/clustermanager/TestClusterBasedJobCoordinator.java b/samza-core/src/test/java/org/apache/samza/clustermanager/TestClusterBasedJobCoordinator.java\nindex 377d6b940..787edf217 100644\n--- a/samza-core/src/test/java/org/apache/samza/clustermanager/TestClusterBasedJobCoordinator.java\n+++ b/samza-core/src/test/java/org/apache/samza/clustermanager/TestClusterBasedJobCoordinator.java\n", "chunk": "@@ -211,23 +219,25 @@ public class TestClusterBasedJobCoordinator {\n \n   @Test\n   public void testCreateFromConfigLoader() throws Exception {\n-    // partially mock ClusterBasedJobCoordinator (mock prepareJob method only)\n-    PowerMockito.spy(ClusterBasedJobCoordinator.class);\n-\n     Map<String, String> config = new HashMap<>();\n     config.put(ApplicationConfig.APP_CLASS, MockStreamApplication.class.getCanonicalName());\n     config.put(JobConfig.CONFIG_LOADER_FACTORY, PropertiesConfigLoaderFactory.class.getCanonicalName());\n     config.put(PropertiesConfigLoaderFactory.CONFIG_LOADER_PROPERTIES_PREFIX + \"path\",\n         getClass().getResource(\"/test.properties\").getPath());\n+    Config submissionConfig = new MapConfig(config);\n+    JobConfig fullJobConfig = new JobConfig(ConfigUtil.loadConfig(submissionConfig));\n+\n+    RemoteJobPlanner mockJobPlanner = mock(RemoteJobPlanner.class);\n+    CoordinatorStreamStore mockCoordinatorStreamStore = mock(CoordinatorStreamStore.class);\n \n-    PowerMockito.doAnswer(invocation -> invocation.getArgumentAt(0, Config.class))\n-        .when(ClusterBasedJobCoordinator.class, \"prepareJob\", any());\n     PowerMockito.whenNew(ClusterBasedJobCoordinator.class).withAnyArguments().thenReturn(mock(ClusterBasedJobCoordinator.class));\n-    PowerMockito.whenNew(CoordinatorStreamStore.class).withAnyArguments().thenReturn(mock(CoordinatorStreamStore.class));\n+    PowerMockito.doReturn(new MapConfig()).when(CoordinatorStreamUtil.class, \"buildCoordinatorStreamConfig\", any());\n+    PowerMockito.whenNew(CoordinatorStreamStore.class).withAnyArguments().thenReturn(mockCoordinatorStreamStore);\n+    PowerMockito.whenNew(RemoteJobPlanner.class).withAnyArguments().thenReturn(mockJobPlanner);\n+    when(mockJobPlanner.prepareJobs()).thenReturn(Collections.singletonList(fullJobConfig));\n \n-    ClusterBasedJobCoordinator.createFromConfigLoader(new MapConfig(config));\n+    ClusterBasedJobCoordinator.createFromConfigLoader(submissionConfig);\n \n-    verifyPrivate(ClusterBasedJobCoordinator.class).invoke(\"prepareJob\", any());\n-    verifyNew(ClusterBasedJobCoordinator.class).withArguments(any(), any(), any());\n+    verifyNew(ClusterBasedJobCoordinator.class).withArguments(any(MetricsRegistryMap.class), eq(mockCoordinatorStreamStore), eq(fullJobConfig));\n   }\n }\n", "next_change": {"commit": "e4eefe2a9b7d6559ee5ce236e5357d773c199816", "changed_code": [{"header": "diff --git a/samza-core/src/test/java/org/apache/samza/clustermanager/TestClusterBasedJobCoordinator.java b/samza-core/src/test/java/org/apache/samza/clustermanager/TestClusterBasedJobCoordinator.java\nindex 787edf217..513c07559 100644\n--- a/samza-core/src/test/java/org/apache/samza/clustermanager/TestClusterBasedJobCoordinator.java\n+++ b/samza-core/src/test/java/org/apache/samza/clustermanager/TestClusterBasedJobCoordinator.java\n", "chunk": "@@ -240,4 +241,24 @@ public class TestClusterBasedJobCoordinator {\n \n     verifyNew(ClusterBasedJobCoordinator.class).withArguments(any(MetricsRegistryMap.class), eq(mockCoordinatorStreamStore), eq(fullJobConfig));\n   }\n+\n+  @Test\n+  public void testToArgs() {\n+    ApplicationConfig appConfig = new ApplicationConfig(new MapConfig(ImmutableMap.of(\n+        JobConfig.JOB_NAME, \"test1\",\n+        ApplicationConfig.APP_CLASS, \"class1\",\n+        ApplicationConfig.APP_MAIN_ARGS, \"--runner=SamzaRunner --maxSourceParallelism=1024\"\n+    )));\n+\n+    List<String> expected = Arrays.asList(\n+        \"--config\", \"job.name=test1\",\n+        \"--config\", \"app.class=class1\",\n+        \"--runner=SamzaRunner\",\n+        \"--maxSourceParallelism=1024\");\n+    List<String> actual = Arrays.asList(ClusterBasedJobCoordinator.toArgs(appConfig));\n+\n+    // cannot assert expected equals to actual as the order can be different.\n+    assertEquals(expected.size(), actual.size());\n+    assertTrue(actual.containsAll(expected));\n+  }\n }\n", "next_change": {"commit": "d689fd2568ea9dd457ed1c7c9cb193f4ae6fa631", "changed_code": [{"header": "diff --git a/samza-core/src/test/java/org/apache/samza/clustermanager/TestClusterBasedJobCoordinator.java b/samza-core/src/test/java/org/apache/samza/clustermanager/TestClusterBasedJobCoordinator.java\nindex 513c07559..caa1ffe75 100644\n--- a/samza-core/src/test/java/org/apache/samza/clustermanager/TestClusterBasedJobCoordinator.java\n+++ b/samza-core/src/test/java/org/apache/samza/clustermanager/TestClusterBasedJobCoordinator.java\n", "chunk": "@@ -255,7 +186,7 @@ public class TestClusterBasedJobCoordinator {\n         \"--config\", \"app.class=class1\",\n         \"--runner=SamzaRunner\",\n         \"--maxSourceParallelism=1024\");\n-    List<String> actual = Arrays.asList(ClusterBasedJobCoordinator.toArgs(appConfig));\n+    List<String> actual = Arrays.asList(ClusterBasedJobCoordinatorRunner.toArgs(appConfig));\n \n     // cannot assert expected equals to actual as the order can be different.\n     assertEquals(expected.size(), actual.size());\n", "next_change": {"commit": "108768393960a893f9d202edf50bf47d2b1af590", "changed_code": [{"header": "diff --git a/samza-core/src/test/java/org/apache/samza/clustermanager/TestClusterBasedJobCoordinator.java b/samza-core/src/test/java/org/apache/samza/clustermanager/TestClusterBasedJobCoordinator.java\nindex caa1ffe75..50a1ee161 100644\n--- a/samza-core/src/test/java/org/apache/samza/clustermanager/TestClusterBasedJobCoordinator.java\n+++ b/samza-core/src/test/java/org/apache/samza/clustermanager/TestClusterBasedJobCoordinator.java\n", "chunk": "@@ -192,4 +233,39 @@ public class TestClusterBasedJobCoordinator {\n     assertEquals(expected.size(), actual.size());\n     assertTrue(actual.containsAll(expected));\n   }\n+\n+  @Test\n+  public void testGenerateAndUpdateJobCoordinatorMetadata() {\n+    Config jobConfig = new MapConfig(configMap);\n+    when(CoordinatorStreamUtil.readConfigFromCoordinatorStream(anyObject())).thenReturn(jobConfig);\n+    ClusterBasedJobCoordinator clusterBasedJobCoordinator =\n+        spy(ClusterBasedJobCoordinatorRunner.createFromMetadataStore(jobConfig));\n+\n+    JobCoordinatorMetadata previousMetadata = mock(JobCoordinatorMetadata.class);\n+    JobCoordinatorMetadata newMetadata = mock(JobCoordinatorMetadata.class);\n+    JobCoordinatorMetadataManager jobCoordinatorMetadataManager = mock(JobCoordinatorMetadataManager.class);\n+    JobModel mockJobModel = mock(JobModel.class);\n+\n+    when(jobCoordinatorMetadataManager.readJobCoordinatorMetadata()).thenReturn(previousMetadata);\n+    when(jobCoordinatorMetadataManager.generateJobCoordinatorMetadata(any(), any())).thenReturn(newMetadata);\n+    when(jobCoordinatorMetadataManager.checkForMetadataChanges(newMetadata, previousMetadata)).thenReturn(false);\n+    when(clusterBasedJobCoordinator.createJobCoordinatorMetadataManager()).thenReturn(jobCoordinatorMetadataManager);\n+\n+    /*\n+     * Verify if there are no changes to metadata, the metadata changed flag remains false and no interactions\n+     * with job coordinator metadata manager\n+     */\n+    clusterBasedJobCoordinator.generateAndUpdateJobCoordinatorMetadata(mockJobModel);\n+    assertFalse(\"JC metadata changed should remain unchanged\",\n+        clusterBasedJobCoordinator.isMetadataChangedAcrossAttempts());\n+    verify(jobCoordinatorMetadataManager, times(0)).writeJobCoordinatorMetadata(any());\n+\n+    /*\n+     * Verify if there are changes to metadata, we persist the new metadata & update the metadata changed flag\n+     */\n+    when(jobCoordinatorMetadataManager.checkForMetadataChanges(newMetadata, previousMetadata)).thenReturn(true);\n+    clusterBasedJobCoordinator.generateAndUpdateJobCoordinatorMetadata(mockJobModel);\n+    assertTrue(\"JC metadata changed should be true\", clusterBasedJobCoordinator.isMetadataChangedAcrossAttempts());\n+    verify(jobCoordinatorMetadataManager, times(1)).writeJobCoordinatorMetadata(newMetadata);\n+  }\n }\n", "next_change": {"commit": "120098d6c45ca023d2a0fb144b0e333ab4e8ffe8", "changed_code": [{"header": "diff --git a/samza-core/src/test/java/org/apache/samza/clustermanager/TestClusterBasedJobCoordinator.java b/samza-core/src/test/java/org/apache/samza/clustermanager/TestClusterBasedJobCoordinator.java\nindex 50a1ee161..6eeb119da 100644\n--- a/samza-core/src/test/java/org/apache/samza/clustermanager/TestClusterBasedJobCoordinator.java\n+++ b/samza-core/src/test/java/org/apache/samza/clustermanager/TestClusterBasedJobCoordinator.java\n", "chunk": "@@ -263,7 +267,8 @@ public class TestClusterBasedJobCoordinator {\n     /*\n      * Verify if there are changes to metadata, we persist the new metadata & update the metadata changed flag\n      */\n-    when(jobCoordinatorMetadataManager.checkForMetadataChanges(newMetadata, previousMetadata)).thenReturn(true);\n+    when(jobCoordinatorMetadataManager.checkForMetadataChanges(newMetadata, previousMetadata)).thenReturn(\n+        ImmutableSet.of(JobMetadataChange.NEW_DEPLOYMENT));\n     clusterBasedJobCoordinator.generateAndUpdateJobCoordinatorMetadata(mockJobModel);\n     assertTrue(\"JC metadata changed should be true\", clusterBasedJobCoordinator.isMetadataChangedAcrossAttempts());\n     verify(jobCoordinatorMetadataManager, times(1)).writeJobCoordinatorMetadata(newMetadata);\n", "next_change": null}]}}]}}]}}]}}]}, "commits_in_main": [{"oid": "5bef72595faa8c8cdc9e35b09342e36a5085c10b", "message": "Merge commit", "committedDate": null}, {"oid": "e4eefe2a9b7d6559ee5ce236e5357d773c199816", "committedDate": "2020-03-10 13:20:39 -0700", "message": "SAMZA-2453: Update ClusterBasedJobCoordinator to support Beam jobs (#1309)"}, {"oid": "b7cab952317bd4320f12e18c2cc3e3cee77770da", "committedDate": "2020-03-17 19:20:52 -0700", "message": "SAMZA-2488: Add JobCoordinatorLaunchUtil to handle common logic when launching job coordiantor. (#1318)"}, {"oid": "e86951f102c7a854d343b1f80dc2796be29c9c81", "committedDate": "2020-04-24 09:40:25 -0700", "message": "SAMZA-2514: Refactor codes to make runWithClassLoader method more generic (#1349)"}, {"oid": "d689fd2568ea9dd457ed1c7c9cb193f4ae6fa631", "committedDate": "2020-09-02 15:10:42 -0700", "message": "SAMZA-2584: Refactor ClusterBasedJobCoordinator (#1424)"}, {"oid": "108768393960a893f9d202edf50bf47d2b1af590", "committedDate": "2020-12-09 09:33:11 -0800", "message": "SAMZA-2610: Handle Metadata changes for AM HA orchestration (#1450)"}, {"oid": "5748fa6adec729840beef03495aa6b74f739f017", "committedDate": "2020-12-24 11:20:54 -0800", "message": "SAMZA-2605: Make Standby Container Requests Rack Aware  (#1446)"}, {"oid": "120098d6c45ca023d2a0fb144b0e333ab4e8ffe8", "committedDate": "2021-08-24 14:08:17 -0700", "message": "SAMZA-2670: Update granularity of JobCoordinatorMetadataManager.checkForMetadataChanges and epoch id extraction (#1519)"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA3MjE3MA==", "url": "https://github.com/apache/samza/pull/1248#discussion_r368072170", "body": "Can this just be `assertEquals(config, actual)`?", "bodyText": "Can this just be assertEquals(config, actual)?", "bodyHTML": "<p dir=\"auto\">Can this just be <code>assertEquals(config, actual)</code>?</p>", "author": "cameronlee314", "createdAt": "2020-01-17T18:21:43Z", "path": "samza-core/src/test/java/org/apache/samza/util/TestConfigUtil.java", "diffHunk": "@@ -161,6 +162,31 @@ public void testApplyRewriterClassDoesNotExist() {\n     assertEquals(expectedConfig, ConfigUtil.applyRewriter(new MapConfig(fullConfig), REWRITER_NAME));\n   }\n \n+  @Test\n+  public void testLoadConfigWithoutLoader() {\n+    Map<String, String> config = new HashMap<>();\n+    config.put(JobConfig.JOB_NAME, \"new-test-job\");\n+\n+    Config actual = ConfigUtil.loadConfig(new MapConfig(config));\n+\n+    assertEquals(config.size(), actual.size());\n+    assertEquals(\"new-test-job\", actual.get(JobConfig.JOB_NAME));", "originalCommit": "de8ed411e5118dce7ce4f6587379fb29a36495ef", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA3OTMxOA==", "url": "https://github.com/apache/samza/pull/1248#discussion_r368079318", "bodyText": "Update the unit test to check ConfigException instead as we disallow config w/o loader.", "author": "kw2542", "createdAt": "2020-01-17T18:39:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA3MjE3MA=="}], "type": "inlineReview", "revised_code": {"commit": "27210d8aa49b6497400604aab47d722563ff59b4", "changed_code": [{"header": "diff --git a/samza-core/src/test/java/org/apache/samza/util/TestConfigUtil.java b/samza-core/src/test/java/org/apache/samza/util/TestConfigUtil.java\nindex d29296caf..c005f37a3 100644\n--- a/samza-core/src/test/java/org/apache/samza/util/TestConfigUtil.java\n+++ b/samza-core/src/test/java/org/apache/samza/util/TestConfigUtil.java\n", "chunk": "@@ -162,29 +163,32 @@ public class TestConfigUtil {\n     assertEquals(expectedConfig, ConfigUtil.applyRewriter(new MapConfig(fullConfig), REWRITER_NAME));\n   }\n \n-  @Test\n+  @Test(expected = ConfigException.class)\n   public void testLoadConfigWithoutLoader() {\n     Map<String, String> config = new HashMap<>();\n     config.put(JobConfig.JOB_NAME, \"new-test-job\");\n \n-    Config actual = ConfigUtil.loadConfig(new MapConfig(config));\n-\n-    assertEquals(config.size(), actual.size());\n-    assertEquals(\"new-test-job\", actual.get(JobConfig.JOB_NAME));\n+    ConfigUtil.loadConfig(new MapConfig(config));\n   }\n \n   @Test\n-  public void testLoadConfigWithLoader() {\n+  public void testLoadConfigWithOverridesAndRewrites() {\n     Map<String, String> config = new HashMap<>();\n     config.put(JobConfig.CONFIG_LOADER_FACTORY, PropertiesConfigLoaderFactory.class.getCanonicalName());\n     config.put(JobConfig.JOB_NAME, \"new-test-job\");\n+    config.put(JobConfig.CONFIG_REWRITERS, REWRITER_NAME);\n+    config.put(CONFIG_KEY, CONFIG_VALUE);\n+    config.put(String.format(JobConfig.CONFIG_REWRITER_CLASS, REWRITER_NAME), NewPropertyRewriter.class.getName());\n     config.put(PropertiesConfigLoaderFactory.CONFIG_LOADER_PROPERTIES_PREFIX + \"path\", getClass().getResource(\"/test.properties\").getPath());\n \n     Config actual = ConfigUtil.loadConfig(new MapConfig(config));\n \n     assertEquals(\"org.apache.samza.job.MockJobFactory\", actual.get(\"job.factory.class\"));\n-    assertEquals(\"new-test-job\", actual.get(\"job.name\"));\n     assertEquals(\"bar\", actual.get(\"foo\"));\n+    // overridden value\n+    assertEquals(\"new-test-job\", actual.get(\"job.name\"));\n+    // rewritten value\n+    assertEquals(CONFIG_VALUE, actual.get(NEW_CONFIG_KEY));\n   }\n \n   /**\n", "next_change": null}]}, "revised_code_in_main": {"commit": "5bef72595faa8c8cdc9e35b09342e36a5085c10b", "changed_code": [{"header": "diff --git a/samza-core/src/test/java/org/apache/samza/util/TestConfigUtil.java b/samza-core/src/test/java/org/apache/samza/util/TestConfigUtil.java\nindex d29296caf..c005f37a3 100644\n--- a/samza-core/src/test/java/org/apache/samza/util/TestConfigUtil.java\n+++ b/samza-core/src/test/java/org/apache/samza/util/TestConfigUtil.java\n", "chunk": "@@ -162,29 +163,32 @@ public class TestConfigUtil {\n     assertEquals(expectedConfig, ConfigUtil.applyRewriter(new MapConfig(fullConfig), REWRITER_NAME));\n   }\n \n-  @Test\n+  @Test(expected = ConfigException.class)\n   public void testLoadConfigWithoutLoader() {\n     Map<String, String> config = new HashMap<>();\n     config.put(JobConfig.JOB_NAME, \"new-test-job\");\n \n-    Config actual = ConfigUtil.loadConfig(new MapConfig(config));\n-\n-    assertEquals(config.size(), actual.size());\n-    assertEquals(\"new-test-job\", actual.get(JobConfig.JOB_NAME));\n+    ConfigUtil.loadConfig(new MapConfig(config));\n   }\n \n   @Test\n-  public void testLoadConfigWithLoader() {\n+  public void testLoadConfigWithOverridesAndRewrites() {\n     Map<String, String> config = new HashMap<>();\n     config.put(JobConfig.CONFIG_LOADER_FACTORY, PropertiesConfigLoaderFactory.class.getCanonicalName());\n     config.put(JobConfig.JOB_NAME, \"new-test-job\");\n+    config.put(JobConfig.CONFIG_REWRITERS, REWRITER_NAME);\n+    config.put(CONFIG_KEY, CONFIG_VALUE);\n+    config.put(String.format(JobConfig.CONFIG_REWRITER_CLASS, REWRITER_NAME), NewPropertyRewriter.class.getName());\n     config.put(PropertiesConfigLoaderFactory.CONFIG_LOADER_PROPERTIES_PREFIX + \"path\", getClass().getResource(\"/test.properties\").getPath());\n \n     Config actual = ConfigUtil.loadConfig(new MapConfig(config));\n \n     assertEquals(\"org.apache.samza.job.MockJobFactory\", actual.get(\"job.factory.class\"));\n-    assertEquals(\"new-test-job\", actual.get(\"job.name\"));\n     assertEquals(\"bar\", actual.get(\"foo\"));\n+    // overridden value\n+    assertEquals(\"new-test-job\", actual.get(\"job.name\"));\n+    // rewritten value\n+    assertEquals(CONFIG_VALUE, actual.get(NEW_CONFIG_KEY));\n   }\n \n   /**\n", "next_change": null}]}, "commits_in_main": [{"oid": "5bef72595faa8c8cdc9e35b09342e36a5085c10b", "message": "Merge commit", "committedDate": null}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA3MjcwNA==", "url": "https://github.com/apache/samza/pull/1248#discussion_r368072704", "body": "Should this also test config rewriting and overriding?", "bodyText": "Should this also test config rewriting and overriding?", "bodyHTML": "<p dir=\"auto\">Should this also test config rewriting and overriding?</p>", "author": "cameronlee314", "createdAt": "2020-01-17T18:23:03Z", "path": "samza-core/src/test/java/org/apache/samza/util/TestConfigUtil.java", "diffHunk": "@@ -161,6 +162,31 @@ public void testApplyRewriterClassDoesNotExist() {\n     assertEquals(expectedConfig, ConfigUtil.applyRewriter(new MapConfig(fullConfig), REWRITER_NAME));\n   }\n \n+  @Test\n+  public void testLoadConfigWithoutLoader() {\n+    Map<String, String> config = new HashMap<>();\n+    config.put(JobConfig.JOB_NAME, \"new-test-job\");\n+\n+    Config actual = ConfigUtil.loadConfig(new MapConfig(config));\n+\n+    assertEquals(config.size(), actual.size());\n+    assertEquals(\"new-test-job\", actual.get(JobConfig.JOB_NAME));\n+  }\n+\n+  @Test\n+  public void testLoadConfigWithLoader() {", "originalCommit": "de8ed411e5118dce7ce4f6587379fb29a36495ef", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA4NDMwOA==", "url": "https://github.com/apache/samza/pull/1248#discussion_r368084308", "bodyText": "Updated to include both overrides and rewrites.", "author": "kw2542", "createdAt": "2020-01-17T18:51:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA3MjcwNA=="}], "type": "inlineReview", "revised_code": {"commit": "27210d8aa49b6497400604aab47d722563ff59b4", "changed_code": [{"header": "diff --git a/samza-core/src/test/java/org/apache/samza/util/TestConfigUtil.java b/samza-core/src/test/java/org/apache/samza/util/TestConfigUtil.java\nindex d29296caf..c005f37a3 100644\n--- a/samza-core/src/test/java/org/apache/samza/util/TestConfigUtil.java\n+++ b/samza-core/src/test/java/org/apache/samza/util/TestConfigUtil.java\n", "chunk": "@@ -162,29 +163,32 @@ public class TestConfigUtil {\n     assertEquals(expectedConfig, ConfigUtil.applyRewriter(new MapConfig(fullConfig), REWRITER_NAME));\n   }\n \n-  @Test\n+  @Test(expected = ConfigException.class)\n   public void testLoadConfigWithoutLoader() {\n     Map<String, String> config = new HashMap<>();\n     config.put(JobConfig.JOB_NAME, \"new-test-job\");\n \n-    Config actual = ConfigUtil.loadConfig(new MapConfig(config));\n-\n-    assertEquals(config.size(), actual.size());\n-    assertEquals(\"new-test-job\", actual.get(JobConfig.JOB_NAME));\n+    ConfigUtil.loadConfig(new MapConfig(config));\n   }\n \n   @Test\n-  public void testLoadConfigWithLoader() {\n+  public void testLoadConfigWithOverridesAndRewrites() {\n     Map<String, String> config = new HashMap<>();\n     config.put(JobConfig.CONFIG_LOADER_FACTORY, PropertiesConfigLoaderFactory.class.getCanonicalName());\n     config.put(JobConfig.JOB_NAME, \"new-test-job\");\n+    config.put(JobConfig.CONFIG_REWRITERS, REWRITER_NAME);\n+    config.put(CONFIG_KEY, CONFIG_VALUE);\n+    config.put(String.format(JobConfig.CONFIG_REWRITER_CLASS, REWRITER_NAME), NewPropertyRewriter.class.getName());\n     config.put(PropertiesConfigLoaderFactory.CONFIG_LOADER_PROPERTIES_PREFIX + \"path\", getClass().getResource(\"/test.properties\").getPath());\n \n     Config actual = ConfigUtil.loadConfig(new MapConfig(config));\n \n     assertEquals(\"org.apache.samza.job.MockJobFactory\", actual.get(\"job.factory.class\"));\n-    assertEquals(\"new-test-job\", actual.get(\"job.name\"));\n     assertEquals(\"bar\", actual.get(\"foo\"));\n+    // overridden value\n+    assertEquals(\"new-test-job\", actual.get(\"job.name\"));\n+    // rewritten value\n+    assertEquals(CONFIG_VALUE, actual.get(NEW_CONFIG_KEY));\n   }\n \n   /**\n", "next_change": null}]}, "revised_code_in_main": {"commit": "5bef72595faa8c8cdc9e35b09342e36a5085c10b", "changed_code": [{"header": "diff --git a/samza-core/src/test/java/org/apache/samza/util/TestConfigUtil.java b/samza-core/src/test/java/org/apache/samza/util/TestConfigUtil.java\nindex d29296caf..c005f37a3 100644\n--- a/samza-core/src/test/java/org/apache/samza/util/TestConfigUtil.java\n+++ b/samza-core/src/test/java/org/apache/samza/util/TestConfigUtil.java\n", "chunk": "@@ -162,29 +163,32 @@ public class TestConfigUtil {\n     assertEquals(expectedConfig, ConfigUtil.applyRewriter(new MapConfig(fullConfig), REWRITER_NAME));\n   }\n \n-  @Test\n+  @Test(expected = ConfigException.class)\n   public void testLoadConfigWithoutLoader() {\n     Map<String, String> config = new HashMap<>();\n     config.put(JobConfig.JOB_NAME, \"new-test-job\");\n \n-    Config actual = ConfigUtil.loadConfig(new MapConfig(config));\n-\n-    assertEquals(config.size(), actual.size());\n-    assertEquals(\"new-test-job\", actual.get(JobConfig.JOB_NAME));\n+    ConfigUtil.loadConfig(new MapConfig(config));\n   }\n \n   @Test\n-  public void testLoadConfigWithLoader() {\n+  public void testLoadConfigWithOverridesAndRewrites() {\n     Map<String, String> config = new HashMap<>();\n     config.put(JobConfig.CONFIG_LOADER_FACTORY, PropertiesConfigLoaderFactory.class.getCanonicalName());\n     config.put(JobConfig.JOB_NAME, \"new-test-job\");\n+    config.put(JobConfig.CONFIG_REWRITERS, REWRITER_NAME);\n+    config.put(CONFIG_KEY, CONFIG_VALUE);\n+    config.put(String.format(JobConfig.CONFIG_REWRITER_CLASS, REWRITER_NAME), NewPropertyRewriter.class.getName());\n     config.put(PropertiesConfigLoaderFactory.CONFIG_LOADER_PROPERTIES_PREFIX + \"path\", getClass().getResource(\"/test.properties\").getPath());\n \n     Config actual = ConfigUtil.loadConfig(new MapConfig(config));\n \n     assertEquals(\"org.apache.samza.job.MockJobFactory\", actual.get(\"job.factory.class\"));\n-    assertEquals(\"new-test-job\", actual.get(\"job.name\"));\n     assertEquals(\"bar\", actual.get(\"foo\"));\n+    // overridden value\n+    assertEquals(\"new-test-job\", actual.get(\"job.name\"));\n+    // rewritten value\n+    assertEquals(CONFIG_VALUE, actual.get(NEW_CONFIG_KEY));\n   }\n \n   /**\n", "next_change": null}]}, "commits_in_main": [{"oid": "5bef72595faa8c8cdc9e35b09342e36a5085c10b", "message": "Merge commit", "committedDate": null}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA3MzE3MA==", "url": "https://github.com/apache/samza/pull/1248#discussion_r368073170", "body": "If this is public, can you please add a unit test for it? Or you could make it private.\r\nYou could also simplify it to only take in one extra argument since that is currently the only way it is used.", "bodyText": "If this is public, can you please add a unit test for it? Or you could make it private.\nYou could also simplify it to only take in one extra argument since that is currently the only way it is used.", "bodyHTML": "<p dir=\"auto\">If this is public, can you please add a unit test for it? Or you could make it private.<br>\nYou could also simplify it to only take in one extra argument since that is currently the only way it is used.</p>", "author": "cameronlee314", "createdAt": "2020-01-17T18:24:11Z", "path": "samza-core/src/main/java/org/apache/samza/util/ConfigUtil.java", "diffHunk": "@@ -67,4 +72,42 @@ public static Config applyRewriter(Config config, String rewriterName) {\n     LOG.info(\"Re-writing config with {}\", rewriter);\n     return rewriter.rewrite(rewriterName, config);\n   }\n+\n+  /**\n+   * Load full job config with {@link ConfigLoaderFactory} when present.\n+   *\n+   * @param original config\n+   * @return full job config\n+   */\n+  public static Config loadConfig(Config original) {\n+    JobConfig jobConfig = new JobConfig(original);\n+    Config fullConfig = original;\n+\n+    if (jobConfig.getConfigLoaderFactory().isPresent()) {\n+      ConfigLoaderFactory factory = ReflectionUtil.getObj(jobConfig.getConfigLoaderFactory().get(), ConfigLoaderFactory.class);\n+      ConfigLoader loader = factory.getLoader(original.subset(ConfigLoaderFactory.CONFIG_LOADER_PROPERTIES_PREFIX));\n+      // overrides config loaded with original config, which may contain overridden values.\n+      fullConfig = ConfigUtil.rewriteConfig(override(loader.getConfig(), original));\n+    }\n+\n+    return fullConfig;\n+  }\n+\n+  /**\n+   * Overrides original config with overridden values.\n+   *\n+   * @param original config to be overridden.\n+   * @param overrides overridden values.\n+   * @return the overridden config.\n+   */\n+  @SafeVarargs\n+  public static Config override(Config original, Map<String, String>... overrides) {", "originalCommit": "de8ed411e5118dce7ce4f6587379fb29a36495ef", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA3OTUyMA==", "url": "https://github.com/apache/samza/pull/1248#discussion_r368079520", "bodyText": "Updated to private", "author": "kw2542", "createdAt": "2020-01-17T18:39:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA3MzE3MA=="}], "type": "inlineReview", "revised_code": {"commit": "27210d8aa49b6497400604aab47d722563ff59b4", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/util/ConfigUtil.java b/samza-core/src/main/java/org/apache/samza/util/ConfigUtil.java\nindex 86a5f52b5..7206fe284 100644\n--- a/samza-core/src/main/java/org/apache/samza/util/ConfigUtil.java\n+++ b/samza-core/src/main/java/org/apache/samza/util/ConfigUtil.java\n", "chunk": "@@ -101,7 +101,7 @@ public class ConfigUtil {\n    * @return the overridden config.\n    */\n   @SafeVarargs\n-  public static Config override(Config original, Map<String, String>... overrides) {\n+  private static Config override(Config original, Map<String, String>... overrides) {\n     Map<String, String> map = new HashMap<>(original);\n \n     for (Map<String, String> override : overrides) {\n", "next_change": null}]}, "revised_code_in_main": {"commit": "5bef72595faa8c8cdc9e35b09342e36a5085c10b", "changed_code": [{"header": "diff --git a/samza-core/src/main/java/org/apache/samza/util/ConfigUtil.java b/samza-core/src/main/java/org/apache/samza/util/ConfigUtil.java\nindex 86a5f52b5..7206fe284 100644\n--- a/samza-core/src/main/java/org/apache/samza/util/ConfigUtil.java\n+++ b/samza-core/src/main/java/org/apache/samza/util/ConfigUtil.java\n", "chunk": "@@ -101,7 +101,7 @@ public class ConfigUtil {\n    * @return the overridden config.\n    */\n   @SafeVarargs\n-  public static Config override(Config original, Map<String, String>... overrides) {\n+  private static Config override(Config original, Map<String, String>... overrides) {\n     Map<String, String> map = new HashMap<>(original);\n \n     for (Map<String, String> override : overrides) {\n", "next_change": null}]}, "commits_in_main": [{"oid": "5bef72595faa8c8cdc9e35b09342e36a5085c10b", "message": "Merge commit", "committedDate": null}]}, {"oid": "b00cb06351e29501269ac03ca702fba16131590e", "url": "https://github.com/apache/samza/commit/b00cb06351e29501269ac03ca702fba16131590e", "message": "Use StringUtils.isBlank instead of null check", "committedDate": "2020-01-17T18:27:08Z", "type": "commit"}, {"oid": "27210d8aa49b6497400604aab47d722563ff59b4", "url": "https://github.com/apache/samza/commit/27210d8aa49b6497400604aab47d722563ff59b4", "message": "Update", "committedDate": "2020-01-17T18:52:10Z", "type": "commit"}, {"oid": "762fa7de922655c2479e44d8f9470f5944d774c4", "url": "https://github.com/apache/samza/commit/762fa7de922655c2479e44d8f9470f5944d774c4", "message": "Update unit tests", "committedDate": "2020-01-17T19:48:10Z", "type": "commit"}, {"oid": "35f5db240c24b34dd1814930fc4ed6aa56e4b7c3", "url": "https://github.com/apache/samza/commit/35f5db240c24b34dd1814930fc4ed6aa56e4b7c3", "message": "Fix checkstyle in unit test", "committedDate": "2020-01-17T21:03:39Z", "type": "commit"}]}