{"pr_number": 2296, "pr_title": "[HUDI-1425] Performance loss with the additional hoodieRecords.isEmpty() in HoodieSparkSqlWriter#write", "pr_author": "pengzhiwei2018", "pr_createdAt": "2020-12-04T08:47:57Z", "pr_url": "https://github.com/apache/hudi/pull/2296", "timeline": [{"oid": "d4e3d89e0c02f1b9a704a61627f7aafec14e67e6", "url": "https://github.com/apache/hudi/commit/d4e3d89e0c02f1b9a704a61627f7aafec14e67e6", "message": "[HUDI-1425] Performance loss with the additional hoodieRecords.isEmpty() in HoodieSparkSqlWriter#write\n\nadd some test case\n\nskip empty commit\n\nfix test case\n\nadd comment\n\nremove useless change", "committedDate": "2021-02-03T02:16:13Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTgzMjIxNg==", "url": "https://github.com/apache/hudi/pull/2296#discussion_r665832216", "body": "we should actually have this generate an empty commit and test. If we don't then we checkpoints won't move. \r\nConsider this scenario, when deltastreamer reads from kafka using a custom transformer. If the transformer filters out all records from Kafka, we will have empty input for write, but the kafka offsets have to move ahead. ", "bodyText": "we should actually have this generate an empty commit and test. If we don't then we checkpoints won't move.\nConsider this scenario, when deltastreamer reads from kafka using a custom transformer. If the transformer filters out all records from Kafka, we will have empty input for write, but the kafka offsets have to move ahead.", "bodyHTML": "<p dir=\"auto\">we should actually have this generate an empty commit and test. If we don't then we checkpoints won't move.<br>\nConsider this scenario, when deltastreamer reads from kafka using a custom transformer. If the transformer filters out all records from Kafka, we will have empty input for write, but the kafka offsets have to move ahead.</p>", "author": "vinothchandar", "createdAt": "2021-07-08T02:50:55Z", "path": "hudi-utilities/src/test/java/org/apache/hudi/utilities/functional/TestHoodieDeltaStreamer.java", "diffHunk": "@@ -932,15 +932,10 @@ public void testFilterDupes() throws Exception {\n     ds2.sync();\n     mClient = new HoodieTableMetaClient(jsc.hadoopConfiguration(), tableBasePath, true);\n     HoodieInstant newLastFinished = mClient.getCommitsTimeline().filterCompletedInstants().lastInstant().get();\n-    assertTrue(HoodieTimeline.compareTimestamps(newLastFinished.getTimestamp(), HoodieTimeline.GREATER_THAN, lastFinished.getTimestamp()\n+    // there is not new commit generate for empty commits", "originalCommit": "d4e3d89e0c02f1b9a704a61627f7aafec14e67e6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2OTcwMTQxMg==", "url": "https://github.com/apache/hudi/pull/2296#discussion_r669701412", "bodyText": "Yes, can understand this. Will add config to control this and by default we allow the empty commits.", "author": "pengzhiwei2018", "createdAt": "2021-07-14T15:03:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDY2NTgzMjIxNg=="}], "type": "inlineReview"}, {"oid": "f04fd3e1c0f889389c08f533f6621eb843695e88", "url": "https://github.com/apache/hudi/commit/f04fd3e1c0f889389c08f533f6621eb843695e88", "message": "[HUDI-1425] Performance loss with the additional hoodieRecords.isEmpty() in HoodieSparkSqlWriter#write", "committedDate": "2021-07-29T02:24:50Z", "type": "commit"}, {"oid": "f04fd3e1c0f889389c08f533f6621eb843695e88", "url": "https://github.com/apache/hudi/commit/f04fd3e1c0f889389c08f533f6621eb843695e88", "message": "[HUDI-1425] Performance loss with the additional hoodieRecords.isEmpty() in HoodieSparkSqlWriter#write", "committedDate": "2021-07-29T02:24:50Z", "type": "forcePushed"}]}