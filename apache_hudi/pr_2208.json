{"pr_number": 2208, "pr_title": "[HUDI-1040] Make Hudi support Spark 3", "pr_author": "zhedoubushishi", "pr_createdAt": "2020-10-26T20:15:00Z", "pr_url": "https://github.com/apache/hudi/pull/2208", "timeline": [{"oid": "ed2714bb26e11b24707fcf13cebeb5e2116476c5", "url": "https://github.com/apache/hudi/commit/ed2714bb26e11b24707fcf13cebeb5e2116476c5", "message": "Add spark3 profile to handle fasterxml & spark version", "committedDate": "2020-10-28T18:58:40Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzczNjM0OQ==", "url": "https://github.com/apache/hudi/pull/2208#discussion_r513736349", "body": "let's file a tracking JIRA for this? ", "bodyText": "let's file a tracking JIRA for this?", "bodyHTML": "<p dir=\"auto\">let's file a tracking JIRA for this?</p>", "author": "vinothchandar", "createdAt": "2020-10-28T20:22:49Z", "path": "hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/testutils/SparkDatasetTestUtils.java", "diffHunk": "@@ -173,4 +176,17 @@ public static InternalRow getInternalRowWithError(String partitionPath) {\n         .withBulkInsertParallelism(2);\n   }\n \n+  private static InternalRow serializeRow(ExpressionEncoder encoder, Row row)\n+      throws InvocationTargetException, IllegalAccessException, NoSuchMethodException, ClassNotFoundException {\n+    // TODO remove reflection if Spark 2.x support is dropped", "originalCommit": "ed2714bb26e11b24707fcf13cebeb5e2116476c5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDYwMzE5NQ==", "url": "https://github.com/apache/hudi/pull/2208#discussion_r514603195", "body": "What is the need to move the `hudi datasource` itself to `hudi-spark2` ? I think we should leave it under `hudi-spark` and later if we want to have separate datasource implementations we can create separately under `hudi-spark2` and `hudi-spark3` modules. Thoughts ?", "bodyText": "What is the need to move the hudi datasource itself to hudi-spark2 ? I think we should leave it under hudi-spark and later if we want to have separate datasource implementations we can create separately under hudi-spark2 and hudi-spark3 modules. Thoughts ?", "bodyHTML": "<p dir=\"auto\">What is the need to move the <code>hudi datasource</code> itself to <code>hudi-spark2</code> ? I think we should leave it under <code>hudi-spark</code> and later if we want to have separate datasource implementations we can create separately under <code>hudi-spark2</code> and <code>hudi-spark3</code> modules. Thoughts ?</p>", "author": "umehrot2", "createdAt": "2020-10-29T22:26:58Z", "path": "hudi-spark2/src/main/java/org/apache/hudi/internal/DefaultSource.java", "diffHunk": "@@ -18,7 +18,7 @@\n \n package org.apache.hudi.internal;\n \n-import org.apache.hudi.DataSourceUtils;\n+import org.apache.hudi.DataSourceUtilsForSpark2;", "originalCommit": "ed2714bb26e11b24707fcf13cebeb5e2116476c5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTM5NjY4Mg==", "url": "https://github.com/apache/hudi/pull/2208#discussion_r515396682", "bodyText": "Because hudi-spark depends on hudi-spark2. I cannot also let hudi-spark2 depends on hudi-spark tho copying files is not a clean way.", "author": "zhedoubushishi", "createdAt": "2020-10-30T21:45:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDYwMzE5NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQxMDE3OA==", "url": "https://github.com/apache/hudi/pull/2208#discussion_r516410178", "bodyText": "I had misunderstood that you moved DefaultSource.scala which is the main datasource implementation. But seems like you have moved the internal datasource implementation used for bulk insert v2. So it seems fine to me.", "author": "umehrot2", "createdAt": "2020-11-03T03:27:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDYwMzE5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDYwOTgzNA==", "url": "https://github.com/apache/hudi/pull/2208#discussion_r514609834", "body": "As discussed internally regarding this in the code review, can you confirm if this is actually converting paths to point to local file system and not HDFS ? Also would be good to explain why you did this for reference in the description.", "bodyText": "As discussed internally regarding this in the code review, can you confirm if this is actually converting paths to point to local file system and not HDFS ? Also would be good to explain why you did this for reference in the description.", "bodyHTML": "<p dir=\"auto\">As discussed internally regarding this in the code review, can you confirm if this is actually converting paths to point to local file system and not HDFS ? Also would be good to explain why you did this for reference in the description.</p>", "author": "umehrot2", "createdAt": "2020-10-29T22:45:32Z", "path": "hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/testutils/HoodieMergeOnReadTestUtils.java", "diffHunk": "@@ -85,7 +85,7 @@\n         .collect(Collectors.toList()));\n \n     return inputPaths.stream().map(path -> {\n-      setInputPath(jobConf, path);\n+      FileInputFormat.setInputPaths(jobConf, path);", "originalCommit": "ed2714bb26e11b24707fcf13cebeb5e2116476c5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQyMDc2NA==", "url": "https://github.com/apache/hudi/pull/2208#discussion_r516420764", "bodyText": "Me and discussed discussed it internally and this is not a concern anymore.", "author": "umehrot2", "createdAt": "2020-11-03T04:19:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDYwOTgzNA=="}], "type": "inlineReview"}, {"oid": "eac8358868c44c1e031c00a11a4814a59a59d979", "url": "https://github.com/apache/hudi/commit/eac8358868c44c1e031c00a11a4814a59a59d979", "message": "Add spark3 profile to handle fasterxml & spark version", "committedDate": "2020-10-30T21:38:41Z", "type": "forcePushed"}, {"oid": "0df7521bf7ba087be882da55bc6ce3fd3c717a78", "url": "https://github.com/apache/hudi/commit/0df7521bf7ba087be882da55bc6ce3fd3c717a78", "message": "Add spark3 profile to handle fasterxml & spark version", "committedDate": "2020-11-01T22:53:34Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQwNjg3MQ==", "url": "https://github.com/apache/hudi/pull/2208#discussion_r516406871", "body": "It might make sense to create `Spark2RowSerializer` and `Spark3RowSerializer` similar to the implementations we have created for deserializers.", "bodyText": "It might make sense to create Spark2RowSerializer and Spark3RowSerializer similar to the implementations we have created for deserializers.", "bodyHTML": "<p dir=\"auto\">It might make sense to create <code>Spark2RowSerializer</code> and <code>Spark3RowSerializer</code> similar to the implementations we have created for deserializers.</p>", "author": "umehrot2", "createdAt": "2020-11-03T03:11:31Z", "path": "hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/testutils/SparkDatasetTestUtils.java", "diffHunk": "@@ -173,4 +176,17 @@ public static InternalRow getInternalRowWithError(String partitionPath) {\n         .withBulkInsertParallelism(2);\n   }\n \n+  private static InternalRow serializeRow(ExpressionEncoder encoder, Row row)\n+      throws InvocationTargetException, IllegalAccessException, NoSuchMethodException, ClassNotFoundException {\n+    // TODO remove reflection if Spark 2.x support is dropped\n+    if (package$.MODULE$.SPARK_VERSION().startsWith(\"2.\")) {\n+      Method spark2method = encoder.getClass().getMethod(\"toRow\", Object.class);\n+      return (InternalRow) spark2method.invoke(encoder, row);", "originalCommit": "0df7521bf7ba087be882da55bc6ce3fd3c717a78", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjk4NTUwMQ==", "url": "https://github.com/apache/hudi/pull/2208#discussion_r516985501", "bodyText": "The problem here is hudi-spark2 already depends on hudi-common and hudi-client. Say if I create Spark2RowSerializer under hudi-spark2, I also need to make hudi-client depends on hudi-spark2 and as a result, it will bring a dependency loop.", "author": "zhedoubushishi", "createdAt": "2020-11-03T22:11:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQwNjg3MQ=="}], "type": "inlineReview"}, {"oid": "fe002982d099af08df5f5ba4768a7b6905fa61c8", "url": "https://github.com/apache/hudi/commit/fe002982d099af08df5f5ba4768a7b6905fa61c8", "message": "relocate createRdd", "committedDate": "2020-11-04T06:50:21Z", "type": "forcePushed"}, {"oid": "2d55a9972fc4d6016f42d83286f5056fd2dfd3d7", "url": "https://github.com/apache/hudi/commit/2d55a9972fc4d6016f42d83286f5056fd2dfd3d7", "message": "Create hudi-spark-common module & refactor hudi-spark related modules", "committedDate": "2020-12-01T19:52:47Z", "type": "forcePushed"}, {"oid": "8ff0ebc8d6d750e59598d60da63997841af0b8a2", "url": "https://github.com/apache/hudi/commit/8ff0ebc8d6d750e59598d60da63997841af0b8a2", "message": "Fix flaky MOR unit test", "committedDate": "2020-12-08T22:09:42Z", "type": "commit"}, {"oid": "7ea7d3524a9679f60863d4630cb6673ec7845ad3", "url": "https://github.com/apache/hudi/commit/7ea7d3524a9679f60863d4630cb6673ec7845ad3", "message": "Update Spark APIs to make it be compatible with both spark2 & spark3", "committedDate": "2020-12-08T22:09:42Z", "type": "commit"}, {"oid": "f266e1786c1260aa900695a84685de96b83f41e1", "url": "https://github.com/apache/hudi/commit/f266e1786c1260aa900695a84685de96b83f41e1", "message": "Refactor bulk insert v2 part to make Hudi be able to compile with Spark3", "committedDate": "2020-12-08T22:09:42Z", "type": "commit"}, {"oid": "9b9b81819425170ae4ccbb74611294ec45826d0f", "url": "https://github.com/apache/hudi/commit/9b9b81819425170ae4ccbb74611294ec45826d0f", "message": "Add spark3 profile to handle fasterxml & spark version", "committedDate": "2020-12-08T22:09:42Z", "type": "commit"}, {"oid": "d51d3924bfae3b23969ce8b441bbf59a0ef71d32", "url": "https://github.com/apache/hudi/commit/d51d3924bfae3b23969ce8b441bbf59a0ef71d32", "message": "Create hudi-spark-common module & refactor hudi-spark related modules", "committedDate": "2020-12-08T22:09:43Z", "type": "commit"}, {"oid": "d51d3924bfae3b23969ce8b441bbf59a0ef71d32", "url": "https://github.com/apache/hudi/commit/d51d3924bfae3b23969ce8b441bbf59a0ef71d32", "message": "Create hudi-spark-common module & refactor hudi-spark related modules", "committedDate": "2020-12-08T22:09:43Z", "type": "forcePushed"}]}