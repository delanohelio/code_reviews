{"pr_number": 1869, "pr_title": "[HUDI-427] Implement CLI support for performing bootstrap", "pr_author": "zhedoubushishi", "pr_createdAt": "2020-07-24T05:10:11Z", "pr_url": "https://github.com/apache/hudi/pull/1869", "timeline": [{"oid": "3a8b113ad295802d163533f50f9b2bf7ef46289f", "url": "https://github.com/apache/hudi/commit/3a8b113ad295802d163533f50f9b2bf7ef46289f", "message": "[HUDI-971] Clean partitions & fileIds returned by HFileBootstrapIndex", "committedDate": "2020-08-07T21:13:18Z", "type": "commit"}, {"oid": "5bf14eb44a026095d2cfee0c757192b221943ec7", "url": "https://github.com/apache/hudi/commit/5bf14eb44a026095d2cfee0c757192b221943ec7", "message": "[HUDI-427] Implement CLI support for performing bootstrap", "committedDate": "2020-08-07T21:13:18Z", "type": "commit"}, {"oid": "5bf14eb44a026095d2cfee0c757192b221943ec7", "url": "https://github.com/apache/hudi/commit/5bf14eb44a026095d2cfee0c757192b221943ec7", "message": "[HUDI-427] Implement CLI support for performing bootstrap", "committedDate": "2020-08-07T21:13:18Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzM2OTM4Mg==", "url": "https://github.com/apache/hudi/pull/1869#discussion_r467369382", "body": "I reverted this method to be protected. This should not be used directly by  clients.  ", "bodyText": "I reverted this method to be protected. This should not be used directly by  clients.", "bodyHTML": "<p dir=\"auto\">I reverted this method to be protected. This should not be used directly by  clients.</p>", "author": "bvaradar", "createdAt": "2020-08-08T06:25:51Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/bootstrap/index/BootstrapIndex.java", "diffHunk": "@@ -73,12 +73,12 @@ public final boolean useIndex() {\n   /**\n    * Check if bootstrap Index is present and ensures readable.\n    */\n-  protected abstract boolean isPresent();\n+  public abstract boolean isPresent();", "originalCommit": "5bf14eb44a026095d2cfee0c757192b221943ec7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzM2OTQ2MA==", "url": "https://github.com/apache/hudi/pull/1869#discussion_r467369460", "body": "TO preserve uniformity with other CLIs, I renamed the CLI to be \"bootstrap index showpartitions\"", "bodyText": "TO preserve uniformity with other CLIs, I renamed the CLI to be \"bootstrap index showpartitions\"", "bodyHTML": "<p dir=\"auto\">TO preserve uniformity with other CLIs, I renamed the CLI to be \"bootstrap index showpartitions\"</p>", "author": "bvaradar", "createdAt": "2020-08-08T06:26:45Z", "path": "hudi-cli/src/main/java/org/apache/hudi/cli/commands/BootstrapCommand.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.cli.commands;\n+\n+import org.apache.hudi.cli.HoodieCLI;\n+import org.apache.hudi.cli.HoodiePrintHelper;\n+import org.apache.hudi.cli.TableHeader;\n+import org.apache.hudi.cli.commands.SparkMain.SparkCommand;\n+import org.apache.hudi.cli.utils.InputStreamConsumer;\n+import org.apache.hudi.cli.utils.SparkUtil;\n+import org.apache.hudi.common.bootstrap.index.BootstrapIndex;\n+import org.apache.hudi.common.model.BootstrapFileMapping;\n+import org.apache.hudi.common.model.HoodieFileGroupId;\n+import org.apache.hudi.common.table.HoodieTableMetaClient;\n+import org.apache.hudi.exception.HoodieException;\n+import org.apache.hudi.utilities.UtilHelpers;\n+\n+import org.apache.spark.launcher.SparkLauncher;\n+import org.apache.spark.util.Utils;\n+import org.springframework.shell.core.CommandMarker;\n+import org.springframework.shell.core.annotation.CliCommand;\n+import org.springframework.shell.core.annotation.CliOption;\n+import org.springframework.stereotype.Component;\n+\n+import java.io.IOException;\n+import java.net.URISyntaxException;\n+import java.util.Arrays;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import scala.collection.JavaConverters;\n+\n+/**\n+ * CLI command to perform bootstrap action & display bootstrap index.\n+ */\n+@Component\n+public class BootstrapCommand implements CommandMarker {\n+\n+  @CliCommand(value = \"bootstrap run\", help = \"Run a bootstrap action for current Hudi table\")\n+  public String bootstrap(\n+      @CliOption(key = {\"srcPath\"}, mandatory = true, help = \"Bootstrap source data path of the table\") final String srcPath,\n+      @CliOption(key = {\"targetPath\"}, mandatory = true,\n+          help = \"Base path for the target hoodie table\") final String targetPath,\n+      @CliOption(key = {\"tableName\"}, mandatory = true, help = \"Hoodie table name\") final String tableName,\n+      @CliOption(key = {\"tableType\"}, mandatory = true, help = \"Hoodie table type\") final String tableType,\n+      @CliOption(key = {\"rowKeyField\"}, mandatory = true, help = \"Record key columns for bootstrap data\") final String rowKeyField,\n+      @CliOption(key = {\"partitionPathField\"}, unspecifiedDefaultValue = \"\",\n+          help = \"Partition fields for bootstrap source data\") final String partitionPathField,\n+      @CliOption(key = {\"bootstrapIndexClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.common.bootstrap.index.HFileBootstrapIndex\",\n+          help = \"Bootstrap Index Class\") final String bootstrapIndexClass,\n+      @CliOption(key = {\"selectorClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.client.bootstrap.selector.MetadataOnlyBootstrapModeSelector\",\n+          help = \"Selector class for bootstrap\") final String selectorClass,\n+      @CliOption(key = {\"keyGeneratorClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.keygen.SimpleKeyGenerator\",\n+          help = \"Key generator class for bootstrap\") final String keyGeneratorClass,\n+      @CliOption(key = {\"fullBootstrapInputProvider\"}, unspecifiedDefaultValue = \"org.apache.hudi.bootstrap.SparkParquetBootstrapDataProvider\",\n+          help = \"Class for Full bootstrap input provider\") final String fullBootstrapInputProvider,\n+      @CliOption(key = {\"schemaProviderClass\"}, unspecifiedDefaultValue = \"\",\n+          help = \"SchemaProvider to attach schemas to bootstrap source data\") final String schemaProviderClass,\n+      @CliOption(key = {\"payloadClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.common.model.OverwriteWithLatestAvroPayload\",\n+          help = \"Payload Class\") final String payloadClass,\n+      @CliOption(key = {\"parallelism\"}, unspecifiedDefaultValue = \"1500\", help = \"Bootstrap writer parallelism\") final int parallelism,\n+      @CliOption(key = {\"sparkMaster\"}, unspecifiedDefaultValue = \"\", help = \"Spark Master\") String master,\n+      @CliOption(key = {\"sparkMemory\"}, unspecifiedDefaultValue = \"4G\", help = \"Spark executor memory\") final String sparkMemory,\n+      @CliOption(key = {\"enableHiveSync\"}, unspecifiedDefaultValue = \"false\", help = \"Enable Hive sync\") final Boolean enableHiveSync,\n+      @CliOption(key = {\"propsFilePath\"}, help = \"path to properties file on localfs or dfs with configurations for hoodie client for importing\",\n+          unspecifiedDefaultValue = \"\") final String propsFilePath,\n+      @CliOption(key = {\"hoodieConfigs\"}, help = \"Any configuration that can be set in the properties file can be passed here in the form of an array\",\n+          unspecifiedDefaultValue = \"\") final String[] configs)\n+      throws IOException, InterruptedException, URISyntaxException {\n+\n+    String sparkPropertiesPath =\n+        Utils.getDefaultPropertiesFile(JavaConverters.mapAsScalaMapConverter(System.getenv()).asScala());\n+\n+    SparkLauncher sparkLauncher = SparkUtil.initLauncher(sparkPropertiesPath);\n+\n+    String cmd = SparkCommand.BOOTSTRAP.toString();\n+\n+    sparkLauncher.addAppArgs(cmd, master, sparkMemory, tableName, tableType, targetPath, srcPath, rowKeyField,\n+        partitionPathField, String.valueOf(parallelism), schemaProviderClass, bootstrapIndexClass, selectorClass,\n+        keyGeneratorClass, fullBootstrapInputProvider, payloadClass, String.valueOf(enableHiveSync), propsFilePath);\n+    UtilHelpers.validateAndAddProperties(configs, sparkLauncher);\n+    Process process = sparkLauncher.launch();\n+    InputStreamConsumer.captureOutput(process);\n+    int exitCode = process.waitFor();\n+    if (exitCode != 0) {\n+      return \"Failed to bootstrap source data to Hudi dataset\";\n+    }\n+    return \"Bootstrapped source data as Hudi dataset\";\n+  }\n+\n+  @CliCommand(value = \"bootstrap index showMapping\", help = \"Show bootstrap index mapping\")\n+  public String showBootstrapIndexMapping(\n+      @CliOption(key = {\"partitionPath\"}, unspecifiedDefaultValue = \"\", help = \"A valid paritition path\") String partitionPath,\n+      @CliOption(key = {\"fileIds\"}, unspecifiedDefaultValue = \"\", help = \"Valid fileIds split by comma\") String fileIds,\n+      @CliOption(key = {\"limit\"}, unspecifiedDefaultValue = \"-1\", help = \"Limit rows to be displayed\") Integer limit,\n+      @CliOption(key = {\"sortBy\"}, unspecifiedDefaultValue = \"\", help = \"Sorting Field\") final String sortByField,\n+      @CliOption(key = {\"desc\"}, unspecifiedDefaultValue = \"false\", help = \"Ordering\") final boolean descending,\n+      @CliOption(key = {\"headeronly\"}, unspecifiedDefaultValue = \"false\", help = \"Print Header Only\")\n+      final boolean headerOnly) {\n+\n+    if (partitionPath.isEmpty() && !fileIds.isEmpty()) {\n+      throw new IllegalStateException(\"When passing fileIds, partitionPath is mandatory\");\n+    }\n+    BootstrapIndex.IndexReader indexReader = createBootstrapIndexReader();\n+    List<String> indexedPartitions = indexReader.getIndexedPartitionPaths();\n+\n+    if (!partitionPath.isEmpty() && !indexedPartitions.contains(partitionPath)) {\n+      return partitionPath + \" is not an valid indexed partition\";\n+    }\n+\n+    List<BootstrapFileMapping> mappingList = new ArrayList<>();\n+    if (!fileIds.isEmpty()) {\n+      List<HoodieFileGroupId> fileGroupIds = Arrays.stream(fileIds.split(\",\"))\n+          .map(fileId -> new HoodieFileGroupId(partitionPath, fileId)).collect(Collectors.toList());\n+      mappingList.addAll(indexReader.getSourceFileMappingForFileIds(fileGroupIds).values());\n+    } else if (!partitionPath.isEmpty()) {\n+      mappingList.addAll(indexReader.getSourceFileMappingForPartition(partitionPath));\n+    } else {\n+      for (String part : indexedPartitions) {\n+        mappingList.addAll(indexReader.getSourceFileMappingForPartition(part));\n+      }\n+    }\n+\n+    final List<Comparable[]> rows = convertBootstrapSourceFileMapping(mappingList);\n+    final TableHeader header = new TableHeader()\n+        .addTableHeaderField(\"Hudi Partition\")\n+        .addTableHeaderField(\"FileId\")\n+        .addTableHeaderField(\"Source File Base Path\")\n+        .addTableHeaderField(\"Source File Parition\")\n+        .addTableHeaderField(\"Source File Path\");\n+\n+    return HoodiePrintHelper.print(header, new HashMap<>(), sortByField, descending,\n+        limit, headerOnly, rows);\n+  }\n+\n+  @CliCommand(value = \"bootstrap index showPartitions\", help = \"Show bootstrap indexed partitions\")", "originalCommit": "5bf14eb44a026095d2cfee0c757192b221943ec7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzM2OTQ4Ng==", "url": "https://github.com/apache/hudi/pull/1869#discussion_r467369486", "body": "TO preserve uniformity with other CLIs, I renamed the CLI to be \"bootstrap index showmapping\"", "bodyText": "TO preserve uniformity with other CLIs, I renamed the CLI to be \"bootstrap index showmapping\"", "bodyHTML": "<p dir=\"auto\">TO preserve uniformity with other CLIs, I renamed the CLI to be \"bootstrap index showmapping\"</p>", "author": "bvaradar", "createdAt": "2020-08-08T06:26:59Z", "path": "hudi-cli/src/main/java/org/apache/hudi/cli/commands/BootstrapCommand.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.cli.commands;\n+\n+import org.apache.hudi.cli.HoodieCLI;\n+import org.apache.hudi.cli.HoodiePrintHelper;\n+import org.apache.hudi.cli.TableHeader;\n+import org.apache.hudi.cli.commands.SparkMain.SparkCommand;\n+import org.apache.hudi.cli.utils.InputStreamConsumer;\n+import org.apache.hudi.cli.utils.SparkUtil;\n+import org.apache.hudi.common.bootstrap.index.BootstrapIndex;\n+import org.apache.hudi.common.model.BootstrapFileMapping;\n+import org.apache.hudi.common.model.HoodieFileGroupId;\n+import org.apache.hudi.common.table.HoodieTableMetaClient;\n+import org.apache.hudi.exception.HoodieException;\n+import org.apache.hudi.utilities.UtilHelpers;\n+\n+import org.apache.spark.launcher.SparkLauncher;\n+import org.apache.spark.util.Utils;\n+import org.springframework.shell.core.CommandMarker;\n+import org.springframework.shell.core.annotation.CliCommand;\n+import org.springframework.shell.core.annotation.CliOption;\n+import org.springframework.stereotype.Component;\n+\n+import java.io.IOException;\n+import java.net.URISyntaxException;\n+import java.util.Arrays;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import scala.collection.JavaConverters;\n+\n+/**\n+ * CLI command to perform bootstrap action & display bootstrap index.\n+ */\n+@Component\n+public class BootstrapCommand implements CommandMarker {\n+\n+  @CliCommand(value = \"bootstrap run\", help = \"Run a bootstrap action for current Hudi table\")\n+  public String bootstrap(\n+      @CliOption(key = {\"srcPath\"}, mandatory = true, help = \"Bootstrap source data path of the table\") final String srcPath,\n+      @CliOption(key = {\"targetPath\"}, mandatory = true,\n+          help = \"Base path for the target hoodie table\") final String targetPath,\n+      @CliOption(key = {\"tableName\"}, mandatory = true, help = \"Hoodie table name\") final String tableName,\n+      @CliOption(key = {\"tableType\"}, mandatory = true, help = \"Hoodie table type\") final String tableType,\n+      @CliOption(key = {\"rowKeyField\"}, mandatory = true, help = \"Record key columns for bootstrap data\") final String rowKeyField,\n+      @CliOption(key = {\"partitionPathField\"}, unspecifiedDefaultValue = \"\",\n+          help = \"Partition fields for bootstrap source data\") final String partitionPathField,\n+      @CliOption(key = {\"bootstrapIndexClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.common.bootstrap.index.HFileBootstrapIndex\",\n+          help = \"Bootstrap Index Class\") final String bootstrapIndexClass,\n+      @CliOption(key = {\"selectorClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.client.bootstrap.selector.MetadataOnlyBootstrapModeSelector\",\n+          help = \"Selector class for bootstrap\") final String selectorClass,\n+      @CliOption(key = {\"keyGeneratorClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.keygen.SimpleKeyGenerator\",\n+          help = \"Key generator class for bootstrap\") final String keyGeneratorClass,\n+      @CliOption(key = {\"fullBootstrapInputProvider\"}, unspecifiedDefaultValue = \"org.apache.hudi.bootstrap.SparkParquetBootstrapDataProvider\",\n+          help = \"Class for Full bootstrap input provider\") final String fullBootstrapInputProvider,\n+      @CliOption(key = {\"schemaProviderClass\"}, unspecifiedDefaultValue = \"\",\n+          help = \"SchemaProvider to attach schemas to bootstrap source data\") final String schemaProviderClass,\n+      @CliOption(key = {\"payloadClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.common.model.OverwriteWithLatestAvroPayload\",\n+          help = \"Payload Class\") final String payloadClass,\n+      @CliOption(key = {\"parallelism\"}, unspecifiedDefaultValue = \"1500\", help = \"Bootstrap writer parallelism\") final int parallelism,\n+      @CliOption(key = {\"sparkMaster\"}, unspecifiedDefaultValue = \"\", help = \"Spark Master\") String master,\n+      @CliOption(key = {\"sparkMemory\"}, unspecifiedDefaultValue = \"4G\", help = \"Spark executor memory\") final String sparkMemory,\n+      @CliOption(key = {\"enableHiveSync\"}, unspecifiedDefaultValue = \"false\", help = \"Enable Hive sync\") final Boolean enableHiveSync,\n+      @CliOption(key = {\"propsFilePath\"}, help = \"path to properties file on localfs or dfs with configurations for hoodie client for importing\",\n+          unspecifiedDefaultValue = \"\") final String propsFilePath,\n+      @CliOption(key = {\"hoodieConfigs\"}, help = \"Any configuration that can be set in the properties file can be passed here in the form of an array\",\n+          unspecifiedDefaultValue = \"\") final String[] configs)\n+      throws IOException, InterruptedException, URISyntaxException {\n+\n+    String sparkPropertiesPath =\n+        Utils.getDefaultPropertiesFile(JavaConverters.mapAsScalaMapConverter(System.getenv()).asScala());\n+\n+    SparkLauncher sparkLauncher = SparkUtil.initLauncher(sparkPropertiesPath);\n+\n+    String cmd = SparkCommand.BOOTSTRAP.toString();\n+\n+    sparkLauncher.addAppArgs(cmd, master, sparkMemory, tableName, tableType, targetPath, srcPath, rowKeyField,\n+        partitionPathField, String.valueOf(parallelism), schemaProviderClass, bootstrapIndexClass, selectorClass,\n+        keyGeneratorClass, fullBootstrapInputProvider, payloadClass, String.valueOf(enableHiveSync), propsFilePath);\n+    UtilHelpers.validateAndAddProperties(configs, sparkLauncher);\n+    Process process = sparkLauncher.launch();\n+    InputStreamConsumer.captureOutput(process);\n+    int exitCode = process.waitFor();\n+    if (exitCode != 0) {\n+      return \"Failed to bootstrap source data to Hudi dataset\";\n+    }\n+    return \"Bootstrapped source data as Hudi dataset\";\n+  }\n+\n+  @CliCommand(value = \"bootstrap index showMapping\", help = \"Show bootstrap index mapping\")", "originalCommit": "5bf14eb44a026095d2cfee0c757192b221943ec7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzM3MDM0Ng==", "url": "https://github.com/apache/hudi/pull/1869#discussion_r467370346", "body": "Nit: typos, Will fix them", "bodyText": "Nit: typos, Will fix them", "bodyHTML": "<p dir=\"auto\">Nit: typos, Will fix them</p>", "author": "bvaradar", "createdAt": "2020-08-08T06:38:14Z", "path": "hudi-cli/src/main/java/org/apache/hudi/cli/commands/BootstrapCommand.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.cli.commands;\n+\n+import org.apache.hudi.cli.HoodieCLI;\n+import org.apache.hudi.cli.HoodiePrintHelper;\n+import org.apache.hudi.cli.TableHeader;\n+import org.apache.hudi.cli.commands.SparkMain.SparkCommand;\n+import org.apache.hudi.cli.utils.InputStreamConsumer;\n+import org.apache.hudi.cli.utils.SparkUtil;\n+import org.apache.hudi.common.bootstrap.index.BootstrapIndex;\n+import org.apache.hudi.common.model.BootstrapFileMapping;\n+import org.apache.hudi.common.model.HoodieFileGroupId;\n+import org.apache.hudi.common.table.HoodieTableMetaClient;\n+import org.apache.hudi.exception.HoodieException;\n+import org.apache.hudi.utilities.UtilHelpers;\n+\n+import org.apache.spark.launcher.SparkLauncher;\n+import org.apache.spark.util.Utils;\n+import org.springframework.shell.core.CommandMarker;\n+import org.springframework.shell.core.annotation.CliCommand;\n+import org.springframework.shell.core.annotation.CliOption;\n+import org.springframework.stereotype.Component;\n+\n+import java.io.IOException;\n+import java.net.URISyntaxException;\n+import java.util.Arrays;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import scala.collection.JavaConverters;\n+\n+/**\n+ * CLI command to perform bootstrap action & display bootstrap index.\n+ */\n+@Component\n+public class BootstrapCommand implements CommandMarker {\n+\n+  @CliCommand(value = \"bootstrap run\", help = \"Run a bootstrap action for current Hudi table\")\n+  public String bootstrap(\n+      @CliOption(key = {\"srcPath\"}, mandatory = true, help = \"Bootstrap source data path of the table\") final String srcPath,\n+      @CliOption(key = {\"targetPath\"}, mandatory = true,\n+          help = \"Base path for the target hoodie table\") final String targetPath,\n+      @CliOption(key = {\"tableName\"}, mandatory = true, help = \"Hoodie table name\") final String tableName,\n+      @CliOption(key = {\"tableType\"}, mandatory = true, help = \"Hoodie table type\") final String tableType,\n+      @CliOption(key = {\"rowKeyField\"}, mandatory = true, help = \"Record key columns for bootstrap data\") final String rowKeyField,\n+      @CliOption(key = {\"partitionPathField\"}, unspecifiedDefaultValue = \"\",\n+          help = \"Partition fields for bootstrap source data\") final String partitionPathField,\n+      @CliOption(key = {\"bootstrapIndexClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.common.bootstrap.index.HFileBootstrapIndex\",\n+          help = \"Bootstrap Index Class\") final String bootstrapIndexClass,\n+      @CliOption(key = {\"selectorClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.client.bootstrap.selector.MetadataOnlyBootstrapModeSelector\",\n+          help = \"Selector class for bootstrap\") final String selectorClass,\n+      @CliOption(key = {\"keyGeneratorClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.keygen.SimpleKeyGenerator\",\n+          help = \"Key generator class for bootstrap\") final String keyGeneratorClass,\n+      @CliOption(key = {\"fullBootstrapInputProvider\"}, unspecifiedDefaultValue = \"org.apache.hudi.bootstrap.SparkParquetBootstrapDataProvider\",\n+          help = \"Class for Full bootstrap input provider\") final String fullBootstrapInputProvider,\n+      @CliOption(key = {\"schemaProviderClass\"}, unspecifiedDefaultValue = \"\",\n+          help = \"SchemaProvider to attach schemas to bootstrap source data\") final String schemaProviderClass,\n+      @CliOption(key = {\"payloadClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.common.model.OverwriteWithLatestAvroPayload\",\n+          help = \"Payload Class\") final String payloadClass,\n+      @CliOption(key = {\"parallelism\"}, unspecifiedDefaultValue = \"1500\", help = \"Bootstrap writer parallelism\") final int parallelism,\n+      @CliOption(key = {\"sparkMaster\"}, unspecifiedDefaultValue = \"\", help = \"Spark Master\") String master,\n+      @CliOption(key = {\"sparkMemory\"}, unspecifiedDefaultValue = \"4G\", help = \"Spark executor memory\") final String sparkMemory,\n+      @CliOption(key = {\"enableHiveSync\"}, unspecifiedDefaultValue = \"false\", help = \"Enable Hive sync\") final Boolean enableHiveSync,\n+      @CliOption(key = {\"propsFilePath\"}, help = \"path to properties file on localfs or dfs with configurations for hoodie client for importing\",\n+          unspecifiedDefaultValue = \"\") final String propsFilePath,\n+      @CliOption(key = {\"hoodieConfigs\"}, help = \"Any configuration that can be set in the properties file can be passed here in the form of an array\",\n+          unspecifiedDefaultValue = \"\") final String[] configs)\n+      throws IOException, InterruptedException, URISyntaxException {\n+\n+    String sparkPropertiesPath =\n+        Utils.getDefaultPropertiesFile(JavaConverters.mapAsScalaMapConverter(System.getenv()).asScala());\n+\n+    SparkLauncher sparkLauncher = SparkUtil.initLauncher(sparkPropertiesPath);\n+\n+    String cmd = SparkCommand.BOOTSTRAP.toString();\n+\n+    sparkLauncher.addAppArgs(cmd, master, sparkMemory, tableName, tableType, targetPath, srcPath, rowKeyField,\n+        partitionPathField, String.valueOf(parallelism), schemaProviderClass, bootstrapIndexClass, selectorClass,\n+        keyGeneratorClass, fullBootstrapInputProvider, payloadClass, String.valueOf(enableHiveSync), propsFilePath);\n+    UtilHelpers.validateAndAddProperties(configs, sparkLauncher);\n+    Process process = sparkLauncher.launch();\n+    InputStreamConsumer.captureOutput(process);\n+    int exitCode = process.waitFor();\n+    if (exitCode != 0) {\n+      return \"Failed to bootstrap source data to Hudi dataset\";\n+    }\n+    return \"Bootstrapped source data as Hudi dataset\";\n+  }\n+\n+  @CliCommand(value = \"bootstrap index showMapping\", help = \"Show bootstrap index mapping\")\n+  public String showBootstrapIndexMapping(\n+      @CliOption(key = {\"partitionPath\"}, unspecifiedDefaultValue = \"\", help = \"A valid paritition path\") String partitionPath,", "originalCommit": "5bf14eb44a026095d2cfee0c757192b221943ec7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "99e5d7a7a7073a03d8408e40561032813821f7ed", "url": "https://github.com/apache/hudi/commit/99e5d7a7a7073a03d8408e40561032813821f7ed", "message": "[HUDI-427] Address review comments", "committedDate": "2020-08-08T06:41:09Z", "type": "commit"}, {"oid": "22009287af4244992fd5a0136c8ba28df64cd2cb", "url": "https://github.com/apache/hudi/commit/22009287af4244992fd5a0136c8ba28df64cd2cb", "message": "Add error message for a failing test", "committedDate": "2020-08-08T07:35:47Z", "type": "commit"}, {"oid": "5546c15334974a066962facd356d4fd25bd56542", "url": "https://github.com/apache/hudi/commit/5546c15334974a066962facd356d4fd25bd56542", "message": "Add error message for a failing test", "committedDate": "2020-08-08T08:08:33Z", "type": "commit"}, {"oid": "f9dd21b257ee6266e797e42d5ad7dcb6657bc2a4", "url": "https://github.com/apache/hudi/commit/f9dd21b257ee6266e797e42d5ad7dcb6657bc2a4", "message": "Reverting default payload class", "committedDate": "2020-08-08T17:48:02Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzQ4ODMxNg==", "url": "https://github.com/apache/hudi/pull/1869#discussion_r467488316", "body": "Let's retain the old payload class for now. We can rethink about this as part of upgrade-downgrade (https://issues.apache.org/jira/browse/HUDI-1172)", "bodyText": "Let's retain the old payload class for now. We can rethink about this as part of upgrade-downgrade (https://issues.apache.org/jira/browse/HUDI-1172)", "bodyHTML": "<p dir=\"auto\">Let's retain the old payload class for now. We can rethink about this as part of upgrade-downgrade (<a href=\"https://issues.apache.org/jira/browse/HUDI-1172\" rel=\"nofollow\">https://issues.apache.org/jira/browse/HUDI-1172</a>)</p>", "author": "bvaradar", "createdAt": "2020-08-08T17:51:24Z", "path": "hudi-cli/src/main/java/org/apache/hudi/cli/commands/TableCommand.java", "diffHunk": "@@ -87,7 +87,7 @@ public String createTable(\n           help = \"Hoodie Table Type. Must be one of : COPY_ON_WRITE or MERGE_ON_READ\") final String tableTypeStr,\n       @CliOption(key = {\"archiveLogFolder\"}, help = \"Folder Name for storing archived timeline\") String archiveFolder,\n       @CliOption(key = {\"layoutVersion\"}, help = \"Specific Layout Version to use\") Integer layoutVersion,\n-      @CliOption(key = {\"payloadClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.common.model.HoodieAvroPayload\",\n+      @CliOption(key = {\"payloadClass\"}, unspecifiedDefaultValue = \"org.apache.hudi.common.model.OverwriteWithLatestAvroPayload\",", "originalCommit": "5546c15334974a066962facd356d4fd25bd56542", "replyToReviewId": null, "replies": null, "type": "inlineReview"}]}