{"pr_number": 1810, "pr_title": "[HUDI-875] Abstract hudi-sync-common, and support hudi-hive-sync", "pr_author": "lw309637554", "pr_createdAt": "2020-07-08T16:13:06Z", "pr_url": "https://github.com/apache/hudi/pull/1810", "timeline": [{"oid": "4c08849c4d7226118202ca4dbeaa63634b16daf3", "url": "https://github.com/apache/hudi/commit/4c08849c4d7226118202ca4dbeaa63634b16daf3", "message": "[HUDI-875] Abstract hudi-sync-common, and support hudi-hive-sync", "committedDate": "2020-07-15T04:17:54Z", "type": "commit"}, {"oid": "4c08849c4d7226118202ca4dbeaa63634b16daf3", "url": "https://github.com/apache/hudi/commit/4c08849c4d7226118202ca4dbeaa63634b16daf3", "message": "[HUDI-875] Abstract hudi-sync-common, and support hudi-hive-sync", "committedDate": "2020-07-15T04:17:54Z", "type": "forcePushed"}, {"oid": "36979503d9f4d44281136caadc51ab681e1cf056", "url": "https://github.com/apache/hudi/commit/36979503d9f4d44281136caadc51ab681e1cf056", "message": " [HUDI-875] Abstract support hudi-dla-sync", "committedDate": "2020-07-15T09:18:54Z", "type": "commit"}, {"oid": "36979503d9f4d44281136caadc51ab681e1cf056", "url": "https://github.com/apache/hudi/commit/36979503d9f4d44281136caadc51ab681e1cf056", "message": " [HUDI-875] Abstract support hudi-dla-sync", "committedDate": "2020-07-15T09:18:54Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDk3Mzk2MQ==", "url": "https://github.com/apache/hudi/pull/1810#discussion_r454973961", "body": "since dla meta do not support alter table properties yet, it would be simpler here", "bodyText": "since dla meta do not support alter table properties yet, it would be simpler here", "bodyHTML": "<p dir=\"auto\">since dla meta do not support alter table properties yet, it would be simpler here</p>", "author": "leesf", "createdAt": "2020-07-15T11:12:23Z", "path": "hudi-sync/hudi-dla-sync/src/main/java/org/apache/hudi/dla/DLASyncTool.java", "diffHunk": "@@ -0,0 +1,211 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.dla;\n+\n+import com.beust.jcommander.JCommander;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat;\n+import org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe;\n+import org.apache.hudi.common.fs.FSUtils;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.dla.util.Utils;\n+import org.apache.hudi.exception.HoodieException;\n+import org.apache.hudi.exception.InvalidTableException;\n+import org.apache.hudi.hadoop.HoodieParquetInputFormat;\n+import org.apache.hudi.hadoop.realtime.HoodieParquetRealtimeInputFormat;\n+import org.apache.hudi.hive.SchemaDifference;\n+import org.apache.hudi.hive.util.HiveSchemaUtil;\n+import org.apache.hudi.sync.common.AbstractSyncHoodieClient;\n+import org.apache.hudi.sync.common.AbstractSyncTool;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+import org.apache.parquet.schema.MessageType;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.stream.Collectors;\n+\n+/**\n+ * Tool to sync a hoodie table with a dla table. Either use it as a api\n+ * DLASyncTool.syncHoodieTable(DLASyncConfig) or as a command line java -cp hoodie-hive.jar DLASyncTool [args]\n+ * <p>\n+ * This utility will get the schema from the latest commit and will sync dla table schema Also this will sync the\n+ * partitions incrementally (all the partitions modified since the last commit)\n+ */\n+@SuppressWarnings(\"WeakerAccess\")\n+public class DLASyncTool extends AbstractSyncTool {\n+\n+  private static final Logger LOG = LogManager.getLogger(DLASyncTool.class);\n+  public static final String SUFFIX_SNAPSHOT_TABLE = \"_rt\";\n+  public static final String SUFFIX_READ_OPTIMIZED_TABLE = \"_ro\";\n+\n+  private final DLASyncConfig cfg;\n+  private final HoodieDLAClient hoodieDLAClient;\n+  private final String snapshotTableName;\n+  private final Option<String> roTableTableName;\n+\n+  public DLASyncTool(Properties properties, FileSystem fs) {\n+    super(properties, fs);\n+    this.hoodieDLAClient = new HoodieDLAClient(Utils.propertiesToConfig(properties), fs);\n+    this.cfg = Utils.propertiesToConfig(properties);\n+    switch (hoodieDLAClient.getTableType()) {\n+      case COPY_ON_WRITE:\n+        this.snapshotTableName = cfg.tableName;\n+        this.roTableTableName = Option.empty();\n+        break;\n+      case MERGE_ON_READ:\n+        this.snapshotTableName = cfg.tableName + SUFFIX_SNAPSHOT_TABLE;\n+        this.roTableTableName = cfg.skipROSuffix ? Option.of(cfg.tableName) :\n+            Option.of(cfg.tableName + SUFFIX_READ_OPTIMIZED_TABLE);\n+        break;\n+      default:\n+        LOG.error(\"Unknown table type \" + hoodieDLAClient.getTableType());\n+        throw new InvalidTableException(hoodieDLAClient.getBasePath());\n+    }\n+  }\n+\n+  @Override\n+  public void syncHoodieTable() {\n+    try {\n+      switch (hoodieDLAClient.getTableType()) {\n+        case COPY_ON_WRITE:\n+          syncHoodieTable(snapshotTableName, false);\n+          break;\n+        case MERGE_ON_READ:\n+          // sync a RO table for MOR\n+          syncHoodieTable(roTableTableName.get(), false);\n+          // sync a RT table for MOR\n+          syncHoodieTable(snapshotTableName, true);\n+          break;\n+        default:\n+          LOG.error(\"Unknown table type \" + hoodieDLAClient.getTableType());\n+          throw new InvalidTableException(hoodieDLAClient.getBasePath());\n+      }\n+    } catch (RuntimeException re) {\n+      LOG.error(\"Got runtime exception when dla syncing\", re);\n+    } finally {\n+      hoodieDLAClient.close();\n+    }\n+  }\n+\n+  private void syncHoodieTable(String tableName, boolean useRealtimeInputFormat) {\n+    LOG.info(\"Trying to sync hoodie table \" + tableName + \" with base path \" + hoodieDLAClient.getBasePath()\n+        + \" of type \" + hoodieDLAClient.getTableType());\n+    // Check if the necessary table exists\n+    boolean tableExists = hoodieDLAClient.doesTableExist(tableName);\n+    // Get the parquet schema for this table looking at the latest commit\n+    MessageType schema = hoodieDLAClient.getDataSchema();\n+    // Sync schema if needed\n+    syncSchema(tableName, tableExists, useRealtimeInputFormat, schema);\n+\n+    LOG.info(\"Schema sync complete. Syncing partitions for \" + tableName);\n+    // Get the last time we successfully synced partitions\n+    Option<String> lastCommitTimeSynced = Option.empty();\n+    /*if (tableExists) {\n+      lastCommitTimeSynced = hoodieDLAClient.getLastCommitTimeSynced(tableName);\n+    }*/\n+    LOG.info(\"Last commit time synced was found to be \" + lastCommitTimeSynced.orElse(\"null\"));", "originalCommit": "36979503d9f4d44281136caadc51ab681e1cf056", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTAxMTAyMw==", "url": "https://github.com/apache/hudi/pull/1810#discussion_r455011023", "bodyText": "yes", "author": "lw309637554", "createdAt": "2020-07-15T12:25:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDk3Mzk2MQ=="}], "type": "inlineReview"}, {"oid": "458d7ebfff40114bb4c8536fec25038bf89deed1", "url": "https://github.com/apache/hudi/commit/458d7ebfff40114bb4c8536fec25038bf89deed1", "message": " [HUDI-875] merge master", "committedDate": "2020-08-01T16:05:38Z", "type": "commit"}, {"oid": "fcc3a9c1444f8488164a570d506abe6ab245644c", "url": "https://github.com/apache/hudi/commit/fcc3a9c1444f8488164a570d506abe6ab245644c", "message": "Merge branch 'master' into pull/1810", "committedDate": "2020-08-04T04:04:43Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDgwNTU1OA==", "url": "https://github.com/apache/hudi/pull/1810#discussion_r464805558", "body": "can we print a warning around this, so the user knows? \r\n\r\nhere's my take. we can change the code so that --enable-sync and --sync-tool-class-list are the main drivers out of which we derive a `Set<String>` denoting all the sync tool classes. if --enable-hive-sync is specified, then we simply add the hive sync tool class to this set.. rest of the code just syncs to all sync tools in this set. \r\n\r\nthis way, `--enable-hive-sync` will be just isolated to the initial command line parsing code. We can apply the same method to datasource as well, if you don't see issues  @lw309637554 @leesf wdyt? ", "bodyText": "can we print a warning around this, so the user knows?\nhere's my take. we can change the code so that --enable-sync and --sync-tool-class-list are the main drivers out of which we derive a Set<String> denoting all the sync tool classes. if --enable-hive-sync is specified, then we simply add the hive sync tool class to this set.. rest of the code just syncs to all sync tools in this set.\nthis way, --enable-hive-sync will be just isolated to the initial command line parsing code. We can apply the same method to datasource as well, if you don't see issues  @lw309637554 @leesf wdyt?", "bodyHTML": "<p dir=\"auto\">can we print a warning around this, so the user knows?</p>\n<p dir=\"auto\">here's my take. we can change the code so that --enable-sync and --sync-tool-class-list are the main drivers out of which we derive a <code>Set&lt;String&gt;</code> denoting all the sync tool classes. if --enable-hive-sync is specified, then we simply add the hive sync tool class to this set.. rest of the code just syncs to all sync tools in this set.</p>\n<p dir=\"auto\">this way, <code>--enable-hive-sync</code> will be just isolated to the initial command line parsing code. We can apply the same method to datasource as well, if you don't see issues  <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/users/lw309637554/hovercard\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/lw309637554\">@lw309637554</a> <a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/users/leesf/hovercard\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/leesf\">@leesf</a> wdyt?</p>", "author": "vinothchandar", "createdAt": "2020-08-04T05:20:06Z", "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/deltastreamer/HoodieDeltaStreamer.java", "diffHunk": "@@ -267,9 +267,16 @@ public Operation convert(String value) throws ParameterException {\n         description = \"Should duplicate records from source be dropped/filtered out before insert/bulk-insert\")\n     public Boolean filterDupes = false;\n \n+    //will abandon in the future version, recommended use --enable-sync", "originalCommit": "fcc3a9c1444f8488164a570d506abe6ab245644c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTEzMzA5Mg==", "url": "https://github.com/apache/hudi/pull/1810#discussion_r465133092", "bodyText": "agree with you ,and  i will do it", "author": "lw309637554", "createdAt": "2020-08-04T15:22:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDgwNTU1OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDgwNTk4OQ==", "url": "https://github.com/apache/hudi/pull/1810#discussion_r464805989", "body": "what if both hive and meta sync are off? we would still emit metrics for meta? ", "bodyText": "what if both hive and meta sync are off? we would still emit metrics for meta?", "bodyHTML": "<p dir=\"auto\">what if both hive and meta sync are off? we would still emit metrics for meta?</p>", "author": "vinothchandar", "createdAt": "2020-08-04T05:21:33Z", "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/deltastreamer/HoodieDeltaStreamerMetrics.java", "diffHunk": "@@ -67,10 +77,15 @@ String getMetricsName(String action, String metric) {\n     return config == null ? null : String.format(\"%s.%s.%s\", tableName, action, metric);\n   }\n \n-  public void updateDeltaStreamerMetrics(long durationInNs, long hiveSyncNs) {\n+  public void updateDeltaStreamerMetrics(long durationInNs, long syncNs, boolean hiveSync) {\n     if (config.isMetricsOn()) {\n       Metrics.registerGauge(getMetricsName(\"deltastreamer\", \"duration\"), getDurationInMs(durationInNs));\n-      Metrics.registerGauge(getMetricsName(\"deltastreamer\", \"hiveSyncDuration\"), getDurationInMs(hiveSyncNs));\n+      if (hiveSync) {\n+        Metrics.registerGauge(getMetricsName(\"deltastreamer\", \"hiveSyncDuration\"), getDurationInMs(syncNs));\n+      } else {\n+        Metrics.registerGauge(getMetricsName(\"deltastreamer\", \"metaSyncDuration\"), getDurationInMs(syncNs));", "originalCommit": "fcc3a9c1444f8488164a570d506abe6ab245644c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDgwNjU5NA==", "url": "https://github.com/apache/hudi/pull/1810#discussion_r464806594", "bodyText": "should we derive the metric name from the sync tool class. i.e instead of metaSyncDuration, we do dlaSyncDuration?  that seems more usable and understandable", "author": "vinothchandar", "createdAt": "2020-08-04T05:24:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDgwNTk4OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTE1NzA1Nw==", "url": "https://github.com/apache/hudi/pull/1810#discussion_r465157057", "bodyText": "i have do it , different  sync tool class have its own metrics with name of sync class", "author": "lw309637554", "createdAt": "2020-08-04T15:57:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDgwNTk4OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDgwNjMzNQ==", "url": "https://github.com/apache/hudi/pull/1810#discussion_r464806335", "body": "is there a way to do this by iterating over the configured sync tool classes? i.e only do it when sync is configured?  ", "bodyText": "is there a way to do this by iterating over the configured sync tool classes? i.e only do it when sync is configured?", "bodyHTML": "<p dir=\"auto\">is there a way to do this by iterating over the configured sync tool classes? i.e only do it when sync is configured?</p>", "author": "vinothchandar", "createdAt": "2020-08-04T05:23:01Z", "path": "hudi-utilities/src/main/java/org/apache/hudi/utilities/deltastreamer/DeltaSync.java", "diffHunk": "@@ -442,7 +449,8 @@ private void refreshTimeline() throws IOException {\n     long overallTimeMs = overallTimerContext != null ? overallTimerContext.stop() : 0;\n \n     // Send DeltaStreamer Metrics\n-    metrics.updateDeltaStreamerMetrics(overallTimeMs, hiveSyncTimeMs);\n+    metrics.updateDeltaStreamerMetrics(overallTimeMs, hiveSyncTimeMs, true);\n+    metrics.updateDeltaStreamerMetrics(overallTimeMs, metaSyncTimeMs, false);", "originalCommit": "fcc3a9c1444f8488164a570d506abe6ab245644c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTE1ODYwOA==", "url": "https://github.com/apache/hudi/pull/1810#discussion_r465158608", "bodyText": "ok  , have do this in syncMeta", "author": "lw309637554", "createdAt": "2020-08-04T15:59:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDgwNjMzNQ=="}], "type": "inlineReview"}, {"oid": "e35037775016004364176de7f46091ce2b8ba49e", "url": "https://github.com/apache/hudi/commit/e35037775016004364176de7f46091ce2b8ba49e", "message": "Smaller CR feedback", "committedDate": "2020-08-04T05:43:53Z", "type": "commit"}, {"oid": "3808c3253e6d71c0b7b504046be0c1e9bde969d7", "url": "https://github.com/apache/hudi/commit/3808c3253e6d71c0b7b504046be0c1e9bde969d7", "message": "[HUDI-875] complete metasync metrics and sync all syncclasses", "committedDate": "2020-08-05T13:08:33Z", "type": "commit"}, {"oid": "3808c3253e6d71c0b7b504046be0c1e9bde969d7", "url": "https://github.com/apache/hudi/commit/3808c3253e6d71c0b7b504046be0c1e9bde969d7", "message": "[HUDI-875] complete metasync metrics and sync all syncclasses", "committedDate": "2020-08-05T13:08:33Z", "type": "forcePushed"}, {"oid": "4dae21dd4f23fdbe3e394886e3c94765ed2377f8", "url": "https://github.com/apache/hudi/commit/4dae21dd4f23fdbe3e394886e3c94765ed2377f8", "message": "merge master", "committedDate": "2020-08-06T03:07:13Z", "type": "commit"}, {"oid": "4dae21dd4f23fdbe3e394886e3c94765ed2377f8", "url": "https://github.com/apache/hudi/commit/4dae21dd4f23fdbe3e394886e3c94765ed2377f8", "message": "merge master", "committedDate": "2020-08-06T03:07:13Z", "type": "forcePushed"}]}