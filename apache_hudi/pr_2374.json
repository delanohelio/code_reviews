{"pr_number": 2374, "pr_title": "[HUDI-845] Added locking capability to allow multiple writers", "pr_createdAt": "2020-12-24T06:35:33Z", "pr_url": "https://github.com/apache/hudi/pull/2374", "timeline": [{"oid": "592e4bda9aed9af895b60db0d07393b2a6916d30", "url": "https://github.com/apache/hudi/commit/592e4bda9aed9af895b60db0d07393b2a6916d30", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution", "committedDate": "2020-12-28T05:09:44Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MDY2NA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549550664", "bodyText": "AtomicReference to handle multiple threads using the same client object? +1", "author": "vinothchandar", "createdAt": "2020-12-29T03:00:21Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieClient.java", "diffHunk": "@@ -48,6 +50,7 @@\n   protected final transient Configuration hadoopConf;\n   protected final HoodieWriteConfig config;\n   protected final String basePath;\n+  protected AtomicReference<Option<HoodieInstant>> latestWriteInstantCompletedBeforeWriter = new AtomicReference<>();", "originalCommit": "592e4bda9aed9af895b60db0d07393b2a6916d30", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MDc1Ng==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549550756", "bodyText": "Since this is specific to writing, can we put this in the AbstractHoodieWriteClient subclass?", "author": "vinothchandar", "createdAt": "2020-12-29T03:01:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MDY2NA=="}], "type": "inlineReview", "revised_code": {"commit": "98c3c7ddf879d514e5c14293fee145c92f9416a3", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieClient.java\nindex 52c9e1731..51826e752 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieClient.java\n", "chunk": "@@ -50,7 +47,6 @@ public abstract class AbstractHoodieClient implements Serializable, AutoCloseabl\n   protected final transient Configuration hadoopConf;\n   protected final HoodieWriteConfig config;\n   protected final String basePath;\n-  protected AtomicReference<Option<HoodieInstant>> latestWriteInstantCompletedBeforeWriter = new AtomicReference<>();\n \n   /**\n    * Timeline Server has the same lifetime as that of Client. Any operations done on the same timeline service will be\n", "next_change": {"commit": "289e45a28da6b91fba2a824ec2af3771a34b2930", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieClient.java\nindex 51826e752..350fe0c9b 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieClient.java\n", "chunk": "@@ -47,6 +49,7 @@ public abstract class AbstractHoodieClient implements Serializable, AutoCloseabl\n   protected final transient Configuration hadoopConf;\n   protected final HoodieWriteConfig config;\n   protected final String basePath;\n+  protected final HoodieHeartbeatClient heartbeatClient;\n \n   /**\n    * Timeline Server has the same lifetime as that of Client. Any operations done on the same timeline service will be\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MDk3Ng==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549550976", "bodyText": "use the concurrency mode config introduced by the other PR and use that instead to fence this block?", "author": "vinothchandar", "createdAt": "2020-12-29T03:02:40Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -203,6 +208,45 @@ public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Opti\n     return true;\n   }\n \n+  public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n+                             String commitActionType, Map<String, List<String>> partitionToReplaceFileIds) {\n+\n+    HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n+        operationType, config.getSchema(), commitActionType);\n+    if (config.isMultiWriterEnabled()) {", "originalCommit": "592e4bda9aed9af895b60db0d07393b2a6916d30", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDg1MTg2OQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r550851869", "bodyText": "That's the plan, once it's landed will change this, for now, this config is just a place holder.", "author": "n3nash", "createdAt": "2021-01-02T06:52:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MDk3Ng=="}], "type": "inlineReview", "revised_code": {"commit": "98c3c7ddf879d514e5c14293fee145c92f9416a3", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex e41c1c3ba..42e513e33 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -214,34 +222,10 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n         operationType, config.getSchema(), commitActionType);\n     if (config.isMultiWriterEnabled()) {\n-      // get strategy and lock type\n       LockConfiguration lockConfiguration = new LockConfiguration(config.getProps());\n       LockProvider lockProvider = (LockProvider) ReflectionUtils.loadClass(config.getLockProviderClass(),\n           lockConfiguration, fs.getConf());\n-      try {\n-        // TODO : Get timeout and set the timeout\n-        boolean acquired = lockProvider.tryLock();\n-        if (!acquired) {\n-          throw new HoodieException(\"Unable to acquire lock\");\n-        }\n-        LOG.info(\"Acquired lock for instant time \" + instantTime);\n-        // TODO : Move the following to a \"critical section\"\n-        // Create a Hoodie table which encapsulated the commits and files visible.\n-        // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n-        HoodieTable table = createTable(config, hadoopConf);\n-        try {\n-          metadata = resolveWriteConflictIfAny(table, instantTime, metadata);\n-          return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-        } catch (Exception e) {\n-          // if strategy throws exception, first release lock\n-          lockProvider.unlock();\n-          LOG.info(\"Released lock for instant time \" + instantTime);\n-          throw new HoodieException(e);\n-        }\n-      } finally {\n-        lockProvider.unlock();\n-        LOG.info(\"Released lock if acquired for instant time \" + instantTime);\n-      }\n+      return criticalSectionForWrite(instantTime, stats, extraMetadata, commitActionType, lockProvider, metadata);\n     } else {\n       return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n     }\n", "next_change": {"commit": "57de565ef4bb6ea4386e80fb20d39eeb8dd96455", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 42e513e33..ffb0b3506 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -221,11 +226,10 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n     HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n         operationType, config.getSchema(), commitActionType);\n-    if (config.isMultiWriterEnabled()) {\n+    if (config.getWriteConcurrencyMode().isMultiWriter()) {\n       LockConfiguration lockConfiguration = new LockConfiguration(config.getProps());\n-      LockProvider lockProvider = (LockProvider) ReflectionUtils.loadClass(config.getLockProviderClass(),\n-          lockConfiguration, fs.getConf());\n-      return criticalSectionForWrite(instantTime, stats, extraMetadata, commitActionType, lockProvider, metadata);\n+      LockProvider lockProvider = LockProviderSingleton.getLockProviderInstance(config, lockConfiguration, fs);\n+      return executeCriticalSection(instantTime, stats, extraMetadata, commitActionType, lockProvider, metadata);\n     } else {\n       return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n     }\n", "next_change": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ffb0b3506..ea6c6f81a 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -226,13 +213,26 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n     HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n         operationType, config.getSchema(), commitActionType);\n-    if (config.getWriteConcurrencyMode().isMultiWriter()) {\n-      LockConfiguration lockConfiguration = new LockConfiguration(config.getProps());\n-      LockProvider lockProvider = LockProviderSingleton.getLockProviderInstance(config, lockConfiguration, fs);\n-      return executeCriticalSection(instantTime, stats, extraMetadata, commitActionType, lockProvider, metadata);\n-    } else {\n-      return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-    }\n+    return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n+  }\n+\n+  private void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n+    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n+    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n+    HoodieTable table = createTable(config, hadoopConf);\n+    HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n+    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), instantTime, metadata, config, txnManager.getLastCompletedTransaction());\n+  }\n+\n+  private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n+                      List<HoodieWriteStat> stats) throws IOException {\n+    preCommit(instantTime, metadata);\n+    LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n+    HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n+    // Finalize write\n+    finalizeWrite(table, instantTime, stats);\n+    activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n+        Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n \n   protected abstract HoodieTable<T, I, K, O> createTable(HoodieWriteConfig config, Configuration hadoopConf);\n", "next_change": {"commit": "25a4d7f70cc0cfcec115ddfcc2a543a96bcb17af", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ea6c6f81a..063b26db8 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -221,7 +221,8 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n     HoodieTable table = createTable(config, hadoopConf);\n     HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), instantTime, metadata, config, txnManager.getLastCompletedTransaction());\n+    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), this.txnManager.getCurrentTxnInstant(),\n+        metadata, config, txnManager.getLastCompletedTransaction());\n   }\n \n   private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n", "next_change": {"commit": "f5a56cb4137b5f32af17405277c29d5a9088b6c7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 063b26db8..d45d77154 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,15 +216,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n-    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n-    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n-    HoodieTable table = createTable(config, hadoopConf);\n-    HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), this.txnManager.getCurrentTxnInstant(),\n-        metadata, config, txnManager.getLastCompletedTransaction());\n-  }\n-\n   private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "49dec09bfb444866e678fe956b28c3bf0ad2f373", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex d45d77154..4c1f5bf3c 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,7 +213,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n+  protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n", "next_change": {"commit": "0552abcc6400675c11ee35a4d4f3df109463f6f5", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 4c1f5bf3c..f0ebc54f7 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -220,8 +220,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata(true);\n-    this.txnManager.endTransaction();\n+    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n", "next_change": {"commit": "289e45a28da6b91fba2a824ec2af3771a34b2930", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex f0ebc54f7..3b9e08dd3 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -205,14 +200,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return true;\n   }\n \n-  public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n-                             String commitActionType, Map<String, List<String>> partitionToReplaceFileIds) {\n-\n-    HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n-        operationType, config.getSchema(), commitActionType);\n-    return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-  }\n-\n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 3b9e08dd3..12c55370f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -202,7 +203,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n-    preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n", "next_change": {"commit": "02efbb661e7ed13c3614ddee7ab5157623070f7c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 12c55370f..996648c0e 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -207,15 +210,12 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n \n   protected abstract HoodieTable<T, I, K, O> createTable(HoodieWriteConfig config, Configuration hadoopConf);\n \n-  protected abstract HoodieBackedTableMetadataWriter createMetadataWriter(HoodieWriteConfig config, Configuration hadoopConf);\n-\n   void emitCommitMetrics(String instantTime, HoodieCommitMetadata metadata, String actionType) {\n     try {\n \n", "next_change": null}]}}]}}]}}]}}]}}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ea6c6f81a..063b26db8 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -231,6 +232,8 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n+    syncTableMetadata(true);\n+    this.txnManager.endTransaction();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n", "next_change": {"commit": "f5a56cb4137b5f32af17405277c29d5a9088b6c7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 063b26db8..d45d77154 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,15 +216,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n-    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n-    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n-    HoodieTable table = createTable(config, hadoopConf);\n-    HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), this.txnManager.getCurrentTxnInstant(),\n-        metadata, config, txnManager.getLastCompletedTransaction());\n-  }\n-\n   private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "49dec09bfb444866e678fe956b28c3bf0ad2f373", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex d45d77154..4c1f5bf3c 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,7 +213,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n+  protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n", "next_change": {"commit": "0552abcc6400675c11ee35a4d4f3df109463f6f5", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 4c1f5bf3c..f0ebc54f7 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -220,8 +220,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata(true);\n-    this.txnManager.endTransaction();\n+    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n", "next_change": {"commit": "289e45a28da6b91fba2a824ec2af3771a34b2930", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex f0ebc54f7..3b9e08dd3 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -205,14 +200,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return true;\n   }\n \n-  public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n-                             String commitActionType, Map<String, List<String>> partitionToReplaceFileIds) {\n-\n-    HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n-        operationType, config.getSchema(), commitActionType);\n-    return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-  }\n-\n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 3b9e08dd3..12c55370f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -202,7 +203,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n-    preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n", "next_change": {"commit": "02efbb661e7ed13c3614ddee7ab5157623070f7c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 12c55370f..996648c0e 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -207,15 +210,12 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n \n   protected abstract HoodieTable<T, I, K, O> createTable(HoodieWriteConfig config, Configuration hadoopConf);\n \n-  protected abstract HoodieBackedTableMetadataWriter createMetadataWriter(HoodieWriteConfig config, Configuration hadoopConf);\n-\n   void emitCommitMetrics(String instantTime, HoodieCommitMetadata metadata, String actionType) {\n     try {\n \n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 42e513e33..ffb0b3506 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -233,6 +237,8 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n   protected abstract HoodieTable<T, I, K, O> createTable(HoodieWriteConfig config, Configuration hadoopConf);\n \n+  protected abstract HoodieBackedTableMetadataWriter createMetadataWriter(HoodieWriteConfig config, Configuration hadoopConf);\n+\n   void emitCommitMetrics(String instantTime, HoodieCommitMetadata metadata, String actionType) {\n     try {\n \n", "next_change": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ffb0b3506..ea6c6f81a 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -226,13 +213,26 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n     HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n         operationType, config.getSchema(), commitActionType);\n-    if (config.getWriteConcurrencyMode().isMultiWriter()) {\n-      LockConfiguration lockConfiguration = new LockConfiguration(config.getProps());\n-      LockProvider lockProvider = LockProviderSingleton.getLockProviderInstance(config, lockConfiguration, fs);\n-      return executeCriticalSection(instantTime, stats, extraMetadata, commitActionType, lockProvider, metadata);\n-    } else {\n-      return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-    }\n+    return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n+  }\n+\n+  private void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n+    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n+    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n+    HoodieTable table = createTable(config, hadoopConf);\n+    HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n+    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), instantTime, metadata, config, txnManager.getLastCompletedTransaction());\n+  }\n+\n+  private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n+                      List<HoodieWriteStat> stats) throws IOException {\n+    preCommit(instantTime, metadata);\n+    LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n+    HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n+    // Finalize write\n+    finalizeWrite(table, instantTime, stats);\n+    activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n+        Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n \n   protected abstract HoodieTable<T, I, K, O> createTable(HoodieWriteConfig config, Configuration hadoopConf);\n", "next_change": {"commit": "25a4d7f70cc0cfcec115ddfcc2a543a96bcb17af", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ea6c6f81a..063b26db8 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -221,7 +221,8 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n     HoodieTable table = createTable(config, hadoopConf);\n     HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), instantTime, metadata, config, txnManager.getLastCompletedTransaction());\n+    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), this.txnManager.getCurrentTxnInstant(),\n+        metadata, config, txnManager.getLastCompletedTransaction());\n   }\n \n   private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n", "next_change": {"commit": "f5a56cb4137b5f32af17405277c29d5a9088b6c7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 063b26db8..d45d77154 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,15 +216,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n-    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n-    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n-    HoodieTable table = createTable(config, hadoopConf);\n-    HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), this.txnManager.getCurrentTxnInstant(),\n-        metadata, config, txnManager.getLastCompletedTransaction());\n-  }\n-\n   private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "49dec09bfb444866e678fe956b28c3bf0ad2f373", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex d45d77154..4c1f5bf3c 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,7 +213,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n+  protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n", "next_change": {"commit": "0552abcc6400675c11ee35a4d4f3df109463f6f5", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 4c1f5bf3c..f0ebc54f7 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -220,8 +220,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata(true);\n-    this.txnManager.endTransaction();\n+    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n", "next_change": {"commit": "289e45a28da6b91fba2a824ec2af3771a34b2930", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex f0ebc54f7..3b9e08dd3 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -205,14 +200,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return true;\n   }\n \n-  public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n-                             String commitActionType, Map<String, List<String>> partitionToReplaceFileIds) {\n-\n-    HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n-        operationType, config.getSchema(), commitActionType);\n-    return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-  }\n-\n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 3b9e08dd3..12c55370f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -202,7 +203,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n-    preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n", "next_change": {"commit": "02efbb661e7ed13c3614ddee7ab5157623070f7c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 12c55370f..996648c0e 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -207,15 +210,12 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n \n   protected abstract HoodieTable<T, I, K, O> createTable(HoodieWriteConfig config, Configuration hadoopConf);\n \n-  protected abstract HoodieBackedTableMetadataWriter createMetadataWriter(HoodieWriteConfig config, Configuration hadoopConf);\n-\n   void emitCommitMetrics(String instantTime, HoodieCommitMetadata metadata, String actionType) {\n     try {\n \n", "next_change": null}]}}]}}]}}]}}]}}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ea6c6f81a..063b26db8 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -231,6 +232,8 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n+    syncTableMetadata(true);\n+    this.txnManager.endTransaction();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n", "next_change": {"commit": "f5a56cb4137b5f32af17405277c29d5a9088b6c7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 063b26db8..d45d77154 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,15 +216,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n-    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n-    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n-    HoodieTable table = createTable(config, hadoopConf);\n-    HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), this.txnManager.getCurrentTxnInstant(),\n-        metadata, config, txnManager.getLastCompletedTransaction());\n-  }\n-\n   private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "49dec09bfb444866e678fe956b28c3bf0ad2f373", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex d45d77154..4c1f5bf3c 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,7 +213,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n+  protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n", "next_change": {"commit": "0552abcc6400675c11ee35a4d4f3df109463f6f5", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 4c1f5bf3c..f0ebc54f7 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -220,8 +220,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata(true);\n-    this.txnManager.endTransaction();\n+    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n", "next_change": {"commit": "289e45a28da6b91fba2a824ec2af3771a34b2930", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex f0ebc54f7..3b9e08dd3 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -205,14 +200,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return true;\n   }\n \n-  public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n-                             String commitActionType, Map<String, List<String>> partitionToReplaceFileIds) {\n-\n-    HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n-        operationType, config.getSchema(), commitActionType);\n-    return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-  }\n-\n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 3b9e08dd3..12c55370f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -202,7 +203,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n-    preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n", "next_change": {"commit": "02efbb661e7ed13c3614ddee7ab5157623070f7c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 12c55370f..996648c0e 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -207,15 +210,12 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n \n   protected abstract HoodieTable<T, I, K, O> createTable(HoodieWriteConfig config, Configuration hadoopConf);\n \n-  protected abstract HoodieBackedTableMetadataWriter createMetadataWriter(HoodieWriteConfig config, Configuration hadoopConf);\n-\n   void emitCommitMetrics(String instantTime, HoodieCommitMetadata metadata, String actionType) {\n     try {\n \n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MTAzNg==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549551036", "bodyText": "some more context on basePath, inner exception if any ?", "author": "vinothchandar", "createdAt": "2020-12-29T03:03:08Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -203,6 +208,45 @@ public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Opti\n     return true;\n   }\n \n+  public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n+                             String commitActionType, Map<String, List<String>> partitionToReplaceFileIds) {\n+\n+    HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n+        operationType, config.getSchema(), commitActionType);\n+    if (config.isMultiWriterEnabled()) {\n+      // get strategy and lock type\n+      LockConfiguration lockConfiguration = new LockConfiguration(config.getProps());\n+      LockProvider lockProvider = (LockProvider) ReflectionUtils.loadClass(config.getLockProviderClass(),\n+          lockConfiguration, fs.getConf());\n+      try {\n+        // TODO : Get timeout and set the timeout\n+        boolean acquired = lockProvider.tryLock();\n+        if (!acquired) {\n+          throw new HoodieException(\"Unable to acquire lock\");", "originalCommit": "592e4bda9aed9af895b60db0d07393b2a6916d30", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "98c3c7ddf879d514e5c14293fee145c92f9416a3", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex e41c1c3ba..42e513e33 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -214,34 +222,10 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n         operationType, config.getSchema(), commitActionType);\n     if (config.isMultiWriterEnabled()) {\n-      // get strategy and lock type\n       LockConfiguration lockConfiguration = new LockConfiguration(config.getProps());\n       LockProvider lockProvider = (LockProvider) ReflectionUtils.loadClass(config.getLockProviderClass(),\n           lockConfiguration, fs.getConf());\n-      try {\n-        // TODO : Get timeout and set the timeout\n-        boolean acquired = lockProvider.tryLock();\n-        if (!acquired) {\n-          throw new HoodieException(\"Unable to acquire lock\");\n-        }\n-        LOG.info(\"Acquired lock for instant time \" + instantTime);\n-        // TODO : Move the following to a \"critical section\"\n-        // Create a Hoodie table which encapsulated the commits and files visible.\n-        // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n-        HoodieTable table = createTable(config, hadoopConf);\n-        try {\n-          metadata = resolveWriteConflictIfAny(table, instantTime, metadata);\n-          return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-        } catch (Exception e) {\n-          // if strategy throws exception, first release lock\n-          lockProvider.unlock();\n-          LOG.info(\"Released lock for instant time \" + instantTime);\n-          throw new HoodieException(e);\n-        }\n-      } finally {\n-        lockProvider.unlock();\n-        LOG.info(\"Released lock if acquired for instant time \" + instantTime);\n-      }\n+      return criticalSectionForWrite(instantTime, stats, extraMetadata, commitActionType, lockProvider, metadata);\n     } else {\n       return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n     }\n", "next_change": {"commit": "57de565ef4bb6ea4386e80fb20d39eeb8dd96455", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 42e513e33..ffb0b3506 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -221,11 +226,10 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n     HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n         operationType, config.getSchema(), commitActionType);\n-    if (config.isMultiWriterEnabled()) {\n+    if (config.getWriteConcurrencyMode().isMultiWriter()) {\n       LockConfiguration lockConfiguration = new LockConfiguration(config.getProps());\n-      LockProvider lockProvider = (LockProvider) ReflectionUtils.loadClass(config.getLockProviderClass(),\n-          lockConfiguration, fs.getConf());\n-      return criticalSectionForWrite(instantTime, stats, extraMetadata, commitActionType, lockProvider, metadata);\n+      LockProvider lockProvider = LockProviderSingleton.getLockProviderInstance(config, lockConfiguration, fs);\n+      return executeCriticalSection(instantTime, stats, extraMetadata, commitActionType, lockProvider, metadata);\n     } else {\n       return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n     }\n", "next_change": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ffb0b3506..ea6c6f81a 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -226,13 +213,26 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n     HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n         operationType, config.getSchema(), commitActionType);\n-    if (config.getWriteConcurrencyMode().isMultiWriter()) {\n-      LockConfiguration lockConfiguration = new LockConfiguration(config.getProps());\n-      LockProvider lockProvider = LockProviderSingleton.getLockProviderInstance(config, lockConfiguration, fs);\n-      return executeCriticalSection(instantTime, stats, extraMetadata, commitActionType, lockProvider, metadata);\n-    } else {\n-      return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-    }\n+    return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n+  }\n+\n+  private void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n+    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n+    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n+    HoodieTable table = createTable(config, hadoopConf);\n+    HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n+    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), instantTime, metadata, config, txnManager.getLastCompletedTransaction());\n+  }\n+\n+  private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n+                      List<HoodieWriteStat> stats) throws IOException {\n+    preCommit(instantTime, metadata);\n+    LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n+    HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n+    // Finalize write\n+    finalizeWrite(table, instantTime, stats);\n+    activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n+        Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n \n   protected abstract HoodieTable<T, I, K, O> createTable(HoodieWriteConfig config, Configuration hadoopConf);\n", "next_change": {"commit": "25a4d7f70cc0cfcec115ddfcc2a543a96bcb17af", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ea6c6f81a..063b26db8 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -221,7 +221,8 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n     HoodieTable table = createTable(config, hadoopConf);\n     HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), instantTime, metadata, config, txnManager.getLastCompletedTransaction());\n+    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), this.txnManager.getCurrentTxnInstant(),\n+        metadata, config, txnManager.getLastCompletedTransaction());\n   }\n \n   private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n", "next_change": {"commit": "f5a56cb4137b5f32af17405277c29d5a9088b6c7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 063b26db8..d45d77154 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,15 +216,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n-    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n-    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n-    HoodieTable table = createTable(config, hadoopConf);\n-    HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), this.txnManager.getCurrentTxnInstant(),\n-        metadata, config, txnManager.getLastCompletedTransaction());\n-  }\n-\n   private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "49dec09bfb444866e678fe956b28c3bf0ad2f373", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex d45d77154..4c1f5bf3c 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,7 +213,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n+  protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n", "next_change": {"commit": "0552abcc6400675c11ee35a4d4f3df109463f6f5", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 4c1f5bf3c..f0ebc54f7 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -220,8 +220,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata(true);\n-    this.txnManager.endTransaction();\n+    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n", "next_change": {"commit": "289e45a28da6b91fba2a824ec2af3771a34b2930", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex f0ebc54f7..3b9e08dd3 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -205,14 +200,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return true;\n   }\n \n-  public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n-                             String commitActionType, Map<String, List<String>> partitionToReplaceFileIds) {\n-\n-    HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n-        operationType, config.getSchema(), commitActionType);\n-    return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-  }\n-\n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 3b9e08dd3..12c55370f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -202,7 +203,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n-    preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n", "next_change": {"commit": "02efbb661e7ed13c3614ddee7ab5157623070f7c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 12c55370f..996648c0e 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -207,15 +210,12 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n \n   protected abstract HoodieTable<T, I, K, O> createTable(HoodieWriteConfig config, Configuration hadoopConf);\n \n-  protected abstract HoodieBackedTableMetadataWriter createMetadataWriter(HoodieWriteConfig config, Configuration hadoopConf);\n-\n   void emitCommitMetrics(String instantTime, HoodieCommitMetadata metadata, String actionType) {\n     try {\n \n", "next_change": null}]}}]}}]}}]}}]}}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ea6c6f81a..063b26db8 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -231,6 +232,8 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n+    syncTableMetadata(true);\n+    this.txnManager.endTransaction();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n", "next_change": {"commit": "f5a56cb4137b5f32af17405277c29d5a9088b6c7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 063b26db8..d45d77154 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,15 +216,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n-    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n-    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n-    HoodieTable table = createTable(config, hadoopConf);\n-    HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), this.txnManager.getCurrentTxnInstant(),\n-        metadata, config, txnManager.getLastCompletedTransaction());\n-  }\n-\n   private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "49dec09bfb444866e678fe956b28c3bf0ad2f373", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex d45d77154..4c1f5bf3c 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,7 +213,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n+  protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n", "next_change": {"commit": "0552abcc6400675c11ee35a4d4f3df109463f6f5", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 4c1f5bf3c..f0ebc54f7 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -220,8 +220,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata(true);\n-    this.txnManager.endTransaction();\n+    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n", "next_change": {"commit": "289e45a28da6b91fba2a824ec2af3771a34b2930", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex f0ebc54f7..3b9e08dd3 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -205,14 +200,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return true;\n   }\n \n-  public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n-                             String commitActionType, Map<String, List<String>> partitionToReplaceFileIds) {\n-\n-    HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n-        operationType, config.getSchema(), commitActionType);\n-    return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-  }\n-\n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 3b9e08dd3..12c55370f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -202,7 +203,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n-    preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n", "next_change": {"commit": "02efbb661e7ed13c3614ddee7ab5157623070f7c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 12c55370f..996648c0e 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -207,15 +210,12 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n \n   protected abstract HoodieTable<T, I, K, O> createTable(HoodieWriteConfig config, Configuration hadoopConf);\n \n-  protected abstract HoodieBackedTableMetadataWriter createMetadataWriter(HoodieWriteConfig config, Configuration hadoopConf);\n-\n   void emitCommitMetrics(String instantTime, HoodieCommitMetadata metadata, String actionType) {\n     try {\n \n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 42e513e33..ffb0b3506 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -233,6 +237,8 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n   protected abstract HoodieTable<T, I, K, O> createTable(HoodieWriteConfig config, Configuration hadoopConf);\n \n+  protected abstract HoodieBackedTableMetadataWriter createMetadataWriter(HoodieWriteConfig config, Configuration hadoopConf);\n+\n   void emitCommitMetrics(String instantTime, HoodieCommitMetadata metadata, String actionType) {\n     try {\n \n", "next_change": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ffb0b3506..ea6c6f81a 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -226,13 +213,26 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n     HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n         operationType, config.getSchema(), commitActionType);\n-    if (config.getWriteConcurrencyMode().isMultiWriter()) {\n-      LockConfiguration lockConfiguration = new LockConfiguration(config.getProps());\n-      LockProvider lockProvider = LockProviderSingleton.getLockProviderInstance(config, lockConfiguration, fs);\n-      return executeCriticalSection(instantTime, stats, extraMetadata, commitActionType, lockProvider, metadata);\n-    } else {\n-      return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-    }\n+    return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n+  }\n+\n+  private void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n+    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n+    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n+    HoodieTable table = createTable(config, hadoopConf);\n+    HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n+    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), instantTime, metadata, config, txnManager.getLastCompletedTransaction());\n+  }\n+\n+  private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n+                      List<HoodieWriteStat> stats) throws IOException {\n+    preCommit(instantTime, metadata);\n+    LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n+    HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n+    // Finalize write\n+    finalizeWrite(table, instantTime, stats);\n+    activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n+        Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n \n   protected abstract HoodieTable<T, I, K, O> createTable(HoodieWriteConfig config, Configuration hadoopConf);\n", "next_change": {"commit": "25a4d7f70cc0cfcec115ddfcc2a543a96bcb17af", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ea6c6f81a..063b26db8 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -221,7 +221,8 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n     HoodieTable table = createTable(config, hadoopConf);\n     HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), instantTime, metadata, config, txnManager.getLastCompletedTransaction());\n+    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), this.txnManager.getCurrentTxnInstant(),\n+        metadata, config, txnManager.getLastCompletedTransaction());\n   }\n \n   private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n", "next_change": {"commit": "f5a56cb4137b5f32af17405277c29d5a9088b6c7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 063b26db8..d45d77154 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,15 +216,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n-    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n-    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n-    HoodieTable table = createTable(config, hadoopConf);\n-    HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), this.txnManager.getCurrentTxnInstant(),\n-        metadata, config, txnManager.getLastCompletedTransaction());\n-  }\n-\n   private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "49dec09bfb444866e678fe956b28c3bf0ad2f373", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex d45d77154..4c1f5bf3c 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,7 +213,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n+  protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n", "next_change": {"commit": "0552abcc6400675c11ee35a4d4f3df109463f6f5", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 4c1f5bf3c..f0ebc54f7 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -220,8 +220,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata(true);\n-    this.txnManager.endTransaction();\n+    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n", "next_change": {"commit": "289e45a28da6b91fba2a824ec2af3771a34b2930", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex f0ebc54f7..3b9e08dd3 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -205,14 +200,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return true;\n   }\n \n-  public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n-                             String commitActionType, Map<String, List<String>> partitionToReplaceFileIds) {\n-\n-    HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n-        operationType, config.getSchema(), commitActionType);\n-    return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-  }\n-\n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 3b9e08dd3..12c55370f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -202,7 +203,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n-    preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n", "next_change": {"commit": "02efbb661e7ed13c3614ddee7ab5157623070f7c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 12c55370f..996648c0e 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -207,15 +210,12 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n \n   protected abstract HoodieTable<T, I, K, O> createTable(HoodieWriteConfig config, Configuration hadoopConf);\n \n-  protected abstract HoodieBackedTableMetadataWriter createMetadataWriter(HoodieWriteConfig config, Configuration hadoopConf);\n-\n   void emitCommitMetrics(String instantTime, HoodieCommitMetadata metadata, String actionType) {\n     try {\n \n", "next_change": null}]}}]}}]}}]}}]}}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ea6c6f81a..063b26db8 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -231,6 +232,8 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n+    syncTableMetadata(true);\n+    this.txnManager.endTransaction();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n", "next_change": {"commit": "f5a56cb4137b5f32af17405277c29d5a9088b6c7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 063b26db8..d45d77154 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,15 +216,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n-    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n-    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n-    HoodieTable table = createTable(config, hadoopConf);\n-    HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), this.txnManager.getCurrentTxnInstant(),\n-        metadata, config, txnManager.getLastCompletedTransaction());\n-  }\n-\n   private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "49dec09bfb444866e678fe956b28c3bf0ad2f373", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex d45d77154..4c1f5bf3c 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,7 +213,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n+  protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n", "next_change": {"commit": "0552abcc6400675c11ee35a4d4f3df109463f6f5", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 4c1f5bf3c..f0ebc54f7 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -220,8 +220,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata(true);\n-    this.txnManager.endTransaction();\n+    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n", "next_change": {"commit": "289e45a28da6b91fba2a824ec2af3771a34b2930", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex f0ebc54f7..3b9e08dd3 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -205,14 +200,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return true;\n   }\n \n-  public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n-                             String commitActionType, Map<String, List<String>> partitionToReplaceFileIds) {\n-\n-    HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n-        operationType, config.getSchema(), commitActionType);\n-    return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-  }\n-\n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 3b9e08dd3..12c55370f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -202,7 +203,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n-    preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n", "next_change": {"commit": "02efbb661e7ed13c3614ddee7ab5157623070f7c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 12c55370f..996648c0e 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -207,15 +210,12 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n \n   protected abstract HoodieTable<T, I, K, O> createTable(HoodieWriteConfig config, Configuration hadoopConf);\n \n-  protected abstract HoodieBackedTableMetadataWriter createMetadataWriter(HoodieWriteConfig config, Configuration hadoopConf);\n-\n   void emitCommitMetrics(String instantTime, HoodieCommitMetadata metadata, String actionType) {\n     try {\n \n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MTE2Mg==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549551162", "bodyText": "is TODO still valid?", "author": "vinothchandar", "createdAt": "2020-12-29T03:03:47Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -203,6 +208,45 @@ public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Opti\n     return true;\n   }\n \n+  public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n+                             String commitActionType, Map<String, List<String>> partitionToReplaceFileIds) {\n+\n+    HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n+        operationType, config.getSchema(), commitActionType);\n+    if (config.isMultiWriterEnabled()) {\n+      // get strategy and lock type\n+      LockConfiguration lockConfiguration = new LockConfiguration(config.getProps());\n+      LockProvider lockProvider = (LockProvider) ReflectionUtils.loadClass(config.getLockProviderClass(),\n+          lockConfiguration, fs.getConf());\n+      try {\n+        // TODO : Get timeout and set the timeout\n+        boolean acquired = lockProvider.tryLock();\n+        if (!acquired) {\n+          throw new HoodieException(\"Unable to acquire lock\");\n+        }\n+        LOG.info(\"Acquired lock for instant time \" + instantTime);\n+        // TODO : Move the following to a \"critical section\"", "originalCommit": "592e4bda9aed9af895b60db0d07393b2a6916d30", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDk3MjA2Ng==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r550972066", "bodyText": "Not anymore", "author": "n3nash", "createdAt": "2021-01-03T08:07:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MTE2Mg=="}], "type": "inlineReview", "revised_code": {"commit": "98c3c7ddf879d514e5c14293fee145c92f9416a3", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex e41c1c3ba..42e513e33 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -214,34 +222,10 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n         operationType, config.getSchema(), commitActionType);\n     if (config.isMultiWriterEnabled()) {\n-      // get strategy and lock type\n       LockConfiguration lockConfiguration = new LockConfiguration(config.getProps());\n       LockProvider lockProvider = (LockProvider) ReflectionUtils.loadClass(config.getLockProviderClass(),\n           lockConfiguration, fs.getConf());\n-      try {\n-        // TODO : Get timeout and set the timeout\n-        boolean acquired = lockProvider.tryLock();\n-        if (!acquired) {\n-          throw new HoodieException(\"Unable to acquire lock\");\n-        }\n-        LOG.info(\"Acquired lock for instant time \" + instantTime);\n-        // TODO : Move the following to a \"critical section\"\n-        // Create a Hoodie table which encapsulated the commits and files visible.\n-        // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n-        HoodieTable table = createTable(config, hadoopConf);\n-        try {\n-          metadata = resolveWriteConflictIfAny(table, instantTime, metadata);\n-          return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-        } catch (Exception e) {\n-          // if strategy throws exception, first release lock\n-          lockProvider.unlock();\n-          LOG.info(\"Released lock for instant time \" + instantTime);\n-          throw new HoodieException(e);\n-        }\n-      } finally {\n-        lockProvider.unlock();\n-        LOG.info(\"Released lock if acquired for instant time \" + instantTime);\n-      }\n+      return criticalSectionForWrite(instantTime, stats, extraMetadata, commitActionType, lockProvider, metadata);\n     } else {\n       return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n     }\n", "next_change": {"commit": "57de565ef4bb6ea4386e80fb20d39eeb8dd96455", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 42e513e33..ffb0b3506 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -221,11 +226,10 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n     HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n         operationType, config.getSchema(), commitActionType);\n-    if (config.isMultiWriterEnabled()) {\n+    if (config.getWriteConcurrencyMode().isMultiWriter()) {\n       LockConfiguration lockConfiguration = new LockConfiguration(config.getProps());\n-      LockProvider lockProvider = (LockProvider) ReflectionUtils.loadClass(config.getLockProviderClass(),\n-          lockConfiguration, fs.getConf());\n-      return criticalSectionForWrite(instantTime, stats, extraMetadata, commitActionType, lockProvider, metadata);\n+      LockProvider lockProvider = LockProviderSingleton.getLockProviderInstance(config, lockConfiguration, fs);\n+      return executeCriticalSection(instantTime, stats, extraMetadata, commitActionType, lockProvider, metadata);\n     } else {\n       return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n     }\n", "next_change": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ffb0b3506..ea6c6f81a 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -226,13 +213,26 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n     HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n         operationType, config.getSchema(), commitActionType);\n-    if (config.getWriteConcurrencyMode().isMultiWriter()) {\n-      LockConfiguration lockConfiguration = new LockConfiguration(config.getProps());\n-      LockProvider lockProvider = LockProviderSingleton.getLockProviderInstance(config, lockConfiguration, fs);\n-      return executeCriticalSection(instantTime, stats, extraMetadata, commitActionType, lockProvider, metadata);\n-    } else {\n-      return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-    }\n+    return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n+  }\n+\n+  private void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n+    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n+    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n+    HoodieTable table = createTable(config, hadoopConf);\n+    HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n+    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), instantTime, metadata, config, txnManager.getLastCompletedTransaction());\n+  }\n+\n+  private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n+                      List<HoodieWriteStat> stats) throws IOException {\n+    preCommit(instantTime, metadata);\n+    LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n+    HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n+    // Finalize write\n+    finalizeWrite(table, instantTime, stats);\n+    activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n+        Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n \n   protected abstract HoodieTable<T, I, K, O> createTable(HoodieWriteConfig config, Configuration hadoopConf);\n", "next_change": {"commit": "25a4d7f70cc0cfcec115ddfcc2a543a96bcb17af", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ea6c6f81a..063b26db8 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -221,7 +221,8 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n     HoodieTable table = createTable(config, hadoopConf);\n     HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), instantTime, metadata, config, txnManager.getLastCompletedTransaction());\n+    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), this.txnManager.getCurrentTxnInstant(),\n+        metadata, config, txnManager.getLastCompletedTransaction());\n   }\n \n   private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n", "next_change": {"commit": "f5a56cb4137b5f32af17405277c29d5a9088b6c7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 063b26db8..d45d77154 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,15 +216,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n-    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n-    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n-    HoodieTable table = createTable(config, hadoopConf);\n-    HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), this.txnManager.getCurrentTxnInstant(),\n-        metadata, config, txnManager.getLastCompletedTransaction());\n-  }\n-\n   private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "49dec09bfb444866e678fe956b28c3bf0ad2f373", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex d45d77154..4c1f5bf3c 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,7 +213,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n+  protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n", "next_change": {"commit": "0552abcc6400675c11ee35a4d4f3df109463f6f5", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 4c1f5bf3c..f0ebc54f7 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -220,8 +220,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata(true);\n-    this.txnManager.endTransaction();\n+    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n", "next_change": {"commit": "289e45a28da6b91fba2a824ec2af3771a34b2930", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex f0ebc54f7..3b9e08dd3 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -205,14 +200,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return true;\n   }\n \n-  public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n-                             String commitActionType, Map<String, List<String>> partitionToReplaceFileIds) {\n-\n-    HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n-        operationType, config.getSchema(), commitActionType);\n-    return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-  }\n-\n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 3b9e08dd3..12c55370f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -202,7 +203,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n-    preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n", "next_change": {"commit": "02efbb661e7ed13c3614ddee7ab5157623070f7c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 12c55370f..996648c0e 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -207,15 +210,12 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n \n   protected abstract HoodieTable<T, I, K, O> createTable(HoodieWriteConfig config, Configuration hadoopConf);\n \n-  protected abstract HoodieBackedTableMetadataWriter createMetadataWriter(HoodieWriteConfig config, Configuration hadoopConf);\n-\n   void emitCommitMetrics(String instantTime, HoodieCommitMetadata metadata, String actionType) {\n     try {\n \n", "next_change": null}]}}]}}]}}]}}]}}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ea6c6f81a..063b26db8 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -231,6 +232,8 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n+    syncTableMetadata(true);\n+    this.txnManager.endTransaction();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n", "next_change": {"commit": "f5a56cb4137b5f32af17405277c29d5a9088b6c7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 063b26db8..d45d77154 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,15 +216,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n-    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n-    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n-    HoodieTable table = createTable(config, hadoopConf);\n-    HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), this.txnManager.getCurrentTxnInstant(),\n-        metadata, config, txnManager.getLastCompletedTransaction());\n-  }\n-\n   private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "49dec09bfb444866e678fe956b28c3bf0ad2f373", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex d45d77154..4c1f5bf3c 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,7 +213,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n+  protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n", "next_change": {"commit": "0552abcc6400675c11ee35a4d4f3df109463f6f5", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 4c1f5bf3c..f0ebc54f7 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -220,8 +220,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata(true);\n-    this.txnManager.endTransaction();\n+    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n", "next_change": {"commit": "289e45a28da6b91fba2a824ec2af3771a34b2930", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex f0ebc54f7..3b9e08dd3 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -205,14 +200,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return true;\n   }\n \n-  public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n-                             String commitActionType, Map<String, List<String>> partitionToReplaceFileIds) {\n-\n-    HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n-        operationType, config.getSchema(), commitActionType);\n-    return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-  }\n-\n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 3b9e08dd3..12c55370f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -202,7 +203,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n-    preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n", "next_change": {"commit": "02efbb661e7ed13c3614ddee7ab5157623070f7c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 12c55370f..996648c0e 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -207,15 +210,12 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n \n   protected abstract HoodieTable<T, I, K, O> createTable(HoodieWriteConfig config, Configuration hadoopConf);\n \n-  protected abstract HoodieBackedTableMetadataWriter createMetadataWriter(HoodieWriteConfig config, Configuration hadoopConf);\n-\n   void emitCommitMetrics(String instantTime, HoodieCommitMetadata metadata, String actionType) {\n     try {\n \n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 42e513e33..ffb0b3506 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -233,6 +237,8 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n   protected abstract HoodieTable<T, I, K, O> createTable(HoodieWriteConfig config, Configuration hadoopConf);\n \n+  protected abstract HoodieBackedTableMetadataWriter createMetadataWriter(HoodieWriteConfig config, Configuration hadoopConf);\n+\n   void emitCommitMetrics(String instantTime, HoodieCommitMetadata metadata, String actionType) {\n     try {\n \n", "next_change": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ffb0b3506..ea6c6f81a 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -226,13 +213,26 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n     HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n         operationType, config.getSchema(), commitActionType);\n-    if (config.getWriteConcurrencyMode().isMultiWriter()) {\n-      LockConfiguration lockConfiguration = new LockConfiguration(config.getProps());\n-      LockProvider lockProvider = LockProviderSingleton.getLockProviderInstance(config, lockConfiguration, fs);\n-      return executeCriticalSection(instantTime, stats, extraMetadata, commitActionType, lockProvider, metadata);\n-    } else {\n-      return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-    }\n+    return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n+  }\n+\n+  private void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n+    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n+    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n+    HoodieTable table = createTable(config, hadoopConf);\n+    HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n+    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), instantTime, metadata, config, txnManager.getLastCompletedTransaction());\n+  }\n+\n+  private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n+                      List<HoodieWriteStat> stats) throws IOException {\n+    preCommit(instantTime, metadata);\n+    LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n+    HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n+    // Finalize write\n+    finalizeWrite(table, instantTime, stats);\n+    activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n+        Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n \n   protected abstract HoodieTable<T, I, K, O> createTable(HoodieWriteConfig config, Configuration hadoopConf);\n", "next_change": {"commit": "25a4d7f70cc0cfcec115ddfcc2a543a96bcb17af", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ea6c6f81a..063b26db8 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -221,7 +221,8 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n     HoodieTable table = createTable(config, hadoopConf);\n     HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), instantTime, metadata, config, txnManager.getLastCompletedTransaction());\n+    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), this.txnManager.getCurrentTxnInstant(),\n+        metadata, config, txnManager.getLastCompletedTransaction());\n   }\n \n   private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n", "next_change": {"commit": "f5a56cb4137b5f32af17405277c29d5a9088b6c7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 063b26db8..d45d77154 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,15 +216,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n-    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n-    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n-    HoodieTable table = createTable(config, hadoopConf);\n-    HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), this.txnManager.getCurrentTxnInstant(),\n-        metadata, config, txnManager.getLastCompletedTransaction());\n-  }\n-\n   private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "49dec09bfb444866e678fe956b28c3bf0ad2f373", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex d45d77154..4c1f5bf3c 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,7 +213,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n+  protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n", "next_change": {"commit": "0552abcc6400675c11ee35a4d4f3df109463f6f5", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 4c1f5bf3c..f0ebc54f7 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -220,8 +220,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata(true);\n-    this.txnManager.endTransaction();\n+    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n", "next_change": {"commit": "289e45a28da6b91fba2a824ec2af3771a34b2930", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex f0ebc54f7..3b9e08dd3 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -205,14 +200,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return true;\n   }\n \n-  public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n-                             String commitActionType, Map<String, List<String>> partitionToReplaceFileIds) {\n-\n-    HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n-        operationType, config.getSchema(), commitActionType);\n-    return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-  }\n-\n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 3b9e08dd3..12c55370f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -202,7 +203,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n-    preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n", "next_change": {"commit": "02efbb661e7ed13c3614ddee7ab5157623070f7c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 12c55370f..996648c0e 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -207,15 +210,12 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n \n   protected abstract HoodieTable<T, I, K, O> createTable(HoodieWriteConfig config, Configuration hadoopConf);\n \n-  protected abstract HoodieBackedTableMetadataWriter createMetadataWriter(HoodieWriteConfig config, Configuration hadoopConf);\n-\n   void emitCommitMetrics(String instantTime, HoodieCommitMetadata metadata, String actionType) {\n     try {\n \n", "next_change": null}]}}]}}]}}]}}]}}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ea6c6f81a..063b26db8 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -231,6 +232,8 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n+    syncTableMetadata(true);\n+    this.txnManager.endTransaction();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n", "next_change": {"commit": "f5a56cb4137b5f32af17405277c29d5a9088b6c7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 063b26db8..d45d77154 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,15 +216,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n-    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n-    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n-    HoodieTable table = createTable(config, hadoopConf);\n-    HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), this.txnManager.getCurrentTxnInstant(),\n-        metadata, config, txnManager.getLastCompletedTransaction());\n-  }\n-\n   private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "49dec09bfb444866e678fe956b28c3bf0ad2f373", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex d45d77154..4c1f5bf3c 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,7 +213,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n+  protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n", "next_change": {"commit": "0552abcc6400675c11ee35a4d4f3df109463f6f5", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 4c1f5bf3c..f0ebc54f7 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -220,8 +220,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata(true);\n-    this.txnManager.endTransaction();\n+    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n", "next_change": {"commit": "289e45a28da6b91fba2a824ec2af3771a34b2930", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex f0ebc54f7..3b9e08dd3 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -205,14 +200,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return true;\n   }\n \n-  public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n-                             String commitActionType, Map<String, List<String>> partitionToReplaceFileIds) {\n-\n-    HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n-        operationType, config.getSchema(), commitActionType);\n-    return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-  }\n-\n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 3b9e08dd3..12c55370f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -202,7 +203,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n-    preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n", "next_change": {"commit": "02efbb661e7ed13c3614ddee7ab5157623070f7c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 12c55370f..996648c0e 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -207,15 +210,12 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n \n   protected abstract HoodieTable<T, I, K, O> createTable(HoodieWriteConfig config, Configuration hadoopConf);\n \n-  protected abstract HoodieBackedTableMetadataWriter createMetadataWriter(HoodieWriteConfig config, Configuration hadoopConf);\n-\n   void emitCommitMetrics(String instantTime, HoodieCommitMetadata metadata, String actionType) {\n     try {\n \n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MTIzNw==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549551237", "bodyText": "We need a new Exception class here. HoodieWriteConflictException or sth", "author": "vinothchandar", "createdAt": "2020-12-29T03:04:23Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -203,6 +208,45 @@ public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Opti\n     return true;\n   }\n \n+  public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n+                             String commitActionType, Map<String, List<String>> partitionToReplaceFileIds) {\n+\n+    HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n+        operationType, config.getSchema(), commitActionType);\n+    if (config.isMultiWriterEnabled()) {\n+      // get strategy and lock type\n+      LockConfiguration lockConfiguration = new LockConfiguration(config.getProps());\n+      LockProvider lockProvider = (LockProvider) ReflectionUtils.loadClass(config.getLockProviderClass(),\n+          lockConfiguration, fs.getConf());\n+      try {\n+        // TODO : Get timeout and set the timeout\n+        boolean acquired = lockProvider.tryLock();\n+        if (!acquired) {\n+          throw new HoodieException(\"Unable to acquire lock\");\n+        }\n+        LOG.info(\"Acquired lock for instant time \" + instantTime);\n+        // TODO : Move the following to a \"critical section\"\n+        // Create a Hoodie table which encapsulated the commits and files visible.\n+        // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n+        HoodieTable table = createTable(config, hadoopConf);\n+        try {\n+          metadata = resolveWriteConflictIfAny(table, instantTime, metadata);\n+          return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n+        } catch (Exception e) {", "originalCommit": "592e4bda9aed9af895b60db0d07393b2a6916d30", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "98c3c7ddf879d514e5c14293fee145c92f9416a3", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex e41c1c3ba..42e513e33 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -214,34 +222,10 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n         operationType, config.getSchema(), commitActionType);\n     if (config.isMultiWriterEnabled()) {\n-      // get strategy and lock type\n       LockConfiguration lockConfiguration = new LockConfiguration(config.getProps());\n       LockProvider lockProvider = (LockProvider) ReflectionUtils.loadClass(config.getLockProviderClass(),\n           lockConfiguration, fs.getConf());\n-      try {\n-        // TODO : Get timeout and set the timeout\n-        boolean acquired = lockProvider.tryLock();\n-        if (!acquired) {\n-          throw new HoodieException(\"Unable to acquire lock\");\n-        }\n-        LOG.info(\"Acquired lock for instant time \" + instantTime);\n-        // TODO : Move the following to a \"critical section\"\n-        // Create a Hoodie table which encapsulated the commits and files visible.\n-        // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n-        HoodieTable table = createTable(config, hadoopConf);\n-        try {\n-          metadata = resolveWriteConflictIfAny(table, instantTime, metadata);\n-          return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-        } catch (Exception e) {\n-          // if strategy throws exception, first release lock\n-          lockProvider.unlock();\n-          LOG.info(\"Released lock for instant time \" + instantTime);\n-          throw new HoodieException(e);\n-        }\n-      } finally {\n-        lockProvider.unlock();\n-        LOG.info(\"Released lock if acquired for instant time \" + instantTime);\n-      }\n+      return criticalSectionForWrite(instantTime, stats, extraMetadata, commitActionType, lockProvider, metadata);\n     } else {\n       return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n     }\n", "next_change": {"commit": "57de565ef4bb6ea4386e80fb20d39eeb8dd96455", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 42e513e33..ffb0b3506 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -221,11 +226,10 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n     HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n         operationType, config.getSchema(), commitActionType);\n-    if (config.isMultiWriterEnabled()) {\n+    if (config.getWriteConcurrencyMode().isMultiWriter()) {\n       LockConfiguration lockConfiguration = new LockConfiguration(config.getProps());\n-      LockProvider lockProvider = (LockProvider) ReflectionUtils.loadClass(config.getLockProviderClass(),\n-          lockConfiguration, fs.getConf());\n-      return criticalSectionForWrite(instantTime, stats, extraMetadata, commitActionType, lockProvider, metadata);\n+      LockProvider lockProvider = LockProviderSingleton.getLockProviderInstance(config, lockConfiguration, fs);\n+      return executeCriticalSection(instantTime, stats, extraMetadata, commitActionType, lockProvider, metadata);\n     } else {\n       return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n     }\n", "next_change": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ffb0b3506..ea6c6f81a 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -226,13 +213,26 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n     HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n         operationType, config.getSchema(), commitActionType);\n-    if (config.getWriteConcurrencyMode().isMultiWriter()) {\n-      LockConfiguration lockConfiguration = new LockConfiguration(config.getProps());\n-      LockProvider lockProvider = LockProviderSingleton.getLockProviderInstance(config, lockConfiguration, fs);\n-      return executeCriticalSection(instantTime, stats, extraMetadata, commitActionType, lockProvider, metadata);\n-    } else {\n-      return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-    }\n+    return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n+  }\n+\n+  private void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n+    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n+    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n+    HoodieTable table = createTable(config, hadoopConf);\n+    HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n+    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), instantTime, metadata, config, txnManager.getLastCompletedTransaction());\n+  }\n+\n+  private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n+                      List<HoodieWriteStat> stats) throws IOException {\n+    preCommit(instantTime, metadata);\n+    LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n+    HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n+    // Finalize write\n+    finalizeWrite(table, instantTime, stats);\n+    activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n+        Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n \n   protected abstract HoodieTable<T, I, K, O> createTable(HoodieWriteConfig config, Configuration hadoopConf);\n", "next_change": {"commit": "25a4d7f70cc0cfcec115ddfcc2a543a96bcb17af", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ea6c6f81a..063b26db8 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -221,7 +221,8 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n     HoodieTable table = createTable(config, hadoopConf);\n     HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), instantTime, metadata, config, txnManager.getLastCompletedTransaction());\n+    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), this.txnManager.getCurrentTxnInstant(),\n+        metadata, config, txnManager.getLastCompletedTransaction());\n   }\n \n   private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n", "next_change": {"commit": "f5a56cb4137b5f32af17405277c29d5a9088b6c7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 063b26db8..d45d77154 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,15 +216,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n-    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n-    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n-    HoodieTable table = createTable(config, hadoopConf);\n-    HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), this.txnManager.getCurrentTxnInstant(),\n-        metadata, config, txnManager.getLastCompletedTransaction());\n-  }\n-\n   private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "49dec09bfb444866e678fe956b28c3bf0ad2f373", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex d45d77154..4c1f5bf3c 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,7 +213,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n+  protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n", "next_change": {"commit": "0552abcc6400675c11ee35a4d4f3df109463f6f5", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 4c1f5bf3c..f0ebc54f7 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -220,8 +220,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata(true);\n-    this.txnManager.endTransaction();\n+    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n", "next_change": {"commit": "289e45a28da6b91fba2a824ec2af3771a34b2930", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex f0ebc54f7..3b9e08dd3 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -205,14 +200,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return true;\n   }\n \n-  public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n-                             String commitActionType, Map<String, List<String>> partitionToReplaceFileIds) {\n-\n-    HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n-        operationType, config.getSchema(), commitActionType);\n-    return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-  }\n-\n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 3b9e08dd3..12c55370f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -202,7 +203,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n-    preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n", "next_change": {"commit": "02efbb661e7ed13c3614ddee7ab5157623070f7c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 12c55370f..996648c0e 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -207,15 +210,12 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n \n   protected abstract HoodieTable<T, I, K, O> createTable(HoodieWriteConfig config, Configuration hadoopConf);\n \n-  protected abstract HoodieBackedTableMetadataWriter createMetadataWriter(HoodieWriteConfig config, Configuration hadoopConf);\n-\n   void emitCommitMetrics(String instantTime, HoodieCommitMetadata metadata, String actionType) {\n     try {\n \n", "next_change": null}]}}]}}]}}]}}]}}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ea6c6f81a..063b26db8 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -231,6 +232,8 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n+    syncTableMetadata(true);\n+    this.txnManager.endTransaction();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n", "next_change": {"commit": "f5a56cb4137b5f32af17405277c29d5a9088b6c7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 063b26db8..d45d77154 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,15 +216,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n-    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n-    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n-    HoodieTable table = createTable(config, hadoopConf);\n-    HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), this.txnManager.getCurrentTxnInstant(),\n-        metadata, config, txnManager.getLastCompletedTransaction());\n-  }\n-\n   private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "49dec09bfb444866e678fe956b28c3bf0ad2f373", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex d45d77154..4c1f5bf3c 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,7 +213,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n+  protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n", "next_change": {"commit": "0552abcc6400675c11ee35a4d4f3df109463f6f5", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 4c1f5bf3c..f0ebc54f7 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -220,8 +220,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata(true);\n-    this.txnManager.endTransaction();\n+    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n", "next_change": {"commit": "289e45a28da6b91fba2a824ec2af3771a34b2930", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex f0ebc54f7..3b9e08dd3 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -205,14 +200,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return true;\n   }\n \n-  public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n-                             String commitActionType, Map<String, List<String>> partitionToReplaceFileIds) {\n-\n-    HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n-        operationType, config.getSchema(), commitActionType);\n-    return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-  }\n-\n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 3b9e08dd3..12c55370f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -202,7 +203,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n-    preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n", "next_change": {"commit": "02efbb661e7ed13c3614ddee7ab5157623070f7c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 12c55370f..996648c0e 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -207,15 +210,12 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n \n   protected abstract HoodieTable<T, I, K, O> createTable(HoodieWriteConfig config, Configuration hadoopConf);\n \n-  protected abstract HoodieBackedTableMetadataWriter createMetadataWriter(HoodieWriteConfig config, Configuration hadoopConf);\n-\n   void emitCommitMetrics(String instantTime, HoodieCommitMetadata metadata, String actionType) {\n     try {\n \n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 42e513e33..ffb0b3506 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -233,6 +237,8 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n   protected abstract HoodieTable<T, I, K, O> createTable(HoodieWriteConfig config, Configuration hadoopConf);\n \n+  protected abstract HoodieBackedTableMetadataWriter createMetadataWriter(HoodieWriteConfig config, Configuration hadoopConf);\n+\n   void emitCommitMetrics(String instantTime, HoodieCommitMetadata metadata, String actionType) {\n     try {\n \n", "next_change": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ffb0b3506..ea6c6f81a 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -226,13 +213,26 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n     HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n         operationType, config.getSchema(), commitActionType);\n-    if (config.getWriteConcurrencyMode().isMultiWriter()) {\n-      LockConfiguration lockConfiguration = new LockConfiguration(config.getProps());\n-      LockProvider lockProvider = LockProviderSingleton.getLockProviderInstance(config, lockConfiguration, fs);\n-      return executeCriticalSection(instantTime, stats, extraMetadata, commitActionType, lockProvider, metadata);\n-    } else {\n-      return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-    }\n+    return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n+  }\n+\n+  private void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n+    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n+    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n+    HoodieTable table = createTable(config, hadoopConf);\n+    HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n+    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), instantTime, metadata, config, txnManager.getLastCompletedTransaction());\n+  }\n+\n+  private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n+                      List<HoodieWriteStat> stats) throws IOException {\n+    preCommit(instantTime, metadata);\n+    LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n+    HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n+    // Finalize write\n+    finalizeWrite(table, instantTime, stats);\n+    activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n+        Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n \n   protected abstract HoodieTable<T, I, K, O> createTable(HoodieWriteConfig config, Configuration hadoopConf);\n", "next_change": {"commit": "25a4d7f70cc0cfcec115ddfcc2a543a96bcb17af", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ea6c6f81a..063b26db8 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -221,7 +221,8 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n     HoodieTable table = createTable(config, hadoopConf);\n     HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), instantTime, metadata, config, txnManager.getLastCompletedTransaction());\n+    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), this.txnManager.getCurrentTxnInstant(),\n+        metadata, config, txnManager.getLastCompletedTransaction());\n   }\n \n   private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n", "next_change": {"commit": "f5a56cb4137b5f32af17405277c29d5a9088b6c7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 063b26db8..d45d77154 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,15 +216,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n-    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n-    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n-    HoodieTable table = createTable(config, hadoopConf);\n-    HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), this.txnManager.getCurrentTxnInstant(),\n-        metadata, config, txnManager.getLastCompletedTransaction());\n-  }\n-\n   private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "49dec09bfb444866e678fe956b28c3bf0ad2f373", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex d45d77154..4c1f5bf3c 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,7 +213,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n+  protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n", "next_change": {"commit": "0552abcc6400675c11ee35a4d4f3df109463f6f5", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 4c1f5bf3c..f0ebc54f7 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -220,8 +220,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata(true);\n-    this.txnManager.endTransaction();\n+    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n", "next_change": {"commit": "289e45a28da6b91fba2a824ec2af3771a34b2930", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex f0ebc54f7..3b9e08dd3 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -205,14 +200,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return true;\n   }\n \n-  public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n-                             String commitActionType, Map<String, List<String>> partitionToReplaceFileIds) {\n-\n-    HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n-        operationType, config.getSchema(), commitActionType);\n-    return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-  }\n-\n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 3b9e08dd3..12c55370f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -202,7 +203,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n-    preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n", "next_change": {"commit": "02efbb661e7ed13c3614ddee7ab5157623070f7c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 12c55370f..996648c0e 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -207,15 +210,12 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n \n   protected abstract HoodieTable<T, I, K, O> createTable(HoodieWriteConfig config, Configuration hadoopConf);\n \n-  protected abstract HoodieBackedTableMetadataWriter createMetadataWriter(HoodieWriteConfig config, Configuration hadoopConf);\n-\n   void emitCommitMetrics(String instantTime, HoodieCommitMetadata metadata, String actionType) {\n     try {\n \n", "next_change": null}]}}]}}]}}]}}]}}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ea6c6f81a..063b26db8 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -231,6 +232,8 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n+    syncTableMetadata(true);\n+    this.txnManager.endTransaction();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n", "next_change": {"commit": "f5a56cb4137b5f32af17405277c29d5a9088b6c7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 063b26db8..d45d77154 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,15 +216,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n-    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n-    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n-    HoodieTable table = createTable(config, hadoopConf);\n-    HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), this.txnManager.getCurrentTxnInstant(),\n-        metadata, config, txnManager.getLastCompletedTransaction());\n-  }\n-\n   private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "49dec09bfb444866e678fe956b28c3bf0ad2f373", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex d45d77154..4c1f5bf3c 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,7 +213,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n+  protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n", "next_change": {"commit": "0552abcc6400675c11ee35a4d4f3df109463f6f5", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 4c1f5bf3c..f0ebc54f7 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -220,8 +220,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata(true);\n-    this.txnManager.endTransaction();\n+    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n", "next_change": {"commit": "289e45a28da6b91fba2a824ec2af3771a34b2930", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex f0ebc54f7..3b9e08dd3 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -205,14 +200,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return true;\n   }\n \n-  public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n-                             String commitActionType, Map<String, List<String>> partitionToReplaceFileIds) {\n-\n-    HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n-        operationType, config.getSchema(), commitActionType);\n-    return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-  }\n-\n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 3b9e08dd3..12c55370f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -202,7 +203,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n-    preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n", "next_change": {"commit": "02efbb661e7ed13c3614ddee7ab5157623070f7c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 12c55370f..996648c0e 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -207,15 +210,12 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n \n   protected abstract HoodieTable<T, I, K, O> createTable(HoodieWriteConfig config, Configuration hadoopConf);\n \n-  protected abstract HoodieBackedTableMetadataWriter createMetadataWriter(HoodieWriteConfig config, Configuration hadoopConf);\n-\n   void emitCommitMetrics(String instantTime, HoodieCommitMetadata metadata, String actionType) {\n     try {\n \n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MTI4OQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549551289", "bodyText": "why unlock here again, when you do it in finally", "author": "vinothchandar", "createdAt": "2020-12-29T03:04:36Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -203,6 +208,45 @@ public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Opti\n     return true;\n   }\n \n+  public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n+                             String commitActionType, Map<String, List<String>> partitionToReplaceFileIds) {\n+\n+    HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n+        operationType, config.getSchema(), commitActionType);\n+    if (config.isMultiWriterEnabled()) {\n+      // get strategy and lock type\n+      LockConfiguration lockConfiguration = new LockConfiguration(config.getProps());\n+      LockProvider lockProvider = (LockProvider) ReflectionUtils.loadClass(config.getLockProviderClass(),\n+          lockConfiguration, fs.getConf());\n+      try {\n+        // TODO : Get timeout and set the timeout\n+        boolean acquired = lockProvider.tryLock();\n+        if (!acquired) {\n+          throw new HoodieException(\"Unable to acquire lock\");\n+        }\n+        LOG.info(\"Acquired lock for instant time \" + instantTime);\n+        // TODO : Move the following to a \"critical section\"\n+        // Create a Hoodie table which encapsulated the commits and files visible.\n+        // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n+        HoodieTable table = createTable(config, hadoopConf);\n+        try {\n+          metadata = resolveWriteConflictIfAny(table, instantTime, metadata);\n+          return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n+        } catch (Exception e) {\n+          // if strategy throws exception, first release lock\n+          lockProvider.unlock();", "originalCommit": "592e4bda9aed9af895b60db0d07393b2a6916d30", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "98c3c7ddf879d514e5c14293fee145c92f9416a3", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex e41c1c3ba..42e513e33 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -214,34 +222,10 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n         operationType, config.getSchema(), commitActionType);\n     if (config.isMultiWriterEnabled()) {\n-      // get strategy and lock type\n       LockConfiguration lockConfiguration = new LockConfiguration(config.getProps());\n       LockProvider lockProvider = (LockProvider) ReflectionUtils.loadClass(config.getLockProviderClass(),\n           lockConfiguration, fs.getConf());\n-      try {\n-        // TODO : Get timeout and set the timeout\n-        boolean acquired = lockProvider.tryLock();\n-        if (!acquired) {\n-          throw new HoodieException(\"Unable to acquire lock\");\n-        }\n-        LOG.info(\"Acquired lock for instant time \" + instantTime);\n-        // TODO : Move the following to a \"critical section\"\n-        // Create a Hoodie table which encapsulated the commits and files visible.\n-        // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n-        HoodieTable table = createTable(config, hadoopConf);\n-        try {\n-          metadata = resolveWriteConflictIfAny(table, instantTime, metadata);\n-          return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-        } catch (Exception e) {\n-          // if strategy throws exception, first release lock\n-          lockProvider.unlock();\n-          LOG.info(\"Released lock for instant time \" + instantTime);\n-          throw new HoodieException(e);\n-        }\n-      } finally {\n-        lockProvider.unlock();\n-        LOG.info(\"Released lock if acquired for instant time \" + instantTime);\n-      }\n+      return criticalSectionForWrite(instantTime, stats, extraMetadata, commitActionType, lockProvider, metadata);\n     } else {\n       return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n     }\n", "next_change": {"commit": "57de565ef4bb6ea4386e80fb20d39eeb8dd96455", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 42e513e33..ffb0b3506 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -221,11 +226,10 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n     HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n         operationType, config.getSchema(), commitActionType);\n-    if (config.isMultiWriterEnabled()) {\n+    if (config.getWriteConcurrencyMode().isMultiWriter()) {\n       LockConfiguration lockConfiguration = new LockConfiguration(config.getProps());\n-      LockProvider lockProvider = (LockProvider) ReflectionUtils.loadClass(config.getLockProviderClass(),\n-          lockConfiguration, fs.getConf());\n-      return criticalSectionForWrite(instantTime, stats, extraMetadata, commitActionType, lockProvider, metadata);\n+      LockProvider lockProvider = LockProviderSingleton.getLockProviderInstance(config, lockConfiguration, fs);\n+      return executeCriticalSection(instantTime, stats, extraMetadata, commitActionType, lockProvider, metadata);\n     } else {\n       return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n     }\n", "next_change": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ffb0b3506..ea6c6f81a 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -226,13 +213,26 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n     HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n         operationType, config.getSchema(), commitActionType);\n-    if (config.getWriteConcurrencyMode().isMultiWriter()) {\n-      LockConfiguration lockConfiguration = new LockConfiguration(config.getProps());\n-      LockProvider lockProvider = LockProviderSingleton.getLockProviderInstance(config, lockConfiguration, fs);\n-      return executeCriticalSection(instantTime, stats, extraMetadata, commitActionType, lockProvider, metadata);\n-    } else {\n-      return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-    }\n+    return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n+  }\n+\n+  private void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n+    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n+    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n+    HoodieTable table = createTable(config, hadoopConf);\n+    HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n+    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), instantTime, metadata, config, txnManager.getLastCompletedTransaction());\n+  }\n+\n+  private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n+                      List<HoodieWriteStat> stats) throws IOException {\n+    preCommit(instantTime, metadata);\n+    LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n+    HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n+    // Finalize write\n+    finalizeWrite(table, instantTime, stats);\n+    activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n+        Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n \n   protected abstract HoodieTable<T, I, K, O> createTable(HoodieWriteConfig config, Configuration hadoopConf);\n", "next_change": {"commit": "25a4d7f70cc0cfcec115ddfcc2a543a96bcb17af", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ea6c6f81a..063b26db8 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -221,7 +221,8 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n     HoodieTable table = createTable(config, hadoopConf);\n     HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), instantTime, metadata, config, txnManager.getLastCompletedTransaction());\n+    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), this.txnManager.getCurrentTxnInstant(),\n+        metadata, config, txnManager.getLastCompletedTransaction());\n   }\n \n   private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n", "next_change": {"commit": "f5a56cb4137b5f32af17405277c29d5a9088b6c7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 063b26db8..d45d77154 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,15 +216,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n-    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n-    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n-    HoodieTable table = createTable(config, hadoopConf);\n-    HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), this.txnManager.getCurrentTxnInstant(),\n-        metadata, config, txnManager.getLastCompletedTransaction());\n-  }\n-\n   private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "49dec09bfb444866e678fe956b28c3bf0ad2f373", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex d45d77154..4c1f5bf3c 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,7 +213,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n+  protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n", "next_change": {"commit": "0552abcc6400675c11ee35a4d4f3df109463f6f5", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 4c1f5bf3c..f0ebc54f7 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -220,8 +220,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata(true);\n-    this.txnManager.endTransaction();\n+    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n", "next_change": {"commit": "289e45a28da6b91fba2a824ec2af3771a34b2930", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex f0ebc54f7..3b9e08dd3 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -205,14 +200,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return true;\n   }\n \n-  public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n-                             String commitActionType, Map<String, List<String>> partitionToReplaceFileIds) {\n-\n-    HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n-        operationType, config.getSchema(), commitActionType);\n-    return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-  }\n-\n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 3b9e08dd3..12c55370f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -202,7 +203,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n-    preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n", "next_change": {"commit": "02efbb661e7ed13c3614ddee7ab5157623070f7c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 12c55370f..996648c0e 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -207,15 +210,12 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n \n   protected abstract HoodieTable<T, I, K, O> createTable(HoodieWriteConfig config, Configuration hadoopConf);\n \n-  protected abstract HoodieBackedTableMetadataWriter createMetadataWriter(HoodieWriteConfig config, Configuration hadoopConf);\n-\n   void emitCommitMetrics(String instantTime, HoodieCommitMetadata metadata, String actionType) {\n     try {\n \n", "next_change": null}]}}]}}]}}]}}]}}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ea6c6f81a..063b26db8 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -231,6 +232,8 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n+    syncTableMetadata(true);\n+    this.txnManager.endTransaction();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n", "next_change": {"commit": "f5a56cb4137b5f32af17405277c29d5a9088b6c7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 063b26db8..d45d77154 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,15 +216,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n-    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n-    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n-    HoodieTable table = createTable(config, hadoopConf);\n-    HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), this.txnManager.getCurrentTxnInstant(),\n-        metadata, config, txnManager.getLastCompletedTransaction());\n-  }\n-\n   private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "49dec09bfb444866e678fe956b28c3bf0ad2f373", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex d45d77154..4c1f5bf3c 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,7 +213,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n+  protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n", "next_change": {"commit": "0552abcc6400675c11ee35a4d4f3df109463f6f5", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 4c1f5bf3c..f0ebc54f7 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -220,8 +220,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata(true);\n-    this.txnManager.endTransaction();\n+    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n", "next_change": {"commit": "289e45a28da6b91fba2a824ec2af3771a34b2930", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex f0ebc54f7..3b9e08dd3 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -205,14 +200,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return true;\n   }\n \n-  public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n-                             String commitActionType, Map<String, List<String>> partitionToReplaceFileIds) {\n-\n-    HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n-        operationType, config.getSchema(), commitActionType);\n-    return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-  }\n-\n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 3b9e08dd3..12c55370f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -202,7 +203,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n-    preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n", "next_change": {"commit": "02efbb661e7ed13c3614ddee7ab5157623070f7c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 12c55370f..996648c0e 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -207,15 +210,12 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n \n   protected abstract HoodieTable<T, I, K, O> createTable(HoodieWriteConfig config, Configuration hadoopConf);\n \n-  protected abstract HoodieBackedTableMetadataWriter createMetadataWriter(HoodieWriteConfig config, Configuration hadoopConf);\n-\n   void emitCommitMetrics(String instantTime, HoodieCommitMetadata metadata, String actionType) {\n     try {\n \n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 42e513e33..ffb0b3506 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -233,6 +237,8 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n   protected abstract HoodieTable<T, I, K, O> createTable(HoodieWriteConfig config, Configuration hadoopConf);\n \n+  protected abstract HoodieBackedTableMetadataWriter createMetadataWriter(HoodieWriteConfig config, Configuration hadoopConf);\n+\n   void emitCommitMetrics(String instantTime, HoodieCommitMetadata metadata, String actionType) {\n     try {\n \n", "next_change": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ffb0b3506..ea6c6f81a 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -226,13 +213,26 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n     HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n         operationType, config.getSchema(), commitActionType);\n-    if (config.getWriteConcurrencyMode().isMultiWriter()) {\n-      LockConfiguration lockConfiguration = new LockConfiguration(config.getProps());\n-      LockProvider lockProvider = LockProviderSingleton.getLockProviderInstance(config, lockConfiguration, fs);\n-      return executeCriticalSection(instantTime, stats, extraMetadata, commitActionType, lockProvider, metadata);\n-    } else {\n-      return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-    }\n+    return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n+  }\n+\n+  private void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n+    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n+    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n+    HoodieTable table = createTable(config, hadoopConf);\n+    HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n+    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), instantTime, metadata, config, txnManager.getLastCompletedTransaction());\n+  }\n+\n+  private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n+                      List<HoodieWriteStat> stats) throws IOException {\n+    preCommit(instantTime, metadata);\n+    LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n+    HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n+    // Finalize write\n+    finalizeWrite(table, instantTime, stats);\n+    activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n+        Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n \n   protected abstract HoodieTable<T, I, K, O> createTable(HoodieWriteConfig config, Configuration hadoopConf);\n", "next_change": {"commit": "25a4d7f70cc0cfcec115ddfcc2a543a96bcb17af", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ea6c6f81a..063b26db8 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -221,7 +221,8 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n     HoodieTable table = createTable(config, hadoopConf);\n     HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), instantTime, metadata, config, txnManager.getLastCompletedTransaction());\n+    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), this.txnManager.getCurrentTxnInstant(),\n+        metadata, config, txnManager.getLastCompletedTransaction());\n   }\n \n   private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n", "next_change": {"commit": "f5a56cb4137b5f32af17405277c29d5a9088b6c7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 063b26db8..d45d77154 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,15 +216,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n-    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n-    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n-    HoodieTable table = createTable(config, hadoopConf);\n-    HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), this.txnManager.getCurrentTxnInstant(),\n-        metadata, config, txnManager.getLastCompletedTransaction());\n-  }\n-\n   private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "49dec09bfb444866e678fe956b28c3bf0ad2f373", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex d45d77154..4c1f5bf3c 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,7 +213,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n+  protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n", "next_change": {"commit": "0552abcc6400675c11ee35a4d4f3df109463f6f5", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 4c1f5bf3c..f0ebc54f7 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -220,8 +220,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata(true);\n-    this.txnManager.endTransaction();\n+    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n", "next_change": {"commit": "289e45a28da6b91fba2a824ec2af3771a34b2930", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex f0ebc54f7..3b9e08dd3 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -205,14 +200,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return true;\n   }\n \n-  public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n-                             String commitActionType, Map<String, List<String>> partitionToReplaceFileIds) {\n-\n-    HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n-        operationType, config.getSchema(), commitActionType);\n-    return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-  }\n-\n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 3b9e08dd3..12c55370f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -202,7 +203,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n-    preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n", "next_change": {"commit": "02efbb661e7ed13c3614ddee7ab5157623070f7c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 12c55370f..996648c0e 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -207,15 +210,12 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n \n   protected abstract HoodieTable<T, I, K, O> createTable(HoodieWriteConfig config, Configuration hadoopConf);\n \n-  protected abstract HoodieBackedTableMetadataWriter createMetadataWriter(HoodieWriteConfig config, Configuration hadoopConf);\n-\n   void emitCommitMetrics(String instantTime, HoodieCommitMetadata metadata, String actionType) {\n     try {\n \n", "next_change": null}]}}]}}]}}]}}]}}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ea6c6f81a..063b26db8 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -231,6 +232,8 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n+    syncTableMetadata(true);\n+    this.txnManager.endTransaction();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n", "next_change": {"commit": "f5a56cb4137b5f32af17405277c29d5a9088b6c7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 063b26db8..d45d77154 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,15 +216,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n-    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n-    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n-    HoodieTable table = createTable(config, hadoopConf);\n-    HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), this.txnManager.getCurrentTxnInstant(),\n-        metadata, config, txnManager.getLastCompletedTransaction());\n-  }\n-\n   private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "49dec09bfb444866e678fe956b28c3bf0ad2f373", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex d45d77154..4c1f5bf3c 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,7 +213,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n+  protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n", "next_change": {"commit": "0552abcc6400675c11ee35a4d4f3df109463f6f5", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 4c1f5bf3c..f0ebc54f7 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -220,8 +220,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata(true);\n-    this.txnManager.endTransaction();\n+    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n", "next_change": {"commit": "289e45a28da6b91fba2a824ec2af3771a34b2930", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex f0ebc54f7..3b9e08dd3 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -205,14 +200,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return true;\n   }\n \n-  public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n-                             String commitActionType, Map<String, List<String>> partitionToReplaceFileIds) {\n-\n-    HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n-        operationType, config.getSchema(), commitActionType);\n-    return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-  }\n-\n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 3b9e08dd3..12c55370f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -202,7 +203,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n-    preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n", "next_change": {"commit": "02efbb661e7ed13c3614ddee7ab5157623070f7c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 12c55370f..996648c0e 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -207,15 +210,12 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n \n   protected abstract HoodieTable<T, I, K, O> createTable(HoodieWriteConfig config, Configuration hadoopConf);\n \n-  protected abstract HoodieBackedTableMetadataWriter createMetadataWriter(HoodieWriteConfig config, Configuration hadoopConf);\n-\n   void emitCommitMetrics(String instantTime, HoodieCommitMetadata metadata, String actionType) {\n     try {\n \n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MTYyMA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549551620", "bodyText": "I was expecting to use the atomic reference above. and just pull all the writes that happened after the latestWriteInstantCompletedBeforeWriter ? Also lets not assume that time in seconds is what we will use here.", "author": "vinothchandar", "createdAt": "2020-12-29T03:06:36Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -821,6 +865,38 @@ protected void finalizeWrite(HoodieTable<T, I, K, O> table, String instantTime,\n     }\n   }\n \n+  private HoodieCommitMetadata resolveWriteConflictIfAny(HoodieTable<T, I, K, O> table, final String instantTime,\n+                                            HoodieCommitMetadata thisCommitMetadata) {\n+    Long currentTimeInSecs = System.currentTimeMillis() / 1000;", "originalCommit": "592e4bda9aed9af895b60db0d07393b2a6916d30", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "98c3c7ddf879d514e5c14293fee145c92f9416a3", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex e41c1c3ba..42e513e33 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -866,8 +845,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n   }\n \n   private HoodieCommitMetadata resolveWriteConflictIfAny(HoodieTable<T, I, K, O> table, final String instantTime,\n-                                            HoodieCommitMetadata thisCommitMetadata) {\n-    Long currentTimeInSecs = System.currentTimeMillis() / 1000;\n+                                            HoodieCommitMetadata thisCommitMetadata) throws HoodieWriteConflictException {\n     ConflictResolutionStrategy resolutionStrategy = config.getWriteConflictResolutionStrategy();\n     Option<HoodieInstant> lastCompletedInstantBeforeWriterStarted = this.latestWriteInstantCompletedBeforeWriter.get();\n     String lastInstantTimestamp = lastCompletedInstantBeforeWriterStarted.isPresent()\n", "next_change": {"commit": "57de565ef4bb6ea4386e80fb20d39eeb8dd96455", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 42e513e33..ffb0b3506 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -844,22 +943,30 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     }\n   }\n \n-  private HoodieCommitMetadata resolveWriteConflictIfAny(HoodieTable<T, I, K, O> table, final String instantTime,\n-                                            HoodieCommitMetadata thisCommitMetadata) throws HoodieWriteConflictException {\n+  private HoodieCommitMetadata resolveWriteConflictIfAny(HoodieTable<T, I, K, O> table, HoodieBackedTableMetadataWriter metadataWriter,\n+                                                         final String instantTime, HoodieCommitMetadata thisCommitMetadata)\n+      throws HoodieWriteConflictException {\n     ConflictResolutionStrategy resolutionStrategy = config.getWriteConflictResolutionStrategy();\n-    Option<HoodieInstant> lastCompletedInstantBeforeWriterStarted = this.latestWriteInstantCompletedBeforeWriter.get();\n+    Option<HoodieInstant> lastCompletedInstantBeforeWriterStarted = this.latestCompletedWriteInstant.get();\n     String lastInstantTimestamp = lastCompletedInstantBeforeWriterStarted.isPresent()\n         ? lastCompletedInstantBeforeWriterStarted.get().getTimestamp() : \"0\";\n-    Stream<HoodieInstant> instantStream = table.getActiveTimeline()\n+    // Get completed instants timeline\n+    Stream<HoodieInstant> completedInstantStream = table.getActiveTimeline()\n         .getAllCommitsTimeline()\n+        // TODO : getWriteTimeline to ensure we include replace commits as well\n         .getCommitsAndCompactionTimeline()\n         .filterCompletedInstants()\n         .findInstantsAfter(lastInstantTimestamp)\n         .getInstants();\n \n-    LOG.info(\"Current eligible instants to check conflict against during write of instant \" + instantTime + \" => \"\n-        + instantStream.collect(Collectors.toList()));\n+    // Get pending replace and compaction instants timeline\n+    Stream<HoodieInstant> pendingReplaceAndRequestedInstantStream = table.getActiveTimeline()\n+        .getAllCommitsTimeline()\n+        .filterPendingCompactionAndReplaceTimeline()\n+        .findInstantsAfter(lastInstantTimestamp)\n+        .getInstants();\n \n+    Stream<HoodieInstant> instantStream = Stream.concat(completedInstantStream, pendingReplaceAndRequestedInstantStream);\n     final HoodieCommitOperation thisOperation = new HoodieCommitOperation(thisCommitMetadata, instantTime);\n     instantStream.forEach(instant -> {\n       try {\n", "next_change": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ffb0b3506..ea6c6f81a 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -943,68 +966,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     }\n   }\n \n-  private HoodieCommitMetadata resolveWriteConflictIfAny(HoodieTable<T, I, K, O> table, HoodieBackedTableMetadataWriter metadataWriter,\n-                                                         final String instantTime, HoodieCommitMetadata thisCommitMetadata)\n-      throws HoodieWriteConflictException {\n-    ConflictResolutionStrategy resolutionStrategy = config.getWriteConflictResolutionStrategy();\n-    Option<HoodieInstant> lastCompletedInstantBeforeWriterStarted = this.latestCompletedWriteInstant.get();\n-    String lastInstantTimestamp = lastCompletedInstantBeforeWriterStarted.isPresent()\n-        ? lastCompletedInstantBeforeWriterStarted.get().getTimestamp() : \"0\";\n-    // Get completed instants timeline\n-    Stream<HoodieInstant> completedInstantStream = table.getActiveTimeline()\n-        .getAllCommitsTimeline()\n-        // TODO : getWriteTimeline to ensure we include replace commits as well\n-        .getCommitsAndCompactionTimeline()\n-        .filterCompletedInstants()\n-        .findInstantsAfter(lastInstantTimestamp)\n-        .getInstants();\n-\n-    // Get pending replace and compaction instants timeline\n-    Stream<HoodieInstant> pendingReplaceAndRequestedInstantStream = table.getActiveTimeline()\n-        .getAllCommitsTimeline()\n-        .filterPendingCompactionAndReplaceTimeline()\n-        .findInstantsAfter(lastInstantTimestamp)\n-        .getInstants();\n-\n-    Stream<HoodieInstant> instantStream = Stream.concat(completedInstantStream, pendingReplaceAndRequestedInstantStream);\n-    final HoodieCommitOperation thisOperation = new HoodieCommitOperation(thisCommitMetadata, instantTime);\n-    instantStream.forEach(instant -> {\n-      try {\n-        HoodieCommitOperation otherOperation = new HoodieCommitOperation(HoodieCommitMetadata.fromBytes(\n-            table.getActiveTimeline().getInstantDetails(instant).get(), HoodieCommitMetadata.class), instant.getTimestamp());\n-        if (resolutionStrategy.hasConflict(thisOperation, otherOperation)) {\n-          LOG.info(\"Conflict encountered between instant = \" + thisOperation.getInstant() + \" and instant = \"\n-              + otherOperation.getInstant() + \", attempting to resolve it now\");\n-          resolutionStrategy.resolveConflict(metadataWriter, table, thisOperation, otherOperation);\n-        }\n-      } catch (IOException io) {\n-        throw new HoodieWriteConflictException(\"Unable to resolve conflict, if present\", io);\n-      }\n-    });\n-    return thisOperation.getCommitMetadata();\n-  }\n-\n-  private boolean executeCriticalSection(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n-                                         String commitActionType, LockProvider lockProvider, HoodieCommitMetadata metadata) {\n-    try {\n-      // TODO : Make the executeCriticalSection generic by passing a function\n-      boolean acquired = lockProvider.tryLock(config.getLockAcquireWaitTimeoutInMs(), TimeUnit.MILLISECONDS);\n-      if (!acquired) {\n-        throw new HoodieLockException(\"Unable to acquire lock for instant \" + instantTime);\n-      }\n-      LOG.info(\"Acquired lock for instant time \" + instantTime);\n-      // Create a Hoodie table which encapsulated the commits and files visible.\n-      // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n-      HoodieTable table = createTable(config, hadoopConf);\n-      HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-      metadata = resolveWriteConflictIfAny(table, metadataWriter, instantTime, metadata);\n-      return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-    } finally {\n-      lockProvider.unlock();\n-      LOG.info(\"Released lock if acquired for instant time \" + instantTime);\n-    }\n-  }\n-\n   public HoodieMetrics getMetrics() {\n     return metrics;\n   }\n", "next_change": null}]}}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex e41c1c3ba..42e513e33 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -876,25 +854,47 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n         .getAllCommitsTimeline()\n         .getCommitsAndCompactionTimeline()\n         .filterCompletedInstants()\n-        .findInstantsInRange(lastInstantTimestamp, String.valueOf(currentTimeInSecs))\n+        .findInstantsAfter(lastInstantTimestamp)\n         .getInstants();\n \n-    LOG.info(\"Current eligible instants during write oHoodieWriteConfigf instant \" + instantTime + \" = \"\n+    LOG.info(\"Current eligible instants to check conflict against during write of instant \" + instantTime + \" => \"\n         + instantStream.collect(Collectors.toList()));\n \n-    boolean hasConflict = instantStream.anyMatch(instant -> {\n+    final HoodieCommitOperation thisOperation = new HoodieCommitOperation(thisCommitMetadata, instantTime);\n+    instantStream.forEach(instant -> {\n       try {\n-        return resolutionStrategy.hasConflict(thisCommitMetadata, HoodieCommitMetadata.fromBytes(\n-            table.getActiveTimeline().getInstantDetails(instant).get(), HoodieCommitMetadata.class));\n+        HoodieCommitOperation otherOperation = new HoodieCommitOperation(HoodieCommitMetadata.fromBytes(\n+            table.getActiveTimeline().getInstantDetails(instant).get(), HoodieCommitMetadata.class), instant.getTimestamp());\n+        if (resolutionStrategy.hasConflict(thisOperation, otherOperation)) {\n+          LOG.info(\"Conflict encountered between instant = \" + thisOperation.getInstant() + \" and instant = \"\n+              + otherOperation.getInstant() + \", attempting to resolve it now\");\n+          resolutionStrategy.resolveConflict(thisOperation, otherOperation);\n+        }\n       } catch (IOException io) {\n-        throw new HoodieCommitException(\"Unable to determine if conflict exists\", io);\n+        throw new HoodieWriteConflictException(\"Unable to resolve conflict, if present\", io);\n       }\n     });\n-    HoodieCommitMetadata newMetadataAfterConflictResolution = thisCommitMetadata;\n-    if (hasConflict) {\n-      newMetadataAfterConflictResolution = resolutionStrategy.resolveConflict(config, hadoopConf);\n+    return thisOperation.getCommitMetadata();\n+  }\n+\n+  private boolean criticalSectionForWrite(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n+                               String commitActionType, LockProvider lockProvider, HoodieCommitMetadata metadata) {\n+    try {\n+      boolean acquired = lockProvider.tryLock(config.getLockAcquireWaitTimeoutInMs(), TimeUnit.MILLISECONDS);\n+      if (!acquired) {\n+        throw new HoodieLockException(\"Unable to acquire lock for instant \" + instantTime);\n+      }\n+      LOG.info(\"Acquired lock for instant time \" + instantTime);\n+      // Create a Hoodie table which encapsulated the commits and files visible.\n+      // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n+      HoodieTable table = createTable(config, hadoopConf);\n+      metadata = resolveWriteConflictIfAny(table, instantTime, metadata);\n+      return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n+    } finally {\n+      lockProvider.unlock();\n+      lockProviderOption = Option.of(lockProvider);\n+      LOG.info(\"Released lock if acquired for instant time \" + instantTime);\n     }\n-    return newMetadataAfterConflictResolution;\n   }\n \n   public HoodieMetrics getMetrics() {\n", "next_change": {"commit": "21792c6722dd32dddbc5b6ec743549610cd9a8e0", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 42e513e33..19a0a1da4 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -857,9 +868,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n         .findInstantsAfter(lastInstantTimestamp)\n         .getInstants();\n \n-    LOG.info(\"Current eligible instants to check conflict against during write of instant \" + instantTime + \" => \"\n-        + instantStream.collect(Collectors.toList()));\n-\n     final HoodieCommitOperation thisOperation = new HoodieCommitOperation(thisCommitMetadata, instantTime);\n     instantStream.forEach(instant -> {\n       try {\n", "next_change": {"commit": "57de565ef4bb6ea4386e80fb20d39eeb8dd96455", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 19a0a1da4..ffb0b3506 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -855,19 +943,30 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     }\n   }\n \n-  private HoodieCommitMetadata resolveWriteConflictIfAny(HoodieTable<T, I, K, O> table, final String instantTime,\n-                                            HoodieCommitMetadata thisCommitMetadata) throws HoodieWriteConflictException {\n+  private HoodieCommitMetadata resolveWriteConflictIfAny(HoodieTable<T, I, K, O> table, HoodieBackedTableMetadataWriter metadataWriter,\n+                                                         final String instantTime, HoodieCommitMetadata thisCommitMetadata)\n+      throws HoodieWriteConflictException {\n     ConflictResolutionStrategy resolutionStrategy = config.getWriteConflictResolutionStrategy();\n-    Option<HoodieInstant> lastCompletedInstantBeforeWriterStarted = this.latestWriteInstantCompletedBeforeWriter.get();\n+    Option<HoodieInstant> lastCompletedInstantBeforeWriterStarted = this.latestCompletedWriteInstant.get();\n     String lastInstantTimestamp = lastCompletedInstantBeforeWriterStarted.isPresent()\n         ? lastCompletedInstantBeforeWriterStarted.get().getTimestamp() : \"0\";\n-    Stream<HoodieInstant> instantStream = table.getActiveTimeline()\n+    // Get completed instants timeline\n+    Stream<HoodieInstant> completedInstantStream = table.getActiveTimeline()\n         .getAllCommitsTimeline()\n+        // TODO : getWriteTimeline to ensure we include replace commits as well\n         .getCommitsAndCompactionTimeline()\n         .filterCompletedInstants()\n         .findInstantsAfter(lastInstantTimestamp)\n         .getInstants();\n \n+    // Get pending replace and compaction instants timeline\n+    Stream<HoodieInstant> pendingReplaceAndRequestedInstantStream = table.getActiveTimeline()\n+        .getAllCommitsTimeline()\n+        .filterPendingCompactionAndReplaceTimeline()\n+        .findInstantsAfter(lastInstantTimestamp)\n+        .getInstants();\n+\n+    Stream<HoodieInstant> instantStream = Stream.concat(completedInstantStream, pendingReplaceAndRequestedInstantStream);\n     final HoodieCommitOperation thisOperation = new HoodieCommitOperation(thisCommitMetadata, instantTime);\n     instantStream.forEach(instant -> {\n       try {\n", "next_change": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ffb0b3506..ea6c6f81a 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -943,68 +966,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     }\n   }\n \n-  private HoodieCommitMetadata resolveWriteConflictIfAny(HoodieTable<T, I, K, O> table, HoodieBackedTableMetadataWriter metadataWriter,\n-                                                         final String instantTime, HoodieCommitMetadata thisCommitMetadata)\n-      throws HoodieWriteConflictException {\n-    ConflictResolutionStrategy resolutionStrategy = config.getWriteConflictResolutionStrategy();\n-    Option<HoodieInstant> lastCompletedInstantBeforeWriterStarted = this.latestCompletedWriteInstant.get();\n-    String lastInstantTimestamp = lastCompletedInstantBeforeWriterStarted.isPresent()\n-        ? lastCompletedInstantBeforeWriterStarted.get().getTimestamp() : \"0\";\n-    // Get completed instants timeline\n-    Stream<HoodieInstant> completedInstantStream = table.getActiveTimeline()\n-        .getAllCommitsTimeline()\n-        // TODO : getWriteTimeline to ensure we include replace commits as well\n-        .getCommitsAndCompactionTimeline()\n-        .filterCompletedInstants()\n-        .findInstantsAfter(lastInstantTimestamp)\n-        .getInstants();\n-\n-    // Get pending replace and compaction instants timeline\n-    Stream<HoodieInstant> pendingReplaceAndRequestedInstantStream = table.getActiveTimeline()\n-        .getAllCommitsTimeline()\n-        .filterPendingCompactionAndReplaceTimeline()\n-        .findInstantsAfter(lastInstantTimestamp)\n-        .getInstants();\n-\n-    Stream<HoodieInstant> instantStream = Stream.concat(completedInstantStream, pendingReplaceAndRequestedInstantStream);\n-    final HoodieCommitOperation thisOperation = new HoodieCommitOperation(thisCommitMetadata, instantTime);\n-    instantStream.forEach(instant -> {\n-      try {\n-        HoodieCommitOperation otherOperation = new HoodieCommitOperation(HoodieCommitMetadata.fromBytes(\n-            table.getActiveTimeline().getInstantDetails(instant).get(), HoodieCommitMetadata.class), instant.getTimestamp());\n-        if (resolutionStrategy.hasConflict(thisOperation, otherOperation)) {\n-          LOG.info(\"Conflict encountered between instant = \" + thisOperation.getInstant() + \" and instant = \"\n-              + otherOperation.getInstant() + \", attempting to resolve it now\");\n-          resolutionStrategy.resolveConflict(metadataWriter, table, thisOperation, otherOperation);\n-        }\n-      } catch (IOException io) {\n-        throw new HoodieWriteConflictException(\"Unable to resolve conflict, if present\", io);\n-      }\n-    });\n-    return thisOperation.getCommitMetadata();\n-  }\n-\n-  private boolean executeCriticalSection(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n-                                         String commitActionType, LockProvider lockProvider, HoodieCommitMetadata metadata) {\n-    try {\n-      // TODO : Make the executeCriticalSection generic by passing a function\n-      boolean acquired = lockProvider.tryLock(config.getLockAcquireWaitTimeoutInMs(), TimeUnit.MILLISECONDS);\n-      if (!acquired) {\n-        throw new HoodieLockException(\"Unable to acquire lock for instant \" + instantTime);\n-      }\n-      LOG.info(\"Acquired lock for instant time \" + instantTime);\n-      // Create a Hoodie table which encapsulated the commits and files visible.\n-      // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n-      HoodieTable table = createTable(config, hadoopConf);\n-      HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-      metadata = resolveWriteConflictIfAny(table, metadataWriter, instantTime, metadata);\n-      return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-    } finally {\n-      lockProvider.unlock();\n-      LOG.info(\"Released lock if acquired for instant time \" + instantTime);\n-    }\n-  }\n-\n   public HoodieMetrics getMetrics() {\n     return metrics;\n   }\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MTc1NA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549551754", "bodyText": "can we move the reflection part to the config object?", "author": "vinothchandar", "createdAt": "2020-12-29T03:07:16Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -203,6 +208,45 @@ public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Opti\n     return true;\n   }\n \n+  public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n+                             String commitActionType, Map<String, List<String>> partitionToReplaceFileIds) {\n+\n+    HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n+        operationType, config.getSchema(), commitActionType);\n+    if (config.isMultiWriterEnabled()) {\n+      // get strategy and lock type\n+      LockConfiguration lockConfiguration = new LockConfiguration(config.getProps());\n+      LockProvider lockProvider = (LockProvider) ReflectionUtils.loadClass(config.getLockProviderClass(),", "originalCommit": "592e4bda9aed9af895b60db0d07393b2a6916d30", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDg1Mjg2OQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r550852869", "bodyText": "Already have it that way for ConflictResolutionStrategy, but this reflection requires parameters hence kept it here. If we moved this to config object, we have to make the getLockProviderClass parameterized which will be a problem for clients to get just the class name. Other option is to have 2 overloaded getters. Let me know what you think.", "author": "n3nash", "createdAt": "2021-01-02T07:05:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MTc1NA=="}], "type": "inlineReview", "revised_code": {"commit": "98c3c7ddf879d514e5c14293fee145c92f9416a3", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex e41c1c3ba..42e513e33 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -214,34 +222,10 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n         operationType, config.getSchema(), commitActionType);\n     if (config.isMultiWriterEnabled()) {\n-      // get strategy and lock type\n       LockConfiguration lockConfiguration = new LockConfiguration(config.getProps());\n       LockProvider lockProvider = (LockProvider) ReflectionUtils.loadClass(config.getLockProviderClass(),\n           lockConfiguration, fs.getConf());\n-      try {\n-        // TODO : Get timeout and set the timeout\n-        boolean acquired = lockProvider.tryLock();\n-        if (!acquired) {\n-          throw new HoodieException(\"Unable to acquire lock\");\n-        }\n-        LOG.info(\"Acquired lock for instant time \" + instantTime);\n-        // TODO : Move the following to a \"critical section\"\n-        // Create a Hoodie table which encapsulated the commits and files visible.\n-        // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n-        HoodieTable table = createTable(config, hadoopConf);\n-        try {\n-          metadata = resolveWriteConflictIfAny(table, instantTime, metadata);\n-          return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-        } catch (Exception e) {\n-          // if strategy throws exception, first release lock\n-          lockProvider.unlock();\n-          LOG.info(\"Released lock for instant time \" + instantTime);\n-          throw new HoodieException(e);\n-        }\n-      } finally {\n-        lockProvider.unlock();\n-        LOG.info(\"Released lock if acquired for instant time \" + instantTime);\n-      }\n+      return criticalSectionForWrite(instantTime, stats, extraMetadata, commitActionType, lockProvider, metadata);\n     } else {\n       return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n     }\n", "next_change": {"commit": "57de565ef4bb6ea4386e80fb20d39eeb8dd96455", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 42e513e33..ffb0b3506 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -221,11 +226,10 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n     HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n         operationType, config.getSchema(), commitActionType);\n-    if (config.isMultiWriterEnabled()) {\n+    if (config.getWriteConcurrencyMode().isMultiWriter()) {\n       LockConfiguration lockConfiguration = new LockConfiguration(config.getProps());\n-      LockProvider lockProvider = (LockProvider) ReflectionUtils.loadClass(config.getLockProviderClass(),\n-          lockConfiguration, fs.getConf());\n-      return criticalSectionForWrite(instantTime, stats, extraMetadata, commitActionType, lockProvider, metadata);\n+      LockProvider lockProvider = LockProviderSingleton.getLockProviderInstance(config, lockConfiguration, fs);\n+      return executeCriticalSection(instantTime, stats, extraMetadata, commitActionType, lockProvider, metadata);\n     } else {\n       return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n     }\n", "next_change": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ffb0b3506..ea6c6f81a 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -226,13 +213,26 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n     HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n         operationType, config.getSchema(), commitActionType);\n-    if (config.getWriteConcurrencyMode().isMultiWriter()) {\n-      LockConfiguration lockConfiguration = new LockConfiguration(config.getProps());\n-      LockProvider lockProvider = LockProviderSingleton.getLockProviderInstance(config, lockConfiguration, fs);\n-      return executeCriticalSection(instantTime, stats, extraMetadata, commitActionType, lockProvider, metadata);\n-    } else {\n-      return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-    }\n+    return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n+  }\n+\n+  private void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n+    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n+    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n+    HoodieTable table = createTable(config, hadoopConf);\n+    HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n+    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), instantTime, metadata, config, txnManager.getLastCompletedTransaction());\n+  }\n+\n+  private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n+                      List<HoodieWriteStat> stats) throws IOException {\n+    preCommit(instantTime, metadata);\n+    LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n+    HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n+    // Finalize write\n+    finalizeWrite(table, instantTime, stats);\n+    activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n+        Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n \n   protected abstract HoodieTable<T, I, K, O> createTable(HoodieWriteConfig config, Configuration hadoopConf);\n", "next_change": {"commit": "25a4d7f70cc0cfcec115ddfcc2a543a96bcb17af", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ea6c6f81a..063b26db8 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -221,7 +221,8 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n     HoodieTable table = createTable(config, hadoopConf);\n     HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), instantTime, metadata, config, txnManager.getLastCompletedTransaction());\n+    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), this.txnManager.getCurrentTxnInstant(),\n+        metadata, config, txnManager.getLastCompletedTransaction());\n   }\n \n   private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n", "next_change": {"commit": "f5a56cb4137b5f32af17405277c29d5a9088b6c7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 063b26db8..d45d77154 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,15 +216,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n-    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n-    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n-    HoodieTable table = createTable(config, hadoopConf);\n-    HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), this.txnManager.getCurrentTxnInstant(),\n-        metadata, config, txnManager.getLastCompletedTransaction());\n-  }\n-\n   private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "49dec09bfb444866e678fe956b28c3bf0ad2f373", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex d45d77154..4c1f5bf3c 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,7 +213,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n+  protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n", "next_change": {"commit": "0552abcc6400675c11ee35a4d4f3df109463f6f5", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 4c1f5bf3c..f0ebc54f7 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -220,8 +220,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata(true);\n-    this.txnManager.endTransaction();\n+    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n", "next_change": {"commit": "289e45a28da6b91fba2a824ec2af3771a34b2930", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex f0ebc54f7..3b9e08dd3 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -205,14 +200,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return true;\n   }\n \n-  public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n-                             String commitActionType, Map<String, List<String>> partitionToReplaceFileIds) {\n-\n-    HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n-        operationType, config.getSchema(), commitActionType);\n-    return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-  }\n-\n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 3b9e08dd3..12c55370f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -202,7 +203,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n-    preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n", "next_change": {"commit": "02efbb661e7ed13c3614ddee7ab5157623070f7c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 12c55370f..996648c0e 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -207,15 +210,12 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n \n   protected abstract HoodieTable<T, I, K, O> createTable(HoodieWriteConfig config, Configuration hadoopConf);\n \n-  protected abstract HoodieBackedTableMetadataWriter createMetadataWriter(HoodieWriteConfig config, Configuration hadoopConf);\n-\n   void emitCommitMetrics(String instantTime, HoodieCommitMetadata metadata, String actionType) {\n     try {\n \n", "next_change": null}]}}]}}]}}]}}]}}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ea6c6f81a..063b26db8 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -231,6 +232,8 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n+    syncTableMetadata(true);\n+    this.txnManager.endTransaction();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n", "next_change": {"commit": "f5a56cb4137b5f32af17405277c29d5a9088b6c7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 063b26db8..d45d77154 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,15 +216,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n-    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n-    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n-    HoodieTable table = createTable(config, hadoopConf);\n-    HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), this.txnManager.getCurrentTxnInstant(),\n-        metadata, config, txnManager.getLastCompletedTransaction());\n-  }\n-\n   private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "49dec09bfb444866e678fe956b28c3bf0ad2f373", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex d45d77154..4c1f5bf3c 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,7 +213,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n+  protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n", "next_change": {"commit": "0552abcc6400675c11ee35a4d4f3df109463f6f5", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 4c1f5bf3c..f0ebc54f7 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -220,8 +220,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata(true);\n-    this.txnManager.endTransaction();\n+    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n", "next_change": {"commit": "289e45a28da6b91fba2a824ec2af3771a34b2930", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex f0ebc54f7..3b9e08dd3 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -205,14 +200,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return true;\n   }\n \n-  public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n-                             String commitActionType, Map<String, List<String>> partitionToReplaceFileIds) {\n-\n-    HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n-        operationType, config.getSchema(), commitActionType);\n-    return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-  }\n-\n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 3b9e08dd3..12c55370f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -202,7 +203,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n-    preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n", "next_change": {"commit": "02efbb661e7ed13c3614ddee7ab5157623070f7c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 12c55370f..996648c0e 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -207,15 +210,12 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n \n   protected abstract HoodieTable<T, I, K, O> createTable(HoodieWriteConfig config, Configuration hadoopConf);\n \n-  protected abstract HoodieBackedTableMetadataWriter createMetadataWriter(HoodieWriteConfig config, Configuration hadoopConf);\n-\n   void emitCommitMetrics(String instantTime, HoodieCommitMetadata metadata, String actionType) {\n     try {\n \n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 42e513e33..ffb0b3506 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -233,6 +237,8 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n   protected abstract HoodieTable<T, I, K, O> createTable(HoodieWriteConfig config, Configuration hadoopConf);\n \n+  protected abstract HoodieBackedTableMetadataWriter createMetadataWriter(HoodieWriteConfig config, Configuration hadoopConf);\n+\n   void emitCommitMetrics(String instantTime, HoodieCommitMetadata metadata, String actionType) {\n     try {\n \n", "next_change": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ffb0b3506..ea6c6f81a 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -226,13 +213,26 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n     HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n         operationType, config.getSchema(), commitActionType);\n-    if (config.getWriteConcurrencyMode().isMultiWriter()) {\n-      LockConfiguration lockConfiguration = new LockConfiguration(config.getProps());\n-      LockProvider lockProvider = LockProviderSingleton.getLockProviderInstance(config, lockConfiguration, fs);\n-      return executeCriticalSection(instantTime, stats, extraMetadata, commitActionType, lockProvider, metadata);\n-    } else {\n-      return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-    }\n+    return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n+  }\n+\n+  private void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n+    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n+    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n+    HoodieTable table = createTable(config, hadoopConf);\n+    HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n+    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), instantTime, metadata, config, txnManager.getLastCompletedTransaction());\n+  }\n+\n+  private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n+                      List<HoodieWriteStat> stats) throws IOException {\n+    preCommit(instantTime, metadata);\n+    LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n+    HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n+    // Finalize write\n+    finalizeWrite(table, instantTime, stats);\n+    activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n+        Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n \n   protected abstract HoodieTable<T, I, K, O> createTable(HoodieWriteConfig config, Configuration hadoopConf);\n", "next_change": {"commit": "25a4d7f70cc0cfcec115ddfcc2a543a96bcb17af", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ea6c6f81a..063b26db8 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -221,7 +221,8 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n     HoodieTable table = createTable(config, hadoopConf);\n     HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), instantTime, metadata, config, txnManager.getLastCompletedTransaction());\n+    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), this.txnManager.getCurrentTxnInstant(),\n+        metadata, config, txnManager.getLastCompletedTransaction());\n   }\n \n   private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n", "next_change": {"commit": "f5a56cb4137b5f32af17405277c29d5a9088b6c7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 063b26db8..d45d77154 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,15 +216,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n-    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n-    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n-    HoodieTable table = createTable(config, hadoopConf);\n-    HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), this.txnManager.getCurrentTxnInstant(),\n-        metadata, config, txnManager.getLastCompletedTransaction());\n-  }\n-\n   private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "49dec09bfb444866e678fe956b28c3bf0ad2f373", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex d45d77154..4c1f5bf3c 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,7 +213,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n+  protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n", "next_change": {"commit": "0552abcc6400675c11ee35a4d4f3df109463f6f5", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 4c1f5bf3c..f0ebc54f7 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -220,8 +220,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata(true);\n-    this.txnManager.endTransaction();\n+    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n", "next_change": {"commit": "289e45a28da6b91fba2a824ec2af3771a34b2930", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex f0ebc54f7..3b9e08dd3 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -205,14 +200,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return true;\n   }\n \n-  public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n-                             String commitActionType, Map<String, List<String>> partitionToReplaceFileIds) {\n-\n-    HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n-        operationType, config.getSchema(), commitActionType);\n-    return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-  }\n-\n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 3b9e08dd3..12c55370f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -202,7 +203,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n-    preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n", "next_change": {"commit": "02efbb661e7ed13c3614ddee7ab5157623070f7c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 12c55370f..996648c0e 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -207,15 +210,12 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n \n   protected abstract HoodieTable<T, I, K, O> createTable(HoodieWriteConfig config, Configuration hadoopConf);\n \n-  protected abstract HoodieBackedTableMetadataWriter createMetadataWriter(HoodieWriteConfig config, Configuration hadoopConf);\n-\n   void emitCommitMetrics(String instantTime, HoodieCommitMetadata metadata, String actionType) {\n     try {\n \n", "next_change": null}]}}]}}]}}]}}]}}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ea6c6f81a..063b26db8 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -231,6 +232,8 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n+    syncTableMetadata(true);\n+    this.txnManager.endTransaction();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n", "next_change": {"commit": "f5a56cb4137b5f32af17405277c29d5a9088b6c7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 063b26db8..d45d77154 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,15 +216,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n-    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n-    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n-    HoodieTable table = createTable(config, hadoopConf);\n-    HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), this.txnManager.getCurrentTxnInstant(),\n-        metadata, config, txnManager.getLastCompletedTransaction());\n-  }\n-\n   private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "49dec09bfb444866e678fe956b28c3bf0ad2f373", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex d45d77154..4c1f5bf3c 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -216,7 +213,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n   }\n \n-  private void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n+  protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n", "next_change": {"commit": "0552abcc6400675c11ee35a4d4f3df109463f6f5", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 4c1f5bf3c..f0ebc54f7 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -220,8 +220,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata(true);\n-    this.txnManager.endTransaction();\n+    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n", "next_change": {"commit": "289e45a28da6b91fba2a824ec2af3771a34b2930", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex f0ebc54f7..3b9e08dd3 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -205,14 +200,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     return true;\n   }\n \n-  public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n-                             String commitActionType, Map<String, List<String>> partitionToReplaceFileIds) {\n-\n-    HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata,\n-        operationType, config.getSchema(), commitActionType);\n-    return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-  }\n-\n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n     preCommit(instantTime, metadata);\n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 3b9e08dd3..12c55370f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -202,7 +203,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n-    preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n", "next_change": {"commit": "02efbb661e7ed13c3614ddee7ab5157623070f7c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 12c55370f..996648c0e 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -207,15 +210,12 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n \n   protected abstract HoodieTable<T, I, K, O> createTable(HoodieWriteConfig config, Configuration hadoopConf);\n \n-  protected abstract HoodieBackedTableMetadataWriter createMetadataWriter(HoodieWriteConfig config, Configuration hadoopConf);\n-\n   void emitCommitMetrics(String instantTime, HoodieCommitMetadata metadata, String actionType) {\n     try {\n \n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MTc5Ng==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549551796", "bodyText": "typos", "author": "vinothchandar", "createdAt": "2020-12-29T03:07:34Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -821,6 +865,38 @@ protected void finalizeWrite(HoodieTable<T, I, K, O> table, String instantTime,\n     }\n   }\n \n+  private HoodieCommitMetadata resolveWriteConflictIfAny(HoodieTable<T, I, K, O> table, final String instantTime,\n+                                            HoodieCommitMetadata thisCommitMetadata) {\n+    Long currentTimeInSecs = System.currentTimeMillis() / 1000;\n+    ConflictResolutionStrategy resolutionStrategy = config.getWriteConflictResolutionStrategy();\n+    Option<HoodieInstant> lastCompletedInstantBeforeWriterStarted = this.latestWriteInstantCompletedBeforeWriter.get();\n+    String lastInstantTimestamp = lastCompletedInstantBeforeWriterStarted.isPresent()\n+        ? lastCompletedInstantBeforeWriterStarted.get().getTimestamp() : \"0\";\n+    Stream<HoodieInstant> instantStream = table.getActiveTimeline()\n+        .getAllCommitsTimeline()\n+        .getCommitsAndCompactionTimeline()\n+        .filterCompletedInstants()\n+        .findInstantsInRange(lastInstantTimestamp, String.valueOf(currentTimeInSecs))\n+        .getInstants();\n+\n+    LOG.info(\"Current eligible instants during write oHoodieWriteConfigf instant \" + instantTime + \" = \"", "originalCommit": "592e4bda9aed9af895b60db0d07393b2a6916d30", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "98c3c7ddf879d514e5c14293fee145c92f9416a3", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex e41c1c3ba..42e513e33 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -866,8 +845,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n   }\n \n   private HoodieCommitMetadata resolveWriteConflictIfAny(HoodieTable<T, I, K, O> table, final String instantTime,\n-                                            HoodieCommitMetadata thisCommitMetadata) {\n-    Long currentTimeInSecs = System.currentTimeMillis() / 1000;\n+                                            HoodieCommitMetadata thisCommitMetadata) throws HoodieWriteConflictException {\n     ConflictResolutionStrategy resolutionStrategy = config.getWriteConflictResolutionStrategy();\n     Option<HoodieInstant> lastCompletedInstantBeforeWriterStarted = this.latestWriteInstantCompletedBeforeWriter.get();\n     String lastInstantTimestamp = lastCompletedInstantBeforeWriterStarted.isPresent()\n", "next_change": {"commit": "57de565ef4bb6ea4386e80fb20d39eeb8dd96455", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 42e513e33..ffb0b3506 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -844,22 +943,30 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     }\n   }\n \n-  private HoodieCommitMetadata resolveWriteConflictIfAny(HoodieTable<T, I, K, O> table, final String instantTime,\n-                                            HoodieCommitMetadata thisCommitMetadata) throws HoodieWriteConflictException {\n+  private HoodieCommitMetadata resolveWriteConflictIfAny(HoodieTable<T, I, K, O> table, HoodieBackedTableMetadataWriter metadataWriter,\n+                                                         final String instantTime, HoodieCommitMetadata thisCommitMetadata)\n+      throws HoodieWriteConflictException {\n     ConflictResolutionStrategy resolutionStrategy = config.getWriteConflictResolutionStrategy();\n-    Option<HoodieInstant> lastCompletedInstantBeforeWriterStarted = this.latestWriteInstantCompletedBeforeWriter.get();\n+    Option<HoodieInstant> lastCompletedInstantBeforeWriterStarted = this.latestCompletedWriteInstant.get();\n     String lastInstantTimestamp = lastCompletedInstantBeforeWriterStarted.isPresent()\n         ? lastCompletedInstantBeforeWriterStarted.get().getTimestamp() : \"0\";\n-    Stream<HoodieInstant> instantStream = table.getActiveTimeline()\n+    // Get completed instants timeline\n+    Stream<HoodieInstant> completedInstantStream = table.getActiveTimeline()\n         .getAllCommitsTimeline()\n+        // TODO : getWriteTimeline to ensure we include replace commits as well\n         .getCommitsAndCompactionTimeline()\n         .filterCompletedInstants()\n         .findInstantsAfter(lastInstantTimestamp)\n         .getInstants();\n \n-    LOG.info(\"Current eligible instants to check conflict against during write of instant \" + instantTime + \" => \"\n-        + instantStream.collect(Collectors.toList()));\n+    // Get pending replace and compaction instants timeline\n+    Stream<HoodieInstant> pendingReplaceAndRequestedInstantStream = table.getActiveTimeline()\n+        .getAllCommitsTimeline()\n+        .filterPendingCompactionAndReplaceTimeline()\n+        .findInstantsAfter(lastInstantTimestamp)\n+        .getInstants();\n \n+    Stream<HoodieInstant> instantStream = Stream.concat(completedInstantStream, pendingReplaceAndRequestedInstantStream);\n     final HoodieCommitOperation thisOperation = new HoodieCommitOperation(thisCommitMetadata, instantTime);\n     instantStream.forEach(instant -> {\n       try {\n", "next_change": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ffb0b3506..ea6c6f81a 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -943,68 +966,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     }\n   }\n \n-  private HoodieCommitMetadata resolveWriteConflictIfAny(HoodieTable<T, I, K, O> table, HoodieBackedTableMetadataWriter metadataWriter,\n-                                                         final String instantTime, HoodieCommitMetadata thisCommitMetadata)\n-      throws HoodieWriteConflictException {\n-    ConflictResolutionStrategy resolutionStrategy = config.getWriteConflictResolutionStrategy();\n-    Option<HoodieInstant> lastCompletedInstantBeforeWriterStarted = this.latestCompletedWriteInstant.get();\n-    String lastInstantTimestamp = lastCompletedInstantBeforeWriterStarted.isPresent()\n-        ? lastCompletedInstantBeforeWriterStarted.get().getTimestamp() : \"0\";\n-    // Get completed instants timeline\n-    Stream<HoodieInstant> completedInstantStream = table.getActiveTimeline()\n-        .getAllCommitsTimeline()\n-        // TODO : getWriteTimeline to ensure we include replace commits as well\n-        .getCommitsAndCompactionTimeline()\n-        .filterCompletedInstants()\n-        .findInstantsAfter(lastInstantTimestamp)\n-        .getInstants();\n-\n-    // Get pending replace and compaction instants timeline\n-    Stream<HoodieInstant> pendingReplaceAndRequestedInstantStream = table.getActiveTimeline()\n-        .getAllCommitsTimeline()\n-        .filterPendingCompactionAndReplaceTimeline()\n-        .findInstantsAfter(lastInstantTimestamp)\n-        .getInstants();\n-\n-    Stream<HoodieInstant> instantStream = Stream.concat(completedInstantStream, pendingReplaceAndRequestedInstantStream);\n-    final HoodieCommitOperation thisOperation = new HoodieCommitOperation(thisCommitMetadata, instantTime);\n-    instantStream.forEach(instant -> {\n-      try {\n-        HoodieCommitOperation otherOperation = new HoodieCommitOperation(HoodieCommitMetadata.fromBytes(\n-            table.getActiveTimeline().getInstantDetails(instant).get(), HoodieCommitMetadata.class), instant.getTimestamp());\n-        if (resolutionStrategy.hasConflict(thisOperation, otherOperation)) {\n-          LOG.info(\"Conflict encountered between instant = \" + thisOperation.getInstant() + \" and instant = \"\n-              + otherOperation.getInstant() + \", attempting to resolve it now\");\n-          resolutionStrategy.resolveConflict(metadataWriter, table, thisOperation, otherOperation);\n-        }\n-      } catch (IOException io) {\n-        throw new HoodieWriteConflictException(\"Unable to resolve conflict, if present\", io);\n-      }\n-    });\n-    return thisOperation.getCommitMetadata();\n-  }\n-\n-  private boolean executeCriticalSection(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n-                                         String commitActionType, LockProvider lockProvider, HoodieCommitMetadata metadata) {\n-    try {\n-      // TODO : Make the executeCriticalSection generic by passing a function\n-      boolean acquired = lockProvider.tryLock(config.getLockAcquireWaitTimeoutInMs(), TimeUnit.MILLISECONDS);\n-      if (!acquired) {\n-        throw new HoodieLockException(\"Unable to acquire lock for instant \" + instantTime);\n-      }\n-      LOG.info(\"Acquired lock for instant time \" + instantTime);\n-      // Create a Hoodie table which encapsulated the commits and files visible.\n-      // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n-      HoodieTable table = createTable(config, hadoopConf);\n-      HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-      metadata = resolveWriteConflictIfAny(table, metadataWriter, instantTime, metadata);\n-      return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-    } finally {\n-      lockProvider.unlock();\n-      LOG.info(\"Released lock if acquired for instant time \" + instantTime);\n-    }\n-  }\n-\n   public HoodieMetrics getMetrics() {\n     return metrics;\n   }\n", "next_change": null}]}}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex e41c1c3ba..42e513e33 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -876,25 +854,47 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n         .getAllCommitsTimeline()\n         .getCommitsAndCompactionTimeline()\n         .filterCompletedInstants()\n-        .findInstantsInRange(lastInstantTimestamp, String.valueOf(currentTimeInSecs))\n+        .findInstantsAfter(lastInstantTimestamp)\n         .getInstants();\n \n-    LOG.info(\"Current eligible instants during write oHoodieWriteConfigf instant \" + instantTime + \" = \"\n+    LOG.info(\"Current eligible instants to check conflict against during write of instant \" + instantTime + \" => \"\n         + instantStream.collect(Collectors.toList()));\n \n-    boolean hasConflict = instantStream.anyMatch(instant -> {\n+    final HoodieCommitOperation thisOperation = new HoodieCommitOperation(thisCommitMetadata, instantTime);\n+    instantStream.forEach(instant -> {\n       try {\n-        return resolutionStrategy.hasConflict(thisCommitMetadata, HoodieCommitMetadata.fromBytes(\n-            table.getActiveTimeline().getInstantDetails(instant).get(), HoodieCommitMetadata.class));\n+        HoodieCommitOperation otherOperation = new HoodieCommitOperation(HoodieCommitMetadata.fromBytes(\n+            table.getActiveTimeline().getInstantDetails(instant).get(), HoodieCommitMetadata.class), instant.getTimestamp());\n+        if (resolutionStrategy.hasConflict(thisOperation, otherOperation)) {\n+          LOG.info(\"Conflict encountered between instant = \" + thisOperation.getInstant() + \" and instant = \"\n+              + otherOperation.getInstant() + \", attempting to resolve it now\");\n+          resolutionStrategy.resolveConflict(thisOperation, otherOperation);\n+        }\n       } catch (IOException io) {\n-        throw new HoodieCommitException(\"Unable to determine if conflict exists\", io);\n+        throw new HoodieWriteConflictException(\"Unable to resolve conflict, if present\", io);\n       }\n     });\n-    HoodieCommitMetadata newMetadataAfterConflictResolution = thisCommitMetadata;\n-    if (hasConflict) {\n-      newMetadataAfterConflictResolution = resolutionStrategy.resolveConflict(config, hadoopConf);\n+    return thisOperation.getCommitMetadata();\n+  }\n+\n+  private boolean criticalSectionForWrite(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n+                               String commitActionType, LockProvider lockProvider, HoodieCommitMetadata metadata) {\n+    try {\n+      boolean acquired = lockProvider.tryLock(config.getLockAcquireWaitTimeoutInMs(), TimeUnit.MILLISECONDS);\n+      if (!acquired) {\n+        throw new HoodieLockException(\"Unable to acquire lock for instant \" + instantTime);\n+      }\n+      LOG.info(\"Acquired lock for instant time \" + instantTime);\n+      // Create a Hoodie table which encapsulated the commits and files visible.\n+      // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n+      HoodieTable table = createTable(config, hadoopConf);\n+      metadata = resolveWriteConflictIfAny(table, instantTime, metadata);\n+      return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n+    } finally {\n+      lockProvider.unlock();\n+      lockProviderOption = Option.of(lockProvider);\n+      LOG.info(\"Released lock if acquired for instant time \" + instantTime);\n     }\n-    return newMetadataAfterConflictResolution;\n   }\n \n   public HoodieMetrics getMetrics() {\n", "next_change": {"commit": "21792c6722dd32dddbc5b6ec743549610cd9a8e0", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 42e513e33..19a0a1da4 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -857,9 +868,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n         .findInstantsAfter(lastInstantTimestamp)\n         .getInstants();\n \n-    LOG.info(\"Current eligible instants to check conflict against during write of instant \" + instantTime + \" => \"\n-        + instantStream.collect(Collectors.toList()));\n-\n     final HoodieCommitOperation thisOperation = new HoodieCommitOperation(thisCommitMetadata, instantTime);\n     instantStream.forEach(instant -> {\n       try {\n", "next_change": {"commit": "57de565ef4bb6ea4386e80fb20d39eeb8dd96455", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 19a0a1da4..ffb0b3506 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -855,19 +943,30 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     }\n   }\n \n-  private HoodieCommitMetadata resolveWriteConflictIfAny(HoodieTable<T, I, K, O> table, final String instantTime,\n-                                            HoodieCommitMetadata thisCommitMetadata) throws HoodieWriteConflictException {\n+  private HoodieCommitMetadata resolveWriteConflictIfAny(HoodieTable<T, I, K, O> table, HoodieBackedTableMetadataWriter metadataWriter,\n+                                                         final String instantTime, HoodieCommitMetadata thisCommitMetadata)\n+      throws HoodieWriteConflictException {\n     ConflictResolutionStrategy resolutionStrategy = config.getWriteConflictResolutionStrategy();\n-    Option<HoodieInstant> lastCompletedInstantBeforeWriterStarted = this.latestWriteInstantCompletedBeforeWriter.get();\n+    Option<HoodieInstant> lastCompletedInstantBeforeWriterStarted = this.latestCompletedWriteInstant.get();\n     String lastInstantTimestamp = lastCompletedInstantBeforeWriterStarted.isPresent()\n         ? lastCompletedInstantBeforeWriterStarted.get().getTimestamp() : \"0\";\n-    Stream<HoodieInstant> instantStream = table.getActiveTimeline()\n+    // Get completed instants timeline\n+    Stream<HoodieInstant> completedInstantStream = table.getActiveTimeline()\n         .getAllCommitsTimeline()\n+        // TODO : getWriteTimeline to ensure we include replace commits as well\n         .getCommitsAndCompactionTimeline()\n         .filterCompletedInstants()\n         .findInstantsAfter(lastInstantTimestamp)\n         .getInstants();\n \n+    // Get pending replace and compaction instants timeline\n+    Stream<HoodieInstant> pendingReplaceAndRequestedInstantStream = table.getActiveTimeline()\n+        .getAllCommitsTimeline()\n+        .filterPendingCompactionAndReplaceTimeline()\n+        .findInstantsAfter(lastInstantTimestamp)\n+        .getInstants();\n+\n+    Stream<HoodieInstant> instantStream = Stream.concat(completedInstantStream, pendingReplaceAndRequestedInstantStream);\n     final HoodieCommitOperation thisOperation = new HoodieCommitOperation(thisCommitMetadata, instantTime);\n     instantStream.forEach(instant -> {\n       try {\n", "next_change": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ffb0b3506..ea6c6f81a 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -943,68 +966,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     }\n   }\n \n-  private HoodieCommitMetadata resolveWriteConflictIfAny(HoodieTable<T, I, K, O> table, HoodieBackedTableMetadataWriter metadataWriter,\n-                                                         final String instantTime, HoodieCommitMetadata thisCommitMetadata)\n-      throws HoodieWriteConflictException {\n-    ConflictResolutionStrategy resolutionStrategy = config.getWriteConflictResolutionStrategy();\n-    Option<HoodieInstant> lastCompletedInstantBeforeWriterStarted = this.latestCompletedWriteInstant.get();\n-    String lastInstantTimestamp = lastCompletedInstantBeforeWriterStarted.isPresent()\n-        ? lastCompletedInstantBeforeWriterStarted.get().getTimestamp() : \"0\";\n-    // Get completed instants timeline\n-    Stream<HoodieInstant> completedInstantStream = table.getActiveTimeline()\n-        .getAllCommitsTimeline()\n-        // TODO : getWriteTimeline to ensure we include replace commits as well\n-        .getCommitsAndCompactionTimeline()\n-        .filterCompletedInstants()\n-        .findInstantsAfter(lastInstantTimestamp)\n-        .getInstants();\n-\n-    // Get pending replace and compaction instants timeline\n-    Stream<HoodieInstant> pendingReplaceAndRequestedInstantStream = table.getActiveTimeline()\n-        .getAllCommitsTimeline()\n-        .filterPendingCompactionAndReplaceTimeline()\n-        .findInstantsAfter(lastInstantTimestamp)\n-        .getInstants();\n-\n-    Stream<HoodieInstant> instantStream = Stream.concat(completedInstantStream, pendingReplaceAndRequestedInstantStream);\n-    final HoodieCommitOperation thisOperation = new HoodieCommitOperation(thisCommitMetadata, instantTime);\n-    instantStream.forEach(instant -> {\n-      try {\n-        HoodieCommitOperation otherOperation = new HoodieCommitOperation(HoodieCommitMetadata.fromBytes(\n-            table.getActiveTimeline().getInstantDetails(instant).get(), HoodieCommitMetadata.class), instant.getTimestamp());\n-        if (resolutionStrategy.hasConflict(thisOperation, otherOperation)) {\n-          LOG.info(\"Conflict encountered between instant = \" + thisOperation.getInstant() + \" and instant = \"\n-              + otherOperation.getInstant() + \", attempting to resolve it now\");\n-          resolutionStrategy.resolveConflict(metadataWriter, table, thisOperation, otherOperation);\n-        }\n-      } catch (IOException io) {\n-        throw new HoodieWriteConflictException(\"Unable to resolve conflict, if present\", io);\n-      }\n-    });\n-    return thisOperation.getCommitMetadata();\n-  }\n-\n-  private boolean executeCriticalSection(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n-                                         String commitActionType, LockProvider lockProvider, HoodieCommitMetadata metadata) {\n-    try {\n-      // TODO : Make the executeCriticalSection generic by passing a function\n-      boolean acquired = lockProvider.tryLock(config.getLockAcquireWaitTimeoutInMs(), TimeUnit.MILLISECONDS);\n-      if (!acquired) {\n-        throw new HoodieLockException(\"Unable to acquire lock for instant \" + instantTime);\n-      }\n-      LOG.info(\"Acquired lock for instant time \" + instantTime);\n-      // Create a Hoodie table which encapsulated the commits and files visible.\n-      // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n-      HoodieTable table = createTable(config, hadoopConf);\n-      HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-      metadata = resolveWriteConflictIfAny(table, metadataWriter, instantTime, metadata);\n-      return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-    } finally {\n-      lockProvider.unlock();\n-      LOG.info(\"Released lock if acquired for instant time \" + instantTime);\n-    }\n-  }\n-\n   public HoodieMetrics getMetrics() {\n     return metrics;\n   }\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MjI0MQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549552241", "bodyText": "we should probably have an API to resolveConflict(instant1, instant2) ? i.e like our preCombine method? that will give resolutionStrategy implementors to just reason between two instants and whether they conflict or not, and if they do, then munge the commit metadata somehow.", "author": "vinothchandar", "createdAt": "2020-12-29T03:10:10Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -821,6 +865,38 @@ protected void finalizeWrite(HoodieTable<T, I, K, O> table, String instantTime,\n     }\n   }\n \n+  private HoodieCommitMetadata resolveWriteConflictIfAny(HoodieTable<T, I, K, O> table, final String instantTime,\n+                                            HoodieCommitMetadata thisCommitMetadata) {\n+    Long currentTimeInSecs = System.currentTimeMillis() / 1000;\n+    ConflictResolutionStrategy resolutionStrategy = config.getWriteConflictResolutionStrategy();\n+    Option<HoodieInstant> lastCompletedInstantBeforeWriterStarted = this.latestWriteInstantCompletedBeforeWriter.get();\n+    String lastInstantTimestamp = lastCompletedInstantBeforeWriterStarted.isPresent()\n+        ? lastCompletedInstantBeforeWriterStarted.get().getTimestamp() : \"0\";\n+    Stream<HoodieInstant> instantStream = table.getActiveTimeline()\n+        .getAllCommitsTimeline()\n+        .getCommitsAndCompactionTimeline()\n+        .filterCompletedInstants()\n+        .findInstantsInRange(lastInstantTimestamp, String.valueOf(currentTimeInSecs))\n+        .getInstants();\n+\n+    LOG.info(\"Current eligible instants during write oHoodieWriteConfigf instant \" + instantTime + \" = \"\n+        + instantStream.collect(Collectors.toList()));\n+\n+    boolean hasConflict = instantStream.anyMatch(instant -> {\n+      try {\n+        return resolutionStrategy.hasConflict(thisCommitMetadata, HoodieCommitMetadata.fromBytes(\n+            table.getActiveTimeline().getInstantDetails(instant).get(), HoodieCommitMetadata.class));\n+      } catch (IOException io) {\n+        throw new HoodieCommitException(\"Unable to determine if conflict exists\", io);\n+      }\n+    });\n+    HoodieCommitMetadata newMetadataAfterConflictResolution = thisCommitMetadata;\n+    if (hasConflict) {\n+      newMetadataAfterConflictResolution = resolutionStrategy.resolveConflict(config, hadoopConf);", "originalCommit": "592e4bda9aed9af895b60db0d07393b2a6916d30", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDk3MjA4NA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r550972084", "bodyText": "Done", "author": "n3nash", "createdAt": "2021-01-03T08:08:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MjI0MQ=="}], "type": "inlineReview", "revised_code": {"commit": "98c3c7ddf879d514e5c14293fee145c92f9416a3", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex e41c1c3ba..42e513e33 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -866,8 +845,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n   }\n \n   private HoodieCommitMetadata resolveWriteConflictIfAny(HoodieTable<T, I, K, O> table, final String instantTime,\n-                                            HoodieCommitMetadata thisCommitMetadata) {\n-    Long currentTimeInSecs = System.currentTimeMillis() / 1000;\n+                                            HoodieCommitMetadata thisCommitMetadata) throws HoodieWriteConflictException {\n     ConflictResolutionStrategy resolutionStrategy = config.getWriteConflictResolutionStrategy();\n     Option<HoodieInstant> lastCompletedInstantBeforeWriterStarted = this.latestWriteInstantCompletedBeforeWriter.get();\n     String lastInstantTimestamp = lastCompletedInstantBeforeWriterStarted.isPresent()\n", "next_change": {"commit": "57de565ef4bb6ea4386e80fb20d39eeb8dd96455", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 42e513e33..ffb0b3506 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -844,22 +943,30 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     }\n   }\n \n-  private HoodieCommitMetadata resolveWriteConflictIfAny(HoodieTable<T, I, K, O> table, final String instantTime,\n-                                            HoodieCommitMetadata thisCommitMetadata) throws HoodieWriteConflictException {\n+  private HoodieCommitMetadata resolveWriteConflictIfAny(HoodieTable<T, I, K, O> table, HoodieBackedTableMetadataWriter metadataWriter,\n+                                                         final String instantTime, HoodieCommitMetadata thisCommitMetadata)\n+      throws HoodieWriteConflictException {\n     ConflictResolutionStrategy resolutionStrategy = config.getWriteConflictResolutionStrategy();\n-    Option<HoodieInstant> lastCompletedInstantBeforeWriterStarted = this.latestWriteInstantCompletedBeforeWriter.get();\n+    Option<HoodieInstant> lastCompletedInstantBeforeWriterStarted = this.latestCompletedWriteInstant.get();\n     String lastInstantTimestamp = lastCompletedInstantBeforeWriterStarted.isPresent()\n         ? lastCompletedInstantBeforeWriterStarted.get().getTimestamp() : \"0\";\n-    Stream<HoodieInstant> instantStream = table.getActiveTimeline()\n+    // Get completed instants timeline\n+    Stream<HoodieInstant> completedInstantStream = table.getActiveTimeline()\n         .getAllCommitsTimeline()\n+        // TODO : getWriteTimeline to ensure we include replace commits as well\n         .getCommitsAndCompactionTimeline()\n         .filterCompletedInstants()\n         .findInstantsAfter(lastInstantTimestamp)\n         .getInstants();\n \n-    LOG.info(\"Current eligible instants to check conflict against during write of instant \" + instantTime + \" => \"\n-        + instantStream.collect(Collectors.toList()));\n+    // Get pending replace and compaction instants timeline\n+    Stream<HoodieInstant> pendingReplaceAndRequestedInstantStream = table.getActiveTimeline()\n+        .getAllCommitsTimeline()\n+        .filterPendingCompactionAndReplaceTimeline()\n+        .findInstantsAfter(lastInstantTimestamp)\n+        .getInstants();\n \n+    Stream<HoodieInstant> instantStream = Stream.concat(completedInstantStream, pendingReplaceAndRequestedInstantStream);\n     final HoodieCommitOperation thisOperation = new HoodieCommitOperation(thisCommitMetadata, instantTime);\n     instantStream.forEach(instant -> {\n       try {\n", "next_change": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ffb0b3506..ea6c6f81a 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -943,68 +966,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     }\n   }\n \n-  private HoodieCommitMetadata resolveWriteConflictIfAny(HoodieTable<T, I, K, O> table, HoodieBackedTableMetadataWriter metadataWriter,\n-                                                         final String instantTime, HoodieCommitMetadata thisCommitMetadata)\n-      throws HoodieWriteConflictException {\n-    ConflictResolutionStrategy resolutionStrategy = config.getWriteConflictResolutionStrategy();\n-    Option<HoodieInstant> lastCompletedInstantBeforeWriterStarted = this.latestCompletedWriteInstant.get();\n-    String lastInstantTimestamp = lastCompletedInstantBeforeWriterStarted.isPresent()\n-        ? lastCompletedInstantBeforeWriterStarted.get().getTimestamp() : \"0\";\n-    // Get completed instants timeline\n-    Stream<HoodieInstant> completedInstantStream = table.getActiveTimeline()\n-        .getAllCommitsTimeline()\n-        // TODO : getWriteTimeline to ensure we include replace commits as well\n-        .getCommitsAndCompactionTimeline()\n-        .filterCompletedInstants()\n-        .findInstantsAfter(lastInstantTimestamp)\n-        .getInstants();\n-\n-    // Get pending replace and compaction instants timeline\n-    Stream<HoodieInstant> pendingReplaceAndRequestedInstantStream = table.getActiveTimeline()\n-        .getAllCommitsTimeline()\n-        .filterPendingCompactionAndReplaceTimeline()\n-        .findInstantsAfter(lastInstantTimestamp)\n-        .getInstants();\n-\n-    Stream<HoodieInstant> instantStream = Stream.concat(completedInstantStream, pendingReplaceAndRequestedInstantStream);\n-    final HoodieCommitOperation thisOperation = new HoodieCommitOperation(thisCommitMetadata, instantTime);\n-    instantStream.forEach(instant -> {\n-      try {\n-        HoodieCommitOperation otherOperation = new HoodieCommitOperation(HoodieCommitMetadata.fromBytes(\n-            table.getActiveTimeline().getInstantDetails(instant).get(), HoodieCommitMetadata.class), instant.getTimestamp());\n-        if (resolutionStrategy.hasConflict(thisOperation, otherOperation)) {\n-          LOG.info(\"Conflict encountered between instant = \" + thisOperation.getInstant() + \" and instant = \"\n-              + otherOperation.getInstant() + \", attempting to resolve it now\");\n-          resolutionStrategy.resolveConflict(metadataWriter, table, thisOperation, otherOperation);\n-        }\n-      } catch (IOException io) {\n-        throw new HoodieWriteConflictException(\"Unable to resolve conflict, if present\", io);\n-      }\n-    });\n-    return thisOperation.getCommitMetadata();\n-  }\n-\n-  private boolean executeCriticalSection(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n-                                         String commitActionType, LockProvider lockProvider, HoodieCommitMetadata metadata) {\n-    try {\n-      // TODO : Make the executeCriticalSection generic by passing a function\n-      boolean acquired = lockProvider.tryLock(config.getLockAcquireWaitTimeoutInMs(), TimeUnit.MILLISECONDS);\n-      if (!acquired) {\n-        throw new HoodieLockException(\"Unable to acquire lock for instant \" + instantTime);\n-      }\n-      LOG.info(\"Acquired lock for instant time \" + instantTime);\n-      // Create a Hoodie table which encapsulated the commits and files visible.\n-      // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n-      HoodieTable table = createTable(config, hadoopConf);\n-      HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-      metadata = resolveWriteConflictIfAny(table, metadataWriter, instantTime, metadata);\n-      return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-    } finally {\n-      lockProvider.unlock();\n-      LOG.info(\"Released lock if acquired for instant time \" + instantTime);\n-    }\n-  }\n-\n   public HoodieMetrics getMetrics() {\n     return metrics;\n   }\n", "next_change": null}]}}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex e41c1c3ba..42e513e33 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -876,25 +854,47 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n         .getAllCommitsTimeline()\n         .getCommitsAndCompactionTimeline()\n         .filterCompletedInstants()\n-        .findInstantsInRange(lastInstantTimestamp, String.valueOf(currentTimeInSecs))\n+        .findInstantsAfter(lastInstantTimestamp)\n         .getInstants();\n \n-    LOG.info(\"Current eligible instants during write oHoodieWriteConfigf instant \" + instantTime + \" = \"\n+    LOG.info(\"Current eligible instants to check conflict against during write of instant \" + instantTime + \" => \"\n         + instantStream.collect(Collectors.toList()));\n \n-    boolean hasConflict = instantStream.anyMatch(instant -> {\n+    final HoodieCommitOperation thisOperation = new HoodieCommitOperation(thisCommitMetadata, instantTime);\n+    instantStream.forEach(instant -> {\n       try {\n-        return resolutionStrategy.hasConflict(thisCommitMetadata, HoodieCommitMetadata.fromBytes(\n-            table.getActiveTimeline().getInstantDetails(instant).get(), HoodieCommitMetadata.class));\n+        HoodieCommitOperation otherOperation = new HoodieCommitOperation(HoodieCommitMetadata.fromBytes(\n+            table.getActiveTimeline().getInstantDetails(instant).get(), HoodieCommitMetadata.class), instant.getTimestamp());\n+        if (resolutionStrategy.hasConflict(thisOperation, otherOperation)) {\n+          LOG.info(\"Conflict encountered between instant = \" + thisOperation.getInstant() + \" and instant = \"\n+              + otherOperation.getInstant() + \", attempting to resolve it now\");\n+          resolutionStrategy.resolveConflict(thisOperation, otherOperation);\n+        }\n       } catch (IOException io) {\n-        throw new HoodieCommitException(\"Unable to determine if conflict exists\", io);\n+        throw new HoodieWriteConflictException(\"Unable to resolve conflict, if present\", io);\n       }\n     });\n-    HoodieCommitMetadata newMetadataAfterConflictResolution = thisCommitMetadata;\n-    if (hasConflict) {\n-      newMetadataAfterConflictResolution = resolutionStrategy.resolveConflict(config, hadoopConf);\n+    return thisOperation.getCommitMetadata();\n+  }\n+\n+  private boolean criticalSectionForWrite(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n+                               String commitActionType, LockProvider lockProvider, HoodieCommitMetadata metadata) {\n+    try {\n+      boolean acquired = lockProvider.tryLock(config.getLockAcquireWaitTimeoutInMs(), TimeUnit.MILLISECONDS);\n+      if (!acquired) {\n+        throw new HoodieLockException(\"Unable to acquire lock for instant \" + instantTime);\n+      }\n+      LOG.info(\"Acquired lock for instant time \" + instantTime);\n+      // Create a Hoodie table which encapsulated the commits and files visible.\n+      // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n+      HoodieTable table = createTable(config, hadoopConf);\n+      metadata = resolveWriteConflictIfAny(table, instantTime, metadata);\n+      return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n+    } finally {\n+      lockProvider.unlock();\n+      lockProviderOption = Option.of(lockProvider);\n+      LOG.info(\"Released lock if acquired for instant time \" + instantTime);\n     }\n-    return newMetadataAfterConflictResolution;\n   }\n \n   public HoodieMetrics getMetrics() {\n", "next_change": {"commit": "21792c6722dd32dddbc5b6ec743549610cd9a8e0", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 42e513e33..19a0a1da4 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -857,9 +868,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n         .findInstantsAfter(lastInstantTimestamp)\n         .getInstants();\n \n-    LOG.info(\"Current eligible instants to check conflict against during write of instant \" + instantTime + \" => \"\n-        + instantStream.collect(Collectors.toList()));\n-\n     final HoodieCommitOperation thisOperation = new HoodieCommitOperation(thisCommitMetadata, instantTime);\n     instantStream.forEach(instant -> {\n       try {\n", "next_change": {"commit": "57de565ef4bb6ea4386e80fb20d39eeb8dd96455", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 19a0a1da4..ffb0b3506 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -855,19 +943,30 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     }\n   }\n \n-  private HoodieCommitMetadata resolveWriteConflictIfAny(HoodieTable<T, I, K, O> table, final String instantTime,\n-                                            HoodieCommitMetadata thisCommitMetadata) throws HoodieWriteConflictException {\n+  private HoodieCommitMetadata resolveWriteConflictIfAny(HoodieTable<T, I, K, O> table, HoodieBackedTableMetadataWriter metadataWriter,\n+                                                         final String instantTime, HoodieCommitMetadata thisCommitMetadata)\n+      throws HoodieWriteConflictException {\n     ConflictResolutionStrategy resolutionStrategy = config.getWriteConflictResolutionStrategy();\n-    Option<HoodieInstant> lastCompletedInstantBeforeWriterStarted = this.latestWriteInstantCompletedBeforeWriter.get();\n+    Option<HoodieInstant> lastCompletedInstantBeforeWriterStarted = this.latestCompletedWriteInstant.get();\n     String lastInstantTimestamp = lastCompletedInstantBeforeWriterStarted.isPresent()\n         ? lastCompletedInstantBeforeWriterStarted.get().getTimestamp() : \"0\";\n-    Stream<HoodieInstant> instantStream = table.getActiveTimeline()\n+    // Get completed instants timeline\n+    Stream<HoodieInstant> completedInstantStream = table.getActiveTimeline()\n         .getAllCommitsTimeline()\n+        // TODO : getWriteTimeline to ensure we include replace commits as well\n         .getCommitsAndCompactionTimeline()\n         .filterCompletedInstants()\n         .findInstantsAfter(lastInstantTimestamp)\n         .getInstants();\n \n+    // Get pending replace and compaction instants timeline\n+    Stream<HoodieInstant> pendingReplaceAndRequestedInstantStream = table.getActiveTimeline()\n+        .getAllCommitsTimeline()\n+        .filterPendingCompactionAndReplaceTimeline()\n+        .findInstantsAfter(lastInstantTimestamp)\n+        .getInstants();\n+\n+    Stream<HoodieInstant> instantStream = Stream.concat(completedInstantStream, pendingReplaceAndRequestedInstantStream);\n     final HoodieCommitOperation thisOperation = new HoodieCommitOperation(thisCommitMetadata, instantTime);\n     instantStream.forEach(instant -> {\n       try {\n", "next_change": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ffb0b3506..ea6c6f81a 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -943,68 +966,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     }\n   }\n \n-  private HoodieCommitMetadata resolveWriteConflictIfAny(HoodieTable<T, I, K, O> table, HoodieBackedTableMetadataWriter metadataWriter,\n-                                                         final String instantTime, HoodieCommitMetadata thisCommitMetadata)\n-      throws HoodieWriteConflictException {\n-    ConflictResolutionStrategy resolutionStrategy = config.getWriteConflictResolutionStrategy();\n-    Option<HoodieInstant> lastCompletedInstantBeforeWriterStarted = this.latestCompletedWriteInstant.get();\n-    String lastInstantTimestamp = lastCompletedInstantBeforeWriterStarted.isPresent()\n-        ? lastCompletedInstantBeforeWriterStarted.get().getTimestamp() : \"0\";\n-    // Get completed instants timeline\n-    Stream<HoodieInstant> completedInstantStream = table.getActiveTimeline()\n-        .getAllCommitsTimeline()\n-        // TODO : getWriteTimeline to ensure we include replace commits as well\n-        .getCommitsAndCompactionTimeline()\n-        .filterCompletedInstants()\n-        .findInstantsAfter(lastInstantTimestamp)\n-        .getInstants();\n-\n-    // Get pending replace and compaction instants timeline\n-    Stream<HoodieInstant> pendingReplaceAndRequestedInstantStream = table.getActiveTimeline()\n-        .getAllCommitsTimeline()\n-        .filterPendingCompactionAndReplaceTimeline()\n-        .findInstantsAfter(lastInstantTimestamp)\n-        .getInstants();\n-\n-    Stream<HoodieInstant> instantStream = Stream.concat(completedInstantStream, pendingReplaceAndRequestedInstantStream);\n-    final HoodieCommitOperation thisOperation = new HoodieCommitOperation(thisCommitMetadata, instantTime);\n-    instantStream.forEach(instant -> {\n-      try {\n-        HoodieCommitOperation otherOperation = new HoodieCommitOperation(HoodieCommitMetadata.fromBytes(\n-            table.getActiveTimeline().getInstantDetails(instant).get(), HoodieCommitMetadata.class), instant.getTimestamp());\n-        if (resolutionStrategy.hasConflict(thisOperation, otherOperation)) {\n-          LOG.info(\"Conflict encountered between instant = \" + thisOperation.getInstant() + \" and instant = \"\n-              + otherOperation.getInstant() + \", attempting to resolve it now\");\n-          resolutionStrategy.resolveConflict(metadataWriter, table, thisOperation, otherOperation);\n-        }\n-      } catch (IOException io) {\n-        throw new HoodieWriteConflictException(\"Unable to resolve conflict, if present\", io);\n-      }\n-    });\n-    return thisOperation.getCommitMetadata();\n-  }\n-\n-  private boolean executeCriticalSection(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n-                                         String commitActionType, LockProvider lockProvider, HoodieCommitMetadata metadata) {\n-    try {\n-      // TODO : Make the executeCriticalSection generic by passing a function\n-      boolean acquired = lockProvider.tryLock(config.getLockAcquireWaitTimeoutInMs(), TimeUnit.MILLISECONDS);\n-      if (!acquired) {\n-        throw new HoodieLockException(\"Unable to acquire lock for instant \" + instantTime);\n-      }\n-      LOG.info(\"Acquired lock for instant time \" + instantTime);\n-      // Create a Hoodie table which encapsulated the commits and files visible.\n-      // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n-      HoodieTable table = createTable(config, hadoopConf);\n-      HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-      metadata = resolveWriteConflictIfAny(table, metadataWriter, instantTime, metadata);\n-      return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-    } finally {\n-      lockProvider.unlock();\n-      LOG.info(\"Released lock if acquired for instant time \" + instantTime);\n-    }\n-  }\n-\n   public HoodieMetrics getMetrics() {\n     return metrics;\n   }\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MjMxNA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549552314", "bodyText": "throw a special purpose exception here please", "author": "vinothchandar", "createdAt": "2020-12-29T03:10:51Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConcurrentFileWritesConflictResolutionStrategy.java", "diffHunk": "@@ -0,0 +1,54 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+public class ConcurrentFileWritesConflictResolutionStrategy\n+    implements ConflictResolutionStrategy {\n+\n+  private static final Logger LOG = LogManager.getLogger(ConcurrentFileWritesConflictResolutionStrategy.class);\n+\n+  @Override\n+  public boolean hasConflict(HoodieCommitMetadata firstInstant, HoodieCommitMetadata secondInstant) {\n+    // TODO : Ensure file ids are only the UUID and not the full name, also cann UUID's clash then for insert/insert ?\n+    Set<String> fileIdsSetForFirstInstant = firstInstant.getFileIdWithoutSuffixAndRelativePaths().keySet();\n+    Set<String> fileIdsSetForSecondInstant = secondInstant.getFileIdWithoutSuffixAndRelativePaths().keySet();\n+    Set<String> intersection = new HashSet<>(fileIdsSetForFirstInstant);\n+    intersection.retainAll(fileIdsSetForSecondInstant);\n+    if (!intersection.isEmpty()) {\n+      LOG.error(\"Found conflicting writes \" + intersection);\n+      return true;\n+    }\n+    return false;\n+  }\n+\n+  @Override\n+  public HoodieCommitMetadata resolveConflict(HoodieWriteConfig config, Configuration configuration) {\n+    throw new UnsupportedOperationException(\"Cannot resolve conflicts for overlapping writes\");", "originalCommit": "592e4bda9aed9af895b60db0d07393b2a6916d30", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "98c3c7ddf879d514e5c14293fee145c92f9416a3", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConcurrentFileWritesConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConcurrentFileWritesConflictResolutionStrategy.java\nindex 351830317..78d4022ca 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConcurrentFileWritesConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConcurrentFileWritesConflictResolutionStrategy.java\n", "chunk": "@@ -18,9 +18,10 @@\n \n package org.apache.hudi.client.lock;\n \n-import org.apache.hadoop.conf.Configuration;\n import org.apache.hudi.common.model.HoodieCommitMetadata;\n-import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.hudi.common.model.HoodieCommitOperation;\n+import org.apache.hudi.common.util.CommitMetadataUtils;\n+import org.apache.hudi.exception.HoodieWriteConflictException;\n import org.apache.log4j.LogManager;\n import org.apache.log4j.Logger;\n \n", "next_change": {"commit": "57de565ef4bb6ea4386e80fb20d39eeb8dd96455", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConcurrentFileWritesConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nsimilarity index 81%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConcurrentFileWritesConflictResolutionStrategy.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nindex 78d4022ca..fad1b1695 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConcurrentFileWritesConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n", "chunk": "@@ -22,20 +22,22 @@ import org.apache.hudi.common.model.HoodieCommitMetadata;\n import org.apache.hudi.common.model.HoodieCommitOperation;\n import org.apache.hudi.common.util.CommitMetadataUtils;\n import org.apache.hudi.exception.HoodieWriteConflictException;\n+import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n+import org.apache.hudi.table.HoodieTable;\n import org.apache.log4j.LogManager;\n import org.apache.log4j.Logger;\n \n import java.util.HashSet;\n import java.util.Set;\n \n-public class ConcurrentFileWritesConflictResolutionStrategy\n+public class SimpleConcurrentFileWritesConflictResolutionStrategy\n     implements ConflictResolutionStrategy {\n \n-  private static final Logger LOG = LogManager.getLogger(ConcurrentFileWritesConflictResolutionStrategy.class);\n+  private static final Logger LOG = LogManager.getLogger(SimpleConcurrentFileWritesConflictResolutionStrategy.class);\n \n   @Override\n   public boolean hasConflict(HoodieCommitOperation firstOperation, HoodieCommitOperation secondOperation) {\n-    // TODO : UUID's can clash even for insert/insert, handle that case\n+    // TODO : UUID's can clash even for insert/insert, handle that case.\n     Set<String> fileIdsSetForFirstInstant = CommitMetadataUtils.getFileIdWithoutSuffixAndRelativePaths(firstOperation\n         .getCommitMetadata().getPartitionToWriteStats()).keySet();\n     Set<String> fileIdsSetForSecondInstant = CommitMetadataUtils.getFileIdWithoutSuffixAndRelativePaths(secondOperation\n", "next_change": null}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConcurrentFileWritesConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConcurrentFileWritesConflictResolutionStrategy.java\nindex 351830317..78d4022ca 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConcurrentFileWritesConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConcurrentFileWritesConflictResolutionStrategy.java\n", "chunk": "@@ -33,22 +34,26 @@ public class ConcurrentFileWritesConflictResolutionStrategy\n   private static final Logger LOG = LogManager.getLogger(ConcurrentFileWritesConflictResolutionStrategy.class);\n \n   @Override\n-  public boolean hasConflict(HoodieCommitMetadata firstInstant, HoodieCommitMetadata secondInstant) {\n-    // TODO : Ensure file ids are only the UUID and not the full name, also cann UUID's clash then for insert/insert ?\n-    Set<String> fileIdsSetForFirstInstant = firstInstant.getFileIdWithoutSuffixAndRelativePaths().keySet();\n-    Set<String> fileIdsSetForSecondInstant = secondInstant.getFileIdWithoutSuffixAndRelativePaths().keySet();\n+  public boolean hasConflict(HoodieCommitOperation firstOperation, HoodieCommitOperation secondOperation) {\n+    // TODO : UUID's can clash even for insert/insert, handle that case\n+    Set<String> fileIdsSetForFirstInstant = CommitMetadataUtils.getFileIdWithoutSuffixAndRelativePaths(firstOperation\n+        .getCommitMetadata().getPartitionToWriteStats()).keySet();\n+    Set<String> fileIdsSetForSecondInstant = CommitMetadataUtils.getFileIdWithoutSuffixAndRelativePaths(secondOperation\n+        .getCommitMetadata().getPartitionToWriteStats()).keySet();\n     Set<String> intersection = new HashSet<>(fileIdsSetForFirstInstant);\n     intersection.retainAll(fileIdsSetForSecondInstant);\n     if (!intersection.isEmpty()) {\n-      LOG.error(\"Found conflicting writes \" + intersection);\n+      LOG.error(\"Found conflicting writes for instant1 \" + firstOperation.getInstant()\n+          + \" and instant 2 \" + secondOperation.getInstant() + \", intersecting file ids \" + intersection);\n       return true;\n     }\n     return false;\n   }\n \n   @Override\n-  public HoodieCommitMetadata resolveConflict(HoodieWriteConfig config, Configuration configuration) {\n-    throw new UnsupportedOperationException(\"Cannot resolve conflicts for overlapping writes\");\n+  public HoodieCommitMetadata resolveConflict(HoodieCommitOperation firstOperation,\n+                                              HoodieCommitOperation secondOperation) {\n+    throw new HoodieWriteConflictException(\"Cannot resolve conflicts for overlapping writes\");\n   }\n \n }\n", "next_change": {"commit": "57de565ef4bb6ea4386e80fb20d39eeb8dd96455", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConcurrentFileWritesConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nsimilarity index 81%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConcurrentFileWritesConflictResolutionStrategy.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nindex 78d4022ca..fad1b1695 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConcurrentFileWritesConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n", "chunk": "@@ -22,20 +22,22 @@ import org.apache.hudi.common.model.HoodieCommitMetadata;\n import org.apache.hudi.common.model.HoodieCommitOperation;\n import org.apache.hudi.common.util.CommitMetadataUtils;\n import org.apache.hudi.exception.HoodieWriteConflictException;\n+import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n+import org.apache.hudi.table.HoodieTable;\n import org.apache.log4j.LogManager;\n import org.apache.log4j.Logger;\n \n import java.util.HashSet;\n import java.util.Set;\n \n-public class ConcurrentFileWritesConflictResolutionStrategy\n+public class SimpleConcurrentFileWritesConflictResolutionStrategy\n     implements ConflictResolutionStrategy {\n \n-  private static final Logger LOG = LogManager.getLogger(ConcurrentFileWritesConflictResolutionStrategy.class);\n+  private static final Logger LOG = LogManager.getLogger(SimpleConcurrentFileWritesConflictResolutionStrategy.class);\n \n   @Override\n   public boolean hasConflict(HoodieCommitOperation firstOperation, HoodieCommitOperation secondOperation) {\n-    // TODO : UUID's can clash even for insert/insert, handle that case\n+    // TODO : UUID's can clash even for insert/insert, handle that case.\n     Set<String> fileIdsSetForFirstInstant = CommitMetadataUtils.getFileIdWithoutSuffixAndRelativePaths(firstOperation\n         .getCommitMetadata().getPartitionToWriteStats()).keySet();\n     Set<String> fileIdsSetForSecondInstant = CommitMetadataUtils.getFileIdWithoutSuffixAndRelativePaths(secondOperation\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConcurrentFileWritesConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nsimilarity index 81%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConcurrentFileWritesConflictResolutionStrategy.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nindex 78d4022ca..fad1b1695 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConcurrentFileWritesConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n", "chunk": "@@ -51,8 +53,9 @@ public class ConcurrentFileWritesConflictResolutionStrategy\n   }\n \n   @Override\n-  public HoodieCommitMetadata resolveConflict(HoodieCommitOperation firstOperation,\n-                                              HoodieCommitOperation secondOperation) {\n+  public HoodieCommitMetadata resolveConflict(HoodieBackedTableMetadataWriter metadataWriter, HoodieTable table,\n+                                              HoodieCommitOperation firstOperation, HoodieCommitOperation secondOperation) {\n+    // just abort the current write if conflicts are found\n     throw new HoodieWriteConflictException(\"Cannot resolve conflicts for overlapping writes\");\n   }\n \n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MjMzMg==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549552332", "bodyText": "more information on these logs", "author": "vinothchandar", "createdAt": "2020-12-29T03:11:04Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConcurrentFileWritesConflictResolutionStrategy.java", "diffHunk": "@@ -0,0 +1,54 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+public class ConcurrentFileWritesConflictResolutionStrategy\n+    implements ConflictResolutionStrategy {\n+\n+  private static final Logger LOG = LogManager.getLogger(ConcurrentFileWritesConflictResolutionStrategy.class);\n+\n+  @Override\n+  public boolean hasConflict(HoodieCommitMetadata firstInstant, HoodieCommitMetadata secondInstant) {\n+    // TODO : Ensure file ids are only the UUID and not the full name, also cann UUID's clash then for insert/insert ?\n+    Set<String> fileIdsSetForFirstInstant = firstInstant.getFileIdWithoutSuffixAndRelativePaths().keySet();\n+    Set<String> fileIdsSetForSecondInstant = secondInstant.getFileIdWithoutSuffixAndRelativePaths().keySet();\n+    Set<String> intersection = new HashSet<>(fileIdsSetForFirstInstant);\n+    intersection.retainAll(fileIdsSetForSecondInstant);\n+    if (!intersection.isEmpty()) {\n+      LOG.error(\"Found conflicting writes \" + intersection);", "originalCommit": "592e4bda9aed9af895b60db0d07393b2a6916d30", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "98c3c7ddf879d514e5c14293fee145c92f9416a3", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConcurrentFileWritesConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConcurrentFileWritesConflictResolutionStrategy.java\nindex 351830317..78d4022ca 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConcurrentFileWritesConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConcurrentFileWritesConflictResolutionStrategy.java\n", "chunk": "@@ -18,9 +18,10 @@\n \n package org.apache.hudi.client.lock;\n \n-import org.apache.hadoop.conf.Configuration;\n import org.apache.hudi.common.model.HoodieCommitMetadata;\n-import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.hudi.common.model.HoodieCommitOperation;\n+import org.apache.hudi.common.util.CommitMetadataUtils;\n+import org.apache.hudi.exception.HoodieWriteConflictException;\n import org.apache.log4j.LogManager;\n import org.apache.log4j.Logger;\n \n", "next_change": {"commit": "57de565ef4bb6ea4386e80fb20d39eeb8dd96455", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConcurrentFileWritesConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nsimilarity index 81%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConcurrentFileWritesConflictResolutionStrategy.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nindex 78d4022ca..fad1b1695 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConcurrentFileWritesConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n", "chunk": "@@ -22,20 +22,22 @@ import org.apache.hudi.common.model.HoodieCommitMetadata;\n import org.apache.hudi.common.model.HoodieCommitOperation;\n import org.apache.hudi.common.util.CommitMetadataUtils;\n import org.apache.hudi.exception.HoodieWriteConflictException;\n+import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n+import org.apache.hudi.table.HoodieTable;\n import org.apache.log4j.LogManager;\n import org.apache.log4j.Logger;\n \n import java.util.HashSet;\n import java.util.Set;\n \n-public class ConcurrentFileWritesConflictResolutionStrategy\n+public class SimpleConcurrentFileWritesConflictResolutionStrategy\n     implements ConflictResolutionStrategy {\n \n-  private static final Logger LOG = LogManager.getLogger(ConcurrentFileWritesConflictResolutionStrategy.class);\n+  private static final Logger LOG = LogManager.getLogger(SimpleConcurrentFileWritesConflictResolutionStrategy.class);\n \n   @Override\n   public boolean hasConflict(HoodieCommitOperation firstOperation, HoodieCommitOperation secondOperation) {\n-    // TODO : UUID's can clash even for insert/insert, handle that case\n+    // TODO : UUID's can clash even for insert/insert, handle that case.\n     Set<String> fileIdsSetForFirstInstant = CommitMetadataUtils.getFileIdWithoutSuffixAndRelativePaths(firstOperation\n         .getCommitMetadata().getPartitionToWriteStats()).keySet();\n     Set<String> fileIdsSetForSecondInstant = CommitMetadataUtils.getFileIdWithoutSuffixAndRelativePaths(secondOperation\n", "next_change": null}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConcurrentFileWritesConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConcurrentFileWritesConflictResolutionStrategy.java\nindex 351830317..78d4022ca 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConcurrentFileWritesConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConcurrentFileWritesConflictResolutionStrategy.java\n", "chunk": "@@ -33,22 +34,26 @@ public class ConcurrentFileWritesConflictResolutionStrategy\n   private static final Logger LOG = LogManager.getLogger(ConcurrentFileWritesConflictResolutionStrategy.class);\n \n   @Override\n-  public boolean hasConflict(HoodieCommitMetadata firstInstant, HoodieCommitMetadata secondInstant) {\n-    // TODO : Ensure file ids are only the UUID and not the full name, also cann UUID's clash then for insert/insert ?\n-    Set<String> fileIdsSetForFirstInstant = firstInstant.getFileIdWithoutSuffixAndRelativePaths().keySet();\n-    Set<String> fileIdsSetForSecondInstant = secondInstant.getFileIdWithoutSuffixAndRelativePaths().keySet();\n+  public boolean hasConflict(HoodieCommitOperation firstOperation, HoodieCommitOperation secondOperation) {\n+    // TODO : UUID's can clash even for insert/insert, handle that case\n+    Set<String> fileIdsSetForFirstInstant = CommitMetadataUtils.getFileIdWithoutSuffixAndRelativePaths(firstOperation\n+        .getCommitMetadata().getPartitionToWriteStats()).keySet();\n+    Set<String> fileIdsSetForSecondInstant = CommitMetadataUtils.getFileIdWithoutSuffixAndRelativePaths(secondOperation\n+        .getCommitMetadata().getPartitionToWriteStats()).keySet();\n     Set<String> intersection = new HashSet<>(fileIdsSetForFirstInstant);\n     intersection.retainAll(fileIdsSetForSecondInstant);\n     if (!intersection.isEmpty()) {\n-      LOG.error(\"Found conflicting writes \" + intersection);\n+      LOG.error(\"Found conflicting writes for instant1 \" + firstOperation.getInstant()\n+          + \" and instant 2 \" + secondOperation.getInstant() + \", intersecting file ids \" + intersection);\n       return true;\n     }\n     return false;\n   }\n \n   @Override\n-  public HoodieCommitMetadata resolveConflict(HoodieWriteConfig config, Configuration configuration) {\n-    throw new UnsupportedOperationException(\"Cannot resolve conflicts for overlapping writes\");\n+  public HoodieCommitMetadata resolveConflict(HoodieCommitOperation firstOperation,\n+                                              HoodieCommitOperation secondOperation) {\n+    throw new HoodieWriteConflictException(\"Cannot resolve conflicts for overlapping writes\");\n   }\n \n }\n", "next_change": {"commit": "57de565ef4bb6ea4386e80fb20d39eeb8dd96455", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConcurrentFileWritesConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nsimilarity index 81%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConcurrentFileWritesConflictResolutionStrategy.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nindex 78d4022ca..fad1b1695 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConcurrentFileWritesConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n", "chunk": "@@ -22,20 +22,22 @@ import org.apache.hudi.common.model.HoodieCommitMetadata;\n import org.apache.hudi.common.model.HoodieCommitOperation;\n import org.apache.hudi.common.util.CommitMetadataUtils;\n import org.apache.hudi.exception.HoodieWriteConflictException;\n+import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n+import org.apache.hudi.table.HoodieTable;\n import org.apache.log4j.LogManager;\n import org.apache.log4j.Logger;\n \n import java.util.HashSet;\n import java.util.Set;\n \n-public class ConcurrentFileWritesConflictResolutionStrategy\n+public class SimpleConcurrentFileWritesConflictResolutionStrategy\n     implements ConflictResolutionStrategy {\n \n-  private static final Logger LOG = LogManager.getLogger(ConcurrentFileWritesConflictResolutionStrategy.class);\n+  private static final Logger LOG = LogManager.getLogger(SimpleConcurrentFileWritesConflictResolutionStrategy.class);\n \n   @Override\n   public boolean hasConflict(HoodieCommitOperation firstOperation, HoodieCommitOperation secondOperation) {\n-    // TODO : UUID's can clash even for insert/insert, handle that case\n+    // TODO : UUID's can clash even for insert/insert, handle that case.\n     Set<String> fileIdsSetForFirstInstant = CommitMetadataUtils.getFileIdWithoutSuffixAndRelativePaths(firstOperation\n         .getCommitMetadata().getPartitionToWriteStats()).keySet();\n     Set<String> fileIdsSetForSecondInstant = CommitMetadataUtils.getFileIdWithoutSuffixAndRelativePaths(secondOperation\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConcurrentFileWritesConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nsimilarity index 81%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConcurrentFileWritesConflictResolutionStrategy.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nindex 78d4022ca..fad1b1695 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConcurrentFileWritesConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n", "chunk": "@@ -51,8 +53,9 @@ public class ConcurrentFileWritesConflictResolutionStrategy\n   }\n \n   @Override\n-  public HoodieCommitMetadata resolveConflict(HoodieCommitOperation firstOperation,\n-                                              HoodieCommitOperation secondOperation) {\n+  public HoodieCommitMetadata resolveConflict(HoodieBackedTableMetadataWriter metadataWriter, HoodieTable table,\n+                                              HoodieCommitOperation firstOperation, HoodieCommitOperation secondOperation) {\n+    // just abort the current write if conflicts are found\n     throw new HoodieWriteConflictException(\"Cannot resolve conflicts for overlapping writes\");\n   }\n \n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MjQzNQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549552435", "bodyText": "please add APIMaturity annotations and javadocs.", "author": "vinothchandar", "createdAt": "2020-12-29T03:11:48Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java", "diffHunk": "@@ -0,0 +1,35 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.config.HoodieWriteConfig;\n+\n+/**\n+ * Strategy for conflict resolution with multiple writers. Provide pluggable implementations for different\n+ * kinds of strategies to execute to resolve conflicts when multiple writers are mutating the hoodie table.\n+ */\n+public interface ConflictResolutionStrategy {\n+\n+  boolean hasConflict(HoodieCommitMetadata c1, HoodieCommitMetadata c2);", "originalCommit": "592e4bda9aed9af895b60db0d07393b2a6916d30", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "98c3c7ddf879d514e5c14293fee145c92f9416a3", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\nindex f578c6253..ba64b2330 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n", "chunk": "@@ -18,9 +18,10 @@\n \n package org.apache.hudi.client.lock;\n \n-import org.apache.hadoop.conf.Configuration;\n+import org.apache.hudi.ApiMaturityLevel;\n+import org.apache.hudi.PublicAPIMethod;\n import org.apache.hudi.common.model.HoodieCommitMetadata;\n-import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.hudi.common.model.HoodieCommitOperation;\n \n /**\n  * Strategy for conflict resolution with multiple writers. Provide pluggable implementations for different\n", "next_change": {"commit": "32df18ea69b24a19cda150875cdc636075544589", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\nindex ba64b2330..52086c84c 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n", "chunk": "@@ -24,13 +24,14 @@ import org.apache.hudi.common.model.HoodieCommitMetadata;\n import org.apache.hudi.common.model.HoodieCommitOperation;\n \n /**\n- * Strategy for conflict resolution with multiple writers. Provide pluggable implementations for different\n- * kinds of strategies to execute to resolve conflicts when multiple writers are mutating the hoodie table.\n+ * Strategy interface for conflict resolution with multiple writers.\n+ * Users can provide pluggable implementations for different kinds of strategies to resolve conflicts when multiple\n+ * writers are mutating the hoodie table.\n  */\n public interface ConflictResolutionStrategy {\n \n   /**\n-   * Implementations of this method will determine whether a conflict exists between 2 commits\n+   * Implementations of this method will determine whether a conflict exists between 2 commits.\n    * @param c1\n    * @param c2\n    * @return\n", "next_change": {"commit": "57de565ef4bb6ea4386e80fb20d39eeb8dd96455", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\nindex 52086c84c..06e42db63 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n", "chunk": "@@ -22,6 +22,8 @@ import org.apache.hudi.ApiMaturityLevel;\n import org.apache.hudi.PublicAPIMethod;\n import org.apache.hudi.common.model.HoodieCommitMetadata;\n import org.apache.hudi.common.model.HoodieCommitOperation;\n+import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n+import org.apache.hudi.table.HoodieTable;\n \n /**\n  * Strategy interface for conflict resolution with multiple writers.\n", "next_change": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\nindex 06e42db63..c06cb1046 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n", "chunk": "@@ -22,6 +22,7 @@ import org.apache.hudi.ApiMaturityLevel;\n import org.apache.hudi.PublicAPIMethod;\n import org.apache.hudi.common.model.HoodieCommitMetadata;\n import org.apache.hudi.common.model.HoodieCommitOperation;\n+import org.apache.hudi.common.util.Option;\n import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n import org.apache.hudi.table.HoodieTable;\n \n", "next_change": {"commit": "25a4d7f70cc0cfcec115ddfcc2a543a96bcb17af", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\nindex c06cb1046..0a50ee186 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n", "chunk": "@@ -22,10 +22,14 @@ import org.apache.hudi.ApiMaturityLevel;\n import org.apache.hudi.PublicAPIMethod;\n import org.apache.hudi.common.model.HoodieCommitMetadata;\n import org.apache.hudi.common.model.HoodieCommitOperation;\n+import org.apache.hudi.common.table.timeline.HoodieActiveTimeline;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n import org.apache.hudi.common.util.Option;\n import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n import org.apache.hudi.table.HoodieTable;\n \n+import java.util.stream.Stream;\n+\n /**\n  * Strategy interface for conflict resolution with multiple writers.\n  * Users can provide pluggable implementations for different kinds of strategies to resolve conflicts when multiple\n", "next_change": {"commit": "5f8950131414859ddc28a32fd3002eb1eb590e9b", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\nindex 0a50ee186..12a788ee8 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n", "chunk": "@@ -21,7 +21,6 @@ package org.apache.hudi.client.lock;\n import org.apache.hudi.ApiMaturityLevel;\n import org.apache.hudi.PublicAPIMethod;\n import org.apache.hudi.common.model.HoodieCommitMetadata;\n-import org.apache.hudi.common.model.HoodieCommitOperation;\n import org.apache.hudi.common.table.timeline.HoodieActiveTimeline;\n import org.apache.hudi.common.table.timeline.HoodieInstant;\n import org.apache.hudi.common.util.Option;\n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\nsimilarity index 81%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\nindex 12a788ee8..d6bc8d333 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\n", "chunk": "@@ -16,7 +16,7 @@\n  * limitations under the License.\n  */\n \n-package org.apache.hudi.client.lock;\n+package org.apache.hudi.client.transaction;\n \n import org.apache.hudi.ApiMaturityLevel;\n import org.apache.hudi.PublicAPIMethod;\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\nsimilarity index 81%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\nindex 12a788ee8..d6bc8d333 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\n", "chunk": "@@ -24,7 +24,6 @@ import org.apache.hudi.common.model.HoodieCommitMetadata;\n import org.apache.hudi.common.table.timeline.HoodieActiveTimeline;\n import org.apache.hudi.common.table.timeline.HoodieInstant;\n import org.apache.hudi.common.util.Option;\n-import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n import org.apache.hudi.table.HoodieTable;\n \n import java.util.stream.Stream;\n", "next_change": null}]}}]}}]}}]}}]}}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\nindex f578c6253..ba64b2330 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n", "chunk": "@@ -28,8 +29,22 @@ import org.apache.hudi.config.HoodieWriteConfig;\n  */\n public interface ConflictResolutionStrategy {\n \n-  boolean hasConflict(HoodieCommitMetadata c1, HoodieCommitMetadata c2);\n+  /**\n+   * Implementations of this method will determine whether a conflict exists between 2 commits\n+   * @param c1\n+   * @param c2\n+   * @return\n+   */\n+  @PublicAPIMethod(maturity = ApiMaturityLevel.EVOLVING)\n+  boolean hasConflict(HoodieCommitOperation c1, HoodieCommitOperation c2);\n \n-  HoodieCommitMetadata resolveConflict(HoodieWriteConfig config, Configuration configuration);\n+  /**\n+   * Implementations of this method will determine how to resolve a conflict between 2 commits\n+   * @param c1\n+   * @param c2\n+   * @return\n+   */\n+  @PublicAPIMethod(maturity = ApiMaturityLevel.EVOLVING)\n+  HoodieCommitMetadata resolveConflict(HoodieCommitOperation c1, HoodieCommitOperation c2);\n \n }\n", "next_change": {"commit": "32df18ea69b24a19cda150875cdc636075544589", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\nindex ba64b2330..52086c84c 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n", "chunk": "@@ -24,13 +24,14 @@ import org.apache.hudi.common.model.HoodieCommitMetadata;\n import org.apache.hudi.common.model.HoodieCommitOperation;\n \n /**\n- * Strategy for conflict resolution with multiple writers. Provide pluggable implementations for different\n- * kinds of strategies to execute to resolve conflicts when multiple writers are mutating the hoodie table.\n+ * Strategy interface for conflict resolution with multiple writers.\n+ * Users can provide pluggable implementations for different kinds of strategies to resolve conflicts when multiple\n+ * writers are mutating the hoodie table.\n  */\n public interface ConflictResolutionStrategy {\n \n   /**\n-   * Implementations of this method will determine whether a conflict exists between 2 commits\n+   * Implementations of this method will determine whether a conflict exists between 2 commits.\n    * @param c1\n    * @param c2\n    * @return\n", "next_change": {"commit": "57de565ef4bb6ea4386e80fb20d39eeb8dd96455", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\nindex 52086c84c..06e42db63 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n", "chunk": "@@ -22,6 +22,8 @@ import org.apache.hudi.ApiMaturityLevel;\n import org.apache.hudi.PublicAPIMethod;\n import org.apache.hudi.common.model.HoodieCommitMetadata;\n import org.apache.hudi.common.model.HoodieCommitOperation;\n+import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n+import org.apache.hudi.table.HoodieTable;\n \n /**\n  * Strategy interface for conflict resolution with multiple writers.\n", "next_change": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\nindex 06e42db63..c06cb1046 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n", "chunk": "@@ -22,6 +22,7 @@ import org.apache.hudi.ApiMaturityLevel;\n import org.apache.hudi.PublicAPIMethod;\n import org.apache.hudi.common.model.HoodieCommitMetadata;\n import org.apache.hudi.common.model.HoodieCommitOperation;\n+import org.apache.hudi.common.util.Option;\n import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n import org.apache.hudi.table.HoodieTable;\n \n", "next_change": {"commit": "25a4d7f70cc0cfcec115ddfcc2a543a96bcb17af", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\nindex c06cb1046..0a50ee186 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n", "chunk": "@@ -22,10 +22,14 @@ import org.apache.hudi.ApiMaturityLevel;\n import org.apache.hudi.PublicAPIMethod;\n import org.apache.hudi.common.model.HoodieCommitMetadata;\n import org.apache.hudi.common.model.HoodieCommitOperation;\n+import org.apache.hudi.common.table.timeline.HoodieActiveTimeline;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n import org.apache.hudi.common.util.Option;\n import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n import org.apache.hudi.table.HoodieTable;\n \n+import java.util.stream.Stream;\n+\n /**\n  * Strategy interface for conflict resolution with multiple writers.\n  * Users can provide pluggable implementations for different kinds of strategies to resolve conflicts when multiple\n", "next_change": {"commit": "5f8950131414859ddc28a32fd3002eb1eb590e9b", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\nindex 0a50ee186..12a788ee8 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n", "chunk": "@@ -21,7 +21,6 @@ package org.apache.hudi.client.lock;\n import org.apache.hudi.ApiMaturityLevel;\n import org.apache.hudi.PublicAPIMethod;\n import org.apache.hudi.common.model.HoodieCommitMetadata;\n-import org.apache.hudi.common.model.HoodieCommitOperation;\n import org.apache.hudi.common.table.timeline.HoodieActiveTimeline;\n import org.apache.hudi.common.table.timeline.HoodieInstant;\n import org.apache.hudi.common.util.Option;\n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\nsimilarity index 81%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\nindex 12a788ee8..d6bc8d333 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\n", "chunk": "@@ -16,7 +16,7 @@\n  * limitations under the License.\n  */\n \n-package org.apache.hudi.client.lock;\n+package org.apache.hudi.client.transaction;\n \n import org.apache.hudi.ApiMaturityLevel;\n import org.apache.hudi.PublicAPIMethod;\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\nsimilarity index 81%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\nindex 12a788ee8..d6bc8d333 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\n", "chunk": "@@ -24,7 +24,6 @@ import org.apache.hudi.common.model.HoodieCommitMetadata;\n import org.apache.hudi.common.table.timeline.HoodieActiveTimeline;\n import org.apache.hudi.common.table.timeline.HoodieInstant;\n import org.apache.hudi.common.util.Option;\n-import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n import org.apache.hudi.table.HoodieTable;\n \n import java.util.stream.Stream;\n", "next_change": null}]}}]}}]}}]}}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\nindex ba64b2330..52086c84c 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n", "chunk": "@@ -39,7 +40,7 @@ public interface ConflictResolutionStrategy {\n   boolean hasConflict(HoodieCommitOperation c1, HoodieCommitOperation c2);\n \n   /**\n-   * Implementations of this method will determine how to resolve a conflict between 2 commits\n+   * Implementations of this method will determine how to resolve a conflict between 2 commits.\n    * @param c1\n    * @param c2\n    * @return\n", "next_change": {"commit": "57de565ef4bb6ea4386e80fb20d39eeb8dd96455", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\nindex 52086c84c..06e42db63 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n", "chunk": "@@ -46,6 +48,7 @@ public interface ConflictResolutionStrategy {\n    * @return\n    */\n   @PublicAPIMethod(maturity = ApiMaturityLevel.EVOLVING)\n-  HoodieCommitMetadata resolveConflict(HoodieCommitOperation c1, HoodieCommitOperation c2);\n+  HoodieCommitMetadata resolveConflict(HoodieBackedTableMetadataWriter metadataWriter, HoodieTable table,\n+                                       HoodieCommitOperation c1, HoodieCommitOperation c2);\n \n }\n", "next_change": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\nindex 06e42db63..c06cb1046 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n", "chunk": "@@ -48,7 +49,7 @@ public interface ConflictResolutionStrategy {\n    * @return\n    */\n   @PublicAPIMethod(maturity = ApiMaturityLevel.EVOLVING)\n-  HoodieCommitMetadata resolveConflict(HoodieBackedTableMetadataWriter metadataWriter, HoodieTable table,\n+  HoodieCommitMetadata resolveConflict(Option<HoodieBackedTableMetadataWriter> metadataWriter, HoodieTable table,\n                                        HoodieCommitOperation c1, HoodieCommitOperation c2);\n \n }\n", "next_change": {"commit": "5f8950131414859ddc28a32fd3002eb1eb590e9b", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\nindex c06cb1046..12a788ee8 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n", "chunk": "@@ -33,23 +36,29 @@ import org.apache.hudi.table.HoodieTable;\n  */\n public interface ConflictResolutionStrategy {\n \n+  /**\n+   * Stream of instants to check conflicts against.\n+   * @return\n+   */\n+  Stream<HoodieInstant> getInstantsStream(HoodieActiveTimeline activeTimeline, HoodieInstant currentInstant, Option<HoodieInstant> lastSuccessfulInstant);\n+\n   /**\n    * Implementations of this method will determine whether a conflict exists between 2 commits.\n-   * @param c1\n-   * @param c2\n+   * @param thisOperation\n+   * @param otherOperation\n    * @return\n    */\n   @PublicAPIMethod(maturity = ApiMaturityLevel.EVOLVING)\n-  boolean hasConflict(HoodieCommitOperation c1, HoodieCommitOperation c2);\n+  boolean hasConflict(HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation);\n \n   /**\n    * Implementations of this method will determine how to resolve a conflict between 2 commits.\n-   * @param c1\n-   * @param c2\n+   * @param thisOperation\n+   * @param otherOperation\n    * @return\n    */\n   @PublicAPIMethod(maturity = ApiMaturityLevel.EVOLVING)\n-  HoodieCommitMetadata resolveConflict(Option<HoodieBackedTableMetadataWriter> metadataWriter, HoodieTable table,\n-                                       HoodieCommitOperation c1, HoodieCommitOperation c2);\n+  Option<HoodieCommitMetadata> resolveConflict(Option<HoodieBackedTableMetadataWriter> metadataWriter, HoodieTable table,\n+                                       HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation);\n \n }\n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\nsimilarity index 81%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\nindex 12a788ee8..d6bc8d333 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\n", "chunk": "@@ -40,7 +39,7 @@ public interface ConflictResolutionStrategy {\n    * Stream of instants to check conflicts against.\n    * @return\n    */\n-  Stream<HoodieInstant> getInstantsStream(HoodieActiveTimeline activeTimeline, HoodieInstant currentInstant, Option<HoodieInstant> lastSuccessfulInstant);\n+  Stream<HoodieInstant> getCandidateInstants(HoodieActiveTimeline activeTimeline, HoodieInstant currentInstant, Option<HoodieInstant> lastSuccessfulInstant);\n \n   /**\n    * Implementations of this method will determine whether a conflict exists between 2 commits.\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\nsimilarity index 81%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\nindex 12a788ee8..d6bc8d333 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\n", "chunk": "@@ -58,7 +57,7 @@ public interface ConflictResolutionStrategy {\n    * @return\n    */\n   @PublicAPIMethod(maturity = ApiMaturityLevel.EVOLVING)\n-  Option<HoodieCommitMetadata> resolveConflict(Option<HoodieBackedTableMetadataWriter> metadataWriter, HoodieTable table,\n-                                       HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation);\n+  Option<HoodieCommitMetadata> resolveConflict(HoodieTable table,\n+      HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation);\n \n }\n", "next_change": null}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MjU0OQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549552549", "bodyText": "please use FSUtils.getFS() always ! to get the filesystem object", "author": "vinothchandar", "createdAt": "2020-12-29T03:12:40Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/FileSystemBasedLockProvider.java", "diffHunk": "@@ -0,0 +1,97 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.hudi.common.lock.LockProvider;\n+import org.apache.hudi.exception.HoodieIOException;\n+import org.apache.hudi.exception.HoodieLockException;\n+\n+import java.io.IOException;\n+\n+import static org.apache.hudi.common.config.LockConfiguration.FILESYSTEM_LOCK_PATH_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.HOODIE_LOCK_ACQUIRE_NUM_RETRIES_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.HOODIE_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n+\n+/**\n+ * This lock provider is used to testing purposes only. It provides a simple file system based lock using HDFS atomic\n+ * create operation. This lock does not support cleaning/expiring the lock after a failed write hence cannot be used\n+ * in production environments.\n+ */\n+public class FileSystemBasedLockProvider extends LockProvider {\n+\n+  private static final String LOCK_NAME = \"acquired\";\n+\n+  private String lockPath;\n+  private FileSystem fs;\n+\n+  public FileSystemBasedLockProvider(LockConfiguration lockConfiguration, final Configuration configuration) {\n+    try {\n+      this.lockConfiguration = lockConfiguration;\n+      this.lockPath = lockConfiguration.getConfig().getString(FILESYSTEM_LOCK_PATH_PROP);\n+      this.fs = FileSystem.get(configuration);", "originalCommit": "592e4bda9aed9af895b60db0d07393b2a6916d30", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDk3MjE0NA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r550972144", "bodyText": "Moved this to test scope", "author": "n3nash", "createdAt": "2021-01-03T08:08:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MjU0OQ=="}], "type": "inlineReview", "revised_code": {"commit": "98c3c7ddf879d514e5c14293fee145c92f9416a3", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/FileSystemBasedLockProvider.java b/hudi-client/hudi-client-common/src/test/java/org/apache/hudi/client/lock/FileSystemBasedLockProviderTestClass.java\nsimilarity index 76%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/FileSystemBasedLockProvider.java\nrename to hudi-client/hudi-client-common/src/test/java/org/apache/hudi/client/lock/FileSystemBasedLockProviderTestClass.java\nindex 60a69bf44..fb594169c 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/FileSystemBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/test/java/org/apache/hudi/client/lock/FileSystemBasedLockProviderTestClass.java\n", "chunk": "@@ -27,24 +27,25 @@ import org.apache.hudi.exception.HoodieIOException;\n import org.apache.hudi.exception.HoodieLockException;\n \n import java.io.IOException;\n+import java.util.concurrent.TimeUnit;\n \n import static org.apache.hudi.common.config.LockConfiguration.FILESYSTEM_LOCK_PATH_PROP;\n-import static org.apache.hudi.common.config.LockConfiguration.HOODIE_LOCK_ACQUIRE_NUM_RETRIES_PROP;\n-import static org.apache.hudi.common.config.LockConfiguration.HOODIE_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_NUM_RETRIES_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n \n /**\n- * This lock provider is used to testing purposes only. It provides a simple file system based lock using HDFS atomic\n+ * This lock provider is used for testing purposes only. It provides a simple file system based lock using HDFS atomic\n  * create operation. This lock does not support cleaning/expiring the lock after a failed write hence cannot be used\n  * in production environments.\n  */\n-public class FileSystemBasedLockProvider extends LockProvider {\n+public class FileSystemBasedLockProviderTestClass extends LockProvider {\n \n   private static final String LOCK_NAME = \"acquired\";\n \n   private String lockPath;\n   private FileSystem fs;\n \n-  public FileSystemBasedLockProvider(LockConfiguration lockConfiguration, final Configuration configuration) {\n+  public FileSystemBasedLockProviderTestClass(LockConfiguration lockConfiguration, final Configuration configuration) {\n     try {\n       this.lockConfiguration = lockConfiguration;\n       this.lockPath = lockConfiguration.getConfig().getString(FILESYSTEM_LOCK_PATH_PROP);\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/FileSystemBasedLockProvider.java b/hudi-client/hudi-client-common/src/test/java/org/apache/hudi/client/lock/FileSystemBasedLockProviderTestClass.java\nsimilarity index 76%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/FileSystemBasedLockProvider.java\nrename to hudi-client/hudi-client-common/src/test/java/org/apache/hudi/client/lock/FileSystemBasedLockProviderTestClass.java\nindex 60a69bf44..fb594169c 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/FileSystemBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/test/java/org/apache/hudi/client/lock/FileSystemBasedLockProviderTestClass.java\n", "chunk": "@@ -54,7 +55,6 @@ public class FileSystemBasedLockProvider extends LockProvider {\n     }\n   }\n \n-  @Override\n   public void acquireLock() {\n     try {\n       fs.create(new Path(lockPath + \"/\" + LOCK_NAME)).close();\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/FileSystemBasedLockProvider.java b/hudi-client/hudi-client-common/src/test/java/org/apache/hudi/client/lock/FileSystemBasedLockProviderTestClass.java\nsimilarity index 76%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/FileSystemBasedLockProvider.java\nrename to hudi-client/hudi-client-common/src/test/java/org/apache/hudi/client/lock/FileSystemBasedLockProviderTestClass.java\nindex 60a69bf44..fb594169c 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/FileSystemBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/test/java/org/apache/hudi/client/lock/FileSystemBasedLockProviderTestClass.java\n", "chunk": "@@ -64,17 +64,21 @@ public class FileSystemBasedLockProvider extends LockProvider {\n   }\n \n   @Override\n-  public void close() throws Exception {\n-    fs.close();\n+  public void close() {\n+    try {\n+      fs.close();\n+    } catch (Exception e) {\n+      e.printStackTrace();\n+    }\n   }\n \n   @Override\n-  public boolean tryLock() {\n+  public boolean tryLock(long time, TimeUnit unit) {\n     try {\n       int numRetries = 0;\n       while (fs.exists(new Path(lockPath + \"/\" + LOCK_NAME))\n-          && (numRetries <= lockConfiguration.getConfig().getInteger(HOODIE_LOCK_ACQUIRE_NUM_RETRIES_PROP))) {\n-        Thread.sleep(lockConfiguration.getConfig().getInteger(HOODIE_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP));\n+          && (numRetries <= lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_NUM_RETRIES_PROP))) {\n+        Thread.sleep(lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP));\n       }\n       acquireLock();\n       return true;\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1Mjk1NA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549552954", "bodyText": "whats the guarantee that unlock() will fail for thread B, if thread A had actually created the lock file. Don't think this will work. We should remove this implementation, if we cannot get it right IMO", "author": "vinothchandar", "createdAt": "2020-12-29T03:15:09Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/FileSystemBasedLockProvider.java", "diffHunk": "@@ -0,0 +1,97 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.hudi.common.lock.LockProvider;\n+import org.apache.hudi.exception.HoodieIOException;\n+import org.apache.hudi.exception.HoodieLockException;\n+\n+import java.io.IOException;\n+\n+import static org.apache.hudi.common.config.LockConfiguration.FILESYSTEM_LOCK_PATH_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.HOODIE_LOCK_ACQUIRE_NUM_RETRIES_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.HOODIE_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n+\n+/**\n+ * This lock provider is used to testing purposes only. It provides a simple file system based lock using HDFS atomic\n+ * create operation. This lock does not support cleaning/expiring the lock after a failed write hence cannot be used\n+ * in production environments.\n+ */\n+public class FileSystemBasedLockProvider extends LockProvider {\n+\n+  private static final String LOCK_NAME = \"acquired\";\n+\n+  private String lockPath;\n+  private FileSystem fs;\n+\n+  public FileSystemBasedLockProvider(LockConfiguration lockConfiguration, final Configuration configuration) {\n+    try {\n+      this.lockConfiguration = lockConfiguration;\n+      this.lockPath = lockConfiguration.getConfig().getString(FILESYSTEM_LOCK_PATH_PROP);\n+      this.fs = FileSystem.get(configuration);\n+    } catch (IOException io) {\n+      throw new HoodieIOException(\"Unable to create file systems\", io);\n+    }\n+  }\n+\n+  @Override\n+  public void acquireLock() {\n+    try {\n+      fs.create(new Path(lockPath + \"/\" + LOCK_NAME)).close();\n+    } catch (IOException e) {\n+      throw new HoodieIOException(\"Failed to acquire lock\", e);\n+    }\n+  }\n+\n+  @Override\n+  public void close() throws Exception {\n+    fs.close();\n+  }\n+\n+  @Override\n+  public boolean tryLock() {\n+    try {\n+      int numRetries = 0;\n+      while (fs.exists(new Path(lockPath + \"/\" + LOCK_NAME))\n+          && (numRetries <= lockConfiguration.getConfig().getInteger(HOODIE_LOCK_ACQUIRE_NUM_RETRIES_PROP))) {\n+        Thread.sleep(lockConfiguration.getConfig().getInteger(HOODIE_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP));\n+      }\n+      acquireLock();\n+      return true;\n+    } catch (IOException | InterruptedException e) {\n+      throw new HoodieLockException(\"Failed to acquire lock\", e);\n+    }\n+  }\n+\n+  @Override\n+  public void unlock() {", "originalCommit": "592e4bda9aed9af895b60db0d07393b2a6916d30", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MzAyNA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549553024", "bodyText": "which is indeed hard. I dont its possible on cloud stores.", "author": "vinothchandar", "createdAt": "2020-12-29T03:15:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1Mjk1NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDkzNTM5Ng==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r550935396", "bodyText": "This was just implemented for my testing (mentioned in the comments), I've moved it to test scope.", "author": "n3nash", "createdAt": "2021-01-03T00:05:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1Mjk1NA=="}], "type": "inlineReview", "revised_code": {"commit": "98c3c7ddf879d514e5c14293fee145c92f9416a3", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/FileSystemBasedLockProvider.java b/hudi-client/hudi-client-common/src/test/java/org/apache/hudi/client/lock/FileSystemBasedLockProviderTestClass.java\nsimilarity index 76%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/FileSystemBasedLockProvider.java\nrename to hudi-client/hudi-client-common/src/test/java/org/apache/hudi/client/lock/FileSystemBasedLockProviderTestClass.java\nindex 60a69bf44..fb594169c 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/FileSystemBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/test/java/org/apache/hudi/client/lock/FileSystemBasedLockProviderTestClass.java\n", "chunk": "@@ -27,24 +27,25 @@ import org.apache.hudi.exception.HoodieIOException;\n import org.apache.hudi.exception.HoodieLockException;\n \n import java.io.IOException;\n+import java.util.concurrent.TimeUnit;\n \n import static org.apache.hudi.common.config.LockConfiguration.FILESYSTEM_LOCK_PATH_PROP;\n-import static org.apache.hudi.common.config.LockConfiguration.HOODIE_LOCK_ACQUIRE_NUM_RETRIES_PROP;\n-import static org.apache.hudi.common.config.LockConfiguration.HOODIE_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_NUM_RETRIES_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n \n /**\n- * This lock provider is used to testing purposes only. It provides a simple file system based lock using HDFS atomic\n+ * This lock provider is used for testing purposes only. It provides a simple file system based lock using HDFS atomic\n  * create operation. This lock does not support cleaning/expiring the lock after a failed write hence cannot be used\n  * in production environments.\n  */\n-public class FileSystemBasedLockProvider extends LockProvider {\n+public class FileSystemBasedLockProviderTestClass extends LockProvider {\n \n   private static final String LOCK_NAME = \"acquired\";\n \n   private String lockPath;\n   private FileSystem fs;\n \n-  public FileSystemBasedLockProvider(LockConfiguration lockConfiguration, final Configuration configuration) {\n+  public FileSystemBasedLockProviderTestClass(LockConfiguration lockConfiguration, final Configuration configuration) {\n     try {\n       this.lockConfiguration = lockConfiguration;\n       this.lockPath = lockConfiguration.getConfig().getString(FILESYSTEM_LOCK_PATH_PROP);\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/FileSystemBasedLockProvider.java b/hudi-client/hudi-client-common/src/test/java/org/apache/hudi/client/lock/FileSystemBasedLockProviderTestClass.java\nsimilarity index 76%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/FileSystemBasedLockProvider.java\nrename to hudi-client/hudi-client-common/src/test/java/org/apache/hudi/client/lock/FileSystemBasedLockProviderTestClass.java\nindex 60a69bf44..fb594169c 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/FileSystemBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/test/java/org/apache/hudi/client/lock/FileSystemBasedLockProviderTestClass.java\n", "chunk": "@@ -54,7 +55,6 @@ public class FileSystemBasedLockProvider extends LockProvider {\n     }\n   }\n \n-  @Override\n   public void acquireLock() {\n     try {\n       fs.create(new Path(lockPath + \"/\" + LOCK_NAME)).close();\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/FileSystemBasedLockProvider.java b/hudi-client/hudi-client-common/src/test/java/org/apache/hudi/client/lock/FileSystemBasedLockProviderTestClass.java\nsimilarity index 76%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/FileSystemBasedLockProvider.java\nrename to hudi-client/hudi-client-common/src/test/java/org/apache/hudi/client/lock/FileSystemBasedLockProviderTestClass.java\nindex 60a69bf44..fb594169c 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/FileSystemBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/test/java/org/apache/hudi/client/lock/FileSystemBasedLockProviderTestClass.java\n", "chunk": "@@ -64,17 +64,21 @@ public class FileSystemBasedLockProvider extends LockProvider {\n   }\n \n   @Override\n-  public void close() throws Exception {\n-    fs.close();\n+  public void close() {\n+    try {\n+      fs.close();\n+    } catch (Exception e) {\n+      e.printStackTrace();\n+    }\n   }\n \n   @Override\n-  public boolean tryLock() {\n+  public boolean tryLock(long time, TimeUnit unit) {\n     try {\n       int numRetries = 0;\n       while (fs.exists(new Path(lockPath + \"/\" + LOCK_NAME))\n-          && (numRetries <= lockConfiguration.getConfig().getInteger(HOODIE_LOCK_ACQUIRE_NUM_RETRIES_PROP))) {\n-        Thread.sleep(lockConfiguration.getConfig().getInteger(HOODIE_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP));\n+          && (numRetries <= lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_NUM_RETRIES_PROP))) {\n+        Thread.sleep(lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP));\n       }\n       acquireLock();\n       return true;\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MzEyMg==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549553122", "bodyText": "more context?", "author": "vinothchandar", "createdAt": "2020-12-29T03:16:07Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java", "diffHunk": "@@ -0,0 +1,135 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.curator.framework.CuratorFramework;\n+import org.apache.curator.framework.CuratorFrameworkFactory;\n+import org.apache.curator.framework.recipes.locks.InterProcessMutex;\n+import org.apache.curator.retry.BoundedExponentialBackoffRetry;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.hudi.common.lock.LockProvider;\n+import org.apache.hudi.common.util.ValidationUtils;\n+import org.apache.hudi.exception.HoodieLockException;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_CONNECTION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_SESSION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.HOODIE_LOCK_ACQUIRE_NUM_RETRIES_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.HOODIE_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_BASE_PATH_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECTION_TIMEOUT_MS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECT_URL_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_LOCK_KEY_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_SESSION_TIMEOUT_MS_PROP;\n+\n+/**\n+ * A zookeeper based lock. This {@link LockProvider} implementation allows to lock table operations\n+ * using zookeeper. Users need to have a Zookeeper cluster deployed to be able to use this lock.\n+ */\n+public class ZookeeperBasedLockProvider extends LockProvider {\n+\n+  private static final Logger LOG = LogManager.getLogger(ZookeeperBasedLockProvider.class);\n+\n+  private CuratorFramework curatorFrameworkClient;\n+  private final AtomicReference<InterProcessMutex> lock = new AtomicReference<>();\n+\n+  public ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration, final Configuration conf) {\n+    this(lockConfiguration);\n+    this.curatorFrameworkClient = CuratorFrameworkFactory.builder()\n+        .connectString(lockConfiguration.getConfig().getString(ZK_CONNECT_URL_PROP))\n+        .retryPolicy(new BoundedExponentialBackoffRetry(lockConfiguration.getConfig().getInteger(HOODIE_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP),\n+            5000, lockConfiguration.getConfig().getInteger(HOODIE_LOCK_ACQUIRE_NUM_RETRIES_PROP)))\n+        .namespace(lockConfiguration.getConfig().getString(ZK_BASE_PATH_PROP))\n+        .sessionTimeoutMs(lockConfiguration.getConfig().getInteger(ZK_SESSION_TIMEOUT_MS_PROP, DEFAULT_ZK_SESSION_TIMEOUT_MS))\n+        .connectionTimeoutMs(lockConfiguration.getConfig().getInteger(ZK_CONNECTION_TIMEOUT_MS_PROP, DEFAULT_ZK_CONNECTION_TIMEOUT_MS))\n+        .build();\n+    this.curatorFrameworkClient.start();\n+  }\n+\n+  public ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration, final CuratorFramework curatorFramework) {\n+    this(lockConfiguration);\n+    this.curatorFrameworkClient = curatorFramework;\n+    this.curatorFrameworkClient.start();\n+  }\n+\n+  ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration) {\n+    checkRequiredProps(lockConfiguration);\n+    this.lockConfiguration = lockConfiguration;\n+  }\n+  \n+  @Override\n+  public void acquireLock() throws Exception {\n+    ValidationUtils.checkArgument(this.lock.get() == null, \"Lock is already acquired\");\n+    InterProcessMutex newLock = new InterProcessMutex(\n+        this.curatorFrameworkClient, lockConfiguration.getConfig().getString(ZK_BASE_PATH_PROP) + \"/\"\n+        + this.lockConfiguration.getConfig().getString(ZK_LOCK_KEY_PROP));\n+    newLock.acquire();\n+    lock.compareAndSet(null, newLock);\n+  }\n+\n+  @Override\n+  public boolean tryLock() {\n+    LOG.info(\"Trying to acquire lock for ZkBasePath \" + lockConfiguration.getConfig().getString(ZK_BASE_PATH_PROP)\n+        + \" and lock key \" + this.lockConfiguration.getConfig().getString(ZK_LOCK_KEY_PROP));\n+    try {\n+      acquireLock();\n+    } catch (Exception e) {\n+      throw new HoodieLockException(\"Unable to acquire lock\", e);\n+    }\n+    return lock.get() != null && lock.get().isAcquiredInThisProcess();\n+  }\n+\n+  @Override\n+  public void unlock() {\n+    try {\n+      LOG.info(\"Releasing lock for ZkBasePath \"\n+          + lockConfiguration.getConfig().getString(ZK_BASE_PATH_PROP) + \" and lock key \"\n+          + this.lockConfiguration.getConfig().getString(ZK_LOCK_KEY_PROP));\n+      if (lock.get() == null) {\n+        return;\n+      }\n+      lock.get().release();\n+      lock.set(null);\n+      LOG.info(\"Released lock\");", "originalCommit": "592e4bda9aed9af895b60db0d07393b2a6916d30", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "98c3c7ddf879d514e5c14293fee145c92f9416a3", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nindex 94a2b8a4b..0067e47fb 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -20,22 +20,27 @@ package org.apache.hudi.client.lock;\n \n import org.apache.curator.framework.CuratorFramework;\n import org.apache.curator.framework.CuratorFrameworkFactory;\n+import org.apache.curator.framework.imps.CuratorFrameworkState;\n import org.apache.curator.framework.recipes.locks.InterProcessMutex;\n import org.apache.curator.retry.BoundedExponentialBackoffRetry;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.hudi.common.config.LockConfiguration;\n import org.apache.hudi.common.lock.LockProvider;\n+import org.apache.hudi.common.lock.LockState;\n+import org.apache.hudi.common.lock.LockUtils;\n+import org.apache.hudi.common.util.StringUtils;\n import org.apache.hudi.common.util.ValidationUtils;\n import org.apache.hudi.exception.HoodieLockException;\n import org.apache.log4j.LogManager;\n import org.apache.log4j.Logger;\n \n-import java.util.concurrent.atomic.AtomicReference;\n+import javax.annotation.concurrent.NotThreadSafe;\n+import java.util.concurrent.TimeUnit;\n \n import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_CONNECTION_TIMEOUT_MS;\n import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_SESSION_TIMEOUT_MS;\n-import static org.apache.hudi.common.config.LockConfiguration.HOODIE_LOCK_ACQUIRE_NUM_RETRIES_PROP;\n-import static org.apache.hudi.common.config.LockConfiguration.HOODIE_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_NUM_RETRIES_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n import static org.apache.hudi.common.config.LockConfiguration.ZK_BASE_PATH_PROP;\n import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECTION_TIMEOUT_MS_PROP;\n import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECT_URL_PROP;\n", "next_change": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nindex 0067e47fb..868f2effa 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -27,7 +27,6 @@ import org.apache.hadoop.conf.Configuration;\n import org.apache.hudi.common.config.LockConfiguration;\n import org.apache.hudi.common.lock.LockProvider;\n import org.apache.hudi.common.lock.LockState;\n-import org.apache.hudi.common.lock.LockUtils;\n import org.apache.hudi.common.util.StringUtils;\n import org.apache.hudi.common.util.ValidationUtils;\n import org.apache.hudi.exception.HoodieLockException;\n", "next_change": null}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nindex 94a2b8a4b..0067e47fb 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -46,19 +51,20 @@ import static org.apache.hudi.common.config.LockConfiguration.ZK_SESSION_TIMEOUT\n  * A zookeeper based lock. This {@link LockProvider} implementation allows to lock table operations\n  * using zookeeper. Users need to have a Zookeeper cluster deployed to be able to use this lock.\n  */\n+@NotThreadSafe\n public class ZookeeperBasedLockProvider extends LockProvider {\n \n   private static final Logger LOG = LogManager.getLogger(ZookeeperBasedLockProvider.class);\n \n   private CuratorFramework curatorFrameworkClient;\n-  private final AtomicReference<InterProcessMutex> lock = new AtomicReference<>();\n+  private volatile InterProcessMutex lock = null;\n \n   public ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration, final Configuration conf) {\n     this(lockConfiguration);\n     this.curatorFrameworkClient = CuratorFrameworkFactory.builder()\n         .connectString(lockConfiguration.getConfig().getString(ZK_CONNECT_URL_PROP))\n-        .retryPolicy(new BoundedExponentialBackoffRetry(lockConfiguration.getConfig().getInteger(HOODIE_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP),\n-            5000, lockConfiguration.getConfig().getInteger(HOODIE_LOCK_ACQUIRE_NUM_RETRIES_PROP)))\n+        .retryPolicy(new BoundedExponentialBackoffRetry(lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP),\n+            5000, lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_NUM_RETRIES_PROP)))\n         .namespace(lockConfiguration.getConfig().getString(ZK_BASE_PATH_PROP))\n         .sessionTimeoutMs(lockConfiguration.getConfig().getInteger(ZK_SESSION_TIMEOUT_MS_PROP, DEFAULT_ZK_SESSION_TIMEOUT_MS))\n         .connectionTimeoutMs(lockConfiguration.getConfig().getInteger(ZK_CONNECTION_TIMEOUT_MS_PROP, DEFAULT_ZK_CONNECTION_TIMEOUT_MS))\n", "next_change": {"commit": "09ba2a5ee6bd79ad616dd7cab835a8511878024b", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nindex 0067e47fb..03c2408ca 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -65,7 +64,6 @@ public class ZookeeperBasedLockProvider extends LockProvider {\n         .connectString(lockConfiguration.getConfig().getString(ZK_CONNECT_URL_PROP))\n         .retryPolicy(new BoundedExponentialBackoffRetry(lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP),\n             5000, lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_NUM_RETRIES_PROP)))\n-        .namespace(lockConfiguration.getConfig().getString(ZK_BASE_PATH_PROP))\n         .sessionTimeoutMs(lockConfiguration.getConfig().getInteger(ZK_SESSION_TIMEOUT_MS_PROP, DEFAULT_ZK_SESSION_TIMEOUT_MS))\n         .connectionTimeoutMs(lockConfiguration.getConfig().getInteger(ZK_CONNECTION_TIMEOUT_MS_PROP, DEFAULT_ZK_CONNECTION_TIMEOUT_MS))\n         .build();\n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nsimilarity index 88%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nindex 03c2408ca..5e7ec67fe 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -55,11 +55,12 @@ public class ZookeeperBasedLockProvider extends LockProvider {\n \n   private static final Logger LOG = LogManager.getLogger(ZookeeperBasedLockProvider.class);\n \n-  private CuratorFramework curatorFrameworkClient;\n+  private final CuratorFramework curatorFrameworkClient;\n   private volatile InterProcessMutex lock = null;\n \n   public ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration, final Configuration conf) {\n-    this(lockConfiguration);\n+    checkRequiredProps(lockConfiguration);\n+    this.lockConfiguration = lockConfiguration;\n     this.curatorFrameworkClient = CuratorFrameworkFactory.builder()\n         .connectString(lockConfiguration.getConfig().getString(ZK_CONNECT_URL_PROP))\n         .retryPolicy(new BoundedExponentialBackoffRetry(lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP),\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nsimilarity index 88%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nindex 03c2408ca..5e7ec67fe 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -70,8 +71,11 @@ public class ZookeeperBasedLockProvider extends LockProvider {\n     this.curatorFrameworkClient.start();\n   }\n \n-  public ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration, final CuratorFramework curatorFrameworkClient) {\n-    this(lockConfiguration);\n+  // Only used for testing\n+  public ZookeeperBasedLockProvider(\n+      final LockConfiguration lockConfiguration, final CuratorFramework curatorFrameworkClient) {\n+    checkRequiredProps(lockConfiguration);\n+    this.lockConfiguration = lockConfiguration;\n     this.curatorFrameworkClient = curatorFrameworkClient;\n     synchronized (this.curatorFrameworkClient) {\n       if (this.curatorFrameworkClient.getState() != CuratorFrameworkState.STARTED) {\n", "next_change": null}]}}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nindex 94a2b8a4b..0067e47fb 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -66,10 +72,14 @@ public class ZookeeperBasedLockProvider extends LockProvider {\n     this.curatorFrameworkClient.start();\n   }\n \n-  public ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration, final CuratorFramework curatorFramework) {\n+  public ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration, final CuratorFramework curatorFrameworkClient) {\n     this(lockConfiguration);\n-    this.curatorFrameworkClient = curatorFramework;\n-    this.curatorFrameworkClient.start();\n+    this.curatorFrameworkClient = curatorFrameworkClient;\n+    synchronized (this.curatorFrameworkClient) {\n+      if (this.curatorFrameworkClient.getState() != CuratorFrameworkState.STARTED) {\n+        this.curatorFrameworkClient.start();\n+      }\n+    }\n   }\n \n   ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration) {\n", "next_change": {"commit": "09ba2a5ee6bd79ad616dd7cab835a8511878024b", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nindex 0067e47fb..03c2408ca 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -65,7 +64,6 @@ public class ZookeeperBasedLockProvider extends LockProvider {\n         .connectString(lockConfiguration.getConfig().getString(ZK_CONNECT_URL_PROP))\n         .retryPolicy(new BoundedExponentialBackoffRetry(lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP),\n             5000, lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_NUM_RETRIES_PROP)))\n-        .namespace(lockConfiguration.getConfig().getString(ZK_BASE_PATH_PROP))\n         .sessionTimeoutMs(lockConfiguration.getConfig().getInteger(ZK_SESSION_TIMEOUT_MS_PROP, DEFAULT_ZK_SESSION_TIMEOUT_MS))\n         .connectionTimeoutMs(lockConfiguration.getConfig().getInteger(ZK_CONNECTION_TIMEOUT_MS_PROP, DEFAULT_ZK_CONNECTION_TIMEOUT_MS))\n         .build();\n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nsimilarity index 88%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nindex 03c2408ca..5e7ec67fe 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -55,11 +55,12 @@ public class ZookeeperBasedLockProvider extends LockProvider {\n \n   private static final Logger LOG = LogManager.getLogger(ZookeeperBasedLockProvider.class);\n \n-  private CuratorFramework curatorFrameworkClient;\n+  private final CuratorFramework curatorFrameworkClient;\n   private volatile InterProcessMutex lock = null;\n \n   public ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration, final Configuration conf) {\n-    this(lockConfiguration);\n+    checkRequiredProps(lockConfiguration);\n+    this.lockConfiguration = lockConfiguration;\n     this.curatorFrameworkClient = CuratorFrameworkFactory.builder()\n         .connectString(lockConfiguration.getConfig().getString(ZK_CONNECT_URL_PROP))\n         .retryPolicy(new BoundedExponentialBackoffRetry(lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP),\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nsimilarity index 88%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nindex 03c2408ca..5e7ec67fe 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -70,8 +71,11 @@ public class ZookeeperBasedLockProvider extends LockProvider {\n     this.curatorFrameworkClient.start();\n   }\n \n-  public ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration, final CuratorFramework curatorFrameworkClient) {\n-    this(lockConfiguration);\n+  // Only used for testing\n+  public ZookeeperBasedLockProvider(\n+      final LockConfiguration lockConfiguration, final CuratorFramework curatorFrameworkClient) {\n+    checkRequiredProps(lockConfiguration);\n+    this.lockConfiguration = lockConfiguration;\n     this.curatorFrameworkClient = curatorFrameworkClient;\n     synchronized (this.curatorFrameworkClient) {\n       if (this.curatorFrameworkClient.getState() != CuratorFrameworkState.STARTED) {\n", "next_change": null}]}}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nindex 94a2b8a4b..0067e47fb 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -77,52 +87,55 @@ public class ZookeeperBasedLockProvider extends LockProvider {\n     this.lockConfiguration = lockConfiguration;\n   }\n   \n-  @Override\n-  public void acquireLock() throws Exception {\n-    ValidationUtils.checkArgument(this.lock.get() == null, \"Lock is already acquired\");\n+  public void acquireLock(long time, TimeUnit unit) throws Exception {\n+    ValidationUtils.checkArgument(this.lock == null, LockState.ALREADY_ACQUIRED.name());\n     InterProcessMutex newLock = new InterProcessMutex(\n         this.curatorFrameworkClient, lockConfiguration.getConfig().getString(ZK_BASE_PATH_PROP) + \"/\"\n         + this.lockConfiguration.getConfig().getString(ZK_LOCK_KEY_PROP));\n-    newLock.acquire();\n-    lock.compareAndSet(null, newLock);\n+    newLock.acquire(time, unit);\n+    if (newLock.isAcquiredInThisProcess()) {\n+      lock = newLock;\n+    }\n   }\n \n   @Override\n-  public boolean tryLock() {\n-    LOG.info(\"Trying to acquire lock for ZkBasePath \" + lockConfiguration.getConfig().getString(ZK_BASE_PATH_PROP)\n-        + \" and lock key \" + this.lockConfiguration.getConfig().getString(ZK_LOCK_KEY_PROP));\n+  public boolean tryLock(long time, TimeUnit unit) {\n+    LOG.info(LockUtils.generateLogStatement(LockState.ACQUIRING, generateLogSuffixString()));\n     try {\n-      acquireLock();\n+      acquireLock(time, unit);\n+      LOG.info(LockUtils.generateLogStatement(LockState.ACQUIRED, generateLogSuffixString()));\n     } catch (Exception e) {\n-      throw new HoodieLockException(\"Unable to acquire lock\", e);\n+      throw new HoodieLockException(LockUtils.generateLogStatement(LockState.FAILED_TO_ACQUIRE, generateLogSuffixString()), e);\n     }\n-    return lock.get() != null && lock.get().isAcquiredInThisProcess();\n+    return lock != null && lock.isAcquiredInThisProcess();\n   }\n \n   @Override\n   public void unlock() {\n     try {\n-      LOG.info(\"Releasing lock for ZkBasePath \"\n-          + lockConfiguration.getConfig().getString(ZK_BASE_PATH_PROP) + \" and lock key \"\n-          + this.lockConfiguration.getConfig().getString(ZK_LOCK_KEY_PROP));\n-      if (lock.get() == null) {\n+      LOG.info(LockUtils.generateLogStatement(LockState.RELEASING, generateLogSuffixString()));\n+      if (lock == null || !lock.isAcquiredInThisProcess()) {\n         return;\n       }\n-      lock.get().release();\n-      lock.set(null);\n-      LOG.info(\"Released lock\");\n+      lock.release();\n+      lock = null;\n+      LOG.info(LockUtils.generateLogStatement(LockState.RELEASED, generateLogSuffixString()));\n     } catch (Exception e) {\n-      throw new HoodieLockException(\"Unable to release lock\", e);\n+      throw new HoodieLockException(LockUtils.generateLogStatement(LockState.FAILED_TO_RELEASE, generateLogSuffixString()), e);\n     }\n   }\n \n   @Override\n-  public void close() throws Exception {\n-    if (lock.get() != null) {\n-      lock.get().release();\n-      lock.set(null);\n+  public void close() {\n+    try {\n+      if (lock != null) {\n+        lock.release();\n+        lock = null;\n+      }\n+      this.curatorFrameworkClient.close();\n+    } catch (Exception e) {\n+      LOG.error(LockUtils.generateLogStatement(LockState.FAILED_TO_RELEASE, generateLogSuffixString()));\n     }\n-    this.curatorFrameworkClient.close();\n   }\n \n   private void checkRequiredProps(final LockConfiguration config) {\n", "next_change": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nindex 0067e47fb..868f2effa 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -100,12 +99,12 @@ public class ZookeeperBasedLockProvider extends LockProvider {\n \n   @Override\n   public boolean tryLock(long time, TimeUnit unit) {\n-    LOG.info(LockUtils.generateLogStatement(LockState.ACQUIRING, generateLogSuffixString()));\n+    LOG.info(generateLogStatement(LockState.ACQUIRING, generateLogSuffixString()));\n     try {\n       acquireLock(time, unit);\n-      LOG.info(LockUtils.generateLogStatement(LockState.ACQUIRED, generateLogSuffixString()));\n+      LOG.info(generateLogStatement(LockState.ACQUIRED, generateLogSuffixString()));\n     } catch (Exception e) {\n-      throw new HoodieLockException(LockUtils.generateLogStatement(LockState.FAILED_TO_ACQUIRE, generateLogSuffixString()), e);\n+      throw new HoodieLockException(generateLogStatement(LockState.FAILED_TO_ACQUIRE, generateLogSuffixString()), e);\n     }\n     return lock != null && lock.isAcquiredInThisProcess();\n   }\n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nsimilarity index 88%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nindex 868f2effa..5e7ec67fe 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -81,22 +84,6 @@ public class ZookeeperBasedLockProvider extends LockProvider {\n     }\n   }\n \n-  ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration) {\n-    checkRequiredProps(lockConfiguration);\n-    this.lockConfiguration = lockConfiguration;\n-  }\n-  \n-  public void acquireLock(long time, TimeUnit unit) throws Exception {\n-    ValidationUtils.checkArgument(this.lock == null, LockState.ALREADY_ACQUIRED.name());\n-    InterProcessMutex newLock = new InterProcessMutex(\n-        this.curatorFrameworkClient, lockConfiguration.getConfig().getString(ZK_BASE_PATH_PROP) + \"/\"\n-        + this.lockConfiguration.getConfig().getString(ZK_LOCK_KEY_PROP));\n-    newLock.acquire(time, unit);\n-    if (newLock.isAcquiredInThisProcess()) {\n-      lock = newLock;\n-    }\n-  }\n-\n   @Override\n   public boolean tryLock(long time, TimeUnit unit) {\n     LOG.info(generateLogStatement(LockState.ACQUIRING, generateLogSuffixString()));\n", "next_change": null}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nindex 0067e47fb..868f2effa 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -113,15 +112,15 @@ public class ZookeeperBasedLockProvider extends LockProvider {\n   @Override\n   public void unlock() {\n     try {\n-      LOG.info(LockUtils.generateLogStatement(LockState.RELEASING, generateLogSuffixString()));\n+      LOG.info(generateLogStatement(LockState.RELEASING, generateLogSuffixString()));\n       if (lock == null || !lock.isAcquiredInThisProcess()) {\n         return;\n       }\n       lock.release();\n       lock = null;\n-      LOG.info(LockUtils.generateLogStatement(LockState.RELEASED, generateLogSuffixString()));\n+      LOG.info(generateLogStatement(LockState.RELEASED, generateLogSuffixString()));\n     } catch (Exception e) {\n-      throw new HoodieLockException(LockUtils.generateLogStatement(LockState.FAILED_TO_RELEASE, generateLogSuffixString()), e);\n+      throw new HoodieLockException(generateLogStatement(LockState.FAILED_TO_RELEASE, generateLogSuffixString()), e);\n     }\n   }\n \n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nindex 0067e47fb..868f2effa 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -134,7 +133,7 @@ public class ZookeeperBasedLockProvider extends LockProvider {\n       }\n       this.curatorFrameworkClient.close();\n     } catch (Exception e) {\n-      LOG.error(LockUtils.generateLogStatement(LockState.FAILED_TO_RELEASE, generateLogSuffixString()));\n+      LOG.error(generateLogStatement(LockState.FAILED_TO_RELEASE, generateLogSuffixString()));\n     }\n   }\n \n", "next_change": {"commit": "df38dccc1f6c2193479d23ab62f4f24f27908b55", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nindex 868f2effa..3d57e4690 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -137,6 +136,11 @@ public class ZookeeperBasedLockProvider extends LockProvider {\n     }\n   }\n \n+  @Override\n+  public InterProcessMutex getLock() {\n+    return this.lock;\n+  }\n+\n   private void checkRequiredProps(final LockConfiguration config) {\n     ValidationUtils.checkArgument(config.getConfig().getString(ZK_CONNECT_URL_PROP) != null);\n     ValidationUtils.checkArgument(config.getConfig().getString(ZK_BASE_PATH_PROP) != null);\n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nsimilarity index 89%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nindex 3d57e4690..5e7ec67fe 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -141,6 +129,22 @@ public class ZookeeperBasedLockProvider extends LockProvider {\n     return this.lock;\n   }\n \n+  private void acquireLock(long time, TimeUnit unit) throws Exception {\n+    ValidationUtils.checkArgument(this.lock == null, LockState.ALREADY_ACQUIRED.name());\n+    InterProcessMutex newLock = new InterProcessMutex(\n+        this.curatorFrameworkClient, lockConfiguration.getConfig().getString(ZK_BASE_PATH_PROP) + \"/\"\n+        + this.lockConfiguration.getConfig().getString(ZK_LOCK_KEY_PROP));\n+    boolean acquired = newLock.acquire(time, unit);\n+    if (!acquired) {\n+      throw new HoodieLockException(generateLogStatement(LockState.FAILED_TO_ACQUIRE, generateLogSuffixString()));\n+    }\n+    if (newLock.isAcquiredInThisProcess()) {\n+      lock = newLock;\n+    } else {\n+      throw new HoodieLockException(generateLogStatement(LockState.FAILED_TO_ACQUIRE, generateLogSuffixString()));\n+    }\n+  }\n+\n   private void checkRequiredProps(final LockConfiguration config) {\n     ValidationUtils.checkArgument(config.getConfig().getString(ZK_CONNECT_URL_PROP) != null);\n     ValidationUtils.checkArgument(config.getConfig().getString(ZK_BASE_PATH_PROP) != null);\n", "next_change": null}]}}]}}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nindex 94a2b8a4b..0067e47fb 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -132,4 +145,10 @@ public class ZookeeperBasedLockProvider extends LockProvider {\n     ValidationUtils.checkArgument(config.getConfig().getString(ZK_CONNECTION_TIMEOUT_MS_PROP) != null);\n     ValidationUtils.checkArgument(config.getConfig().getString(ZK_LOCK_KEY_PROP) != null);\n   }\n+\n+  private String generateLogSuffixString() {\n+    String zkBasePath = this.lockConfiguration.getConfig().getString(ZK_BASE_PATH_PROP);\n+    String lockKey = this.lockConfiguration.getConfig().getString(ZK_LOCK_KEY_PROP);\n+    return StringUtils.join(\"ZkBasePath = \", zkBasePath, \", lock key = \", lockKey);\n+  }\n }\n", "next_change": {"commit": "df38dccc1f6c2193479d23ab62f4f24f27908b55", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nindex 0067e47fb..3d57e4690 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -134,10 +132,15 @@ public class ZookeeperBasedLockProvider extends LockProvider {\n       }\n       this.curatorFrameworkClient.close();\n     } catch (Exception e) {\n-      LOG.error(LockUtils.generateLogStatement(LockState.FAILED_TO_RELEASE, generateLogSuffixString()));\n+      LOG.error(generateLogStatement(LockState.FAILED_TO_RELEASE, generateLogSuffixString()));\n     }\n   }\n \n+  @Override\n+  public InterProcessMutex getLock() {\n+    return this.lock;\n+  }\n+\n   private void checkRequiredProps(final LockConfiguration config) {\n     ValidationUtils.checkArgument(config.getConfig().getString(ZK_CONNECT_URL_PROP) != null);\n     ValidationUtils.checkArgument(config.getConfig().getString(ZK_BASE_PATH_PROP) != null);\n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nsimilarity index 89%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nindex 3d57e4690..5e7ec67fe 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -141,6 +129,22 @@ public class ZookeeperBasedLockProvider extends LockProvider {\n     return this.lock;\n   }\n \n+  private void acquireLock(long time, TimeUnit unit) throws Exception {\n+    ValidationUtils.checkArgument(this.lock == null, LockState.ALREADY_ACQUIRED.name());\n+    InterProcessMutex newLock = new InterProcessMutex(\n+        this.curatorFrameworkClient, lockConfiguration.getConfig().getString(ZK_BASE_PATH_PROP) + \"/\"\n+        + this.lockConfiguration.getConfig().getString(ZK_LOCK_KEY_PROP));\n+    boolean acquired = newLock.acquire(time, unit);\n+    if (!acquired) {\n+      throw new HoodieLockException(generateLogStatement(LockState.FAILED_TO_ACQUIRE, generateLogSuffixString()));\n+    }\n+    if (newLock.isAcquiredInThisProcess()) {\n+      lock = newLock;\n+    } else {\n+      throw new HoodieLockException(generateLogStatement(LockState.FAILED_TO_ACQUIRE, generateLogSuffixString()));\n+    }\n+  }\n+\n   private void checkRequiredProps(final LockConfiguration config) {\n     ValidationUtils.checkArgument(config.getConfig().getString(ZK_CONNECT_URL_PROP) != null);\n     ValidationUtils.checkArgument(config.getConfig().getString(ZK_BASE_PATH_PROP) != null);\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MzI3Mw==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549553273", "bodyText": "lets drop the HOODIE_ prefix from the properties, per how we have named the configs thus far", "author": "vinothchandar", "createdAt": "2020-12-29T03:16:50Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java", "diffHunk": "@@ -0,0 +1,145 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.config;\n+\n+import org.apache.hudi.client.lock.ConcurrentFileWritesConflictResolutionStrategy;\n+import org.apache.hudi.client.lock.ConflictResolutionStrategy;\n+import org.apache.hudi.client.lock.FileSystemBasedLockProvider;\n+import org.apache.hudi.common.config.DefaultHoodieConfig;\n+import org.apache.hudi.common.lock.LockProvider;\n+\n+import java.io.File;\n+import java.io.FileReader;\n+import java.io.IOException;\n+import java.util.Properties;\n+\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_HOODIE_LOCK_ACQUIRE_NUM_RETRIES;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_HOODIE_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS;\n+import static org.apache.hudi.common.config.LockConfiguration.HIVE_DATABASE_NAME_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.HIVE_TABLE_NAME_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.HOODIE_LOCK_ACQUIRE_NUM_RETRIES_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.HOODIE_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.HOODIE_LOCK_PREFIX;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_BASE_PATH_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECT_URL_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_LOCK_KEY_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_PORT_PROP;\n+\n+/**\n+ * Write callback related config.\n+ */\n+public class HoodieLockConfig extends DefaultHoodieConfig {\n+\n+  // Pluggable type of lock provider\n+  public static final String HOODIE_LOCK_PROVIDER_CLASS_PROP = HOODIE_LOCK_PREFIX + \"provider\";", "originalCommit": "592e4bda9aed9af895b60db0d07393b2a6916d30", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "98c3c7ddf879d514e5c14293fee145c92f9416a3", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\nindex 991d64cb1..4d231b1d2 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\n", "chunk": "@@ -19,7 +19,7 @@ package org.apache.hudi.config;\n \n import org.apache.hudi.client.lock.ConcurrentFileWritesConflictResolutionStrategy;\n import org.apache.hudi.client.lock.ConflictResolutionStrategy;\n-import org.apache.hudi.client.lock.FileSystemBasedLockProvider;\n+import org.apache.hudi.client.lock.ZookeeperBasedLockProvider;\n import org.apache.hudi.common.config.DefaultHoodieConfig;\n import org.apache.hudi.common.lock.LockProvider;\n \n", "next_change": {"commit": "57de565ef4bb6ea4386e80fb20d39eeb8dd96455", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\nindex 4d231b1d2..79bd9e95b 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\n", "chunk": "@@ -17,7 +17,7 @@\n \n package org.apache.hudi.config;\n \n-import org.apache.hudi.client.lock.ConcurrentFileWritesConflictResolutionStrategy;\n+import org.apache.hudi.client.lock.SimpleConcurrentFileWritesConflictResolutionStrategy;\n import org.apache.hudi.client.lock.ConflictResolutionStrategy;\n import org.apache.hudi.client.lock.ZookeeperBasedLockProvider;\n import org.apache.hudi.common.config.DefaultHoodieConfig;\n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\nindex 79bd9e95b..1f0328e2f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\n", "chunk": "@@ -17,9 +17,9 @@\n \n package org.apache.hudi.config;\n \n-import org.apache.hudi.client.lock.SimpleConcurrentFileWritesConflictResolutionStrategy;\n-import org.apache.hudi.client.lock.ConflictResolutionStrategy;\n-import org.apache.hudi.client.lock.ZookeeperBasedLockProvider;\n+import org.apache.hudi.client.transaction.SimpleConcurrentFileWritesConflictResolutionStrategy;\n+import org.apache.hudi.client.transaction.ConflictResolutionStrategy;\n+import org.apache.hudi.client.transaction.lock.ZookeeperBasedLockProvider;\n import org.apache.hudi.common.config.DefaultHoodieConfig;\n import org.apache.hudi.common.lock.LockProvider;\n \n", "next_change": null}]}}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\nindex 991d64cb1..4d231b1d2 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\n", "chunk": "@@ -28,17 +28,24 @@ import java.io.FileReader;\n import java.io.IOException;\n import java.util.Properties;\n \n-import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_HOODIE_LOCK_ACQUIRE_NUM_RETRIES;\n-import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_HOODIE_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_LOCK_ACQUIRE_NUM_RETRIES;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ACQUIRE_LOCK_WAIT_TIMEOUT_MS;\n import static org.apache.hudi.common.config.LockConfiguration.HIVE_DATABASE_NAME_PROP;\n import static org.apache.hudi.common.config.LockConfiguration.HIVE_TABLE_NAME_PROP;\n-import static org.apache.hudi.common.config.LockConfiguration.HOODIE_LOCK_ACQUIRE_NUM_RETRIES_PROP;\n-import static org.apache.hudi.common.config.LockConfiguration.HOODIE_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n-import static org.apache.hudi.common.config.LockConfiguration.HOODIE_LOCK_PREFIX;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_NUM_RETRIES_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_PREFIX;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_WAIT_TIMEOUT_MS_PROP;\n import static org.apache.hudi.common.config.LockConfiguration.ZK_BASE_PATH_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECTION_TIMEOUT_MS_PROP;\n import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECT_URL_PROP;\n import static org.apache.hudi.common.config.LockConfiguration.ZK_LOCK_KEY_PROP;\n import static org.apache.hudi.common.config.LockConfiguration.ZK_PORT_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_CONNECTION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_SESSION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_SESSION_TIMEOUT_MS_PROP;\n+\n \n /**\n  * Write callback related config.\n", "next_change": {"commit": "21792c6722dd32dddbc5b6ec743549610cd9a8e0", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\nindex 4d231b1d2..3be4f19f7 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\n", "chunk": "@@ -28,22 +28,22 @@ import java.io.FileReader;\n import java.io.IOException;\n import java.util.Properties;\n \n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ACQUIRE_LOCK_WAIT_TIMEOUT_MS;\n import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_LOCK_ACQUIRE_NUM_RETRIES;\n import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS;\n-import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ACQUIRE_LOCK_WAIT_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_CONNECTION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_SESSION_TIMEOUT_MS;\n import static org.apache.hudi.common.config.LockConfiguration.HIVE_DATABASE_NAME_PROP;\n import static org.apache.hudi.common.config.LockConfiguration.HIVE_TABLE_NAME_PROP;\n import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_NUM_RETRIES_PROP;\n import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n-import static org.apache.hudi.common.config.LockConfiguration.LOCK_PREFIX;\n import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_WAIT_TIMEOUT_MS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_PREFIX;\n import static org.apache.hudi.common.config.LockConfiguration.ZK_BASE_PATH_PROP;\n import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECTION_TIMEOUT_MS_PROP;\n import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECT_URL_PROP;\n import static org.apache.hudi.common.config.LockConfiguration.ZK_LOCK_KEY_PROP;\n import static org.apache.hudi.common.config.LockConfiguration.ZK_PORT_PROP;\n-import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_CONNECTION_TIMEOUT_MS;\n-import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_SESSION_TIMEOUT_MS;\n import static org.apache.hudi.common.config.LockConfiguration.ZK_SESSION_TIMEOUT_MS_PROP;\n \n \n", "next_change": {"commit": "0552abcc6400675c11ee35a4d4f3df109463f6f5", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\nindex 3be4f19f7..5bac07679 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\n", "chunk": "@@ -48,7 +48,7 @@ import static org.apache.hudi.common.config.LockConfiguration.ZK_SESSION_TIMEOUT\n \n \n /**\n- * Write callback related config.\n+ * Hoodie Configs for Locks.\n  */\n public class HoodieLockConfig extends DefaultHoodieConfig {\n \n", "next_change": null}]}}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\nindex 991d64cb1..4d231b1d2 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\n", "chunk": "@@ -46,12 +53,12 @@ import static org.apache.hudi.common.config.LockConfiguration.ZK_PORT_PROP;\n public class HoodieLockConfig extends DefaultHoodieConfig {\n \n   // Pluggable type of lock provider\n-  public static final String HOODIE_LOCK_PROVIDER_CLASS_PROP = HOODIE_LOCK_PREFIX + \"provider\";\n-  public static final String DEFAULT_HOODIE_LOCK_PROVIDER_CLASS = FileSystemBasedLockProvider.class.getName();\n+  public static final String LOCK_PROVIDER_CLASS_PROP = LOCK_PREFIX + \"provider\";\n+  public static final String DEFAULT_LOCK_PROVIDER_CLASS = ZookeeperBasedLockProvider.class.getName();\n   // Pluggable strategies to use when resolving conflicts\n-  public static final String HOODIE_WRITE_CONFLICT_RESOLUTION_STRATEGY_CLASS_PROP =\n-      HOODIE_LOCK_PREFIX + \"conflict.resolution.strategy\";\n-  public static final String DEFAULT_HOODIE_WRITE_CONFLICT_RESOLUTION_STRATEGY_CLASS =\n+  public static final String WRITE_CONFLICT_RESOLUTION_STRATEGY_CLASS_PROP =\n+      LOCK_PREFIX + \"conflict.resolution.strategy\";\n+  public static final String DEFAULT_WRITE_CONFLICT_RESOLUTION_STRATEGY_CLASS =\n       ConcurrentFileWritesConflictResolutionStrategy.class.getName();\n \n   private HoodieLockConfig(Properties props) {\n", "next_change": {"commit": "57de565ef4bb6ea4386e80fb20d39eeb8dd96455", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\nindex 4d231b1d2..79bd9e95b 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\n", "chunk": "@@ -59,7 +59,7 @@ public class HoodieLockConfig extends DefaultHoodieConfig {\n   public static final String WRITE_CONFLICT_RESOLUTION_STRATEGY_CLASS_PROP =\n       LOCK_PREFIX + \"conflict.resolution.strategy\";\n   public static final String DEFAULT_WRITE_CONFLICT_RESOLUTION_STRATEGY_CLASS =\n-      ConcurrentFileWritesConflictResolutionStrategy.class.getName();\n+      SimpleConcurrentFileWritesConflictResolutionStrategy.class.getName();\n \n   private HoodieLockConfig(Properties props) {\n     super(props);\n", "next_change": null}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\nindex 991d64cb1..4d231b1d2 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\n", "chunk": "@@ -79,7 +86,7 @@ public class HoodieLockConfig extends DefaultHoodieConfig {\n     }\n \n     public HoodieLockConfig.Builder withLockProvider(LockProvider lockProvider) {\n-      props.setProperty(HOODIE_LOCK_PROVIDER_CLASS_PROP, lockProvider.getClass().getName());\n+      props.setProperty(LOCK_PROVIDER_CLASS_PROP, lockProvider.getClass().getName());\n       return this;\n     }\n \n", "next_change": {"commit": "21792c6722dd32dddbc5b6ec743549610cd9a8e0", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\nindex 4d231b1d2..3be4f19f7 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\n", "chunk": "@@ -85,8 +85,8 @@ public class HoodieLockConfig extends DefaultHoodieConfig {\n       return this;\n     }\n \n-    public HoodieLockConfig.Builder withLockProvider(LockProvider lockProvider) {\n-      props.setProperty(LOCK_PROVIDER_CLASS_PROP, lockProvider.getClass().getName());\n+    public HoodieLockConfig.Builder withLockProvider(Class<? extends LockProvider> lockProvider) {\n+      props.setProperty(LOCK_PROVIDER_CLASS_PROP, lockProvider.getName());\n       return this;\n     }\n \n", "next_change": null}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\nindex 991d64cb1..4d231b1d2 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\n", "chunk": "@@ -113,31 +120,52 @@ public class HoodieLockConfig extends DefaultHoodieConfig {\n       return this;\n     }\n \n+    public HoodieLockConfig.Builder withZkConnectionTimeoutInMs(Long connectionTimeoutInMs) {\n+      props.setProperty(ZK_CONNECTION_TIMEOUT_MS_PROP, String.valueOf(connectionTimeoutInMs));\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withZkSessionTimeoutInMs(Long sessionTimeoutInMs) {\n+      props.setProperty(ZK_SESSION_TIMEOUT_MS_PROP, String.valueOf(sessionTimeoutInMs));\n+      return this;\n+    }\n+\n     public HoodieLockConfig.Builder withNumRetries(int numRetries) {\n-      props.setProperty(HOODIE_LOCK_ACQUIRE_NUM_RETRIES_PROP, String.valueOf(numRetries));\n+      props.setProperty(LOCK_ACQUIRE_NUM_RETRIES_PROP, String.valueOf(numRetries));\n       return this;\n     }\n \n     public HoodieLockConfig.Builder withRetryWaitTimeInMillis(Long retryWaitTimeInMillis) {\n-      props.setProperty(HOODIE_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP, String.valueOf(retryWaitTimeInMillis));\n+      props.setProperty(LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP, String.valueOf(retryWaitTimeInMillis));\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withLockWaitTimeInMillis(Long waitTimeInMillis) {\n+      props.setProperty(LOCK_ACQUIRE_WAIT_TIMEOUT_MS_PROP, String.valueOf(waitTimeInMillis));\n       return this;\n     }\n \n     public HoodieLockConfig.Builder withConflictResolutionStrategy(ConflictResolutionStrategy conflictResolutionStrategy) {\n-      props.setProperty(HOODIE_WRITE_CONFLICT_RESOLUTION_STRATEGY_CLASS_PROP, conflictResolutionStrategy.getClass().getName());\n+      props.setProperty(WRITE_CONFLICT_RESOLUTION_STRATEGY_CLASS_PROP, conflictResolutionStrategy.getClass().getName());\n       return this;\n     }\n \n     public HoodieLockConfig build() {\n       HoodieLockConfig config = new HoodieLockConfig(props);\n-      setDefaultOnCondition(props, !props.containsKey(HOODIE_LOCK_PROVIDER_CLASS_PROP),\n-          HOODIE_LOCK_PROVIDER_CLASS_PROP, DEFAULT_HOODIE_LOCK_PROVIDER_CLASS);\n-      setDefaultOnCondition(props, !props.containsKey(HOODIE_WRITE_CONFLICT_RESOLUTION_STRATEGY_CLASS_PROP),\n-          HOODIE_WRITE_CONFLICT_RESOLUTION_STRATEGY_CLASS_PROP, DEFAULT_HOODIE_WRITE_CONFLICT_RESOLUTION_STRATEGY_CLASS);\n-      setDefaultOnCondition(props, !props.containsKey(HOODIE_LOCK_ACQUIRE_NUM_RETRIES_PROP),\n-          HOODIE_LOCK_ACQUIRE_NUM_RETRIES_PROP, DEFAULT_HOODIE_LOCK_ACQUIRE_NUM_RETRIES);\n-      setDefaultOnCondition(props, !props.containsKey(HOODIE_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP),\n-          HOODIE_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP, DEFAULT_HOODIE_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS);\n+      setDefaultOnCondition(props, !props.containsKey(LOCK_PROVIDER_CLASS_PROP),\n+          LOCK_PROVIDER_CLASS_PROP, DEFAULT_LOCK_PROVIDER_CLASS);\n+      setDefaultOnCondition(props, !props.containsKey(WRITE_CONFLICT_RESOLUTION_STRATEGY_CLASS_PROP),\n+          WRITE_CONFLICT_RESOLUTION_STRATEGY_CLASS_PROP, DEFAULT_WRITE_CONFLICT_RESOLUTION_STRATEGY_CLASS);\n+      setDefaultOnCondition(props, !props.containsKey(LOCK_ACQUIRE_NUM_RETRIES_PROP),\n+          LOCK_ACQUIRE_NUM_RETRIES_PROP, DEFAULT_LOCK_ACQUIRE_NUM_RETRIES);\n+      setDefaultOnCondition(props, !props.containsKey(LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP),\n+          LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP, DEFAULT_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS);\n+      setDefaultOnCondition(props, !props.containsKey(ZK_CONNECTION_TIMEOUT_MS_PROP),\n+          ZK_CONNECTION_TIMEOUT_MS_PROP, String.valueOf(DEFAULT_ZK_CONNECTION_TIMEOUT_MS));\n+      setDefaultOnCondition(props, !props.containsKey(ZK_SESSION_TIMEOUT_MS_PROP),\n+          ZK_SESSION_TIMEOUT_MS_PROP, String.valueOf(DEFAULT_ZK_SESSION_TIMEOUT_MS));\n+      setDefaultOnCondition(props, !props.containsKey(LOCK_ACQUIRE_WAIT_TIMEOUT_MS_PROP),\n+          LOCK_ACQUIRE_WAIT_TIMEOUT_MS_PROP, String.valueOf(DEFAULT_ACQUIRE_LOCK_WAIT_TIMEOUT_MS));\n       return config;\n     }\n   }\n", "next_change": {"commit": "df38dccc1f6c2193479d23ab62f4f24f27908b55", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\nindex 4d231b1d2..4ddf149f3 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\n", "chunk": "@@ -140,6 +144,16 @@ public class HoodieLockConfig extends DefaultHoodieConfig {\n       return this;\n     }\n \n+    public HoodieLockConfig.Builder withClientNumRetries(int clientNumRetries) {\n+      props.setProperty(LOCK_ACQUIRE_CLIENT_NUM_RETRIES_PROP, String.valueOf(clientNumRetries));\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withClientRetryWaitTimeInMillis(Long clientRetryWaitTimeInMillis) {\n+      props.setProperty(LOCK_ACQUIRE_CLIENT_RETRY_WAIT_TIME_IN_MILLIS_PROP, String.valueOf(clientRetryWaitTimeInMillis));\n+      return this;\n+    }\n+\n     public HoodieLockConfig.Builder withLockWaitTimeInMillis(Long waitTimeInMillis) {\n       props.setProperty(LOCK_ACQUIRE_WAIT_TIMEOUT_MS_PROP, String.valueOf(waitTimeInMillis));\n       return this;\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\nindex 4d231b1d2..4ddf149f3 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\n", "chunk": "@@ -160,6 +174,10 @@ public class HoodieLockConfig extends DefaultHoodieConfig {\n           LOCK_ACQUIRE_NUM_RETRIES_PROP, DEFAULT_LOCK_ACQUIRE_NUM_RETRIES);\n       setDefaultOnCondition(props, !props.containsKey(LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP),\n           LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP, DEFAULT_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS);\n+      setDefaultOnCondition(props, !props.containsKey(LOCK_ACQUIRE_CLIENT_NUM_RETRIES_PROP),\n+          LOCK_ACQUIRE_CLIENT_NUM_RETRIES_PROP, DEFAULT_LOCK_ACQUIRE_CLIENT_NUM_RETRIES);\n+      setDefaultOnCondition(props, !props.containsKey(LOCK_ACQUIRE_CLIENT_RETRY_WAIT_TIME_IN_MILLIS_PROP),\n+          LOCK_ACQUIRE_CLIENT_RETRY_WAIT_TIME_IN_MILLIS_PROP, DEFAULT_LOCK_ACQUIRE_CLIENT_RETRY_WAIT_TIME_IN_MILLIS);\n       setDefaultOnCondition(props, !props.containsKey(ZK_CONNECTION_TIMEOUT_MS_PROP),\n           ZK_CONNECTION_TIMEOUT_MS_PROP, String.valueOf(DEFAULT_ZK_CONNECTION_TIMEOUT_MS));\n       setDefaultOnCondition(props, !props.containsKey(ZK_SESSION_TIMEOUT_MS_PROP),\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MzM2Ng==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549553366", "bodyText": "repeating my earlier comment; lets just use the concurrency mode config from the other PR .", "author": "vinothchandar", "createdAt": "2020-12-29T03:17:26Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java", "diffHunk": "@@ -122,6 +123,10 @@\n   private static final String MERGE_DATA_VALIDATION_CHECK_ENABLED = \"hoodie.merge.data.validation.enabled\";\n   private static final String DEFAULT_MERGE_DATA_VALIDATION_CHECK_ENABLED = \"false\";\n \n+  // Enable multi writer support\n+  private static final String HOODIE_TABLE_MULTIWRITER_ENABLED_PROP = \"hoodie.table.multiwriter.enabled\";", "originalCommit": "592e4bda9aed9af895b60db0d07393b2a6916d30", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDkzNTQ2OQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r550935469", "bodyText": "Responded earlier", "author": "n3nash", "createdAt": "2021-01-03T00:05:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MzM2Ng=="}], "type": "inlineReview", "revised_code": {"commit": "7f975c1dbae58d16c244968b2d7ebaae5f3f99ac", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\nindex b83811271..419893547 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\n", "chunk": "@@ -123,9 +136,13 @@ public class HoodieWriteConfig extends DefaultHoodieConfig {\n   private static final String MERGE_DATA_VALIDATION_CHECK_ENABLED = \"hoodie.merge.data.validation.enabled\";\n   private static final String DEFAULT_MERGE_DATA_VALIDATION_CHECK_ENABLED = \"false\";\n \n-  // Enable multi writer support\n-  private static final String HOODIE_TABLE_MULTIWRITER_ENABLED_PROP = \"hoodie.table.multiwriter.enabled\";\n-  private static final String DEFAULT_HOODIE_TABLE_MULTIWRITER_ENABLED = \"false\";\n+  // Enable different concurrency support\n+  public static final String WRITE_CONCURRENCY_MODE_PROP =\n+      \"write.concurrency.mode\";\n+  public static final String DEFAULT_WRITE_CONCURRENCY_MODE = WriteConcurrencyMode.SINGLE_WRITER.name();\n+\n+  private static final String TABLE_SERVICES_ENABLED_PROP = \"table.services.enabled\";\n+  private static final String DEFAULT_TABLE_SERVICES_ENABLED = \"true\";\n \n   /**\n    * HUDI-858 : There are users who had been directly using RDD APIs and have relied on a behavior in 0.4.x to allow\n", "next_change": {"commit": "57de565ef4bb6ea4386e80fb20d39eeb8dd96455", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\nindex 419893547..eefd79868 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\n", "chunk": "@@ -141,9 +141,6 @@ public class HoodieWriteConfig extends DefaultHoodieConfig {\n       \"write.concurrency.mode\";\n   public static final String DEFAULT_WRITE_CONCURRENCY_MODE = WriteConcurrencyMode.SINGLE_WRITER.name();\n \n-  private static final String TABLE_SERVICES_ENABLED_PROP = \"table.services.enabled\";\n-  private static final String DEFAULT_TABLE_SERVICES_ENABLED = \"true\";\n-\n   /**\n    * HUDI-858 : There are users who had been directly using RDD APIs and have relied on a behavior in 0.4.x to allow\n    * multiple write operations (upsert/buk-insert/...) to be executed within a single commit.\n", "next_change": {"commit": "340efd27821ca9bfeac3bcf3f2cc616948440e2f", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\nindex eefd79868..004c89809 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\n", "chunk": "@@ -136,6 +134,10 @@ public class HoodieWriteConfig extends DefaultHoodieConfig {\n   private static final String MERGE_DATA_VALIDATION_CHECK_ENABLED = \"hoodie.merge.data.validation.enabled\";\n   private static final String DEFAULT_MERGE_DATA_VALIDATION_CHECK_ENABLED = \"false\";\n \n+  // Allow duplicates with inserts while merging with existing records\n+  private static final String MERGE_ALLOW_DUPLICATE_ON_INSERTS = \"hoodie.merge.allow.duplicate.on.inserts\";\n+  private static final String DEFAULT_MERGE_ALLOW_DUPLICATE_ON_INSERTS = \"false\";\n+\n   // Enable different concurrency support\n   public static final String WRITE_CONCURRENCY_MODE_PROP =\n       \"write.concurrency.mode\";\n", "next_change": {"commit": "289e45a28da6b91fba2a824ec2af3771a34b2930", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\nindex 004c89809..f48beaa80 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\n", "chunk": "@@ -138,6 +141,11 @@ public class HoodieWriteConfig extends DefaultHoodieConfig {\n   private static final String MERGE_ALLOW_DUPLICATE_ON_INSERTS = \"hoodie.merge.allow.duplicate.on.inserts\";\n   private static final String DEFAULT_MERGE_ALLOW_DUPLICATE_ON_INSERTS = \"false\";\n \n+  public static final String CLIENT_HEARTBEAT_INTERVAL_IN_MS_PROP = \"hoodie.client.heartbeat.interval_in_ms\";\n+  public static final Integer DEFAULT_CLIENT_HEARTBEAT_INTERVAL_IN_MS = 60 * 1000;\n+\n+  public static final String CLIENT_HEARTBEAT_NUM_TOLERABLE_MISSES_PROP = \"hoodie.client.heartbeat.tolerable.misses\";\n+  public static final Integer DEFAULT_CLIENT_HEARTBEAT_NUM_TOLERABLE_MISSES = 2;\n   // Enable different concurrency support\n   public static final String WRITE_CONCURRENCY_MODE_PROP =\n       \"write.concurrency.mode\";\n", "next_change": {"commit": "1b41b773c6bb94ac28609bf829e875cefce6e5d3", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\nindex f48beaa80..62c79649c 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\n", "chunk": "@@ -148,7 +154,7 @@ public class HoodieWriteConfig extends DefaultHoodieConfig {\n   public static final Integer DEFAULT_CLIENT_HEARTBEAT_NUM_TOLERABLE_MISSES = 2;\n   // Enable different concurrency support\n   public static final String WRITE_CONCURRENCY_MODE_PROP =\n-      \"write.concurrency.mode\";\n+      \"hoodie.write.concurrency.mode\";\n   public static final String DEFAULT_WRITE_CONCURRENCY_MODE = WriteConcurrencyMode.SINGLE_WRITER.name();\n \n   /**\n", "next_change": {"commit": "1886bbd803f1a51e3d261705dd1283cfa8caf06b", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\nindex 62c79649c..944cd0230 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\n", "chunk": "@@ -157,6 +157,11 @@ public class HoodieWriteConfig extends DefaultHoodieConfig {\n       \"hoodie.write.concurrency.mode\";\n   public static final String DEFAULT_WRITE_CONCURRENCY_MODE = WriteConcurrencyMode.SINGLE_WRITER.name();\n \n+  // Comma separated metadata key prefixes to override from latest commit during overlapping commits via multi writing\n+  public static final String WRITE_META_KEY_PREFIXES_PROP =\n+      \"hoodie.write.meta.key.prefixes\";\n+  public static final String DEFAULT_WRITE_META_KEY_PREFIXES = \"\";\n+\n   /**\n    * HUDI-858 : There are users who had been directly using RDD APIs and have relied on a behavior in 0.4.x to allow\n    * multiple write operations (upsert/buk-insert/...) to be executed within a single commit.\n", "next_change": {"commit": "461047d03e9b7b73b34536ccf290a24f4aada6b0", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\nindex 944cd0230..f7ad3a0fa 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\n", "chunk": "@@ -157,11 +157,6 @@ public class HoodieWriteConfig extends DefaultHoodieConfig {\n       \"hoodie.write.concurrency.mode\";\n   public static final String DEFAULT_WRITE_CONCURRENCY_MODE = WriteConcurrencyMode.SINGLE_WRITER.name();\n \n-  // Comma separated metadata key prefixes to override from latest commit during overlapping commits via multi writing\n-  public static final String WRITE_META_KEY_PREFIXES_PROP =\n-      \"hoodie.write.meta.key.prefixes\";\n-  public static final String DEFAULT_WRITE_META_KEY_PREFIXES = \"\";\n-\n   /**\n    * HUDI-858 : There are users who had been directly using RDD APIs and have relied on a behavior in 0.4.x to allow\n    * multiple write operations (upsert/buk-insert/...) to be executed within a single commit.\n", "next_change": {"commit": "a466320b7537bf2862df853344e80fbd0be6d16a", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\nindex f7ad3a0fa..944cd0230 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\n", "chunk": "@@ -157,6 +157,11 @@ public class HoodieWriteConfig extends DefaultHoodieConfig {\n       \"hoodie.write.concurrency.mode\";\n   public static final String DEFAULT_WRITE_CONCURRENCY_MODE = WriteConcurrencyMode.SINGLE_WRITER.name();\n \n+  // Comma separated metadata key prefixes to override from latest commit during overlapping commits via multi writing\n+  public static final String WRITE_META_KEY_PREFIXES_PROP =\n+      \"hoodie.write.meta.key.prefixes\";\n+  public static final String DEFAULT_WRITE_META_KEY_PREFIXES = \"\";\n+\n   /**\n    * HUDI-858 : There are users who had been directly using RDD APIs and have relied on a behavior in 0.4.x to allow\n    * multiple write operations (upsert/buk-insert/...) to be executed within a single commit.\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MzU2MA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549553560", "bodyText": "so, I was expecting we will do some kind of atomic swap, not just a set. if you just want to set, even a volatile variable is fine right?", "author": "vinothchandar", "createdAt": "2020-12-29T03:18:41Z", "path": "hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java", "diffHunk": "@@ -385,6 +386,10 @@ protected void completeClustering(HoodieReplaceCommitMetadata metadata, JavaRDD<\n     } else {\n       writeTimer = metrics.getDeltaCommitCtx();\n     }\n+    latestWriteInstantCompletedBeforeWriter.set(table.getMetaClient().getActiveTimeline().getAllCommitsTimeline()", "originalCommit": "592e4bda9aed9af895b60db0d07393b2a6916d30", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDkzNTUyNA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r550935524", "bodyText": "That was the intention, missed this, fixed now", "author": "n3nash", "createdAt": "2021-01-03T00:06:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MzU2MA=="}], "type": "inlineReview", "revised_code": {"commit": "98c3c7ddf879d514e5c14293fee145c92f9416a3", "changed_code": [{"header": "diff --git a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\nindex d9a36fb4e..6f156ab34 100644\n--- a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n+++ b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n", "chunk": "@@ -386,7 +393,7 @@ public class SparkRDDWriteClient<T extends HoodieRecordPayload> extends\n     } else {\n       writeTimer = metrics.getDeltaCommitCtx();\n     }\n-    latestWriteInstantCompletedBeforeWriter.set(table.getMetaClient().getActiveTimeline().getAllCommitsTimeline()\n+    latestWriteInstantCompletedBeforeWriter.compareAndSet(null, table.getMetaClient().getActiveTimeline().getAllCommitsTimeline()\n         .getCommitsAndCompactionTimeline().filterCompletedInstants().lastInstant());\n     LOG.info(\"Last Instant Cached by writer with instant \" + instantTime + \" is \"\n         + latestWriteInstantCompletedBeforeWriter.get());\n", "next_change": {"commit": "d81016bdc87968e58e1fcd8809b65000b1a64ff5", "changed_code": [{"header": "diff --git a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\nindex 6f156ab34..9e5579d77 100644\n--- a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n+++ b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n", "chunk": "@@ -399,4 +404,34 @@ public class SparkRDDWriteClient<T extends HoodieRecordPayload> extends\n         + latestWriteInstantCompletedBeforeWriter.get());\n     return table;\n   }\n+\n+  @Override\n+  public void syncTableMetadata() {\n+    // Open up the metadata table again, for syncing\n+    SparkHoodieBackedTableMetadataWriter.create(hadoopConf, config, context);\n+  }\n+\n+  @Override\n+  protected void initWrapperFSMetrics() {\n+    if (config.isMetricsOn()) {\n+      Registry registry;\n+      Registry registryMeta;\n+      JavaSparkContext jsc = ((HoodieSparkEngineContext) context).getJavaSparkContext();\n+\n+      if (config.isExecutorMetricsEnabled()) {\n+        // Create a distributed registry for HoodieWrapperFileSystem\n+        registry = Registry.getRegistry(HoodieWrapperFileSystem.class.getSimpleName(),\n+            DistributedRegistry.class.getName());\n+        ((DistributedRegistry)registry).register(jsc);\n+        registryMeta = Registry.getRegistry(HoodieWrapperFileSystem.class.getSimpleName() + \"MetaFolder\",\n+            DistributedRegistry.class.getName());\n+        ((DistributedRegistry)registryMeta).register(jsc);\n+      } else {\n+        registry = Registry.getRegistry(HoodieWrapperFileSystem.class.getSimpleName());\n+        registryMeta = Registry.getRegistry(HoodieWrapperFileSystem.class.getSimpleName() + \"MetaFolder\");\n+      }\n+\n+      HoodieWrapperFileSystem.setMetricsRegistry(registry, registryMeta);\n+    }\n+  }\n }\n", "next_change": {"commit": "7f975c1dbae58d16c244968b2d7ebaae5f3f99ac", "changed_code": [{"header": "diff --git a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\nindex 9e5579d77..13ac1f49a 100644\n--- a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n+++ b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n", "chunk": "@@ -407,8 +411,10 @@ public class SparkRDDWriteClient<T extends HoodieRecordPayload> extends\n \n   @Override\n   public void syncTableMetadata() {\n+    // TODO : LOCK here\n     // Open up the metadata table again, for syncing\n     SparkHoodieBackedTableMetadataWriter.create(hadoopConf, config, context);\n+    // TODO : Unlock here\n   }\n \n   @Override\n", "next_change": {"commit": "57de565ef4bb6ea4386e80fb20d39eeb8dd96455", "changed_code": [{"header": "diff --git a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\nindex 13ac1f49a..5841bbbab 100644\n--- a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n+++ b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n", "chunk": "@@ -402,19 +408,17 @@ public class SparkRDDWriteClient<T extends HoodieRecordPayload> extends\n     } else {\n       writeTimer = metrics.getDeltaCommitCtx();\n     }\n-    latestWriteInstantCompletedBeforeWriter.compareAndSet(null, table.getMetaClient().getActiveTimeline().getAllCommitsTimeline()\n+    latestCompletedWriteInstant.compareAndSet(null, table.getMetaClient().getActiveTimeline().getAllCommitsTimeline()\n         .getCommitsAndCompactionTimeline().filterCompletedInstants().lastInstant());\n     LOG.info(\"Last Instant Cached by writer with instant \" + instantTime + \" is \"\n-        + latestWriteInstantCompletedBeforeWriter.get());\n+        + latestCompletedWriteInstant.get());\n     return table;\n   }\n \n   @Override\n-  public void syncTableMetadata() {\n-    // TODO : LOCK here\n+  public void syncTableMetadata(boolean bootstrapIfNeeded) {\n     // Open up the metadata table again, for syncing\n-    SparkHoodieBackedTableMetadataWriter.create(hadoopConf, config, context);\n-    // TODO : Unlock here\n+    SparkHoodieBackedTableMetadataWriter.create(hadoopConf, config, context, bootstrapIfNeeded);\n   }\n \n   @Override\n", "next_change": {"commit": "97180d4ab0c6c988aa95ac566f63d249dbdbb2dd", "changed_code": [{"header": "diff --git a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\nindex 5841bbbab..2f61c0bbc 100644\n--- a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n+++ b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n", "chunk": "@@ -418,7 +412,12 @@ public class SparkRDDWriteClient<T extends HoodieRecordPayload> extends\n   @Override\n   public void syncTableMetadata(boolean bootstrapIfNeeded) {\n     // Open up the metadata table again, for syncing\n-    SparkHoodieBackedTableMetadataWriter.create(hadoopConf, config, context, bootstrapIfNeeded);\n+    try (HoodieTableMetadataWriter writer =\n+             SparkHoodieBackedTableMetadataWriter.create(hadoopConf, config, context, bootstrapIfNeeded)) {\n+      LOG.info(\"Successfully synced to metadata table\");\n+    } catch (Exception e) {\n+      throw new HoodieMetadataException(\"Error syncing to metadata table.\", e);\n+    }\n   }\n \n   @Override\n", "next_change": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\nindex 2f61c0bbc..1f955a1a9 100644\n--- a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n+++ b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n", "chunk": "@@ -402,18 +447,22 @@ public class SparkRDDWriteClient<T extends HoodieRecordPayload> extends\n     } else {\n       writeTimer = metrics.getDeltaCommitCtx();\n     }\n-    latestCompletedWriteInstant.compareAndSet(null, table.getMetaClient().getActiveTimeline().getAllCommitsTimeline()\n-        .getCommitsAndCompactionTimeline().filterCompletedInstants().lastInstant());\n+    this.txnManager.setLastCompletedTransaction(getLastCompletedCommit());\n     LOG.info(\"Last Instant Cached by writer with instant \" + instantTime + \" is \"\n-        + latestCompletedWriteInstant.get());\n+        + this.txnManager.getLastCompletedTransaction());\n     return table;\n   }\n \n+  private Option<HoodieInstant> getLastCompletedCommit() {\n+    return createMetaClient(true).getActiveTimeline().getAllCommitsTimeline()\n+        .getCommitsAndCompactionTimeline().filterCompletedInstants().lastInstant();\n+  }\n+\n   @Override\n-  public void syncTableMetadata(boolean bootstrapIfNeeded) {\n+  public void syncTableMetadata(boolean bootstrapMetadata) {\n     // Open up the metadata table again, for syncing\n     try (HoodieTableMetadataWriter writer =\n-             SparkHoodieBackedTableMetadataWriter.create(hadoopConf, config, context, bootstrapIfNeeded)) {\n+             SparkHoodieBackedTableMetadataWriter.create(hadoopConf, config, context, bootstrapMetadata)) {\n       LOG.info(\"Successfully synced to metadata table\");\n     } catch (Exception e) {\n       throw new HoodieMetadataException(\"Error syncing to metadata table.\", e);\n", "next_change": {"commit": "f5a56cb4137b5f32af17405277c29d5a9088b6c7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\nindex 1f955a1a9..a63e08b59 100644\n--- a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n+++ b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n", "chunk": "@@ -469,6 +457,16 @@ public class SparkRDDWriteClient<T extends HoodieRecordPayload> extends\n     }\n   }\n \n+  @Override\n+  protected void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n+    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n+    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n+    HoodieTable table = createTable(config, hadoopConf);\n+    HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n+    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), this.txnManager.getCurrentTxnInstant(),\n+        metadata, config, txnManager.getLastCompletedTransaction());\n+  }\n+\n   @Override\n   protected void initWrapperFSMetrics() {\n     if (config.isMetricsOn()) {\n", "next_change": {"commit": "49dec09bfb444866e678fe956b28c3bf0ad2f373", "changed_code": [{"header": "diff --git a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\nindex a63e08b59..40b809a9d 100644\n--- a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n+++ b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n", "chunk": "@@ -449,8 +449,9 @@ public class SparkRDDWriteClient<T extends HoodieRecordPayload> extends\n   @Override\n   public void syncTableMetadata(boolean bootstrapMetadata) {\n     // Open up the metadata table again, for syncing\n-    try (HoodieTableMetadataWriter writer =\n-             SparkHoodieBackedTableMetadataWriter.create(hadoopConf, config, context, bootstrapMetadata)) {\n+    try {\n+      HoodieTableMetadataWriter writer =\n+          SparkHoodieBackedTableMetadataWriter.create(hadoopConf, config, context, bootstrapMetadata);\n       LOG.info(\"Successfully synced to metadata table\");\n     } catch (Exception e) {\n       throw new HoodieMetadataException(\"Error syncing to metadata table.\", e);\n", "next_change": {"commit": "8f2bd5f5539fa72267c4c73c03068e9384df646f", "changed_code": [{"header": "diff --git a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\nindex 40b809a9d..565b30c8f 100644\n--- a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n+++ b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n", "chunk": "@@ -435,17 +431,9 @@ public class SparkRDDWriteClient<T extends HoodieRecordPayload> extends\n     } else {\n       writeTimer = metrics.getDeltaCommitCtx();\n     }\n-    this.txnManager.setLastCompletedTransaction(getLastCompletedCommit());\n-    LOG.info(\"Last Instant Cached by writer with instant \" + instantTime + \" is \"\n-        + this.txnManager.getLastCompletedTransactionOwner());\n     return table;\n   }\n \n-  private Option<HoodieInstant> getLastCompletedCommit() {\n-    return createMetaClient(true).getActiveTimeline().getAllCommitsTimeline()\n-        .getCommitsAndCompactionTimeline().filterCompletedInstants().lastInstant();\n-  }\n-\n   @Override\n   public void syncTableMetadata(boolean bootstrapMetadata) {\n     // Open up the metadata table again, for syncing\n", "next_change": {"commit": "0552abcc6400675c11ee35a4d4f3df109463f6f5", "changed_code": [{"header": "diff --git a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\nindex 565b30c8f..4ca792cff 100644\n--- a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n+++ b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n", "chunk": "@@ -435,11 +435,11 @@ public class SparkRDDWriteClient<T extends HoodieRecordPayload> extends\n   }\n \n   @Override\n-  public void syncTableMetadata(boolean bootstrapMetadata) {\n+  public void syncTableMetadata() {\n     // Open up the metadata table again, for syncing\n     try {\n       HoodieTableMetadataWriter writer =\n-          SparkHoodieBackedTableMetadataWriter.create(hadoopConf, config, context, bootstrapMetadata);\n+          SparkHoodieBackedTableMetadataWriter.create(hadoopConf, config, context);\n       LOG.info(\"Successfully synced to metadata table\");\n     } catch (Exception e) {\n       throw new HoodieMetadataException(\"Error syncing to metadata table.\", e);\n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\nindex 4ca792cff..c68543f1c 100644\n--- a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n+++ b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n", "chunk": "@@ -437,9 +448,7 @@ public class SparkRDDWriteClient<T extends HoodieRecordPayload> extends\n   @Override\n   public void syncTableMetadata() {\n     // Open up the metadata table again, for syncing\n-    try {\n-      HoodieTableMetadataWriter writer =\n-          SparkHoodieBackedTableMetadataWriter.create(hadoopConf, config, context);\n+    try(HoodieTableMetadataWriter writer = SparkHoodieBackedTableMetadataWriter.create(hadoopConf, config, context)) {\n       LOG.info(\"Successfully synced to metadata table\");\n     } catch (Exception e) {\n       throw new HoodieMetadataException(\"Error syncing to metadata table.\", e);\n", "next_change": {"commit": "630f1410aadd947d3f2c9fa0d6a4f69cd67e1c4f", "changed_code": [{"header": "diff --git a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\nindex c68543f1c..255d5d538 100644\n--- a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n+++ b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n", "chunk": "@@ -448,7 +448,7 @@ public class SparkRDDWriteClient<T extends HoodieRecordPayload> extends\n   @Override\n   public void syncTableMetadata() {\n     // Open up the metadata table again, for syncing\n-    try(HoodieTableMetadataWriter writer = SparkHoodieBackedTableMetadataWriter.create(hadoopConf, config, context)) {\n+    try (HoodieTableMetadataWriter writer = SparkHoodieBackedTableMetadataWriter.create(hadoopConf, config, context)) {\n       LOG.info(\"Successfully synced to metadata table\");\n     } catch (Exception e) {\n       throw new HoodieMetadataException(\"Error syncing to metadata table.\", e);\n", "next_change": null}]}}]}}]}}]}}, {"header": "diff --git a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\nindex a63e08b59..40b809a9d 100644\n--- a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n+++ b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n", "chunk": "@@ -464,7 +465,7 @@ public class SparkRDDWriteClient<T extends HoodieRecordPayload> extends\n     HoodieTable table = createTable(config, hadoopConf);\n     HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n     TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), this.txnManager.getCurrentTxnInstant(),\n-        metadata, config, txnManager.getLastCompletedTransaction());\n+        Option.of(metadata), config, txnManager.getLastCompletedTransactionOwner());\n   }\n \n   @Override\n", "next_change": {"commit": "8f2bd5f5539fa72267c4c73c03068e9384df646f", "changed_code": [{"header": "diff --git a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\nindex 40b809a9d..565b30c8f 100644\n--- a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n+++ b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n", "chunk": "@@ -464,7 +452,7 @@ public class SparkRDDWriteClient<T extends HoodieRecordPayload> extends\n     // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n     HoodieTable table = createTable(config, hadoopConf);\n     HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), this.txnManager.getCurrentTxnInstant(),\n+    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), this.txnManager.getCurrentTransactionOwner().get(),\n         Option.of(metadata), config, txnManager.getLastCompletedTransactionOwner());\n   }\n \n", "next_change": {"commit": "9d857ed63bba87ec2528eb26bae1e69216814bdd", "changed_code": [{"header": "diff --git a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\nindex 565b30c8f..8bcf51db7 100644\n--- a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n+++ b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n", "chunk": "@@ -452,7 +452,7 @@ public class SparkRDDWriteClient<T extends HoodieRecordPayload> extends\n     // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n     HoodieTable table = createTable(config, hadoopConf);\n     HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), this.txnManager.getCurrentTransactionOwner().get(),\n+    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), this.txnManager.getCurrentTransactionOwner(),\n         Option.of(metadata), config, txnManager.getLastCompletedTransactionOwner());\n   }\n \n", "next_change": {"commit": "02efbb661e7ed13c3614ddee7ab5157623070f7c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\nindex 8bcf51db7..8a0eee59a 100644\n--- a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n+++ b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n", "chunk": "@@ -451,8 +453,7 @@ public class SparkRDDWriteClient<T extends HoodieRecordPayload> extends\n     // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n     // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n     HoodieTable table = createTable(config, hadoopConf);\n-    HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-    TransactionUtils.resolveWriteConflictIfAny(table, Option.of(metadataWriter), this.txnManager.getCurrentTransactionOwner(),\n+    TransactionUtils.resolveWriteConflictIfAny(table, this.txnManager.getCurrentTransactionOwner(),\n         Option.of(metadata), config, txnManager.getLastCompletedTransactionOwner());\n   }\n \n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MzYyMg==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549553622", "bodyText": "why is this relevant here?", "author": "vinothchandar", "createdAt": "2020-12-29T03:19:07Z", "path": "hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/table/action/cluster/SparkExecuteClusteringCommitActionExecutor.java", "diffHunk": "@@ -118,7 +118,7 @@ public SparkExecuteClusteringCommitActionExecutor(HoodieEngineContext context,\n       Schema readerSchema = HoodieAvroUtils.addMetadataFields(new Schema.Parser().parse(config.getSchema()));\n       return ((ClusteringExecutionStrategy<T, JavaRDD<HoodieRecord<? extends HoodieRecordPayload>>, JavaRDD<HoodieKey>, JavaRDD<WriteStatus>>)\n           ReflectionUtils.loadClass(config.getClusteringExecutionStrategyClass(), table, context, config))\n-          .performClustering(inputRecords, clusteringGroup.getNumOutputFileGroups(), instantTime, strategyParams, readerSchema);\n+          .performClustering(inputRecords, 0, instantTime, strategyParams, readerSchema);", "originalCommit": "592e4bda9aed9af895b60db0d07393b2a6916d30", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDk3MjI1NQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r550972255", "bodyText": "The build was failing and not able to find this because I probably hadn't built the avro classes, so these changes were just a workaround, they have been reverted now.", "author": "n3nash", "createdAt": "2021-01-03T08:09:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MzYyMg=="}], "type": "inlineReview", "revised_code": {"commit": "98c3c7ddf879d514e5c14293fee145c92f9416a3", "changed_code": [{"header": "diff --git a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/table/action/cluster/SparkExecuteClusteringCommitActionExecutor.java b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/table/action/cluster/SparkExecuteClusteringCommitActionExecutor.java\nindex bf6c9835e..a8044edcf 100644\n--- a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/table/action/cluster/SparkExecuteClusteringCommitActionExecutor.java\n+++ b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/table/action/cluster/SparkExecuteClusteringCommitActionExecutor.java\n", "chunk": "@@ -118,7 +118,7 @@ public class SparkExecuteClusteringCommitActionExecutor<T extends HoodieRecordPa\n       Schema readerSchema = HoodieAvroUtils.addMetadataFields(new Schema.Parser().parse(config.getSchema()));\n       return ((ClusteringExecutionStrategy<T, JavaRDD<HoodieRecord<? extends HoodieRecordPayload>>, JavaRDD<HoodieKey>, JavaRDD<WriteStatus>>)\n           ReflectionUtils.loadClass(config.getClusteringExecutionStrategyClass(), table, context, config))\n-          .performClustering(inputRecords, 0, instantTime, strategyParams, readerSchema);\n+          .performClustering(inputRecords, clusteringGroup.getNumOutputFileGroups(), instantTime, strategyParams, readerSchema);\n     });\n \n     return writeStatusesFuture;\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1Mzc1Mw==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549553753", "bodyText": "lets add a new test around the multi writing please. it should ideally be agnostic of COW/MOR. and we can just test MOR.", "author": "vinothchandar", "createdAt": "2020-12-29T03:20:06Z", "path": "hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/client/TestHoodieClientOnCopyOnWriteStorage.java", "diffHunk": "@@ -216,6 +222,71 @@ public void testDeduplicationOnUpsert() throws Exception {\n     testDeduplication(SparkRDDWriteClient::upsert);\n   }\n \n+  @Test\n+  public void testMultiWriter() throws Exception {", "originalCommit": "592e4bda9aed9af895b60db0d07393b2a6916d30", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "21792c6722dd32dddbc5b6ec743549610cd9a8e0", "changed_code": [{"header": "diff --git a/hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/client/TestHoodieClientOnCopyOnWriteStorage.java b/hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/client/TestHoodieClientOnCopyOnWriteStorage.java\nindex eb93b266a..b6c538345 100644\n--- a/hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/client/TestHoodieClientOnCopyOnWriteStorage.java\n+++ b/hudi-client/hudi-spark-client/src/test/java/org/apache/hudi/client/TestHoodieClientOnCopyOnWriteStorage.java\n", "chunk": "@@ -222,71 +234,6 @@ public class TestHoodieClientOnCopyOnWriteStorage extends HoodieClientTestBase {\n     testDeduplication(SparkRDDWriteClient::upsert);\n   }\n \n-  @Test\n-  public void testMultiWriter() throws Exception {\n-    Properties properties = new Properties();\n-    HoodieWriteConfig cfg = getConfigBuilder()\n-        .withLockConfig(HoodieLockConfig.newBuilder().build()).withAutoCommit(false).withProperties(properties).build();\n-    try (SparkRDDWriteClient client = getHoodieWriteClient(cfg);) {\n-\n-      String prevCommitTime = \"000\";\n-      String newCommitTime = \"001\";\n-      int numRecords = 200;\n-      JavaRDD<WriteStatus> result = insertFirstBatch(cfg, client, newCommitTime, prevCommitTime, numRecords, SparkRDDWriteClient::bulkInsert,\n-          false, false, numRecords);\n-      assertFalse(testTable.commitExists(newCommitTime),\n-          \"If Autocommit is false, then commit should not be made automatically\");\n-      assertTrue(client.commit(newCommitTime, result), \"Commit should succeed\");\n-      assertTrue(testTable.commitExists(newCommitTime),\n-          \"After explicit commit, commit file should be created\");\n-    }\n-    try {\n-      ExecutorService executors = Executors.newFixedThreadPool(2);\n-      SparkRDDWriteClient client1 = getHoodieWriteClient(cfg);\n-      SparkRDDWriteClient client2 = getHoodieWriteClient(cfg);\n-      Future future1 = executors.submit(() -> {\n-        String newCommitTime = \"001\";\n-        String initCommitTime = \"000\";\n-        // Write 2 (updates)\n-        String prevCommitTime = newCommitTime;\n-        newCommitTime = \"004\";\n-        int numRecords = 100;\n-        String commitTimeBetweenPrevAndNew = \"002\";\n-        try {\n-          JavaRDD<WriteStatus> result = updateBatch(cfg, client1, newCommitTime, prevCommitTime,\n-              Option.of(Arrays.asList(commitTimeBetweenPrevAndNew)), initCommitTime, numRecords, SparkRDDWriteClient::upsert, false, false,\n-              numRecords, 200, 2);\n-          client1.commit(newCommitTime, result);\n-        } catch (Exception e) {\n-          throw new RuntimeException(e);\n-        }\n-      });\n-      Future future2 = executors.submit(() -> {\n-        String newCommitTime = \"001\";\n-        String initCommitTime = \"000\";\n-        // Write 2 (updates)\n-        String prevCommitTime = newCommitTime;\n-        newCommitTime = \"005\";\n-        int numRecords = 100;\n-        String commitTimeBetweenPrevAndNew = \"002\";\n-        try {\n-          JavaRDD<WriteStatus> result = updateBatch(cfg, client2, newCommitTime, prevCommitTime,\n-              Option.of(Arrays.asList(commitTimeBetweenPrevAndNew)), initCommitTime, numRecords, SparkRDDWriteClient::upsert, false, false,\n-              numRecords, 200, 2);\n-          client2.commit(newCommitTime, result);\n-        } catch (Exception e) {\n-          throw new RuntimeException(e);\n-        }\n-      });\n-      future1.get();\n-      future2.get();\n-    } catch (RuntimeException e) {\n-      e.printStackTrace();\n-      // Expected to fail due to overlapping commits\n-    }\n-    Assertions.fail(\"Should not reach here, this means concurrent writes were handled incorrectly\");\n-  }\n-\n   /**\n    * Test Deduplication Logic for write function.\n    *\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MzgwMQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549553801", "bodyText": "Drop the HOODIE_ ?", "author": "vinothchandar", "createdAt": "2020-12-29T03:20:27Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/config/LockConfiguration.java", "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.config;\n+\n+import java.util.Properties;\n+\n+/**\n+ * Configuration for managing locks. Since this configuration needs to be shared with HiveMetaStore based lock,\n+ * which is in a different package than other lock providers, we use this as a data transfer object in hoodie-common\n+ */\n+public class LockConfiguration {\n+\n+  public static final String HOODIE_LOCK_PREFIX = \"hoodie.writer.lock.\";\n+  public static final String HOODIE_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP = HOODIE_LOCK_PREFIX + \"wait_time_ms\";", "originalCommit": "592e4bda9aed9af895b60db0d07393b2a6916d30", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "98c3c7ddf879d514e5c14293fee145c92f9416a3", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/config/LockConfiguration.java b/hudi-common/src/main/java/org/apache/hudi/common/config/LockConfiguration.java\nindex b3dfecf25..cf8e07126 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/config/LockConfiguration.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/config/LockConfiguration.java\n", "chunk": "@@ -26,20 +26,22 @@ import java.util.Properties;\n  */\n public class LockConfiguration {\n \n-  public static final String HOODIE_LOCK_PREFIX = \"hoodie.writer.lock.\";\n-  public static final String HOODIE_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP = HOODIE_LOCK_PREFIX + \"wait_time_ms\";\n-  public static final String DEFAULT_HOODIE_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS = String.valueOf(5000L);\n-  public static final String HOODIE_LOCK_ACQUIRE_NUM_RETRIES_PROP = HOODIE_LOCK_PREFIX + \"num_retries\";\n-  public static final String DEFAULT_HOODIE_LOCK_ACQUIRE_NUM_RETRIES = String.valueOf(3);\n+  public static final String LOCK_PREFIX = \"hoodie.writer.lock.\";\n+  public static final String LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP = LOCK_PREFIX + \"wait_time_ms_between_retry\";\n+  public static final String DEFAULT_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS = String.valueOf(5000L);\n+  public static final String LOCK_ACQUIRE_NUM_RETRIES_PROP = LOCK_PREFIX + \"num_retries\";\n+  public static final String DEFAULT_LOCK_ACQUIRE_NUM_RETRIES = String.valueOf(3);\n+  public static final String LOCK_ACQUIRE_WAIT_TIMEOUT_MS_PROP = LOCK_PREFIX + \"wait_time_ms\";\n+  public static final int DEFAULT_ACQUIRE_LOCK_WAIT_TIMEOUT_MS = 60 * 1000;\n   // configs for file system based locks. NOTE: This only works for DFS with atomic create/delete operation\n-  public static final String FILESYSTEM_BASED_LOCK_PROPERTY_PREFIX = HOODIE_LOCK_PREFIX + \"filesystem.\";\n+  public static final String FILESYSTEM_BASED_LOCK_PROPERTY_PREFIX = LOCK_PREFIX + \"filesystem.\";\n   public static final String FILESYSTEM_LOCK_PATH_PROP = FILESYSTEM_BASED_LOCK_PROPERTY_PREFIX + \"path\";\n   // configs for metastore based locks\n-  public static final String HIVE_METASTORE_LOCK_PROPERTY_PREFIX = HOODIE_LOCK_PREFIX + \"hivemetastore.\";\n+  public static final String HIVE_METASTORE_LOCK_PROPERTY_PREFIX = LOCK_PREFIX + \"hivemetastore.\";\n   public static final String HIVE_DATABASE_NAME_PROP = HIVE_METASTORE_LOCK_PROPERTY_PREFIX + \"database\";\n   public static final String HIVE_TABLE_NAME_PROP = HIVE_METASTORE_LOCK_PROPERTY_PREFIX + \"table\";\n   // Zookeeper configs for zk based locks\n-  public static final String ZOOKEEPER_BASED_LOCK_PROPERTY_PREFIX = HOODIE_LOCK_PREFIX + \"zookeeper.\";\n+  public static final String ZOOKEEPER_BASED_LOCK_PROPERTY_PREFIX = LOCK_PREFIX + \"zookeeper.\";\n   public static final String ZK_BASE_PATH_PROP = ZOOKEEPER_BASED_LOCK_PROPERTY_PREFIX + \"zk_base_path\";\n   public static final String ZK_SESSION_TIMEOUT_MS_PROP = ZOOKEEPER_BASED_LOCK_PROPERTY_PREFIX + \"zk_session_timeout_ms\";\n   public static final int DEFAULT_ZK_SESSION_TIMEOUT_MS = 60 * 1000;\n", "next_change": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/config/LockConfiguration.java b/hudi-common/src/main/java/org/apache/hudi/common/config/LockConfiguration.java\nindex cf8e07126..fbd17097b 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/config/LockConfiguration.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/config/LockConfiguration.java\n", "chunk": "@@ -18,13 +18,14 @@\n \n package org.apache.hudi.common.config;\n \n+import java.io.Serializable;\n import java.util.Properties;\n \n /**\n  * Configuration for managing locks. Since this configuration needs to be shared with HiveMetaStore based lock,\n  * which is in a different package than other lock providers, we use this as a data transfer object in hoodie-common\n  */\n-public class LockConfiguration {\n+public class LockConfiguration implements Serializable {\n \n   public static final String LOCK_PREFIX = \"hoodie.writer.lock.\";\n   public static final String LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP = LOCK_PREFIX + \"wait_time_ms_between_retry\";\n", "next_change": {"commit": "df38dccc1f6c2193479d23ab62f4f24f27908b55", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/config/LockConfiguration.java b/hudi-common/src/main/java/org/apache/hudi/common/config/LockConfiguration.java\nindex fbd17097b..d9be6a647 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/config/LockConfiguration.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/config/LockConfiguration.java\n", "chunk": "@@ -30,8 +30,12 @@ public class LockConfiguration implements Serializable {\n   public static final String LOCK_PREFIX = \"hoodie.writer.lock.\";\n   public static final String LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP = LOCK_PREFIX + \"wait_time_ms_between_retry\";\n   public static final String DEFAULT_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS = String.valueOf(5000L);\n+  public static final String LOCK_ACQUIRE_CLIENT_RETRY_WAIT_TIME_IN_MILLIS_PROP = LOCK_PREFIX + \"client.wait_time_ms_between_retry\";\n+  public static final String DEFAULT_LOCK_ACQUIRE_CLIENT_RETRY_WAIT_TIME_IN_MILLIS = String.valueOf(10000L);\n   public static final String LOCK_ACQUIRE_NUM_RETRIES_PROP = LOCK_PREFIX + \"num_retries\";\n   public static final String DEFAULT_LOCK_ACQUIRE_NUM_RETRIES = String.valueOf(3);\n+  public static final String LOCK_ACQUIRE_CLIENT_NUM_RETRIES_PROP = LOCK_PREFIX + \"client.num_retries\";\n+  public static final String DEFAULT_LOCK_ACQUIRE_CLIENT_NUM_RETRIES = String.valueOf(0);\n   public static final String LOCK_ACQUIRE_WAIT_TIMEOUT_MS_PROP = LOCK_PREFIX + \"wait_time_ms\";\n   public static final int DEFAULT_ACQUIRE_LOCK_WAIT_TIMEOUT_MS = 60 * 1000;\n   // configs for file system based locks. NOTE: This only works for DFS with atomic create/delete operation\n", "next_change": null}]}}]}}, {"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/config/LockConfiguration.java b/hudi-common/src/main/java/org/apache/hudi/common/config/LockConfiguration.java\nindex b3dfecf25..cf8e07126 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/config/LockConfiguration.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/config/LockConfiguration.java\n", "chunk": "@@ -47,7 +49,7 @@ public class LockConfiguration {\n   public static final int DEFAULT_ZK_CONNECTION_TIMEOUT_MS = 15 * 1000;\n   public static final String ZK_CONNECT_URL_PROP = ZOOKEEPER_BASED_LOCK_PROPERTY_PREFIX + \"url\";\n   public static final String ZK_PORT_PROP = ZOOKEEPER_BASED_LOCK_PROPERTY_PREFIX + \"port\";\n-  public static final String ZK_LOCK_KEY_PROP = HOODIE_LOCK_PREFIX + \"lock_key\";\n+  public static final String ZK_LOCK_KEY_PROP = LOCK_PREFIX + \"lock_key\";\n \n   private final TypedProperties props;\n \n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MzgzOQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549553839", "bodyText": "whats the reason to have this in hudi-common? locking is only used by writing correct.", "author": "vinothchandar", "createdAt": "2020-12-29T03:20:53Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/config/LockConfiguration.java", "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.config;\n+\n+import java.util.Properties;\n+\n+/**\n+ * Configuration for managing locks. Since this configuration needs to be shared with HiveMetaStore based lock,\n+ * which is in a different package than other lock providers, we use this as a data transfer object in hoodie-common\n+ */\n+public class LockConfiguration {", "originalCommit": "592e4bda9aed9af895b60db0d07393b2a6916d30", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDk3MjY2NA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r550972664", "bodyText": "So we need to pass the same configs to HiveMetastoreBasedLockProvider which is in hudi-hive-sync as well as ZookeeperBasedLockProvider which is in hudi-client. This object helps to keep the config reading from the same class.", "author": "n3nash", "createdAt": "2021-01-03T08:14:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MzgzOQ=="}], "type": "inlineReview", "revised_code": {"commit": "98c3c7ddf879d514e5c14293fee145c92f9416a3", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/config/LockConfiguration.java b/hudi-common/src/main/java/org/apache/hudi/common/config/LockConfiguration.java\nindex b3dfecf25..cf8e07126 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/config/LockConfiguration.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/config/LockConfiguration.java\n", "chunk": "@@ -26,20 +26,22 @@ import java.util.Properties;\n  */\n public class LockConfiguration {\n \n-  public static final String HOODIE_LOCK_PREFIX = \"hoodie.writer.lock.\";\n-  public static final String HOODIE_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP = HOODIE_LOCK_PREFIX + \"wait_time_ms\";\n-  public static final String DEFAULT_HOODIE_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS = String.valueOf(5000L);\n-  public static final String HOODIE_LOCK_ACQUIRE_NUM_RETRIES_PROP = HOODIE_LOCK_PREFIX + \"num_retries\";\n-  public static final String DEFAULT_HOODIE_LOCK_ACQUIRE_NUM_RETRIES = String.valueOf(3);\n+  public static final String LOCK_PREFIX = \"hoodie.writer.lock.\";\n+  public static final String LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP = LOCK_PREFIX + \"wait_time_ms_between_retry\";\n+  public static final String DEFAULT_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS = String.valueOf(5000L);\n+  public static final String LOCK_ACQUIRE_NUM_RETRIES_PROP = LOCK_PREFIX + \"num_retries\";\n+  public static final String DEFAULT_LOCK_ACQUIRE_NUM_RETRIES = String.valueOf(3);\n+  public static final String LOCK_ACQUIRE_WAIT_TIMEOUT_MS_PROP = LOCK_PREFIX + \"wait_time_ms\";\n+  public static final int DEFAULT_ACQUIRE_LOCK_WAIT_TIMEOUT_MS = 60 * 1000;\n   // configs for file system based locks. NOTE: This only works for DFS with atomic create/delete operation\n-  public static final String FILESYSTEM_BASED_LOCK_PROPERTY_PREFIX = HOODIE_LOCK_PREFIX + \"filesystem.\";\n+  public static final String FILESYSTEM_BASED_LOCK_PROPERTY_PREFIX = LOCK_PREFIX + \"filesystem.\";\n   public static final String FILESYSTEM_LOCK_PATH_PROP = FILESYSTEM_BASED_LOCK_PROPERTY_PREFIX + \"path\";\n   // configs for metastore based locks\n-  public static final String HIVE_METASTORE_LOCK_PROPERTY_PREFIX = HOODIE_LOCK_PREFIX + \"hivemetastore.\";\n+  public static final String HIVE_METASTORE_LOCK_PROPERTY_PREFIX = LOCK_PREFIX + \"hivemetastore.\";\n   public static final String HIVE_DATABASE_NAME_PROP = HIVE_METASTORE_LOCK_PROPERTY_PREFIX + \"database\";\n   public static final String HIVE_TABLE_NAME_PROP = HIVE_METASTORE_LOCK_PROPERTY_PREFIX + \"table\";\n   // Zookeeper configs for zk based locks\n-  public static final String ZOOKEEPER_BASED_LOCK_PROPERTY_PREFIX = HOODIE_LOCK_PREFIX + \"zookeeper.\";\n+  public static final String ZOOKEEPER_BASED_LOCK_PROPERTY_PREFIX = LOCK_PREFIX + \"zookeeper.\";\n   public static final String ZK_BASE_PATH_PROP = ZOOKEEPER_BASED_LOCK_PROPERTY_PREFIX + \"zk_base_path\";\n   public static final String ZK_SESSION_TIMEOUT_MS_PROP = ZOOKEEPER_BASED_LOCK_PROPERTY_PREFIX + \"zk_session_timeout_ms\";\n   public static final int DEFAULT_ZK_SESSION_TIMEOUT_MS = 60 * 1000;\n", "next_change": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/config/LockConfiguration.java b/hudi-common/src/main/java/org/apache/hudi/common/config/LockConfiguration.java\nindex cf8e07126..fbd17097b 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/config/LockConfiguration.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/config/LockConfiguration.java\n", "chunk": "@@ -18,13 +18,14 @@\n \n package org.apache.hudi.common.config;\n \n+import java.io.Serializable;\n import java.util.Properties;\n \n /**\n  * Configuration for managing locks. Since this configuration needs to be shared with HiveMetaStore based lock,\n  * which is in a different package than other lock providers, we use this as a data transfer object in hoodie-common\n  */\n-public class LockConfiguration {\n+public class LockConfiguration implements Serializable {\n \n   public static final String LOCK_PREFIX = \"hoodie.writer.lock.\";\n   public static final String LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP = LOCK_PREFIX + \"wait_time_ms_between_retry\";\n", "next_change": {"commit": "df38dccc1f6c2193479d23ab62f4f24f27908b55", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/config/LockConfiguration.java b/hudi-common/src/main/java/org/apache/hudi/common/config/LockConfiguration.java\nindex fbd17097b..d9be6a647 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/config/LockConfiguration.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/config/LockConfiguration.java\n", "chunk": "@@ -30,8 +30,12 @@ public class LockConfiguration implements Serializable {\n   public static final String LOCK_PREFIX = \"hoodie.writer.lock.\";\n   public static final String LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP = LOCK_PREFIX + \"wait_time_ms_between_retry\";\n   public static final String DEFAULT_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS = String.valueOf(5000L);\n+  public static final String LOCK_ACQUIRE_CLIENT_RETRY_WAIT_TIME_IN_MILLIS_PROP = LOCK_PREFIX + \"client.wait_time_ms_between_retry\";\n+  public static final String DEFAULT_LOCK_ACQUIRE_CLIENT_RETRY_WAIT_TIME_IN_MILLIS = String.valueOf(10000L);\n   public static final String LOCK_ACQUIRE_NUM_RETRIES_PROP = LOCK_PREFIX + \"num_retries\";\n   public static final String DEFAULT_LOCK_ACQUIRE_NUM_RETRIES = String.valueOf(3);\n+  public static final String LOCK_ACQUIRE_CLIENT_NUM_RETRIES_PROP = LOCK_PREFIX + \"client.num_retries\";\n+  public static final String DEFAULT_LOCK_ACQUIRE_CLIENT_NUM_RETRIES = String.valueOf(0);\n   public static final String LOCK_ACQUIRE_WAIT_TIMEOUT_MS_PROP = LOCK_PREFIX + \"wait_time_ms\";\n   public static final int DEFAULT_ACQUIRE_LOCK_WAIT_TIMEOUT_MS = 60 * 1000;\n   // configs for file system based locks. NOTE: This only works for DFS with atomic create/delete operation\n", "next_change": null}]}}]}}, {"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/config/LockConfiguration.java b/hudi-common/src/main/java/org/apache/hudi/common/config/LockConfiguration.java\nindex b3dfecf25..cf8e07126 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/config/LockConfiguration.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/config/LockConfiguration.java\n", "chunk": "@@ -47,7 +49,7 @@ public class LockConfiguration {\n   public static final int DEFAULT_ZK_CONNECTION_TIMEOUT_MS = 15 * 1000;\n   public static final String ZK_CONNECT_URL_PROP = ZOOKEEPER_BASED_LOCK_PROPERTY_PREFIX + \"url\";\n   public static final String ZK_PORT_PROP = ZOOKEEPER_BASED_LOCK_PROPERTY_PREFIX + \"port\";\n-  public static final String ZK_LOCK_KEY_PROP = HOODIE_LOCK_PREFIX + \"lock_key\";\n+  public static final String ZK_LOCK_KEY_PROP = LOCK_PREFIX + \"lock_key\";\n \n   private final TypedProperties props;\n \n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MzkwNg==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549553906", "bodyText": "can this be an interface?", "author": "vinothchandar", "createdAt": "2020-12-29T03:21:25Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java", "diffHunk": "@@ -0,0 +1,66 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.lock;\n+\n+import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.Condition;\n+import java.util.concurrent.locks.Lock;\n+\n+/**\n+ * Pluggable lock implementations using this provider class.\n+ */\n+public abstract class LockProvider implements Lock, AutoCloseable {", "originalCommit": "592e4bda9aed9af895b60db0d07393b2a6916d30", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDk3MjcwOA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r550972708", "bodyText": "Any specific reason you want this to be an interface ?", "author": "n3nash", "createdAt": "2021-01-03T08:14:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1MzkwNg=="}], "type": "inlineReview", "revised_code": {"commit": "98c3c7ddf879d514e5c14293fee145c92f9416a3", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\nindex 60290a9df..5f7111a61 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n", "chunk": "@@ -19,10 +19,13 @@\n package org.apache.hudi.common.lock;\n \n import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.hudi.exception.HoodieLockException;\n import org.apache.log4j.LogManager;\n import org.apache.log4j.Logger;\n+import shaded.parquet.org.apache.thrift.TException;\n \n import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n import java.util.concurrent.locks.Condition;\n import java.util.concurrent.locks.Lock;\n \n", "next_change": {"commit": "32df18ea69b24a19cda150875cdc636075544589", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\nindex 5f7111a61..d2f9ad77e 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n", "chunk": "@@ -22,10 +22,8 @@ import org.apache.hudi.common.config.LockConfiguration;\n import org.apache.hudi.exception.HoodieLockException;\n import org.apache.log4j.LogManager;\n import org.apache.log4j.Logger;\n-import shaded.parquet.org.apache.thrift.TException;\n \n import java.util.concurrent.TimeUnit;\n-import java.util.concurrent.TimeoutException;\n import java.util.concurrent.locks.Condition;\n import java.util.concurrent.locks.Lock;\n \n", "next_change": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\nindex d2f9ad77e..b17e74b73 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n", "chunk": "@@ -19,6 +19,7 @@\n package org.apache.hudi.common.lock;\n \n import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.hudi.common.util.StringUtils;\n import org.apache.hudi.exception.HoodieLockException;\n import org.apache.log4j.LogManager;\n import org.apache.log4j.Logger;\n", "next_change": {"commit": "45e931ec410685bcc1ec8dd974560add27dac684", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\nindex b17e74b73..e5cf51691 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n", "chunk": "@@ -18,65 +18,35 @@\n \n package org.apache.hudi.common.lock;\n \n-import org.apache.hudi.common.config.LockConfiguration;\n-import org.apache.hudi.common.util.StringUtils;\n-import org.apache.hudi.exception.HoodieLockException;\n-import org.apache.log4j.LogManager;\n-import org.apache.log4j.Logger;\n-\n-import java.util.concurrent.TimeUnit;\n import java.util.concurrent.locks.Condition;\n import java.util.concurrent.locks.Lock;\n \n /**\n  * Pluggable lock implementations using this provider class.\n  */\n-public abstract class LockProvider implements Lock, AutoCloseable {\n-\n-  private static final Logger LOG = LogManager.getLogger(LockProvider.class);\n-\n-  protected LockConfiguration lockConfiguration;\n+public interface LockProvider<T> extends Lock, AutoCloseable {\n \n   @Override\n-  public final void lockInterruptibly() {\n+  default void lockInterruptibly() {\n     throw new UnsupportedOperationException();\n   }\n \n   @Override\n-  public final void lock() {\n+  default void lock() {\n     throw new UnsupportedOperationException();\n   }\n \n   @Override\n-  public final boolean tryLock() {\n+  default boolean tryLock() {\n     throw new UnsupportedOperationException();\n   }\n \n   @Override\n-  public boolean tryLock(long time, TimeUnit unit) {\n-    try {\n-      return tryLock(time, unit);\n-    } catch (Exception e) {\n-      throw new HoodieLockException(e);\n-    }\n-  }\n-\n-  @Override\n-  public final Condition newCondition() {\n+  default Condition newCondition() {\n     throw new UnsupportedOperationException();\n   }\n \n-  @Override\n-  public void close() {\n-    try {\n-      close();\n-    } catch (Exception e) {\n-      LOG.error(e);\n-    }\n+  default T getLock() {\n+    throw new IllegalArgumentException();\n   }\n-\n-  protected String generateLogStatement(LockState state, String suffix) {\n-    return StringUtils.join(state.name(), \" lock at \", suffix);\n-  }\n-\n }\n", "next_change": {"commit": "1b41b773c6bb94ac28609bf829e875cefce6e5d3", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\nindex e5cf51691..7d8e52738 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n", "chunk": "@@ -49,4 +49,8 @@ public interface LockProvider<T> extends Lock, AutoCloseable {\n   default T getLock() {\n     throw new IllegalArgumentException();\n   }\n+\n+  @Override\n+  default void close() {\n+  }\n }\n", "next_change": null}]}}]}}]}}]}}, {"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\nindex 60290a9df..5f7111a61 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n", "chunk": "@@ -35,27 +38,28 @@ public abstract class LockProvider implements Lock, AutoCloseable {\n \n   protected LockConfiguration lockConfiguration;\n \n-  protected abstract void acquireLock() throws Exception;\n+  @Override\n+  public final void lockInterruptibly() {\n+    throw new UnsupportedOperationException();\n+  }\n \n   @Override\n   public final void lock() {\n-    LOG.info(\"Acquiring lock\");\n-    try {\n-      acquireLock();\n-    } catch (Exception e) {\n-      throw new RuntimeException(e);\n-    }\n-    LOG.info(\"Acquired lock\");\n+    throw new UnsupportedOperationException();\n   }\n \n   @Override\n-  public final void lockInterruptibly() {\n+  public final boolean tryLock() {\n     throw new UnsupportedOperationException();\n   }\n \n   @Override\n-  public final boolean tryLock(long time, TimeUnit unit) {\n-    throw new UnsupportedOperationException();\n+  public boolean tryLock(long time, TimeUnit unit) {\n+    try {\n+      return tryLock(time, unit);\n+    } catch (Exception e) {\n+      throw new HoodieLockException(e);\n+    }\n   }\n \n   @Override\n", "next_change": {"commit": "df38dccc1f6c2193479d23ab62f4f24f27908b55", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\nindex 5f7111a61..4784ffda4 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n", "chunk": "@@ -19,20 +19,19 @@\n package org.apache.hudi.common.lock;\n \n import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.hudi.common.util.StringUtils;\n import org.apache.hudi.exception.HoodieLockException;\n import org.apache.log4j.LogManager;\n import org.apache.log4j.Logger;\n-import shaded.parquet.org.apache.thrift.TException;\n \n import java.util.concurrent.TimeUnit;\n-import java.util.concurrent.TimeoutException;\n import java.util.concurrent.locks.Condition;\n import java.util.concurrent.locks.Lock;\n \n /**\n  * Pluggable lock implementations using this provider class.\n  */\n-public abstract class LockProvider implements Lock, AutoCloseable {\n+public abstract class LockProvider<T> implements Lock, AutoCloseable {\n \n   private static final Logger LOG = LogManager.getLogger(LockProvider.class);\n \n", "next_change": {"commit": "45e931ec410685bcc1ec8dd974560add27dac684", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\nindex 4784ffda4..e5cf51691 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n", "chunk": "@@ -18,69 +18,35 @@\n \n package org.apache.hudi.common.lock;\n \n-import org.apache.hudi.common.config.LockConfiguration;\n-import org.apache.hudi.common.util.StringUtils;\n-import org.apache.hudi.exception.HoodieLockException;\n-import org.apache.log4j.LogManager;\n-import org.apache.log4j.Logger;\n-\n-import java.util.concurrent.TimeUnit;\n import java.util.concurrent.locks.Condition;\n import java.util.concurrent.locks.Lock;\n \n /**\n  * Pluggable lock implementations using this provider class.\n  */\n-public abstract class LockProvider<T> implements Lock, AutoCloseable {\n-\n-  private static final Logger LOG = LogManager.getLogger(LockProvider.class);\n-\n-  protected LockConfiguration lockConfiguration;\n+public interface LockProvider<T> extends Lock, AutoCloseable {\n \n   @Override\n-  public final void lockInterruptibly() {\n+  default void lockInterruptibly() {\n     throw new UnsupportedOperationException();\n   }\n \n   @Override\n-  public final void lock() {\n+  default void lock() {\n     throw new UnsupportedOperationException();\n   }\n \n   @Override\n-  public final boolean tryLock() {\n+  default boolean tryLock() {\n     throw new UnsupportedOperationException();\n   }\n \n   @Override\n-  public boolean tryLock(long time, TimeUnit unit) {\n-    try {\n-      return tryLock(time, unit);\n-    } catch (Exception e) {\n-      throw new HoodieLockException(e);\n-    }\n-  }\n-\n-  public T getLock() {\n+  default Condition newCondition() {\n     throw new UnsupportedOperationException();\n   }\n \n-  @Override\n-  public final Condition newCondition() {\n-    throw new UnsupportedOperationException();\n+  default T getLock() {\n+    throw new IllegalArgumentException();\n   }\n-\n-  @Override\n-  public void close() {\n-    try {\n-      close();\n-    } catch (Exception e) {\n-      LOG.error(e);\n-    }\n-  }\n-\n-  protected String generateLogStatement(LockState state, String suffix) {\n-    return StringUtils.join(state.name(), \" lock at\", suffix);\n-  }\n-\n }\n", "next_change": {"commit": "1b41b773c6bb94ac28609bf829e875cefce6e5d3", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\nindex e5cf51691..7d8e52738 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n", "chunk": "@@ -49,4 +49,8 @@ public interface LockProvider<T> extends Lock, AutoCloseable {\n   default T getLock() {\n     throw new IllegalArgumentException();\n   }\n+\n+  @Override\n+  default void close() {\n+  }\n }\n", "next_change": null}]}}]}}, {"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\nindex 5f7111a61..4784ffda4 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n", "chunk": "@@ -62,6 +61,10 @@ public abstract class LockProvider implements Lock, AutoCloseable {\n     }\n   }\n \n+  public T getLock() {\n+    throw new UnsupportedOperationException();\n+  }\n+\n   @Override\n   public final Condition newCondition() {\n     throw new UnsupportedOperationException();\n", "next_change": {"commit": "45e931ec410685bcc1ec8dd974560add27dac684", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\nindex 4784ffda4..e5cf51691 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n", "chunk": "@@ -18,69 +18,35 @@\n \n package org.apache.hudi.common.lock;\n \n-import org.apache.hudi.common.config.LockConfiguration;\n-import org.apache.hudi.common.util.StringUtils;\n-import org.apache.hudi.exception.HoodieLockException;\n-import org.apache.log4j.LogManager;\n-import org.apache.log4j.Logger;\n-\n-import java.util.concurrent.TimeUnit;\n import java.util.concurrent.locks.Condition;\n import java.util.concurrent.locks.Lock;\n \n /**\n  * Pluggable lock implementations using this provider class.\n  */\n-public abstract class LockProvider<T> implements Lock, AutoCloseable {\n-\n-  private static final Logger LOG = LogManager.getLogger(LockProvider.class);\n-\n-  protected LockConfiguration lockConfiguration;\n+public interface LockProvider<T> extends Lock, AutoCloseable {\n \n   @Override\n-  public final void lockInterruptibly() {\n+  default void lockInterruptibly() {\n     throw new UnsupportedOperationException();\n   }\n \n   @Override\n-  public final void lock() {\n+  default void lock() {\n     throw new UnsupportedOperationException();\n   }\n \n   @Override\n-  public final boolean tryLock() {\n+  default boolean tryLock() {\n     throw new UnsupportedOperationException();\n   }\n \n   @Override\n-  public boolean tryLock(long time, TimeUnit unit) {\n-    try {\n-      return tryLock(time, unit);\n-    } catch (Exception e) {\n-      throw new HoodieLockException(e);\n-    }\n-  }\n-\n-  public T getLock() {\n+  default Condition newCondition() {\n     throw new UnsupportedOperationException();\n   }\n \n-  @Override\n-  public final Condition newCondition() {\n-    throw new UnsupportedOperationException();\n+  default T getLock() {\n+    throw new IllegalArgumentException();\n   }\n-\n-  @Override\n-  public void close() {\n-    try {\n-      close();\n-    } catch (Exception e) {\n-      LOG.error(e);\n-    }\n-  }\n-\n-  protected String generateLogStatement(LockState state, String suffix) {\n-    return StringUtils.join(state.name(), \" lock at\", suffix);\n-  }\n-\n }\n", "next_change": {"commit": "1b41b773c6bb94ac28609bf829e875cefce6e5d3", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\nindex e5cf51691..7d8e52738 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n", "chunk": "@@ -49,4 +49,8 @@ public interface LockProvider<T> extends Lock, AutoCloseable {\n   default T getLock() {\n     throw new IllegalArgumentException();\n   }\n+\n+  @Override\n+  default void close() {\n+  }\n }\n", "next_change": null}]}}]}}]}}, {"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\nindex 60290a9df..5f7111a61 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n", "chunk": "@@ -63,4 +67,13 @@ public abstract class LockProvider implements Lock, AutoCloseable {\n     throw new UnsupportedOperationException();\n   }\n \n+  @Override\n+  public void close() {\n+    try {\n+      close();\n+    } catch (Exception e) {\n+      LOG.error(e);\n+    }\n+  }\n+\n }\n", "next_change": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\nindex 5f7111a61..b17e74b73 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n", "chunk": "@@ -76,4 +75,8 @@ public abstract class LockProvider implements Lock, AutoCloseable {\n     }\n   }\n \n+  protected String generateLogStatement(LockState state, String suffix) {\n+    return StringUtils.join(state.name(), \" lock at \", suffix);\n+  }\n+\n }\n", "next_change": {"commit": "d155914cd673d7699bb5258e6f9cafb85059673a", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\nindex b17e74b73..962c30012 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n", "chunk": "@@ -76,7 +76,7 @@ public abstract class LockProvider implements Lock, AutoCloseable {\n   }\n \n   protected String generateLogStatement(LockState state, String suffix) {\n-    return StringUtils.join(state.name(), \" lock at \", suffix);\n+    return StringUtils.join(state.name(), \" lock at\", suffix);\n   }\n \n }\n", "next_change": {"commit": "45e931ec410685bcc1ec8dd974560add27dac684", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\nindex 962c30012..e5cf51691 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n", "chunk": "@@ -18,65 +18,35 @@\n \n package org.apache.hudi.common.lock;\n \n-import org.apache.hudi.common.config.LockConfiguration;\n-import org.apache.hudi.common.util.StringUtils;\n-import org.apache.hudi.exception.HoodieLockException;\n-import org.apache.log4j.LogManager;\n-import org.apache.log4j.Logger;\n-\n-import java.util.concurrent.TimeUnit;\n import java.util.concurrent.locks.Condition;\n import java.util.concurrent.locks.Lock;\n \n /**\n  * Pluggable lock implementations using this provider class.\n  */\n-public abstract class LockProvider implements Lock, AutoCloseable {\n-\n-  private static final Logger LOG = LogManager.getLogger(LockProvider.class);\n-\n-  protected LockConfiguration lockConfiguration;\n+public interface LockProvider<T> extends Lock, AutoCloseable {\n \n   @Override\n-  public final void lockInterruptibly() {\n+  default void lockInterruptibly() {\n     throw new UnsupportedOperationException();\n   }\n \n   @Override\n-  public final void lock() {\n+  default void lock() {\n     throw new UnsupportedOperationException();\n   }\n \n   @Override\n-  public final boolean tryLock() {\n+  default boolean tryLock() {\n     throw new UnsupportedOperationException();\n   }\n \n   @Override\n-  public boolean tryLock(long time, TimeUnit unit) {\n-    try {\n-      return tryLock(time, unit);\n-    } catch (Exception e) {\n-      throw new HoodieLockException(e);\n-    }\n-  }\n-\n-  @Override\n-  public final Condition newCondition() {\n+  default Condition newCondition() {\n     throw new UnsupportedOperationException();\n   }\n \n-  @Override\n-  public void close() {\n-    try {\n-      close();\n-    } catch (Exception e) {\n-      LOG.error(e);\n-    }\n+  default T getLock() {\n+    throw new IllegalArgumentException();\n   }\n-\n-  protected String generateLogStatement(LockState state, String suffix) {\n-    return StringUtils.join(state.name(), \" lock at\", suffix);\n-  }\n-\n }\n", "next_change": {"commit": "1b41b773c6bb94ac28609bf829e875cefce6e5d3", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\nindex e5cf51691..7d8e52738 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n", "chunk": "@@ -49,4 +49,8 @@ public interface LockProvider<T> extends Lock, AutoCloseable {\n   default T getLock() {\n     throw new IllegalArgumentException();\n   }\n+\n+  @Override\n+  default void close() {\n+  }\n }\n", "next_change": null}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1NDA3Mw==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549554073", "bodyText": "we should probably support this right. even of the lock() , since this has a timeout param?", "author": "vinothchandar", "createdAt": "2020-12-29T03:22:42Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java", "diffHunk": "@@ -0,0 +1,66 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.lock;\n+\n+import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.Condition;\n+import java.util.concurrent.locks.Lock;\n+\n+/**\n+ * Pluggable lock implementations using this provider class.\n+ */\n+public abstract class LockProvider implements Lock, AutoCloseable {\n+\n+  private static final Logger LOG = LogManager.getLogger(LockProvider.class);\n+\n+  protected LockConfiguration lockConfiguration;\n+\n+  protected abstract void acquireLock() throws Exception;\n+\n+  @Override\n+  public final void lock() {\n+    LOG.info(\"Acquiring lock\");\n+    try {\n+      acquireLock();\n+    } catch (Exception e) {\n+      throw new RuntimeException(e);\n+    }\n+    LOG.info(\"Acquired lock\");\n+  }\n+\n+  @Override\n+  public final void lockInterruptibly() {\n+    throw new UnsupportedOperationException();\n+  }\n+\n+  @Override\n+  public final boolean tryLock(long time, TimeUnit unit) {", "originalCommit": "592e4bda9aed9af895b60db0d07393b2a6916d30", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDk3NDM1Mw==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r550974353", "bodyText": "Had implemented this differently earlier, changed some of the contracts, take a look again please", "author": "n3nash", "createdAt": "2021-01-03T08:30:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1NDA3Mw=="}], "type": "inlineReview", "revised_code": {"commit": "98c3c7ddf879d514e5c14293fee145c92f9416a3", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\nindex 60290a9df..5f7111a61 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n", "chunk": "@@ -19,10 +19,13 @@\n package org.apache.hudi.common.lock;\n \n import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.hudi.exception.HoodieLockException;\n import org.apache.log4j.LogManager;\n import org.apache.log4j.Logger;\n+import shaded.parquet.org.apache.thrift.TException;\n \n import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n import java.util.concurrent.locks.Condition;\n import java.util.concurrent.locks.Lock;\n \n", "next_change": {"commit": "32df18ea69b24a19cda150875cdc636075544589", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\nindex 5f7111a61..d2f9ad77e 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n", "chunk": "@@ -22,10 +22,8 @@ import org.apache.hudi.common.config.LockConfiguration;\n import org.apache.hudi.exception.HoodieLockException;\n import org.apache.log4j.LogManager;\n import org.apache.log4j.Logger;\n-import shaded.parquet.org.apache.thrift.TException;\n \n import java.util.concurrent.TimeUnit;\n-import java.util.concurrent.TimeoutException;\n import java.util.concurrent.locks.Condition;\n import java.util.concurrent.locks.Lock;\n \n", "next_change": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\nindex d2f9ad77e..b17e74b73 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n", "chunk": "@@ -19,6 +19,7 @@\n package org.apache.hudi.common.lock;\n \n import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.hudi.common.util.StringUtils;\n import org.apache.hudi.exception.HoodieLockException;\n import org.apache.log4j.LogManager;\n import org.apache.log4j.Logger;\n", "next_change": {"commit": "45e931ec410685bcc1ec8dd974560add27dac684", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\nindex b17e74b73..e5cf51691 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n", "chunk": "@@ -18,65 +18,35 @@\n \n package org.apache.hudi.common.lock;\n \n-import org.apache.hudi.common.config.LockConfiguration;\n-import org.apache.hudi.common.util.StringUtils;\n-import org.apache.hudi.exception.HoodieLockException;\n-import org.apache.log4j.LogManager;\n-import org.apache.log4j.Logger;\n-\n-import java.util.concurrent.TimeUnit;\n import java.util.concurrent.locks.Condition;\n import java.util.concurrent.locks.Lock;\n \n /**\n  * Pluggable lock implementations using this provider class.\n  */\n-public abstract class LockProvider implements Lock, AutoCloseable {\n-\n-  private static final Logger LOG = LogManager.getLogger(LockProvider.class);\n-\n-  protected LockConfiguration lockConfiguration;\n+public interface LockProvider<T> extends Lock, AutoCloseable {\n \n   @Override\n-  public final void lockInterruptibly() {\n+  default void lockInterruptibly() {\n     throw new UnsupportedOperationException();\n   }\n \n   @Override\n-  public final void lock() {\n+  default void lock() {\n     throw new UnsupportedOperationException();\n   }\n \n   @Override\n-  public final boolean tryLock() {\n+  default boolean tryLock() {\n     throw new UnsupportedOperationException();\n   }\n \n   @Override\n-  public boolean tryLock(long time, TimeUnit unit) {\n-    try {\n-      return tryLock(time, unit);\n-    } catch (Exception e) {\n-      throw new HoodieLockException(e);\n-    }\n-  }\n-\n-  @Override\n-  public final Condition newCondition() {\n+  default Condition newCondition() {\n     throw new UnsupportedOperationException();\n   }\n \n-  @Override\n-  public void close() {\n-    try {\n-      close();\n-    } catch (Exception e) {\n-      LOG.error(e);\n-    }\n+  default T getLock() {\n+    throw new IllegalArgumentException();\n   }\n-\n-  protected String generateLogStatement(LockState state, String suffix) {\n-    return StringUtils.join(state.name(), \" lock at \", suffix);\n-  }\n-\n }\n", "next_change": {"commit": "1b41b773c6bb94ac28609bf829e875cefce6e5d3", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\nindex e5cf51691..7d8e52738 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n", "chunk": "@@ -49,4 +49,8 @@ public interface LockProvider<T> extends Lock, AutoCloseable {\n   default T getLock() {\n     throw new IllegalArgumentException();\n   }\n+\n+  @Override\n+  default void close() {\n+  }\n }\n", "next_change": null}]}}]}}]}}]}}, {"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\nindex 60290a9df..5f7111a61 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n", "chunk": "@@ -35,27 +38,28 @@ public abstract class LockProvider implements Lock, AutoCloseable {\n \n   protected LockConfiguration lockConfiguration;\n \n-  protected abstract void acquireLock() throws Exception;\n+  @Override\n+  public final void lockInterruptibly() {\n+    throw new UnsupportedOperationException();\n+  }\n \n   @Override\n   public final void lock() {\n-    LOG.info(\"Acquiring lock\");\n-    try {\n-      acquireLock();\n-    } catch (Exception e) {\n-      throw new RuntimeException(e);\n-    }\n-    LOG.info(\"Acquired lock\");\n+    throw new UnsupportedOperationException();\n   }\n \n   @Override\n-  public final void lockInterruptibly() {\n+  public final boolean tryLock() {\n     throw new UnsupportedOperationException();\n   }\n \n   @Override\n-  public final boolean tryLock(long time, TimeUnit unit) {\n-    throw new UnsupportedOperationException();\n+  public boolean tryLock(long time, TimeUnit unit) {\n+    try {\n+      return tryLock(time, unit);\n+    } catch (Exception e) {\n+      throw new HoodieLockException(e);\n+    }\n   }\n \n   @Override\n", "next_change": {"commit": "df38dccc1f6c2193479d23ab62f4f24f27908b55", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\nindex 5f7111a61..4784ffda4 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n", "chunk": "@@ -19,20 +19,19 @@\n package org.apache.hudi.common.lock;\n \n import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.hudi.common.util.StringUtils;\n import org.apache.hudi.exception.HoodieLockException;\n import org.apache.log4j.LogManager;\n import org.apache.log4j.Logger;\n-import shaded.parquet.org.apache.thrift.TException;\n \n import java.util.concurrent.TimeUnit;\n-import java.util.concurrent.TimeoutException;\n import java.util.concurrent.locks.Condition;\n import java.util.concurrent.locks.Lock;\n \n /**\n  * Pluggable lock implementations using this provider class.\n  */\n-public abstract class LockProvider implements Lock, AutoCloseable {\n+public abstract class LockProvider<T> implements Lock, AutoCloseable {\n \n   private static final Logger LOG = LogManager.getLogger(LockProvider.class);\n \n", "next_change": {"commit": "45e931ec410685bcc1ec8dd974560add27dac684", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\nindex 4784ffda4..e5cf51691 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n", "chunk": "@@ -18,69 +18,35 @@\n \n package org.apache.hudi.common.lock;\n \n-import org.apache.hudi.common.config.LockConfiguration;\n-import org.apache.hudi.common.util.StringUtils;\n-import org.apache.hudi.exception.HoodieLockException;\n-import org.apache.log4j.LogManager;\n-import org.apache.log4j.Logger;\n-\n-import java.util.concurrent.TimeUnit;\n import java.util.concurrent.locks.Condition;\n import java.util.concurrent.locks.Lock;\n \n /**\n  * Pluggable lock implementations using this provider class.\n  */\n-public abstract class LockProvider<T> implements Lock, AutoCloseable {\n-\n-  private static final Logger LOG = LogManager.getLogger(LockProvider.class);\n-\n-  protected LockConfiguration lockConfiguration;\n+public interface LockProvider<T> extends Lock, AutoCloseable {\n \n   @Override\n-  public final void lockInterruptibly() {\n+  default void lockInterruptibly() {\n     throw new UnsupportedOperationException();\n   }\n \n   @Override\n-  public final void lock() {\n+  default void lock() {\n     throw new UnsupportedOperationException();\n   }\n \n   @Override\n-  public final boolean tryLock() {\n+  default boolean tryLock() {\n     throw new UnsupportedOperationException();\n   }\n \n   @Override\n-  public boolean tryLock(long time, TimeUnit unit) {\n-    try {\n-      return tryLock(time, unit);\n-    } catch (Exception e) {\n-      throw new HoodieLockException(e);\n-    }\n-  }\n-\n-  public T getLock() {\n+  default Condition newCondition() {\n     throw new UnsupportedOperationException();\n   }\n \n-  @Override\n-  public final Condition newCondition() {\n-    throw new UnsupportedOperationException();\n+  default T getLock() {\n+    throw new IllegalArgumentException();\n   }\n-\n-  @Override\n-  public void close() {\n-    try {\n-      close();\n-    } catch (Exception e) {\n-      LOG.error(e);\n-    }\n-  }\n-\n-  protected String generateLogStatement(LockState state, String suffix) {\n-    return StringUtils.join(state.name(), \" lock at\", suffix);\n-  }\n-\n }\n", "next_change": {"commit": "1b41b773c6bb94ac28609bf829e875cefce6e5d3", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\nindex e5cf51691..7d8e52738 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n", "chunk": "@@ -49,4 +49,8 @@ public interface LockProvider<T> extends Lock, AutoCloseable {\n   default T getLock() {\n     throw new IllegalArgumentException();\n   }\n+\n+  @Override\n+  default void close() {\n+  }\n }\n", "next_change": null}]}}]}}, {"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\nindex 5f7111a61..4784ffda4 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n", "chunk": "@@ -62,6 +61,10 @@ public abstract class LockProvider implements Lock, AutoCloseable {\n     }\n   }\n \n+  public T getLock() {\n+    throw new UnsupportedOperationException();\n+  }\n+\n   @Override\n   public final Condition newCondition() {\n     throw new UnsupportedOperationException();\n", "next_change": {"commit": "45e931ec410685bcc1ec8dd974560add27dac684", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\nindex 4784ffda4..e5cf51691 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n", "chunk": "@@ -18,69 +18,35 @@\n \n package org.apache.hudi.common.lock;\n \n-import org.apache.hudi.common.config.LockConfiguration;\n-import org.apache.hudi.common.util.StringUtils;\n-import org.apache.hudi.exception.HoodieLockException;\n-import org.apache.log4j.LogManager;\n-import org.apache.log4j.Logger;\n-\n-import java.util.concurrent.TimeUnit;\n import java.util.concurrent.locks.Condition;\n import java.util.concurrent.locks.Lock;\n \n /**\n  * Pluggable lock implementations using this provider class.\n  */\n-public abstract class LockProvider<T> implements Lock, AutoCloseable {\n-\n-  private static final Logger LOG = LogManager.getLogger(LockProvider.class);\n-\n-  protected LockConfiguration lockConfiguration;\n+public interface LockProvider<T> extends Lock, AutoCloseable {\n \n   @Override\n-  public final void lockInterruptibly() {\n+  default void lockInterruptibly() {\n     throw new UnsupportedOperationException();\n   }\n \n   @Override\n-  public final void lock() {\n+  default void lock() {\n     throw new UnsupportedOperationException();\n   }\n \n   @Override\n-  public final boolean tryLock() {\n+  default boolean tryLock() {\n     throw new UnsupportedOperationException();\n   }\n \n   @Override\n-  public boolean tryLock(long time, TimeUnit unit) {\n-    try {\n-      return tryLock(time, unit);\n-    } catch (Exception e) {\n-      throw new HoodieLockException(e);\n-    }\n-  }\n-\n-  public T getLock() {\n+  default Condition newCondition() {\n     throw new UnsupportedOperationException();\n   }\n \n-  @Override\n-  public final Condition newCondition() {\n-    throw new UnsupportedOperationException();\n+  default T getLock() {\n+    throw new IllegalArgumentException();\n   }\n-\n-  @Override\n-  public void close() {\n-    try {\n-      close();\n-    } catch (Exception e) {\n-      LOG.error(e);\n-    }\n-  }\n-\n-  protected String generateLogStatement(LockState state, String suffix) {\n-    return StringUtils.join(state.name(), \" lock at\", suffix);\n-  }\n-\n }\n", "next_change": {"commit": "1b41b773c6bb94ac28609bf829e875cefce6e5d3", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\nindex e5cf51691..7d8e52738 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n", "chunk": "@@ -49,4 +49,8 @@ public interface LockProvider<T> extends Lock, AutoCloseable {\n   default T getLock() {\n     throw new IllegalArgumentException();\n   }\n+\n+  @Override\n+  default void close() {\n+  }\n }\n", "next_change": null}]}}]}}]}}, {"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\nindex 60290a9df..5f7111a61 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n", "chunk": "@@ -63,4 +67,13 @@ public abstract class LockProvider implements Lock, AutoCloseable {\n     throw new UnsupportedOperationException();\n   }\n \n+  @Override\n+  public void close() {\n+    try {\n+      close();\n+    } catch (Exception e) {\n+      LOG.error(e);\n+    }\n+  }\n+\n }\n", "next_change": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\nindex 5f7111a61..b17e74b73 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n", "chunk": "@@ -76,4 +75,8 @@ public abstract class LockProvider implements Lock, AutoCloseable {\n     }\n   }\n \n+  protected String generateLogStatement(LockState state, String suffix) {\n+    return StringUtils.join(state.name(), \" lock at \", suffix);\n+  }\n+\n }\n", "next_change": {"commit": "d155914cd673d7699bb5258e6f9cafb85059673a", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\nindex b17e74b73..962c30012 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n", "chunk": "@@ -76,7 +76,7 @@ public abstract class LockProvider implements Lock, AutoCloseable {\n   }\n \n   protected String generateLogStatement(LockState state, String suffix) {\n-    return StringUtils.join(state.name(), \" lock at \", suffix);\n+    return StringUtils.join(state.name(), \" lock at\", suffix);\n   }\n \n }\n", "next_change": {"commit": "45e931ec410685bcc1ec8dd974560add27dac684", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\nindex 962c30012..e5cf51691 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n", "chunk": "@@ -18,65 +18,35 @@\n \n package org.apache.hudi.common.lock;\n \n-import org.apache.hudi.common.config.LockConfiguration;\n-import org.apache.hudi.common.util.StringUtils;\n-import org.apache.hudi.exception.HoodieLockException;\n-import org.apache.log4j.LogManager;\n-import org.apache.log4j.Logger;\n-\n-import java.util.concurrent.TimeUnit;\n import java.util.concurrent.locks.Condition;\n import java.util.concurrent.locks.Lock;\n \n /**\n  * Pluggable lock implementations using this provider class.\n  */\n-public abstract class LockProvider implements Lock, AutoCloseable {\n-\n-  private static final Logger LOG = LogManager.getLogger(LockProvider.class);\n-\n-  protected LockConfiguration lockConfiguration;\n+public interface LockProvider<T> extends Lock, AutoCloseable {\n \n   @Override\n-  public final void lockInterruptibly() {\n+  default void lockInterruptibly() {\n     throw new UnsupportedOperationException();\n   }\n \n   @Override\n-  public final void lock() {\n+  default void lock() {\n     throw new UnsupportedOperationException();\n   }\n \n   @Override\n-  public final boolean tryLock() {\n+  default boolean tryLock() {\n     throw new UnsupportedOperationException();\n   }\n \n   @Override\n-  public boolean tryLock(long time, TimeUnit unit) {\n-    try {\n-      return tryLock(time, unit);\n-    } catch (Exception e) {\n-      throw new HoodieLockException(e);\n-    }\n-  }\n-\n-  @Override\n-  public final Condition newCondition() {\n+  default Condition newCondition() {\n     throw new UnsupportedOperationException();\n   }\n \n-  @Override\n-  public void close() {\n-    try {\n-      close();\n-    } catch (Exception e) {\n-      LOG.error(e);\n-    }\n+  default T getLock() {\n+    throw new IllegalArgumentException();\n   }\n-\n-  protected String generateLogStatement(LockState state, String suffix) {\n-    return StringUtils.join(state.name(), \" lock at\", suffix);\n-  }\n-\n }\n", "next_change": {"commit": "1b41b773c6bb94ac28609bf829e875cefce6e5d3", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\nindex e5cf51691..7d8e52738 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n", "chunk": "@@ -49,4 +49,8 @@ public interface LockProvider<T> extends Lock, AutoCloseable {\n   default T getLock() {\n     throw new IllegalArgumentException();\n   }\n+\n+  @Override\n+  default void close() {\n+  }\n }\n", "next_change": null}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1NDE0Mg==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549554142", "bodyText": "can this sit somewhere else? in a helper method?", "author": "vinothchandar", "createdAt": "2020-12-29T03:23:13Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/model/HoodieCommitMetadata.java", "diffHunk": "@@ -109,6 +108,17 @@ public void setCompacted(Boolean compacted) {\n     return filePaths;\n   }\n \n+  public HashMap<String, String> getFileIdWithoutSuffixAndRelativePaths() {", "originalCommit": "592e4bda9aed9af895b60db0d07393b2a6916d30", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDk3NDkwMQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r550974901", "bodyText": "done", "author": "n3nash", "createdAt": "2021-01-03T08:36:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1NDE0Mg=="}], "type": "inlineReview", "revised_code": {"commit": "98c3c7ddf879d514e5c14293fee145c92f9416a3", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/model/HoodieCommitMetadata.java b/hudi-common/src/main/java/org/apache/hudi/common/model/HoodieCommitMetadata.java\nindex 42502eea9..7982e199b 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/model/HoodieCommitMetadata.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/model/HoodieCommitMetadata.java\n", "chunk": "@@ -108,17 +108,6 @@ public class HoodieCommitMetadata implements Serializable {\n     return filePaths;\n   }\n \n-  public HashMap<String, String> getFileIdWithoutSuffixAndRelativePaths() {\n-    HashMap<String, String> fileIdToPath = new HashMap<>();\n-    // list all partitions paths\n-    for (Map.Entry<String, List<HoodieWriteStat>> entry : getPartitionToWriteStats().entrySet()) {\n-      for (HoodieWriteStat stat : entry.getValue()) {\n-        fileIdToPath.put(FSUtils.getFileId(stat.getFileId()), stat.getPath());\n-      }\n-    }\n-    return fileIdToPath;\n-  }\n-\n   public void setOperationType(WriteOperationType type) {\n     this.operationType = type;\n   }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1NDE3OQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r549554179", "bodyText": "why this change?", "author": "vinothchandar", "createdAt": "2020-12-29T03:23:29Z", "path": "hudi-integ-test/src/main/java/org/apache/hudi/integ/testsuite/generator/GenericRecordFullPayloadGenerator.java", "diffHunk": "@@ -284,7 +284,7 @@ private Object typeConvert(Schema.Field field) {\n   private Object generateFixedType(Schema localSchema) {\n     // TODO: Need to implement valid data generation for fixed type\n     GenericFixed genericFixed = new GenericData.Fixed(localSchema);\n-    switch (localSchema.getLogicalType().getName()) {\n+    switch (localSchema.getType().getName()) {", "originalCommit": "592e4bda9aed9af895b60db0d07393b2a6916d30", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDk3NDkzNg==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r550974936", "bodyText": "Same, my intellij doesn't work, reverted", "author": "n3nash", "createdAt": "2021-01-03T08:36:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU1NDE3OQ=="}], "type": "inlineReview", "revised_code": {"commit": "98c3c7ddf879d514e5c14293fee145c92f9416a3", "changed_code": [{"header": "diff --git a/hudi-integ-test/src/main/java/org/apache/hudi/integ/testsuite/generator/GenericRecordFullPayloadGenerator.java b/hudi-integ-test/src/main/java/org/apache/hudi/integ/testsuite/generator/GenericRecordFullPayloadGenerator.java\nindex 29c4c1b14..510fc499b 100644\n--- a/hudi-integ-test/src/main/java/org/apache/hudi/integ/testsuite/generator/GenericRecordFullPayloadGenerator.java\n+++ b/hudi-integ-test/src/main/java/org/apache/hudi/integ/testsuite/generator/GenericRecordFullPayloadGenerator.java\n", "chunk": "@@ -284,7 +298,7 @@ public class GenericRecordFullPayloadGenerator implements Serializable {\n   private Object generateFixedType(Schema localSchema) {\n     // TODO: Need to implement valid data generation for fixed type\n     GenericFixed genericFixed = new GenericData.Fixed(localSchema);\n-    switch (localSchema.getType().getName()) {\n+    switch (localSchema.getLogicalType().getName()) {\n       case UUID_NAME:\n         ((Fixed) genericFixed).bytes(UUID.randomUUID().toString().getBytes());\n         return genericFixed;\n", "next_change": null}]}}, {"oid": "98c3c7ddf879d514e5c14293fee145c92f9416a3", "url": "https://github.com/apache/hudi/commit/98c3c7ddf879d514e5c14293fee145c92f9416a3", "message": "Addresing code review comments", "committedDate": "2021-01-03T08:40:52Z", "type": "forcePushed"}, {"oid": "32df18ea69b24a19cda150875cdc636075544589", "url": "https://github.com/apache/hudi/commit/32df18ea69b24a19cda150875cdc636075544589", "message": "Addresing code review comments", "committedDate": "2021-01-05T05:43:36Z", "type": "forcePushed"}, {"oid": "d81016bdc87968e58e1fcd8809b65000b1a64ff5", "url": "https://github.com/apache/hudi/commit/d81016bdc87968e58e1fcd8809b65000b1a64ff5", "message": "Addresing code review comments", "committedDate": "2021-01-05T05:58:50Z", "type": "forcePushed"}, {"oid": "21792c6722dd32dddbc5b6ec743549610cd9a8e0", "url": "https://github.com/apache/hudi/commit/21792c6722dd32dddbc5b6ec743549610cd9a8e0", "message": "Addresing code review comments", "committedDate": "2021-01-05T08:20:25Z", "type": "forcePushed"}, {"oid": "7f975c1dbae58d16c244968b2d7ebaae5f3f99ac", "url": "https://github.com/apache/hudi/commit/7f975c1dbae58d16c244968b2d7ebaae5f3f99ac", "message": "Addresing code review comments", "committedDate": "2021-01-08T08:08:13Z", "type": "forcePushed"}, {"oid": "57de565ef4bb6ea4386e80fb20d39eeb8dd96455", "url": "https://github.com/apache/hudi/commit/57de565ef4bb6ea4386e80fb20d39eeb8dd96455", "message": "Addresing code review comments and other refactoring", "committedDate": "2021-01-19T05:18:21Z", "type": "forcePushed"}, {"oid": "ccc5f9a486b3cb3829359339d858c2dc827e84b9", "url": "https://github.com/apache/hudi/commit/ccc5f9a486b3cb3829359339d858c2dc827e84b9", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution", "committedDate": "2021-01-19T05:19:50Z", "type": "forcePushed"}, {"oid": "15157b355d6e977f06c705097eecb22bbd415752", "url": "https://github.com/apache/hudi/commit/15157b355d6e977f06c705097eecb22bbd415752", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services", "committedDate": "2021-01-19T05:27:44Z", "type": "forcePushed"}, {"oid": "3a462df23a85a66d9e2237ea9d20a47815f1becb", "url": "https://github.com/apache/hudi/commit/3a462df23a85a66d9e2237ea9d20a47815f1becb", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services", "committedDate": "2021-01-19T07:32:22Z", "type": "forcePushed"}, {"oid": "8750225e15ade84d4182cbf4c2966cccf6f78c70", "url": "https://github.com/apache/hudi/commit/8750225e15ade84d4182cbf4c2966cccf6f78c70", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services", "committedDate": "2021-01-20T09:08:57Z", "type": "forcePushed"}, {"oid": "97180d4ab0c6c988aa95ac566f63d249dbdbb2dd", "url": "https://github.com/apache/hudi/commit/97180d4ab0c6c988aa95ac566f63d249dbdbb2dd", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services", "committedDate": "2021-01-20T18:03:23Z", "type": "forcePushed"}, {"oid": "7ababeac2cb1c0735a3dff9434522b99fa4f1580", "url": "https://github.com/apache/hudi/commit/7ababeac2cb1c0735a3dff9434522b99fa4f1580", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services", "committedDate": "2021-01-21T05:29:04Z", "type": "forcePushed"}, {"oid": "8b8d5945136066148f200d30c5d3bf6d5be70cbf", "url": "https://github.com/apache/hudi/commit/8b8d5945136066148f200d30c5d3bf6d5be70cbf", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services", "committedDate": "2021-01-21T19:37:14Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg0MTIxMQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r568841211", "bodyText": "how about empty instead of null. In general, like to avoid using null for any kind of sentinel", "author": "vinothchandar", "createdAt": "2021-02-02T18:39:08Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -188,6 +203,8 @@ public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Opti\n       postCommit(table, metadata, instantTime, extraMetadata);\n       emitCommitMetrics(instantTime, metadata, commitActionType);\n       LOG.info(\"Committed \" + instantTime);\n+      // Reset the last completed write instant\n+      latestCompletedWriteInstant.set(null);", "originalCommit": "8b8d5945136066148f200d30c5d3bf6d5be70cbf", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 64cc5e5f0..ea6c6f81a 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -189,25 +181,21 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n   public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n                              String commitActionType, Map<String, List<String>> partitionToReplaceFileIds, HoodieCommitMetadata metadata) {\n-    LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n-    // Create a Hoodie table which encapsulated the commits and files visible\n-    HoodieTable table = createTable(config, hadoopConf);\n-\n-    HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n-    // Finalize write\n-    finalizeWrite(table, instantTime, stats);\n-\n     try {\n-      activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n-          Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n+      // Create a Hoodie table which encapsulated the commits and files visible\n+      HoodieTable table = createTable(config, hadoopConf);\n+      this.txnManager.startTransaction();\n+      this.txnManager.setTransactionInstant(Option.of(new HoodieInstant(HoodieInstant.State.INFLIGHT, commitActionType, instantTime)));\n+      commit(table, commitActionType, instantTime, metadata, stats);\n+      this.txnManager.endTransaction();\n       postCommit(table, metadata, instantTime, extraMetadata);\n       emitCommitMetrics(instantTime, metadata, commitActionType);\n       LOG.info(\"Committed \" + instantTime);\n-      // Reset the last completed write instant\n-      latestCompletedWriteInstant.set(null);\n     } catch (IOException e) {\n       throw new HoodieCommitException(\"Failed to complete commit \" + config.getBasePath() + \" at time \" + instantTime,\n           e);\n+    } finally {\n+      this.txnManager.endTransaction();\n     }\n \n     // callback if needed.\n", "next_change": {"commit": "49dec09bfb444866e678fe956b28c3bf0ad2f373", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ea6c6f81a..4c1f5bf3c 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -181,13 +179,12 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n   public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n                              String commitActionType, Map<String, List<String>> partitionToReplaceFileIds, HoodieCommitMetadata metadata) {\n+    // Create a Hoodie table which encapsulated the commits and files visible\n+    HoodieTable table = createTable(config, hadoopConf);\n+    this.txnManager.beginTransaction();\n     try {\n-      // Create a Hoodie table which encapsulated the commits and files visible\n-      HoodieTable table = createTable(config, hadoopConf);\n-      this.txnManager.startTransaction();\n-      this.txnManager.setTransactionInstant(Option.of(new HoodieInstant(HoodieInstant.State.INFLIGHT, commitActionType, instantTime)));\n+      this.txnManager.setTransactionOwner(Option.of(new HoodieInstant(HoodieInstant.State.INFLIGHT, commitActionType, instantTime)));\n       commit(table, commitActionType, instantTime, metadata, stats);\n-      this.txnManager.endTransaction();\n       postCommit(table, metadata, instantTime, extraMetadata);\n       emitCommitMetrics(instantTime, metadata, commitActionType);\n       LOG.info(\"Committed \" + instantTime);\n", "next_change": {"commit": "8f2bd5f5539fa72267c4c73c03068e9384df646f", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 4c1f5bf3c..797dcb20f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -183,7 +183,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieTable table = createTable(config, hadoopConf);\n     this.txnManager.beginTransaction();\n     try {\n-      this.txnManager.setTransactionOwner(Option.of(new HoodieInstant(HoodieInstant.State.INFLIGHT, commitActionType, instantTime)));\n       commit(table, commitActionType, instantTime, metadata, stats);\n       postCommit(table, metadata, instantTime, extraMetadata);\n       emitCommitMetrics(instantTime, metadata, commitActionType);\n", "next_change": {"commit": "289e45a28da6b91fba2a824ec2af3771a34b2930", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 797dcb20f..3b9e08dd3 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -178,9 +169,14 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n   }\n \n   public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n-                             String commitActionType, Map<String, List<String>> partitionToReplaceFileIds, HoodieCommitMetadata metadata) {\n+                             String commitActionType, Map<String, List<String>> partitionToReplaceFileIds) {\n     // Create a Hoodie table which encapsulated the commits and files visible\n     HoodieTable table = createTable(config, hadoopConf);\n+    HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n+    HoodieCommitMetadata metadata = CommitUtils.buildMetadata(stats, partitionToReplaceFileIds, extraMetadata, operationType, config.getSchema(), commitActionType);\n+    // Finalize write\n+    finalizeWrite(table, instantTime, stats);\n+    HeartbeatUtils.abortIfHeartbeatExpired(instantTime, table, heartbeatClient, config);\n     this.txnManager.beginTransaction();\n     try {\n       commit(table, commitActionType, instantTime, metadata, stats);\n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 3b9e08dd3..12c55370f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -179,6 +179,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HeartbeatUtils.abortIfHeartbeatExpired(instantTime, table, heartbeatClient, config);\n     this.txnManager.beginTransaction();\n     try {\n+      preCommit(instantTime, metadata);\n       commit(table, commitActionType, instantTime, metadata, stats);\n       postCommit(table, metadata, instantTime, extraMetadata);\n       emitCommitMetrics(instantTime, metadata, commitActionType);\n", "next_change": {"commit": "45e931ec410685bcc1ec8dd974560add27dac684", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 12c55370f..5ab836ee7 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -177,7 +177,8 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n     HeartbeatUtils.abortIfHeartbeatExpired(instantTime, table, heartbeatClient, config);\n-    this.txnManager.beginTransaction();\n+    this.txnManager.beginTransaction(Option.of(new HoodieInstant(State.INFLIGHT, table.getMetaClient().getCommitActionType(), instantTime)),\n+        table.getMetaClient().getActiveTimeline().getCommitsTimeline().filterCompletedInstants().lastInstant());\n     try {\n       preCommit(instantTime, metadata);\n       commit(table, commitActionType, instantTime, metadata, stats);\n", "next_change": {"commit": "1b522ef9c2fec7a32c7a1bfae2039e8f07a60d8f", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 5ab836ee7..f663e64d4 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -178,7 +180,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     finalizeWrite(table, instantTime, stats);\n     HeartbeatUtils.abortIfHeartbeatExpired(instantTime, table, heartbeatClient, config);\n     this.txnManager.beginTransaction(Option.of(new HoodieInstant(State.INFLIGHT, table.getMetaClient().getCommitActionType(), instantTime)),\n-        table.getMetaClient().getActiveTimeline().getCommitsTimeline().filterCompletedInstants().lastInstant());\n+        lastCompletedTxn);\n     try {\n       preCommit(instantTime, metadata);\n       commit(table, commitActionType, instantTime, metadata, stats);\n", "next_change": {"commit": "1886bbd803f1a51e3d261705dd1283cfa8caf06b", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex f663e64d4..80e79155b 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -180,7 +180,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     finalizeWrite(table, instantTime, stats);\n     HeartbeatUtils.abortIfHeartbeatExpired(instantTime, table, heartbeatClient, config);\n     this.txnManager.beginTransaction(Option.of(new HoodieInstant(State.INFLIGHT, table.getMetaClient().getCommitActionType(), instantTime)),\n-        lastCompletedTxn);\n+        lastCompletedTxnAndMetadata.isPresent() ? Option.of(lastCompletedTxnAndMetadata.get().getLeft()) : Option.empty());\n     try {\n       preCommit(instantTime, metadata);\n       commit(table, commitActionType, instantTime, metadata, stats);\n", "next_change": {"commit": "9278889bad4fe529a7c403857f20bcd0198322e6", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 80e79155b..096e644df 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -184,16 +184,14 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     try {\n       preCommit(instantTime, metadata);\n       commit(table, commitActionType, instantTime, metadata, stats);\n-      postCommit(table, metadata, instantTime, extraMetadata);\n-      emitCommitMetrics(instantTime, metadata, commitActionType);\n       LOG.info(\"Committed \" + instantTime);\n     } catch (IOException e) {\n-      throw new HoodieCommitException(\"Failed to complete commit \" + config.getBasePath() + \" at time \" + instantTime,\n-          e);\n+      throw new HoodieCommitException(\"Failed to complete commit \" + config.getBasePath() + \" at time \" + instantTime, e);\n     } finally {\n       this.txnManager.endTransaction();\n     }\n-\n+    postCommit(table, metadata, instantTime, extraMetadata);\n+    emitCommitMetrics(instantTime, metadata, commitActionType);\n     // callback if needed.\n     if (config.writeCommitCallbackOn()) {\n       if (null == commitCallback) {\n", "next_change": {"commit": "461047d03e9b7b73b34536ccf290a24f4aada6b0", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 096e644df..656b209e7 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -180,18 +179,20 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     finalizeWrite(table, instantTime, stats);\n     HeartbeatUtils.abortIfHeartbeatExpired(instantTime, table, heartbeatClient, config);\n     this.txnManager.beginTransaction(Option.of(new HoodieInstant(State.INFLIGHT, table.getMetaClient().getCommitActionType(), instantTime)),\n-        lastCompletedTxnAndMetadata.isPresent() ? Option.of(lastCompletedTxnAndMetadata.get().getLeft()) : Option.empty());\n+        lastCompletedTxn);\n     try {\n       preCommit(instantTime, metadata);\n       commit(table, commitActionType, instantTime, metadata, stats);\n+      postCommit(table, metadata, instantTime, extraMetadata);\n+      emitCommitMetrics(instantTime, metadata, commitActionType);\n       LOG.info(\"Committed \" + instantTime);\n     } catch (IOException e) {\n-      throw new HoodieCommitException(\"Failed to complete commit \" + config.getBasePath() + \" at time \" + instantTime, e);\n+      throw new HoodieCommitException(\"Failed to complete commit \" + config.getBasePath() + \" at time \" + instantTime,\n+          e);\n     } finally {\n       this.txnManager.endTransaction();\n     }\n-    postCommit(table, metadata, instantTime, extraMetadata);\n-    emitCommitMetrics(instantTime, metadata, commitActionType);\n+\n     // callback if needed.\n     if (config.writeCommitCallbackOn()) {\n       if (null == commitCallback) {\n", "next_change": {"commit": "a466320b7537bf2862df853344e80fbd0be6d16a", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 656b209e7..096e644df 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -179,20 +180,18 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     finalizeWrite(table, instantTime, stats);\n     HeartbeatUtils.abortIfHeartbeatExpired(instantTime, table, heartbeatClient, config);\n     this.txnManager.beginTransaction(Option.of(new HoodieInstant(State.INFLIGHT, table.getMetaClient().getCommitActionType(), instantTime)),\n-        lastCompletedTxn);\n+        lastCompletedTxnAndMetadata.isPresent() ? Option.of(lastCompletedTxnAndMetadata.get().getLeft()) : Option.empty());\n     try {\n       preCommit(instantTime, metadata);\n       commit(table, commitActionType, instantTime, metadata, stats);\n-      postCommit(table, metadata, instantTime, extraMetadata);\n-      emitCommitMetrics(instantTime, metadata, commitActionType);\n       LOG.info(\"Committed \" + instantTime);\n     } catch (IOException e) {\n-      throw new HoodieCommitException(\"Failed to complete commit \" + config.getBasePath() + \" at time \" + instantTime,\n-          e);\n+      throw new HoodieCommitException(\"Failed to complete commit \" + config.getBasePath() + \" at time \" + instantTime, e);\n     } finally {\n       this.txnManager.endTransaction();\n     }\n-\n+    postCommit(table, metadata, instantTime, extraMetadata);\n+    emitCommitMetrics(instantTime, metadata, commitActionType);\n     // callback if needed.\n     if (config.writeCommitCallbackOn()) {\n       if (null == commitCallback) {\n", "next_change": {"commit": "8c092be25de58e65cd339478e9b2c0ba37d20e5e", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 096e644df..da2430225 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -184,13 +184,15 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     try {\n       preCommit(instantTime, metadata);\n       commit(table, commitActionType, instantTime, metadata, stats);\n+      postCommit(table, metadata, instantTime, extraMetadata);\n       LOG.info(\"Committed \" + instantTime);\n     } catch (IOException e) {\n       throw new HoodieCommitException(\"Failed to complete commit \" + config.getBasePath() + \" at time \" + instantTime, e);\n     } finally {\n       this.txnManager.endTransaction();\n     }\n-    postCommit(table, metadata, instantTime, extraMetadata);\n+    // do this outside of lock since compaction, clustering can be time taking and holds lock for longer period of time\n+    runTableServices(table, metadata, extraMetadata);\n     emitCommitMetrics(instantTime, metadata, commitActionType);\n     // callback if needed.\n     if (config.writeCommitCallbackOn()) {\n", "next_change": {"commit": "bbb02ab5c74551803f8003900d066d056646c951", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex da2430225..1047ede02 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -191,7 +191,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     } finally {\n       this.txnManager.endTransaction();\n     }\n-    // do this outside of lock since compaction, clustering can be time taking and holds lock for longer period of time\n+    // do this outside of lock since compaction, clustering can be time taking and we don't need a lock for the entire execution period\n     runTableServices(table, metadata, extraMetadata);\n     emitCommitMetrics(instantTime, metadata, commitActionType);\n     // callback if needed.\n", "next_change": {"commit": "d47718945d2ad86eb653daafc03f1f74a57b6881", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 1047ede02..edc8dc47a 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -192,7 +192,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n       this.txnManager.endTransaction();\n     }\n     // do this outside of lock since compaction, clustering can be time taking and we don't need a lock for the entire execution period\n-    runTableServices(table, metadata, extraMetadata);\n+    runTableServicesInline(table, metadata, extraMetadata);\n     emitCommitMetrics(instantTime, metadata, commitActionType);\n     // callback if needed.\n     if (config.writeCommitCallbackOn()) {\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg0MjY4Mw==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r568842683", "bodyText": "whats NO_WRITER ? its kind of difficult to understand . can we remove this", "author": "vinothchandar", "createdAt": "2021-02-02T18:41:25Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java", "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.model;\n+\n+import org.apache.hudi.exception.HoodieException;\n+\n+import java.util.Locale;\n+\n+/**\n+ * Different concurrency modes for write operations.\n+ */\n+public enum WriteConcurrencyMode {\n+  NO_WRITER(\"no_writer\"),", "originalCommit": "8b8d5945136066148f200d30c5d3bf6d5be70cbf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTE4OTM5Mw==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r569189393", "bodyText": "Old code, removed.", "author": "n3nash", "createdAt": "2021-02-03T07:39:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg0MjY4Mw=="}], "type": "inlineReview", "revised_code": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java b/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java\nindex 0ad5add3c..835390771 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java\n", "chunk": "@@ -26,7 +26,6 @@ import java.util.Locale;\n  * Different concurrency modes for write operations.\n  */\n public enum WriteConcurrencyMode {\n-  NO_WRITER(\"no_writer\"),\n   // Only a single writer can perform write ops\n   SINGLE_WRITER(\"single_writer\"),\n   // Multiple writer can perform write ops with lazy conflict resolution using locks\n", "next_change": {"commit": "d155914cd673d7699bb5258e6f9cafb85059673a", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java b/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java\nindex 835390771..9fe66ca0a 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java\n", "chunk": "@@ -29,7 +29,7 @@ public enum WriteConcurrencyMode {\n   // Only a single writer can perform write ops\n   SINGLE_WRITER(\"single_writer\"),\n   // Multiple writer can perform write ops with lazy conflict resolution using locks\n-  OPTIMISTIC_CONCURRENCY_CONTROL_SHARED_LOCK(\"optimistic_concurrency_control_shared_lock\");\n+  OPTIMISTIC_CONCURRENCY_CONTROL(\"optimistic_concurrency_control\");\n \n   private final String value;\n \n", "next_change": null}]}}, {"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java b/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java\nindex 0ad5add3c..835390771 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java\n", "chunk": "@@ -51,8 +50,6 @@ public enum WriteConcurrencyMode {\n    */\n   public static WriteConcurrencyMode fromValue(String value) {\n     switch (value.toLowerCase(Locale.ROOT)) {\n-      case \"no_writer\":\n-        return NO_WRITER;\n       case \"single_writer\":\n         return SINGLE_WRITER;\n       case \"optimistic_concurrency_control_shared_lock\":\n", "next_change": {"commit": "d155914cd673d7699bb5258e6f9cafb85059673a", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java b/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java\nindex 835390771..9fe66ca0a 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java\n", "chunk": "@@ -52,15 +52,15 @@ public enum WriteConcurrencyMode {\n     switch (value.toLowerCase(Locale.ROOT)) {\n       case \"single_writer\":\n         return SINGLE_WRITER;\n-      case \"optimistic_concurrency_control_shared_lock\":\n-        return OPTIMISTIC_CONCURRENCY_CONTROL_SHARED_LOCK;\n+      case \"optimistic_concurrency_control\":\n+        return OPTIMISTIC_CONCURRENCY_CONTROL;\n       default:\n         throw new HoodieException(\"Invalid value of Type.\");\n     }\n   }\n \n   public boolean supportsOptimisticConcurrencyControl() {\n-    return this == OPTIMISTIC_CONCURRENCY_CONTROL_SHARED_LOCK;\n+    return this == OPTIMISTIC_CONCURRENCY_CONTROL;\n   }\n \n }\n", "next_change": null}]}}, {"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java b/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java\nindex 0ad5add3c..835390771 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java\n", "chunk": "@@ -62,15 +59,8 @@ public enum WriteConcurrencyMode {\n     }\n   }\n \n-  public boolean isMultiWriter() {\n+  public boolean supportsOptimisticConcurrencyControl() {\n     return this == OPTIMISTIC_CONCURRENCY_CONTROL_SHARED_LOCK;\n   }\n \n-  public boolean isSingleWriter() {\n-    return this == SINGLE_WRITER;\n-  }\n-\n-  public boolean isNoWriter() {\n-    return this == NO_WRITER;\n-  }\n }\n", "next_change": {"commit": "d155914cd673d7699bb5258e6f9cafb85059673a", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java b/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java\nindex 835390771..9fe66ca0a 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java\n", "chunk": "@@ -52,15 +52,15 @@ public enum WriteConcurrencyMode {\n     switch (value.toLowerCase(Locale.ROOT)) {\n       case \"single_writer\":\n         return SINGLE_WRITER;\n-      case \"optimistic_concurrency_control_shared_lock\":\n-        return OPTIMISTIC_CONCURRENCY_CONTROL_SHARED_LOCK;\n+      case \"optimistic_concurrency_control\":\n+        return OPTIMISTIC_CONCURRENCY_CONTROL;\n       default:\n         throw new HoodieException(\"Invalid value of Type.\");\n     }\n   }\n \n   public boolean supportsOptimisticConcurrencyControl() {\n-    return this == OPTIMISTIC_CONCURRENCY_CONTROL_SHARED_LOCK;\n+    return this == OPTIMISTIC_CONCURRENCY_CONTROL;\n   }\n \n }\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg0Mzk3Mw==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r568843973", "bodyText": "rename to : supportsOptimisticConcurrencyControl() to match mode name.", "author": "vinothchandar", "createdAt": "2021-02-02T18:43:35Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java", "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.model;\n+\n+import org.apache.hudi.exception.HoodieException;\n+\n+import java.util.Locale;\n+\n+/**\n+ * Different concurrency modes for write operations.\n+ */\n+public enum WriteConcurrencyMode {\n+  NO_WRITER(\"no_writer\"),\n+  // Only a single writer can perform write ops\n+  SINGLE_WRITER(\"single_writer\"),\n+  // Multiple writer can perform write ops with lazy conflict resolution using locks\n+  OPTIMISTIC_CONCURRENCY_CONTROL_SHARED_LOCK(\"optimistic_concurrency_control_shared_lock\");\n+\n+  private final String value;\n+\n+  WriteConcurrencyMode(String value) {\n+    this.value = value;\n+  }\n+\n+  /**\n+   * Getter for write concurrency mode.\n+   * @return\n+   */\n+  public String value() {\n+    return value;\n+  }\n+\n+  /**\n+   * Convert string value to WriteConcurrencyMode.\n+   */\n+  public static WriteConcurrencyMode fromValue(String value) {\n+    switch (value.toLowerCase(Locale.ROOT)) {\n+      case \"no_writer\":\n+        return NO_WRITER;\n+      case \"single_writer\":\n+        return SINGLE_WRITER;\n+      case \"optimistic_concurrency_control_shared_lock\":\n+        return OPTIMISTIC_CONCURRENCY_CONTROL_SHARED_LOCK;\n+      default:\n+        throw new HoodieException(\"Invalid value of Type.\");\n+    }\n+  }\n+\n+  public boolean isMultiWriter() {", "originalCommit": "8b8d5945136066148f200d30c5d3bf6d5be70cbf", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java b/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java\nindex 0ad5add3c..835390771 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java\n", "chunk": "@@ -26,7 +26,6 @@ import java.util.Locale;\n  * Different concurrency modes for write operations.\n  */\n public enum WriteConcurrencyMode {\n-  NO_WRITER(\"no_writer\"),\n   // Only a single writer can perform write ops\n   SINGLE_WRITER(\"single_writer\"),\n   // Multiple writer can perform write ops with lazy conflict resolution using locks\n", "next_change": {"commit": "d155914cd673d7699bb5258e6f9cafb85059673a", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java b/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java\nindex 835390771..9fe66ca0a 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java\n", "chunk": "@@ -29,7 +29,7 @@ public enum WriteConcurrencyMode {\n   // Only a single writer can perform write ops\n   SINGLE_WRITER(\"single_writer\"),\n   // Multiple writer can perform write ops with lazy conflict resolution using locks\n-  OPTIMISTIC_CONCURRENCY_CONTROL_SHARED_LOCK(\"optimistic_concurrency_control_shared_lock\");\n+  OPTIMISTIC_CONCURRENCY_CONTROL(\"optimistic_concurrency_control\");\n \n   private final String value;\n \n", "next_change": null}]}}, {"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java b/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java\nindex 0ad5add3c..835390771 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java\n", "chunk": "@@ -51,8 +50,6 @@ public enum WriteConcurrencyMode {\n    */\n   public static WriteConcurrencyMode fromValue(String value) {\n     switch (value.toLowerCase(Locale.ROOT)) {\n-      case \"no_writer\":\n-        return NO_WRITER;\n       case \"single_writer\":\n         return SINGLE_WRITER;\n       case \"optimistic_concurrency_control_shared_lock\":\n", "next_change": {"commit": "d155914cd673d7699bb5258e6f9cafb85059673a", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java b/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java\nindex 835390771..9fe66ca0a 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java\n", "chunk": "@@ -52,15 +52,15 @@ public enum WriteConcurrencyMode {\n     switch (value.toLowerCase(Locale.ROOT)) {\n       case \"single_writer\":\n         return SINGLE_WRITER;\n-      case \"optimistic_concurrency_control_shared_lock\":\n-        return OPTIMISTIC_CONCURRENCY_CONTROL_SHARED_LOCK;\n+      case \"optimistic_concurrency_control\":\n+        return OPTIMISTIC_CONCURRENCY_CONTROL;\n       default:\n         throw new HoodieException(\"Invalid value of Type.\");\n     }\n   }\n \n   public boolean supportsOptimisticConcurrencyControl() {\n-    return this == OPTIMISTIC_CONCURRENCY_CONTROL_SHARED_LOCK;\n+    return this == OPTIMISTIC_CONCURRENCY_CONTROL;\n   }\n \n }\n", "next_change": null}]}}, {"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java b/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java\nindex 0ad5add3c..835390771 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java\n", "chunk": "@@ -62,15 +59,8 @@ public enum WriteConcurrencyMode {\n     }\n   }\n \n-  public boolean isMultiWriter() {\n+  public boolean supportsOptimisticConcurrencyControl() {\n     return this == OPTIMISTIC_CONCURRENCY_CONTROL_SHARED_LOCK;\n   }\n \n-  public boolean isSingleWriter() {\n-    return this == SINGLE_WRITER;\n-  }\n-\n-  public boolean isNoWriter() {\n-    return this == NO_WRITER;\n-  }\n }\n", "next_change": {"commit": "d155914cd673d7699bb5258e6f9cafb85059673a", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java b/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java\nindex 835390771..9fe66ca0a 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java\n", "chunk": "@@ -52,15 +52,15 @@ public enum WriteConcurrencyMode {\n     switch (value.toLowerCase(Locale.ROOT)) {\n       case \"single_writer\":\n         return SINGLE_WRITER;\n-      case \"optimistic_concurrency_control_shared_lock\":\n-        return OPTIMISTIC_CONCURRENCY_CONTROL_SHARED_LOCK;\n+      case \"optimistic_concurrency_control\":\n+        return OPTIMISTIC_CONCURRENCY_CONTROL;\n       default:\n         throw new HoodieException(\"Invalid value of Type.\");\n     }\n   }\n \n   public boolean supportsOptimisticConcurrencyControl() {\n-    return this == OPTIMISTIC_CONCURRENCY_CONTROL_SHARED_LOCK;\n+    return this == OPTIMISTIC_CONCURRENCY_CONTROL;\n   }\n \n }\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg0NTEzMw==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r568845133", "bodyText": "lets just add this to an existing class like CommitUtils", "author": "vinothchandar", "createdAt": "2021-02-02T18:45:35Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/util/CommitMetadataUtils.java", "diffHunk": "@@ -0,0 +1,44 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.util;\n+\n+import org.apache.hudi.common.fs.FSUtils;\n+import org.apache.hudi.common.model.HoodieWriteStat;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * Helper class to manipulate commit metadata.\n+ */\n+public class CommitMetadataUtils {", "originalCommit": "8b8d5945136066148f200d30c5d3bf6d5be70cbf", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/util/CommitMetadataUtils.java b/hudi-common/src/main/java/org/apache/hudi/common/util/CommitMetadataUtils.java\ndeleted file mode 100644\nindex 1f9da8f3b..000000000\n--- a/hudi-common/src/main/java/org/apache/hudi/common/util/CommitMetadataUtils.java\n+++ /dev/null\n", "chunk": "@@ -1,44 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *      http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.hudi.common.util;\n-\n-import org.apache.hudi.common.fs.FSUtils;\n-import org.apache.hudi.common.model.HoodieWriteStat;\n-\n-import java.util.HashMap;\n-import java.util.List;\n-import java.util.Map;\n-\n-/**\n- * Helper class to manipulate commit metadata.\n- */\n-public class CommitMetadataUtils {\n-\n-  public static HashMap<String, String> getFileIdWithoutSuffixAndRelativePaths(Map<String, List<HoodieWriteStat>>\n-                                                                            partitionToWriteStats) {\n-    HashMap<String, String> fileIdToPath = new HashMap<>();\n-    // list all partitions paths\n-    for (Map.Entry<String, List<HoodieWriteStat>> entry : partitionToWriteStats.entrySet()) {\n-      for (HoodieWriteStat stat : entry.getValue()) {\n-        fileIdToPath.put(FSUtils.getFileId(stat.getFileId()), stat.getPath());\n-      }\n-    }\n-    return fileIdToPath;\n-  }\n-}\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg0NTUzMg==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r568845532", "bodyText": "should archival be here too?", "author": "vinothchandar", "createdAt": "2021-02-02T18:46:13Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/model/TableService.java", "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.model;\n+\n+import org.apache.hudi.exception.HoodieException;\n+\n+import java.util.Locale;\n+\n+/**\n+ * Supported runtime table services.\n+ */\n+public enum TableService {\n+  COMPACT(\"compact\"),", "originalCommit": "8b8d5945136066148f200d30c5d3bf6d5be70cbf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTE5MTI5NQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r569191295", "bodyText": "It should be, but for each of these table services, we now follow the steps of schedule -> inflight -> complete. Archival doesn't do that right now and we never run archival async (unlike clean), so I haven't added it here. I have refactored the clean actions to do this. Filed a ticket for async archival -> https://issues.apache.org/jira/browse/HUDI-1576", "author": "n3nash", "createdAt": "2021-02-03T07:43:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg0NTUzMg=="}], "type": "inlineReview", "revised_code": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/model/TableService.java b/hudi-common/src/main/java/org/apache/hudi/common/model/TableService.java\nindex 53da99b72..b41b76d72 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/model/TableService.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/model/TableService.java\n", "chunk": "@@ -18,45 +18,24 @@\n \n package org.apache.hudi.common.model;\n \n-import org.apache.hudi.exception.HoodieException;\n-\n-import java.util.Locale;\n+import org.apache.hudi.common.table.timeline.HoodieTimeline;\n \n /**\n  * Supported runtime table services.\n  */\n public enum TableService {\n-  COMPACT(\"compact\"),\n-  CLUSTER(\"cluster\"),\n-  CLEAN(\"clean\");\n-  private final String value;\n-\n-  TableService(String value) {\n-    this.value = value;\n-  }\n-\n-  /**\n-   * Convert string value to TableService.\n-   */\n-  public static TableService fromValue(String value) {\n-    switch (value.toLowerCase(Locale.ROOT)) {\n-      case \"cluster\":\n-        return CLUSTER;\n-      case \"compact\":\n-        return COMPACT;\n-      case \"clean\":\n-        return CLEAN;\n+  COMPACT, CLUSTER, CLEAN;\n+\n+  public String getAction() {\n+    switch (this) {\n+      case COMPACT:\n+        return HoodieTimeline.COMPACTION_ACTION;\n+      case CLEAN:\n+        return HoodieTimeline.CLEAN_ACTION;\n+      case CLUSTER:\n+        return HoodieTimeline.REPLACE_COMMIT_ACTION;\n       default:\n-        throw new HoodieException(\"Invalid value of TableService.\");\n+        throw new IllegalArgumentException(\"Unknown table service \" + this);\n     }\n   }\n-\n-  /**\n-   * Getter for value.\n-   * @return string form of TableService\n-   */\n-  public String value() {\n-    return value;\n-  }\n-\n }\n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/model/TableService.java b/hudi-common/src/main/java/org/apache/hudi/common/model/TableServiceType.java\nsimilarity index 97%\nrename from hudi-common/src/main/java/org/apache/hudi/common/model/TableService.java\nrename to hudi-common/src/main/java/org/apache/hudi/common/model/TableServiceType.java\nindex b41b76d72..90444a3d6 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/model/TableService.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/model/TableServiceType.java\n", "chunk": "@@ -23,7 +23,7 @@ import org.apache.hudi.common.table.timeline.HoodieTimeline;\n /**\n  * Supported runtime table services.\n  */\n-public enum TableService {\n+public enum TableServiceType {\n   COMPACT, CLUSTER, CLEAN;\n \n   public String getAction() {\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg0NjIxNg==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r568846216", "bodyText": "rename: Sting name. I actually don't see the need for this field atm now.", "author": "vinothchandar", "createdAt": "2021-02-02T18:47:08Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/model/TableService.java", "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.model;\n+\n+import org.apache.hudi.exception.HoodieException;\n+\n+import java.util.Locale;\n+\n+/**\n+ * Supported runtime table services.\n+ */\n+public enum TableService {\n+  COMPACT(\"compact\"),\n+  CLUSTER(\"cluster\"),\n+  CLEAN(\"clean\");\n+  private final String value;", "originalCommit": "8b8d5945136066148f200d30c5d3bf6d5be70cbf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTE5MTgxMw==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r569191813", "bodyText": "removed", "author": "n3nash", "createdAt": "2021-02-03T07:44:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg0NjIxNg=="}], "type": "inlineReview", "revised_code": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/model/TableService.java b/hudi-common/src/main/java/org/apache/hudi/common/model/TableService.java\nindex 53da99b72..b41b76d72 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/model/TableService.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/model/TableService.java\n", "chunk": "@@ -18,45 +18,24 @@\n \n package org.apache.hudi.common.model;\n \n-import org.apache.hudi.exception.HoodieException;\n-\n-import java.util.Locale;\n+import org.apache.hudi.common.table.timeline.HoodieTimeline;\n \n /**\n  * Supported runtime table services.\n  */\n public enum TableService {\n-  COMPACT(\"compact\"),\n-  CLUSTER(\"cluster\"),\n-  CLEAN(\"clean\");\n-  private final String value;\n-\n-  TableService(String value) {\n-    this.value = value;\n-  }\n-\n-  /**\n-   * Convert string value to TableService.\n-   */\n-  public static TableService fromValue(String value) {\n-    switch (value.toLowerCase(Locale.ROOT)) {\n-      case \"cluster\":\n-        return CLUSTER;\n-      case \"compact\":\n-        return COMPACT;\n-      case \"clean\":\n-        return CLEAN;\n+  COMPACT, CLUSTER, CLEAN;\n+\n+  public String getAction() {\n+    switch (this) {\n+      case COMPACT:\n+        return HoodieTimeline.COMPACTION_ACTION;\n+      case CLEAN:\n+        return HoodieTimeline.CLEAN_ACTION;\n+      case CLUSTER:\n+        return HoodieTimeline.REPLACE_COMMIT_ACTION;\n       default:\n-        throw new HoodieException(\"Invalid value of TableService.\");\n+        throw new IllegalArgumentException(\"Unknown table service \" + this);\n     }\n   }\n-\n-  /**\n-   * Getter for value.\n-   * @return string form of TableService\n-   */\n-  public String value() {\n-    return value;\n-  }\n-\n }\n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/model/TableService.java b/hudi-common/src/main/java/org/apache/hudi/common/model/TableServiceType.java\nsimilarity index 97%\nrename from hudi-common/src/main/java/org/apache/hudi/common/model/TableService.java\nrename to hudi-common/src/main/java/org/apache/hudi/common/model/TableServiceType.java\nindex b41b76d72..90444a3d6 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/model/TableService.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/model/TableServiceType.java\n", "chunk": "@@ -23,7 +23,7 @@ import org.apache.hudi.common.table.timeline.HoodieTimeline;\n /**\n  * Supported runtime table services.\n  */\n-public enum TableService {\n+public enum TableServiceType {\n   COMPACT, CLUSTER, CLEAN;\n \n   public String getAction() {\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg0ODc1MA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r568848750", "bodyText": "lets call this  initIfNeeded. to avoid overloading bootstrap which has its own meaning. .", "author": "vinothchandar", "createdAt": "2021-02-02T18:50:49Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -220,7 +253,7 @@ void emitCommitMetrics(String instantTime, HoodieCommitMetadata metadata, String\n     }\n   }\n \n-  protected void syncTableMetadata() {\n+  protected void syncTableMetadata(boolean bootstrapIfNeeded) {", "originalCommit": "8b8d5945136066148f200d30c5d3bf6d5be70cbf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTE5Mjc4MQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r569192781", "bodyText": "init also has a different meaning inside the HoodieBackedTableMetadataWriter where init just means initializing the table metadata. How about just bootstrapMetadata ?", "author": "n3nash", "createdAt": "2021-02-03T07:46:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg0ODc1MA=="}], "type": "inlineReview", "revised_code": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 64cc5e5f0..ea6c6f81a 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -253,7 +254,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     }\n   }\n \n-  protected void syncTableMetadata(boolean bootstrapIfNeeded) {\n+  protected void syncTableMetadata(boolean bootstrapMetadata) {\n     // no-op\n   }\n \n", "next_change": {"commit": "f5a56cb4137b5f32af17405277c29d5a9088b6c7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ea6c6f81a..d45d77154 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -254,6 +248,11 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     }\n   }\n \n+  protected void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n+    // no-op\n+    // TODO : Conflict resolution is not support for Flink,Java engines\n+  }\n+\n   protected void syncTableMetadata(boolean bootstrapMetadata) {\n     // no-op\n   }\n", "next_change": {"commit": "0552abcc6400675c11ee35a4d4f3df109463f6f5", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex d45d77154..f0ebc54f7 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -253,7 +249,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     // TODO : Conflict resolution is not support for Flink,Java engines\n   }\n \n-  protected void syncTableMetadata(boolean bootstrapMetadata) {\n+  protected void syncTableMetadata() {\n     // no-op\n   }\n \n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex f0ebc54f7..12c55370f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -246,7 +233,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n   protected void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n     // no-op\n-    // TODO : Conflict resolution is not support for Flink,Java engines\n+    // TODO : Conflict resolution is not supported for Flink & Java engines\n   }\n \n   protected void syncTableMetadata() {\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg1MDA4NA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r568850084", "bodyText": "Do we need this check with OCC mode? in any case, we should ensure the bootstrap code downgrades to single writer, so users don't have to worry about this. Most people do bootstrap then followed by writing anyway.", "author": "vinothchandar", "createdAt": "2021-02-02T18:52:59Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -239,6 +272,9 @@ public void bootstrap(Option<Map<String, String>> extraMetadata) {\n     if (rollbackPending) {\n       rollBackInflightBootstrap();\n     }\n+    if (config.getWriteConcurrencyMode().isMultiWriter()) {", "originalCommit": "8b8d5945136066148f200d30c5d3bf6d5be70cbf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTk3ODQ3NA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r569978474", "bodyText": "Right now, we don't have multi-writer so people might remain cautious. Once we support multiwriter, it's easy to set one config and run bootstrap/incremental, guarding against such behaviors.\nRight now, do we have a way to enforce users to downgrade to a single writer ?", "author": "n3nash", "createdAt": "2021-02-04T06:36:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg1MDA4NA=="}], "type": "inlineReview", "revised_code": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 64cc5e5f0..ea6c6f81a 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -272,7 +273,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     if (rollbackPending) {\n       rollBackInflightBootstrap();\n     }\n-    if (config.getWriteConcurrencyMode().isMultiWriter()) {\n+    if (config.getWriteConcurrencyMode().supportsOptimisticConcurrencyControl()) {\n       throw new HoodieException(\"Cannot bootstrap the table in multi-writer mode\");\n     }\n     HoodieTable<T, I, K, O> table = getTableAndInitCtx(WriteOperationType.UPSERT, HoodieTimeline.METADATA_BOOTSTRAP_INSTANT_TS);\n", "next_change": {"commit": "289e45a28da6b91fba2a824ec2af3771a34b2930", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ea6c6f81a..3b9e08dd3 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -270,20 +252,19 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n    * Main API to run bootstrap to hudi.\n    */\n   public void bootstrap(Option<Map<String, String>> extraMetadata) {\n-    if (rollbackPending) {\n-      rollBackInflightBootstrap();\n-    }\n+    // TODO : MULTIWRITER -> check if failed bootstrap files can be cleaned later\n     if (config.getWriteConcurrencyMode().supportsOptimisticConcurrencyControl()) {\n       throw new HoodieException(\"Cannot bootstrap the table in multi-writer mode\");\n     }\n     HoodieTable<T, I, K, O> table = getTableAndInitCtx(WriteOperationType.UPSERT, HoodieTimeline.METADATA_BOOTSTRAP_INSTANT_TS);\n+    rollbackFailedBootstrap();\n     table.bootstrap(context, extraMetadata);\n   }\n \n   /**\n-   * Main API to rollback pending bootstrap.\n+   * Main API to rollback failed bootstrap.\n    */\n-  protected void rollBackInflightBootstrap() {\n+  public void rollbackFailedBootstrap() {\n     LOG.info(\"Rolling back pending bootstrap if present\");\n     HoodieTable<T, I, K, O> table = createTable(config, hadoopConf);\n     HoodieTimeline inflightTimeline = table.getMetaClient().getCommitsTimeline().filterPendingExcludingCompaction();\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg1MDM0OA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r568850348", "bodyText": "just double check if the indents are okay here?", "author": "vinothchandar", "createdAt": "2021-02-02T18:53:26Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -403,30 +439,32 @@ protected void postCommit(HoodieTable<T, I, K, O> table, HoodieCommitMetadata me\n       // Delete the marker directory for the instant.\n       new MarkerFiles(table, instantTime).quietDeleteMarkerDir(context, config.getMarkersDeleteParallelism());\n \n-      // Do an inline compaction if enabled\n-      if (config.isInlineCompaction()) {\n-        runAnyPendingCompactions(table);\n-        metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"true\");\n-        inlineCompact(extraMetadata);\n-      } else {\n-        metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"false\");\n-      }\n+      if (config.isInlineTableServiceEnabled()) {\n+        // Do an inline compaction if enabled\n+        if (config.isInlineCompaction()) {\n+          runAnyPendingCompactions(table);\n+          metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"true\");\n+          inlineCompact(extraMetadata);\n+        } else {\n+          metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"false\");\n+        }\n \n-      // Do an inline clustering if enabled\n-      if (config.isInlineClustering()) {\n-        runAnyPendingClustering(table);\n-        metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"true\");\n-        inlineCluster(extraMetadata);\n-      } else {\n-        metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n-      }\n+        // Do an inline clustering if enabled", "originalCommit": "8b8d5945136066148f200d30c5d3bf6d5be70cbf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTE5MzgxNQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r569193815", "bodyText": "Intellij says ok, not sure why it's appearing this way here", "author": "n3nash", "createdAt": "2021-02-03T07:48:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg1MDM0OA=="}], "type": "inlineReview", "revised_code": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 64cc5e5f0..ea6c6f81a 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -439,9 +440,9 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n       // Delete the marker directory for the instant.\n       new MarkerFiles(table, instantTime).quietDeleteMarkerDir(context, config.getMarkersDeleteParallelism());\n \n-      if (config.isInlineTableServiceEnabled()) {\n+      if (config.inlineTableServices()) {\n         // Do an inline compaction if enabled\n-        if (config.isInlineCompaction()) {\n+        if (config.inlineCompactionEnabled()) {\n           runAnyPendingCompactions(table);\n           metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"true\");\n           inlineCompact(extraMetadata);\n", "next_change": {"commit": "8c092be25de58e65cd339478e9b2c0ba37d20e5e", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ea6c6f81a..da2430225 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -436,45 +424,44 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n    */\n   protected void postCommit(HoodieTable<T, I, K, O> table, HoodieCommitMetadata metadata, String instantTime, Option<Map<String, String>> extraMetadata) {\n     try {\n-\n       // Delete the marker directory for the instant.\n       new MarkerFiles(table, instantTime).quietDeleteMarkerDir(context, config.getMarkersDeleteParallelism());\n+      // We cannot have unbounded commit files. Archive commits if we have to archive\n+      HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(config, table);\n+      archiveLog.archiveIfRequired(context);\n+      autoCleanOnCommit();\n+      syncTableMetadata();\n+    } catch (IOException ioe) {\n+      throw new HoodieIOException(ioe.getMessage(), ioe);\n+    } finally {\n+      this.heartbeatClient.stop(instantTime);\n+    }\n+  }\n \n-      if (config.inlineTableServices()) {\n-        // Do an inline compaction if enabled\n-        if (config.inlineCompactionEnabled()) {\n-          runAnyPendingCompactions(table);\n-          metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"true\");\n-          inlineCompact(extraMetadata);\n-        } else {\n-          metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"false\");\n-        }\n-\n-        // Do an inline clustering if enabled\n-        if (config.inlineClusteringEnabled()) {\n-          runAnyPendingClustering(table);\n-          metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"true\");\n-          inlineCluster(extraMetadata);\n-        } else {\n-          metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n-        }\n-\n-        // We cannot have unbounded commit files. Archive commits if we have to archive\n-        HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(config, table);\n-        archiveLog.archiveIfRequired(context);\n-        if (config.isAutoClean() || config.inlineCleaningEnabled()) {\n-          autoCleanOnCommit();\n-        }\n+  protected void runTableServices(HoodieTable<T, I, K, O> table, HoodieCommitMetadata metadata, Option<Map<String, String>> extraMetadata) {\n+    if (config.inlineTableServices()) {\n+      // Do an inline compaction if enabled\n+      if (config.inlineCompactionEnabled()) {\n+        runAnyPendingCompactions(table);\n+        metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"true\");\n+        inlineCompact(extraMetadata);\n+      } else {\n+        metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"false\");\n       }\n \n-      syncTableMetadata(true);\n-    } catch (IOException ioe) {\n-      throw new HoodieIOException(ioe.getMessage(), ioe);\n+      // Do an inline clustering if enabled\n+      if (config.inlineClusteringEnabled()) {\n+        runAnyPendingClustering(table);\n+        metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"true\");\n+        inlineCluster(extraMetadata);\n+      } else {\n+        metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n+      }\n     }\n   }\n \n   protected void runAnyPendingCompactions(HoodieTable<T, I, K, O> table) {\n-    table.getActiveTimeline().getCommitsAndCompactionTimeline().filterPendingCompactionTimeline().getInstants()\n+    table.getActiveTimeline().getWriteTimeline().filterPendingCompactionTimeline().getInstants()\n         .forEach(instant -> {\n           LOG.info(\"Running previously failed inflight compaction at instant \" + instant);\n           compact(instant.getTimestamp(), true);\n", "next_change": {"commit": "d47718945d2ad86eb653daafc03f1f74a57b6881", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex da2430225..edc8dc47a 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -438,7 +438,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     }\n   }\n \n-  protected void runTableServices(HoodieTable<T, I, K, O> table, HoodieCommitMetadata metadata, Option<Map<String, String>> extraMetadata) {\n+  protected void runTableServicesInline(HoodieTable<T, I, K, O> table, HoodieCommitMetadata metadata, Option<Map<String, String>> extraMetadata) {\n     if (config.inlineTableServices()) {\n       // Do an inline compaction if enabled\n       if (config.inlineCompactionEnabled()) {\n", "next_change": null}]}}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 64cc5e5f0..ea6c6f81a 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -450,7 +451,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n         }\n \n         // Do an inline clustering if enabled\n-        if (config.isInlineClustering()) {\n+        if (config.inlineClusteringEnabled()) {\n           runAnyPendingClustering(table);\n           metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"true\");\n           inlineCluster(extraMetadata);\n", "next_change": {"commit": "9d857ed63bba87ec2528eb26bae1e69216814bdd", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ea6c6f81a..4835e9438 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -457,6 +463,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n           inlineCluster(extraMetadata);\n         } else {\n           metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n+          metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n         }\n \n         // We cannot have unbounded commit files. Archive commits if we have to archive\n", "next_change": {"commit": "289e45a28da6b91fba2a824ec2af3771a34b2930", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 4835e9438..3b9e08dd3 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -465,22 +448,23 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n           metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n           metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n         }\n-\n         // We cannot have unbounded commit files. Archive commits if we have to archive\n         HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(config, table);\n         archiveLog.archiveIfRequired(context);\n         if (config.isAutoClean() || config.inlineCleaningEnabled()) {\n           autoCleanOnCommit();\n         }\n+        syncTableMetadata();\n       }\n-\n     } catch (IOException ioe) {\n       throw new HoodieIOException(ioe.getMessage(), ioe);\n+    } finally {\n+      this.heartbeatClient.stop(instantTime);\n     }\n   }\n \n   protected void runAnyPendingCompactions(HoodieTable<T, I, K, O> table) {\n-    table.getActiveTimeline().getCommitsAndCompactionTimeline().filterPendingCompactionTimeline().getInstants()\n+    table.getActiveTimeline().getWriteTimeline().filterPendingCompactionTimeline().getInstants()\n         .forEach(instant -> {\n           LOG.info(\"Running previously failed inflight compaction at instant \" + instant);\n           compact(instant.getTimestamp(), true);\n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 3b9e08dd3..12c55370f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -446,12 +444,11 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n           inlineCluster(extraMetadata);\n         } else {\n           metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n-          metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n         }\n         // We cannot have unbounded commit files. Archive commits if we have to archive\n         HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(config, table);\n         archiveLog.archiveIfRequired(context);\n-        if (config.isAutoClean() || config.inlineCleaningEnabled()) {\n+        if (config.isAutoClean()) {\n           autoCleanOnCommit();\n         }\n         syncTableMetadata();\n", "next_change": {"commit": "02efbb661e7ed13c3614ddee7ab5157623070f7c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 12c55370f..996648c0e 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -445,14 +445,12 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n         } else {\n           metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n         }\n-        // We cannot have unbounded commit files. Archive commits if we have to archive\n-        HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(config, table);\n-        archiveLog.archiveIfRequired(context);\n-        if (config.isAutoClean()) {\n-          autoCleanOnCommit();\n-        }\n-        syncTableMetadata();\n       }\n+      // We cannot have unbounded commit files. Archive commits if we have to archive\n+      HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(config, table);\n+      archiveLog.archiveIfRequired(context);\n+      autoCleanOnCommit();\n+      syncTableMetadata();\n     } catch (IOException ioe) {\n       throw new HoodieIOException(ioe.getMessage(), ioe);\n     } finally {\n", "next_change": {"commit": "8c092be25de58e65cd339478e9b2c0ba37d20e5e", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 996648c0e..da2430225 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -423,29 +424,8 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n    */\n   protected void postCommit(HoodieTable<T, I, K, O> table, HoodieCommitMetadata metadata, String instantTime, Option<Map<String, String>> extraMetadata) {\n     try {\n-\n       // Delete the marker directory for the instant.\n       new MarkerFiles(table, instantTime).quietDeleteMarkerDir(context, config.getMarkersDeleteParallelism());\n-\n-      if (config.inlineTableServices()) {\n-        // Do an inline compaction if enabled\n-        if (config.inlineCompactionEnabled()) {\n-          runAnyPendingCompactions(table);\n-          metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"true\");\n-          inlineCompact(extraMetadata);\n-        } else {\n-          metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"false\");\n-        }\n-\n-        // Do an inline clustering if enabled\n-        if (config.inlineClusteringEnabled()) {\n-          runAnyPendingClustering(table);\n-          metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"true\");\n-          inlineCluster(extraMetadata);\n-        } else {\n-          metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n-        }\n-      }\n       // We cannot have unbounded commit files. Archive commits if we have to archive\n       HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(config, table);\n       archiveLog.archiveIfRequired(context);\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 996648c0e..da2430225 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -458,6 +438,28 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     }\n   }\n \n+  protected void runTableServices(HoodieTable<T, I, K, O> table, HoodieCommitMetadata metadata, Option<Map<String, String>> extraMetadata) {\n+    if (config.inlineTableServices()) {\n+      // Do an inline compaction if enabled\n+      if (config.inlineCompactionEnabled()) {\n+        runAnyPendingCompactions(table);\n+        metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"true\");\n+        inlineCompact(extraMetadata);\n+      } else {\n+        metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"false\");\n+      }\n+\n+      // Do an inline clustering if enabled\n+      if (config.inlineClusteringEnabled()) {\n+        runAnyPendingClustering(table);\n+        metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"true\");\n+        inlineCluster(extraMetadata);\n+      } else {\n+        metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n+      }\n+    }\n+  }\n+\n   protected void runAnyPendingCompactions(HoodieTable<T, I, K, O> table) {\n     table.getActiveTimeline().getWriteTimeline().filterPendingCompactionTimeline().getInstants()\n         .forEach(instant -> {\n", "next_change": {"commit": "d47718945d2ad86eb653daafc03f1f74a57b6881", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex da2430225..edc8dc47a 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -438,7 +438,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     }\n   }\n \n-  protected void runTableServices(HoodieTable<T, I, K, O> table, HoodieCommitMetadata metadata, Option<Map<String, String>> extraMetadata) {\n+  protected void runTableServicesInline(HoodieTable<T, I, K, O> table, HoodieCommitMetadata metadata, Option<Map<String, String>> extraMetadata) {\n     if (config.inlineTableServices()) {\n       // Do an inline compaction if enabled\n       if (config.inlineCompactionEnabled()) {\n", "next_change": null}]}}]}}]}}]}}]}}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 64cc5e5f0..ea6c6f81a 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -461,7 +462,9 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n         // We cannot have unbounded commit files. Archive commits if we have to archive\n         HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(config, table);\n         archiveLog.archiveIfRequired(context);\n-        autoCleanOnCommit();\n+        if (config.isAutoClean() || config.inlineCleaningEnabled()) {\n+          autoCleanOnCommit();\n+        }\n       }\n \n       syncTableMetadata(true);\n", "next_change": {"commit": "25a4d7f70cc0cfcec115ddfcc2a543a96bcb17af", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ea6c6f81a..063b26db8 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -467,7 +470,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n         }\n       }\n \n-      syncTableMetadata(true);\n     } catch (IOException ioe) {\n       throw new HoodieIOException(ioe.getMessage(), ioe);\n     }\n", "next_change": {"commit": "289e45a28da6b91fba2a824ec2af3771a34b2930", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 063b26db8..3b9e08dd3 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -460,23 +446,25 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n           inlineCluster(extraMetadata);\n         } else {\n           metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n+          metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n         }\n-\n         // We cannot have unbounded commit files. Archive commits if we have to archive\n         HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(config, table);\n         archiveLog.archiveIfRequired(context);\n         if (config.isAutoClean() || config.inlineCleaningEnabled()) {\n           autoCleanOnCommit();\n         }\n+        syncTableMetadata();\n       }\n-\n     } catch (IOException ioe) {\n       throw new HoodieIOException(ioe.getMessage(), ioe);\n+    } finally {\n+      this.heartbeatClient.stop(instantTime);\n     }\n   }\n \n   protected void runAnyPendingCompactions(HoodieTable<T, I, K, O> table) {\n-    table.getActiveTimeline().getCommitsAndCompactionTimeline().filterPendingCompactionTimeline().getInstants()\n+    table.getActiveTimeline().getWriteTimeline().filterPendingCompactionTimeline().getInstants()\n         .forEach(instant -> {\n           LOG.info(\"Running previously failed inflight compaction at instant \" + instant);\n           compact(instant.getTimestamp(), true);\n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 3b9e08dd3..12c55370f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -446,12 +444,11 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n           inlineCluster(extraMetadata);\n         } else {\n           metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n-          metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n         }\n         // We cannot have unbounded commit files. Archive commits if we have to archive\n         HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(config, table);\n         archiveLog.archiveIfRequired(context);\n-        if (config.isAutoClean() || config.inlineCleaningEnabled()) {\n+        if (config.isAutoClean()) {\n           autoCleanOnCommit();\n         }\n         syncTableMetadata();\n", "next_change": {"commit": "02efbb661e7ed13c3614ddee7ab5157623070f7c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 12c55370f..996648c0e 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -445,14 +445,12 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n         } else {\n           metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n         }\n-        // We cannot have unbounded commit files. Archive commits if we have to archive\n-        HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(config, table);\n-        archiveLog.archiveIfRequired(context);\n-        if (config.isAutoClean()) {\n-          autoCleanOnCommit();\n-        }\n-        syncTableMetadata();\n       }\n+      // We cannot have unbounded commit files. Archive commits if we have to archive\n+      HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(config, table);\n+      archiveLog.archiveIfRequired(context);\n+      autoCleanOnCommit();\n+      syncTableMetadata();\n     } catch (IOException ioe) {\n       throw new HoodieIOException(ioe.getMessage(), ioe);\n     } finally {\n", "next_change": {"commit": "8c092be25de58e65cd339478e9b2c0ba37d20e5e", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 996648c0e..da2430225 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -423,29 +424,8 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n    */\n   protected void postCommit(HoodieTable<T, I, K, O> table, HoodieCommitMetadata metadata, String instantTime, Option<Map<String, String>> extraMetadata) {\n     try {\n-\n       // Delete the marker directory for the instant.\n       new MarkerFiles(table, instantTime).quietDeleteMarkerDir(context, config.getMarkersDeleteParallelism());\n-\n-      if (config.inlineTableServices()) {\n-        // Do an inline compaction if enabled\n-        if (config.inlineCompactionEnabled()) {\n-          runAnyPendingCompactions(table);\n-          metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"true\");\n-          inlineCompact(extraMetadata);\n-        } else {\n-          metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"false\");\n-        }\n-\n-        // Do an inline clustering if enabled\n-        if (config.inlineClusteringEnabled()) {\n-          runAnyPendingClustering(table);\n-          metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"true\");\n-          inlineCluster(extraMetadata);\n-        } else {\n-          metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n-        }\n-      }\n       // We cannot have unbounded commit files. Archive commits if we have to archive\n       HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(config, table);\n       archiveLog.archiveIfRequired(context);\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 996648c0e..da2430225 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -458,6 +438,28 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     }\n   }\n \n+  protected void runTableServices(HoodieTable<T, I, K, O> table, HoodieCommitMetadata metadata, Option<Map<String, String>> extraMetadata) {\n+    if (config.inlineTableServices()) {\n+      // Do an inline compaction if enabled\n+      if (config.inlineCompactionEnabled()) {\n+        runAnyPendingCompactions(table);\n+        metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"true\");\n+        inlineCompact(extraMetadata);\n+      } else {\n+        metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"false\");\n+      }\n+\n+      // Do an inline clustering if enabled\n+      if (config.inlineClusteringEnabled()) {\n+        runAnyPendingClustering(table);\n+        metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"true\");\n+        inlineCluster(extraMetadata);\n+      } else {\n+        metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n+      }\n+    }\n+  }\n+\n   protected void runAnyPendingCompactions(HoodieTable<T, I, K, O> table) {\n     table.getActiveTimeline().getWriteTimeline().filterPendingCompactionTimeline().getInstants()\n         .forEach(instant -> {\n", "next_change": {"commit": "d47718945d2ad86eb653daafc03f1f74a57b6881", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex da2430225..edc8dc47a 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -438,7 +438,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     }\n   }\n \n-  protected void runTableServices(HoodieTable<T, I, K, O> table, HoodieCommitMetadata metadata, Option<Map<String, String>> extraMetadata) {\n+  protected void runTableServicesInline(HoodieTable<T, I, K, O> table, HoodieCommitMetadata metadata, Option<Map<String, String>> extraMetadata) {\n     if (config.inlineTableServices()) {\n       // Do an inline compaction if enabled\n       if (config.inlineCompactionEnabled()) {\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg1MTA3MQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r568851071", "bodyText": "why was this change needed", "author": "vinothchandar", "createdAt": "2021-02-02T18:54:32Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -599,6 +637,7 @@ public HoodieRestoreMetadata restoreToInstant(final String instantTime) throws H\n   public HoodieCleanMetadata clean(String cleanInstantTime) throws HoodieIOException {\n     LOG.info(\"Cleaner started\");\n     final Timer.Context timerContext = metrics.getCleanCtx();\n+    scheduleCleaningAtInstant(cleanInstantTime, Option.empty());", "originalCommit": "8b8d5945136066148f200d30c5d3bf6d5be70cbf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTE5NDIyOQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r569194229", "bodyText": "I refactored the code to ensure we follow schedule -> inflight -> complete for clean actions as well.", "author": "n3nash", "createdAt": "2021-02-03T07:48:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg1MTA3MQ=="}], "type": "inlineReview", "revised_code": {"commit": "8f2bd5f5539fa72267c4c73c03068e9384df646f", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 64cc5e5f0..797dcb20f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -635,9 +642,20 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n    * cleaned)\n    */\n   public HoodieCleanMetadata clean(String cleanInstantTime) throws HoodieIOException {\n+    return clean(cleanInstantTime, false);\n+  }\n+\n+  /**\n+   * Clean up any stale/old files/data lying around (either on file storage or index storage) based on the\n+   * configurations and CleaningPolicy used. (typically files that no longer can be used by a running query can be\n+   * cleaned)\n+   */\n+  public HoodieCleanMetadata clean(String cleanInstantTime, boolean scheduleInline) throws HoodieIOException {\n     LOG.info(\"Cleaner started\");\n     final Timer.Context timerContext = metrics.getCleanCtx();\n-    scheduleCleaningAtInstant(cleanInstantTime, Option.empty());\n+    if (scheduleInline) {\n+      scheduleCleaningAtInstant(cleanInstantTime, Option.empty());\n+    }\n     HoodieCleanMetadata metadata = createTable(config, hadoopConf).clean(context, cleanInstantTime);\n     if (timerContext != null && metadata != null) {\n       long durationMs = metrics.getDurationInMs(timerContext.stop());\n", "next_change": {"commit": "93cdfc8b6d57570cca44070d2f2498b25ad16741", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 797dcb20f..633f4a1ec 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -642,20 +644,22 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n    * cleaned)\n    */\n   public HoodieCleanMetadata clean(String cleanInstantTime) throws HoodieIOException {\n-    return clean(cleanInstantTime, false);\n+    return clean(cleanInstantTime, true);\n   }\n \n   /**\n    * Clean up any stale/old files/data lying around (either on file storage or index storage) based on the\n    * configurations and CleaningPolicy used. (typically files that no longer can be used by a running query can be\n-   * cleaned)\n+   * cleaned). This API provides the flexibility to schedule clean instant asynchronously via\n+   * {@link AbstractHoodieWriteClient#scheduleTableService(String, Option, TableService)} and disable inline scheduling\n+   * of clean.\n    */\n   public HoodieCleanMetadata clean(String cleanInstantTime, boolean scheduleInline) throws HoodieIOException {\n-    LOG.info(\"Cleaner started\");\n-    final Timer.Context timerContext = metrics.getCleanCtx();\n     if (scheduleInline) {\n       scheduleCleaningAtInstant(cleanInstantTime, Option.empty());\n     }\n+    LOG.info(\"Cleaner started\");\n+    final Timer.Context timerContext = metrics.getCleanCtx();\n     HoodieCleanMetadata metadata = createTable(config, hadoopConf).clean(context, cleanInstantTime);\n     if (timerContext != null && metadata != null) {\n       long durationMs = metrics.getDurationInMs(timerContext.stop());\n", "next_change": {"commit": "289e45a28da6b91fba2a824ec2af3771a34b2930", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 633f4a1ec..3b9e08dd3 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -660,6 +647,9 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     }\n     LOG.info(\"Cleaner started\");\n     final Timer.Context timerContext = metrics.getCleanCtx();\n+    LOG.info(\"Cleaned failed attempts if any\");\n+    CleanerUtils.rollbackFailedWrites(config.getFailedWritesCleanPolicy(),\n+        HoodieTimeline.CLEAN_ACTION, () -> rollbackFailedWrites());\n     HoodieCleanMetadata metadata = createTable(config, hadoopConf).clean(context, cleanInstantTime);\n     if (timerContext != null && metadata != null) {\n       long durationMs = metrics.getDurationInMs(timerContext.stop());\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg1MTkyMw==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r568851923", "bodyText": "so, this block only enables the inline execution of the table services? or does it also cover the scheduling of cleaning, compaction, clustering etc?", "author": "vinothchandar", "createdAt": "2021-02-02T18:55:43Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -403,30 +439,32 @@ protected void postCommit(HoodieTable<T, I, K, O> table, HoodieCommitMetadata me\n       // Delete the marker directory for the instant.\n       new MarkerFiles(table, instantTime).quietDeleteMarkerDir(context, config.getMarkersDeleteParallelism());\n \n-      // Do an inline compaction if enabled\n-      if (config.isInlineCompaction()) {\n-        runAnyPendingCompactions(table);\n-        metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"true\");\n-        inlineCompact(extraMetadata);\n-      } else {\n-        metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"false\");\n-      }\n+      if (config.isInlineTableServiceEnabled()) {", "originalCommit": "8b8d5945136066148f200d30c5d3bf6d5be70cbf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg1MjMyNw==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r568852327", "bodyText": "We should also protect the scheduling, correct? (may be it comes down the line)", "author": "vinothchandar", "createdAt": "2021-02-02T18:56:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg1MTkyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTE5NjQ4MQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r569196481", "bodyText": "I just wrapped all table services together as inline or async. The scheduling is protected via lock in inline as well as async.", "author": "n3nash", "createdAt": "2021-02-03T07:53:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg1MTkyMw=="}], "type": "inlineReview", "revised_code": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 64cc5e5f0..ea6c6f81a 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -439,9 +440,9 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n       // Delete the marker directory for the instant.\n       new MarkerFiles(table, instantTime).quietDeleteMarkerDir(context, config.getMarkersDeleteParallelism());\n \n-      if (config.isInlineTableServiceEnabled()) {\n+      if (config.inlineTableServices()) {\n         // Do an inline compaction if enabled\n-        if (config.isInlineCompaction()) {\n+        if (config.inlineCompactionEnabled()) {\n           runAnyPendingCompactions(table);\n           metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"true\");\n           inlineCompact(extraMetadata);\n", "next_change": {"commit": "8c092be25de58e65cd339478e9b2c0ba37d20e5e", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ea6c6f81a..da2430225 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -436,45 +424,44 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n    */\n   protected void postCommit(HoodieTable<T, I, K, O> table, HoodieCommitMetadata metadata, String instantTime, Option<Map<String, String>> extraMetadata) {\n     try {\n-\n       // Delete the marker directory for the instant.\n       new MarkerFiles(table, instantTime).quietDeleteMarkerDir(context, config.getMarkersDeleteParallelism());\n+      // We cannot have unbounded commit files. Archive commits if we have to archive\n+      HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(config, table);\n+      archiveLog.archiveIfRequired(context);\n+      autoCleanOnCommit();\n+      syncTableMetadata();\n+    } catch (IOException ioe) {\n+      throw new HoodieIOException(ioe.getMessage(), ioe);\n+    } finally {\n+      this.heartbeatClient.stop(instantTime);\n+    }\n+  }\n \n-      if (config.inlineTableServices()) {\n-        // Do an inline compaction if enabled\n-        if (config.inlineCompactionEnabled()) {\n-          runAnyPendingCompactions(table);\n-          metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"true\");\n-          inlineCompact(extraMetadata);\n-        } else {\n-          metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"false\");\n-        }\n-\n-        // Do an inline clustering if enabled\n-        if (config.inlineClusteringEnabled()) {\n-          runAnyPendingClustering(table);\n-          metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"true\");\n-          inlineCluster(extraMetadata);\n-        } else {\n-          metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n-        }\n-\n-        // We cannot have unbounded commit files. Archive commits if we have to archive\n-        HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(config, table);\n-        archiveLog.archiveIfRequired(context);\n-        if (config.isAutoClean() || config.inlineCleaningEnabled()) {\n-          autoCleanOnCommit();\n-        }\n+  protected void runTableServices(HoodieTable<T, I, K, O> table, HoodieCommitMetadata metadata, Option<Map<String, String>> extraMetadata) {\n+    if (config.inlineTableServices()) {\n+      // Do an inline compaction if enabled\n+      if (config.inlineCompactionEnabled()) {\n+        runAnyPendingCompactions(table);\n+        metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"true\");\n+        inlineCompact(extraMetadata);\n+      } else {\n+        metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"false\");\n       }\n \n-      syncTableMetadata(true);\n-    } catch (IOException ioe) {\n-      throw new HoodieIOException(ioe.getMessage(), ioe);\n+      // Do an inline clustering if enabled\n+      if (config.inlineClusteringEnabled()) {\n+        runAnyPendingClustering(table);\n+        metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"true\");\n+        inlineCluster(extraMetadata);\n+      } else {\n+        metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n+      }\n     }\n   }\n \n   protected void runAnyPendingCompactions(HoodieTable<T, I, K, O> table) {\n-    table.getActiveTimeline().getCommitsAndCompactionTimeline().filterPendingCompactionTimeline().getInstants()\n+    table.getActiveTimeline().getWriteTimeline().filterPendingCompactionTimeline().getInstants()\n         .forEach(instant -> {\n           LOG.info(\"Running previously failed inflight compaction at instant \" + instant);\n           compact(instant.getTimestamp(), true);\n", "next_change": {"commit": "d47718945d2ad86eb653daafc03f1f74a57b6881", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex da2430225..edc8dc47a 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -438,7 +438,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     }\n   }\n \n-  protected void runTableServices(HoodieTable<T, I, K, O> table, HoodieCommitMetadata metadata, Option<Map<String, String>> extraMetadata) {\n+  protected void runTableServicesInline(HoodieTable<T, I, K, O> table, HoodieCommitMetadata metadata, Option<Map<String, String>> extraMetadata) {\n     if (config.inlineTableServices()) {\n       // Do an inline compaction if enabled\n       if (config.inlineCompactionEnabled()) {\n", "next_change": null}]}}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 64cc5e5f0..ea6c6f81a 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -450,7 +451,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n         }\n \n         // Do an inline clustering if enabled\n-        if (config.isInlineClustering()) {\n+        if (config.inlineClusteringEnabled()) {\n           runAnyPendingClustering(table);\n           metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"true\");\n           inlineCluster(extraMetadata);\n", "next_change": {"commit": "9d857ed63bba87ec2528eb26bae1e69216814bdd", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ea6c6f81a..4835e9438 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -457,6 +463,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n           inlineCluster(extraMetadata);\n         } else {\n           metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n+          metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n         }\n \n         // We cannot have unbounded commit files. Archive commits if we have to archive\n", "next_change": {"commit": "289e45a28da6b91fba2a824ec2af3771a34b2930", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 4835e9438..3b9e08dd3 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -465,22 +448,23 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n           metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n           metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n         }\n-\n         // We cannot have unbounded commit files. Archive commits if we have to archive\n         HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(config, table);\n         archiveLog.archiveIfRequired(context);\n         if (config.isAutoClean() || config.inlineCleaningEnabled()) {\n           autoCleanOnCommit();\n         }\n+        syncTableMetadata();\n       }\n-\n     } catch (IOException ioe) {\n       throw new HoodieIOException(ioe.getMessage(), ioe);\n+    } finally {\n+      this.heartbeatClient.stop(instantTime);\n     }\n   }\n \n   protected void runAnyPendingCompactions(HoodieTable<T, I, K, O> table) {\n-    table.getActiveTimeline().getCommitsAndCompactionTimeline().filterPendingCompactionTimeline().getInstants()\n+    table.getActiveTimeline().getWriteTimeline().filterPendingCompactionTimeline().getInstants()\n         .forEach(instant -> {\n           LOG.info(\"Running previously failed inflight compaction at instant \" + instant);\n           compact(instant.getTimestamp(), true);\n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 3b9e08dd3..12c55370f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -446,12 +444,11 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n           inlineCluster(extraMetadata);\n         } else {\n           metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n-          metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n         }\n         // We cannot have unbounded commit files. Archive commits if we have to archive\n         HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(config, table);\n         archiveLog.archiveIfRequired(context);\n-        if (config.isAutoClean() || config.inlineCleaningEnabled()) {\n+        if (config.isAutoClean()) {\n           autoCleanOnCommit();\n         }\n         syncTableMetadata();\n", "next_change": {"commit": "02efbb661e7ed13c3614ddee7ab5157623070f7c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 12c55370f..996648c0e 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -445,14 +445,12 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n         } else {\n           metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n         }\n-        // We cannot have unbounded commit files. Archive commits if we have to archive\n-        HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(config, table);\n-        archiveLog.archiveIfRequired(context);\n-        if (config.isAutoClean()) {\n-          autoCleanOnCommit();\n-        }\n-        syncTableMetadata();\n       }\n+      // We cannot have unbounded commit files. Archive commits if we have to archive\n+      HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(config, table);\n+      archiveLog.archiveIfRequired(context);\n+      autoCleanOnCommit();\n+      syncTableMetadata();\n     } catch (IOException ioe) {\n       throw new HoodieIOException(ioe.getMessage(), ioe);\n     } finally {\n", "next_change": {"commit": "8c092be25de58e65cd339478e9b2c0ba37d20e5e", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 996648c0e..da2430225 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -423,29 +424,8 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n    */\n   protected void postCommit(HoodieTable<T, I, K, O> table, HoodieCommitMetadata metadata, String instantTime, Option<Map<String, String>> extraMetadata) {\n     try {\n-\n       // Delete the marker directory for the instant.\n       new MarkerFiles(table, instantTime).quietDeleteMarkerDir(context, config.getMarkersDeleteParallelism());\n-\n-      if (config.inlineTableServices()) {\n-        // Do an inline compaction if enabled\n-        if (config.inlineCompactionEnabled()) {\n-          runAnyPendingCompactions(table);\n-          metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"true\");\n-          inlineCompact(extraMetadata);\n-        } else {\n-          metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"false\");\n-        }\n-\n-        // Do an inline clustering if enabled\n-        if (config.inlineClusteringEnabled()) {\n-          runAnyPendingClustering(table);\n-          metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"true\");\n-          inlineCluster(extraMetadata);\n-        } else {\n-          metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n-        }\n-      }\n       // We cannot have unbounded commit files. Archive commits if we have to archive\n       HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(config, table);\n       archiveLog.archiveIfRequired(context);\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 996648c0e..da2430225 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -458,6 +438,28 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     }\n   }\n \n+  protected void runTableServices(HoodieTable<T, I, K, O> table, HoodieCommitMetadata metadata, Option<Map<String, String>> extraMetadata) {\n+    if (config.inlineTableServices()) {\n+      // Do an inline compaction if enabled\n+      if (config.inlineCompactionEnabled()) {\n+        runAnyPendingCompactions(table);\n+        metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"true\");\n+        inlineCompact(extraMetadata);\n+      } else {\n+        metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"false\");\n+      }\n+\n+      // Do an inline clustering if enabled\n+      if (config.inlineClusteringEnabled()) {\n+        runAnyPendingClustering(table);\n+        metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"true\");\n+        inlineCluster(extraMetadata);\n+      } else {\n+        metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n+      }\n+    }\n+  }\n+\n   protected void runAnyPendingCompactions(HoodieTable<T, I, K, O> table) {\n     table.getActiveTimeline().getWriteTimeline().filterPendingCompactionTimeline().getInstants()\n         .forEach(instant -> {\n", "next_change": {"commit": "d47718945d2ad86eb653daafc03f1f74a57b6881", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex da2430225..edc8dc47a 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -438,7 +438,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     }\n   }\n \n-  protected void runTableServices(HoodieTable<T, I, K, O> table, HoodieCommitMetadata metadata, Option<Map<String, String>> extraMetadata) {\n+  protected void runTableServicesInline(HoodieTable<T, I, K, O> table, HoodieCommitMetadata metadata, Option<Map<String, String>> extraMetadata) {\n     if (config.inlineTableServices()) {\n       // Do an inline compaction if enabled\n       if (config.inlineCompactionEnabled()) {\n", "next_change": null}]}}]}}]}}]}}]}}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 64cc5e5f0..ea6c6f81a 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -461,7 +462,9 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n         // We cannot have unbounded commit files. Archive commits if we have to archive\n         HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(config, table);\n         archiveLog.archiveIfRequired(context);\n-        autoCleanOnCommit();\n+        if (config.isAutoClean() || config.inlineCleaningEnabled()) {\n+          autoCleanOnCommit();\n+        }\n       }\n \n       syncTableMetadata(true);\n", "next_change": {"commit": "25a4d7f70cc0cfcec115ddfcc2a543a96bcb17af", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ea6c6f81a..063b26db8 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -467,7 +470,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n         }\n       }\n \n-      syncTableMetadata(true);\n     } catch (IOException ioe) {\n       throw new HoodieIOException(ioe.getMessage(), ioe);\n     }\n", "next_change": {"commit": "289e45a28da6b91fba2a824ec2af3771a34b2930", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 063b26db8..3b9e08dd3 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -460,23 +446,25 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n           inlineCluster(extraMetadata);\n         } else {\n           metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n+          metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n         }\n-\n         // We cannot have unbounded commit files. Archive commits if we have to archive\n         HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(config, table);\n         archiveLog.archiveIfRequired(context);\n         if (config.isAutoClean() || config.inlineCleaningEnabled()) {\n           autoCleanOnCommit();\n         }\n+        syncTableMetadata();\n       }\n-\n     } catch (IOException ioe) {\n       throw new HoodieIOException(ioe.getMessage(), ioe);\n+    } finally {\n+      this.heartbeatClient.stop(instantTime);\n     }\n   }\n \n   protected void runAnyPendingCompactions(HoodieTable<T, I, K, O> table) {\n-    table.getActiveTimeline().getCommitsAndCompactionTimeline().filterPendingCompactionTimeline().getInstants()\n+    table.getActiveTimeline().getWriteTimeline().filterPendingCompactionTimeline().getInstants()\n         .forEach(instant -> {\n           LOG.info(\"Running previously failed inflight compaction at instant \" + instant);\n           compact(instant.getTimestamp(), true);\n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 3b9e08dd3..12c55370f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -446,12 +444,11 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n           inlineCluster(extraMetadata);\n         } else {\n           metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n-          metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n         }\n         // We cannot have unbounded commit files. Archive commits if we have to archive\n         HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(config, table);\n         archiveLog.archiveIfRequired(context);\n-        if (config.isAutoClean() || config.inlineCleaningEnabled()) {\n+        if (config.isAutoClean()) {\n           autoCleanOnCommit();\n         }\n         syncTableMetadata();\n", "next_change": {"commit": "02efbb661e7ed13c3614ddee7ab5157623070f7c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 12c55370f..996648c0e 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -445,14 +445,12 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n         } else {\n           metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n         }\n-        // We cannot have unbounded commit files. Archive commits if we have to archive\n-        HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(config, table);\n-        archiveLog.archiveIfRequired(context);\n-        if (config.isAutoClean()) {\n-          autoCleanOnCommit();\n-        }\n-        syncTableMetadata();\n       }\n+      // We cannot have unbounded commit files. Archive commits if we have to archive\n+      HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(config, table);\n+      archiveLog.archiveIfRequired(context);\n+      autoCleanOnCommit();\n+      syncTableMetadata();\n     } catch (IOException ioe) {\n       throw new HoodieIOException(ioe.getMessage(), ioe);\n     } finally {\n", "next_change": {"commit": "8c092be25de58e65cd339478e9b2c0ba37d20e5e", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 996648c0e..da2430225 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -423,29 +424,8 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n    */\n   protected void postCommit(HoodieTable<T, I, K, O> table, HoodieCommitMetadata metadata, String instantTime, Option<Map<String, String>> extraMetadata) {\n     try {\n-\n       // Delete the marker directory for the instant.\n       new MarkerFiles(table, instantTime).quietDeleteMarkerDir(context, config.getMarkersDeleteParallelism());\n-\n-      if (config.inlineTableServices()) {\n-        // Do an inline compaction if enabled\n-        if (config.inlineCompactionEnabled()) {\n-          runAnyPendingCompactions(table);\n-          metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"true\");\n-          inlineCompact(extraMetadata);\n-        } else {\n-          metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"false\");\n-        }\n-\n-        // Do an inline clustering if enabled\n-        if (config.inlineClusteringEnabled()) {\n-          runAnyPendingClustering(table);\n-          metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"true\");\n-          inlineCluster(extraMetadata);\n-        } else {\n-          metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n-        }\n-      }\n       // We cannot have unbounded commit files. Archive commits if we have to archive\n       HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(config, table);\n       archiveLog.archiveIfRequired(context);\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 996648c0e..da2430225 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -458,6 +438,28 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     }\n   }\n \n+  protected void runTableServices(HoodieTable<T, I, K, O> table, HoodieCommitMetadata metadata, Option<Map<String, String>> extraMetadata) {\n+    if (config.inlineTableServices()) {\n+      // Do an inline compaction if enabled\n+      if (config.inlineCompactionEnabled()) {\n+        runAnyPendingCompactions(table);\n+        metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"true\");\n+        inlineCompact(extraMetadata);\n+      } else {\n+        metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"false\");\n+      }\n+\n+      // Do an inline clustering if enabled\n+      if (config.inlineClusteringEnabled()) {\n+        runAnyPendingClustering(table);\n+        metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"true\");\n+        inlineCluster(extraMetadata);\n+      } else {\n+        metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n+      }\n+    }\n+  }\n+\n   protected void runAnyPendingCompactions(HoodieTable<T, I, K, O> table) {\n     table.getActiveTimeline().getWriteTimeline().filterPendingCompactionTimeline().getInstants()\n         .forEach(instant -> {\n", "next_change": {"commit": "d47718945d2ad86eb653daafc03f1f74a57b6881", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex da2430225..edc8dc47a 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -438,7 +438,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     }\n   }\n \n-  protected void runTableServices(HoodieTable<T, I, K, O> table, HoodieCommitMetadata metadata, Option<Map<String, String>> extraMetadata) {\n+  protected void runTableServicesInline(HoodieTable<T, I, K, O> table, HoodieCommitMetadata metadata, Option<Map<String, String>> extraMetadata) {\n     if (config.inlineTableServices()) {\n       // Do an inline compaction if enabled\n       if (config.inlineCompactionEnabled()) {\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg1MzAxOQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r568853019", "bodyText": "we should clear annotate/document that this we do not support multiple writers on the same writeClient instance.", "author": "vinothchandar", "createdAt": "2021-02-02T18:57:30Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -98,6 +112,7 @@\n   private transient HoodieWriteCommitCallback commitCallback;\n   private transient AsyncCleanerService asyncCleanerService;\n   protected final boolean rollbackPending;\n+  protected AtomicReference<Option<HoodieInstant>> latestCompletedWriteInstant = new AtomicReference<>();", "originalCommit": "8b8d5945136066148f200d30c5d3bf6d5be70cbf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTE5ODY3MQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r569198671", "bodyText": "Created issue -> https://issues.apache.org/jira/browse/HUDI-1577", "author": "n3nash", "createdAt": "2021-02-03T07:57:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg1MzAxOQ=="}], "type": "inlineReview", "revised_code": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 64cc5e5f0..ea6c6f81a 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -112,8 +104,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n   private transient HoodieWriteCommitCallback commitCallback;\n   private transient AsyncCleanerService asyncCleanerService;\n   protected final boolean rollbackPending;\n-  protected AtomicReference<Option<HoodieInstant>> latestCompletedWriteInstant = new AtomicReference<>();\n-\n+  protected final TransactionManager txnManager;\n   /**\n    * Create a write client, without cleaning up failed/inflight commits.\n    *\n", "next_change": {"commit": "289e45a28da6b91fba2a824ec2af3771a34b2930", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ea6c6f81a..3b9e08dd3 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -102,46 +105,32 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n   private transient WriteOperationType operationType;\n   private transient HoodieWriteCommitCallback commitCallback;\n-  private transient AsyncCleanerService asyncCleanerService;\n-  protected final boolean rollbackPending;\n+  protected transient AsyncCleanerService asyncCleanerService;\n   protected final TransactionManager txnManager;\n-  /**\n-   * Create a write client, without cleaning up failed/inflight commits.\n-   *\n-   * @param context HoodieEngineContext\n-   * @param clientConfig instance of HoodieWriteConfig\n-   */\n-  public AbstractHoodieWriteClient(HoodieEngineContext context, HoodieWriteConfig clientConfig) {\n-    this(context, clientConfig, false);\n-  }\n \n   /**\n    * Create a write client, with new hudi index.\n-   *\n    * @param context HoodieEngineContext\n    * @param writeConfig instance of HoodieWriteConfig\n-   * @param rollbackPending whether need to cleanup pending commits\n    */\n-  public AbstractHoodieWriteClient(HoodieEngineContext context, HoodieWriteConfig writeConfig, boolean rollbackPending) {\n-    this(context, writeConfig, rollbackPending, Option.empty());\n+  @Deprecated\n+  public AbstractHoodieWriteClient(HoodieEngineContext context, HoodieWriteConfig writeConfig) {\n+    this(context, writeConfig, Option.empty());\n   }\n \n   /**\n    * Create a write client, allows to specify all parameters.\n-   *\n    * @param context         HoodieEngineContext\n    * @param writeConfig instance of HoodieWriteConfig\n-   * @param rollbackPending whether need to cleanup pending commits\n    * @param timelineService Timeline Service that runs as part of write client.\n    */\n-  public AbstractHoodieWriteClient(HoodieEngineContext context, HoodieWriteConfig writeConfig, boolean rollbackPending,\n+  @Deprecated\n+  public AbstractHoodieWriteClient(HoodieEngineContext context, HoodieWriteConfig writeConfig,\n                                    Option<EmbeddedTimelineService> timelineService) {\n     super(context, writeConfig, timelineService);\n     this.metrics = new HoodieMetrics(config, config.getTableName());\n-    this.rollbackPending = rollbackPending;\n     this.index = createIndex(writeConfig);\n     this.txnManager = new TransactionManager(config, fs);\n-    syncTableMetadata(false);\n   }\n \n   protected abstract HoodieIndex<T, I, K, O> createIndex(HoodieWriteConfig writeConfig);\n", "next_change": {"commit": "1b522ef9c2fec7a32c7a1bfae2039e8f07a60d8f", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 3b9e08dd3..f663e64d4 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -107,6 +108,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n   private transient HoodieWriteCommitCallback commitCallback;\n   protected transient AsyncCleanerService asyncCleanerService;\n   protected final TransactionManager txnManager;\n+  protected Option<HoodieInstant> lastCompletedTxn;\n \n   /**\n    * Create a write client, with new hudi index.\n", "next_change": {"commit": "1886bbd803f1a51e3d261705dd1283cfa8caf06b", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex f663e64d4..80e79155b 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -108,7 +108,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n   private transient HoodieWriteCommitCallback commitCallback;\n   protected transient AsyncCleanerService asyncCleanerService;\n   protected final TransactionManager txnManager;\n-  protected Option<HoodieInstant> lastCompletedTxn;\n+  protected Option<Pair<HoodieInstant, Map<String, String>>> lastCompletedTxnAndMetadata;\n \n   /**\n    * Create a write client, with new hudi index.\n", "next_change": {"commit": "4e029d324c4ea812ec09acb2a3bcd487b2d35eb8", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 80e79155b..97e3f59ca 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -108,7 +108,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n   private transient HoodieWriteCommitCallback commitCallback;\n   protected transient AsyncCleanerService asyncCleanerService;\n   protected final TransactionManager txnManager;\n-  protected Option<Pair<HoodieInstant, Map<String, String>>> lastCompletedTxnAndMetadata;\n+  protected Option<Pair<HoodieInstant, Map<String, String>>> lastCompletedTxnAndMetadata = Option.empty();\n \n   /**\n    * Create a write client, with new hudi index.\n", "next_change": {"commit": "461047d03e9b7b73b34536ccf290a24f4aada6b0", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 97e3f59ca..656b209e7 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -108,7 +107,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n   private transient HoodieWriteCommitCallback commitCallback;\n   protected transient AsyncCleanerService asyncCleanerService;\n   protected final TransactionManager txnManager;\n-  protected Option<Pair<HoodieInstant, Map<String, String>>> lastCompletedTxnAndMetadata = Option.empty();\n+  protected Option<HoodieInstant> lastCompletedTxn;\n \n   /**\n    * Create a write client, with new hudi index.\n", "next_change": {"commit": "a466320b7537bf2862df853344e80fbd0be6d16a", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 656b209e7..096e644df 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -107,7 +108,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n   private transient HoodieWriteCommitCallback commitCallback;\n   protected transient AsyncCleanerService asyncCleanerService;\n   protected final TransactionManager txnManager;\n-  protected Option<HoodieInstant> lastCompletedTxn;\n+  protected Option<Pair<HoodieInstant, Map<String, String>>> lastCompletedTxnAndMetadata = Option.empty();\n \n   /**\n    * Create a write client, with new hudi index.\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg1NDUyMQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r568854521", "bodyText": "can this code sit somewhere else?  we should try to keep the write client file pretty lean and do only the control flow", "author": "vinothchandar", "createdAt": "2021-02-02T18:59:45Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -859,6 +973,68 @@ protected void finalizeWrite(HoodieTable<T, I, K, O> table, String instantTime,\n     }\n   }\n \n+  private HoodieCommitMetadata resolveWriteConflictIfAny(HoodieTable<T, I, K, O> table, HoodieBackedTableMetadataWriter metadataWriter,", "originalCommit": "8b8d5945136066148f200d30c5d3bf6d5be70cbf", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 64cc5e5f0..ea6c6f81a 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -973,68 +966,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     }\n   }\n \n-  private HoodieCommitMetadata resolveWriteConflictIfAny(HoodieTable<T, I, K, O> table, HoodieBackedTableMetadataWriter metadataWriter,\n-                                                         final String instantTime, HoodieCommitMetadata thisCommitMetadata)\n-      throws HoodieWriteConflictException {\n-    ConflictResolutionStrategy resolutionStrategy = config.getWriteConflictResolutionStrategy();\n-    Option<HoodieInstant> lastCompletedInstantBeforeWriterStarted = this.latestCompletedWriteInstant.get();\n-    String lastInstantTimestamp = lastCompletedInstantBeforeWriterStarted.isPresent()\n-        ? lastCompletedInstantBeforeWriterStarted.get().getTimestamp() : \"0\";\n-    // Get completed instants timeline\n-    Stream<HoodieInstant> completedInstantStream = table.getActiveTimeline()\n-        .getAllCommitsTimeline()\n-        // TODO : getWriteTimeline to ensure we include replace commits as well\n-        .getCommitsAndCompactionTimeline()\n-        .filterCompletedInstants()\n-        .findInstantsAfter(lastInstantTimestamp)\n-        .getInstants();\n-\n-    // Get pending replace and compaction instants timeline\n-    Stream<HoodieInstant> pendingReplaceAndRequestedInstantStream = table.getActiveTimeline()\n-        .getAllCommitsTimeline()\n-        .filterPendingCompactionAndReplaceTimeline()\n-        .findInstantsAfter(lastInstantTimestamp)\n-        .getInstants();\n-\n-    Stream<HoodieInstant> instantStream = Stream.concat(completedInstantStream, pendingReplaceAndRequestedInstantStream);\n-    final HoodieCommitOperation thisOperation = new HoodieCommitOperation(thisCommitMetadata, instantTime);\n-    instantStream.forEach(instant -> {\n-      try {\n-        HoodieCommitOperation otherOperation = new HoodieCommitOperation(HoodieCommitMetadata.fromBytes(\n-            table.getActiveTimeline().getInstantDetails(instant).get(), HoodieCommitMetadata.class), instant.getTimestamp());\n-        if (resolutionStrategy.hasConflict(thisOperation, otherOperation)) {\n-          LOG.info(\"Conflict encountered between instant = \" + thisOperation.getInstant() + \" and instant = \"\n-              + otherOperation.getInstant() + \", attempting to resolve it now\");\n-          resolutionStrategy.resolveConflict(metadataWriter, table, thisOperation, otherOperation);\n-        }\n-      } catch (IOException io) {\n-        throw new HoodieWriteConflictException(\"Unable to resolve conflict, if present\", io);\n-      }\n-    });\n-    return thisOperation.getCommitMetadata();\n-  }\n-\n-  private boolean executeCriticalSection(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n-                                         String commitActionType, LockProvider lockProvider, HoodieCommitMetadata metadata) {\n-    try {\n-      // TODO : Make the executeCriticalSection generic by passing a function\n-      boolean acquired = lockProvider.tryLock(config.getLockAcquireWaitTimeoutInMs(), TimeUnit.MILLISECONDS);\n-      if (!acquired) {\n-        throw new HoodieLockException(\"Unable to acquire lock for instant \" + instantTime);\n-      }\n-      LOG.info(\"Acquired lock for instant time \" + instantTime);\n-      // Create a Hoodie table which encapsulated the commits and files visible.\n-      // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n-      HoodieTable table = createTable(config, hadoopConf);\n-      HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-      metadata = resolveWriteConflictIfAny(table, metadataWriter, instantTime, metadata);\n-      return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-    } finally {\n-      lockProvider.unlock();\n-      LOG.info(\"Released lock if acquired for instant time \" + instantTime);\n-    }\n-  }\n-\n   public HoodieMetrics getMetrics() {\n     return metrics;\n   }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg1NDc2Ng==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r568854766", "bodyText": "same with this.", "author": "vinothchandar", "createdAt": "2021-02-02T19:00:09Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -859,6 +973,68 @@ protected void finalizeWrite(HoodieTable<T, I, K, O> table, String instantTime,\n     }\n   }\n \n+  private HoodieCommitMetadata resolveWriteConflictIfAny(HoodieTable<T, I, K, O> table, HoodieBackedTableMetadataWriter metadataWriter,\n+                                                         final String instantTime, HoodieCommitMetadata thisCommitMetadata)\n+      throws HoodieWriteConflictException {\n+    ConflictResolutionStrategy resolutionStrategy = config.getWriteConflictResolutionStrategy();\n+    Option<HoodieInstant> lastCompletedInstantBeforeWriterStarted = this.latestCompletedWriteInstant.get();\n+    String lastInstantTimestamp = lastCompletedInstantBeforeWriterStarted.isPresent()\n+        ? lastCompletedInstantBeforeWriterStarted.get().getTimestamp() : \"0\";\n+    // Get completed instants timeline\n+    Stream<HoodieInstant> completedInstantStream = table.getActiveTimeline()\n+        .getAllCommitsTimeline()\n+        // TODO : getWriteTimeline to ensure we include replace commits as well\n+        .getCommitsAndCompactionTimeline()\n+        .filterCompletedInstants()\n+        .findInstantsAfter(lastInstantTimestamp)\n+        .getInstants();\n+\n+    // Get pending replace and compaction instants timeline\n+    Stream<HoodieInstant> pendingReplaceAndRequestedInstantStream = table.getActiveTimeline()\n+        .getAllCommitsTimeline()\n+        .filterPendingCompactionAndReplaceTimeline()\n+        .findInstantsAfter(lastInstantTimestamp)\n+        .getInstants();\n+\n+    Stream<HoodieInstant> instantStream = Stream.concat(completedInstantStream, pendingReplaceAndRequestedInstantStream);\n+    final HoodieCommitOperation thisOperation = new HoodieCommitOperation(thisCommitMetadata, instantTime);\n+    instantStream.forEach(instant -> {\n+      try {\n+        HoodieCommitOperation otherOperation = new HoodieCommitOperation(HoodieCommitMetadata.fromBytes(\n+            table.getActiveTimeline().getInstantDetails(instant).get(), HoodieCommitMetadata.class), instant.getTimestamp());\n+        if (resolutionStrategy.hasConflict(thisOperation, otherOperation)) {\n+          LOG.info(\"Conflict encountered between instant = \" + thisOperation.getInstant() + \" and instant = \"\n+              + otherOperation.getInstant() + \", attempting to resolve it now\");\n+          resolutionStrategy.resolveConflict(metadataWriter, table, thisOperation, otherOperation);\n+        }\n+      } catch (IOException io) {\n+        throw new HoodieWriteConflictException(\"Unable to resolve conflict, if present\", io);\n+      }\n+    });\n+    return thisOperation.getCommitMetadata();\n+  }\n+\n+  private boolean executeCriticalSection(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,", "originalCommit": "8b8d5945136066148f200d30c5d3bf6d5be70cbf", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 64cc5e5f0..ea6c6f81a 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -973,68 +966,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     }\n   }\n \n-  private HoodieCommitMetadata resolveWriteConflictIfAny(HoodieTable<T, I, K, O> table, HoodieBackedTableMetadataWriter metadataWriter,\n-                                                         final String instantTime, HoodieCommitMetadata thisCommitMetadata)\n-      throws HoodieWriteConflictException {\n-    ConflictResolutionStrategy resolutionStrategy = config.getWriteConflictResolutionStrategy();\n-    Option<HoodieInstant> lastCompletedInstantBeforeWriterStarted = this.latestCompletedWriteInstant.get();\n-    String lastInstantTimestamp = lastCompletedInstantBeforeWriterStarted.isPresent()\n-        ? lastCompletedInstantBeforeWriterStarted.get().getTimestamp() : \"0\";\n-    // Get completed instants timeline\n-    Stream<HoodieInstant> completedInstantStream = table.getActiveTimeline()\n-        .getAllCommitsTimeline()\n-        // TODO : getWriteTimeline to ensure we include replace commits as well\n-        .getCommitsAndCompactionTimeline()\n-        .filterCompletedInstants()\n-        .findInstantsAfter(lastInstantTimestamp)\n-        .getInstants();\n-\n-    // Get pending replace and compaction instants timeline\n-    Stream<HoodieInstant> pendingReplaceAndRequestedInstantStream = table.getActiveTimeline()\n-        .getAllCommitsTimeline()\n-        .filterPendingCompactionAndReplaceTimeline()\n-        .findInstantsAfter(lastInstantTimestamp)\n-        .getInstants();\n-\n-    Stream<HoodieInstant> instantStream = Stream.concat(completedInstantStream, pendingReplaceAndRequestedInstantStream);\n-    final HoodieCommitOperation thisOperation = new HoodieCommitOperation(thisCommitMetadata, instantTime);\n-    instantStream.forEach(instant -> {\n-      try {\n-        HoodieCommitOperation otherOperation = new HoodieCommitOperation(HoodieCommitMetadata.fromBytes(\n-            table.getActiveTimeline().getInstantDetails(instant).get(), HoodieCommitMetadata.class), instant.getTimestamp());\n-        if (resolutionStrategy.hasConflict(thisOperation, otherOperation)) {\n-          LOG.info(\"Conflict encountered between instant = \" + thisOperation.getInstant() + \" and instant = \"\n-              + otherOperation.getInstant() + \", attempting to resolve it now\");\n-          resolutionStrategy.resolveConflict(metadataWriter, table, thisOperation, otherOperation);\n-        }\n-      } catch (IOException io) {\n-        throw new HoodieWriteConflictException(\"Unable to resolve conflict, if present\", io);\n-      }\n-    });\n-    return thisOperation.getCommitMetadata();\n-  }\n-\n-  private boolean executeCriticalSection(String instantTime, List<HoodieWriteStat> stats, Option<Map<String, String>> extraMetadata,\n-                                         String commitActionType, LockProvider lockProvider, HoodieCommitMetadata metadata) {\n-    try {\n-      // TODO : Make the executeCriticalSection generic by passing a function\n-      boolean acquired = lockProvider.tryLock(config.getLockAcquireWaitTimeoutInMs(), TimeUnit.MILLISECONDS);\n-      if (!acquired) {\n-        throw new HoodieLockException(\"Unable to acquire lock for instant \" + instantTime);\n-      }\n-      LOG.info(\"Acquired lock for instant time \" + instantTime);\n-      // Create a Hoodie table which encapsulated the commits and files visible.\n-      // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n-      HoodieTable table = createTable(config, hadoopConf);\n-      HoodieBackedTableMetadataWriter metadataWriter = createMetadataWriter(config, hadoopConf);\n-      metadata = resolveWriteConflictIfAny(table, metadataWriter, instantTime, metadata);\n-      return commitStats(instantTime, stats, extraMetadata, commitActionType, Collections.emptyMap(), metadata);\n-    } finally {\n-      lockProvider.unlock();\n-      LOG.info(\"Released lock if acquired for instant time \" + instantTime);\n-    }\n-  }\n-\n   public HoodieMetrics getMetrics() {\n     return metrics;\n   }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg1NTIzNQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r568855235", "bodyText": "please move these comments into the actual implementation. and not in this file", "author": "vinothchandar", "createdAt": "2021-02-02T19:00:51Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -907,11 +1083,20 @@ public void close() {\n     // release AsyncCleanerService\n     AsyncCleanerService.forceShutdown(asyncCleanerService);\n     asyncCleanerService = null;\n-\n     // Stop timeline-server if running\n     super.close();\n     // Calling this here releases any resources used by your index, so make sure to finish any related operations\n     // before this point\n     this.index.close();\n+    // HiveMetastoreClient does not implement AutoCloseable. Additionally, we cannot call close() after unlock()", "originalCommit": "8b8d5945136066148f200d30c5d3bf6d5be70cbf", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 64cc5e5f0..ea6c6f81a 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -1088,15 +1019,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     // Calling this here releases any resources used by your index, so make sure to finish any related operations\n     // before this point\n     this.index.close();\n-    // HiveMetastoreClient does not implement AutoCloseable. Additionally, we cannot call close() after unlock()\n-    // because if there are multiple operations started from the same WriteClient (via multiple threads), closing the\n-    // hive client causes all other threads who may have already initiated the tryLock() to fail since the\n-    // HiveMetastoreClient is shared. Hence, we choose to close the connection here at the end to reduce number of\n-    // connections created and share the same connection.\n-    if (LockProviderSingleton.lockProviderInstance != null) {\n-      LockProviderSingleton.lockProviderInstance.close();\n-      LOG.info(\"Released connection created for acquiring lock\");\n-      LockProviderSingleton.lockProviderInstance = null;\n-    }\n+    this.txnManager.close();\n   }\n }\n", "next_change": {"commit": "289e45a28da6b91fba2a824ec2af3771a34b2930", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex ea6c6f81a..3b9e08dd3 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -1019,6 +1051,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     // Calling this here releases any resources used by your index, so make sure to finish any related operations\n     // before this point\n     this.index.close();\n+    this.heartbeatClient.stop();\n     this.txnManager.close();\n   }\n }\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg1NjY3NQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r568856675", "bodyText": "we should check somewhere that user cannot turn on both async and inline? , if we are adding an explicit config.", "author": "vinothchandar", "createdAt": "2021-02-02T19:03:17Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieCompactionConfig.java", "diffHunk": "@@ -41,7 +41,8 @@\n   public static final String CLEANER_POLICY_PROP = \"hoodie.cleaner.policy\";\n   public static final String AUTO_CLEAN_PROP = \"hoodie.clean.automatic\";\n   public static final String ASYNC_CLEAN_PROP = \"hoodie.clean.async\";\n-\n+  // Turn on inline cleaning\n+  public static final String INLINE_CLEAN_PROP = \"hoodie.clean.inline\";", "originalCommit": "8b8d5945136066148f200d30c5d3bf6d5be70cbf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTk3NzYyNQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r569977625", "bodyText": "Right now, this config is harmless, it just assumes the role of autoClean.", "author": "n3nash", "createdAt": "2021-02-04T06:34:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg1NjY3NQ=="}], "type": "inlineReview", "revised_code": {"commit": "d155914cd673d7699bb5258e6f9cafb85059673a", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieCompactionConfig.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieCompactionConfig.java\nindex 5d4f73501..58c47d0ed 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieCompactionConfig.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieCompactionConfig.java\n", "chunk": "@@ -47,6 +48,9 @@ public class HoodieCompactionConfig extends DefaultHoodieConfig {\n   public static final String INLINE_COMPACT_PROP = \"hoodie.compact.inline\";\n   // Run a compaction every N delta commits\n   public static final String INLINE_COMPACT_NUM_DELTA_COMMITS_PROP = \"hoodie.compact.inline.max.delta.commits\";\n+  // Run a compaction when time elapsed > N seconds since last compaction\n+  public static final String INLINE_COMPACT_TIME_DELTA_SECONDS_PROP = \"hoodie.compact.inline.max.delta.seconds\";\n+  public static final String INLINE_COMPACT_TRIGGER_STRATEGY_PROP = \"hoodie.compact.inline.trigger.strategy\";\n   public static final String CLEANER_FILE_VERSIONS_RETAINED_PROP = \"hoodie.cleaner.fileversions.retained\";\n   public static final String CLEANER_COMMITS_RETAINED_PROP = \"hoodie.cleaner.commits.retained\";\n   public static final String CLEANER_INCREMENTAL_MODE = \"hoodie.cleaner.incremental.mode\";\n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieCompactionConfig.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieCompactionConfig.java\nindex 58c47d0ed..43af00a13 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieCompactionConfig.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieCompactionConfig.java\n", "chunk": "@@ -42,8 +43,6 @@ public class HoodieCompactionConfig extends DefaultHoodieConfig {\n   public static final String CLEANER_POLICY_PROP = \"hoodie.cleaner.policy\";\n   public static final String AUTO_CLEAN_PROP = \"hoodie.clean.automatic\";\n   public static final String ASYNC_CLEAN_PROP = \"hoodie.clean.async\";\n-  // Turn on inline cleaning\n-  public static final String INLINE_CLEAN_PROP = \"hoodie.clean.inline\";\n   // Turn on inline compaction - after fw delta commits a inline compaction will be run\n   public static final String INLINE_COMPACT_PROP = \"hoodie.compact.inline\";\n   // Run a compaction every N delta commits\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg1NzQ3OA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r568857478", "bodyText": "this does not read easily. rename inlineCleaningEnabled or shouldCleanInline() or something like tht? (same wherever applicable)", "author": "vinothchandar", "createdAt": "2021-02-02T19:04:40Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java", "diffHunk": "@@ -389,6 +397,10 @@ public boolean isAsyncClean() {\n     return Boolean.parseBoolean(props.getProperty(HoodieCompactionConfig.ASYNC_CLEAN_PROP));\n   }\n \n+  public boolean isInlineCleaning() {", "originalCommit": "8b8d5945136066148f200d30c5d3bf6d5be70cbf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTIwMTM4OA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r569201388", "bodyText": "I kept the same naming convention as before for isInlineCompaction etc. I refactored all of them to inline<..>Enabled", "author": "n3nash", "createdAt": "2021-02-03T08:01:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg1NzQ3OA=="}], "type": "inlineReview", "revised_code": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\nindex 3b49d38e2..02f7c65ad 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\n", "chunk": "@@ -397,7 +397,7 @@ public class HoodieWriteConfig extends DefaultHoodieConfig {\n     return Boolean.parseBoolean(props.getProperty(HoodieCompactionConfig.ASYNC_CLEAN_PROP));\n   }\n \n-  public boolean isInlineCleaning() {\n+  public boolean inlineCleaningEnabled() {\n     return Boolean.parseBoolean(props.getProperty(HoodieCompactionConfig.INLINE_CLEAN_PROP));\n   }\n \n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\nindex 02f7c65ad..e95f0aa31 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\n", "chunk": "@@ -397,10 +431,6 @@ public class HoodieWriteConfig extends DefaultHoodieConfig {\n     return Boolean.parseBoolean(props.getProperty(HoodieCompactionConfig.ASYNC_CLEAN_PROP));\n   }\n \n-  public boolean inlineCleaningEnabled() {\n-    return Boolean.parseBoolean(props.getProperty(HoodieCompactionConfig.INLINE_CLEAN_PROP));\n-  }\n-\n   public boolean incrementalCleanerModeEnabled() {\n     return Boolean.parseBoolean(props.getProperty(HoodieCompactionConfig.CLEANER_INCREMENTAL_MODE));\n   }\n", "next_change": null}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\nindex 3b49d38e2..02f7c65ad 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\n", "chunk": "@@ -405,7 +405,7 @@ public class HoodieWriteConfig extends DefaultHoodieConfig {\n     return Boolean.parseBoolean(props.getProperty(HoodieCompactionConfig.CLEANER_INCREMENTAL_MODE));\n   }\n \n-  public boolean isInlineCompaction() {\n+  public boolean inlineCompactionEnabled() {\n     return Boolean.parseBoolean(props.getProperty(HoodieCompactionConfig.INLINE_COMPACT_PROP));\n   }\n \n", "next_change": {"commit": "d155914cd673d7699bb5258e6f9cafb85059673a", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\nindex 02f7c65ad..dd0e5e0a9 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\n", "chunk": "@@ -409,10 +418,18 @@ public class HoodieWriteConfig extends DefaultHoodieConfig {\n     return Boolean.parseBoolean(props.getProperty(HoodieCompactionConfig.INLINE_COMPACT_PROP));\n   }\n \n+  public CompactionTriggerStrategy getInlineCompactTriggerStrategy() {\n+    return CompactionTriggerStrategy.valueOf(props.getProperty(HoodieCompactionConfig.INLINE_COMPACT_TRIGGER_STRATEGY_PROP));\n+  }\n+\n   public int getInlineCompactDeltaCommitMax() {\n     return Integer.parseInt(props.getProperty(HoodieCompactionConfig.INLINE_COMPACT_NUM_DELTA_COMMITS_PROP));\n   }\n \n+  public int getInlineCompactDeltaSecondsMax() {\n+    return Integer.parseInt(props.getProperty(HoodieCompactionConfig.INLINE_COMPACT_TIME_DELTA_SECONDS_PROP));\n+  }\n+\n   public CompactionStrategy getCompactionStrategy() {\n     return ReflectionUtils.loadClass(props.getProperty(HoodieCompactionConfig.COMPACTION_STRATEGY_PROP));\n   }\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg1ODA4Ng==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r568858086", "bodyText": "same. rename inlineTableServices()?", "author": "vinothchandar", "createdAt": "2021-02-02T19:05:44Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java", "diffHunk": "@@ -923,6 +935,39 @@ public int getMetadataCleanerCommitsRetained() {\n     return Integer.parseInt(props.getProperty(HoodieMetadataConfig.CLEANER_COMMITS_RETAINED_PROP));\n   }\n \n+  /**\n+   * Hoodie Client Lock Configs.\n+   * @return\n+   */\n+\n+  public String getLockProviderClass() {\n+    return props.getProperty(HoodieLockConfig.LOCK_PROVIDER_CLASS_PROP);\n+  }\n+\n+  public String getLockHiveDatabaseName() {\n+    return props.getProperty(HIVE_DATABASE_NAME_PROP);\n+  }\n+\n+  public String getLockHiveTableName() {\n+    return props.getProperty(HIVE_TABLE_NAME_PROP);\n+  }\n+\n+  public ConflictResolutionStrategy getWriteConflictResolutionStrategy() {\n+    return ReflectionUtils.loadClass(props.getProperty(HoodieLockConfig.WRITE_CONFLICT_RESOLUTION_STRATEGY_CLASS_PROP));\n+  }\n+\n+  public Long getLockAcquireWaitTimeoutInMs() {\n+    return Long.valueOf(props.getProperty(LockConfiguration.LOCK_ACQUIRE_WAIT_TIMEOUT_MS_PROP));\n+  }\n+\n+  public WriteConcurrencyMode getWriteConcurrencyMode() {\n+    return WriteConcurrencyMode.fromValue(props.getProperty(WRITE_CONCURRENCY_MODE_PROP));\n+  }\n+\n+  public Boolean isInlineTableServiceEnabled() {", "originalCommit": "8b8d5945136066148f200d30c5d3bf6d5be70cbf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTIwMDA1NA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r569200054", "bodyText": "done", "author": "n3nash", "createdAt": "2021-02-03T07:59:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg1ODA4Ng=="}], "type": "inlineReview", "revised_code": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\nindex 3b49d38e2..02f7c65ad 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\n", "chunk": "@@ -964,8 +964,8 @@ public class HoodieWriteConfig extends DefaultHoodieConfig {\n     return WriteConcurrencyMode.fromValue(props.getProperty(WRITE_CONCURRENCY_MODE_PROP));\n   }\n \n-  public Boolean isInlineTableServiceEnabled() {\n-    return isInlineClustering() || isInlineCompaction() || isInlineCleaning();\n+  public Boolean inlineTableServices() {\n+    return inlineClusteringEnabled() || inlineCompactionEnabled() || inlineCleaningEnabled();\n   }\n \n   public static class Builder {\n", "next_change": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\nindex 02f7c65ad..e95f0aa31 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\n", "chunk": "@@ -965,7 +1020,7 @@ public class HoodieWriteConfig extends DefaultHoodieConfig {\n   }\n \n   public Boolean inlineTableServices() {\n-    return inlineClusteringEnabled() || inlineCompactionEnabled() || inlineCleaningEnabled();\n+    return inlineClusteringEnabled() || inlineCompactionEnabled();\n   }\n \n   public static class Builder {\n", "next_change": {"commit": "1b522ef9c2fec7a32c7a1bfae2039e8f07a60d8f", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\nindex e95f0aa31..f7ad3a0fa 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\n", "chunk": "@@ -1020,7 +1020,7 @@ public class HoodieWriteConfig extends DefaultHoodieConfig {\n   }\n \n   public Boolean inlineTableServices() {\n-    return inlineClusteringEnabled() || inlineCompactionEnabled();\n+    return inlineClusteringEnabled() || inlineCompactionEnabled() || isAutoClean();\n   }\n \n   public static class Builder {\n", "next_change": {"commit": "1886bbd803f1a51e3d261705dd1283cfa8caf06b", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\nindex f7ad3a0fa..944cd0230 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\n", "chunk": "@@ -1023,6 +1028,10 @@ public class HoodieWriteConfig extends DefaultHoodieConfig {\n     return inlineClusteringEnabled() || inlineCompactionEnabled() || isAutoClean();\n   }\n \n+  public String getWriteMetaKeyPrefixes() {\n+    return props.getProperty(WRITE_META_KEY_PREFIXES_PROP);\n+  }\n+\n   public static class Builder {\n \n     protected final Properties props = new Properties();\n", "next_change": {"commit": "461047d03e9b7b73b34536ccf290a24f4aada6b0", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\nindex 944cd0230..f7ad3a0fa 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\n", "chunk": "@@ -1028,10 +1023,6 @@ public class HoodieWriteConfig extends DefaultHoodieConfig {\n     return inlineClusteringEnabled() || inlineCompactionEnabled() || isAutoClean();\n   }\n \n-  public String getWriteMetaKeyPrefixes() {\n-    return props.getProperty(WRITE_META_KEY_PREFIXES_PROP);\n-  }\n-\n   public static class Builder {\n \n     protected final Properties props = new Properties();\n", "next_change": {"commit": "a466320b7537bf2862df853344e80fbd0be6d16a", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\nindex f7ad3a0fa..944cd0230 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieWriteConfig.java\n", "chunk": "@@ -1023,6 +1028,10 @@ public class HoodieWriteConfig extends DefaultHoodieConfig {\n     return inlineClusteringEnabled() || inlineCompactionEnabled() || isAutoClean();\n   }\n \n+  public String getWriteMetaKeyPrefixes() {\n+    return props.getProperty(WRITE_META_KEY_PREFIXES_PROP);\n+  }\n+\n   public static class Builder {\n \n     protected final Properties props = new Properties();\n", "next_change": null}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg1ODM5NA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r568858394", "bodyText": "rename to initIfNeeded consistently", "author": "vinothchandar", "createdAt": "2021-02-02T19:06:08Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java", "diffHunk": "@@ -88,7 +88,7 @@\n   protected SerializableConfiguration hadoopConf;\n   protected final transient HoodieEngineContext engineContext;\n \n-  protected HoodieBackedTableMetadataWriter(Configuration hadoopConf, HoodieWriteConfig writeConfig, HoodieEngineContext engineContext) {\n+  protected HoodieBackedTableMetadataWriter(Configuration hadoopConf, HoodieWriteConfig writeConfig, HoodieEngineContext engineContext, boolean bootstrapIfNeeded) {", "originalCommit": "8b8d5945136066148f200d30c5d3bf6d5be70cbf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTE5OTY4NQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r569199685", "bodyText": "refactored to bootstrapMetadata", "author": "n3nash", "createdAt": "2021-02-03T07:58:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg1ODM5NA=="}], "type": "inlineReview", "revised_code": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java\nindex 479ec682a..0ec031ac5 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java\n", "chunk": "@@ -88,7 +88,7 @@ public abstract class HoodieBackedTableMetadataWriter implements HoodieTableMeta\n   protected SerializableConfiguration hadoopConf;\n   protected final transient HoodieEngineContext engineContext;\n \n-  protected HoodieBackedTableMetadataWriter(Configuration hadoopConf, HoodieWriteConfig writeConfig, HoodieEngineContext engineContext, boolean bootstrapIfNeeded) {\n+  protected HoodieBackedTableMetadataWriter(Configuration hadoopConf, HoodieWriteConfig writeConfig, HoodieEngineContext engineContext, boolean bootstrapMetadata) {\n     this.datasetWriteConfig = writeConfig;\n     this.engineContext = engineContext;\n     this.hadoopConf = new SerializableConfiguration(hadoopConf);\n", "next_change": {"commit": "0552abcc6400675c11ee35a4d4f3df109463f6f5", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java\nindex 0ec031ac5..312b980f2 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java\n", "chunk": "@@ -88,7 +89,8 @@ public abstract class HoodieBackedTableMetadataWriter implements HoodieTableMeta\n   protected SerializableConfiguration hadoopConf;\n   protected final transient HoodieEngineContext engineContext;\n \n-  protected HoodieBackedTableMetadataWriter(Configuration hadoopConf, HoodieWriteConfig writeConfig, HoodieEngineContext engineContext, boolean bootstrapMetadata) {\n+  protected HoodieBackedTableMetadataWriter(Configuration hadoopConf, HoodieWriteConfig writeConfig,\n+      HoodieEngineContext engineContext) {\n     this.datasetWriteConfig = writeConfig;\n     this.engineContext = engineContext;\n     this.hadoopConf = new SerializableConfiguration(hadoopConf);\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg1ODUzMQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r568858531", "bodyText": "we can also rename this method if needed", "author": "vinothchandar", "createdAt": "2021-02-02T19:06:22Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java", "diffHunk": "@@ -230,13 +235,18 @@ protected void initTableMetadata() {\n     }\n   }\n \n-  protected void bootstrapIfNeeded(HoodieEngineContext engineContext, HoodieTableMetaClient datasetMetaClient) throws IOException {\n-    HoodieTimer timer = new HoodieTimer().startTimer();\n-    boolean exists = datasetMetaClient.getFs().exists(new Path(metadataWriteConfig.getBasePath(), HoodieTableMetaClient.METAFOLDER_NAME));\n-    if (!exists) {\n-      // Initialize for the first time by listing partitions and files directly from the file system\n-      bootstrapFromFilesystem(engineContext, datasetMetaClient);\n-      metrics.ifPresent(m -> m.updateMetrics(HoodieMetadataMetrics.INITIALIZE_STR, timer.endTimer()));\n+  protected void bootstrapIfNeeded(HoodieEngineContext engineContext, HoodieTableMetaClient datasetMetaClient) {", "originalCommit": "8b8d5945136066148f200d30c5d3bf6d5be70cbf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTE5OTU3Nw==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r569199577", "bodyText": "refactored to bootstrapMetadata", "author": "n3nash", "createdAt": "2021-02-03T07:58:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODg1ODUzMQ=="}], "type": "inlineReview", "revised_code": {"commit": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java\nindex 479ec682a..0ec031ac5 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java\n", "chunk": "@@ -235,7 +235,7 @@ public abstract class HoodieBackedTableMetadataWriter implements HoodieTableMeta\n     }\n   }\n \n-  protected void bootstrapIfNeeded(HoodieEngineContext engineContext, HoodieTableMetaClient datasetMetaClient) {\n+  protected void bootstrapMetadata(HoodieEngineContext engineContext, HoodieTableMetaClient datasetMetaClient) {\n     try {\n       HoodieTimer timer = new HoodieTimer().startTimer();\n       boolean exists = datasetMetaClient.getFs().exists(new Path(metadataWriteConfig.getBasePath(), HoodieTableMetaClient.METAFOLDER_NAME));\n", "next_change": {"commit": "0552abcc6400675c11ee35a4d4f3df109463f6f5", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java\nindex 0ec031ac5..312b980f2 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java\n", "chunk": "@@ -235,18 +233,13 @@ public abstract class HoodieBackedTableMetadataWriter implements HoodieTableMeta\n     }\n   }\n \n-  protected void bootstrapMetadata(HoodieEngineContext engineContext, HoodieTableMetaClient datasetMetaClient) {\n-    try {\n-      HoodieTimer timer = new HoodieTimer().startTimer();\n-      boolean exists = datasetMetaClient.getFs().exists(new Path(metadataWriteConfig.getBasePath(), HoodieTableMetaClient.METAFOLDER_NAME));\n-      if (!exists) {\n-        // Initialize for the first time by listing partitions and files directly from the file system\n-        bootstrapFromFilesystem(engineContext, datasetMetaClient);\n-        metrics.ifPresent(m -> m.updateMetrics(HoodieMetadataMetrics.INITIALIZE_STR, timer.endTimer()));\n-      }\n-    } catch (IOException io) {\n-      LOG.error(\"Failed to initialize metadata table. Disabling the writer.\", io);\n-      enabled = false;\n+  protected void bootstrapIfNeeded(HoodieEngineContext engineContext, HoodieTableMetaClient datasetMetaClient) throws IOException {\n+    HoodieTimer timer = new HoodieTimer().startTimer();\n+    boolean exists = datasetMetaClient.getFs().exists(new Path(metadataWriteConfig.getBasePath(), HoodieTableMetaClient.METAFOLDER_NAME));\n+    if (!exists) {\n+      // Initialize for the first time by listing partitions and files directly from the file system\n+      bootstrapFromFilesystem(engineContext, datasetMetaClient);\n+      metrics.ifPresent(m -> m.updateMetrics(HoodieMetadataMetrics.INITIALIZE_STR, timer.endTimer()));\n     }\n   }\n \n", "next_change": {"commit": "4b0c990fea2cbacbbba92cdc4a96bb48a625653f", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java\nindex 312b980f2..da51c00fb 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/metadata/HoodieBackedTableMetadataWriter.java\n", "chunk": "@@ -236,6 +238,29 @@ public abstract class HoodieBackedTableMetadataWriter implements HoodieTableMeta\n   protected void bootstrapIfNeeded(HoodieEngineContext engineContext, HoodieTableMetaClient datasetMetaClient) throws IOException {\n     HoodieTimer timer = new HoodieTimer().startTimer();\n     boolean exists = datasetMetaClient.getFs().exists(new Path(metadataWriteConfig.getBasePath(), HoodieTableMetaClient.METAFOLDER_NAME));\n+    boolean rebootstrap = false;\n+    if (exists) {\n+      // If the un-synched instants have been archived then the metadata table will need to be bootstrapped again\n+      HoodieTableMetaClient metaClient = HoodieTableMetaClient.builder().setConf(hadoopConf.get())\n+          .setBasePath(metadataWriteConfig.getBasePath()).build();\n+      Option<HoodieInstant> latestMetadataInstant = metaClient.getActiveTimeline().filterCompletedInstants().lastInstant();\n+      if (!latestMetadataInstant.isPresent()) {\n+        LOG.warn(\"Metadata Table will need to be re-bootstrapped as no instants were found\");\n+        rebootstrap = true;\n+      } else if (datasetMetaClient.getActiveTimeline().isBeforeTimelineStarts(latestMetadataInstant.get().getTimestamp())) {\n+        LOG.warn(\"Metadata Table will need to be re-bootstrapped as un-synced instants have been archived.\"\n+            + \"latestMetadataInstant=\" + latestMetadataInstant.get().getTimestamp()\n+            + \", latestDatasetInstant=\" + datasetMetaClient.getActiveTimeline().firstInstant().get().getTimestamp());\n+        rebootstrap = true;\n+      }\n+    }\n+\n+    if (rebootstrap) {\n+      LOG.info(\"Deleting Metadata Table directory so that it can be re-bootstrapped\");\n+      datasetMetaClient.getFs().delete(new Path(metadataWriteConfig.getBasePath()), true);\n+      exists = false;\n+    }\n+\n     if (!exists) {\n       // Initialize for the first time by listing partitions and files directly from the file system\n       bootstrapFromFilesystem(engineContext, datasetMetaClient);\n", "next_change": null}]}}]}}]}}, {"oid": "e93d5994cbca54a8a3eb653437ff3df01df12ee7", "url": "https://github.com/apache/hudi/commit/e93d5994cbca54a8a3eb653437ff3df01df12ee7", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services", "committedDate": "2021-02-04T07:14:03Z", "type": "forcePushed"}, {"oid": "340efd27821ca9bfeac3bcf3f2cc616948440e2f", "url": "https://github.com/apache/hudi/commit/340efd27821ca9bfeac3bcf3f2cc616948440e2f", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services", "committedDate": "2021-02-04T07:16:17Z", "type": "forcePushed"}, {"oid": "09ba2a5ee6bd79ad616dd7cab835a8511878024b", "url": "https://github.com/apache/hudi/commit/09ba2a5ee6bd79ad616dd7cab835a8511878024b", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services", "committedDate": "2021-02-06T07:32:46Z", "type": "forcePushed"}, {"oid": "622880bf42140bb1e1df1874b8cce9f08c4a876d", "url": "https://github.com/apache/hudi/commit/622880bf42140bb1e1df1874b8cce9f08c4a876d", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services", "committedDate": "2021-02-06T08:16:24Z", "type": "forcePushed"}, {"oid": "25a4d7f70cc0cfcec115ddfcc2a543a96bcb17af", "url": "https://github.com/apache/hudi/commit/25a4d7f70cc0cfcec115ddfcc2a543a96bcb17af", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services", "committedDate": "2021-02-08T01:14:16Z", "type": "forcePushed"}, {"oid": "f5a56cb4137b5f32af17405277c29d5a9088b6c7", "url": "https://github.com/apache/hudi/commit/f5a56cb4137b5f32af17405277c29d5a9088b6c7", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services", "committedDate": "2021-02-08T05:00:58Z", "type": "forcePushed"}, {"oid": "21214cb86a490dc3e2f604a8419130ca9db2045a", "url": "https://github.com/apache/hudi/commit/21214cb86a490dc3e2f604a8419130ca9db2045a", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services", "committedDate": "2021-02-08T06:00:21Z", "type": "forcePushed"}, {"oid": "5f8950131414859ddc28a32fd3002eb1eb590e9b", "url": "https://github.com/apache/hudi/commit/5f8950131414859ddc28a32fd3002eb1eb590e9b", "message": "refactoring", "committedDate": "2021-02-09T18:15:47Z", "type": "forcePushed"}, {"oid": "11dcecf844466de7421139e5254f48ecc467f59c", "url": "https://github.com/apache/hudi/commit/11dcecf844466de7421139e5254f48ecc467f59c", "message": "refactoring", "committedDate": "2021-02-09T20:30:49Z", "type": "forcePushed"}, {"oid": "49dec09bfb444866e678fe956b28c3bf0ad2f373", "url": "https://github.com/apache/hudi/commit/49dec09bfb444866e678fe956b28c3bf0ad2f373", "message": "refactoring", "committedDate": "2021-02-15T03:57:26Z", "type": "forcePushed"}, {"oid": "d155914cd673d7699bb5258e6f9cafb85059673a", "url": "https://github.com/apache/hudi/commit/d155914cd673d7699bb5258e6f9cafb85059673a", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services", "committedDate": "2021-02-18T09:11:04Z", "type": "forcePushed"}, {"oid": "8f2bd5f5539fa72267c4c73c03068e9384df646f", "url": "https://github.com/apache/hudi/commit/8f2bd5f5539fa72267c4c73c03068e9384df646f", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services", "committedDate": "2021-02-19T07:56:26Z", "type": "forcePushed"}, {"oid": "9d857ed63bba87ec2528eb26bae1e69216814bdd", "url": "https://github.com/apache/hudi/commit/9d857ed63bba87ec2528eb26bae1e69216814bdd", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services", "committedDate": "2021-02-19T22:24:42Z", "type": "forcePushed"}, {"oid": "93cdfc8b6d57570cca44070d2f2498b25ad16741", "url": "https://github.com/apache/hudi/commit/93cdfc8b6d57570cca44070d2f2498b25ad16741", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services", "committedDate": "2021-02-19T23:59:23Z", "type": "forcePushed"}, {"oid": "0552abcc6400675c11ee35a4d4f3df109463f6f5", "url": "https://github.com/apache/hudi/commit/0552abcc6400675c11ee35a4d4f3df109463f6f5", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services", "committedDate": "2021-02-20T06:59:14Z", "type": "forcePushed"}, {"oid": "ab566b2002a39ebcc98cf5f16d2dc478bcbd1b29", "url": "https://github.com/apache/hudi/commit/ab566b2002a39ebcc98cf5f16d2dc478bcbd1b29", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services", "committedDate": "2021-02-20T07:27:02Z", "type": "forcePushed"}, {"oid": "289e45a28da6b91fba2a824ec2af3771a34b2930", "url": "https://github.com/apache/hudi/commit/289e45a28da6b91fba2a824ec2af3771a34b2930", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services", "committedDate": "2021-02-20T08:11:15Z", "type": "forcePushed"}, {"oid": "22b7a6a8e45945ce7175556e0c409263e8ffdc87", "url": "https://github.com/apache/hudi/commit/22b7a6a8e45945ce7175556e0c409263e8ffdc87", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services", "committedDate": "2021-02-21T23:04:20Z", "type": "forcePushed"}, {"oid": "15e25022abe1c2f4f1dff00057ad4d18860fb762", "url": "https://github.com/apache/hudi/commit/15e25022abe1c2f4f1dff00057ad4d18860fb762", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services", "committedDate": "2021-02-22T00:28:39Z", "type": "forcePushed"}, {"oid": "44a9129e627e3a61421bb130c816e2781bdd2eed", "url": "https://github.com/apache/hudi/commit/44a9129e627e3a61421bb130c816e2781bdd2eed", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services", "committedDate": "2021-02-22T06:39:46Z", "type": "forcePushed"}, {"oid": "df38dccc1f6c2193479d23ab62f4f24f27908b55", "url": "https://github.com/apache/hudi/commit/df38dccc1f6c2193479d23ab62f4f24f27908b55", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services", "committedDate": "2021-03-01T01:17:46Z", "type": "forcePushed"}, {"oid": "2d7d8901533555af7512dc4bc5c3deb489d503c7", "url": "https://github.com/apache/hudi/commit/2d7d8901533555af7512dc4bc5c3deb489d503c7", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services", "committedDate": "2021-03-01T01:50:20Z", "type": "forcePushed"}, {"oid": "61275eac2605bdb087762050588603bab4c4ee2d", "url": "https://github.com/apache/hudi/commit/61275eac2605bdb087762050588603bab4c4ee2d", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services", "committedDate": "2021-03-01T06:22:45Z", "type": "forcePushed"}, {"oid": "4b0c990fea2cbacbbba92cdc4a96bb48a625653f", "url": "https://github.com/apache/hudi/commit/4b0c990fea2cbacbbba92cdc4a96bb48a625653f", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services", "committedDate": "2021-03-04T05:18:23Z", "type": "forcePushed"}, {"oid": "27bae91298c897984335b1c6c3b39e758d962e6b", "url": "https://github.com/apache/hudi/commit/27bae91298c897984335b1c6c3b39e758d962e6b", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services", "committedDate": "2021-03-04T07:50:21Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzA0OTkxMA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587049910", "bodyText": "lock as a package name feels off to me. Can we have org.apache.hudi.client.transaction.TransactionManager?\nThen .lock can be a sub package under i.e .transaction.lock.", "author": "vinothchandar", "createdAt": "2021-03-04T03:37:54Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -30,16 +31,19 @@\n import org.apache.hudi.callback.util.HoodieCommitCallbackFactory;\n import org.apache.hudi.client.embedded.EmbeddedTimelineService;\n import org.apache.hudi.client.heartbeat.HeartbeatUtils;\n+import org.apache.hudi.client.lock.TransactionManager;", "originalCommit": "61275eac2605bdb087762050588603bab4c4ee2d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 11c8f0b95..12c55370f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -31,14 +31,14 @@ import org.apache.hudi.callback.common.HoodieWriteCommitCallbackMessage;\n import org.apache.hudi.callback.util.HoodieCommitCallbackFactory;\n import org.apache.hudi.client.embedded.EmbeddedTimelineService;\n import org.apache.hudi.client.heartbeat.HeartbeatUtils;\n-import org.apache.hudi.client.lock.TransactionManager;\n+import org.apache.hudi.client.transaction.TransactionManager;\n import org.apache.hudi.common.engine.HoodieEngineContext;\n import org.apache.hudi.common.model.HoodieCommitMetadata;\n import org.apache.hudi.common.model.HoodieFailedWritesCleaningPolicy;\n import org.apache.hudi.common.model.HoodieKey;\n import org.apache.hudi.common.model.HoodieRecordPayload;\n import org.apache.hudi.common.model.HoodieWriteStat;\n-import org.apache.hudi.common.model.TableService;\n+import org.apache.hudi.common.model.TableServiceType;\n import org.apache.hudi.common.model.WriteOperationType;\n import org.apache.hudi.common.table.HoodieTableMetaClient;\n import org.apache.hudi.common.table.timeline.HoodieActiveTimeline;\n", "next_change": {"commit": "1886bbd803f1a51e3d261705dd1283cfa8caf06b", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 12c55370f..80e79155b 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -32,6 +33,7 @@ import org.apache.hudi.callback.util.HoodieCommitCallbackFactory;\n import org.apache.hudi.client.embedded.EmbeddedTimelineService;\n import org.apache.hudi.client.heartbeat.HeartbeatUtils;\n import org.apache.hudi.client.transaction.TransactionManager;\n+import org.apache.hudi.client.utils.TransactionUtils;\n import org.apache.hudi.common.engine.HoodieEngineContext;\n import org.apache.hudi.common.model.HoodieCommitMetadata;\n import org.apache.hudi.common.model.HoodieFailedWritesCleaningPolicy;\n", "next_change": {"commit": "461047d03e9b7b73b34536ccf290a24f4aada6b0", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 80e79155b..656b209e7 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -33,7 +33,6 @@ import org.apache.hudi.callback.util.HoodieCommitCallbackFactory;\n import org.apache.hudi.client.embedded.EmbeddedTimelineService;\n import org.apache.hudi.client.heartbeat.HeartbeatUtils;\n import org.apache.hudi.client.transaction.TransactionManager;\n-import org.apache.hudi.client.utils.TransactionUtils;\n import org.apache.hudi.common.engine.HoodieEngineContext;\n import org.apache.hudi.common.model.HoodieCommitMetadata;\n import org.apache.hudi.common.model.HoodieFailedWritesCleaningPolicy;\n", "next_change": {"commit": "a466320b7537bf2862df853344e80fbd0be6d16a", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 656b209e7..096e644df 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -33,6 +33,7 @@ import org.apache.hudi.callback.util.HoodieCommitCallbackFactory;\n import org.apache.hudi.client.embedded.EmbeddedTimelineService;\n import org.apache.hudi.client.heartbeat.HeartbeatUtils;\n import org.apache.hudi.client.transaction.TransactionManager;\n+import org.apache.hudi.client.utils.TransactionUtils;\n import org.apache.hudi.common.engine.HoodieEngineContext;\n import org.apache.hudi.common.model.HoodieCommitMetadata;\n import org.apache.hudi.common.model.HoodieFailedWritesCleaningPolicy;\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzA1MDU3NA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587050574", "bodyText": "So, model package should just contain pojos i.e data structure objects. Lets move TableService elsewhere", "author": "vinothchandar", "createdAt": "2021-03-04T03:38:45Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -30,16 +31,19 @@\n import org.apache.hudi.callback.util.HoodieCommitCallbackFactory;\n import org.apache.hudi.client.embedded.EmbeddedTimelineService;\n import org.apache.hudi.client.heartbeat.HeartbeatUtils;\n+import org.apache.hudi.client.lock.TransactionManager;\n import org.apache.hudi.common.engine.HoodieEngineContext;\n import org.apache.hudi.common.model.HoodieCommitMetadata;\n import org.apache.hudi.common.model.HoodieFailedWritesCleaningPolicy;\n import org.apache.hudi.common.model.HoodieKey;\n import org.apache.hudi.common.model.HoodieRecordPayload;\n import org.apache.hudi.common.model.HoodieWriteStat;\n+import org.apache.hudi.common.model.TableService;", "originalCommit": "61275eac2605bdb087762050588603bab4c4ee2d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc3NzA4OQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587777089", "bodyText": "I kept it here because WriteOperationType is also here.", "author": "n3nash", "createdAt": "2021-03-04T19:55:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzA1MDU3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODY0NzIwOA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588647208", "bodyText": "If its an enum, its okay. I thought it had code. Still not a model per se, but we can do the moving in a different PR", "author": "vinothchandar", "createdAt": "2021-03-05T20:01:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzA1MDU3NA=="}], "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 11c8f0b95..12c55370f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -31,14 +31,14 @@ import org.apache.hudi.callback.common.HoodieWriteCommitCallbackMessage;\n import org.apache.hudi.callback.util.HoodieCommitCallbackFactory;\n import org.apache.hudi.client.embedded.EmbeddedTimelineService;\n import org.apache.hudi.client.heartbeat.HeartbeatUtils;\n-import org.apache.hudi.client.lock.TransactionManager;\n+import org.apache.hudi.client.transaction.TransactionManager;\n import org.apache.hudi.common.engine.HoodieEngineContext;\n import org.apache.hudi.common.model.HoodieCommitMetadata;\n import org.apache.hudi.common.model.HoodieFailedWritesCleaningPolicy;\n import org.apache.hudi.common.model.HoodieKey;\n import org.apache.hudi.common.model.HoodieRecordPayload;\n import org.apache.hudi.common.model.HoodieWriteStat;\n-import org.apache.hudi.common.model.TableService;\n+import org.apache.hudi.common.model.TableServiceType;\n import org.apache.hudi.common.model.WriteOperationType;\n import org.apache.hudi.common.table.HoodieTableMetaClient;\n import org.apache.hudi.common.table.timeline.HoodieActiveTimeline;\n", "next_change": {"commit": "1886bbd803f1a51e3d261705dd1283cfa8caf06b", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 12c55370f..80e79155b 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -32,6 +33,7 @@ import org.apache.hudi.callback.util.HoodieCommitCallbackFactory;\n import org.apache.hudi.client.embedded.EmbeddedTimelineService;\n import org.apache.hudi.client.heartbeat.HeartbeatUtils;\n import org.apache.hudi.client.transaction.TransactionManager;\n+import org.apache.hudi.client.utils.TransactionUtils;\n import org.apache.hudi.common.engine.HoodieEngineContext;\n import org.apache.hudi.common.model.HoodieCommitMetadata;\n import org.apache.hudi.common.model.HoodieFailedWritesCleaningPolicy;\n", "next_change": {"commit": "461047d03e9b7b73b34536ccf290a24f4aada6b0", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 80e79155b..656b209e7 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -33,7 +33,6 @@ import org.apache.hudi.callback.util.HoodieCommitCallbackFactory;\n import org.apache.hudi.client.embedded.EmbeddedTimelineService;\n import org.apache.hudi.client.heartbeat.HeartbeatUtils;\n import org.apache.hudi.client.transaction.TransactionManager;\n-import org.apache.hudi.client.utils.TransactionUtils;\n import org.apache.hudi.common.engine.HoodieEngineContext;\n import org.apache.hudi.common.model.HoodieCommitMetadata;\n import org.apache.hudi.common.model.HoodieFailedWritesCleaningPolicy;\n", "next_change": {"commit": "a466320b7537bf2862df853344e80fbd0be6d16a", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 656b209e7..096e644df 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -33,6 +33,7 @@ import org.apache.hudi.callback.util.HoodieCommitCallbackFactory;\n import org.apache.hudi.client.embedded.EmbeddedTimelineService;\n import org.apache.hudi.client.heartbeat.HeartbeatUtils;\n import org.apache.hudi.client.transaction.TransactionManager;\n+import org.apache.hudi.client.utils.TransactionUtils;\n import org.apache.hudi.common.engine.HoodieEngineContext;\n import org.apache.hudi.common.model.HoodieCommitMetadata;\n import org.apache.hudi.common.model.HoodieFailedWritesCleaningPolicy;\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzA1MTc5OA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587051798", "bodyText": "lets move the preCommit() call out of here? commit() calling preCommit() is bit confusing to read", "author": "vinothchandar", "createdAt": "2021-03-04T03:40:26Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -193,8 +200,22 @@ public boolean commitStats(String instantTime, List<HoodieWriteStat> stats, Opti\n     return true;\n   }\n \n+  protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n+                      List<HoodieWriteStat> stats) throws IOException {\n+    preCommit(instantTime, metadata);", "originalCommit": "61275eac2605bdb087762050588603bab4c4ee2d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 11c8f0b95..12c55370f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -202,7 +203,6 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n   protected void commit(HoodieTable table, String commitActionType, String instantTime, HoodieCommitMetadata metadata,\n                       List<HoodieWriteStat> stats) throws IOException {\n-    preCommit(instantTime, metadata);\n     LOG.info(\"Committing \" + instantTime + \" action \" + commitActionType);\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n", "next_change": {"commit": "02efbb661e7ed13c3614ddee7ab5157623070f7c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 12c55370f..996648c0e 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -207,15 +210,12 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     HoodieActiveTimeline activeTimeline = table.getActiveTimeline();\n     // Finalize write\n     finalizeWrite(table, instantTime, stats);\n-    syncTableMetadata();\n     activeTimeline.saveAsComplete(new HoodieInstant(true, commitActionType, instantTime),\n         Option.of(metadata.toJsonString().getBytes(StandardCharsets.UTF_8)));\n   }\n \n   protected abstract HoodieTable<T, I, K, O> createTable(HoodieWriteConfig config, Configuration hadoopConf);\n \n-  protected abstract HoodieBackedTableMetadataWriter createMetadataWriter(HoodieWriteConfig config, Configuration hadoopConf);\n-\n   void emitCommitMetrics(String instantTime, HoodieCommitMetadata metadata, String actionType) {\n     try {\n \n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzA1MjIyMg==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587052222", "bodyText": "typo: not supported", "author": "vinothchandar", "createdAt": "2021-03-04T03:40:59Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -210,6 +231,11 @@ void emitCommitMetrics(String instantTime, HoodieCommitMetadata metadata, String\n     }\n   }\n \n+  protected void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n+    // no-op\n+    // TODO : Conflict resolution is not support for Flink,Java engines", "originalCommit": "61275eac2605bdb087762050588603bab4c4ee2d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 11c8f0b95..12c55370f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -233,7 +233,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n \n   protected void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n     // no-op\n-    // TODO : Conflict resolution is not support for Flink,Java engines\n+    // TODO : Conflict resolution is not supported for Flink & Java engines\n   }\n \n   protected void syncTableMetadata() {\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzA1NDQxMA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587054410", "bodyText": "can the above setters be passed to an overloaded beginTransaction(..) call? Whenever we have these contracts that some setters must be called ahead of a beginTransaction, makes for a harder maintenance/read", "author": "vinothchandar", "createdAt": "2021-03-04T03:43:34Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -359,10 +388,21 @@ public abstract O bulkInsertPreppedRecords(I preppedRecords, final String instan\n    * Common method containing steps to be performed before write (upsert/insert/...\n    * @param instantTime\n    * @param writeOperationType\n+   * @param metaClient\n    */\n-  protected void preWrite(String instantTime, WriteOperationType writeOperationType) {\n+  protected void preWrite(String instantTime, WriteOperationType writeOperationType,\n+      HoodieTableMetaClient metaClient) {\n     setOperationType(writeOperationType);\n-    syncTableMetadata();\n+    this.txnManager.setLastCompletedTransaction(metaClient.getActiveTimeline().getCommitsTimeline().filterCompletedInstants()\n+        .lastInstant());\n+    LOG.info(\"Last Instant Cached by writer with instant \" + instantTime + \" is \" + this.txnManager.getLastCompletedTransactionOwner());\n+    this.txnManager.setTransactionOwner(Option.of(new HoodieInstant(State.INFLIGHT, metaClient.getCommitActionType(), instantTime)));\n+    this.txnManager.beginTransaction();", "originalCommit": "61275eac2605bdb087762050588603bab4c4ee2d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc3OTUwOA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587779508", "bodyText": "I also realized this during implementation but wanted to keep beginTransaction(..) API simple. I've added a overridden method now", "author": "n3nash", "createdAt": "2021-03-04T19:58:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzA1NDQxMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODY0ODg3MA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588648870", "bodyText": "Understood. but if some calls are needed prior to this, then either the object constructor should take them or the method should take them as arguments. Or we have a transaction builder or sorts.\nSo I would say, if this is always the case, i.e the setters are needed, then we change the beginTransaction() signature for good, not just an overload.", "author": "vinothchandar", "createdAt": "2021-03-05T20:03:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzA1NDQxMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODkzMzE0MA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588933140", "bodyText": "Made changes accordingly", "author": "n3nash", "createdAt": "2021-03-06T21:27:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzA1NDQxMA=="}], "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 11c8f0b95..12c55370f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -393,11 +393,9 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n   protected void preWrite(String instantTime, WriteOperationType writeOperationType,\n       HoodieTableMetaClient metaClient) {\n     setOperationType(writeOperationType);\n-    this.txnManager.setLastCompletedTransaction(metaClient.getActiveTimeline().getCommitsTimeline().filterCompletedInstants()\n-        .lastInstant());\n-    LOG.info(\"Last Instant Cached by writer with instant \" + instantTime + \" is \" + this.txnManager.getLastCompletedTransactionOwner());\n-    this.txnManager.setTransactionOwner(Option.of(new HoodieInstant(State.INFLIGHT, metaClient.getCommitActionType(), instantTime)));\n-    this.txnManager.beginTransaction();\n+    this.txnManager.beginTransaction(Option.of(new HoodieInstant(State.INFLIGHT, metaClient.getCommitActionType(), instantTime)),\n+        metaClient.getActiveTimeline().getCommitsTimeline().filterCompletedInstants()\n+            .lastInstant());\n     try {\n       syncTableMetadata();\n     } finally {\n", "next_change": {"commit": "1b522ef9c2fec7a32c7a1bfae2039e8f07a60d8f", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 12c55370f..f663e64d4 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -393,9 +396,9 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n   protected void preWrite(String instantTime, WriteOperationType writeOperationType,\n       HoodieTableMetaClient metaClient) {\n     setOperationType(writeOperationType);\n-    this.txnManager.beginTransaction(Option.of(new HoodieInstant(State.INFLIGHT, metaClient.getCommitActionType(), instantTime)),\n-        metaClient.getActiveTimeline().getCommitsTimeline().filterCompletedInstants()\n-            .lastInstant());\n+    this.lastCompletedTxn = metaClient.getActiveTimeline().getCommitsTimeline().filterCompletedInstants()\n+        .lastInstant();\n+    this.txnManager.beginTransaction(Option.of(new HoodieInstant(State.INFLIGHT, metaClient.getCommitActionType(), instantTime)), lastCompletedTxn);\n     try {\n       syncTableMetadata();\n     } finally {\n", "next_change": {"commit": "1886bbd803f1a51e3d261705dd1283cfa8caf06b", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex f663e64d4..80e79155b 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -396,9 +393,10 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n   protected void preWrite(String instantTime, WriteOperationType writeOperationType,\n       HoodieTableMetaClient metaClient) {\n     setOperationType(writeOperationType);\n-    this.lastCompletedTxn = metaClient.getActiveTimeline().getCommitsTimeline().filterCompletedInstants()\n-        .lastInstant();\n-    this.txnManager.beginTransaction(Option.of(new HoodieInstant(State.INFLIGHT, metaClient.getCommitActionType(), instantTime)), lastCompletedTxn);\n+    this.lastCompletedTxnAndMetadata = TransactionUtils.getLastCompletedTxnInstantAndMetadata(metaClient);\n+    this.txnManager.beginTransaction(Option.of(new HoodieInstant(State.INFLIGHT, metaClient.getCommitActionType(), instantTime)), lastCompletedTxnAndMetadata\n+        .isPresent()\n+        ? Option.of(lastCompletedTxnAndMetadata.get().getLeft()) : Option.empty());\n     try {\n       syncTableMetadata();\n     } finally {\n", "next_change": {"commit": "461047d03e9b7b73b34536ccf290a24f4aada6b0", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 80e79155b..656b209e7 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -393,10 +392,9 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n   protected void preWrite(String instantTime, WriteOperationType writeOperationType,\n       HoodieTableMetaClient metaClient) {\n     setOperationType(writeOperationType);\n-    this.lastCompletedTxnAndMetadata = TransactionUtils.getLastCompletedTxnInstantAndMetadata(metaClient);\n-    this.txnManager.beginTransaction(Option.of(new HoodieInstant(State.INFLIGHT, metaClient.getCommitActionType(), instantTime)), lastCompletedTxnAndMetadata\n-        .isPresent()\n-        ? Option.of(lastCompletedTxnAndMetadata.get().getLeft()) : Option.empty());\n+    this.lastCompletedTxn = metaClient.getActiveTimeline().getCommitsTimeline().filterCompletedInstants()\n+        .lastInstant();\n+    this.txnManager.beginTransaction(Option.of(new HoodieInstant(State.INFLIGHT, metaClient.getCommitActionType(), instantTime)), lastCompletedTxn);\n     try {\n       syncTableMetadata();\n     } finally {\n", "next_change": {"commit": "a466320b7537bf2862df853344e80fbd0be6d16a", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 656b209e7..096e644df 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -392,9 +391,10 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n   protected void preWrite(String instantTime, WriteOperationType writeOperationType,\n       HoodieTableMetaClient metaClient) {\n     setOperationType(writeOperationType);\n-    this.lastCompletedTxn = metaClient.getActiveTimeline().getCommitsTimeline().filterCompletedInstants()\n-        .lastInstant();\n-    this.txnManager.beginTransaction(Option.of(new HoodieInstant(State.INFLIGHT, metaClient.getCommitActionType(), instantTime)), lastCompletedTxn);\n+    this.lastCompletedTxnAndMetadata = TransactionUtils.getLastCompletedTxnInstantAndMetadata(metaClient);\n+    this.txnManager.beginTransaction(Option.of(new HoodieInstant(State.INFLIGHT, metaClient.getCommitActionType(), instantTime)), lastCompletedTxnAndMetadata\n+        .isPresent()\n+        ? Option.of(lastCompletedTxnAndMetadata.get().getLeft()) : Option.empty());\n     try {\n       syncTableMetadata();\n     } finally {\n", "next_change": null}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzA1NTM5Nw==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587055397", "bodyText": "do we need to distinguish between endTransaction() and an abort ? i.e any cleanups in the transaction manager to be done here upon exception?", "author": "vinothchandar", "createdAt": "2021-03-04T03:44:37Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -359,10 +388,21 @@ public abstract O bulkInsertPreppedRecords(I preppedRecords, final String instan\n    * Common method containing steps to be performed before write (upsert/insert/...\n    * @param instantTime\n    * @param writeOperationType\n+   * @param metaClient\n    */\n-  protected void preWrite(String instantTime, WriteOperationType writeOperationType) {\n+  protected void preWrite(String instantTime, WriteOperationType writeOperationType,\n+      HoodieTableMetaClient metaClient) {\n     setOperationType(writeOperationType);\n-    syncTableMetadata();\n+    this.txnManager.setLastCompletedTransaction(metaClient.getActiveTimeline().getCommitsTimeline().filterCompletedInstants()\n+        .lastInstant());\n+    LOG.info(\"Last Instant Cached by writer with instant \" + instantTime + \" is \" + this.txnManager.getLastCompletedTransactionOwner());\n+    this.txnManager.setTransactionOwner(Option.of(new HoodieInstant(State.INFLIGHT, metaClient.getCommitActionType(), instantTime)));\n+    this.txnManager.beginTransaction();\n+    try {\n+      syncTableMetadata();\n+    } finally {\n+      this.txnManager.endTransaction();", "originalCommit": "61275eac2605bdb087762050588603bab4c4ee2d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODExOTc1OA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588119758", "bodyText": "Right now, endTransaction() is doing the job or end & abort - no difference in behavior. Both ensure that if lock was acquired release and cleanup other state.", "author": "n3nash", "createdAt": "2021-03-05T08:37:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzA1NTM5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODY1MDIwMA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588650200", "bodyText": "I was wondering about the following scenario. if the cleanup fails, I guess it throws an error in both cases also? if so, this is okay. gtg", "author": "vinothchandar", "createdAt": "2021-03-05T20:05:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzA1NTM5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODg1Nzc0Mw==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588857743", "bodyText": "Yes, underlying unlock implementation should throw error.", "author": "n3nash", "createdAt": "2021-03-06T09:15:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzA1NTM5Nw=="}], "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 11c8f0b95..12c55370f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -393,11 +393,9 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n   protected void preWrite(String instantTime, WriteOperationType writeOperationType,\n       HoodieTableMetaClient metaClient) {\n     setOperationType(writeOperationType);\n-    this.txnManager.setLastCompletedTransaction(metaClient.getActiveTimeline().getCommitsTimeline().filterCompletedInstants()\n-        .lastInstant());\n-    LOG.info(\"Last Instant Cached by writer with instant \" + instantTime + \" is \" + this.txnManager.getLastCompletedTransactionOwner());\n-    this.txnManager.setTransactionOwner(Option.of(new HoodieInstant(State.INFLIGHT, metaClient.getCommitActionType(), instantTime)));\n-    this.txnManager.beginTransaction();\n+    this.txnManager.beginTransaction(Option.of(new HoodieInstant(State.INFLIGHT, metaClient.getCommitActionType(), instantTime)),\n+        metaClient.getActiveTimeline().getCommitsTimeline().filterCompletedInstants()\n+            .lastInstant());\n     try {\n       syncTableMetadata();\n     } finally {\n", "next_change": {"commit": "1b522ef9c2fec7a32c7a1bfae2039e8f07a60d8f", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 12c55370f..f663e64d4 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -393,9 +396,9 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n   protected void preWrite(String instantTime, WriteOperationType writeOperationType,\n       HoodieTableMetaClient metaClient) {\n     setOperationType(writeOperationType);\n-    this.txnManager.beginTransaction(Option.of(new HoodieInstant(State.INFLIGHT, metaClient.getCommitActionType(), instantTime)),\n-        metaClient.getActiveTimeline().getCommitsTimeline().filterCompletedInstants()\n-            .lastInstant());\n+    this.lastCompletedTxn = metaClient.getActiveTimeline().getCommitsTimeline().filterCompletedInstants()\n+        .lastInstant();\n+    this.txnManager.beginTransaction(Option.of(new HoodieInstant(State.INFLIGHT, metaClient.getCommitActionType(), instantTime)), lastCompletedTxn);\n     try {\n       syncTableMetadata();\n     } finally {\n", "next_change": {"commit": "1886bbd803f1a51e3d261705dd1283cfa8caf06b", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex f663e64d4..80e79155b 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -396,9 +393,10 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n   protected void preWrite(String instantTime, WriteOperationType writeOperationType,\n       HoodieTableMetaClient metaClient) {\n     setOperationType(writeOperationType);\n-    this.lastCompletedTxn = metaClient.getActiveTimeline().getCommitsTimeline().filterCompletedInstants()\n-        .lastInstant();\n-    this.txnManager.beginTransaction(Option.of(new HoodieInstant(State.INFLIGHT, metaClient.getCommitActionType(), instantTime)), lastCompletedTxn);\n+    this.lastCompletedTxnAndMetadata = TransactionUtils.getLastCompletedTxnInstantAndMetadata(metaClient);\n+    this.txnManager.beginTransaction(Option.of(new HoodieInstant(State.INFLIGHT, metaClient.getCommitActionType(), instantTime)), lastCompletedTxnAndMetadata\n+        .isPresent()\n+        ? Option.of(lastCompletedTxnAndMetadata.get().getLeft()) : Option.empty());\n     try {\n       syncTableMetadata();\n     } finally {\n", "next_change": {"commit": "461047d03e9b7b73b34536ccf290a24f4aada6b0", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 80e79155b..656b209e7 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -393,10 +392,9 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n   protected void preWrite(String instantTime, WriteOperationType writeOperationType,\n       HoodieTableMetaClient metaClient) {\n     setOperationType(writeOperationType);\n-    this.lastCompletedTxnAndMetadata = TransactionUtils.getLastCompletedTxnInstantAndMetadata(metaClient);\n-    this.txnManager.beginTransaction(Option.of(new HoodieInstant(State.INFLIGHT, metaClient.getCommitActionType(), instantTime)), lastCompletedTxnAndMetadata\n-        .isPresent()\n-        ? Option.of(lastCompletedTxnAndMetadata.get().getLeft()) : Option.empty());\n+    this.lastCompletedTxn = metaClient.getActiveTimeline().getCommitsTimeline().filterCompletedInstants()\n+        .lastInstant();\n+    this.txnManager.beginTransaction(Option.of(new HoodieInstant(State.INFLIGHT, metaClient.getCommitActionType(), instantTime)), lastCompletedTxn);\n     try {\n       syncTableMetadata();\n     } finally {\n", "next_change": {"commit": "a466320b7537bf2862df853344e80fbd0be6d16a", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 656b209e7..096e644df 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -392,9 +391,10 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n   protected void preWrite(String instantTime, WriteOperationType writeOperationType,\n       HoodieTableMetaClient metaClient) {\n     setOperationType(writeOperationType);\n-    this.lastCompletedTxn = metaClient.getActiveTimeline().getCommitsTimeline().filterCompletedInstants()\n-        .lastInstant();\n-    this.txnManager.beginTransaction(Option.of(new HoodieInstant(State.INFLIGHT, metaClient.getCommitActionType(), instantTime)), lastCompletedTxn);\n+    this.lastCompletedTxnAndMetadata = TransactionUtils.getLastCompletedTxnInstantAndMetadata(metaClient);\n+    this.txnManager.beginTransaction(Option.of(new HoodieInstant(State.INFLIGHT, metaClient.getCommitActionType(), instantTime)), lastCompletedTxnAndMetadata\n+        .isPresent()\n+        ? Option.of(lastCompletedTxnAndMetadata.get().getLeft()) : Option.empty());\n     try {\n       syncTableMetadata();\n     } finally {\n", "next_change": null}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzA1NjIzMA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587056230", "bodyText": "duplicate line?", "author": "vinothchandar", "createdAt": "2021-03-04T03:45:36Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -389,29 +429,33 @@ protected void postCommit(HoodieTable<T, I, K, O> table, HoodieCommitMetadata me\n       // Delete the marker directory for the instant.\n       new MarkerFiles(table, instantTime).quietDeleteMarkerDir(context, config.getMarkersDeleteParallelism());\n \n-      // Do an inline compaction if enabled\n-      if (config.isInlineCompaction()) {\n-        runAnyPendingCompactions(table);\n-        metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"true\");\n-        inlineCompact(extraMetadata);\n-      } else {\n-        metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"false\");\n-      }\n+      if (config.inlineTableServices()) {\n+        // Do an inline compaction if enabled\n+        if (config.inlineCompactionEnabled()) {\n+          runAnyPendingCompactions(table);\n+          metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"true\");\n+          inlineCompact(extraMetadata);\n+        } else {\n+          metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"false\");\n+        }\n \n-      // Do an inline clustering if enabled\n-      if (config.isInlineClustering()) {\n-        runAnyPendingClustering(table);\n-        metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"true\");\n-        inlineCluster(extraMetadata);\n-      } else {\n-        metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n+        // Do an inline clustering if enabled\n+        if (config.inlineClusteringEnabled()) {\n+          runAnyPendingClustering(table);\n+          metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"true\");\n+          inlineCluster(extraMetadata);\n+        } else {\n+          metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");", "originalCommit": "61275eac2605bdb087762050588603bab4c4ee2d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 11c8f0b95..12c55370f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -446,12 +444,11 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n           inlineCluster(extraMetadata);\n         } else {\n           metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n-          metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n         }\n         // We cannot have unbounded commit files. Archive commits if we have to archive\n         HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(config, table);\n         archiveLog.archiveIfRequired(context);\n-        if (config.isAutoClean() || config.inlineCleaningEnabled()) {\n+        if (config.isAutoClean()) {\n           autoCleanOnCommit();\n         }\n         syncTableMetadata();\n", "next_change": {"commit": "02efbb661e7ed13c3614ddee7ab5157623070f7c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 12c55370f..996648c0e 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -445,14 +445,12 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n         } else {\n           metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n         }\n-        // We cannot have unbounded commit files. Archive commits if we have to archive\n-        HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(config, table);\n-        archiveLog.archiveIfRequired(context);\n-        if (config.isAutoClean()) {\n-          autoCleanOnCommit();\n-        }\n-        syncTableMetadata();\n       }\n+      // We cannot have unbounded commit files. Archive commits if we have to archive\n+      HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(config, table);\n+      archiveLog.archiveIfRequired(context);\n+      autoCleanOnCommit();\n+      syncTableMetadata();\n     } catch (IOException ioe) {\n       throw new HoodieIOException(ioe.getMessage(), ioe);\n     } finally {\n", "next_change": {"commit": "8c092be25de58e65cd339478e9b2c0ba37d20e5e", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 996648c0e..da2430225 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -423,29 +424,8 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n    */\n   protected void postCommit(HoodieTable<T, I, K, O> table, HoodieCommitMetadata metadata, String instantTime, Option<Map<String, String>> extraMetadata) {\n     try {\n-\n       // Delete the marker directory for the instant.\n       new MarkerFiles(table, instantTime).quietDeleteMarkerDir(context, config.getMarkersDeleteParallelism());\n-\n-      if (config.inlineTableServices()) {\n-        // Do an inline compaction if enabled\n-        if (config.inlineCompactionEnabled()) {\n-          runAnyPendingCompactions(table);\n-          metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"true\");\n-          inlineCompact(extraMetadata);\n-        } else {\n-          metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"false\");\n-        }\n-\n-        // Do an inline clustering if enabled\n-        if (config.inlineClusteringEnabled()) {\n-          runAnyPendingClustering(table);\n-          metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"true\");\n-          inlineCluster(extraMetadata);\n-        } else {\n-          metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n-        }\n-      }\n       // We cannot have unbounded commit files. Archive commits if we have to archive\n       HoodieTimelineArchiveLog archiveLog = new HoodieTimelineArchiveLog(config, table);\n       archiveLog.archiveIfRequired(context);\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 996648c0e..da2430225 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -458,6 +438,28 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     }\n   }\n \n+  protected void runTableServices(HoodieTable<T, I, K, O> table, HoodieCommitMetadata metadata, Option<Map<String, String>> extraMetadata) {\n+    if (config.inlineTableServices()) {\n+      // Do an inline compaction if enabled\n+      if (config.inlineCompactionEnabled()) {\n+        runAnyPendingCompactions(table);\n+        metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"true\");\n+        inlineCompact(extraMetadata);\n+      } else {\n+        metadata.addMetadata(HoodieCompactionConfig.INLINE_COMPACT_PROP, \"false\");\n+      }\n+\n+      // Do an inline clustering if enabled\n+      if (config.inlineClusteringEnabled()) {\n+        runAnyPendingClustering(table);\n+        metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"true\");\n+        inlineCluster(extraMetadata);\n+      } else {\n+        metadata.addMetadata(HoodieClusteringConfig.INLINE_CLUSTERING_PROP, \"false\");\n+      }\n+    }\n+  }\n+\n   protected void runAnyPendingCompactions(HoodieTable<T, I, K, O> table) {\n     table.getActiveTimeline().getWriteTimeline().filterPendingCompactionTimeline().getInstants()\n         .forEach(instant -> {\n", "next_change": {"commit": "d47718945d2ad86eb653daafc03f1f74a57b6881", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex da2430225..edc8dc47a 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -438,7 +438,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n     }\n   }\n \n-  protected void runTableServices(HoodieTable<T, I, K, O> table, HoodieCommitMetadata metadata, Option<Map<String, String>> extraMetadata) {\n+  protected void runTableServicesInline(HoodieTable<T, I, K, O> table, HoodieCommitMetadata metadata, Option<Map<String, String>> extraMetadata) {\n     if (config.inlineTableServices()) {\n       // Do an inline compaction if enabled\n       if (config.inlineCompactionEnabled()) {\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzA1NzgzMQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587057831", "bodyText": "rename: compactionInstantTime", "author": "vinothchandar", "createdAt": "2021-03-04T03:47:39Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java", "diffHunk": "@@ -797,7 +853,9 @@ public Boolean rollbackFailedWrites() {\n    * Performs a compaction operation on a table, serially before or after an insert/upsert action.\n    */\n   protected Option<String> inlineCompact(Option<Map<String, String>> extraMetadata) {\n-    Option<String> compactionInstantTimeOpt = scheduleCompaction(extraMetadata);\n+    String schedulingCompactionInstant = HoodieActiveTimeline.createNewInstantTime();", "originalCommit": "61275eac2605bdb087762050588603bab4c4ee2d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 11c8f0b95..12c55370f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -853,12 +855,12 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n    * Performs a compaction operation on a table, serially before or after an insert/upsert action.\n    */\n   protected Option<String> inlineCompact(Option<Map<String, String>> extraMetadata) {\n-    String schedulingCompactionInstant = HoodieActiveTimeline.createNewInstantTime();\n-    Option<String> compactionInstantTimeOpt = scheduleTableServiceInternal(schedulingCompactionInstant,\n-        extraMetadata, TableService.COMPACT);\n-    compactionInstantTimeOpt.ifPresent(compactionInstantTime -> {\n+    String compactionInstantTime = HoodieActiveTimeline.createNewInstantTime();\n+    Option<String> compactionInstantTimeOpt = scheduleTableServiceInternal(compactionInstantTime,\n+        extraMetadata, TableServiceType.COMPACT);\n+    compactionInstantTimeOpt.ifPresent(compactInstantTime -> {\n       // inline compaction should auto commit as the user is never given control\n-      compact(compactionInstantTime, true);\n+      compact(compactInstantTime, true);\n     });\n     return compactionInstantTimeOpt;\n   }\n", "next_change": {"commit": "8c092be25de58e65cd339478e9b2c0ba37d20e5e", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex 12c55370f..da2430225 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -855,9 +854,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n    * Performs a compaction operation on a table, serially before or after an insert/upsert action.\n    */\n   protected Option<String> inlineCompact(Option<Map<String, String>> extraMetadata) {\n-    String compactionInstantTime = HoodieActiveTimeline.createNewInstantTime();\n-    Option<String> compactionInstantTimeOpt = scheduleTableServiceInternal(compactionInstantTime,\n-        extraMetadata, TableServiceType.COMPACT);\n+    Option<String> compactionInstantTimeOpt = scheduleTableService(extraMetadata, TableServiceType.COMPACT);\n     compactionInstantTimeOpt.ifPresent(compactInstantTime -> {\n       // inline compaction should auto commit as the user is never given control\n       compact(compactInstantTime, true);\n", "next_change": {"commit": "2a305dc45a1a175ebb07c96b9a9e8c698088283e", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\nindex da2430225..9f3b74b0c 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/AbstractHoodieWriteClient.java\n", "chunk": "@@ -854,7 +850,7 @@ public abstract class AbstractHoodieWriteClient<T extends HoodieRecordPayload, I\n    * Performs a compaction operation on a table, serially before or after an insert/upsert action.\n    */\n   protected Option<String> inlineCompact(Option<Map<String, String>> extraMetadata) {\n-    Option<String> compactionInstantTimeOpt = scheduleTableService(extraMetadata, TableServiceType.COMPACT);\n+    Option<String> compactionInstantTimeOpt = scheduleCompaction(extraMetadata);\n     compactionInstantTimeOpt.ifPresent(compactInstantTime -> {\n       // inline compaction should auto commit as the user is never given control\n       compact(compactInstantTime, true);\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcwNDQ4Ng==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587704486", "bodyText": "rename: getCandidateInstants() to clarify intent.", "author": "vinothchandar", "createdAt": "2021-03-04T18:14:24Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java", "diffHunk": "@@ -0,0 +1,64 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.hudi.ApiMaturityLevel;\n+import org.apache.hudi.PublicAPIMethod;\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.table.timeline.HoodieActiveTimeline;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n+import org.apache.hudi.table.HoodieTable;\n+\n+import java.util.stream.Stream;\n+\n+/**\n+ * Strategy interface for conflict resolution with multiple writers.\n+ * Users can provide pluggable implementations for different kinds of strategies to resolve conflicts when multiple\n+ * writers are mutating the hoodie table.\n+ */\n+public interface ConflictResolutionStrategy {\n+\n+  /**\n+   * Stream of instants to check conflicts against.\n+   * @return\n+   */\n+  Stream<HoodieInstant> getInstantsStream(HoodieActiveTimeline activeTimeline, HoodieInstant currentInstant, Option<HoodieInstant> lastSuccessfulInstant);", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\nsimilarity index 81%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\nindex 12a788ee8..d6bc8d333 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\n", "chunk": "@@ -16,7 +16,7 @@\n  * limitations under the License.\n  */\n \n-package org.apache.hudi.client.lock;\n+package org.apache.hudi.client.transaction;\n \n import org.apache.hudi.ApiMaturityLevel;\n import org.apache.hudi.PublicAPIMethod;\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\nsimilarity index 81%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\nindex 12a788ee8..d6bc8d333 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\n", "chunk": "@@ -24,7 +24,6 @@ import org.apache.hudi.common.model.HoodieCommitMetadata;\n import org.apache.hudi.common.table.timeline.HoodieActiveTimeline;\n import org.apache.hudi.common.table.timeline.HoodieInstant;\n import org.apache.hudi.common.util.Option;\n-import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n import org.apache.hudi.table.HoodieTable;\n \n import java.util.stream.Stream;\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\nsimilarity index 81%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\nindex 12a788ee8..d6bc8d333 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\n", "chunk": "@@ -40,7 +39,7 @@ public interface ConflictResolutionStrategy {\n    * Stream of instants to check conflicts against.\n    * @return\n    */\n-  Stream<HoodieInstant> getInstantsStream(HoodieActiveTimeline activeTimeline, HoodieInstant currentInstant, Option<HoodieInstant> lastSuccessfulInstant);\n+  Stream<HoodieInstant> getCandidateInstants(HoodieActiveTimeline activeTimeline, HoodieInstant currentInstant, Option<HoodieInstant> lastSuccessfulInstant);\n \n   /**\n    * Implementations of this method will determine whether a conflict exists between 2 commits.\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\nsimilarity index 81%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\nindex 12a788ee8..d6bc8d333 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\n", "chunk": "@@ -58,7 +57,7 @@ public interface ConflictResolutionStrategy {\n    * @return\n    */\n   @PublicAPIMethod(maturity = ApiMaturityLevel.EVOLVING)\n-  Option<HoodieCommitMetadata> resolveConflict(Option<HoodieBackedTableMetadataWriter> metadataWriter, HoodieTable table,\n-                                       HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation);\n+  Option<HoodieCommitMetadata> resolveConflict(HoodieTable table,\n+      HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation);\n \n }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcwNDYzMg==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587704632", "bodyText": "this reads nicely :)", "author": "vinothchandar", "createdAt": "2021-03-04T18:14:40Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java", "diffHunk": "@@ -0,0 +1,64 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.hudi.ApiMaturityLevel;\n+import org.apache.hudi.PublicAPIMethod;\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.table.timeline.HoodieActiveTimeline;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n+import org.apache.hudi.table.HoodieTable;\n+\n+import java.util.stream.Stream;\n+\n+/**\n+ * Strategy interface for conflict resolution with multiple writers.\n+ * Users can provide pluggable implementations for different kinds of strategies to resolve conflicts when multiple\n+ * writers are mutating the hoodie table.\n+ */\n+public interface ConflictResolutionStrategy {\n+\n+  /**\n+   * Stream of instants to check conflicts against.\n+   * @return\n+   */\n+  Stream<HoodieInstant> getInstantsStream(HoodieActiveTimeline activeTimeline, HoodieInstant currentInstant, Option<HoodieInstant> lastSuccessfulInstant);\n+\n+  /**\n+   * Implementations of this method will determine whether a conflict exists between 2 commits.\n+   * @param thisOperation\n+   * @param otherOperation\n+   * @return\n+   */\n+  @PublicAPIMethod(maturity = ApiMaturityLevel.EVOLVING)\n+  boolean hasConflict(HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation);", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\nsimilarity index 81%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\nindex 12a788ee8..d6bc8d333 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\n", "chunk": "@@ -16,7 +16,7 @@\n  * limitations under the License.\n  */\n \n-package org.apache.hudi.client.lock;\n+package org.apache.hudi.client.transaction;\n \n import org.apache.hudi.ApiMaturityLevel;\n import org.apache.hudi.PublicAPIMethod;\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\nsimilarity index 81%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\nindex 12a788ee8..d6bc8d333 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\n", "chunk": "@@ -24,7 +24,6 @@ import org.apache.hudi.common.model.HoodieCommitMetadata;\n import org.apache.hudi.common.table.timeline.HoodieActiveTimeline;\n import org.apache.hudi.common.table.timeline.HoodieInstant;\n import org.apache.hudi.common.util.Option;\n-import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n import org.apache.hudi.table.HoodieTable;\n \n import java.util.stream.Stream;\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\nsimilarity index 81%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\nindex 12a788ee8..d6bc8d333 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\n", "chunk": "@@ -40,7 +39,7 @@ public interface ConflictResolutionStrategy {\n    * Stream of instants to check conflicts against.\n    * @return\n    */\n-  Stream<HoodieInstant> getInstantsStream(HoodieActiveTimeline activeTimeline, HoodieInstant currentInstant, Option<HoodieInstant> lastSuccessfulInstant);\n+  Stream<HoodieInstant> getCandidateInstants(HoodieActiveTimeline activeTimeline, HoodieInstant currentInstant, Option<HoodieInstant> lastSuccessfulInstant);\n \n   /**\n    * Implementations of this method will determine whether a conflict exists between 2 commits.\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\nsimilarity index 81%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\nindex 12a788ee8..d6bc8d333 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\n", "chunk": "@@ -58,7 +57,7 @@ public interface ConflictResolutionStrategy {\n    * @return\n    */\n   @PublicAPIMethod(maturity = ApiMaturityLevel.EVOLVING)\n-  Option<HoodieCommitMetadata> resolveConflict(Option<HoodieBackedTableMetadataWriter> metadataWriter, HoodieTable table,\n-                                       HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation);\n+  Option<HoodieCommitMetadata> resolveConflict(HoodieTable table,\n+      HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation);\n \n }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcwNTUwNg==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587705506", "bodyText": "having the metadata writer passed in, feels off. any way to avoid this?", "author": "vinothchandar", "createdAt": "2021-03-04T18:15:49Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java", "diffHunk": "@@ -0,0 +1,64 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.hudi.ApiMaturityLevel;\n+import org.apache.hudi.PublicAPIMethod;\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.table.timeline.HoodieActiveTimeline;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n+import org.apache.hudi.table.HoodieTable;\n+\n+import java.util.stream.Stream;\n+\n+/**\n+ * Strategy interface for conflict resolution with multiple writers.\n+ * Users can provide pluggable implementations for different kinds of strategies to resolve conflicts when multiple\n+ * writers are mutating the hoodie table.\n+ */\n+public interface ConflictResolutionStrategy {\n+\n+  /**\n+   * Stream of instants to check conflicts against.\n+   * @return\n+   */\n+  Stream<HoodieInstant> getInstantsStream(HoodieActiveTimeline activeTimeline, HoodieInstant currentInstant, Option<HoodieInstant> lastSuccessfulInstant);\n+\n+  /**\n+   * Implementations of this method will determine whether a conflict exists between 2 commits.\n+   * @param thisOperation\n+   * @param otherOperation\n+   * @return\n+   */\n+  @PublicAPIMethod(maturity = ApiMaturityLevel.EVOLVING)\n+  boolean hasConflict(HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation);\n+\n+  /**\n+   * Implementations of this method will determine how to resolve a conflict between 2 commits.\n+   * @param thisOperation\n+   * @param otherOperation\n+   * @return\n+   */\n+  @PublicAPIMethod(maturity = ApiMaturityLevel.EVOLVING)\n+  Option<HoodieCommitMetadata> resolveConflict(Option<HoodieBackedTableMetadataWriter> metadataWriter, HoodieTable table,", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzgxMzY4NA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587813684", "bodyText": "So this is being passed to allow for the metadata to be manipulated to do some kind of conflict resolution. Right now it's not being used anywhere, I can remove it but will need to be added sometime soon when we need to do conflict resolution more than just throwing exception.", "author": "n3nash", "createdAt": "2021-03-04T20:47:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcwNTUwNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODY1MTQwNg==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588651406", "bodyText": "lets remove it. we can introduce it as needed. This will simplify the implementation, as it stands now.", "author": "vinothchandar", "createdAt": "2021-03-05T20:06:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcwNTUwNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODg1Nzc5OQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588857799", "bodyText": "Removed", "author": "n3nash", "createdAt": "2021-03-06T09:16:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcwNTUwNg=="}], "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\nsimilarity index 81%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\nindex 12a788ee8..d6bc8d333 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\n", "chunk": "@@ -16,7 +16,7 @@\n  * limitations under the License.\n  */\n \n-package org.apache.hudi.client.lock;\n+package org.apache.hudi.client.transaction;\n \n import org.apache.hudi.ApiMaturityLevel;\n import org.apache.hudi.PublicAPIMethod;\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\nsimilarity index 81%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\nindex 12a788ee8..d6bc8d333 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\n", "chunk": "@@ -24,7 +24,6 @@ import org.apache.hudi.common.model.HoodieCommitMetadata;\n import org.apache.hudi.common.table.timeline.HoodieActiveTimeline;\n import org.apache.hudi.common.table.timeline.HoodieInstant;\n import org.apache.hudi.common.util.Option;\n-import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n import org.apache.hudi.table.HoodieTable;\n \n import java.util.stream.Stream;\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\nsimilarity index 81%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\nindex 12a788ee8..d6bc8d333 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\n", "chunk": "@@ -40,7 +39,7 @@ public interface ConflictResolutionStrategy {\n    * Stream of instants to check conflicts against.\n    * @return\n    */\n-  Stream<HoodieInstant> getInstantsStream(HoodieActiveTimeline activeTimeline, HoodieInstant currentInstant, Option<HoodieInstant> lastSuccessfulInstant);\n+  Stream<HoodieInstant> getCandidateInstants(HoodieActiveTimeline activeTimeline, HoodieInstant currentInstant, Option<HoodieInstant> lastSuccessfulInstant);\n \n   /**\n    * Implementations of this method will determine whether a conflict exists between 2 commits.\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\nsimilarity index 81%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\nindex 12a788ee8..d6bc8d333 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/ConflictResolutionStrategy.java\n", "chunk": "@@ -58,7 +57,7 @@ public interface ConflictResolutionStrategy {\n    * @return\n    */\n   @PublicAPIMethod(maturity = ApiMaturityLevel.EVOLVING)\n-  Option<HoodieCommitMetadata> resolveConflict(Option<HoodieBackedTableMetadataWriter> metadataWriter, HoodieTable table,\n-                                       HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation);\n+  Option<HoodieCommitMetadata> resolveConflict(HoodieTable table,\n+      HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation);\n \n }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcwNjEzMQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587706131", "bodyText": "rename: ConflictingOperation", "author": "vinothchandar", "createdAt": "2021-03-04T18:16:46Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/HoodieCommitOperation.java", "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.model.HoodieCommonMetadata;\n+import org.apache.hudi.common.model.WriteOperationType;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.util.CommitUtils;\n+import org.apache.hudi.common.util.Option;\n+import java.util.Collections;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import static org.apache.hudi.common.table.timeline.HoodieTimeline.COMMIT_ACTION;\n+import static org.apache.hudi.common.table.timeline.HoodieTimeline.COMPACTION_ACTION;\n+import static org.apache.hudi.common.table.timeline.HoodieTimeline.DELTA_COMMIT_ACTION;\n+import static org.apache.hudi.common.table.timeline.HoodieTimeline.REPLACE_COMMIT_ACTION;\n+\n+/**\n+ * This class is used to hold all information used to identify how to resolve conflicts between instants.\n+ * Since we interchange payload types between AVRO specific records and POJO's, this object serves as\n+ * a common payload to manage these conversions.\n+ */\n+public class HoodieCommitOperation {", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzgxNjA5NQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587816095", "bodyText": "So this is just wrap the CommitMetadata to a common payload. ConflictingOperation suggests this is already a conflicting operation which it is not yet. Open to other suggestions if you have", "author": "n3nash", "createdAt": "2021-03-04T20:51:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcwNjEzMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODY1NDMzNw==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588654337", "bodyText": "So the thing is , this has the common metadata, overloading \"commit\" is always confusing in our code base, since commit often refers to a specific action type. Given its used specifically, in the conflict resolution scenario, I think somethihg like ConcurrentOperation captures the intent. Its just concurrent to the current operation, the conflict resolution will determine if its actually a conflict like you mentioned.", "author": "vinothchandar", "createdAt": "2021-03-05T20:10:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcwNjEzMQ=="}], "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/HoodieCommitOperation.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/HoodieCommitOperation.java\nsimilarity index 91%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/HoodieCommitOperation.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/HoodieCommitOperation.java\nindex 08eccb11a..0733ce98c 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/HoodieCommitOperation.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/HoodieCommitOperation.java\n", "chunk": "@@ -16,10 +16,10 @@\n  * limitations under the License.\n  */\n \n-package org.apache.hudi.client.lock;\n+package org.apache.hudi.client.transaction;\n \n import org.apache.hudi.common.model.HoodieCommitMetadata;\n-import org.apache.hudi.common.model.HoodieCommonMetadata;\n+import org.apache.hudi.common.model.HoodieMetadataWrapper;\n import org.apache.hudi.common.model.WriteOperationType;\n import org.apache.hudi.common.table.timeline.HoodieInstant;\n import org.apache.hudi.common.util.CommitUtils;\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/HoodieCommitOperation.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/HoodieCommitOperation.java\nsimilarity index 91%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/HoodieCommitOperation.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/HoodieCommitOperation.java\nindex 08eccb11a..0733ce98c 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/HoodieCommitOperation.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/HoodieCommitOperation.java\n", "chunk": "@@ -40,14 +40,14 @@ import static org.apache.hudi.common.table.timeline.HoodieTimeline.REPLACE_COMMI\n public class HoodieCommitOperation {\n \n   private WriteOperationType operationType;\n-  private final Option<HoodieCommonMetadata> commonMetadata;\n+  private final Option<HoodieMetadataWrapper> commonMetadata;\n   private final Option<HoodieCommitMetadata> commitMetadataOption;\n   private final String actionState;\n   private final String actionType;\n   private final String instantTime;\n   private Set<String> mutatedFileIds = Collections.EMPTY_SET;\n \n-  public HoodieCommitOperation(HoodieCommonMetadata commonMetadata) {\n+  public HoodieCommitOperation(HoodieMetadataWrapper commonMetadata) {\n     this.commonMetadata = Option.of(commonMetadata);\n     this.actionState = commonMetadata.getWrappedMetadata().getActionState();\n     this.actionType = commonMetadata.getWrappedMetadata().getActionType();\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/HoodieCommitOperation.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/HoodieCommitOperation.java\nsimilarity index 91%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/HoodieCommitOperation.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/HoodieCommitOperation.java\nindex 08eccb11a..0733ce98c 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/HoodieCommitOperation.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/HoodieCommitOperation.java\n", "chunk": "@@ -94,20 +94,20 @@ public class HoodieCommitOperation {\n     if (getInstantActionState() != HoodieInstant.State.INFLIGHT.name()) {\n       switch (getInstantActionType()) {\n         case COMPACTION_ACTION:\n-          this.operationType = WriteOperationType.UNKNOWN;\n+          this.operationType = WriteOperationType.COMPACT;\n           this.mutatedFileIds = commonMetadata.get().getWrappedMetadata().getHoodieCompactionPlan().getOperations()\n                   .stream()\n                   .map(op -> op.getFileId())\n                   .collect(Collectors.toSet());\n           break;\n         case COMMIT_ACTION:\n-          this.mutatedFileIds = CommitUtils.getFileIdWithoutSuffixAndRelativePaths(commonMetadata.get().getWrappedMetadata().getHoodieCommitMetadata()\n+          this.mutatedFileIds = CommitUtils.getFileIdWithoutSuffixAndRelativePathsFromSpecificRecord(commonMetadata.get().getWrappedMetadata().getHoodieCommitMetadata()\n                   .getPartitionToWriteStats()).keySet();\n           this.operationType = WriteOperationType.fromValue(commonMetadata.get().getWrappedMetadata().getHoodieCommitMetadata().getOperationType());\n           break;\n         case REPLACE_COMMIT_ACTION:\n           if (commonMetadata.get().getWrappedMetadata().getHoodieReplaceCommitMetadata().getOperationType() == WriteOperationType.CLUSTER.name()) {\n-            this.mutatedFileIds = CommitUtils.getFileIdWithoutSuffixAndRelativePaths(\n+            this.mutatedFileIds = CommitUtils.getFileIdWithoutSuffixAndRelativePathsFromSpecificRecord(\n                     commonMetadata.get().getWrappedMetadata().getHoodieReplaceCommitMetadata().getPartitionToWriteStats()).keySet();\n           } else {\n             this.mutatedFileIds = Collections.EMPTY_SET;\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/HoodieCommitOperation.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/HoodieCommitOperation.java\nsimilarity index 91%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/HoodieCommitOperation.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/HoodieCommitOperation.java\nindex 08eccb11a..0733ce98c 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/HoodieCommitOperation.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/HoodieCommitOperation.java\n", "chunk": "@@ -121,7 +121,7 @@ public class HoodieCommitOperation {\n       switch (getInstantActionType()) {\n         case COMMIT_ACTION:\n         case DELTA_COMMIT_ACTION:\n-          this.mutatedFileIds = CommitUtils.getFileIdWithoutSuffixAndRelativePathsFromCommit(commitMetadataOption.get()\n+          this.mutatedFileIds = CommitUtils.getFileIdWithoutSuffixAndRelativePaths(commitMetadataOption.get()\n                   .getPartitionToWriteStats()).keySet();\n           this.operationType = commitMetadataOption.get().getOperationType();\n           break;\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcwNzY3OQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587707679", "bodyText": "any special handling for InterruptedException? this is a common cause of bugs in such locking code paths", "author": "vinothchandar", "createdAt": "2021-03-04T18:19:04Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/LockManager.java", "diffHunk": "@@ -0,0 +1,125 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_CLIENT_NUM_RETRIES_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_CLIENT_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n+\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.hudi.common.config.SerializableConfiguration;\n+import org.apache.hudi.common.lock.LockProvider;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.common.util.ReflectionUtils;\n+import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.hudi.exception.HoodieLockException;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.io.Serializable;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+/**\n+ * This class wraps implementations of {@link LockProvider} and provides an easy way to manage the lifecycle of a lock.\n+ */\n+public class LockManager implements Serializable {\n+\n+  private static final Logger LOG = LogManager.getLogger(LockManager.class);\n+  private final HoodieWriteConfig writeConfig;\n+  private final LockConfiguration lockConfiguration;\n+  private final SerializableConfiguration hadoopConf;\n+  private volatile LockProvider lockProvider;\n+  // Holds the latest completed write instant to know which ones to check conflict against\n+  private final AtomicReference<Option<HoodieInstant>> latestCompletedWriteInstant;\n+\n+  public LockManager(HoodieWriteConfig writeConfig, FileSystem fs) {\n+    this.latestCompletedWriteInstant = new AtomicReference<>(Option.empty());\n+    this.writeConfig = writeConfig;\n+    this.hadoopConf = new SerializableConfiguration(fs.getConf());\n+    this.lockConfiguration = new LockConfiguration(writeConfig.getProps());\n+  }\n+\n+  public void lock() {\n+    if (writeConfig.getWriteConcurrencyMode().supportsOptimisticConcurrencyControl()) {\n+      LockProvider lockProvider = getLockProvider();\n+      boolean acquired = false;\n+      try {\n+        int retries = lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_CLIENT_NUM_RETRIES_PROP);\n+        long waitTimeInMs = lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_CLIENT_RETRY_WAIT_TIME_IN_MILLIS_PROP);\n+        int retryCount = 0;\n+        while (retryCount <= retries) {\n+          acquired = lockProvider.tryLock(writeConfig.getLockAcquireWaitTimeoutInMs(), TimeUnit.MILLISECONDS);\n+          if (acquired) {\n+            break;\n+          }\n+          LOG.info(\"Retrying...\");\n+          Thread.sleep(waitTimeInMs);\n+          retryCount++;\n+        }\n+      } catch (Exception e) {", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODA2NjAwNw==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588066007", "bodyText": "If the lock was accepted by the LockProvider server but an interrupted exception happens then we rely on the fact that the lock will timeout after X mins (settings in HiveMetastore & Zookeeper). I have tested in in my production runs.\nI have added some special checks for HiveMetastore in case of interruptedException but for Zookeeper it's not possible to do those checks.\n acquired = lockProvider.tryLock(writeConfig.getLockAcquireWaitTimeoutInMs(), TimeUnit.MILLISECONDS);\n          if (acquired) {\n            break;\n          }\n\nAnother extremely low probability is for the above code, lock is acquired but the running thread gets Interrupted before it can break. Again in this case, we just rely on the Lock Timeout on the server side of the LockProviders.", "author": "n3nash", "createdAt": "2021-03-05T06:40:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcwNzY3OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODY1NTI3NQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588655275", "bodyText": "I think. for the retries, we should handle interrupted exception and continue retrying. Thats what I was getting at.", "author": "vinothchandar", "createdAt": "2021-03-05T20:11:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcwNzY3OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODkyMjYzMA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588922630", "bodyText": "added", "author": "n3nash", "createdAt": "2021-03-06T19:43:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcwNzY3OQ=="}], "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/LockManager.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/LockManager.java\nsimilarity index 98%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/LockManager.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/LockManager.java\nindex 0f387e7e8..9a349af75 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/LockManager.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/LockManager.java\n", "chunk": "@@ -16,7 +16,7 @@\n  * limitations under the License.\n  */\n \n-package org.apache.hudi.client.lock;\n+package org.apache.hudi.client.transaction.lock;\n \n import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_CLIENT_NUM_RETRIES_PROP;\n import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_CLIENT_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/LockManager.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/LockManager.java\nsimilarity index 98%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/LockManager.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/LockManager.java\nindex 0f387e7e8..9a349af75 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/LockManager.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/LockManager.java\n", "chunk": "@@ -70,7 +70,7 @@ public class LockManager implements Serializable {\n           if (acquired) {\n             break;\n           }\n-          LOG.info(\"Retrying...\");\n+          LOG.info(\"Retrying to acquire lock...\");\n           Thread.sleep(waitTimeInMs);\n           retryCount++;\n         }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcwODIyMQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587708221", "bodyText": "I assume the providers unlock() will throw more exceptions.", "author": "vinothchandar", "createdAt": "2021-03-04T18:19:57Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/LockManager.java", "diffHunk": "@@ -0,0 +1,125 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_CLIENT_NUM_RETRIES_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_CLIENT_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n+\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.hudi.common.config.SerializableConfiguration;\n+import org.apache.hudi.common.lock.LockProvider;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.common.util.ReflectionUtils;\n+import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.hudi.exception.HoodieLockException;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.io.Serializable;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+/**\n+ * This class wraps implementations of {@link LockProvider} and provides an easy way to manage the lifecycle of a lock.\n+ */\n+public class LockManager implements Serializable {\n+\n+  private static final Logger LOG = LogManager.getLogger(LockManager.class);\n+  private final HoodieWriteConfig writeConfig;\n+  private final LockConfiguration lockConfiguration;\n+  private final SerializableConfiguration hadoopConf;\n+  private volatile LockProvider lockProvider;\n+  // Holds the latest completed write instant to know which ones to check conflict against\n+  private final AtomicReference<Option<HoodieInstant>> latestCompletedWriteInstant;\n+\n+  public LockManager(HoodieWriteConfig writeConfig, FileSystem fs) {\n+    this.latestCompletedWriteInstant = new AtomicReference<>(Option.empty());\n+    this.writeConfig = writeConfig;\n+    this.hadoopConf = new SerializableConfiguration(fs.getConf());\n+    this.lockConfiguration = new LockConfiguration(writeConfig.getProps());\n+  }\n+\n+  public void lock() {\n+    if (writeConfig.getWriteConcurrencyMode().supportsOptimisticConcurrencyControl()) {\n+      LockProvider lockProvider = getLockProvider();\n+      boolean acquired = false;\n+      try {\n+        int retries = lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_CLIENT_NUM_RETRIES_PROP);\n+        long waitTimeInMs = lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_CLIENT_RETRY_WAIT_TIME_IN_MILLIS_PROP);\n+        int retryCount = 0;\n+        while (retryCount <= retries) {\n+          acquired = lockProvider.tryLock(writeConfig.getLockAcquireWaitTimeoutInMs(), TimeUnit.MILLISECONDS);\n+          if (acquired) {\n+            break;\n+          }\n+          LOG.info(\"Retrying...\");\n+          Thread.sleep(waitTimeInMs);\n+          retryCount++;\n+        }\n+      } catch (Exception e) {\n+        throw new HoodieLockException(\"Unable to acquire lock \", e);\n+      }\n+      if (!acquired) {\n+        throw new HoodieLockException(\"Unable to acquire lock, lock object \" + lockProvider.getLock());\n+      }\n+    }\n+  }\n+\n+  public void unlock() {\n+    if (writeConfig.getWriteConcurrencyMode().supportsOptimisticConcurrencyControl()) {\n+      getLockProvider().unlock();", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODA2Mjk0OQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588062949", "bodyText": "Yes, both providers underlying implementation return void but throw exceptions", "author": "n3nash", "createdAt": "2021-03-05T06:32:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcwODIyMQ=="}], "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/LockManager.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/LockManager.java\nsimilarity index 98%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/LockManager.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/LockManager.java\nindex 0f387e7e8..9a349af75 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/LockManager.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/LockManager.java\n", "chunk": "@@ -16,7 +16,7 @@\n  * limitations under the License.\n  */\n \n-package org.apache.hudi.client.lock;\n+package org.apache.hudi.client.transaction.lock;\n \n import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_CLIENT_NUM_RETRIES_PROP;\n import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_CLIENT_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/LockManager.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/LockManager.java\nsimilarity index 98%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/LockManager.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/LockManager.java\nindex 0f387e7e8..9a349af75 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/LockManager.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/LockManager.java\n", "chunk": "@@ -70,7 +70,7 @@ public class LockManager implements Serializable {\n           if (acquired) {\n             break;\n           }\n-          LOG.info(\"Retrying...\");\n+          LOG.info(\"Retrying to acquire lock...\");\n           Thread.sleep(waitTimeInMs);\n           retryCount++;\n         }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcxMDkxOA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587710918", "bodyText": "can we avoid passing the \"0\" or use an existing constant for init instant time etc", "author": "vinothchandar", "createdAt": "2021-03-04T18:24:04Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.model.WriteOperationType;\n+import org.apache.hudi.common.table.timeline.HoodieActiveTimeline;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.table.timeline.HoodieTimeline;\n+import org.apache.hudi.common.util.CollectionUtils;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.exception.HoodieWriteConflictException;\n+import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n+import org.apache.hudi.table.HoodieTable;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.util.ConcurrentModificationException;\n+import java.util.HashSet;\n+import java.util.Set;\n+import java.util.stream.Stream;\n+\n+import static org.apache.hudi.common.table.timeline.HoodieTimeline.COMPACTION_ACTION;\n+import static org.apache.hudi.common.table.timeline.HoodieTimeline.REPLACE_COMMIT_ACTION;\n+\n+/**\n+ * This class is a basic implementation of a conflict resolution strategy for concurrent writes {@link ConflictResolutionStrategy}.\n+ */\n+public class SimpleConcurrentFileWritesConflictResolutionStrategy\n+    implements ConflictResolutionStrategy {\n+\n+  private static final Logger LOG = LogManager.getLogger(SimpleConcurrentFileWritesConflictResolutionStrategy.class);\n+\n+  @Override\n+  public Stream<HoodieInstant> getInstantsStream(HoodieActiveTimeline activeTimeline, HoodieInstant currentInstant,\n+                                                 Option<HoodieInstant> lastSuccessfulInstant) {\n+\n+    // To find which instants are conflicting, we apply the following logic\n+    // 1. Get completed instants timeline only for commits that have happened since the last successful write.\n+    // 2. Get any scheduled or completed compaction or clustering operations that have started and/or finished\n+    // after the current instant. We need to check for write conflicts since they may have mutated the same files\n+    // that are being newly created by the current write.\n+    Stream<HoodieInstant> completedCommitsInstantStream = activeTimeline\n+        .getCommitsTimeline()\n+        // TODO : getWriteTimeline to ensure we include replace commits as well\n+        .filterCompletedInstants()\n+        .findInstantsAfter(lastSuccessfulInstant.isPresent() ? lastSuccessfulInstant.get().getTimestamp() : \"0\")", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzgxNjcwNQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587816705", "bodyText": "Used HoodieTimeline.INIT_INSTANT_TS now", "author": "n3nash", "createdAt": "2021-03-04T20:52:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcxMDkxOA=="}], "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nsimilarity index 77%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nindex cf70da094..a27d78bf1 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n", "chunk": "@@ -16,7 +16,7 @@\n  * limitations under the License.\n  */\n \n-package org.apache.hudi.client.lock;\n+package org.apache.hudi.client.transaction;\n \n import org.apache.hudi.common.model.HoodieCommitMetadata;\n import org.apache.hudi.common.model.WriteOperationType;\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nsimilarity index 77%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nindex cf70da094..a27d78bf1 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n", "chunk": "@@ -26,7 +26,6 @@ import org.apache.hudi.common.table.timeline.HoodieTimeline;\n import org.apache.hudi.common.util.CollectionUtils;\n import org.apache.hudi.common.util.Option;\n import org.apache.hudi.exception.HoodieWriteConflictException;\n-import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n import org.apache.hudi.table.HoodieTable;\n import org.apache.log4j.LogManager;\n import org.apache.log4j.Logger;\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nsimilarity index 77%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nindex cf70da094..a27d78bf1 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n", "chunk": "@@ -48,7 +47,7 @@ public class SimpleConcurrentFileWritesConflictResolutionStrategy\n   private static final Logger LOG = LogManager.getLogger(SimpleConcurrentFileWritesConflictResolutionStrategy.class);\n \n   @Override\n-  public Stream<HoodieInstant> getInstantsStream(HoodieActiveTimeline activeTimeline, HoodieInstant currentInstant,\n+  public Stream<HoodieInstant> getCandidateInstants(HoodieActiveTimeline activeTimeline, HoodieInstant currentInstant,\n                                                  Option<HoodieInstant> lastSuccessfulInstant) {\n \n     // To find which instants are conflicting, we apply the following logic\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nsimilarity index 77%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nindex cf70da094..a27d78bf1 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n", "chunk": "@@ -56,11 +55,12 @@ public class SimpleConcurrentFileWritesConflictResolutionStrategy\n     // 2. Get any scheduled or completed compaction or clustering operations that have started and/or finished\n     // after the current instant. We need to check for write conflicts since they may have mutated the same files\n     // that are being newly created by the current write.\n+    // NOTE that any commits from table services such as compaction, clustering or cleaning since the\n+    // overlapping of files is handled using MVCC.\n     Stream<HoodieInstant> completedCommitsInstantStream = activeTimeline\n         .getCommitsTimeline()\n-        // TODO : getWriteTimeline to ensure we include replace commits as well\n         .filterCompletedInstants()\n-        .findInstantsAfter(lastSuccessfulInstant.isPresent() ? lastSuccessfulInstant.get().getTimestamp() : \"0\")\n+        .findInstantsAfter(lastSuccessfulInstant.isPresent() ? lastSuccessfulInstant.get().getTimestamp() : HoodieTimeline.INIT_INSTANT_TS)\n         .getInstants();\n \n     Stream<HoodieInstant> compactionAndClusteringTimeline = activeTimeline\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nsimilarity index 77%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nindex cf70da094..a27d78bf1 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n", "chunk": "@@ -78,7 +78,7 @@ public class SimpleConcurrentFileWritesConflictResolutionStrategy\n     Set<String> intersection = new HashSet<>(fileIdsSetForFirstInstant);\n     intersection.retainAll(fileIdsSetForSecondInstant);\n     if (!intersection.isEmpty()) {\n-      LOG.error(\"Found conflicting writes between first operation = \" + thisOperation\n+      LOG.warn(\"Found conflicting writes between first operation = \" + thisOperation\n           + \", second operation = \" + otherOperation + \" , intersecting file ids \" + intersection);\n       return true;\n     }\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nsimilarity index 77%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nindex cf70da094..a27d78bf1 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n", "chunk": "@@ -86,14 +86,23 @@ public class SimpleConcurrentFileWritesConflictResolutionStrategy\n   }\n \n   @Override\n-  public Option<HoodieCommitMetadata> resolveConflict(Option<HoodieBackedTableMetadataWriter> metadataWriter, HoodieTable table,\n-                                              HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation) {\n-    // NOTE that any commits from table services such as compaction, clustering or cleaning since the\n-    // overlapping of files is handled using MVCC. Since compaction is eventually written as commit, we need to ensure\n-    // we handle this during conflict resolution and not treat the commit from compaction operation as a regular commit.\n-    if (otherOperation.getOperationType() == WriteOperationType.UNKNOWN\n-        && HoodieTimeline.compareTimestamps(otherOperation.getInstantTimestamp(), HoodieTimeline.LESSER_THAN, thisOperation.getInstantTimestamp())) {\n-      return thisOperation.getCommitMetadataOption();\n+  public Option<HoodieCommitMetadata> resolveConflict(HoodieTable table,\n+      HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation) {\n+    // Since compaction is eventually written as commit, we need to ensure\n+    // we handle this during conflict resolution and not treat the commit from compaction operation\n+    // as a regular commit.\n+    // Also, clustering can be used for INSERT_OVERWRITE use-cases which need to be checked\n+    if (HoodieTimeline.compareTimestamps(otherOperation.getInstantTimestamp(),\n+        HoodieTimeline.LESSER_THAN, thisOperation.getInstantTimestamp())) {\n+      switch (otherOperation.getOperationType()) {\n+        case COMPACT:\n+          return thisOperation.getCommitMetadataOption();\n+        case INSERT_OVERWRITE:\n+        case INSERT_OVERWRITE_TABLE:\n+          return thisOperation.getCommitMetadataOption();\n+        default:\n+          break;\n+      }\n     }\n     // just abort the current write if conflicts are found\n     throw new HoodieWriteConflictException(new ConcurrentModificationException(\"Cannot resolve conflicts for overlapping writes\"));\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcxMTc4NQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587711785", "bodyText": "is this an error though. can we move to INFO", "author": "vinothchandar", "createdAt": "2021-03-04T18:25:24Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.model.WriteOperationType;\n+import org.apache.hudi.common.table.timeline.HoodieActiveTimeline;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.table.timeline.HoodieTimeline;\n+import org.apache.hudi.common.util.CollectionUtils;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.exception.HoodieWriteConflictException;\n+import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n+import org.apache.hudi.table.HoodieTable;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.util.ConcurrentModificationException;\n+import java.util.HashSet;\n+import java.util.Set;\n+import java.util.stream.Stream;\n+\n+import static org.apache.hudi.common.table.timeline.HoodieTimeline.COMPACTION_ACTION;\n+import static org.apache.hudi.common.table.timeline.HoodieTimeline.REPLACE_COMMIT_ACTION;\n+\n+/**\n+ * This class is a basic implementation of a conflict resolution strategy for concurrent writes {@link ConflictResolutionStrategy}.\n+ */\n+public class SimpleConcurrentFileWritesConflictResolutionStrategy\n+    implements ConflictResolutionStrategy {\n+\n+  private static final Logger LOG = LogManager.getLogger(SimpleConcurrentFileWritesConflictResolutionStrategy.class);\n+\n+  @Override\n+  public Stream<HoodieInstant> getInstantsStream(HoodieActiveTimeline activeTimeline, HoodieInstant currentInstant,\n+                                                 Option<HoodieInstant> lastSuccessfulInstant) {\n+\n+    // To find which instants are conflicting, we apply the following logic\n+    // 1. Get completed instants timeline only for commits that have happened since the last successful write.\n+    // 2. Get any scheduled or completed compaction or clustering operations that have started and/or finished\n+    // after the current instant. We need to check for write conflicts since they may have mutated the same files\n+    // that are being newly created by the current write.\n+    Stream<HoodieInstant> completedCommitsInstantStream = activeTimeline\n+        .getCommitsTimeline()\n+        // TODO : getWriteTimeline to ensure we include replace commits as well\n+        .filterCompletedInstants()\n+        .findInstantsAfter(lastSuccessfulInstant.isPresent() ? lastSuccessfulInstant.get().getTimestamp() : \"0\")\n+        .getInstants();\n+\n+    Stream<HoodieInstant> compactionAndClusteringTimeline = activeTimeline\n+        .getTimelineOfActions(CollectionUtils.createSet(REPLACE_COMMIT_ACTION, COMPACTION_ACTION))\n+        .findInstantsAfter(currentInstant.getTimestamp())\n+        .getInstants();\n+    return Stream.concat(completedCommitsInstantStream, compactionAndClusteringTimeline);\n+  }\n+\n+  @Override\n+  public boolean hasConflict(HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation) {\n+    // TODO : UUID's can clash even for insert/insert, handle that case.\n+    Set<String> fileIdsSetForFirstInstant = thisOperation.getMutatedFileIds();\n+    Set<String> fileIdsSetForSecondInstant = otherOperation.getMutatedFileIds();\n+    Set<String> intersection = new HashSet<>(fileIdsSetForFirstInstant);\n+    intersection.retainAll(fileIdsSetForSecondInstant);\n+    if (!intersection.isEmpty()) {\n+      LOG.error(\"Found conflicting writes between first operation = \" + thisOperation", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzgxNzA5OQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587817099", "bodyText": "I can make it WARN. This is useful to debug issues and INFO might get ignored.", "author": "n3nash", "createdAt": "2021-03-04T20:53:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcxMTc4NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODY1NjI0OA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588656248", "bodyText": "WARN should indicate abnormal execution. So may be or may be not. I still think INFO is the cleanest, since this code is supposed to handle the conflcting case. For debugging, users can always turn it on.", "author": "vinothchandar", "createdAt": "2021-03-05T20:12:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcxMTc4NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODkxODUxNw==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588918517", "bodyText": "Okay, made it INFO", "author": "n3nash", "createdAt": "2021-03-06T19:06:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcxMTc4NQ=="}], "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nsimilarity index 77%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nindex cf70da094..a27d78bf1 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n", "chunk": "@@ -16,7 +16,7 @@\n  * limitations under the License.\n  */\n \n-package org.apache.hudi.client.lock;\n+package org.apache.hudi.client.transaction;\n \n import org.apache.hudi.common.model.HoodieCommitMetadata;\n import org.apache.hudi.common.model.WriteOperationType;\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nsimilarity index 77%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nindex cf70da094..a27d78bf1 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n", "chunk": "@@ -26,7 +26,6 @@ import org.apache.hudi.common.table.timeline.HoodieTimeline;\n import org.apache.hudi.common.util.CollectionUtils;\n import org.apache.hudi.common.util.Option;\n import org.apache.hudi.exception.HoodieWriteConflictException;\n-import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n import org.apache.hudi.table.HoodieTable;\n import org.apache.log4j.LogManager;\n import org.apache.log4j.Logger;\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nsimilarity index 77%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nindex cf70da094..a27d78bf1 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n", "chunk": "@@ -48,7 +47,7 @@ public class SimpleConcurrentFileWritesConflictResolutionStrategy\n   private static final Logger LOG = LogManager.getLogger(SimpleConcurrentFileWritesConflictResolutionStrategy.class);\n \n   @Override\n-  public Stream<HoodieInstant> getInstantsStream(HoodieActiveTimeline activeTimeline, HoodieInstant currentInstant,\n+  public Stream<HoodieInstant> getCandidateInstants(HoodieActiveTimeline activeTimeline, HoodieInstant currentInstant,\n                                                  Option<HoodieInstant> lastSuccessfulInstant) {\n \n     // To find which instants are conflicting, we apply the following logic\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nsimilarity index 77%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nindex cf70da094..a27d78bf1 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n", "chunk": "@@ -56,11 +55,12 @@ public class SimpleConcurrentFileWritesConflictResolutionStrategy\n     // 2. Get any scheduled or completed compaction or clustering operations that have started and/or finished\n     // after the current instant. We need to check for write conflicts since they may have mutated the same files\n     // that are being newly created by the current write.\n+    // NOTE that any commits from table services such as compaction, clustering or cleaning since the\n+    // overlapping of files is handled using MVCC.\n     Stream<HoodieInstant> completedCommitsInstantStream = activeTimeline\n         .getCommitsTimeline()\n-        // TODO : getWriteTimeline to ensure we include replace commits as well\n         .filterCompletedInstants()\n-        .findInstantsAfter(lastSuccessfulInstant.isPresent() ? lastSuccessfulInstant.get().getTimestamp() : \"0\")\n+        .findInstantsAfter(lastSuccessfulInstant.isPresent() ? lastSuccessfulInstant.get().getTimestamp() : HoodieTimeline.INIT_INSTANT_TS)\n         .getInstants();\n \n     Stream<HoodieInstant> compactionAndClusteringTimeline = activeTimeline\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nsimilarity index 77%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nindex cf70da094..a27d78bf1 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n", "chunk": "@@ -78,7 +78,7 @@ public class SimpleConcurrentFileWritesConflictResolutionStrategy\n     Set<String> intersection = new HashSet<>(fileIdsSetForFirstInstant);\n     intersection.retainAll(fileIdsSetForSecondInstant);\n     if (!intersection.isEmpty()) {\n-      LOG.error(\"Found conflicting writes between first operation = \" + thisOperation\n+      LOG.warn(\"Found conflicting writes between first operation = \" + thisOperation\n           + \", second operation = \" + otherOperation + \" , intersecting file ids \" + intersection);\n       return true;\n     }\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nsimilarity index 77%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nindex cf70da094..a27d78bf1 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n", "chunk": "@@ -86,14 +86,23 @@ public class SimpleConcurrentFileWritesConflictResolutionStrategy\n   }\n \n   @Override\n-  public Option<HoodieCommitMetadata> resolveConflict(Option<HoodieBackedTableMetadataWriter> metadataWriter, HoodieTable table,\n-                                              HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation) {\n-    // NOTE that any commits from table services such as compaction, clustering or cleaning since the\n-    // overlapping of files is handled using MVCC. Since compaction is eventually written as commit, we need to ensure\n-    // we handle this during conflict resolution and not treat the commit from compaction operation as a regular commit.\n-    if (otherOperation.getOperationType() == WriteOperationType.UNKNOWN\n-        && HoodieTimeline.compareTimestamps(otherOperation.getInstantTimestamp(), HoodieTimeline.LESSER_THAN, thisOperation.getInstantTimestamp())) {\n-      return thisOperation.getCommitMetadataOption();\n+  public Option<HoodieCommitMetadata> resolveConflict(HoodieTable table,\n+      HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation) {\n+    // Since compaction is eventually written as commit, we need to ensure\n+    // we handle this during conflict resolution and not treat the commit from compaction operation\n+    // as a regular commit.\n+    // Also, clustering can be used for INSERT_OVERWRITE use-cases which need to be checked\n+    if (HoodieTimeline.compareTimestamps(otherOperation.getInstantTimestamp(),\n+        HoodieTimeline.LESSER_THAN, thisOperation.getInstantTimestamp())) {\n+      switch (otherOperation.getOperationType()) {\n+        case COMPACT:\n+          return thisOperation.getCommitMetadataOption();\n+        case INSERT_OVERWRITE:\n+        case INSERT_OVERWRITE_TABLE:\n+          return thisOperation.getCommitMetadataOption();\n+        default:\n+          break;\n+      }\n     }\n     // just abort the current write if conflicts are found\n     throw new HoodieWriteConflictException(new ConcurrentModificationException(\"Cannot resolve conflicts for overlapping writes\"));\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcxMzU4Ng==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587713586", "bodyText": "but replace commit can also result from INSERT_OVERWRITE correct? how do we distinguish this? I feel we need a more nuanced check here. So ensure only writes fail each other.", "author": "vinothchandar", "createdAt": "2021-03-04T18:27:57Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.model.WriteOperationType;\n+import org.apache.hudi.common.table.timeline.HoodieActiveTimeline;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.table.timeline.HoodieTimeline;\n+import org.apache.hudi.common.util.CollectionUtils;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.exception.HoodieWriteConflictException;\n+import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n+import org.apache.hudi.table.HoodieTable;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.util.ConcurrentModificationException;\n+import java.util.HashSet;\n+import java.util.Set;\n+import java.util.stream.Stream;\n+\n+import static org.apache.hudi.common.table.timeline.HoodieTimeline.COMPACTION_ACTION;\n+import static org.apache.hudi.common.table.timeline.HoodieTimeline.REPLACE_COMMIT_ACTION;\n+\n+/**\n+ * This class is a basic implementation of a conflict resolution strategy for concurrent writes {@link ConflictResolutionStrategy}.\n+ */\n+public class SimpleConcurrentFileWritesConflictResolutionStrategy\n+    implements ConflictResolutionStrategy {\n+\n+  private static final Logger LOG = LogManager.getLogger(SimpleConcurrentFileWritesConflictResolutionStrategy.class);\n+\n+  @Override\n+  public Stream<HoodieInstant> getInstantsStream(HoodieActiveTimeline activeTimeline, HoodieInstant currentInstant,\n+                                                 Option<HoodieInstant> lastSuccessfulInstant) {\n+\n+    // To find which instants are conflicting, we apply the following logic\n+    // 1. Get completed instants timeline only for commits that have happened since the last successful write.\n+    // 2. Get any scheduled or completed compaction or clustering operations that have started and/or finished\n+    // after the current instant. We need to check for write conflicts since they may have mutated the same files\n+    // that are being newly created by the current write.\n+    Stream<HoodieInstant> completedCommitsInstantStream = activeTimeline\n+        .getCommitsTimeline()\n+        // TODO : getWriteTimeline to ensure we include replace commits as well\n+        .filterCompletedInstants()\n+        .findInstantsAfter(lastSuccessfulInstant.isPresent() ? lastSuccessfulInstant.get().getTimestamp() : \"0\")\n+        .getInstants();\n+\n+    Stream<HoodieInstant> compactionAndClusteringTimeline = activeTimeline\n+        .getTimelineOfActions(CollectionUtils.createSet(REPLACE_COMMIT_ACTION, COMPACTION_ACTION))\n+        .findInstantsAfter(currentInstant.getTimestamp())\n+        .getInstants();\n+    return Stream.concat(completedCommitsInstantStream, compactionAndClusteringTimeline);\n+  }\n+\n+  @Override\n+  public boolean hasConflict(HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation) {\n+    // TODO : UUID's can clash even for insert/insert, handle that case.\n+    Set<String> fileIdsSetForFirstInstant = thisOperation.getMutatedFileIds();\n+    Set<String> fileIdsSetForSecondInstant = otherOperation.getMutatedFileIds();\n+    Set<String> intersection = new HashSet<>(fileIdsSetForFirstInstant);\n+    intersection.retainAll(fileIdsSetForSecondInstant);\n+    if (!intersection.isEmpty()) {\n+      LOG.error(\"Found conflicting writes between first operation = \" + thisOperation\n+          + \", second operation = \" + otherOperation + \" , intersecting file ids \" + intersection);\n+      return true;\n+    }\n+    return false;\n+  }\n+\n+  @Override\n+  public Option<HoodieCommitMetadata> resolveConflict(Option<HoodieBackedTableMetadataWriter> metadataWriter, HoodieTable table,\n+                                              HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation) {\n+    // NOTE that any commits from table services such as compaction, clustering or cleaning since the\n+    // overlapping of files is handled using MVCC. Since compaction is eventually written as commit, we need to ensure\n+    // we handle this during conflict resolution and not treat the commit from compaction operation as a regular commit.\n+    if (otherOperation.getOperationType() == WriteOperationType.UNKNOWN", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODA4Njg1MQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588086851", "bodyText": "Re-did the comments let me know if it's more clear now.", "author": "n3nash", "createdAt": "2021-03-05T07:34:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcxMzU4Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODY3MjkyMQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588672921", "bodyText": "See newer review, for followup", "author": "vinothchandar", "createdAt": "2021-03-05T20:30:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcxMzU4Ng=="}], "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nsimilarity index 77%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nindex cf70da094..a27d78bf1 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n", "chunk": "@@ -16,7 +16,7 @@\n  * limitations under the License.\n  */\n \n-package org.apache.hudi.client.lock;\n+package org.apache.hudi.client.transaction;\n \n import org.apache.hudi.common.model.HoodieCommitMetadata;\n import org.apache.hudi.common.model.WriteOperationType;\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nsimilarity index 77%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nindex cf70da094..a27d78bf1 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n", "chunk": "@@ -26,7 +26,6 @@ import org.apache.hudi.common.table.timeline.HoodieTimeline;\n import org.apache.hudi.common.util.CollectionUtils;\n import org.apache.hudi.common.util.Option;\n import org.apache.hudi.exception.HoodieWriteConflictException;\n-import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n import org.apache.hudi.table.HoodieTable;\n import org.apache.log4j.LogManager;\n import org.apache.log4j.Logger;\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nsimilarity index 77%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nindex cf70da094..a27d78bf1 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n", "chunk": "@@ -48,7 +47,7 @@ public class SimpleConcurrentFileWritesConflictResolutionStrategy\n   private static final Logger LOG = LogManager.getLogger(SimpleConcurrentFileWritesConflictResolutionStrategy.class);\n \n   @Override\n-  public Stream<HoodieInstant> getInstantsStream(HoodieActiveTimeline activeTimeline, HoodieInstant currentInstant,\n+  public Stream<HoodieInstant> getCandidateInstants(HoodieActiveTimeline activeTimeline, HoodieInstant currentInstant,\n                                                  Option<HoodieInstant> lastSuccessfulInstant) {\n \n     // To find which instants are conflicting, we apply the following logic\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nsimilarity index 77%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nindex cf70da094..a27d78bf1 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n", "chunk": "@@ -56,11 +55,12 @@ public class SimpleConcurrentFileWritesConflictResolutionStrategy\n     // 2. Get any scheduled or completed compaction or clustering operations that have started and/or finished\n     // after the current instant. We need to check for write conflicts since they may have mutated the same files\n     // that are being newly created by the current write.\n+    // NOTE that any commits from table services such as compaction, clustering or cleaning since the\n+    // overlapping of files is handled using MVCC.\n     Stream<HoodieInstant> completedCommitsInstantStream = activeTimeline\n         .getCommitsTimeline()\n-        // TODO : getWriteTimeline to ensure we include replace commits as well\n         .filterCompletedInstants()\n-        .findInstantsAfter(lastSuccessfulInstant.isPresent() ? lastSuccessfulInstant.get().getTimestamp() : \"0\")\n+        .findInstantsAfter(lastSuccessfulInstant.isPresent() ? lastSuccessfulInstant.get().getTimestamp() : HoodieTimeline.INIT_INSTANT_TS)\n         .getInstants();\n \n     Stream<HoodieInstant> compactionAndClusteringTimeline = activeTimeline\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nsimilarity index 77%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nindex cf70da094..a27d78bf1 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n", "chunk": "@@ -78,7 +78,7 @@ public class SimpleConcurrentFileWritesConflictResolutionStrategy\n     Set<String> intersection = new HashSet<>(fileIdsSetForFirstInstant);\n     intersection.retainAll(fileIdsSetForSecondInstant);\n     if (!intersection.isEmpty()) {\n-      LOG.error(\"Found conflicting writes between first operation = \" + thisOperation\n+      LOG.warn(\"Found conflicting writes between first operation = \" + thisOperation\n           + \", second operation = \" + otherOperation + \" , intersecting file ids \" + intersection);\n       return true;\n     }\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nsimilarity index 77%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nindex cf70da094..a27d78bf1 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n", "chunk": "@@ -86,14 +86,23 @@ public class SimpleConcurrentFileWritesConflictResolutionStrategy\n   }\n \n   @Override\n-  public Option<HoodieCommitMetadata> resolveConflict(Option<HoodieBackedTableMetadataWriter> metadataWriter, HoodieTable table,\n-                                              HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation) {\n-    // NOTE that any commits from table services such as compaction, clustering or cleaning since the\n-    // overlapping of files is handled using MVCC. Since compaction is eventually written as commit, we need to ensure\n-    // we handle this during conflict resolution and not treat the commit from compaction operation as a regular commit.\n-    if (otherOperation.getOperationType() == WriteOperationType.UNKNOWN\n-        && HoodieTimeline.compareTimestamps(otherOperation.getInstantTimestamp(), HoodieTimeline.LESSER_THAN, thisOperation.getInstantTimestamp())) {\n-      return thisOperation.getCommitMetadataOption();\n+  public Option<HoodieCommitMetadata> resolveConflict(HoodieTable table,\n+      HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation) {\n+    // Since compaction is eventually written as commit, we need to ensure\n+    // we handle this during conflict resolution and not treat the commit from compaction operation\n+    // as a regular commit.\n+    // Also, clustering can be used for INSERT_OVERWRITE use-cases which need to be checked\n+    if (HoodieTimeline.compareTimestamps(otherOperation.getInstantTimestamp(),\n+        HoodieTimeline.LESSER_THAN, thisOperation.getInstantTimestamp())) {\n+      switch (otherOperation.getOperationType()) {\n+        case COMPACT:\n+          return thisOperation.getCommitMetadataOption();\n+        case INSERT_OVERWRITE:\n+        case INSERT_OVERWRITE_TABLE:\n+          return thisOperation.getCommitMetadataOption();\n+        default:\n+          break;\n+      }\n     }\n     // just abort the current write if conflicts are found\n     throw new HoodieWriteConflictException(new ConcurrentModificationException(\"Cannot resolve conflicts for overlapping writes\"));\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcxNDM1Mg==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587714352", "bodyText": "combine into a single log line?", "author": "vinothchandar", "createdAt": "2021-03-04T18:29:05Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/TransactionManager.java", "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.io.Serializable;\n+\n+/**\n+ * This class allows clients to start and end transactions. Anything done between a start and end transaction is\n+ * guaranteed to be atomic.\n+ */\n+public class TransactionManager implements Serializable {\n+\n+  private static final Logger LOG = LogManager.getLogger(TransactionManager.class);\n+\n+  private final LockManager lockManager;\n+  private Option<HoodieInstant> currentTxnOwnerInstant;\n+  private Option<HoodieInstant> lastCompletedTxnOwnerInstant;\n+\n+  public TransactionManager(HoodieWriteConfig config, FileSystem fs) {\n+    this.lockManager = new LockManager(config, fs);\n+  }\n+\n+  public synchronized void setLastCompletedTransaction(Option<HoodieInstant> instant) {\n+    this.lastCompletedTxnOwnerInstant = instant;\n+    lockManager.compareAndSetLatestCompletedWriteInstant(lockManager.getLatestCompletedWriteInstant().get(), instant);\n+    LOG.info(\"Latest completed transaction instant \" + instant);\n+  }\n+\n+  public synchronized void setTransactionOwner(Option<HoodieInstant> instant) {\n+    this.currentTxnOwnerInstant = instant;\n+    LOG.info(\"Current transaction instant \" + instant);\n+  }\n+\n+  public synchronized void beginTransaction() {\n+    LOG.info(\"Transaction starting\");", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/TransactionManager.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/TransactionManager.java\nsimilarity index 76%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/TransactionManager.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/TransactionManager.java\nindex 441454b1c..309f437f1 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/TransactionManager.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/TransactionManager.java\n", "chunk": "@@ -16,9 +16,10 @@\n  * limitations under the License.\n  */\n \n-package org.apache.hudi.client.lock;\n+package org.apache.hudi.client.transaction;\n \n import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hudi.client.transaction.lock.LockManager;\n import org.apache.hudi.common.table.timeline.HoodieInstant;\n import org.apache.hudi.common.util.Option;\n import org.apache.hudi.config.HoodieWriteConfig;\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/TransactionManager.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/TransactionManager.java\nsimilarity index 76%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/TransactionManager.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/TransactionManager.java\nindex 441454b1c..309f437f1 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/TransactionManager.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/TransactionManager.java\n", "chunk": "@@ -61,9 +62,18 @@ public class TransactionManager implements Serializable {\n     LOG.info(\"Transaction started\");\n   }\n \n+  public synchronized void beginTransaction(Option<HoodieInstant> currentTxnOwnerInstant, Option<HoodieInstant> lastCompletedTxnOwnerInstant) {\n+    this.lastCompletedTxnOwnerInstant = lastCompletedTxnOwnerInstant;\n+    lockManager.compareAndSetLatestCompletedWriteInstant(lockManager.getLatestCompletedWriteInstant().get(), lastCompletedTxnOwnerInstant);\n+    LOG.info(\"Latest completed transaction instant \" + lastCompletedTxnOwnerInstant);\n+    this.currentTxnOwnerInstant = currentTxnOwnerInstant;\n+    LOG.info(\"Transaction starting with current transaction owner \" + currentTxnOwnerInstant);\n+    lockManager.lock();\n+    LOG.info(\"Transaction started\");\n+  }\n+\n   public synchronized void endTransaction() {\n-    LOG.info(\"Transaction ending\");\n-    LOG.info(\"Transaction Owner \" + currentTxnOwnerInstant);\n+    LOG.info(\"Transaction ending with Transaction owner \" + currentTxnOwnerInstant);\n     lockManager.unlock();\n     LOG.info(\"Transaction ended\");\n   }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcxNDQwNQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587714405", "bodyText": "same . combine?", "author": "vinothchandar", "createdAt": "2021-03-04T18:29:11Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/TransactionManager.java", "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.io.Serializable;\n+\n+/**\n+ * This class allows clients to start and end transactions. Anything done between a start and end transaction is\n+ * guaranteed to be atomic.\n+ */\n+public class TransactionManager implements Serializable {\n+\n+  private static final Logger LOG = LogManager.getLogger(TransactionManager.class);\n+\n+  private final LockManager lockManager;\n+  private Option<HoodieInstant> currentTxnOwnerInstant;\n+  private Option<HoodieInstant> lastCompletedTxnOwnerInstant;\n+\n+  public TransactionManager(HoodieWriteConfig config, FileSystem fs) {\n+    this.lockManager = new LockManager(config, fs);\n+  }\n+\n+  public synchronized void setLastCompletedTransaction(Option<HoodieInstant> instant) {\n+    this.lastCompletedTxnOwnerInstant = instant;\n+    lockManager.compareAndSetLatestCompletedWriteInstant(lockManager.getLatestCompletedWriteInstant().get(), instant);\n+    LOG.info(\"Latest completed transaction instant \" + instant);\n+  }\n+\n+  public synchronized void setTransactionOwner(Option<HoodieInstant> instant) {\n+    this.currentTxnOwnerInstant = instant;\n+    LOG.info(\"Current transaction instant \" + instant);\n+  }\n+\n+  public synchronized void beginTransaction() {\n+    LOG.info(\"Transaction starting\");\n+    LOG.info(\"Transaction Owner \" + currentTxnOwnerInstant);\n+    lockManager.lock();\n+    LOG.info(\"Transaction started\");\n+  }\n+\n+  public synchronized void endTransaction() {\n+    LOG.info(\"Transaction ending\");", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/TransactionManager.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/TransactionManager.java\nsimilarity index 76%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/TransactionManager.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/TransactionManager.java\nindex 441454b1c..309f437f1 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/TransactionManager.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/TransactionManager.java\n", "chunk": "@@ -16,9 +16,10 @@\n  * limitations under the License.\n  */\n \n-package org.apache.hudi.client.lock;\n+package org.apache.hudi.client.transaction;\n \n import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hudi.client.transaction.lock.LockManager;\n import org.apache.hudi.common.table.timeline.HoodieInstant;\n import org.apache.hudi.common.util.Option;\n import org.apache.hudi.config.HoodieWriteConfig;\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/TransactionManager.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/TransactionManager.java\nsimilarity index 76%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/TransactionManager.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/TransactionManager.java\nindex 441454b1c..309f437f1 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/TransactionManager.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/TransactionManager.java\n", "chunk": "@@ -61,9 +62,18 @@ public class TransactionManager implements Serializable {\n     LOG.info(\"Transaction started\");\n   }\n \n+  public synchronized void beginTransaction(Option<HoodieInstant> currentTxnOwnerInstant, Option<HoodieInstant> lastCompletedTxnOwnerInstant) {\n+    this.lastCompletedTxnOwnerInstant = lastCompletedTxnOwnerInstant;\n+    lockManager.compareAndSetLatestCompletedWriteInstant(lockManager.getLatestCompletedWriteInstant().get(), lastCompletedTxnOwnerInstant);\n+    LOG.info(\"Latest completed transaction instant \" + lastCompletedTxnOwnerInstant);\n+    this.currentTxnOwnerInstant = currentTxnOwnerInstant;\n+    LOG.info(\"Transaction starting with current transaction owner \" + currentTxnOwnerInstant);\n+    lockManager.lock();\n+    LOG.info(\"Transaction started\");\n+  }\n+\n   public synchronized void endTransaction() {\n-    LOG.info(\"Transaction ending\");\n-    LOG.info(\"Transaction Owner \" + currentTxnOwnerInstant);\n+    LOG.info(\"Transaction ending with Transaction owner \" + currentTxnOwnerInstant);\n     lockManager.unlock();\n     LOG.info(\"Transaction ended\");\n   }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcxNTU0NQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587715545", "bodyText": "make it final. In general, can you make a pass to ensure what can be final is made final.", "author": "vinothchandar", "createdAt": "2021-03-04T18:30:48Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java", "diffHunk": "@@ -0,0 +1,157 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.curator.framework.CuratorFramework;\n+import org.apache.curator.framework.CuratorFrameworkFactory;\n+import org.apache.curator.framework.imps.CuratorFrameworkState;\n+import org.apache.curator.framework.recipes.locks.InterProcessMutex;\n+import org.apache.curator.retry.BoundedExponentialBackoffRetry;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.hudi.common.lock.LockProvider;\n+import org.apache.hudi.common.lock.LockState;\n+import org.apache.hudi.common.util.StringUtils;\n+import org.apache.hudi.common.util.ValidationUtils;\n+import org.apache.hudi.exception.HoodieLockException;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_CONNECTION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_SESSION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_NUM_RETRIES_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_BASE_PATH_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECTION_TIMEOUT_MS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECT_URL_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_LOCK_KEY_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_SESSION_TIMEOUT_MS_PROP;\n+\n+/**\n+ * A zookeeper based lock. This {@link LockProvider} implementation allows to lock table operations\n+ * using zookeeper. Users need to have a Zookeeper cluster deployed to be able to use this lock.\n+ */\n+@NotThreadSafe\n+public class ZookeeperBasedLockProvider extends LockProvider {\n+\n+  private static final Logger LOG = LogManager.getLogger(ZookeeperBasedLockProvider.class);\n+\n+  private CuratorFramework curatorFrameworkClient;", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nsimilarity index 89%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nindex 3d57e4690..5e7ec67fe 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -16,7 +16,7 @@\n  * limitations under the License.\n  */\n \n-package org.apache.hudi.client.lock;\n+package org.apache.hudi.client.transaction.lock;\n \n import org.apache.curator.framework.CuratorFramework;\n import org.apache.curator.framework.CuratorFrameworkFactory;\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nsimilarity index 89%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nindex 3d57e4690..5e7ec67fe 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -55,11 +55,12 @@ public class ZookeeperBasedLockProvider extends LockProvider {\n \n   private static final Logger LOG = LogManager.getLogger(ZookeeperBasedLockProvider.class);\n \n-  private CuratorFramework curatorFrameworkClient;\n+  private final CuratorFramework curatorFrameworkClient;\n   private volatile InterProcessMutex lock = null;\n \n   public ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration, final Configuration conf) {\n-    this(lockConfiguration);\n+    checkRequiredProps(lockConfiguration);\n+    this.lockConfiguration = lockConfiguration;\n     this.curatorFrameworkClient = CuratorFrameworkFactory.builder()\n         .connectString(lockConfiguration.getConfig().getString(ZK_CONNECT_URL_PROP))\n         .retryPolicy(new BoundedExponentialBackoffRetry(lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP),\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nsimilarity index 89%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nindex 3d57e4690..5e7ec67fe 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -70,8 +71,11 @@ public class ZookeeperBasedLockProvider extends LockProvider {\n     this.curatorFrameworkClient.start();\n   }\n \n-  public ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration, final CuratorFramework curatorFrameworkClient) {\n-    this(lockConfiguration);\n+  // Only used for testing\n+  public ZookeeperBasedLockProvider(\n+      final LockConfiguration lockConfiguration, final CuratorFramework curatorFrameworkClient) {\n+    checkRequiredProps(lockConfiguration);\n+    this.lockConfiguration = lockConfiguration;\n     this.curatorFrameworkClient = curatorFrameworkClient;\n     synchronized (this.curatorFrameworkClient) {\n       if (this.curatorFrameworkClient.getState() != CuratorFrameworkState.STARTED) {\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nsimilarity index 89%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nindex 3d57e4690..5e7ec67fe 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -80,22 +84,6 @@ public class ZookeeperBasedLockProvider extends LockProvider {\n     }\n   }\n \n-  ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration) {\n-    checkRequiredProps(lockConfiguration);\n-    this.lockConfiguration = lockConfiguration;\n-  }\n-  \n-  public void acquireLock(long time, TimeUnit unit) throws Exception {\n-    ValidationUtils.checkArgument(this.lock == null, LockState.ALREADY_ACQUIRED.name());\n-    InterProcessMutex newLock = new InterProcessMutex(\n-        this.curatorFrameworkClient, lockConfiguration.getConfig().getString(ZK_BASE_PATH_PROP) + \"/\"\n-        + this.lockConfiguration.getConfig().getString(ZK_LOCK_KEY_PROP));\n-    newLock.acquire(time, unit);\n-    if (newLock.isAcquiredInThisProcess()) {\n-      lock = newLock;\n-    }\n-  }\n-\n   @Override\n   public boolean tryLock(long time, TimeUnit unit) {\n     LOG.info(generateLogStatement(LockState.ACQUIRING, generateLogSuffixString()));\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nsimilarity index 89%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nindex 3d57e4690..5e7ec67fe 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -141,6 +129,22 @@ public class ZookeeperBasedLockProvider extends LockProvider {\n     return this.lock;\n   }\n \n+  private void acquireLock(long time, TimeUnit unit) throws Exception {\n+    ValidationUtils.checkArgument(this.lock == null, LockState.ALREADY_ACQUIRED.name());\n+    InterProcessMutex newLock = new InterProcessMutex(\n+        this.curatorFrameworkClient, lockConfiguration.getConfig().getString(ZK_BASE_PATH_PROP) + \"/\"\n+        + this.lockConfiguration.getConfig().getString(ZK_LOCK_KEY_PROP));\n+    boolean acquired = newLock.acquire(time, unit);\n+    if (!acquired) {\n+      throw new HoodieLockException(generateLogStatement(LockState.FAILED_TO_ACQUIRE, generateLogSuffixString()));\n+    }\n+    if (newLock.isAcquiredInThisProcess()) {\n+      lock = newLock;\n+    } else {\n+      throw new HoodieLockException(generateLogStatement(LockState.FAILED_TO_ACQUIRE, generateLogSuffixString()));\n+    }\n+  }\n+\n   private void checkRequiredProps(final LockConfiguration config) {\n     ValidationUtils.checkArgument(config.getConfig().getString(ZK_CONNECT_URL_PROP) != null);\n     ValidationUtils.checkArgument(config.getConfig().getString(ZK_BASE_PATH_PROP) != null);\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcxNjYxMA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587716610", "bodyText": "how are you testing this? I don't see curator added to any of the bundles? Same for the zookeeper dependencies. This is a really really important part", "author": "vinothchandar", "createdAt": "2021-03-04T18:32:31Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java", "diffHunk": "@@ -0,0 +1,157 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.curator.framework.CuratorFramework;", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODExODMyMw==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588118323", "bodyText": "ZK & Curator comes with Hbase-Server. Do you want me to add it explicitly in the bundles ?", "author": "n3nash", "createdAt": "2021-03-05T08:34:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcxNjYxMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODY2MDcwMg==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588660702", "bodyText": "In the bundles, we explicitly white list dependencies. So not sure how transitive dependencies would have been picked up.  How are you testing all this - not using the utilities/spark bundles?\nStandard practice for dependencies that are actually used in the projects code, is to explicitly deal with the dependency. We should not depend on hbase-server transitiively bringing it in.", "author": "vinothchandar", "createdAt": "2021-03-05T20:17:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcxNjYxMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODY2MzY0Nw==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588663647", "bodyText": "vmacs:target vs$ jar tf hudi-spark-bundle_2.11-0.8.0-SNAPSHOT.jar | grep curator | wc -l\n       0\nvmacs:target vs$ jar tf hudi-spark-bundle_2.11-0.8.0-SNAPSHOT.jar | grep hbase | wc -l\n    4734\nvmacs:target vs$ \n\nDon't see curator, in fact.", "author": "vinothchandar", "createdAt": "2021-03-05T20:21:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcxNjYxMA=="}], "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nsimilarity index 89%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nindex 3d57e4690..5e7ec67fe 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -16,7 +16,7 @@\n  * limitations under the License.\n  */\n \n-package org.apache.hudi.client.lock;\n+package org.apache.hudi.client.transaction.lock;\n \n import org.apache.curator.framework.CuratorFramework;\n import org.apache.curator.framework.CuratorFrameworkFactory;\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nsimilarity index 89%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nindex 3d57e4690..5e7ec67fe 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -55,11 +55,12 @@ public class ZookeeperBasedLockProvider extends LockProvider {\n \n   private static final Logger LOG = LogManager.getLogger(ZookeeperBasedLockProvider.class);\n \n-  private CuratorFramework curatorFrameworkClient;\n+  private final CuratorFramework curatorFrameworkClient;\n   private volatile InterProcessMutex lock = null;\n \n   public ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration, final Configuration conf) {\n-    this(lockConfiguration);\n+    checkRequiredProps(lockConfiguration);\n+    this.lockConfiguration = lockConfiguration;\n     this.curatorFrameworkClient = CuratorFrameworkFactory.builder()\n         .connectString(lockConfiguration.getConfig().getString(ZK_CONNECT_URL_PROP))\n         .retryPolicy(new BoundedExponentialBackoffRetry(lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP),\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nsimilarity index 89%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nindex 3d57e4690..5e7ec67fe 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -70,8 +71,11 @@ public class ZookeeperBasedLockProvider extends LockProvider {\n     this.curatorFrameworkClient.start();\n   }\n \n-  public ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration, final CuratorFramework curatorFrameworkClient) {\n-    this(lockConfiguration);\n+  // Only used for testing\n+  public ZookeeperBasedLockProvider(\n+      final LockConfiguration lockConfiguration, final CuratorFramework curatorFrameworkClient) {\n+    checkRequiredProps(lockConfiguration);\n+    this.lockConfiguration = lockConfiguration;\n     this.curatorFrameworkClient = curatorFrameworkClient;\n     synchronized (this.curatorFrameworkClient) {\n       if (this.curatorFrameworkClient.getState() != CuratorFrameworkState.STARTED) {\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nsimilarity index 89%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nindex 3d57e4690..5e7ec67fe 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -80,22 +84,6 @@ public class ZookeeperBasedLockProvider extends LockProvider {\n     }\n   }\n \n-  ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration) {\n-    checkRequiredProps(lockConfiguration);\n-    this.lockConfiguration = lockConfiguration;\n-  }\n-  \n-  public void acquireLock(long time, TimeUnit unit) throws Exception {\n-    ValidationUtils.checkArgument(this.lock == null, LockState.ALREADY_ACQUIRED.name());\n-    InterProcessMutex newLock = new InterProcessMutex(\n-        this.curatorFrameworkClient, lockConfiguration.getConfig().getString(ZK_BASE_PATH_PROP) + \"/\"\n-        + this.lockConfiguration.getConfig().getString(ZK_LOCK_KEY_PROP));\n-    newLock.acquire(time, unit);\n-    if (newLock.isAcquiredInThisProcess()) {\n-      lock = newLock;\n-    }\n-  }\n-\n   @Override\n   public boolean tryLock(long time, TimeUnit unit) {\n     LOG.info(generateLogStatement(LockState.ACQUIRING, generateLogSuffixString()));\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nsimilarity index 89%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nindex 3d57e4690..5e7ec67fe 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -141,6 +129,22 @@ public class ZookeeperBasedLockProvider extends LockProvider {\n     return this.lock;\n   }\n \n+  private void acquireLock(long time, TimeUnit unit) throws Exception {\n+    ValidationUtils.checkArgument(this.lock == null, LockState.ALREADY_ACQUIRED.name());\n+    InterProcessMutex newLock = new InterProcessMutex(\n+        this.curatorFrameworkClient, lockConfiguration.getConfig().getString(ZK_BASE_PATH_PROP) + \"/\"\n+        + this.lockConfiguration.getConfig().getString(ZK_LOCK_KEY_PROP));\n+    boolean acquired = newLock.acquire(time, unit);\n+    if (!acquired) {\n+      throw new HoodieLockException(generateLogStatement(LockState.FAILED_TO_ACQUIRE, generateLogSuffixString()));\n+    }\n+    if (newLock.isAcquiredInThisProcess()) {\n+      lock = newLock;\n+    } else {\n+      throw new HoodieLockException(generateLogStatement(LockState.FAILED_TO_ACQUIRE, generateLogSuffixString()));\n+    }\n+  }\n+\n   private void checkRequiredProps(final LockConfiguration config) {\n     ValidationUtils.checkArgument(config.getConfig().getString(ZK_CONNECT_URL_PROP) != null);\n     ValidationUtils.checkArgument(config.getConfig().getString(ZK_BASE_PATH_PROP) != null);\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcxODMwMA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587718300", "bodyText": "but we seem to synchronize down below?", "author": "vinothchandar", "createdAt": "2021-03-04T18:35:06Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java", "diffHunk": "@@ -0,0 +1,157 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.curator.framework.CuratorFramework;\n+import org.apache.curator.framework.CuratorFrameworkFactory;\n+import org.apache.curator.framework.imps.CuratorFrameworkState;\n+import org.apache.curator.framework.recipes.locks.InterProcessMutex;\n+import org.apache.curator.retry.BoundedExponentialBackoffRetry;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.hudi.common.lock.LockProvider;\n+import org.apache.hudi.common.lock.LockState;\n+import org.apache.hudi.common.util.StringUtils;\n+import org.apache.hudi.common.util.ValidationUtils;\n+import org.apache.hudi.exception.HoodieLockException;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_CONNECTION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_SESSION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_NUM_RETRIES_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_BASE_PATH_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECTION_TIMEOUT_MS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECT_URL_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_LOCK_KEY_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_SESSION_TIMEOUT_MS_PROP;\n+\n+/**\n+ * A zookeeper based lock. This {@link LockProvider} implementation allows to lock table operations\n+ * using zookeeper. Users need to have a Zookeeper cluster deployed to be able to use this lock.\n+ */\n+@NotThreadSafe", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzgxOTg2MA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587819860", "bodyText": "The synchronized method is just for testing to start the ZK else parallel tests end up triggering start multiple times and that causes issues.. Since we don't use @VisibleTesting, I've put a comment", "author": "n3nash", "createdAt": "2021-03-04T20:57:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcxODMwMA=="}], "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nsimilarity index 89%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nindex 3d57e4690..5e7ec67fe 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -16,7 +16,7 @@\n  * limitations under the License.\n  */\n \n-package org.apache.hudi.client.lock;\n+package org.apache.hudi.client.transaction.lock;\n \n import org.apache.curator.framework.CuratorFramework;\n import org.apache.curator.framework.CuratorFrameworkFactory;\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nsimilarity index 89%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nindex 3d57e4690..5e7ec67fe 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -55,11 +55,12 @@ public class ZookeeperBasedLockProvider extends LockProvider {\n \n   private static final Logger LOG = LogManager.getLogger(ZookeeperBasedLockProvider.class);\n \n-  private CuratorFramework curatorFrameworkClient;\n+  private final CuratorFramework curatorFrameworkClient;\n   private volatile InterProcessMutex lock = null;\n \n   public ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration, final Configuration conf) {\n-    this(lockConfiguration);\n+    checkRequiredProps(lockConfiguration);\n+    this.lockConfiguration = lockConfiguration;\n     this.curatorFrameworkClient = CuratorFrameworkFactory.builder()\n         .connectString(lockConfiguration.getConfig().getString(ZK_CONNECT_URL_PROP))\n         .retryPolicy(new BoundedExponentialBackoffRetry(lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP),\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nsimilarity index 89%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nindex 3d57e4690..5e7ec67fe 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -70,8 +71,11 @@ public class ZookeeperBasedLockProvider extends LockProvider {\n     this.curatorFrameworkClient.start();\n   }\n \n-  public ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration, final CuratorFramework curatorFrameworkClient) {\n-    this(lockConfiguration);\n+  // Only used for testing\n+  public ZookeeperBasedLockProvider(\n+      final LockConfiguration lockConfiguration, final CuratorFramework curatorFrameworkClient) {\n+    checkRequiredProps(lockConfiguration);\n+    this.lockConfiguration = lockConfiguration;\n     this.curatorFrameworkClient = curatorFrameworkClient;\n     synchronized (this.curatorFrameworkClient) {\n       if (this.curatorFrameworkClient.getState() != CuratorFrameworkState.STARTED) {\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nsimilarity index 89%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nindex 3d57e4690..5e7ec67fe 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -80,22 +84,6 @@ public class ZookeeperBasedLockProvider extends LockProvider {\n     }\n   }\n \n-  ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration) {\n-    checkRequiredProps(lockConfiguration);\n-    this.lockConfiguration = lockConfiguration;\n-  }\n-  \n-  public void acquireLock(long time, TimeUnit unit) throws Exception {\n-    ValidationUtils.checkArgument(this.lock == null, LockState.ALREADY_ACQUIRED.name());\n-    InterProcessMutex newLock = new InterProcessMutex(\n-        this.curatorFrameworkClient, lockConfiguration.getConfig().getString(ZK_BASE_PATH_PROP) + \"/\"\n-        + this.lockConfiguration.getConfig().getString(ZK_LOCK_KEY_PROP));\n-    newLock.acquire(time, unit);\n-    if (newLock.isAcquiredInThisProcess()) {\n-      lock = newLock;\n-    }\n-  }\n-\n   @Override\n   public boolean tryLock(long time, TimeUnit unit) {\n     LOG.info(generateLogStatement(LockState.ACQUIRING, generateLogSuffixString()));\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nsimilarity index 89%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nindex 3d57e4690..5e7ec67fe 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -141,6 +129,22 @@ public class ZookeeperBasedLockProvider extends LockProvider {\n     return this.lock;\n   }\n \n+  private void acquireLock(long time, TimeUnit unit) throws Exception {\n+    ValidationUtils.checkArgument(this.lock == null, LockState.ALREADY_ACQUIRED.name());\n+    InterProcessMutex newLock = new InterProcessMutex(\n+        this.curatorFrameworkClient, lockConfiguration.getConfig().getString(ZK_BASE_PATH_PROP) + \"/\"\n+        + this.lockConfiguration.getConfig().getString(ZK_LOCK_KEY_PROP));\n+    boolean acquired = newLock.acquire(time, unit);\n+    if (!acquired) {\n+      throw new HoodieLockException(generateLogStatement(LockState.FAILED_TO_ACQUIRE, generateLogSuffixString()));\n+    }\n+    if (newLock.isAcquiredInThisProcess()) {\n+      lock = newLock;\n+    } else {\n+      throw new HoodieLockException(generateLogStatement(LockState.FAILED_TO_ACQUIRE, generateLogSuffixString()));\n+    }\n+  }\n+\n   private void checkRequiredProps(final LockConfiguration config) {\n     ValidationUtils.checkArgument(config.getConfig().getString(ZK_CONNECT_URL_PROP) != null);\n     ValidationUtils.checkArgument(config.getConfig().getString(ZK_BASE_PATH_PROP) != null);\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcxOTIxMQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587719211", "bodyText": "why public", "author": "vinothchandar", "createdAt": "2021-03-04T18:35:48Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java", "diffHunk": "@@ -0,0 +1,157 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.curator.framework.CuratorFramework;\n+import org.apache.curator.framework.CuratorFrameworkFactory;\n+import org.apache.curator.framework.imps.CuratorFrameworkState;\n+import org.apache.curator.framework.recipes.locks.InterProcessMutex;\n+import org.apache.curator.retry.BoundedExponentialBackoffRetry;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.hudi.common.lock.LockProvider;\n+import org.apache.hudi.common.lock.LockState;\n+import org.apache.hudi.common.util.StringUtils;\n+import org.apache.hudi.common.util.ValidationUtils;\n+import org.apache.hudi.exception.HoodieLockException;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_CONNECTION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_SESSION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_NUM_RETRIES_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_BASE_PATH_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECTION_TIMEOUT_MS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECT_URL_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_LOCK_KEY_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_SESSION_TIMEOUT_MS_PROP;\n+\n+/**\n+ * A zookeeper based lock. This {@link LockProvider} implementation allows to lock table operations\n+ * using zookeeper. Users need to have a Zookeeper cluster deployed to be able to use this lock.\n+ */\n+@NotThreadSafe\n+public class ZookeeperBasedLockProvider extends LockProvider {\n+\n+  private static final Logger LOG = LogManager.getLogger(ZookeeperBasedLockProvider.class);\n+\n+  private CuratorFramework curatorFrameworkClient;\n+  private volatile InterProcessMutex lock = null;\n+\n+  public ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration, final Configuration conf) {\n+    this(lockConfiguration);\n+    this.curatorFrameworkClient = CuratorFrameworkFactory.builder()\n+        .connectString(lockConfiguration.getConfig().getString(ZK_CONNECT_URL_PROP))\n+        .retryPolicy(new BoundedExponentialBackoffRetry(lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP),\n+            5000, lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_NUM_RETRIES_PROP)))\n+        .sessionTimeoutMs(lockConfiguration.getConfig().getInteger(ZK_SESSION_TIMEOUT_MS_PROP, DEFAULT_ZK_SESSION_TIMEOUT_MS))\n+        .connectionTimeoutMs(lockConfiguration.getConfig().getInteger(ZK_CONNECTION_TIMEOUT_MS_PROP, DEFAULT_ZK_CONNECTION_TIMEOUT_MS))\n+        .build();\n+    this.curatorFrameworkClient.start();\n+  }\n+\n+  public ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration, final CuratorFramework curatorFrameworkClient) {\n+    this(lockConfiguration);\n+    this.curatorFrameworkClient = curatorFrameworkClient;\n+    synchronized (this.curatorFrameworkClient) {\n+      if (this.curatorFrameworkClient.getState() != CuratorFrameworkState.STARTED) {\n+        this.curatorFrameworkClient.start();\n+      }\n+    }\n+  }\n+\n+  ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration) {\n+    checkRequiredProps(lockConfiguration);\n+    this.lockConfiguration = lockConfiguration;\n+  }\n+  \n+  public void acquireLock(long time, TimeUnit unit) throws Exception {", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nsimilarity index 89%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nindex 3d57e4690..5e7ec67fe 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -16,7 +16,7 @@\n  * limitations under the License.\n  */\n \n-package org.apache.hudi.client.lock;\n+package org.apache.hudi.client.transaction.lock;\n \n import org.apache.curator.framework.CuratorFramework;\n import org.apache.curator.framework.CuratorFrameworkFactory;\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nsimilarity index 89%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nindex 3d57e4690..5e7ec67fe 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -55,11 +55,12 @@ public class ZookeeperBasedLockProvider extends LockProvider {\n \n   private static final Logger LOG = LogManager.getLogger(ZookeeperBasedLockProvider.class);\n \n-  private CuratorFramework curatorFrameworkClient;\n+  private final CuratorFramework curatorFrameworkClient;\n   private volatile InterProcessMutex lock = null;\n \n   public ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration, final Configuration conf) {\n-    this(lockConfiguration);\n+    checkRequiredProps(lockConfiguration);\n+    this.lockConfiguration = lockConfiguration;\n     this.curatorFrameworkClient = CuratorFrameworkFactory.builder()\n         .connectString(lockConfiguration.getConfig().getString(ZK_CONNECT_URL_PROP))\n         .retryPolicy(new BoundedExponentialBackoffRetry(lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP),\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nsimilarity index 89%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nindex 3d57e4690..5e7ec67fe 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -70,8 +71,11 @@ public class ZookeeperBasedLockProvider extends LockProvider {\n     this.curatorFrameworkClient.start();\n   }\n \n-  public ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration, final CuratorFramework curatorFrameworkClient) {\n-    this(lockConfiguration);\n+  // Only used for testing\n+  public ZookeeperBasedLockProvider(\n+      final LockConfiguration lockConfiguration, final CuratorFramework curatorFrameworkClient) {\n+    checkRequiredProps(lockConfiguration);\n+    this.lockConfiguration = lockConfiguration;\n     this.curatorFrameworkClient = curatorFrameworkClient;\n     synchronized (this.curatorFrameworkClient) {\n       if (this.curatorFrameworkClient.getState() != CuratorFrameworkState.STARTED) {\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nsimilarity index 89%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nindex 3d57e4690..5e7ec67fe 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -80,22 +84,6 @@ public class ZookeeperBasedLockProvider extends LockProvider {\n     }\n   }\n \n-  ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration) {\n-    checkRequiredProps(lockConfiguration);\n-    this.lockConfiguration = lockConfiguration;\n-  }\n-  \n-  public void acquireLock(long time, TimeUnit unit) throws Exception {\n-    ValidationUtils.checkArgument(this.lock == null, LockState.ALREADY_ACQUIRED.name());\n-    InterProcessMutex newLock = new InterProcessMutex(\n-        this.curatorFrameworkClient, lockConfiguration.getConfig().getString(ZK_BASE_PATH_PROP) + \"/\"\n-        + this.lockConfiguration.getConfig().getString(ZK_LOCK_KEY_PROP));\n-    newLock.acquire(time, unit);\n-    if (newLock.isAcquiredInThisProcess()) {\n-      lock = newLock;\n-    }\n-  }\n-\n   @Override\n   public boolean tryLock(long time, TimeUnit unit) {\n     LOG.info(generateLogStatement(LockState.ACQUIRING, generateLogSuffixString()));\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nsimilarity index 89%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nindex 3d57e4690..5e7ec67fe 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -141,6 +129,22 @@ public class ZookeeperBasedLockProvider extends LockProvider {\n     return this.lock;\n   }\n \n+  private void acquireLock(long time, TimeUnit unit) throws Exception {\n+    ValidationUtils.checkArgument(this.lock == null, LockState.ALREADY_ACQUIRED.name());\n+    InterProcessMutex newLock = new InterProcessMutex(\n+        this.curatorFrameworkClient, lockConfiguration.getConfig().getString(ZK_BASE_PATH_PROP) + \"/\"\n+        + this.lockConfiguration.getConfig().getString(ZK_LOCK_KEY_PROP));\n+    boolean acquired = newLock.acquire(time, unit);\n+    if (!acquired) {\n+      throw new HoodieLockException(generateLogStatement(LockState.FAILED_TO_ACQUIRE, generateLogSuffixString()));\n+    }\n+    if (newLock.isAcquiredInThisProcess()) {\n+      lock = newLock;\n+    } else {\n+      throw new HoodieLockException(generateLogStatement(LockState.FAILED_TO_ACQUIRE, generateLogSuffixString()));\n+    }\n+  }\n+\n   private void checkRequiredProps(final LockConfiguration config) {\n     ValidationUtils.checkArgument(config.getConfig().getString(ZK_CONNECT_URL_PROP) != null);\n     ValidationUtils.checkArgument(config.getConfig().getString(ZK_BASE_PATH_PROP) != null);\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyMDc5Nw==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587720797", "bodyText": "so, the lock can be acquired by another process and we don't raise this exception?  is that ok? I see lines 94-96 above, where we simply do the assignment and not raise any exceptions from an else block", "author": "vinothchandar", "createdAt": "2021-03-04T18:37:23Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java", "diffHunk": "@@ -0,0 +1,157 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.lock;\n+\n+import org.apache.curator.framework.CuratorFramework;\n+import org.apache.curator.framework.CuratorFrameworkFactory;\n+import org.apache.curator.framework.imps.CuratorFrameworkState;\n+import org.apache.curator.framework.recipes.locks.InterProcessMutex;\n+import org.apache.curator.retry.BoundedExponentialBackoffRetry;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.hudi.common.lock.LockProvider;\n+import org.apache.hudi.common.lock.LockState;\n+import org.apache.hudi.common.util.StringUtils;\n+import org.apache.hudi.common.util.ValidationUtils;\n+import org.apache.hudi.exception.HoodieLockException;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_CONNECTION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_SESSION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_NUM_RETRIES_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_BASE_PATH_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECTION_TIMEOUT_MS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECT_URL_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_LOCK_KEY_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_SESSION_TIMEOUT_MS_PROP;\n+\n+/**\n+ * A zookeeper based lock. This {@link LockProvider} implementation allows to lock table operations\n+ * using zookeeper. Users need to have a Zookeeper cluster deployed to be able to use this lock.\n+ */\n+@NotThreadSafe\n+public class ZookeeperBasedLockProvider extends LockProvider {\n+\n+  private static final Logger LOG = LogManager.getLogger(ZookeeperBasedLockProvider.class);\n+\n+  private CuratorFramework curatorFrameworkClient;\n+  private volatile InterProcessMutex lock = null;\n+\n+  public ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration, final Configuration conf) {\n+    this(lockConfiguration);\n+    this.curatorFrameworkClient = CuratorFrameworkFactory.builder()\n+        .connectString(lockConfiguration.getConfig().getString(ZK_CONNECT_URL_PROP))\n+        .retryPolicy(new BoundedExponentialBackoffRetry(lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP),\n+            5000, lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_NUM_RETRIES_PROP)))\n+        .sessionTimeoutMs(lockConfiguration.getConfig().getInteger(ZK_SESSION_TIMEOUT_MS_PROP, DEFAULT_ZK_SESSION_TIMEOUT_MS))\n+        .connectionTimeoutMs(lockConfiguration.getConfig().getInteger(ZK_CONNECTION_TIMEOUT_MS_PROP, DEFAULT_ZK_CONNECTION_TIMEOUT_MS))\n+        .build();\n+    this.curatorFrameworkClient.start();\n+  }\n+\n+  public ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration, final CuratorFramework curatorFrameworkClient) {\n+    this(lockConfiguration);\n+    this.curatorFrameworkClient = curatorFrameworkClient;\n+    synchronized (this.curatorFrameworkClient) {\n+      if (this.curatorFrameworkClient.getState() != CuratorFrameworkState.STARTED) {\n+        this.curatorFrameworkClient.start();\n+      }\n+    }\n+  }\n+\n+  ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration) {\n+    checkRequiredProps(lockConfiguration);\n+    this.lockConfiguration = lockConfiguration;\n+  }\n+  \n+  public void acquireLock(long time, TimeUnit unit) throws Exception {\n+    ValidationUtils.checkArgument(this.lock == null, LockState.ALREADY_ACQUIRED.name());\n+    InterProcessMutex newLock = new InterProcessMutex(\n+        this.curatorFrameworkClient, lockConfiguration.getConfig().getString(ZK_BASE_PATH_PROP) + \"/\"\n+        + this.lockConfiguration.getConfig().getString(ZK_LOCK_KEY_PROP));\n+    newLock.acquire(time, unit);\n+    if (newLock.isAcquiredInThisProcess()) {\n+      lock = newLock;\n+    }\n+  }\n+\n+  @Override\n+  public boolean tryLock(long time, TimeUnit unit) {\n+    LOG.info(generateLogStatement(LockState.ACQUIRING, generateLogSuffixString()));\n+    try {\n+      acquireLock(time, unit);\n+      LOG.info(generateLogStatement(LockState.ACQUIRED, generateLogSuffixString()));\n+    } catch (Exception e) {\n+      throw new HoodieLockException(generateLogStatement(LockState.FAILED_TO_ACQUIRE, generateLogSuffixString()), e);", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODEyNDgyNQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588124825", "bodyText": "This is not the code on my local. Something amiss happened during rebase and squash commits on my local. I have re-done the merge to ensure nothing got lost.", "author": "n3nash", "createdAt": "2021-03-05T08:45:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyMDc5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODY4MzEwOA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588683108", "bodyText": "I think the actual code you have know handles this.", "author": "vinothchandar", "createdAt": "2021-03-05T20:41:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyMDc5Nw=="}], "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nsimilarity index 89%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nindex 3d57e4690..5e7ec67fe 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -16,7 +16,7 @@\n  * limitations under the License.\n  */\n \n-package org.apache.hudi.client.lock;\n+package org.apache.hudi.client.transaction.lock;\n \n import org.apache.curator.framework.CuratorFramework;\n import org.apache.curator.framework.CuratorFrameworkFactory;\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nsimilarity index 89%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nindex 3d57e4690..5e7ec67fe 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -55,11 +55,12 @@ public class ZookeeperBasedLockProvider extends LockProvider {\n \n   private static final Logger LOG = LogManager.getLogger(ZookeeperBasedLockProvider.class);\n \n-  private CuratorFramework curatorFrameworkClient;\n+  private final CuratorFramework curatorFrameworkClient;\n   private volatile InterProcessMutex lock = null;\n \n   public ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration, final Configuration conf) {\n-    this(lockConfiguration);\n+    checkRequiredProps(lockConfiguration);\n+    this.lockConfiguration = lockConfiguration;\n     this.curatorFrameworkClient = CuratorFrameworkFactory.builder()\n         .connectString(lockConfiguration.getConfig().getString(ZK_CONNECT_URL_PROP))\n         .retryPolicy(new BoundedExponentialBackoffRetry(lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP),\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nsimilarity index 89%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nindex 3d57e4690..5e7ec67fe 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -70,8 +71,11 @@ public class ZookeeperBasedLockProvider extends LockProvider {\n     this.curatorFrameworkClient.start();\n   }\n \n-  public ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration, final CuratorFramework curatorFrameworkClient) {\n-    this(lockConfiguration);\n+  // Only used for testing\n+  public ZookeeperBasedLockProvider(\n+      final LockConfiguration lockConfiguration, final CuratorFramework curatorFrameworkClient) {\n+    checkRequiredProps(lockConfiguration);\n+    this.lockConfiguration = lockConfiguration;\n     this.curatorFrameworkClient = curatorFrameworkClient;\n     synchronized (this.curatorFrameworkClient) {\n       if (this.curatorFrameworkClient.getState() != CuratorFrameworkState.STARTED) {\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nsimilarity index 89%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nindex 3d57e4690..5e7ec67fe 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -80,22 +84,6 @@ public class ZookeeperBasedLockProvider extends LockProvider {\n     }\n   }\n \n-  ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration) {\n-    checkRequiredProps(lockConfiguration);\n-    this.lockConfiguration = lockConfiguration;\n-  }\n-  \n-  public void acquireLock(long time, TimeUnit unit) throws Exception {\n-    ValidationUtils.checkArgument(this.lock == null, LockState.ALREADY_ACQUIRED.name());\n-    InterProcessMutex newLock = new InterProcessMutex(\n-        this.curatorFrameworkClient, lockConfiguration.getConfig().getString(ZK_BASE_PATH_PROP) + \"/\"\n-        + this.lockConfiguration.getConfig().getString(ZK_LOCK_KEY_PROP));\n-    newLock.acquire(time, unit);\n-    if (newLock.isAcquiredInThisProcess()) {\n-      lock = newLock;\n-    }\n-  }\n-\n   @Override\n   public boolean tryLock(long time, TimeUnit unit) {\n     LOG.info(generateLogStatement(LockState.ACQUIRING, generateLogSuffixString()));\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nsimilarity index 89%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nindex 3d57e4690..5e7ec67fe 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -141,6 +129,22 @@ public class ZookeeperBasedLockProvider extends LockProvider {\n     return this.lock;\n   }\n \n+  private void acquireLock(long time, TimeUnit unit) throws Exception {\n+    ValidationUtils.checkArgument(this.lock == null, LockState.ALREADY_ACQUIRED.name());\n+    InterProcessMutex newLock = new InterProcessMutex(\n+        this.curatorFrameworkClient, lockConfiguration.getConfig().getString(ZK_BASE_PATH_PROP) + \"/\"\n+        + this.lockConfiguration.getConfig().getString(ZK_LOCK_KEY_PROP));\n+    boolean acquired = newLock.acquire(time, unit);\n+    if (!acquired) {\n+      throw new HoodieLockException(generateLogStatement(LockState.FAILED_TO_ACQUIRE, generateLogSuffixString()));\n+    }\n+    if (newLock.isAcquiredInThisProcess()) {\n+      lock = newLock;\n+    } else {\n+      throw new HoodieLockException(generateLogStatement(LockState.FAILED_TO_ACQUIRE, generateLogSuffixString()));\n+    }\n+  }\n+\n   private void checkRequiredProps(final LockConfiguration config) {\n     ValidationUtils.checkArgument(config.getConfig().getString(ZK_CONNECT_URL_PROP) != null);\n     ValidationUtils.checkArgument(config.getConfig().getString(ZK_BASE_PATH_PROP) != null);\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyMTQyMA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587721420", "bodyText": "does this have an unit test on its own?", "author": "vinothchandar", "createdAt": "2021-03-04T18:38:14Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/HoodieMetadataConversionUtils.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.utils;\n+\n+import com.fasterxml.jackson.databind.DeserializationFeature;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.apache.hudi.avro.model.HoodieArchivedMetaEntry;\n+import org.apache.hudi.avro.model.HoodieCompactionPlan;\n+import org.apache.hudi.avro.model.HoodieRollbackMetadata;\n+import org.apache.hudi.avro.model.HoodieSavepointMetadata;\n+import org.apache.hudi.client.ReplaceArchivalHelper;\n+import org.apache.hudi.common.model.ActionType;\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.model.HoodieReplaceCommitMetadata;\n+import org.apache.hudi.common.model.HoodieRollingStatMetadata;\n+import org.apache.hudi.common.table.HoodieTableMetaClient;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.table.timeline.HoodieTimeline;\n+import org.apache.hudi.common.table.timeline.TimelineMetadataUtils;\n+import org.apache.hudi.common.util.CleanerUtils;\n+import org.apache.hudi.common.util.CompactionUtils;\n+import java.io.IOException;\n+\n+/**\n+ * Helper class to convert between different action related payloads and {@link HoodieArchivedMetaEntry}.\n+ */\n+public class HoodieMetadataConversionUtils {", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODEyNDk3Ng==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588124976", "bodyText": "Added one now", "author": "n3nash", "createdAt": "2021-03-05T08:46:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyMTQyMA=="}], "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/HoodieMetadataConversionUtils.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/MetadataConversionUtils.java\nsimilarity index 86%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/HoodieMetadataConversionUtils.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/MetadataConversionUtils.java\nindex 8a2ae8166..35dd43858 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/HoodieMetadataConversionUtils.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/MetadataConversionUtils.java\n", "chunk": "@@ -40,7 +40,7 @@ import java.io.IOException;\n /**\n  * Helper class to convert between different action related payloads and {@link HoodieArchivedMetaEntry}.\n  */\n-public class HoodieMetadataConversionUtils {\n+public class MetadataConversionUtils {\n \n   public static HoodieArchivedMetaEntry createMetaWrapper(HoodieInstant hoodieInstant, HoodieTableMetaClient metaClient) throws IOException {\n     HoodieArchivedMetaEntry archivedMetaWrapper = new HoodieArchivedMetaEntry();\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/HoodieMetadataConversionUtils.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/MetadataConversionUtils.java\nsimilarity index 86%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/HoodieMetadataConversionUtils.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/MetadataConversionUtils.java\nindex 8a2ae8166..35dd43858 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/HoodieMetadataConversionUtils.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/MetadataConversionUtils.java\n", "chunk": "@@ -117,23 +117,4 @@ public class HoodieMetadataConversionUtils {\n     avroMetaData.getExtraMetadata().put(HoodieRollingStatMetadata.ROLLING_STAT_METADATA_KEY, \"\");\n     return avroMetaData;\n   }\n-\n-  // TODO : Fix converting from SpecificRecord to POJO\n-  public static HoodieCommitMetadata convertCommitMetadata(\n-          org.apache.hudi.avro.model.HoodieCommitMetadata hoodieCommitMetadata) {\n-    HoodieCommitMetadata avroMetaData =\n-            new HoodieCommitMetadata();\n-    // Do not archive Rolling Stats, cannot set to null since AVRO will throw null pointer\n-    avroMetaData.getExtraMetadata().put(HoodieRollingStatMetadata.ROLLING_STAT_METADATA_KEY, \"\");\n-    return avroMetaData;\n-  }\n-\n-  public static HoodieCommitMetadata convertReplaceMetadata(\n-          org.apache.hudi.avro.model.HoodieReplaceCommitMetadata hoodieReplaceCommitMetadata) {\n-    HoodieReplaceCommitMetadata avroMetaData =\n-            new HoodieReplaceCommitMetadata();\n-    // Do not archive Rolling Stats, cannot set to null since AVRO will throw null pointer\n-    avroMetaData.getExtraMetadata().put(HoodieRollingStatMetadata.ROLLING_STAT_METADATA_KEY, \"\");\n-    return avroMetaData;\n-  }\n }\n\\ No newline at end of file\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyMTcxMg==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587721712", "bodyText": "would this come back to haunt us ?", "author": "vinothchandar", "createdAt": "2021-03-04T18:38:38Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/HoodieMetadataConversionUtils.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.utils;\n+\n+import com.fasterxml.jackson.databind.DeserializationFeature;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.apache.hudi.avro.model.HoodieArchivedMetaEntry;\n+import org.apache.hudi.avro.model.HoodieCompactionPlan;\n+import org.apache.hudi.avro.model.HoodieRollbackMetadata;\n+import org.apache.hudi.avro.model.HoodieSavepointMetadata;\n+import org.apache.hudi.client.ReplaceArchivalHelper;\n+import org.apache.hudi.common.model.ActionType;\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.model.HoodieReplaceCommitMetadata;\n+import org.apache.hudi.common.model.HoodieRollingStatMetadata;\n+import org.apache.hudi.common.table.HoodieTableMetaClient;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.table.timeline.HoodieTimeline;\n+import org.apache.hudi.common.table.timeline.TimelineMetadataUtils;\n+import org.apache.hudi.common.util.CleanerUtils;\n+import org.apache.hudi.common.util.CompactionUtils;\n+import java.io.IOException;\n+\n+/**\n+ * Helper class to convert between different action related payloads and {@link HoodieArchivedMetaEntry}.\n+ */\n+public class HoodieMetadataConversionUtils {\n+\n+  public static HoodieArchivedMetaEntry createMetaWrapper(HoodieInstant hoodieInstant, HoodieTableMetaClient metaClient) throws IOException {\n+    HoodieArchivedMetaEntry archivedMetaWrapper = new HoodieArchivedMetaEntry();\n+    archivedMetaWrapper.setCommitTime(hoodieInstant.getTimestamp());\n+    archivedMetaWrapper.setActionState(hoodieInstant.getState().name());\n+    switch (hoodieInstant.getAction()) {\n+      case HoodieTimeline.CLEAN_ACTION: {\n+        if (hoodieInstant.isCompleted()) {\n+          archivedMetaWrapper.setHoodieCleanMetadata(CleanerUtils.getCleanerMetadata(metaClient, hoodieInstant));\n+        } else {\n+          archivedMetaWrapper.setHoodieCleanerPlan(CleanerUtils.getCleanerPlan(metaClient, hoodieInstant));\n+        }\n+        archivedMetaWrapper.setActionType(ActionType.clean.name());\n+        break;\n+      }\n+      case HoodieTimeline.COMMIT_ACTION:\n+      case HoodieTimeline.DELTA_COMMIT_ACTION: {\n+        HoodieCommitMetadata commitMetadata = HoodieCommitMetadata\n+                .fromBytes(metaClient.getCommitTimeline().getInstantDetails(hoodieInstant).get(), HoodieCommitMetadata.class);\n+        archivedMetaWrapper.setHoodieCommitMetadata(convertCommitMetadata(commitMetadata));\n+        archivedMetaWrapper.setActionType(ActionType.commit.name());\n+        break;\n+      }\n+      case HoodieTimeline.REPLACE_COMMIT_ACTION: {\n+        HoodieReplaceCommitMetadata replaceCommitMetadata = HoodieReplaceCommitMetadata\n+                .fromBytes(metaClient.getCommitTimeline().getInstantDetails(hoodieInstant).get(), HoodieReplaceCommitMetadata.class);\n+        archivedMetaWrapper.setHoodieReplaceCommitMetadata(ReplaceArchivalHelper.convertReplaceCommitMetadata(replaceCommitMetadata));\n+        archivedMetaWrapper.setActionType(ActionType.replacecommit.name());\n+        break;\n+      }\n+      case HoodieTimeline.ROLLBACK_ACTION: {\n+        archivedMetaWrapper.setHoodieRollbackMetadata(TimelineMetadataUtils.deserializeAvroMetadata(\n+                metaClient.getCommitTimeline().getInstantDetails(hoodieInstant).get(), HoodieRollbackMetadata.class));\n+        archivedMetaWrapper.setActionType(ActionType.rollback.name());\n+        break;\n+      }\n+      case HoodieTimeline.SAVEPOINT_ACTION: {\n+        archivedMetaWrapper.setHoodieSavePointMetadata(TimelineMetadataUtils.deserializeAvroMetadata(\n+                metaClient.getCommitTimeline().getInstantDetails(hoodieInstant).get(), HoodieSavepointMetadata.class));\n+        archivedMetaWrapper.setActionType(ActionType.savepoint.name());\n+        break;\n+      }\n+      case HoodieTimeline.COMPACTION_ACTION: {\n+        HoodieCompactionPlan plan = CompactionUtils.getCompactionPlan(metaClient, hoodieInstant.getTimestamp());\n+        archivedMetaWrapper.setHoodieCompactionPlan(plan);\n+        archivedMetaWrapper.setActionType(ActionType.compaction.name());\n+        break;\n+      }\n+      default: {\n+        throw new UnsupportedOperationException(\"Action not fully supported yet\");\n+      }\n+    }\n+    return archivedMetaWrapper;\n+  }\n+\n+  public static HoodieArchivedMetaEntry createMetaWrapper(HoodieInstant hoodieInstant,\n+                                                          HoodieCommitMetadata hoodieCommitMetadata) {\n+    HoodieArchivedMetaEntry archivedMetaWrapper = new HoodieArchivedMetaEntry();\n+    archivedMetaWrapper.setCommitTime(hoodieInstant.getTimestamp());\n+    archivedMetaWrapper.setActionState(hoodieInstant.getState().name());\n+    archivedMetaWrapper.setHoodieCommitMetadata(convertCommitMetadata(hoodieCommitMetadata));\n+    archivedMetaWrapper.setActionType(ActionType.commit.name());\n+    return archivedMetaWrapper;\n+  }\n+\n+  public static org.apache.hudi.avro.model.HoodieCommitMetadata convertCommitMetadata(\n+          HoodieCommitMetadata hoodieCommitMetadata) {\n+    ObjectMapper mapper = new ObjectMapper();\n+    // Need this to ignore other public get() methods\n+    mapper.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false);\n+    org.apache.hudi.avro.model.HoodieCommitMetadata avroMetaData =\n+            mapper.convertValue(hoodieCommitMetadata, org.apache.hudi.avro.model.HoodieCommitMetadata.class);\n+    // Do not archive Rolling Stats, cannot set to null since AVRO will throw null pointer\n+    avroMetaData.getExtraMetadata().put(HoodieRollingStatMetadata.ROLLING_STAT_METADATA_KEY, \"\");\n+    return avroMetaData;\n+  }\n+\n+  // TODO : Fix converting from SpecificRecord to POJO", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzgyNTIzOQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587825239", "bodyText": "I've removed the method for now to be sure no one uses it.", "author": "n3nash", "createdAt": "2021-03-04T21:06:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyMTcxMg=="}], "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/HoodieMetadataConversionUtils.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/MetadataConversionUtils.java\nsimilarity index 86%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/HoodieMetadataConversionUtils.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/MetadataConversionUtils.java\nindex 8a2ae8166..35dd43858 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/HoodieMetadataConversionUtils.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/MetadataConversionUtils.java\n", "chunk": "@@ -40,7 +40,7 @@ import java.io.IOException;\n /**\n  * Helper class to convert between different action related payloads and {@link HoodieArchivedMetaEntry}.\n  */\n-public class HoodieMetadataConversionUtils {\n+public class MetadataConversionUtils {\n \n   public static HoodieArchivedMetaEntry createMetaWrapper(HoodieInstant hoodieInstant, HoodieTableMetaClient metaClient) throws IOException {\n     HoodieArchivedMetaEntry archivedMetaWrapper = new HoodieArchivedMetaEntry();\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/HoodieMetadataConversionUtils.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/MetadataConversionUtils.java\nsimilarity index 86%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/HoodieMetadataConversionUtils.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/MetadataConversionUtils.java\nindex 8a2ae8166..35dd43858 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/HoodieMetadataConversionUtils.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/MetadataConversionUtils.java\n", "chunk": "@@ -117,23 +117,4 @@ public class HoodieMetadataConversionUtils {\n     avroMetaData.getExtraMetadata().put(HoodieRollingStatMetadata.ROLLING_STAT_METADATA_KEY, \"\");\n     return avroMetaData;\n   }\n-\n-  // TODO : Fix converting from SpecificRecord to POJO\n-  public static HoodieCommitMetadata convertCommitMetadata(\n-          org.apache.hudi.avro.model.HoodieCommitMetadata hoodieCommitMetadata) {\n-    HoodieCommitMetadata avroMetaData =\n-            new HoodieCommitMetadata();\n-    // Do not archive Rolling Stats, cannot set to null since AVRO will throw null pointer\n-    avroMetaData.getExtraMetadata().put(HoodieRollingStatMetadata.ROLLING_STAT_METADATA_KEY, \"\");\n-    return avroMetaData;\n-  }\n-\n-  public static HoodieCommitMetadata convertReplaceMetadata(\n-          org.apache.hudi.avro.model.HoodieReplaceCommitMetadata hoodieReplaceCommitMetadata) {\n-    HoodieReplaceCommitMetadata avroMetaData =\n-            new HoodieReplaceCommitMetadata();\n-    // Do not archive Rolling Stats, cannot set to null since AVRO will throw null pointer\n-    avroMetaData.getExtraMetadata().put(HoodieRollingStatMetadata.ROLLING_STAT_METADATA_KEY, \"\");\n-    return avroMetaData;\n-  }\n }\n\\ No newline at end of file\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyMjA1Ng==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587722056", "bodyText": "Do we need this? is this TODO still relevant", "author": "vinothchandar", "createdAt": "2021-03-04T18:39:11Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.utils;\n+\n+import org.apache.hudi.client.lock.ConflictResolutionStrategy;\n+import org.apache.hudi.client.lock.HoodieCommitOperation;\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.model.HoodieCommonMetadata;\n+import org.apache.hudi.common.table.HoodieTableMetaClient;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.common.util.ValidationUtils;\n+import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.hudi.exception.HoodieWriteConflictException;\n+import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n+import org.apache.hudi.table.HoodieTable;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+import java.io.IOException;\n+import java.util.stream.Stream;\n+\n+public class TransactionUtils {\n+\n+  private static final Logger LOG = LogManager.getLogger(TransactionUtils.class);\n+\n+  /**\n+   * Resolve any write conflicts when committing data.\n+   * @param table\n+   * @param metadataWriter\n+   * @param currentTxnOwnerInstant\n+   * @param thisCommitMetadata\n+   * @param config\n+   * @param lastCompletedTxnOwnerInstant\n+   * @return\n+   * @throws HoodieWriteConflictException\n+   */\n+  public static Option<HoodieCommitMetadata> resolveWriteConflictIfAny(final HoodieTable table, final Option<HoodieBackedTableMetadataWriter> metadataWriter,\n+                                                                       final Option<HoodieInstant> currentTxnOwnerInstant, final Option<HoodieCommitMetadata> thisCommitMetadata,\n+                                                                       final HoodieWriteConfig config, Option<HoodieInstant> lastCompletedTxnOwnerInstant)\n+      throws HoodieWriteConflictException {\n+    if (config.getWriteConcurrencyMode().supportsOptimisticConcurrencyControl()) {\n+      ConflictResolutionStrategy resolutionStrategy = config.getWriteConflictResolutionStrategy();\n+      Stream<HoodieInstant> instantStream = resolutionStrategy.getInstantsStream(table.getActiveTimeline(), currentTxnOwnerInstant.get(), lastCompletedTxnOwnerInstant);\n+      // TODO : metadataWriter.reload() inside resolve write conflict ??", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzgyNjgwMA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587826800", "bodyText": "I put this TODO since we are going to need a way to use the MetadataWriter to manipulate any concurrent actions performed, we will address this use-case in a follow up PR. I have removed metadata writer for now.", "author": "n3nash", "createdAt": "2021-03-04T21:08:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyMjA1Ng=="}], "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\nindex 27e44db6c..e4ab81057 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n", "chunk": "@@ -18,14 +18,12 @@\n \n package org.apache.hudi.client.utils;\n \n-import org.apache.hudi.client.lock.ConflictResolutionStrategy;\n-import org.apache.hudi.client.lock.HoodieCommitOperation;\n+import org.apache.hudi.client.transaction.ConflictResolutionStrategy;\n+import org.apache.hudi.client.transaction.HoodieCommitOperation;\n import org.apache.hudi.common.model.HoodieCommitMetadata;\n-import org.apache.hudi.common.model.HoodieCommonMetadata;\n-import org.apache.hudi.common.table.HoodieTableMetaClient;\n+import org.apache.hudi.common.model.HoodieMetadataWrapper;\n import org.apache.hudi.common.table.timeline.HoodieInstant;\n import org.apache.hudi.common.util.Option;\n-import org.apache.hudi.common.util.ValidationUtils;\n import org.apache.hudi.config.HoodieWriteConfig;\n import org.apache.hudi.exception.HoodieWriteConflictException;\n import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n", "next_change": {"commit": "45e931ec410685bcc1ec8dd974560add27dac684", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\nindex e4ab81057..e8fb2dc80 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n", "chunk": "@@ -19,9 +19,8 @@\n package org.apache.hudi.client.utils;\n \n import org.apache.hudi.client.transaction.ConflictResolutionStrategy;\n-import org.apache.hudi.client.transaction.HoodieCommitOperation;\n+import org.apache.hudi.client.transaction.ConcurrentOperation;\n import org.apache.hudi.common.model.HoodieCommitMetadata;\n-import org.apache.hudi.common.model.HoodieMetadataWrapper;\n import org.apache.hudi.common.table.timeline.HoodieInstant;\n import org.apache.hudi.common.util.Option;\n import org.apache.hudi.config.HoodieWriteConfig;\n", "next_change": {"commit": "02efbb661e7ed13c3614ddee7ab5157623070f7c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\nindex e8fb2dc80..d4ba4fb0d 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n", "chunk": "@@ -25,7 +25,6 @@ import org.apache.hudi.common.table.timeline.HoodieInstant;\n import org.apache.hudi.common.util.Option;\n import org.apache.hudi.config.HoodieWriteConfig;\n import org.apache.hudi.exception.HoodieWriteConflictException;\n-import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n import org.apache.hudi.table.HoodieTable;\n import org.apache.log4j.LogManager;\n import org.apache.log4j.Logger;\n", "next_change": {"commit": "1886bbd803f1a51e3d261705dd1283cfa8caf06b", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\nindex d4ba4fb0d..cbd9eaa71 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n", "chunk": "@@ -18,12 +18,20 @@\n \n package org.apache.hudi.client.utils;\n \n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n import org.apache.hudi.client.transaction.ConflictResolutionStrategy;\n import org.apache.hudi.client.transaction.ConcurrentOperation;\n import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.model.HoodieReplaceCommitMetadata;\n+import org.apache.hudi.common.table.HoodieTableMetaClient;\n import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.table.timeline.HoodieTimeline;\n import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.common.util.collection.Pair;\n import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.hudi.exception.HoodieIOException;\n import org.apache.hudi.exception.HoodieWriteConflictException;\n import org.apache.hudi.table.HoodieTable;\n import org.apache.log4j.LogManager;\n", "next_change": {"commit": "461047d03e9b7b73b34536ccf290a24f4aada6b0", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\nindex cbd9eaa71..d4ba4fb0d 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n", "chunk": "@@ -18,20 +18,12 @@\n \n package org.apache.hudi.client.utils;\n \n-import java.util.Arrays;\n-import java.util.List;\n-import java.util.Map;\n import org.apache.hudi.client.transaction.ConflictResolutionStrategy;\n import org.apache.hudi.client.transaction.ConcurrentOperation;\n import org.apache.hudi.common.model.HoodieCommitMetadata;\n-import org.apache.hudi.common.model.HoodieReplaceCommitMetadata;\n-import org.apache.hudi.common.table.HoodieTableMetaClient;\n import org.apache.hudi.common.table.timeline.HoodieInstant;\n-import org.apache.hudi.common.table.timeline.HoodieTimeline;\n import org.apache.hudi.common.util.Option;\n-import org.apache.hudi.common.util.collection.Pair;\n import org.apache.hudi.config.HoodieWriteConfig;\n-import org.apache.hudi.exception.HoodieIOException;\n import org.apache.hudi.exception.HoodieWriteConflictException;\n import org.apache.hudi.table.HoodieTable;\n import org.apache.log4j.LogManager;\n", "next_change": {"commit": "a466320b7537bf2862df853344e80fbd0be6d16a", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\nindex d4ba4fb0d..56e028bb1 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n", "chunk": "@@ -18,12 +18,20 @@\n \n package org.apache.hudi.client.utils;\n \n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n import org.apache.hudi.client.transaction.ConflictResolutionStrategy;\n import org.apache.hudi.client.transaction.ConcurrentOperation;\n import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.model.HoodieReplaceCommitMetadata;\n+import org.apache.hudi.common.table.HoodieTableMetaClient;\n import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.table.timeline.HoodieTimeline;\n import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.common.util.collection.Pair;\n import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.hudi.exception.HoodieIOException;\n import org.apache.hudi.exception.HoodieWriteConflictException;\n import org.apache.hudi.table.HoodieTable;\n import org.apache.log4j.LogManager;\n", "next_change": null}]}}]}}]}}]}}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\nindex 27e44db6c..e4ab81057 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n", "chunk": "@@ -56,18 +54,19 @@ public class TransactionUtils {\n       throws HoodieWriteConflictException {\n     if (config.getWriteConcurrencyMode().supportsOptimisticConcurrencyControl()) {\n       ConflictResolutionStrategy resolutionStrategy = config.getWriteConflictResolutionStrategy();\n-      Stream<HoodieInstant> instantStream = resolutionStrategy.getInstantsStream(table.getActiveTimeline(), currentTxnOwnerInstant.get(), lastCompletedTxnOwnerInstant);\n+      Stream<HoodieInstant> instantStream = resolutionStrategy.getCandidateInstants(table.getActiveTimeline(), currentTxnOwnerInstant.get(), lastCompletedTxnOwnerInstant);\n       // TODO : metadataWriter.reload() inside resolve write conflict ??\n       // TODO : Refactor to allow for checking against schedule compaction, clustering, cleaning (each of them plan is different)\n       final HoodieCommitOperation thisOperation = new HoodieCommitOperation(currentTxnOwnerInstant.get().getState().name(),\n               currentTxnOwnerInstant.get().getAction(), currentTxnOwnerInstant.get().getTimestamp(), thisCommitMetadata.get());\n       instantStream.forEach(instant -> {\n         try {\n-          HoodieCommitOperation otherOperation = new HoodieCommitOperation(new HoodieCommonMetadata(HoodieMetadataConversionUtils.createMetaWrapper(instant, table.getMetaClient())));\n+          HoodieCommitOperation otherOperation = new HoodieCommitOperation(new HoodieMetadataWrapper(\n+              MetadataConversionUtils.createMetaWrapper(instant, table.getMetaClient())));\n           if (resolutionStrategy.hasConflict(thisOperation, otherOperation)) {\n             LOG.info(\"Conflict encountered between current instant = \" + thisOperation + \" and instant = \"\n                     + otherOperation + \", attempting to resolve it...\");\n-            resolutionStrategy.resolveConflict(metadataWriter, table, thisOperation, otherOperation);\n+            resolutionStrategy.resolveConflict(table, thisOperation, otherOperation);\n           }\n         } catch (IOException io) {\n           throw new HoodieWriteConflictException(\"Unable to resolve conflict, if present\", io);\n", "next_change": {"commit": "45e931ec410685bcc1ec8dd974560add27dac684", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\nindex e4ab81057..e8fb2dc80 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n", "chunk": "@@ -55,14 +54,10 @@ public class TransactionUtils {\n     if (config.getWriteConcurrencyMode().supportsOptimisticConcurrencyControl()) {\n       ConflictResolutionStrategy resolutionStrategy = config.getWriteConflictResolutionStrategy();\n       Stream<HoodieInstant> instantStream = resolutionStrategy.getCandidateInstants(table.getActiveTimeline(), currentTxnOwnerInstant.get(), lastCompletedTxnOwnerInstant);\n-      // TODO : metadataWriter.reload() inside resolve write conflict ??\n-      // TODO : Refactor to allow for checking against schedule compaction, clustering, cleaning (each of them plan is different)\n-      final HoodieCommitOperation thisOperation = new HoodieCommitOperation(currentTxnOwnerInstant.get().getState().name(),\n-              currentTxnOwnerInstant.get().getAction(), currentTxnOwnerInstant.get().getTimestamp(), thisCommitMetadata.get());\n+      final ConcurrentOperation thisOperation = new ConcurrentOperation(currentTxnOwnerInstant.get(), thisCommitMetadata.get());\n       instantStream.forEach(instant -> {\n         try {\n-          HoodieCommitOperation otherOperation = new HoodieCommitOperation(new HoodieMetadataWrapper(\n-              MetadataConversionUtils.createMetaWrapper(instant, table.getMetaClient())));\n+          ConcurrentOperation otherOperation = new ConcurrentOperation(instant, table.getMetaClient());\n           if (resolutionStrategy.hasConflict(thisOperation, otherOperation)) {\n             LOG.info(\"Conflict encountered between current instant = \" + thisOperation + \" and instant = \"\n                     + otherOperation + \", attempting to resolve it...\");\n", "next_change": {"commit": "02efbb661e7ed13c3614ddee7ab5157623070f7c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\nindex e8fb2dc80..d4ba4fb0d 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n", "chunk": "@@ -47,10 +45,8 @@ public class TransactionUtils {\n    * @return\n    * @throws HoodieWriteConflictException\n    */\n-  public static Option<HoodieCommitMetadata> resolveWriteConflictIfAny(final HoodieTable table, final Option<HoodieBackedTableMetadataWriter> metadataWriter,\n-                                                                       final Option<HoodieInstant> currentTxnOwnerInstant, final Option<HoodieCommitMetadata> thisCommitMetadata,\n-                                                                       final HoodieWriteConfig config, Option<HoodieInstant> lastCompletedTxnOwnerInstant)\n-      throws HoodieWriteConflictException {\n+  public static Option<HoodieCommitMetadata> resolveWriteConflictIfAny(final HoodieTable table, final Option<HoodieInstant> currentTxnOwnerInstant,\n+      final Option<HoodieCommitMetadata> thisCommitMetadata, final HoodieWriteConfig config, Option<HoodieInstant> lastCompletedTxnOwnerInstant) throws HoodieWriteConflictException {\n     if (config.getWriteConcurrencyMode().supportsOptimisticConcurrencyControl()) {\n       ConflictResolutionStrategy resolutionStrategy = config.getWriteConflictResolutionStrategy();\n       Stream<HoodieInstant> instantStream = resolutionStrategy.getCandidateInstants(table.getActiveTimeline(), currentTxnOwnerInstant.get(), lastCompletedTxnOwnerInstant);\n", "next_change": null}]}}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\nindex 27e44db6c..e4ab81057 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n", "chunk": "@@ -78,12 +77,4 @@ public class TransactionUtils {\n     }\n     return thisCommitMetadata;\n   }\n-\n-  /**\n-   * Special conflict resolution only for upgrade/downgrade scenarios.\n-   * @param metaClient\n-   */\n-  public static void resolveConflictIfAnyForUpgradeDowngrade(HoodieTableMetaClient metaClient) {\n-    ValidationUtils.checkState(metaClient.getActiveTimeline().filterInflights().countInstants() == 0, \"Cannot perform Upgrade/Downgrade while another write is in progress\");\n-  }\n }\n\\ No newline at end of file\n", "next_change": {"commit": "1886bbd803f1a51e3d261705dd1283cfa8caf06b", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\nindex e4ab81057..cbd9eaa71 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n", "chunk": "@@ -73,8 +72,47 @@ public class TransactionUtils {\n         }\n       });\n       LOG.info(\"Successfully resolved conflicts, if any\");\n+      // carry over necessary metadata from latest commit metadata\n+      overrideWithLatestCommitMetadata(table.getMetaClient(), thisOperation.getCommitMetadataOption(), currentTxnOwnerInstant, Arrays.asList(config.getWriteMetaKeyPrefixes().split(\",\")));\n       return thisOperation.getCommitMetadataOption();\n     }\n     return thisCommitMetadata;\n   }\n+\n+  public static Option<Pair<HoodieInstant, Map<String, String>>> getLastCompletedTxnInstantAndMetadata(\n+      HoodieTableMetaClient metaClient) {\n+    Option<HoodieInstant> hoodieInstantOption = metaClient.getActiveTimeline().getCommitsTimeline()\n+        .filterCompletedInstants().lastInstant();\n+    try {\n+      if (hoodieInstantOption.isPresent() && hoodieInstantOption.get().getAction().equals(\n+          HoodieTimeline.REPLACE_COMMIT_ACTION)) {\n+        HoodieReplaceCommitMetadata replaceCommitMetadata = HoodieReplaceCommitMetadata\n+            .fromBytes(metaClient.getCommitTimeline().getInstantDetails(hoodieInstantOption.get()).get(), HoodieReplaceCommitMetadata.class);\n+        return Option.of(Pair.of(hoodieInstantOption.get(), replaceCommitMetadata.getExtraMetadata()));\n+      } else if (hoodieInstantOption.isPresent() && (hoodieInstantOption.get().getAction().equals(\n+          HoodieTimeline.DELTA_COMMIT_ACTION) || hoodieInstantOption.get().getAction().equals(HoodieTimeline.COMMIT_ACTION))) {\n+        HoodieCommitMetadata commitMetadata = HoodieCommitMetadata\n+            .fromBytes(metaClient.getCommitTimeline().getInstantDetails(hoodieInstantOption.get()).get(), HoodieCommitMetadata.class);\n+        return Option.of(Pair.of(hoodieInstantOption.get(), commitMetadata.getExtraMetadata()));\n+      } else {\n+        return Option.empty();\n+      }\n+    } catch (IOException io) {\n+      throw new HoodieIOException(\"Unable to read metadata for instant \" + hoodieInstantOption.get(), io);\n+    }\n+  }\n+\n+  private static void overrideWithLatestCommitMetadata(HoodieTableMetaClient metaClient, Option<HoodieCommitMetadata> thisMetadata,\n+      Option<HoodieInstant> thisInstant, List<String> keyPrefixes) {\n+    if (keyPrefixes.size() > 0) {\n+      Option<Pair<HoodieInstant, Map<String, String>>> lastInstant = getLastCompletedTxnInstantAndMetadata(metaClient);\n+      if (lastInstant.isPresent() && thisMetadata.isPresent()\n+          && HoodieTimeline.compareTimestamps(lastInstant.get().getLeft().getTimestamp(), HoodieTimeline.GREATER_THAN, thisInstant.get().getTimestamp())) {\n+        Stream<String> keys = thisMetadata.get().getExtraMetadata().keySet().stream();\n+        keyPrefixes.stream().forEach(keyPrefix -> keys\n+            .filter(key -> key.startsWith(keyPrefix))\n+            .forEach(key -> thisMetadata.get().getExtraMetadata().put(key, lastInstant.get().getRight().get(key))));\n+      }\n+    }\n+  }\n }\n\\ No newline at end of file\n", "next_change": {"commit": "01577fda0944e2cb710f0907965ca8e602650f8a", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\nindex cbd9eaa71..4301eaa1f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n", "chunk": "@@ -106,8 +106,7 @@ public class TransactionUtils {\n       Option<HoodieInstant> thisInstant, List<String> keyPrefixes) {\n     if (keyPrefixes.size() > 0) {\n       Option<Pair<HoodieInstant, Map<String, String>>> lastInstant = getLastCompletedTxnInstantAndMetadata(metaClient);\n-      if (lastInstant.isPresent() && thisMetadata.isPresent()\n-          && HoodieTimeline.compareTimestamps(lastInstant.get().getLeft().getTimestamp(), HoodieTimeline.GREATER_THAN, thisInstant.get().getTimestamp())) {\n+      if (lastInstant.isPresent() && thisMetadata.isPresent()) {\n         Stream<String> keys = thisMetadata.get().getExtraMetadata().keySet().stream();\n         keyPrefixes.stream().forEach(keyPrefix -> keys\n             .filter(key -> key.startsWith(keyPrefix))\n", "next_change": {"commit": "9278889bad4fe529a7c403857f20bcd0198322e6", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\nindex 4301eaa1f..56e028bb1 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n", "chunk": "@@ -104,14 +104,15 @@ public class TransactionUtils {\n \n   private static void overrideWithLatestCommitMetadata(HoodieTableMetaClient metaClient, Option<HoodieCommitMetadata> thisMetadata,\n       Option<HoodieInstant> thisInstant, List<String> keyPrefixes) {\n-    if (keyPrefixes.size() > 0) {\n-      Option<Pair<HoodieInstant, Map<String, String>>> lastInstant = getLastCompletedTxnInstantAndMetadata(metaClient);\n-      if (lastInstant.isPresent() && thisMetadata.isPresent()) {\n-        Stream<String> keys = thisMetadata.get().getExtraMetadata().keySet().stream();\n-        keyPrefixes.stream().forEach(keyPrefix -> keys\n-            .filter(key -> key.startsWith(keyPrefix))\n-            .forEach(key -> thisMetadata.get().getExtraMetadata().put(key, lastInstant.get().getRight().get(key))));\n-      }\n+    if (keyPrefixes.size() == 1 && keyPrefixes.get(0).length() < 1) {\n+      return;\n+    }\n+    Option<Pair<HoodieInstant, Map<String, String>>> lastInstant = getLastCompletedTxnInstantAndMetadata(metaClient);\n+    if (lastInstant.isPresent() && thisMetadata.isPresent()) {\n+      Stream<String> keys = thisMetadata.get().getExtraMetadata().keySet().stream();\n+      keyPrefixes.stream().forEach(keyPrefix -> keys\n+          .filter(key -> key.startsWith(keyPrefix))\n+          .forEach(key -> thisMetadata.get().getExtraMetadata().put(key, lastInstant.get().getRight().get(key))));\n     }\n   }\n }\n\\ No newline at end of file\n", "next_change": {"commit": "461047d03e9b7b73b34536ccf290a24f4aada6b0", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\nindex 56e028bb1..d4ba4fb0d 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n", "chunk": "@@ -72,47 +64,8 @@ public class TransactionUtils {\n         }\n       });\n       LOG.info(\"Successfully resolved conflicts, if any\");\n-      // carry over necessary metadata from latest commit metadata\n-      overrideWithLatestCommitMetadata(table.getMetaClient(), thisOperation.getCommitMetadataOption(), currentTxnOwnerInstant, Arrays.asList(config.getWriteMetaKeyPrefixes().split(\",\")));\n       return thisOperation.getCommitMetadataOption();\n     }\n     return thisCommitMetadata;\n   }\n-\n-  public static Option<Pair<HoodieInstant, Map<String, String>>> getLastCompletedTxnInstantAndMetadata(\n-      HoodieTableMetaClient metaClient) {\n-    Option<HoodieInstant> hoodieInstantOption = metaClient.getActiveTimeline().getCommitsTimeline()\n-        .filterCompletedInstants().lastInstant();\n-    try {\n-      if (hoodieInstantOption.isPresent() && hoodieInstantOption.get().getAction().equals(\n-          HoodieTimeline.REPLACE_COMMIT_ACTION)) {\n-        HoodieReplaceCommitMetadata replaceCommitMetadata = HoodieReplaceCommitMetadata\n-            .fromBytes(metaClient.getCommitTimeline().getInstantDetails(hoodieInstantOption.get()).get(), HoodieReplaceCommitMetadata.class);\n-        return Option.of(Pair.of(hoodieInstantOption.get(), replaceCommitMetadata.getExtraMetadata()));\n-      } else if (hoodieInstantOption.isPresent() && (hoodieInstantOption.get().getAction().equals(\n-          HoodieTimeline.DELTA_COMMIT_ACTION) || hoodieInstantOption.get().getAction().equals(HoodieTimeline.COMMIT_ACTION))) {\n-        HoodieCommitMetadata commitMetadata = HoodieCommitMetadata\n-            .fromBytes(metaClient.getCommitTimeline().getInstantDetails(hoodieInstantOption.get()).get(), HoodieCommitMetadata.class);\n-        return Option.of(Pair.of(hoodieInstantOption.get(), commitMetadata.getExtraMetadata()));\n-      } else {\n-        return Option.empty();\n-      }\n-    } catch (IOException io) {\n-      throw new HoodieIOException(\"Unable to read metadata for instant \" + hoodieInstantOption.get(), io);\n-    }\n-  }\n-\n-  private static void overrideWithLatestCommitMetadata(HoodieTableMetaClient metaClient, Option<HoodieCommitMetadata> thisMetadata,\n-      Option<HoodieInstant> thisInstant, List<String> keyPrefixes) {\n-    if (keyPrefixes.size() == 1 && keyPrefixes.get(0).length() < 1) {\n-      return;\n-    }\n-    Option<Pair<HoodieInstant, Map<String, String>>> lastInstant = getLastCompletedTxnInstantAndMetadata(metaClient);\n-    if (lastInstant.isPresent() && thisMetadata.isPresent()) {\n-      Stream<String> keys = thisMetadata.get().getExtraMetadata().keySet().stream();\n-      keyPrefixes.stream().forEach(keyPrefix -> keys\n-          .filter(key -> key.startsWith(keyPrefix))\n-          .forEach(key -> thisMetadata.get().getExtraMetadata().put(key, lastInstant.get().getRight().get(key))));\n-    }\n-  }\n }\n\\ No newline at end of file\n", "next_change": {"commit": "a466320b7537bf2862df853344e80fbd0be6d16a", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\nindex d4ba4fb0d..56e028bb1 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n", "chunk": "@@ -64,8 +72,47 @@ public class TransactionUtils {\n         }\n       });\n       LOG.info(\"Successfully resolved conflicts, if any\");\n+      // carry over necessary metadata from latest commit metadata\n+      overrideWithLatestCommitMetadata(table.getMetaClient(), thisOperation.getCommitMetadataOption(), currentTxnOwnerInstant, Arrays.asList(config.getWriteMetaKeyPrefixes().split(\",\")));\n       return thisOperation.getCommitMetadataOption();\n     }\n     return thisCommitMetadata;\n   }\n+\n+  public static Option<Pair<HoodieInstant, Map<String, String>>> getLastCompletedTxnInstantAndMetadata(\n+      HoodieTableMetaClient metaClient) {\n+    Option<HoodieInstant> hoodieInstantOption = metaClient.getActiveTimeline().getCommitsTimeline()\n+        .filterCompletedInstants().lastInstant();\n+    try {\n+      if (hoodieInstantOption.isPresent() && hoodieInstantOption.get().getAction().equals(\n+          HoodieTimeline.REPLACE_COMMIT_ACTION)) {\n+        HoodieReplaceCommitMetadata replaceCommitMetadata = HoodieReplaceCommitMetadata\n+            .fromBytes(metaClient.getCommitTimeline().getInstantDetails(hoodieInstantOption.get()).get(), HoodieReplaceCommitMetadata.class);\n+        return Option.of(Pair.of(hoodieInstantOption.get(), replaceCommitMetadata.getExtraMetadata()));\n+      } else if (hoodieInstantOption.isPresent() && (hoodieInstantOption.get().getAction().equals(\n+          HoodieTimeline.DELTA_COMMIT_ACTION) || hoodieInstantOption.get().getAction().equals(HoodieTimeline.COMMIT_ACTION))) {\n+        HoodieCommitMetadata commitMetadata = HoodieCommitMetadata\n+            .fromBytes(metaClient.getCommitTimeline().getInstantDetails(hoodieInstantOption.get()).get(), HoodieCommitMetadata.class);\n+        return Option.of(Pair.of(hoodieInstantOption.get(), commitMetadata.getExtraMetadata()));\n+      } else {\n+        return Option.empty();\n+      }\n+    } catch (IOException io) {\n+      throw new HoodieIOException(\"Unable to read metadata for instant \" + hoodieInstantOption.get(), io);\n+    }\n+  }\n+\n+  private static void overrideWithLatestCommitMetadata(HoodieTableMetaClient metaClient, Option<HoodieCommitMetadata> thisMetadata,\n+      Option<HoodieInstant> thisInstant, List<String> keyPrefixes) {\n+    if (keyPrefixes.size() == 1 && keyPrefixes.get(0).length() < 1) {\n+      return;\n+    }\n+    Option<Pair<HoodieInstant, Map<String, String>>> lastInstant = getLastCompletedTxnInstantAndMetadata(metaClient);\n+    if (lastInstant.isPresent() && thisMetadata.isPresent()) {\n+      Stream<String> keys = thisMetadata.get().getExtraMetadata().keySet().stream();\n+      keyPrefixes.stream().forEach(keyPrefix -> keys\n+          .filter(key -> key.startsWith(keyPrefix))\n+          .forEach(key -> thisMetadata.get().getExtraMetadata().put(key, lastInstant.get().getRight().get(key))));\n+    }\n+  }\n }\n\\ No newline at end of file\n", "next_change": {"commit": "bcc0f5baddc3eefad510441865cbf40a44c9a719", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\nindex 56e028bb1..82a22494b 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n", "chunk": "@@ -79,21 +79,30 @@ public class TransactionUtils {\n     return thisCommitMetadata;\n   }\n \n+  /**\n+   * Get the last completed transaction hoodie instant and {@link HoodieCommitMetadata#getExtraMetadata()}.\n+   * @param metaClient\n+   * @return\n+   */\n   public static Option<Pair<HoodieInstant, Map<String, String>>> getLastCompletedTxnInstantAndMetadata(\n       HoodieTableMetaClient metaClient) {\n     Option<HoodieInstant> hoodieInstantOption = metaClient.getActiveTimeline().getCommitsTimeline()\n         .filterCompletedInstants().lastInstant();\n     try {\n-      if (hoodieInstantOption.isPresent() && hoodieInstantOption.get().getAction().equals(\n-          HoodieTimeline.REPLACE_COMMIT_ACTION)) {\n-        HoodieReplaceCommitMetadata replaceCommitMetadata = HoodieReplaceCommitMetadata\n-            .fromBytes(metaClient.getCommitTimeline().getInstantDetails(hoodieInstantOption.get()).get(), HoodieReplaceCommitMetadata.class);\n-        return Option.of(Pair.of(hoodieInstantOption.get(), replaceCommitMetadata.getExtraMetadata()));\n-      } else if (hoodieInstantOption.isPresent() && (hoodieInstantOption.get().getAction().equals(\n-          HoodieTimeline.DELTA_COMMIT_ACTION) || hoodieInstantOption.get().getAction().equals(HoodieTimeline.COMMIT_ACTION))) {\n-        HoodieCommitMetadata commitMetadata = HoodieCommitMetadata\n-            .fromBytes(metaClient.getCommitTimeline().getInstantDetails(hoodieInstantOption.get()).get(), HoodieCommitMetadata.class);\n-        return Option.of(Pair.of(hoodieInstantOption.get(), commitMetadata.getExtraMetadata()));\n+      if (hoodieInstantOption.isPresent()) {\n+        switch (hoodieInstantOption.get().getAction()) {\n+          case HoodieTimeline.REPLACE_COMMIT_ACTION:\n+            HoodieReplaceCommitMetadata replaceCommitMetadata = HoodieReplaceCommitMetadata\n+            .fromBytes(metaClient.getActiveTimeline().getInstantDetails(hoodieInstantOption.get()).get(), HoodieReplaceCommitMetadata.class);\n+            return Option.of(Pair.of(hoodieInstantOption.get(), replaceCommitMetadata.getExtraMetadata()));\n+          case HoodieTimeline.DELTA_COMMIT_ACTION:\n+          case HoodieTimeline.COMMIT_ACTION:\n+            HoodieCommitMetadata commitMetadata = HoodieCommitMetadata\n+            .fromBytes(metaClient.getActiveTimeline().getInstantDetails(hoodieInstantOption.get()).get(), HoodieCommitMetadata.class);\n+            return Option.of(Pair.of(hoodieInstantOption.get(), commitMetadata.getExtraMetadata()));\n+          default:\n+            throw new IllegalArgumentException(\"Unknown instant action\" + hoodieInstantOption.get().getAction());\n+        }\n       } else {\n         return Option.empty();\n       }\n", "next_change": {"commit": "0e7fbb3ab8c02fbaee04adfc89205d6bee0834ab", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\nindex 82a22494b..80a412010 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n", "chunk": "@@ -93,12 +93,12 @@ public class TransactionUtils {\n         switch (hoodieInstantOption.get().getAction()) {\n           case HoodieTimeline.REPLACE_COMMIT_ACTION:\n             HoodieReplaceCommitMetadata replaceCommitMetadata = HoodieReplaceCommitMetadata\n-            .fromBytes(metaClient.getActiveTimeline().getInstantDetails(hoodieInstantOption.get()).get(), HoodieReplaceCommitMetadata.class);\n+                .fromBytes(metaClient.getActiveTimeline().getInstantDetails(hoodieInstantOption.get()).get(), HoodieReplaceCommitMetadata.class);\n             return Option.of(Pair.of(hoodieInstantOption.get(), replaceCommitMetadata.getExtraMetadata()));\n           case HoodieTimeline.DELTA_COMMIT_ACTION:\n           case HoodieTimeline.COMMIT_ACTION:\n             HoodieCommitMetadata commitMetadata = HoodieCommitMetadata\n-            .fromBytes(metaClient.getActiveTimeline().getInstantDetails(hoodieInstantOption.get()).get(), HoodieCommitMetadata.class);\n+                .fromBytes(metaClient.getActiveTimeline().getInstantDetails(hoodieInstantOption.get()).get(), HoodieCommitMetadata.class);\n             return Option.of(Pair.of(hoodieInstantOption.get(), commitMetadata.getExtraMetadata()));\n           default:\n             throw new IllegalArgumentException(\"Unknown instant action\" + hoodieInstantOption.get().getAction());\n", "next_change": null}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\nindex 56e028bb1..82a22494b 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n", "chunk": "@@ -102,6 +111,7 @@ public class TransactionUtils {\n     }\n   }\n \n+  // override the current metadata with the metadata from the latest instant for the specified key prefixes\n   private static void overrideWithLatestCommitMetadata(HoodieTableMetaClient metaClient, Option<HoodieCommitMetadata> thisMetadata,\n       Option<HoodieInstant> thisInstant, List<String> keyPrefixes) {\n     if (keyPrefixes.size() == 1 && keyPrefixes.get(0).length() < 1) {\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyMjM2MQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587722361", "bodyText": "rename to MetadataConversionUtils ?", "author": "vinothchandar", "createdAt": "2021-03-04T18:39:38Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/HoodieMetadataConversionUtils.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.utils;\n+\n+import com.fasterxml.jackson.databind.DeserializationFeature;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.apache.hudi.avro.model.HoodieArchivedMetaEntry;\n+import org.apache.hudi.avro.model.HoodieCompactionPlan;\n+import org.apache.hudi.avro.model.HoodieRollbackMetadata;\n+import org.apache.hudi.avro.model.HoodieSavepointMetadata;\n+import org.apache.hudi.client.ReplaceArchivalHelper;\n+import org.apache.hudi.common.model.ActionType;\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.model.HoodieReplaceCommitMetadata;\n+import org.apache.hudi.common.model.HoodieRollingStatMetadata;\n+import org.apache.hudi.common.table.HoodieTableMetaClient;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.table.timeline.HoodieTimeline;\n+import org.apache.hudi.common.table.timeline.TimelineMetadataUtils;\n+import org.apache.hudi.common.util.CleanerUtils;\n+import org.apache.hudi.common.util.CompactionUtils;\n+import java.io.IOException;\n+\n+/**\n+ * Helper class to convert between different action related payloads and {@link HoodieArchivedMetaEntry}.\n+ */\n+public class HoodieMetadataConversionUtils {", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/HoodieMetadataConversionUtils.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/MetadataConversionUtils.java\nsimilarity index 86%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/HoodieMetadataConversionUtils.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/MetadataConversionUtils.java\nindex 8a2ae8166..35dd43858 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/HoodieMetadataConversionUtils.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/MetadataConversionUtils.java\n", "chunk": "@@ -40,7 +40,7 @@ import java.io.IOException;\n /**\n  * Helper class to convert between different action related payloads and {@link HoodieArchivedMetaEntry}.\n  */\n-public class HoodieMetadataConversionUtils {\n+public class MetadataConversionUtils {\n \n   public static HoodieArchivedMetaEntry createMetaWrapper(HoodieInstant hoodieInstant, HoodieTableMetaClient metaClient) throws IOException {\n     HoodieArchivedMetaEntry archivedMetaWrapper = new HoodieArchivedMetaEntry();\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/HoodieMetadataConversionUtils.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/MetadataConversionUtils.java\nsimilarity index 86%\nrename from hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/HoodieMetadataConversionUtils.java\nrename to hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/MetadataConversionUtils.java\nindex 8a2ae8166..35dd43858 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/HoodieMetadataConversionUtils.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/MetadataConversionUtils.java\n", "chunk": "@@ -117,23 +117,4 @@ public class HoodieMetadataConversionUtils {\n     avroMetaData.getExtraMetadata().put(HoodieRollingStatMetadata.ROLLING_STAT_METADATA_KEY, \"\");\n     return avroMetaData;\n   }\n-\n-  // TODO : Fix converting from SpecificRecord to POJO\n-  public static HoodieCommitMetadata convertCommitMetadata(\n-          org.apache.hudi.avro.model.HoodieCommitMetadata hoodieCommitMetadata) {\n-    HoodieCommitMetadata avroMetaData =\n-            new HoodieCommitMetadata();\n-    // Do not archive Rolling Stats, cannot set to null since AVRO will throw null pointer\n-    avroMetaData.getExtraMetadata().put(HoodieRollingStatMetadata.ROLLING_STAT_METADATA_KEY, \"\");\n-    return avroMetaData;\n-  }\n-\n-  public static HoodieCommitMetadata convertReplaceMetadata(\n-          org.apache.hudi.avro.model.HoodieReplaceCommitMetadata hoodieReplaceCommitMetadata) {\n-    HoodieReplaceCommitMetadata avroMetaData =\n-            new HoodieReplaceCommitMetadata();\n-    // Do not archive Rolling Stats, cannot set to null since AVRO will throw null pointer\n-    avroMetaData.getExtraMetadata().put(HoodieRollingStatMetadata.ROLLING_STAT_METADATA_KEY, \"\");\n-    return avroMetaData;\n-  }\n }\n\\ No newline at end of file\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyMzU0NA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587723544", "bodyText": "unit test this method?", "author": "vinothchandar", "createdAt": "2021-03-04T18:41:20Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.utils;\n+\n+import org.apache.hudi.client.lock.ConflictResolutionStrategy;\n+import org.apache.hudi.client.lock.HoodieCommitOperation;\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.model.HoodieCommonMetadata;\n+import org.apache.hudi.common.table.HoodieTableMetaClient;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.common.util.ValidationUtils;\n+import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.hudi.exception.HoodieWriteConflictException;\n+import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n+import org.apache.hudi.table.HoodieTable;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+import java.io.IOException;\n+import java.util.stream.Stream;\n+\n+public class TransactionUtils {\n+\n+  private static final Logger LOG = LogManager.getLogger(TransactionUtils.class);\n+\n+  /**\n+   * Resolve any write conflicts when committing data.\n+   * @param table\n+   * @param metadataWriter\n+   * @param currentTxnOwnerInstant\n+   * @param thisCommitMetadata\n+   * @param config\n+   * @param lastCompletedTxnOwnerInstant\n+   * @return\n+   * @throws HoodieWriteConflictException\n+   */\n+  public static Option<HoodieCommitMetadata> resolveWriteConflictIfAny(final HoodieTable table, final Option<HoodieBackedTableMetadataWriter> metadataWriter,", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzczNTI3OA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587735278", "bodyText": "is the metadataWriter really used inside this method?", "author": "vinothchandar", "createdAt": "2021-03-04T18:59:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyMzU0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzgyNTY0MQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587825641", "bodyText": "Replied above.", "author": "n3nash", "createdAt": "2021-03-04T21:07:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyMzU0NA=="}], "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\nindex 27e44db6c..e4ab81057 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n", "chunk": "@@ -18,14 +18,12 @@\n \n package org.apache.hudi.client.utils;\n \n-import org.apache.hudi.client.lock.ConflictResolutionStrategy;\n-import org.apache.hudi.client.lock.HoodieCommitOperation;\n+import org.apache.hudi.client.transaction.ConflictResolutionStrategy;\n+import org.apache.hudi.client.transaction.HoodieCommitOperation;\n import org.apache.hudi.common.model.HoodieCommitMetadata;\n-import org.apache.hudi.common.model.HoodieCommonMetadata;\n-import org.apache.hudi.common.table.HoodieTableMetaClient;\n+import org.apache.hudi.common.model.HoodieMetadataWrapper;\n import org.apache.hudi.common.table.timeline.HoodieInstant;\n import org.apache.hudi.common.util.Option;\n-import org.apache.hudi.common.util.ValidationUtils;\n import org.apache.hudi.config.HoodieWriteConfig;\n import org.apache.hudi.exception.HoodieWriteConflictException;\n import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n", "next_change": {"commit": "45e931ec410685bcc1ec8dd974560add27dac684", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\nindex e4ab81057..e8fb2dc80 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n", "chunk": "@@ -19,9 +19,8 @@\n package org.apache.hudi.client.utils;\n \n import org.apache.hudi.client.transaction.ConflictResolutionStrategy;\n-import org.apache.hudi.client.transaction.HoodieCommitOperation;\n+import org.apache.hudi.client.transaction.ConcurrentOperation;\n import org.apache.hudi.common.model.HoodieCommitMetadata;\n-import org.apache.hudi.common.model.HoodieMetadataWrapper;\n import org.apache.hudi.common.table.timeline.HoodieInstant;\n import org.apache.hudi.common.util.Option;\n import org.apache.hudi.config.HoodieWriteConfig;\n", "next_change": {"commit": "02efbb661e7ed13c3614ddee7ab5157623070f7c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\nindex e8fb2dc80..d4ba4fb0d 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n", "chunk": "@@ -25,7 +25,6 @@ import org.apache.hudi.common.table.timeline.HoodieInstant;\n import org.apache.hudi.common.util.Option;\n import org.apache.hudi.config.HoodieWriteConfig;\n import org.apache.hudi.exception.HoodieWriteConflictException;\n-import org.apache.hudi.metadata.HoodieBackedTableMetadataWriter;\n import org.apache.hudi.table.HoodieTable;\n import org.apache.log4j.LogManager;\n import org.apache.log4j.Logger;\n", "next_change": {"commit": "1886bbd803f1a51e3d261705dd1283cfa8caf06b", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\nindex d4ba4fb0d..cbd9eaa71 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n", "chunk": "@@ -18,12 +18,20 @@\n \n package org.apache.hudi.client.utils;\n \n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n import org.apache.hudi.client.transaction.ConflictResolutionStrategy;\n import org.apache.hudi.client.transaction.ConcurrentOperation;\n import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.model.HoodieReplaceCommitMetadata;\n+import org.apache.hudi.common.table.HoodieTableMetaClient;\n import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.table.timeline.HoodieTimeline;\n import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.common.util.collection.Pair;\n import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.hudi.exception.HoodieIOException;\n import org.apache.hudi.exception.HoodieWriteConflictException;\n import org.apache.hudi.table.HoodieTable;\n import org.apache.log4j.LogManager;\n", "next_change": {"commit": "461047d03e9b7b73b34536ccf290a24f4aada6b0", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\nindex cbd9eaa71..d4ba4fb0d 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n", "chunk": "@@ -18,20 +18,12 @@\n \n package org.apache.hudi.client.utils;\n \n-import java.util.Arrays;\n-import java.util.List;\n-import java.util.Map;\n import org.apache.hudi.client.transaction.ConflictResolutionStrategy;\n import org.apache.hudi.client.transaction.ConcurrentOperation;\n import org.apache.hudi.common.model.HoodieCommitMetadata;\n-import org.apache.hudi.common.model.HoodieReplaceCommitMetadata;\n-import org.apache.hudi.common.table.HoodieTableMetaClient;\n import org.apache.hudi.common.table.timeline.HoodieInstant;\n-import org.apache.hudi.common.table.timeline.HoodieTimeline;\n import org.apache.hudi.common.util.Option;\n-import org.apache.hudi.common.util.collection.Pair;\n import org.apache.hudi.config.HoodieWriteConfig;\n-import org.apache.hudi.exception.HoodieIOException;\n import org.apache.hudi.exception.HoodieWriteConflictException;\n import org.apache.hudi.table.HoodieTable;\n import org.apache.log4j.LogManager;\n", "next_change": {"commit": "a466320b7537bf2862df853344e80fbd0be6d16a", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\nindex d4ba4fb0d..56e028bb1 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n", "chunk": "@@ -18,12 +18,20 @@\n \n package org.apache.hudi.client.utils;\n \n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n import org.apache.hudi.client.transaction.ConflictResolutionStrategy;\n import org.apache.hudi.client.transaction.ConcurrentOperation;\n import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.model.HoodieReplaceCommitMetadata;\n+import org.apache.hudi.common.table.HoodieTableMetaClient;\n import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.table.timeline.HoodieTimeline;\n import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.common.util.collection.Pair;\n import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.hudi.exception.HoodieIOException;\n import org.apache.hudi.exception.HoodieWriteConflictException;\n import org.apache.hudi.table.HoodieTable;\n import org.apache.log4j.LogManager;\n", "next_change": null}]}}]}}]}}]}}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\nindex 27e44db6c..e4ab81057 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n", "chunk": "@@ -56,18 +54,19 @@ public class TransactionUtils {\n       throws HoodieWriteConflictException {\n     if (config.getWriteConcurrencyMode().supportsOptimisticConcurrencyControl()) {\n       ConflictResolutionStrategy resolutionStrategy = config.getWriteConflictResolutionStrategy();\n-      Stream<HoodieInstant> instantStream = resolutionStrategy.getInstantsStream(table.getActiveTimeline(), currentTxnOwnerInstant.get(), lastCompletedTxnOwnerInstant);\n+      Stream<HoodieInstant> instantStream = resolutionStrategy.getCandidateInstants(table.getActiveTimeline(), currentTxnOwnerInstant.get(), lastCompletedTxnOwnerInstant);\n       // TODO : metadataWriter.reload() inside resolve write conflict ??\n       // TODO : Refactor to allow for checking against schedule compaction, clustering, cleaning (each of them plan is different)\n       final HoodieCommitOperation thisOperation = new HoodieCommitOperation(currentTxnOwnerInstant.get().getState().name(),\n               currentTxnOwnerInstant.get().getAction(), currentTxnOwnerInstant.get().getTimestamp(), thisCommitMetadata.get());\n       instantStream.forEach(instant -> {\n         try {\n-          HoodieCommitOperation otherOperation = new HoodieCommitOperation(new HoodieCommonMetadata(HoodieMetadataConversionUtils.createMetaWrapper(instant, table.getMetaClient())));\n+          HoodieCommitOperation otherOperation = new HoodieCommitOperation(new HoodieMetadataWrapper(\n+              MetadataConversionUtils.createMetaWrapper(instant, table.getMetaClient())));\n           if (resolutionStrategy.hasConflict(thisOperation, otherOperation)) {\n             LOG.info(\"Conflict encountered between current instant = \" + thisOperation + \" and instant = \"\n                     + otherOperation + \", attempting to resolve it...\");\n-            resolutionStrategy.resolveConflict(metadataWriter, table, thisOperation, otherOperation);\n+            resolutionStrategy.resolveConflict(table, thisOperation, otherOperation);\n           }\n         } catch (IOException io) {\n           throw new HoodieWriteConflictException(\"Unable to resolve conflict, if present\", io);\n", "next_change": {"commit": "45e931ec410685bcc1ec8dd974560add27dac684", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\nindex e4ab81057..e8fb2dc80 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n", "chunk": "@@ -55,14 +54,10 @@ public class TransactionUtils {\n     if (config.getWriteConcurrencyMode().supportsOptimisticConcurrencyControl()) {\n       ConflictResolutionStrategy resolutionStrategy = config.getWriteConflictResolutionStrategy();\n       Stream<HoodieInstant> instantStream = resolutionStrategy.getCandidateInstants(table.getActiveTimeline(), currentTxnOwnerInstant.get(), lastCompletedTxnOwnerInstant);\n-      // TODO : metadataWriter.reload() inside resolve write conflict ??\n-      // TODO : Refactor to allow for checking against schedule compaction, clustering, cleaning (each of them plan is different)\n-      final HoodieCommitOperation thisOperation = new HoodieCommitOperation(currentTxnOwnerInstant.get().getState().name(),\n-              currentTxnOwnerInstant.get().getAction(), currentTxnOwnerInstant.get().getTimestamp(), thisCommitMetadata.get());\n+      final ConcurrentOperation thisOperation = new ConcurrentOperation(currentTxnOwnerInstant.get(), thisCommitMetadata.get());\n       instantStream.forEach(instant -> {\n         try {\n-          HoodieCommitOperation otherOperation = new HoodieCommitOperation(new HoodieMetadataWrapper(\n-              MetadataConversionUtils.createMetaWrapper(instant, table.getMetaClient())));\n+          ConcurrentOperation otherOperation = new ConcurrentOperation(instant, table.getMetaClient());\n           if (resolutionStrategy.hasConflict(thisOperation, otherOperation)) {\n             LOG.info(\"Conflict encountered between current instant = \" + thisOperation + \" and instant = \"\n                     + otherOperation + \", attempting to resolve it...\");\n", "next_change": {"commit": "02efbb661e7ed13c3614ddee7ab5157623070f7c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\nindex e8fb2dc80..d4ba4fb0d 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n", "chunk": "@@ -47,10 +45,8 @@ public class TransactionUtils {\n    * @return\n    * @throws HoodieWriteConflictException\n    */\n-  public static Option<HoodieCommitMetadata> resolveWriteConflictIfAny(final HoodieTable table, final Option<HoodieBackedTableMetadataWriter> metadataWriter,\n-                                                                       final Option<HoodieInstant> currentTxnOwnerInstant, final Option<HoodieCommitMetadata> thisCommitMetadata,\n-                                                                       final HoodieWriteConfig config, Option<HoodieInstant> lastCompletedTxnOwnerInstant)\n-      throws HoodieWriteConflictException {\n+  public static Option<HoodieCommitMetadata> resolveWriteConflictIfAny(final HoodieTable table, final Option<HoodieInstant> currentTxnOwnerInstant,\n+      final Option<HoodieCommitMetadata> thisCommitMetadata, final HoodieWriteConfig config, Option<HoodieInstant> lastCompletedTxnOwnerInstant) throws HoodieWriteConflictException {\n     if (config.getWriteConcurrencyMode().supportsOptimisticConcurrencyControl()) {\n       ConflictResolutionStrategy resolutionStrategy = config.getWriteConflictResolutionStrategy();\n       Stream<HoodieInstant> instantStream = resolutionStrategy.getCandidateInstants(table.getActiveTimeline(), currentTxnOwnerInstant.get(), lastCompletedTxnOwnerInstant);\n", "next_change": null}]}}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\nindex 27e44db6c..e4ab81057 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n", "chunk": "@@ -78,12 +77,4 @@ public class TransactionUtils {\n     }\n     return thisCommitMetadata;\n   }\n-\n-  /**\n-   * Special conflict resolution only for upgrade/downgrade scenarios.\n-   * @param metaClient\n-   */\n-  public static void resolveConflictIfAnyForUpgradeDowngrade(HoodieTableMetaClient metaClient) {\n-    ValidationUtils.checkState(metaClient.getActiveTimeline().filterInflights().countInstants() == 0, \"Cannot perform Upgrade/Downgrade while another write is in progress\");\n-  }\n }\n\\ No newline at end of file\n", "next_change": {"commit": "1886bbd803f1a51e3d261705dd1283cfa8caf06b", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\nindex e4ab81057..cbd9eaa71 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n", "chunk": "@@ -73,8 +72,47 @@ public class TransactionUtils {\n         }\n       });\n       LOG.info(\"Successfully resolved conflicts, if any\");\n+      // carry over necessary metadata from latest commit metadata\n+      overrideWithLatestCommitMetadata(table.getMetaClient(), thisOperation.getCommitMetadataOption(), currentTxnOwnerInstant, Arrays.asList(config.getWriteMetaKeyPrefixes().split(\",\")));\n       return thisOperation.getCommitMetadataOption();\n     }\n     return thisCommitMetadata;\n   }\n+\n+  public static Option<Pair<HoodieInstant, Map<String, String>>> getLastCompletedTxnInstantAndMetadata(\n+      HoodieTableMetaClient metaClient) {\n+    Option<HoodieInstant> hoodieInstantOption = metaClient.getActiveTimeline().getCommitsTimeline()\n+        .filterCompletedInstants().lastInstant();\n+    try {\n+      if (hoodieInstantOption.isPresent() && hoodieInstantOption.get().getAction().equals(\n+          HoodieTimeline.REPLACE_COMMIT_ACTION)) {\n+        HoodieReplaceCommitMetadata replaceCommitMetadata = HoodieReplaceCommitMetadata\n+            .fromBytes(metaClient.getCommitTimeline().getInstantDetails(hoodieInstantOption.get()).get(), HoodieReplaceCommitMetadata.class);\n+        return Option.of(Pair.of(hoodieInstantOption.get(), replaceCommitMetadata.getExtraMetadata()));\n+      } else if (hoodieInstantOption.isPresent() && (hoodieInstantOption.get().getAction().equals(\n+          HoodieTimeline.DELTA_COMMIT_ACTION) || hoodieInstantOption.get().getAction().equals(HoodieTimeline.COMMIT_ACTION))) {\n+        HoodieCommitMetadata commitMetadata = HoodieCommitMetadata\n+            .fromBytes(metaClient.getCommitTimeline().getInstantDetails(hoodieInstantOption.get()).get(), HoodieCommitMetadata.class);\n+        return Option.of(Pair.of(hoodieInstantOption.get(), commitMetadata.getExtraMetadata()));\n+      } else {\n+        return Option.empty();\n+      }\n+    } catch (IOException io) {\n+      throw new HoodieIOException(\"Unable to read metadata for instant \" + hoodieInstantOption.get(), io);\n+    }\n+  }\n+\n+  private static void overrideWithLatestCommitMetadata(HoodieTableMetaClient metaClient, Option<HoodieCommitMetadata> thisMetadata,\n+      Option<HoodieInstant> thisInstant, List<String> keyPrefixes) {\n+    if (keyPrefixes.size() > 0) {\n+      Option<Pair<HoodieInstant, Map<String, String>>> lastInstant = getLastCompletedTxnInstantAndMetadata(metaClient);\n+      if (lastInstant.isPresent() && thisMetadata.isPresent()\n+          && HoodieTimeline.compareTimestamps(lastInstant.get().getLeft().getTimestamp(), HoodieTimeline.GREATER_THAN, thisInstant.get().getTimestamp())) {\n+        Stream<String> keys = thisMetadata.get().getExtraMetadata().keySet().stream();\n+        keyPrefixes.stream().forEach(keyPrefix -> keys\n+            .filter(key -> key.startsWith(keyPrefix))\n+            .forEach(key -> thisMetadata.get().getExtraMetadata().put(key, lastInstant.get().getRight().get(key))));\n+      }\n+    }\n+  }\n }\n\\ No newline at end of file\n", "next_change": {"commit": "01577fda0944e2cb710f0907965ca8e602650f8a", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\nindex cbd9eaa71..4301eaa1f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n", "chunk": "@@ -106,8 +106,7 @@ public class TransactionUtils {\n       Option<HoodieInstant> thisInstant, List<String> keyPrefixes) {\n     if (keyPrefixes.size() > 0) {\n       Option<Pair<HoodieInstant, Map<String, String>>> lastInstant = getLastCompletedTxnInstantAndMetadata(metaClient);\n-      if (lastInstant.isPresent() && thisMetadata.isPresent()\n-          && HoodieTimeline.compareTimestamps(lastInstant.get().getLeft().getTimestamp(), HoodieTimeline.GREATER_THAN, thisInstant.get().getTimestamp())) {\n+      if (lastInstant.isPresent() && thisMetadata.isPresent()) {\n         Stream<String> keys = thisMetadata.get().getExtraMetadata().keySet().stream();\n         keyPrefixes.stream().forEach(keyPrefix -> keys\n             .filter(key -> key.startsWith(keyPrefix))\n", "next_change": {"commit": "9278889bad4fe529a7c403857f20bcd0198322e6", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\nindex 4301eaa1f..56e028bb1 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n", "chunk": "@@ -104,14 +104,15 @@ public class TransactionUtils {\n \n   private static void overrideWithLatestCommitMetadata(HoodieTableMetaClient metaClient, Option<HoodieCommitMetadata> thisMetadata,\n       Option<HoodieInstant> thisInstant, List<String> keyPrefixes) {\n-    if (keyPrefixes.size() > 0) {\n-      Option<Pair<HoodieInstant, Map<String, String>>> lastInstant = getLastCompletedTxnInstantAndMetadata(metaClient);\n-      if (lastInstant.isPresent() && thisMetadata.isPresent()) {\n-        Stream<String> keys = thisMetadata.get().getExtraMetadata().keySet().stream();\n-        keyPrefixes.stream().forEach(keyPrefix -> keys\n-            .filter(key -> key.startsWith(keyPrefix))\n-            .forEach(key -> thisMetadata.get().getExtraMetadata().put(key, lastInstant.get().getRight().get(key))));\n-      }\n+    if (keyPrefixes.size() == 1 && keyPrefixes.get(0).length() < 1) {\n+      return;\n+    }\n+    Option<Pair<HoodieInstant, Map<String, String>>> lastInstant = getLastCompletedTxnInstantAndMetadata(metaClient);\n+    if (lastInstant.isPresent() && thisMetadata.isPresent()) {\n+      Stream<String> keys = thisMetadata.get().getExtraMetadata().keySet().stream();\n+      keyPrefixes.stream().forEach(keyPrefix -> keys\n+          .filter(key -> key.startsWith(keyPrefix))\n+          .forEach(key -> thisMetadata.get().getExtraMetadata().put(key, lastInstant.get().getRight().get(key))));\n     }\n   }\n }\n\\ No newline at end of file\n", "next_change": {"commit": "461047d03e9b7b73b34536ccf290a24f4aada6b0", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\nindex 56e028bb1..d4ba4fb0d 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n", "chunk": "@@ -72,47 +64,8 @@ public class TransactionUtils {\n         }\n       });\n       LOG.info(\"Successfully resolved conflicts, if any\");\n-      // carry over necessary metadata from latest commit metadata\n-      overrideWithLatestCommitMetadata(table.getMetaClient(), thisOperation.getCommitMetadataOption(), currentTxnOwnerInstant, Arrays.asList(config.getWriteMetaKeyPrefixes().split(\",\")));\n       return thisOperation.getCommitMetadataOption();\n     }\n     return thisCommitMetadata;\n   }\n-\n-  public static Option<Pair<HoodieInstant, Map<String, String>>> getLastCompletedTxnInstantAndMetadata(\n-      HoodieTableMetaClient metaClient) {\n-    Option<HoodieInstant> hoodieInstantOption = metaClient.getActiveTimeline().getCommitsTimeline()\n-        .filterCompletedInstants().lastInstant();\n-    try {\n-      if (hoodieInstantOption.isPresent() && hoodieInstantOption.get().getAction().equals(\n-          HoodieTimeline.REPLACE_COMMIT_ACTION)) {\n-        HoodieReplaceCommitMetadata replaceCommitMetadata = HoodieReplaceCommitMetadata\n-            .fromBytes(metaClient.getCommitTimeline().getInstantDetails(hoodieInstantOption.get()).get(), HoodieReplaceCommitMetadata.class);\n-        return Option.of(Pair.of(hoodieInstantOption.get(), replaceCommitMetadata.getExtraMetadata()));\n-      } else if (hoodieInstantOption.isPresent() && (hoodieInstantOption.get().getAction().equals(\n-          HoodieTimeline.DELTA_COMMIT_ACTION) || hoodieInstantOption.get().getAction().equals(HoodieTimeline.COMMIT_ACTION))) {\n-        HoodieCommitMetadata commitMetadata = HoodieCommitMetadata\n-            .fromBytes(metaClient.getCommitTimeline().getInstantDetails(hoodieInstantOption.get()).get(), HoodieCommitMetadata.class);\n-        return Option.of(Pair.of(hoodieInstantOption.get(), commitMetadata.getExtraMetadata()));\n-      } else {\n-        return Option.empty();\n-      }\n-    } catch (IOException io) {\n-      throw new HoodieIOException(\"Unable to read metadata for instant \" + hoodieInstantOption.get(), io);\n-    }\n-  }\n-\n-  private static void overrideWithLatestCommitMetadata(HoodieTableMetaClient metaClient, Option<HoodieCommitMetadata> thisMetadata,\n-      Option<HoodieInstant> thisInstant, List<String> keyPrefixes) {\n-    if (keyPrefixes.size() == 1 && keyPrefixes.get(0).length() < 1) {\n-      return;\n-    }\n-    Option<Pair<HoodieInstant, Map<String, String>>> lastInstant = getLastCompletedTxnInstantAndMetadata(metaClient);\n-    if (lastInstant.isPresent() && thisMetadata.isPresent()) {\n-      Stream<String> keys = thisMetadata.get().getExtraMetadata().keySet().stream();\n-      keyPrefixes.stream().forEach(keyPrefix -> keys\n-          .filter(key -> key.startsWith(keyPrefix))\n-          .forEach(key -> thisMetadata.get().getExtraMetadata().put(key, lastInstant.get().getRight().get(key))));\n-    }\n-  }\n }\n\\ No newline at end of file\n", "next_change": {"commit": "a466320b7537bf2862df853344e80fbd0be6d16a", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\nindex d4ba4fb0d..56e028bb1 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n", "chunk": "@@ -64,8 +72,47 @@ public class TransactionUtils {\n         }\n       });\n       LOG.info(\"Successfully resolved conflicts, if any\");\n+      // carry over necessary metadata from latest commit metadata\n+      overrideWithLatestCommitMetadata(table.getMetaClient(), thisOperation.getCommitMetadataOption(), currentTxnOwnerInstant, Arrays.asList(config.getWriteMetaKeyPrefixes().split(\",\")));\n       return thisOperation.getCommitMetadataOption();\n     }\n     return thisCommitMetadata;\n   }\n+\n+  public static Option<Pair<HoodieInstant, Map<String, String>>> getLastCompletedTxnInstantAndMetadata(\n+      HoodieTableMetaClient metaClient) {\n+    Option<HoodieInstant> hoodieInstantOption = metaClient.getActiveTimeline().getCommitsTimeline()\n+        .filterCompletedInstants().lastInstant();\n+    try {\n+      if (hoodieInstantOption.isPresent() && hoodieInstantOption.get().getAction().equals(\n+          HoodieTimeline.REPLACE_COMMIT_ACTION)) {\n+        HoodieReplaceCommitMetadata replaceCommitMetadata = HoodieReplaceCommitMetadata\n+            .fromBytes(metaClient.getCommitTimeline().getInstantDetails(hoodieInstantOption.get()).get(), HoodieReplaceCommitMetadata.class);\n+        return Option.of(Pair.of(hoodieInstantOption.get(), replaceCommitMetadata.getExtraMetadata()));\n+      } else if (hoodieInstantOption.isPresent() && (hoodieInstantOption.get().getAction().equals(\n+          HoodieTimeline.DELTA_COMMIT_ACTION) || hoodieInstantOption.get().getAction().equals(HoodieTimeline.COMMIT_ACTION))) {\n+        HoodieCommitMetadata commitMetadata = HoodieCommitMetadata\n+            .fromBytes(metaClient.getCommitTimeline().getInstantDetails(hoodieInstantOption.get()).get(), HoodieCommitMetadata.class);\n+        return Option.of(Pair.of(hoodieInstantOption.get(), commitMetadata.getExtraMetadata()));\n+      } else {\n+        return Option.empty();\n+      }\n+    } catch (IOException io) {\n+      throw new HoodieIOException(\"Unable to read metadata for instant \" + hoodieInstantOption.get(), io);\n+    }\n+  }\n+\n+  private static void overrideWithLatestCommitMetadata(HoodieTableMetaClient metaClient, Option<HoodieCommitMetadata> thisMetadata,\n+      Option<HoodieInstant> thisInstant, List<String> keyPrefixes) {\n+    if (keyPrefixes.size() == 1 && keyPrefixes.get(0).length() < 1) {\n+      return;\n+    }\n+    Option<Pair<HoodieInstant, Map<String, String>>> lastInstant = getLastCompletedTxnInstantAndMetadata(metaClient);\n+    if (lastInstant.isPresent() && thisMetadata.isPresent()) {\n+      Stream<String> keys = thisMetadata.get().getExtraMetadata().keySet().stream();\n+      keyPrefixes.stream().forEach(keyPrefix -> keys\n+          .filter(key -> key.startsWith(keyPrefix))\n+          .forEach(key -> thisMetadata.get().getExtraMetadata().put(key, lastInstant.get().getRight().get(key))));\n+    }\n+  }\n }\n\\ No newline at end of file\n", "next_change": {"commit": "bcc0f5baddc3eefad510441865cbf40a44c9a719", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\nindex 56e028bb1..82a22494b 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n", "chunk": "@@ -79,21 +79,30 @@ public class TransactionUtils {\n     return thisCommitMetadata;\n   }\n \n+  /**\n+   * Get the last completed transaction hoodie instant and {@link HoodieCommitMetadata#getExtraMetadata()}.\n+   * @param metaClient\n+   * @return\n+   */\n   public static Option<Pair<HoodieInstant, Map<String, String>>> getLastCompletedTxnInstantAndMetadata(\n       HoodieTableMetaClient metaClient) {\n     Option<HoodieInstant> hoodieInstantOption = metaClient.getActiveTimeline().getCommitsTimeline()\n         .filterCompletedInstants().lastInstant();\n     try {\n-      if (hoodieInstantOption.isPresent() && hoodieInstantOption.get().getAction().equals(\n-          HoodieTimeline.REPLACE_COMMIT_ACTION)) {\n-        HoodieReplaceCommitMetadata replaceCommitMetadata = HoodieReplaceCommitMetadata\n-            .fromBytes(metaClient.getCommitTimeline().getInstantDetails(hoodieInstantOption.get()).get(), HoodieReplaceCommitMetadata.class);\n-        return Option.of(Pair.of(hoodieInstantOption.get(), replaceCommitMetadata.getExtraMetadata()));\n-      } else if (hoodieInstantOption.isPresent() && (hoodieInstantOption.get().getAction().equals(\n-          HoodieTimeline.DELTA_COMMIT_ACTION) || hoodieInstantOption.get().getAction().equals(HoodieTimeline.COMMIT_ACTION))) {\n-        HoodieCommitMetadata commitMetadata = HoodieCommitMetadata\n-            .fromBytes(metaClient.getCommitTimeline().getInstantDetails(hoodieInstantOption.get()).get(), HoodieCommitMetadata.class);\n-        return Option.of(Pair.of(hoodieInstantOption.get(), commitMetadata.getExtraMetadata()));\n+      if (hoodieInstantOption.isPresent()) {\n+        switch (hoodieInstantOption.get().getAction()) {\n+          case HoodieTimeline.REPLACE_COMMIT_ACTION:\n+            HoodieReplaceCommitMetadata replaceCommitMetadata = HoodieReplaceCommitMetadata\n+            .fromBytes(metaClient.getActiveTimeline().getInstantDetails(hoodieInstantOption.get()).get(), HoodieReplaceCommitMetadata.class);\n+            return Option.of(Pair.of(hoodieInstantOption.get(), replaceCommitMetadata.getExtraMetadata()));\n+          case HoodieTimeline.DELTA_COMMIT_ACTION:\n+          case HoodieTimeline.COMMIT_ACTION:\n+            HoodieCommitMetadata commitMetadata = HoodieCommitMetadata\n+            .fromBytes(metaClient.getActiveTimeline().getInstantDetails(hoodieInstantOption.get()).get(), HoodieCommitMetadata.class);\n+            return Option.of(Pair.of(hoodieInstantOption.get(), commitMetadata.getExtraMetadata()));\n+          default:\n+            throw new IllegalArgumentException(\"Unknown instant action\" + hoodieInstantOption.get().getAction());\n+        }\n       } else {\n         return Option.empty();\n       }\n", "next_change": {"commit": "0e7fbb3ab8c02fbaee04adfc89205d6bee0834ab", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\nindex 82a22494b..80a412010 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n", "chunk": "@@ -93,12 +93,12 @@ public class TransactionUtils {\n         switch (hoodieInstantOption.get().getAction()) {\n           case HoodieTimeline.REPLACE_COMMIT_ACTION:\n             HoodieReplaceCommitMetadata replaceCommitMetadata = HoodieReplaceCommitMetadata\n-            .fromBytes(metaClient.getActiveTimeline().getInstantDetails(hoodieInstantOption.get()).get(), HoodieReplaceCommitMetadata.class);\n+                .fromBytes(metaClient.getActiveTimeline().getInstantDetails(hoodieInstantOption.get()).get(), HoodieReplaceCommitMetadata.class);\n             return Option.of(Pair.of(hoodieInstantOption.get(), replaceCommitMetadata.getExtraMetadata()));\n           case HoodieTimeline.DELTA_COMMIT_ACTION:\n           case HoodieTimeline.COMMIT_ACTION:\n             HoodieCommitMetadata commitMetadata = HoodieCommitMetadata\n-            .fromBytes(metaClient.getActiveTimeline().getInstantDetails(hoodieInstantOption.get()).get(), HoodieCommitMetadata.class);\n+                .fromBytes(metaClient.getActiveTimeline().getInstantDetails(hoodieInstantOption.get()).get(), HoodieCommitMetadata.class);\n             return Option.of(Pair.of(hoodieInstantOption.get(), commitMetadata.getExtraMetadata()));\n           default:\n             throw new IllegalArgumentException(\"Unknown instant action\" + hoodieInstantOption.get().getAction());\n", "next_change": null}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\nindex 56e028bb1..82a22494b 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/utils/TransactionUtils.java\n", "chunk": "@@ -102,6 +111,7 @@ public class TransactionUtils {\n     }\n   }\n \n+  // override the current metadata with the metadata from the latest instant for the specified key prefixes\n   private static void overrideWithLatestCommitMetadata(HoodieTableMetaClient metaClient, Option<HoodieCommitMetadata> thisMetadata,\n       Option<HoodieInstant> thisInstant, List<String> keyPrefixes) {\n     if (keyPrefixes.size() == 1 && keyPrefixes.get(0).length() < 1) {\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyNTgxNw==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587725817", "bodyText": "should there be a single property? i.e hoodie.clean.async= false does imply hoodie.clean.inline=true right?", "author": "vinothchandar", "createdAt": "2021-03-04T18:45:06Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieCompactionConfig.java", "diffHunk": "@@ -43,7 +43,8 @@\n   public static final String CLEANER_POLICY_PROP = \"hoodie.cleaner.policy\";\n   public static final String AUTO_CLEAN_PROP = \"hoodie.clean.automatic\";\n   public static final String ASYNC_CLEAN_PROP = \"hoodie.clean.async\";\n-\n+  // Turn on inline cleaning\n+  public static final String INLINE_CLEAN_PROP = \"hoodie.clean.inline\";", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODE0MDYzMg==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588140632", "bodyText": "I was trying to keep the same concepts of inline for clustering, compact. The problem is there are autoClean & autoCommit but no autoCompact or autoCluster etc. Additionally, we used inline as the flag to toggle between inline & async for compact & cluster while we have chosen async as the flag for clean.\nI have removed hoodie.clean.inline. We can address these in another PR after we decide what convention to follow.", "author": "n3nash", "createdAt": "2021-03-05T09:10:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyNTgxNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODY4NDQxMw==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588684413", "bodyText": "sure. the idea is to not proliferate, since it then becomes one more config to take care of.", "author": "vinothchandar", "createdAt": "2021-03-05T20:42:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyNTgxNw=="}], "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieCompactionConfig.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieCompactionConfig.java\nindex ff11540c7..43af00a13 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieCompactionConfig.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieCompactionConfig.java\n", "chunk": "@@ -43,8 +43,6 @@ public class HoodieCompactionConfig extends DefaultHoodieConfig {\n   public static final String CLEANER_POLICY_PROP = \"hoodie.cleaner.policy\";\n   public static final String AUTO_CLEAN_PROP = \"hoodie.clean.automatic\";\n   public static final String ASYNC_CLEAN_PROP = \"hoodie.clean.async\";\n-  // Turn on inline cleaning\n-  public static final String INLINE_CLEAN_PROP = \"hoodie.clean.inline\";\n   // Turn on inline compaction - after fw delta commits a inline compaction will be run\n   public static final String INLINE_COMPACT_PROP = \"hoodie.compact.inline\";\n   // Run a compaction every N delta commits\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyNjUwNw==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587726507", "bodyText": "auto clean is different from the cleaning mode itself. lets just have an assignment to the hardcoded string \"true\"?", "author": "vinothchandar", "createdAt": "2021-03-04T18:46:01Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieCompactionConfig.java", "diffHunk": "@@ -114,6 +115,7 @@\n       HoodieFailedWritesCleaningPolicy.EAGER.name();\n   private static final String DEFAULT_AUTO_CLEAN = \"true\";\n   private static final String DEFAULT_ASYNC_CLEAN = \"false\";\n+  private static final String DEFAULT_INLINE_CLEAN = DEFAULT_AUTO_CLEAN;", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODA0NTA4OQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588045089", "bodyText": "done", "author": "n3nash", "createdAt": "2021-03-05T05:38:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyNjUwNw=="}], "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieCompactionConfig.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieCompactionConfig.java\nindex ff11540c7..43af00a13 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieCompactionConfig.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieCompactionConfig.java\n", "chunk": "@@ -115,7 +113,6 @@ public class HoodieCompactionConfig extends DefaultHoodieConfig {\n       HoodieFailedWritesCleaningPolicy.EAGER.name();\n   private static final String DEFAULT_AUTO_CLEAN = \"true\";\n   private static final String DEFAULT_ASYNC_CLEAN = \"false\";\n-  private static final String DEFAULT_INLINE_CLEAN = DEFAULT_AUTO_CLEAN;\n   private static final String DEFAULT_INLINE_COMPACT = \"false\";\n   private static final String DEFAULT_INCREMENTAL_CLEANER = \"true\";\n   private static final String DEFAULT_INLINE_COMPACT_NUM_DELTA_COMMITS = \"5\";\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyNzk0Ng==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587727946", "bodyText": "are these ever used in hudi-common? if we don't anticipate readers using this. we should just keep all this in hudi-client-common under a transaction package", "author": "vinothchandar", "createdAt": "2021-03-04T18:48:07Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java", "diffHunk": "@@ -0,0 +1,191 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.config;\n+\n+import org.apache.hudi.client.lock.SimpleConcurrentFileWritesConflictResolutionStrategy;\n+import org.apache.hudi.client.lock.ConflictResolutionStrategy;\n+import org.apache.hudi.client.lock.ZookeeperBasedLockProvider;\n+import org.apache.hudi.common.config.DefaultHoodieConfig;\n+import org.apache.hudi.common.lock.LockProvider;\n+\n+import java.io.File;\n+import java.io.FileReader;\n+import java.io.IOException;\n+import java.util.Properties;\n+\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ACQUIRE_LOCK_WAIT_TIMEOUT_MS;", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzgzMDk5OA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587830998", "bodyText": "These configs are cross used for HiveMetastoreLockProvider which does not depend on hudi-client-common. Hence these are in hudi-common", "author": "n3nash", "createdAt": "2021-03-04T21:15:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyNzk0Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODY4NTg2Mw==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588685863", "bodyText": "But, could you explain why even HiveMetastoreLockProvider that has to be in hudi-common? That was my main point. We will be needlessly increasing the weight of hudi-common, which is picked up by hudi-hadoop-mr for e.g.", "author": "vinothchandar", "createdAt": "2021-03-05T20:43:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyNzk0Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODkxODM1Mw==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588918353", "bodyText": "HiveMetastoreLockProvider has always been in hudi-hive-sync package. Only the LockConfiguration is in hudi-common since that is shared across hudi-hive-sync and hudi-client-common", "author": "n3nash", "createdAt": "2021-03-06T19:04:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyNzk0Ng=="}], "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\nindex 4ddf149f3..1f0328e2f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\n", "chunk": "@@ -17,9 +17,9 @@\n \n package org.apache.hudi.config;\n \n-import org.apache.hudi.client.lock.SimpleConcurrentFileWritesConflictResolutionStrategy;\n-import org.apache.hudi.client.lock.ConflictResolutionStrategy;\n-import org.apache.hudi.client.lock.ZookeeperBasedLockProvider;\n+import org.apache.hudi.client.transaction.SimpleConcurrentFileWritesConflictResolutionStrategy;\n+import org.apache.hudi.client.transaction.ConflictResolutionStrategy;\n+import org.apache.hudi.client.transaction.lock.ZookeeperBasedLockProvider;\n import org.apache.hudi.common.config.DefaultHoodieConfig;\n import org.apache.hudi.common.lock.LockProvider;\n \n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyOTI1Mg==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587729252", "bodyText": "given we have had some typo related issues recently, please check each line once for correctness", "author": "vinothchandar", "createdAt": "2021-03-04T18:50:08Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java", "diffHunk": "@@ -0,0 +1,191 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.config;\n+\n+import org.apache.hudi.client.lock.SimpleConcurrentFileWritesConflictResolutionStrategy;\n+import org.apache.hudi.client.lock.ConflictResolutionStrategy;\n+import org.apache.hudi.client.lock.ZookeeperBasedLockProvider;\n+import org.apache.hudi.common.config.DefaultHoodieConfig;\n+import org.apache.hudi.common.lock.LockProvider;\n+\n+import java.io.File;\n+import java.io.FileReader;\n+import java.io.IOException;\n+import java.util.Properties;\n+\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ACQUIRE_LOCK_WAIT_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_LOCK_ACQUIRE_CLIENT_NUM_RETRIES;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_LOCK_ACQUIRE_CLIENT_RETRY_WAIT_TIME_IN_MILLIS;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_LOCK_ACQUIRE_NUM_RETRIES;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_CONNECTION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_SESSION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.HIVE_DATABASE_NAME_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.HIVE_TABLE_NAME_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_CLIENT_NUM_RETRIES_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_CLIENT_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_NUM_RETRIES_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_WAIT_TIMEOUT_MS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_PREFIX;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_BASE_PATH_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECTION_TIMEOUT_MS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECT_URL_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_LOCK_KEY_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_PORT_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_SESSION_TIMEOUT_MS_PROP;\n+\n+\n+/**\n+ * Hoodie Configs for Locks.\n+ */\n+public class HoodieLockConfig extends DefaultHoodieConfig {\n+\n+  // Pluggable type of lock provider\n+  public static final String LOCK_PROVIDER_CLASS_PROP = LOCK_PREFIX + \"provider\";\n+  public static final String DEFAULT_LOCK_PROVIDER_CLASS = ZookeeperBasedLockProvider.class.getName();\n+  // Pluggable strategies to use when resolving conflicts\n+  public static final String WRITE_CONFLICT_RESOLUTION_STRATEGY_CLASS_PROP =\n+      LOCK_PREFIX + \"conflict.resolution.strategy\";\n+  public static final String DEFAULT_WRITE_CONFLICT_RESOLUTION_STRATEGY_CLASS =\n+      SimpleConcurrentFileWritesConflictResolutionStrategy.class.getName();\n+\n+  private HoodieLockConfig(Properties props) {\n+    super(props);\n+  }\n+\n+  public static HoodieLockConfig.Builder newBuilder() {\n+    return new HoodieLockConfig.Builder();\n+  }\n+\n+  public static class Builder {\n+\n+    private final Properties props = new Properties();\n+\n+    public HoodieLockConfig.Builder fromFile(File propertiesFile) throws IOException {\n+      try (FileReader reader = new FileReader(propertiesFile)) {\n+        this.props.load(reader);\n+        return this;\n+      }\n+    }\n+\n+    public HoodieLockConfig.Builder fromProperties(Properties props) {\n+      this.props.putAll(props);\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withLockProvider(Class<? extends LockProvider> lockProvider) {\n+      props.setProperty(LOCK_PROVIDER_CLASS_PROP, lockProvider.getName());\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withHiveDatabaseName(String databaseName) {\n+      props.setProperty(HIVE_DATABASE_NAME_PROP, databaseName);\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withHiveTableName(String tableName) {\n+      props.setProperty(HIVE_TABLE_NAME_PROP, tableName);\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withZkQuorum(String zkQuorum) {\n+      props.setProperty(ZK_CONNECT_URL_PROP, zkQuorum);\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withZkBasePath(String zkBasePath) {\n+      props.setProperty(ZK_BASE_PATH_PROP, zkBasePath);\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withZkPort(String zkPort) {\n+      props.setProperty(ZK_PORT_PROP, zkPort);\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withZkLockKey(String zkLockKey) {\n+      props.setProperty(ZK_LOCK_KEY_PROP, zkLockKey);\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withZkConnectionTimeoutInMs(Long connectionTimeoutInMs) {\n+      props.setProperty(ZK_CONNECTION_TIMEOUT_MS_PROP, String.valueOf(connectionTimeoutInMs));\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withZkSessionTimeoutInMs(Long sessionTimeoutInMs) {\n+      props.setProperty(ZK_SESSION_TIMEOUT_MS_PROP, String.valueOf(sessionTimeoutInMs));\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withNumRetries(int numRetries) {\n+      props.setProperty(LOCK_ACQUIRE_NUM_RETRIES_PROP, String.valueOf(numRetries));\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withRetryWaitTimeInMillis(Long retryWaitTimeInMillis) {\n+      props.setProperty(LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP, String.valueOf(retryWaitTimeInMillis));\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withClientNumRetries(int clientNumRetries) {\n+      props.setProperty(LOCK_ACQUIRE_CLIENT_NUM_RETRIES_PROP, String.valueOf(clientNumRetries));\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withClientRetryWaitTimeInMillis(Long clientRetryWaitTimeInMillis) {\n+      props.setProperty(LOCK_ACQUIRE_CLIENT_RETRY_WAIT_TIME_IN_MILLIS_PROP, String.valueOf(clientRetryWaitTimeInMillis));\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withLockWaitTimeInMillis(Long waitTimeInMillis) {\n+      props.setProperty(LOCK_ACQUIRE_WAIT_TIMEOUT_MS_PROP, String.valueOf(waitTimeInMillis));\n+      return this;\n+    }\n+\n+    public HoodieLockConfig.Builder withConflictResolutionStrategy(ConflictResolutionStrategy conflictResolutionStrategy) {\n+      props.setProperty(WRITE_CONFLICT_RESOLUTION_STRATEGY_CLASS_PROP, conflictResolutionStrategy.getClass().getName());\n+      return this;\n+    }\n+\n+    public HoodieLockConfig build() {", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODA0NDcxMg==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588044712", "bodyText": "checked", "author": "n3nash", "createdAt": "2021-03-05T05:37:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzcyOTI1Mg=="}], "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\nindex 4ddf149f3..1f0328e2f 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/config/HoodieLockConfig.java\n", "chunk": "@@ -17,9 +17,9 @@\n \n package org.apache.hudi.config;\n \n-import org.apache.hudi.client.lock.SimpleConcurrentFileWritesConflictResolutionStrategy;\n-import org.apache.hudi.client.lock.ConflictResolutionStrategy;\n-import org.apache.hudi.client.lock.ZookeeperBasedLockProvider;\n+import org.apache.hudi.client.transaction.SimpleConcurrentFileWritesConflictResolutionStrategy;\n+import org.apache.hudi.client.transaction.ConflictResolutionStrategy;\n+import org.apache.hudi.client.transaction.lock.ZookeeperBasedLockProvider;\n import org.apache.hudi.common.config.DefaultHoodieConfig;\n import org.apache.hudi.common.lock.LockProvider;\n \n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzczMTc1Mw==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587731753", "bodyText": "I don't understand why we just pick the last cleaned metadata. Lets do the generically right thing. If you want to handle more than more cleaning operation, lets return a list?", "author": "vinothchandar", "createdAt": "2021-03-04T18:54:00Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/clean/BaseCleanActionExecutor.java", "diffHunk": "@@ -195,30 +126,24 @@ private HoodieCleanMetadata runClean(HoodieTable<T, I, K, O> table, HoodieInstan\n \n   @Override\n   public HoodieCleanMetadata execute() {\n+    List<HoodieCleanMetadata> cleanMetadataList = new ArrayList<>();\n     // If there are inflight(failed) or previously requested clean operation, first perform them\n     List<HoodieInstant> pendingCleanInstants = table.getCleanTimeline()\n         .filterInflightsAndRequested().getInstants().collect(Collectors.toList());\n     if (pendingCleanInstants.size() > 0) {\n       pendingCleanInstants.forEach(hoodieInstant -> {\n         LOG.info(\"Finishing previously unfinished cleaner instant=\" + hoodieInstant);\n         try {\n-          runPendingClean(table, hoodieInstant);\n+          cleanMetadataList.add(runPendingClean(table, hoodieInstant));\n         } catch (Exception e) {\n           LOG.warn(\"Failed to perform previous clean operation, instant: \" + hoodieInstant, e);\n         }\n       });\n       table.getMetaClient().reloadActiveTimeline();\n     }\n-\n-    // Plan and execute a new clean action\n-    Option<HoodieCleanerPlan> cleanerPlanOpt = requestClean(instantTime);\n-    if (cleanerPlanOpt.isPresent()) {\n-      table.getMetaClient().reloadActiveTimeline();\n-      HoodieCleanerPlan cleanerPlan = cleanerPlanOpt.get();\n-      if ((cleanerPlan.getFilePathsToBeDeletedPerPartition() != null) && !cleanerPlan.getFilePathsToBeDeletedPerPartition().isEmpty()) {\n-        return runClean(table, HoodieTimeline.getCleanRequestedInstant(instantTime), cleanerPlan);\n-      }\n-    }\n-    return null;\n+    // return the last clean metadata for now\n+    // TODO (NA) : Clean only the earliest pending clean just like how we do for other table services", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzczMTk2OA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587731968", "bodyText": "Won't this for e.g mess up the metadata table? by missing some deletes?", "author": "vinothchandar", "createdAt": "2021-03-04T18:54:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzczMTc1Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODAwNTUwMQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588005501", "bodyText": "Currently, the clean metadata from runPendingClean is never returned if you see above in line 205. The current logic is as follows\n\nFor all pending clean operations, we just return null.\nIf there is new clean to be done, we do the new clean and return the metadata.\n\nClean metadata is always persisted before this method inside the runClean method and the return value of this method is NOT used by the client.\nI made above changes to reuse the same methods and  to keep the same behavior, except with one change :\n\nFor all pending clean operations, we return the latest pending clean from previous runs.\nIf there is new clean to be done, we do the new clean and return the metadata.\n\nOther logic remains the same. The returned metadata is ONLY used for a) Logging b) Metrics.\nLet's refactor all these issues in the ActionExecutor in follow up PR. Filed issue here -> https://issues.apache.org/jira/browse/HUDI-1666", "author": "n3nash", "createdAt": "2021-03-05T03:26:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzczMTc1Mw=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzczMzI2NQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587733265", "bodyText": "I assume, this is all just code moved from the other class. if not , please point out what has changed", "author": "vinothchandar", "createdAt": "2021-03-04T18:56:11Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/clean/BaseCleanPlanActionExecutor.java", "diffHunk": "@@ -0,0 +1,132 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.table.action.clean;\n+\n+import org.apache.hudi.avro.model.HoodieActionInstant;\n+import org.apache.hudi.avro.model.HoodieCleanFileInfo;\n+import org.apache.hudi.avro.model.HoodieCleanerPlan;\n+import org.apache.hudi.common.engine.HoodieEngineContext;\n+import org.apache.hudi.common.model.HoodieCleaningPolicy;\n+import org.apache.hudi.common.model.HoodieRecordPayload;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.table.timeline.HoodieTimeline;\n+import org.apache.hudi.common.table.timeline.TimelineMetadataUtils;\n+import org.apache.hudi.common.util.CleanerUtils;\n+import org.apache.hudi.common.util.CollectionUtils;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.common.util.collection.Pair;\n+import org.apache.hudi.config.HoodieWriteConfig;\n+import org.apache.hudi.exception.HoodieIOException;\n+import org.apache.hudi.table.HoodieTable;\n+import org.apache.hudi.table.action.BaseActionExecutor;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+public abstract class BaseCleanPlanActionExecutor<T extends HoodieRecordPayload, I, K, O> extends BaseActionExecutor<T, I, K, O, Option<HoodieCleanerPlan>> {\n+\n+  private static final Logger LOG = LogManager.getLogger(CleanPlanner.class);\n+\n+  private final Option<Map<String, String>> extraMetadata;\n+\n+  public BaseCleanPlanActionExecutor(HoodieEngineContext context,\n+                                     HoodieWriteConfig config,\n+                                     HoodieTable<T, I, K, O> table,\n+                                     String instantTime,\n+                                     Option<Map<String, String>> extraMetadata) {\n+    super(context, config, table, instantTime);\n+    this.extraMetadata = extraMetadata;\n+  }\n+\n+  protected abstract Option<HoodieCleanerPlan> createCleanerPlan();\n+\n+  /**\n+   * Generates List of files to be cleaned.\n+   *\n+   * @param context HoodieEngineContext\n+   * @return Cleaner Plan\n+   */\n+  HoodieCleanerPlan requestClean(HoodieEngineContext context) {", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzgzMTQzNA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587831434", "bodyText": "Yes, no change.", "author": "n3nash", "createdAt": "2021-03-04T21:16:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzczMzI2NQ=="}], "type": "inlineReview", "revised_code": {"commit": "4dd32416d378254600bd1a810ed6dc0c2dbec2b6", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/clean/BaseCleanPlanActionExecutor.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/clean/BaseCleanPlanActionExecutor.java\nindex 811f02f72..fc0c000a6 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/clean/BaseCleanPlanActionExecutor.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/clean/BaseCleanPlanActionExecutor.java\n", "chunk": "@@ -125,7 +125,7 @@ public abstract class BaseCleanPlanActionExecutor<T extends HoodieRecordPayload,\n \n   @Override\n   public Option<HoodieCleanerPlan> execute() {\n-    // Plan and execute a new clean action\n+    // Plan a new clean action\n     return requestClean(instantTime);\n   }\n \n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzczMzY0Mw==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587733643", "bodyText": "lets create a code cleanup JIRA for this. else we may not get to this.", "author": "vinothchandar", "createdAt": "2021-03-04T18:56:50Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java", "diffHunk": "@@ -66,6 +70,11 @@ public BaseCommitActionExecutor(HoodieEngineContext context, HoodieWriteConfig c\n     this.operationType = operationType;\n     this.extraMetadata = extraMetadata;\n     this.taskContextSupplier = context.getTaskContextSupplier();\n+    this.txnManager = new TransactionManager(config, table.getMetaClient().getFs());\n+    // TODO : Remove this once we refactor and move out autoCommit method from here, since the TxnManager is held in {@link AbstractHoodieWriteClient}.", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODAwMDU5MA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588000590", "bodyText": "https://issues.apache.org/jira/browse/HUDI-1665", "author": "n3nash", "createdAt": "2021-03-05T03:09:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzczMzY0Mw=="}], "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java\nindex 26d512f67..492875441 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java\n", "chunk": "@@ -72,9 +72,6 @@ public abstract class BaseCommitActionExecutor<T extends HoodieRecordPayload, I,\n     this.taskContextSupplier = context.getTaskContextSupplier();\n     this.txnManager = new TransactionManager(config, table.getMetaClient().getFs());\n     // TODO : Remove this once we refactor and move out autoCommit method from here, since the TxnManager is held in {@link AbstractHoodieWriteClient}.\n-    this.txnManager.setLastCompletedTransaction(table.getActiveTimeline().getCommitsTimeline().filterCompletedInstants()\n-        .lastInstant());\n-    this.txnManager.setTransactionOwner(Option.of(new HoodieInstant(State.INFLIGHT, HoodieTimeline.COMMIT_ACTION, instantTime)));\n   }\n \n   public abstract HoodieWriteMetadata<O> execute(I inputRecords);\n", "next_change": {"commit": "1b522ef9c2fec7a32c7a1bfae2039e8f07a60d8f", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java\nindex 492875441..4c908ae79 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java\n", "chunk": "@@ -70,8 +71,10 @@ public abstract class BaseCommitActionExecutor<T extends HoodieRecordPayload, I,\n     this.operationType = operationType;\n     this.extraMetadata = extraMetadata;\n     this.taskContextSupplier = context.getTaskContextSupplier();\n-    this.txnManager = new TransactionManager(config, table.getMetaClient().getFs());\n     // TODO : Remove this once we refactor and move out autoCommit method from here, since the TxnManager is held in {@link AbstractHoodieWriteClient}.\n+    this.txnManager = new TransactionManager(config, table.getMetaClient().getFs());\n+    this.lastCompletedTxn = table.getActiveTimeline().getCommitsTimeline().filterCompletedInstants()\n+        .lastInstant();\n   }\n \n   public abstract HoodieWriteMetadata<O> execute(I inputRecords);\n", "next_change": {"commit": "1886bbd803f1a51e3d261705dd1283cfa8caf06b", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java\nindex 4c908ae79..16638fd95 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java\n", "chunk": "@@ -73,8 +74,7 @@ public abstract class BaseCommitActionExecutor<T extends HoodieRecordPayload, I,\n     this.taskContextSupplier = context.getTaskContextSupplier();\n     // TODO : Remove this once we refactor and move out autoCommit method from here, since the TxnManager is held in {@link AbstractHoodieWriteClient}.\n     this.txnManager = new TransactionManager(config, table.getMetaClient().getFs());\n-    this.lastCompletedTxn = table.getActiveTimeline().getCommitsTimeline().filterCompletedInstants()\n-        .lastInstant();\n+    this.lastCompletedTxn = TransactionUtils.getLastCompletedTxnInstantAndMetadata(table.getMetaClient());\n   }\n \n   public abstract HoodieWriteMetadata<O> execute(I inputRecords);\n", "next_change": {"commit": "461047d03e9b7b73b34536ccf290a24f4aada6b0", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java\nindex 16638fd95..ffb403b21 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java\n", "chunk": "@@ -74,7 +73,8 @@ public abstract class BaseCommitActionExecutor<T extends HoodieRecordPayload, I,\n     this.taskContextSupplier = context.getTaskContextSupplier();\n     // TODO : Remove this once we refactor and move out autoCommit method from here, since the TxnManager is held in {@link AbstractHoodieWriteClient}.\n     this.txnManager = new TransactionManager(config, table.getMetaClient().getFs());\n-    this.lastCompletedTxn = TransactionUtils.getLastCompletedTxnInstantAndMetadata(table.getMetaClient());\n+    this.lastCompletedTxn = table.getActiveTimeline().getCommitsTimeline().filterCompletedInstants()\n+        .lastInstant();\n   }\n \n   public abstract HoodieWriteMetadata<O> execute(I inputRecords);\n", "next_change": {"commit": "a466320b7537bf2862df853344e80fbd0be6d16a", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java\nindex ffb403b21..16638fd95 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java\n", "chunk": "@@ -73,8 +74,7 @@ public abstract class BaseCommitActionExecutor<T extends HoodieRecordPayload, I,\n     this.taskContextSupplier = context.getTaskContextSupplier();\n     // TODO : Remove this once we refactor and move out autoCommit method from here, since the TxnManager is held in {@link AbstractHoodieWriteClient}.\n     this.txnManager = new TransactionManager(config, table.getMetaClient().getFs());\n-    this.lastCompletedTxn = table.getActiveTimeline().getCommitsTimeline().filterCompletedInstants()\n-        .lastInstant();\n+    this.lastCompletedTxn = TransactionUtils.getLastCompletedTxnInstantAndMetadata(table.getMetaClient());\n   }\n \n   public abstract HoodieWriteMetadata<O> execute(I inputRecords);\n", "next_change": null}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzczNTY0MQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587735641", "bodyText": "revisit the todo?", "author": "vinothchandar", "createdAt": "2021-03-04T18:59:39Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java", "diffHunk": "@@ -117,12 +126,24 @@ protected String getCommitActionType() {\n   protected void commitOnAutoCommit(HoodieWriteMetadata result) {\n     if (config.shouldAutoCommit()) {\n       LOG.info(\"Auto commit enabled: Committing \" + instantTime);\n-      commit(extraMetadata, result);\n+      autoCommit(extraMetadata, result);\n     } else {\n       LOG.info(\"Auto commit disabled for \" + instantTime);\n     }\n   }\n \n+  protected void autoCommit(Option<Map<String, String>> extraMetadata, HoodieWriteMetadata<O> result) {\n+    this.txnManager.beginTransaction();\n+    try {\n+      // TODO : Refactor this method so we can pass a valid metadata table writer", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzgzMTg4Nw==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587831887", "bodyText": "Removed metadata writer for now.", "author": "n3nash", "createdAt": "2021-03-04T21:17:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzczNTY0MQ=="}], "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java\nindex 26d512f67..492875441 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java\n", "chunk": "@@ -133,9 +130,10 @@ public abstract class BaseCommitActionExecutor<T extends HoodieRecordPayload, I,\n   }\n \n   protected void autoCommit(Option<Map<String, String>> extraMetadata, HoodieWriteMetadata<O> result) {\n-    this.txnManager.beginTransaction();\n+    this.txnManager.beginTransaction(Option.of(new HoodieInstant(State.INFLIGHT, HoodieTimeline.COMMIT_ACTION, instantTime)),\n+        table.getActiveTimeline().getCommitsTimeline().filterCompletedInstants()\n+            .lastInstant());\n     try {\n-      // TODO : Refactor this method so we can pass a valid metadata table writer\n       TransactionUtils.resolveWriteConflictIfAny(table, Option.empty(), this.txnManager.getCurrentTransactionOwner(),\n           result.getCommitMetadata(), config, this.txnManager.getLastCompletedTransactionOwner());\n       commit(extraMetadata, result);\n", "next_change": {"commit": "1b522ef9c2fec7a32c7a1bfae2039e8f07a60d8f", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java\nindex 492875441..4c908ae79 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java\n", "chunk": "@@ -131,8 +134,7 @@ public abstract class BaseCommitActionExecutor<T extends HoodieRecordPayload, I,\n \n   protected void autoCommit(Option<Map<String, String>> extraMetadata, HoodieWriteMetadata<O> result) {\n     this.txnManager.beginTransaction(Option.of(new HoodieInstant(State.INFLIGHT, HoodieTimeline.COMMIT_ACTION, instantTime)),\n-        table.getActiveTimeline().getCommitsTimeline().filterCompletedInstants()\n-            .lastInstant());\n+        lastCompletedTxn);\n     try {\n       TransactionUtils.resolveWriteConflictIfAny(table, Option.empty(), this.txnManager.getCurrentTransactionOwner(),\n           result.getCommitMetadata(), config, this.txnManager.getLastCompletedTransactionOwner());\n", "next_change": {"commit": "02efbb661e7ed13c3614ddee7ab5157623070f7c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java\nindex 4c908ae79..ffb403b21 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java\n", "chunk": "@@ -136,7 +136,7 @@ public abstract class BaseCommitActionExecutor<T extends HoodieRecordPayload, I,\n     this.txnManager.beginTransaction(Option.of(new HoodieInstant(State.INFLIGHT, HoodieTimeline.COMMIT_ACTION, instantTime)),\n         lastCompletedTxn);\n     try {\n-      TransactionUtils.resolveWriteConflictIfAny(table, Option.empty(), this.txnManager.getCurrentTransactionOwner(),\n+      TransactionUtils.resolveWriteConflictIfAny(table, this.txnManager.getCurrentTransactionOwner(),\n           result.getCommitMetadata(), config, this.txnManager.getLastCompletedTransactionOwner());\n       commit(extraMetadata, result);\n     } finally {\n", "next_change": {"commit": "1886bbd803f1a51e3d261705dd1283cfa8caf06b", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java\nindex ffb403b21..16638fd95 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java\n", "chunk": "@@ -134,7 +134,7 @@ public abstract class BaseCommitActionExecutor<T extends HoodieRecordPayload, I,\n \n   protected void autoCommit(Option<Map<String, String>> extraMetadata, HoodieWriteMetadata<O> result) {\n     this.txnManager.beginTransaction(Option.of(new HoodieInstant(State.INFLIGHT, HoodieTimeline.COMMIT_ACTION, instantTime)),\n-        lastCompletedTxn);\n+        lastCompletedTxn.isPresent() ? Option.of(lastCompletedTxn.get().getLeft()) : Option.empty());\n     try {\n       TransactionUtils.resolveWriteConflictIfAny(table, this.txnManager.getCurrentTransactionOwner(),\n           result.getCommitMetadata(), config, this.txnManager.getLastCompletedTransactionOwner());\n", "next_change": {"commit": "461047d03e9b7b73b34536ccf290a24f4aada6b0", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java\nindex 16638fd95..ffb403b21 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java\n", "chunk": "@@ -134,7 +134,7 @@ public abstract class BaseCommitActionExecutor<T extends HoodieRecordPayload, I,\n \n   protected void autoCommit(Option<Map<String, String>> extraMetadata, HoodieWriteMetadata<O> result) {\n     this.txnManager.beginTransaction(Option.of(new HoodieInstant(State.INFLIGHT, HoodieTimeline.COMMIT_ACTION, instantTime)),\n-        lastCompletedTxn.isPresent() ? Option.of(lastCompletedTxn.get().getLeft()) : Option.empty());\n+        lastCompletedTxn);\n     try {\n       TransactionUtils.resolveWriteConflictIfAny(table, this.txnManager.getCurrentTransactionOwner(),\n           result.getCommitMetadata(), config, this.txnManager.getLastCompletedTransactionOwner());\n", "next_change": {"commit": "a466320b7537bf2862df853344e80fbd0be6d16a", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java\nindex ffb403b21..16638fd95 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/table/action/commit/BaseCommitActionExecutor.java\n", "chunk": "@@ -134,7 +134,7 @@ public abstract class BaseCommitActionExecutor<T extends HoodieRecordPayload, I,\n \n   protected void autoCommit(Option<Map<String, String>> extraMetadata, HoodieWriteMetadata<O> result) {\n     this.txnManager.beginTransaction(Option.of(new HoodieInstant(State.INFLIGHT, HoodieTimeline.COMMIT_ACTION, instantTime)),\n-        lastCompletedTxn);\n+        lastCompletedTxn.isPresent() ? Option.of(lastCompletedTxn.get().getLeft()) : Option.empty());\n     try {\n       TransactionUtils.resolveWriteConflictIfAny(table, this.txnManager.getCurrentTransactionOwner(),\n           result.getCommitMetadata(), config, this.txnManager.getLastCompletedTransactionOwner());\n", "next_change": null}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzczODA3OA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587738078", "bodyText": "I think the common term is . zookeeper chroot?", "author": "vinothchandar", "createdAt": "2021-03-04T19:02:00Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/config/LockConfiguration.java", "diffHunk": "@@ -0,0 +1,69 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.config;\n+\n+import java.io.Serializable;\n+import java.util.Properties;\n+\n+/**\n+ * Configuration for managing locks. Since this configuration needs to be shared with HiveMetaStore based lock,\n+ * which is in a different package than other lock providers, we use this as a data transfer object in hoodie-common\n+ */\n+public class LockConfiguration implements Serializable {\n+\n+  public static final String LOCK_PREFIX = \"hoodie.writer.lock.\";\n+  public static final String LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP = LOCK_PREFIX + \"wait_time_ms_between_retry\";\n+  public static final String DEFAULT_LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS = String.valueOf(5000L);\n+  public static final String LOCK_ACQUIRE_CLIENT_RETRY_WAIT_TIME_IN_MILLIS_PROP = LOCK_PREFIX + \"client.wait_time_ms_between_retry\";\n+  public static final String DEFAULT_LOCK_ACQUIRE_CLIENT_RETRY_WAIT_TIME_IN_MILLIS = String.valueOf(10000L);\n+  public static final String LOCK_ACQUIRE_NUM_RETRIES_PROP = LOCK_PREFIX + \"num_retries\";\n+  public static final String DEFAULT_LOCK_ACQUIRE_NUM_RETRIES = String.valueOf(3);\n+  public static final String LOCK_ACQUIRE_CLIENT_NUM_RETRIES_PROP = LOCK_PREFIX + \"client.num_retries\";\n+  public static final String DEFAULT_LOCK_ACQUIRE_CLIENT_NUM_RETRIES = String.valueOf(0);\n+  public static final String LOCK_ACQUIRE_WAIT_TIMEOUT_MS_PROP = LOCK_PREFIX + \"wait_time_ms\";\n+  public static final int DEFAULT_ACQUIRE_LOCK_WAIT_TIMEOUT_MS = 60 * 1000;\n+  // configs for file system based locks. NOTE: This only works for DFS with atomic create/delete operation\n+  public static final String FILESYSTEM_BASED_LOCK_PROPERTY_PREFIX = LOCK_PREFIX + \"filesystem.\";\n+  public static final String FILESYSTEM_LOCK_PATH_PROP = FILESYSTEM_BASED_LOCK_PROPERTY_PREFIX + \"path\";\n+  // configs for metastore based locks\n+  public static final String HIVE_METASTORE_LOCK_PROPERTY_PREFIX = LOCK_PREFIX + \"hivemetastore.\";\n+  public static final String HIVE_DATABASE_NAME_PROP = HIVE_METASTORE_LOCK_PROPERTY_PREFIX + \"database\";\n+  public static final String HIVE_TABLE_NAME_PROP = HIVE_METASTORE_LOCK_PROPERTY_PREFIX + \"table\";\n+  // Zookeeper configs for zk based locks\n+  public static final String ZOOKEEPER_BASED_LOCK_PROPERTY_PREFIX = LOCK_PREFIX + \"zookeeper.\";\n+  public static final String ZK_BASE_PATH_PROP = ZOOKEEPER_BASED_LOCK_PROPERTY_PREFIX + \"zk_base_path\";", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzg2ODY4Mw==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587868683", "bodyText": "This is the base path for the zk lock which users can select. I have not exposed a config to change the chroot. This will be the default.", "author": "n3nash", "createdAt": "2021-03-04T22:21:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzczODA3OA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzczOTI1NQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587739255", "bodyText": "can this be an interface?", "author": "vinothchandar", "createdAt": "2021-03-04T19:02:44Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java", "diffHunk": "@@ -0,0 +1,86 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.lock;\n+\n+import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.hudi.common.util.StringUtils;\n+import org.apache.hudi.exception.HoodieLockException;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.Condition;\n+import java.util.concurrent.locks.Lock;\n+\n+/**\n+ * Pluggable lock implementations using this provider class.\n+ */\n+public abstract class LockProvider<T> implements Lock, AutoCloseable {", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc0MDAyMA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587740020", "bodyText": "if there is no shared code here, we should go for an interface vs an abstract class", "author": "vinothchandar", "createdAt": "2021-03-04T19:03:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzczOTI1NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzg2NzE5MA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587867190", "bodyText": "I want to mark some methods as not implementable which is why abstract class is chosen", "author": "n3nash", "createdAt": "2021-03-04T22:18:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzczOTI1NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODc3NTM5Mg==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588775392", "bodyText": "We can always to interface and default methods, right?", "author": "vinothchandar", "createdAt": "2021-03-05T23:07:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzczOTI1NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODkxODI4MQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588918281", "bodyText": "I want to make some methods final which we cannot do in interfaces. But it's fine, I have changed it to interface, I don't have a very strong preference.", "author": "n3nash", "createdAt": "2021-03-06T19:04:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzczOTI1NQ=="}], "type": "inlineReview", "revised_code": {"commit": "45e931ec410685bcc1ec8dd974560add27dac684", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\nindex 4784ffda4..e5cf51691 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n", "chunk": "@@ -18,69 +18,35 @@\n \n package org.apache.hudi.common.lock;\n \n-import org.apache.hudi.common.config.LockConfiguration;\n-import org.apache.hudi.common.util.StringUtils;\n-import org.apache.hudi.exception.HoodieLockException;\n-import org.apache.log4j.LogManager;\n-import org.apache.log4j.Logger;\n-\n-import java.util.concurrent.TimeUnit;\n import java.util.concurrent.locks.Condition;\n import java.util.concurrent.locks.Lock;\n \n /**\n  * Pluggable lock implementations using this provider class.\n  */\n-public abstract class LockProvider<T> implements Lock, AutoCloseable {\n-\n-  private static final Logger LOG = LogManager.getLogger(LockProvider.class);\n-\n-  protected LockConfiguration lockConfiguration;\n+public interface LockProvider<T> extends Lock, AutoCloseable {\n \n   @Override\n-  public final void lockInterruptibly() {\n+  default void lockInterruptibly() {\n     throw new UnsupportedOperationException();\n   }\n \n   @Override\n-  public final void lock() {\n+  default void lock() {\n     throw new UnsupportedOperationException();\n   }\n \n   @Override\n-  public final boolean tryLock() {\n+  default boolean tryLock() {\n     throw new UnsupportedOperationException();\n   }\n \n   @Override\n-  public boolean tryLock(long time, TimeUnit unit) {\n-    try {\n-      return tryLock(time, unit);\n-    } catch (Exception e) {\n-      throw new HoodieLockException(e);\n-    }\n-  }\n-\n-  public T getLock() {\n+  default Condition newCondition() {\n     throw new UnsupportedOperationException();\n   }\n \n-  @Override\n-  public final Condition newCondition() {\n-    throw new UnsupportedOperationException();\n+  default T getLock() {\n+    throw new IllegalArgumentException();\n   }\n-\n-  @Override\n-  public void close() {\n-    try {\n-      close();\n-    } catch (Exception e) {\n-      LOG.error(e);\n-    }\n-  }\n-\n-  protected String generateLogStatement(LockState state, String suffix) {\n-    return StringUtils.join(state.name(), \" lock at\", suffix);\n-  }\n-\n }\n", "next_change": {"commit": "1b41b773c6bb94ac28609bf829e875cefce6e5d3", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\nindex e5cf51691..7d8e52738 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n", "chunk": "@@ -49,4 +49,8 @@ public interface LockProvider<T> extends Lock, AutoCloseable {\n   default T getLock() {\n     throw new IllegalArgumentException();\n   }\n+\n+  @Override\n+  default void close() {\n+  }\n }\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc0MTAzNA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587741034", "bodyText": "rename: HoodieMetadataWrapper", "author": "vinothchandar", "createdAt": "2021-03-04T19:04:16Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/model/HoodieCommonMetadata.java", "diffHunk": "@@ -0,0 +1,33 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.model;\n+\n+import org.apache.hudi.avro.model.HoodieArchivedMetaEntry;\n+\n+public class HoodieCommonMetadata {", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/model/HoodieCommonMetadata.java b/hudi-common/src/main/java/org/apache/hudi/common/model/HoodieMetadataWrapper.java\nsimilarity index 90%\nrename from hudi-common/src/main/java/org/apache/hudi/common/model/HoodieCommonMetadata.java\nrename to hudi-common/src/main/java/org/apache/hudi/common/model/HoodieMetadataWrapper.java\nindex eb9f7d6bd..d2c95aa63 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/model/HoodieCommonMetadata.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/model/HoodieMetadataWrapper.java\n", "chunk": "@@ -20,10 +20,10 @@ package org.apache.hudi.common.model;\n \n import org.apache.hudi.avro.model.HoodieArchivedMetaEntry;\n \n-public class HoodieCommonMetadata {\n+public class HoodieMetadataWrapper {\n   private HoodieArchivedMetaEntry commonMetadata;\n \n-  public HoodieCommonMetadata(HoodieArchivedMetaEntry commonMetadata) {\n+  public HoodieMetadataWrapper(HoodieArchivedMetaEntry commonMetadata) {\n     this.commonMetadata = commonMetadata;\n   }\n \n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc0MTIyOA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587741228", "bodyText": "rename: TableServiceType", "author": "vinothchandar", "createdAt": "2021-03-04T19:04:36Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/model/TableService.java", "diffHunk": "@@ -0,0 +1,41 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.model;\n+\n+import org.apache.hudi.common.table.timeline.HoodieTimeline;\n+\n+/**\n+ * Supported runtime table services.\n+ */\n+public enum TableService {", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/model/TableService.java b/hudi-common/src/main/java/org/apache/hudi/common/model/TableServiceType.java\nsimilarity index 97%\nrename from hudi-common/src/main/java/org/apache/hudi/common/model/TableService.java\nrename to hudi-common/src/main/java/org/apache/hudi/common/model/TableServiceType.java\nindex b41b76d72..90444a3d6 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/model/TableService.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/model/TableServiceType.java\n", "chunk": "@@ -23,7 +23,7 @@ import org.apache.hudi.common.table.timeline.HoodieTimeline;\n /**\n  * Supported runtime table services.\n  */\n-public enum TableService {\n+public enum TableServiceType {\n   COMPACT, CLUSTER, CLEAN;\n \n   public String getAction() {\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc0MTQ3MA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587741470", "bodyText": "rename: isOptimistic... ?", "author": "vinothchandar", "createdAt": "2021-03-04T19:04:58Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/model/WriteConcurrencyMode.java", "diffHunk": "@@ -0,0 +1,66 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.model;\n+\n+import org.apache.hudi.exception.HoodieException;\n+\n+import java.util.Locale;\n+\n+/**\n+ * Different concurrency modes for write operations.\n+ */\n+public enum WriteConcurrencyMode {\n+  // Only a single writer can perform write ops\n+  SINGLE_WRITER(\"single_writer\"),\n+  // Multiple writer can perform write ops with lazy conflict resolution using locks\n+  OPTIMISTIC_CONCURRENCY_CONTROL(\"optimistic_concurrency_control\");\n+\n+  private final String value;\n+\n+  WriteConcurrencyMode(String value) {\n+    this.value = value;\n+  }\n+\n+  /**\n+   * Getter for write concurrency mode.\n+   * @return\n+   */\n+  public String value() {\n+    return value;\n+  }\n+\n+  /**\n+   * Convert string value to WriteConcurrencyMode.\n+   */\n+  public static WriteConcurrencyMode fromValue(String value) {\n+    switch (value.toLowerCase(Locale.ROOT)) {\n+      case \"single_writer\":\n+        return SINGLE_WRITER;\n+      case \"optimistic_concurrency_control\":\n+        return OPTIMISTIC_CONCURRENCY_CONTROL;\n+      default:\n+        throw new HoodieException(\"Invalid value of Type.\");\n+    }\n+  }\n+\n+  public boolean supportsOptimisticConcurrencyControl() {", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzgzNjk4Mw==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587836983", "bodyText": "I feel supportsOptimisticConcurrencyControl as it is more direct vs isOptimisticConcurrencyControl which sounds a little weird. Let me know if you have a strong preference.", "author": "n3nash", "createdAt": "2021-03-04T21:26:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc0MTQ3MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODc3NDQ2NA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588774464", "bodyText": "I was thinking from perspective of, you are just doing a direct comparison. thus hte isXXX naming. but I see your view. lets keep it as is", "author": "vinothchandar", "createdAt": "2021-03-05T23:04:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc0MTQ3MA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc0MTk4MQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587741981", "bodyText": "what is this really?  how can there be an write that is unknown?", "author": "vinothchandar", "createdAt": "2021-03-04T19:05:39Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/model/WriteOperationType.java", "diffHunk": "@@ -82,6 +84,10 @@ public static WriteOperationType fromValue(String value) {\n         return INSERT_OVERWRITE_TABLE;\n       case \"cluster\":\n         return CLUSTER;\n+      case \"compact\":\n+        return COMPACT;\n+      case \"unknown\":", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzgzNzUyNg==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587837526", "bodyText": "This was introduced to address older metadata when we don't store the WriteOperationType in the metadata..", "author": "n3nash", "createdAt": "2021-03-04T21:27:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc0MTk4MQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc0MjU2OQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587742569", "bodyText": "lets unit tests these?", "author": "vinothchandar", "createdAt": "2021-03-04T19:06:30Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/util/CommitUtils.java", "diffHunk": "@@ -93,4 +95,28 @@ private static HoodieCommitMetadata buildMetadataFromStats(List<HoodieWriteStat>\n         + \"numReplaceFileIds:\" + partitionToReplaceFileIds.values().stream().mapToInt(e -> e.size()).sum());\n     return commitMetadata;\n   }\n+\n+  public static HashMap<String, String> getFileIdWithoutSuffixAndRelativePaths(Map<String, List<org.apache.hudi.avro.model.HoodieWriteStat>>", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/util/CommitUtils.java b/hudi-common/src/main/java/org/apache/hudi/common/util/CommitUtils.java\nindex 7b62ba912..e25f6de6d 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/util/CommitUtils.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/util/CommitUtils.java\n", "chunk": "@@ -96,25 +96,25 @@ public class CommitUtils {\n     return commitMetadata;\n   }\n \n-  public static HashMap<String, String> getFileIdWithoutSuffixAndRelativePaths(Map<String, List<org.apache.hudi.avro.model.HoodieWriteStat>>\n+  public static HashMap<String, String> getFileIdWithoutSuffixAndRelativePathsFromSpecificRecord(Map<String, List<org.apache.hudi.avro.model.HoodieWriteStat>>\n                                                                                        partitionToWriteStats) {\n     HashMap<String, String> fileIdToPath = new HashMap<>();\n     // list all partitions paths\n     for (Map.Entry<String, List<org.apache.hudi.avro.model.HoodieWriteStat>> entry : partitionToWriteStats.entrySet()) {\n       for (org.apache.hudi.avro.model.HoodieWriteStat stat : entry.getValue()) {\n-        fileIdToPath.put(FSUtils.getFileId(stat.getFileId()), stat.getPath());\n+        fileIdToPath.put(stat.getFileId(), stat.getPath());\n       }\n     }\n     return fileIdToPath;\n   }\n   \n-  public static HashMap<String, String> getFileIdWithoutSuffixAndRelativePathsFromCommit(Map<String, List<HoodieWriteStat>>\n+  public static HashMap<String, String> getFileIdWithoutSuffixAndRelativePaths(Map<String, List<HoodieWriteStat>>\n       partitionToWriteStats) {\n     HashMap<String, String> fileIdToPath = new HashMap<>();\n     // list all partitions paths\n     for (Map.Entry<String, List<HoodieWriteStat>> entry : partitionToWriteStats.entrySet()) {\n       for (HoodieWriteStat stat : entry.getValue()) {\n-        fileIdToPath.put(FSUtils.getFileId(stat.getFileId()), stat.getPath());\n+        fileIdToPath.put(stat.getFileId(), stat.getPath());\n       }\n     }\n     return fileIdToPath;\n", "next_change": {"commit": "c7323ada211503eae62842f5f2eb31769da2b8bc", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/util/CommitUtils.java b/hudi-common/src/main/java/org/apache/hudi/common/util/CommitUtils.java\nindex e25f6de6d..179055f76 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/util/CommitUtils.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/util/CommitUtils.java\n", "chunk": "@@ -107,7 +106,7 @@ public class CommitUtils {\n     }\n     return fileIdToPath;\n   }\n-  \n+\n   public static HashMap<String, String> getFileIdWithoutSuffixAndRelativePaths(Map<String, List<HoodieWriteStat>>\n       partitionToWriteStats) {\n     HashMap<String, String> fileIdToPath = new HashMap<>();\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc0NDAwOQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587744009", "bodyText": "revisit todo?", "author": "vinothchandar", "createdAt": "2021-03-04T19:08:43Z", "path": "hudi-client/hudi-flink-client/src/main/java/org/apache/hudi/client/HoodieFlinkWriteClient.java", "diffHunk": "@@ -313,6 +320,16 @@ public void cleanHandles() {\n     return writeHandle;\n   }\n \n+  @Override\n+  protected void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n+    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n+    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n+    HoodieTable table = createTable(config, hadoopConf);\n+    // TODO : Metadata Writer is not supported for Flink", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-flink-client/src/main/java/org/apache/hudi/client/HoodieFlinkWriteClient.java b/hudi-client/hudi-flink-client/src/main/java/org/apache/hudi/client/HoodieFlinkWriteClient.java\nindex 54b47109d..974f774f2 100644\n--- a/hudi-client/hudi-flink-client/src/main/java/org/apache/hudi/client/HoodieFlinkWriteClient.java\n+++ b/hudi-client/hudi-flink-client/src/main/java/org/apache/hudi/client/HoodieFlinkWriteClient.java\n", "chunk": "@@ -325,7 +325,6 @@ public class HoodieFlinkWriteClient<T extends HoodieRecordPayload> extends\n     // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n     // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n     HoodieTable table = createTable(config, hadoopConf);\n-    // TODO : Metadata Writer is not supported for Flink\n     TransactionUtils.resolveWriteConflictIfAny(table, Option.empty(), this.txnManager.getCurrentTransactionOwner(),\n         Option.of(metadata), config, txnManager.getLastCompletedTransactionOwner());\n   }\n", "next_change": {"commit": "02efbb661e7ed13c3614ddee7ab5157623070f7c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-flink-client/src/main/java/org/apache/hudi/client/HoodieFlinkWriteClient.java b/hudi-client/hudi-flink-client/src/main/java/org/apache/hudi/client/HoodieFlinkWriteClient.java\nindex 974f774f2..f8be0f1c7 100644\n--- a/hudi-client/hudi-flink-client/src/main/java/org/apache/hudi/client/HoodieFlinkWriteClient.java\n+++ b/hudi-client/hudi-flink-client/src/main/java/org/apache/hudi/client/HoodieFlinkWriteClient.java\n", "chunk": "@@ -325,7 +319,7 @@ public class HoodieFlinkWriteClient<T extends HoodieRecordPayload> extends\n     // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n     // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n     HoodieTable table = createTable(config, hadoopConf);\n-    TransactionUtils.resolveWriteConflictIfAny(table, Option.empty(), this.txnManager.getCurrentTransactionOwner(),\n+    TransactionUtils.resolveWriteConflictIfAny(table, this.txnManager.getCurrentTransactionOwner(),\n         Option.of(metadata), config, txnManager.getLastCompletedTransactionOwner());\n   }\n \n", "next_change": {"commit": "1886bbd803f1a51e3d261705dd1283cfa8caf06b", "changed_code": [{"header": "diff --git a/hudi-client/hudi-flink-client/src/main/java/org/apache/hudi/client/HoodieFlinkWriteClient.java b/hudi-client/hudi-flink-client/src/main/java/org/apache/hudi/client/HoodieFlinkWriteClient.java\nindex f8be0f1c7..7b480403c 100644\n--- a/hudi-client/hudi-flink-client/src/main/java/org/apache/hudi/client/HoodieFlinkWriteClient.java\n+++ b/hudi-client/hudi-flink-client/src/main/java/org/apache/hudi/client/HoodieFlinkWriteClient.java\n", "chunk": "@@ -314,15 +314,6 @@ public class HoodieFlinkWriteClient<T extends HoodieRecordPayload> extends\n     return writeHandle;\n   }\n \n-  @Override\n-  protected void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n-    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n-    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n-    HoodieTable table = createTable(config, hadoopConf);\n-    TransactionUtils.resolveWriteConflictIfAny(table, this.txnManager.getCurrentTransactionOwner(),\n-        Option.of(metadata), config, txnManager.getLastCompletedTransactionOwner());\n-  }\n-\n   private HoodieTable<T, List<HoodieRecord<T>>, List<HoodieKey>, List<WriteStatus>> getTableAndInitCtx(HoodieTableMetaClient metaClient, WriteOperationType operationType) {\n     if (operationType == WriteOperationType.DELETE) {\n       setWriteSchemaForDeletes(metaClient);\n", "next_change": {"commit": "461047d03e9b7b73b34536ccf290a24f4aada6b0", "changed_code": [{"header": "diff --git a/hudi-client/hudi-flink-client/src/main/java/org/apache/hudi/client/HoodieFlinkWriteClient.java b/hudi-client/hudi-flink-client/src/main/java/org/apache/hudi/client/HoodieFlinkWriteClient.java\nindex 7b480403c..f8be0f1c7 100644\n--- a/hudi-client/hudi-flink-client/src/main/java/org/apache/hudi/client/HoodieFlinkWriteClient.java\n+++ b/hudi-client/hudi-flink-client/src/main/java/org/apache/hudi/client/HoodieFlinkWriteClient.java\n", "chunk": "@@ -314,6 +314,15 @@ public class HoodieFlinkWriteClient<T extends HoodieRecordPayload> extends\n     return writeHandle;\n   }\n \n+  @Override\n+  protected void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n+    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n+    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n+    HoodieTable table = createTable(config, hadoopConf);\n+    TransactionUtils.resolveWriteConflictIfAny(table, this.txnManager.getCurrentTransactionOwner(),\n+        Option.of(metadata), config, txnManager.getLastCompletedTransactionOwner());\n+  }\n+\n   private HoodieTable<T, List<HoodieRecord<T>>, List<HoodieKey>, List<WriteStatus>> getTableAndInitCtx(HoodieTableMetaClient metaClient, WriteOperationType operationType) {\n     if (operationType == WriteOperationType.DELETE) {\n       setWriteSchemaForDeletes(metaClient);\n", "next_change": {"commit": "a466320b7537bf2862df853344e80fbd0be6d16a", "changed_code": [{"header": "diff --git a/hudi-client/hudi-flink-client/src/main/java/org/apache/hudi/client/HoodieFlinkWriteClient.java b/hudi-client/hudi-flink-client/src/main/java/org/apache/hudi/client/HoodieFlinkWriteClient.java\nindex f8be0f1c7..7b480403c 100644\n--- a/hudi-client/hudi-flink-client/src/main/java/org/apache/hudi/client/HoodieFlinkWriteClient.java\n+++ b/hudi-client/hudi-flink-client/src/main/java/org/apache/hudi/client/HoodieFlinkWriteClient.java\n", "chunk": "@@ -314,15 +314,6 @@ public class HoodieFlinkWriteClient<T extends HoodieRecordPayload> extends\n     return writeHandle;\n   }\n \n-  @Override\n-  protected void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n-    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n-    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n-    HoodieTable table = createTable(config, hadoopConf);\n-    TransactionUtils.resolveWriteConflictIfAny(table, this.txnManager.getCurrentTransactionOwner(),\n-        Option.of(metadata), config, txnManager.getLastCompletedTransactionOwner());\n-  }\n-\n   private HoodieTable<T, List<HoodieRecord<T>>, List<HoodieKey>, List<WriteStatus>> getTableAndInitCtx(HoodieTableMetaClient metaClient, WriteOperationType operationType) {\n     if (operationType == WriteOperationType.DELETE) {\n       setWriteSchemaForDeletes(metaClient);\n", "next_change": null}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc0NDMwNg==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587744306", "bodyText": "this does not seem ok to do?", "author": "vinothchandar", "createdAt": "2021-03-04T19:09:16Z", "path": "hudi-client/hudi-flink-client/src/main/java/org/apache/hudi/table/HoodieFlinkCopyOnWriteTable.java", "diffHunk": "@@ -265,6 +266,20 @@ public void rollbackBootstrap(HoodieEngineContext context, String instantTime) {\n     throw new HoodieNotSupportedException(\"Bootstrap is not supported yet\");\n   }\n \n+  /**\n+   * TODO :\n+   * Refactor {@link FlinkCleanActionExecutor} to support scheduling of cleaning.\n+   * @param context HoodieEngineContext\n+   * @param instantTime Instant Time for scheduling cleaning\n+   * @param extraMetadata additional metadata to write into plan\n+   * @return\n+   */\n+  @Override\n+  public Option<HoodieCleanerPlan> scheduleCleaning(HoodieEngineContext context, String instantTime, Option<Map<String, String>> extraMetadata) {", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODE0Njg2OA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588146868", "bodyText": "Yeah, had a TODO on this, addressed it now.", "author": "n3nash", "createdAt": "2021-03-05T09:20:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc0NDMwNg=="}], "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-flink-client/src/main/java/org/apache/hudi/table/HoodieFlinkCopyOnWriteTable.java b/hudi-client/hudi-flink-client/src/main/java/org/apache/hudi/table/HoodieFlinkCopyOnWriteTable.java\nindex d77e762e8..167b3766e 100644\n--- a/hudi-client/hudi-flink-client/src/main/java/org/apache/hudi/table/HoodieFlinkCopyOnWriteTable.java\n+++ b/hudi-client/hudi-flink-client/src/main/java/org/apache/hudi/table/HoodieFlinkCopyOnWriteTable.java\n", "chunk": "@@ -267,8 +268,6 @@ public class HoodieFlinkCopyOnWriteTable<T extends HoodieRecordPayload> extends\n   }\n \n   /**\n-   * TODO :\n-   * Refactor {@link FlinkCleanActionExecutor} to support scheduling of cleaning.\n    * @param context HoodieEngineContext\n    * @param instantTime Instant Time for scheduling cleaning\n    * @param extraMetadata additional metadata to write into plan\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-flink-client/src/main/java/org/apache/hudi/table/HoodieFlinkCopyOnWriteTable.java b/hudi-client/hudi-flink-client/src/main/java/org/apache/hudi/table/HoodieFlinkCopyOnWriteTable.java\nindex d77e762e8..167b3766e 100644\n--- a/hudi-client/hudi-flink-client/src/main/java/org/apache/hudi/table/HoodieFlinkCopyOnWriteTable.java\n+++ b/hudi-client/hudi-flink-client/src/main/java/org/apache/hudi/table/HoodieFlinkCopyOnWriteTable.java\n", "chunk": "@@ -276,8 +275,7 @@ public class HoodieFlinkCopyOnWriteTable<T extends HoodieRecordPayload> extends\n    */\n   @Override\n   public Option<HoodieCleanerPlan> scheduleCleaning(HoodieEngineContext context, String instantTime, Option<Map<String, String>> extraMetadata) {\n-    // No-Op;\n-    return Option.empty();\n+    return new FlinkScheduleCleanActionExecutor(context, config, this, instantTime, extraMetadata).execute();\n   }\n \n   @Override\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc0NTI2Mw==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587745263", "bodyText": "revisit comment.", "author": "vinothchandar", "createdAt": "2021-03-04T19:10:46Z", "path": "hudi-client/hudi-java-client/src/main/java/org/apache/hudi/client/HoodieJavaWriteClient.java", "diffHunk": "@@ -224,6 +231,16 @@ protected void completeCompaction(HoodieCommitMetadata metadata,\n     return getTableAndInitCtx(metaClient, operationType);\n   }\n \n+  @Override\n+  protected void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n+    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n+    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n+    HoodieTable table = createTable(config, hadoopConf);\n+    // TODO : Metadata Writer is not supported for Java", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-java-client/src/main/java/org/apache/hudi/client/HoodieJavaWriteClient.java b/hudi-client/hudi-java-client/src/main/java/org/apache/hudi/client/HoodieJavaWriteClient.java\nindex edcd8ab2a..c5c18ca35 100644\n--- a/hudi-client/hudi-java-client/src/main/java/org/apache/hudi/client/HoodieJavaWriteClient.java\n+++ b/hudi-client/hudi-java-client/src/main/java/org/apache/hudi/client/HoodieJavaWriteClient.java\n", "chunk": "@@ -236,7 +236,6 @@ public class HoodieJavaWriteClient<T extends HoodieRecordPayload> extends\n     // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n     // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n     HoodieTable table = createTable(config, hadoopConf);\n-    // TODO : Metadata Writer is not supported for Java\n     TransactionUtils.resolveWriteConflictIfAny(table, Option.empty(), this.txnManager.getCurrentTransactionOwner(),\n         Option.of(metadata), config, txnManager.getLastCompletedTransactionOwner());\n   }\n", "next_change": {"commit": "02efbb661e7ed13c3614ddee7ab5157623070f7c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-java-client/src/main/java/org/apache/hudi/client/HoodieJavaWriteClient.java b/hudi-client/hudi-java-client/src/main/java/org/apache/hudi/client/HoodieJavaWriteClient.java\nindex c5c18ca35..97c6dbbe1 100644\n--- a/hudi-client/hudi-java-client/src/main/java/org/apache/hudi/client/HoodieJavaWriteClient.java\n+++ b/hudi-client/hudi-java-client/src/main/java/org/apache/hudi/client/HoodieJavaWriteClient.java\n", "chunk": "@@ -236,7 +230,7 @@ public class HoodieJavaWriteClient<T extends HoodieRecordPayload> extends\n     // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n     // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n     HoodieTable table = createTable(config, hadoopConf);\n-    TransactionUtils.resolveWriteConflictIfAny(table, Option.empty(), this.txnManager.getCurrentTransactionOwner(),\n+    TransactionUtils.resolveWriteConflictIfAny(table, this.txnManager.getCurrentTransactionOwner(),\n         Option.of(metadata), config, txnManager.getLastCompletedTransactionOwner());\n   }\n \n", "next_change": {"commit": "47403db3c55938e97a8e9baa21f65d6d09c04ee9", "changed_code": [{"header": "diff --git a/hudi-client/hudi-java-client/src/main/java/org/apache/hudi/client/HoodieJavaWriteClient.java b/hudi-client/hudi-java-client/src/main/java/org/apache/hudi/client/HoodieJavaWriteClient.java\nindex 97c6dbbe1..8b7cb198b 100644\n--- a/hudi-client/hudi-java-client/src/main/java/org/apache/hudi/client/HoodieJavaWriteClient.java\n+++ b/hudi-client/hudi-java-client/src/main/java/org/apache/hudi/client/HoodieJavaWriteClient.java\n", "chunk": "@@ -225,15 +224,6 @@ public class HoodieJavaWriteClient<T extends HoodieRecordPayload> extends\n     return getTableAndInitCtx(metaClient, operationType);\n   }\n \n-  @Override\n-  protected void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n-    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n-    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n-    HoodieTable table = createTable(config, hadoopConf);\n-    TransactionUtils.resolveWriteConflictIfAny(table, this.txnManager.getCurrentTransactionOwner(),\n-        Option.of(metadata), config, txnManager.getLastCompletedTransactionOwner());\n-  }\n-\n   private HoodieTable<T, List<HoodieRecord<T>>, List<HoodieKey>, List<WriteStatus>> getTableAndInitCtx(HoodieTableMetaClient metaClient, WriteOperationType operationType) {\n     if (operationType == WriteOperationType.DELETE) {\n       setWriteSchemaForDeletes(metaClient);\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc0NjQzMg==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587746432", "bodyText": "lets clean this up?", "author": "vinothchandar", "createdAt": "2021-03-04T19:12:46Z", "path": "hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java", "diffHunk": "@@ -380,11 +391,40 @@ protected void completeClustering(HoodieReplaceCommitMetadata metadata, JavaRDD<\n   @Override\n   protected HoodieTable<T, JavaRDD<HoodieRecord<T>>, JavaRDD<HoodieKey>, JavaRDD<WriteStatus>> getTableAndInitCtx(WriteOperationType operationType, String instantTime) {\n     HoodieTableMetaClient metaClient = createMetaClient(true);\n-    new SparkUpgradeDowngrade(metaClient, config, context).run(metaClient, HoodieTableVersion.current(), config, context, instantTime);\n-    return getTableAndInitCtx(metaClient, operationType);\n+    if (HoodieTableVersion.current() != metaClient.getTableConfig().getTableVersion()) {\n+      // TODO : Force clean up of all inflights, do this once pending rollback removal PR is landed", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\nindex e14542ddd..c68543f1c 100644\n--- a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n+++ b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n", "chunk": "@@ -391,27 +393,32 @@ public class SparkRDDWriteClient<T extends HoodieRecordPayload> extends\n   @Override\n   protected HoodieTable<T, JavaRDD<HoodieRecord<T>>, JavaRDD<HoodieKey>, JavaRDD<WriteStatus>> getTableAndInitCtx(WriteOperationType operationType, String instantTime) {\n     HoodieTableMetaClient metaClient = createMetaClient(true);\n-    if (HoodieTableVersion.current() != metaClient.getTableConfig().getTableVersion()) {\n-      // TODO : Force clean up of all inflights, do this once pending rollback removal PR is landed\n-      // this.rollbackFailedWrites();\n-      this.txnManager.beginTransaction();\n-      try {\n-        // Ensure no inflight commits\n-        TransactionUtils.resolveConflictIfAnyForUpgradeDowngrade(metaClient);\n-        new SparkUpgradeDowngrade(metaClient, config, context).run(metaClient, HoodieTableVersion.current(), config, context, instantTime);\n-      } finally {\n-        this.txnManager.endTransaction();\n+    AbstractUpgradeDowngrade upgradeDowngrade = new SparkUpgradeDowngrade(metaClient, config, context);\n+    if (upgradeDowngrade.needsUpgradeOrDowngrade(HoodieTableVersion.current())) {\n+      if (config.getWriteConcurrencyMode().supportsOptimisticConcurrencyControl()) {\n+        this.txnManager.beginTransaction();\n+        try {\n+          // Ensure no inflight commits\n+          this.rollbackFailedWrites(getInstantsToRollback(metaClient,\n+              HoodieFailedWritesCleaningPolicy.EAGER));\n+          new SparkUpgradeDowngrade(metaClient, config, context)\n+              .run(metaClient, HoodieTableVersion.current(), config, context, instantTime);\n+        } finally {\n+          this.txnManager.endTransaction();\n+        }\n+      } else {\n+        upgradeDowngrade.run(metaClient, HoodieTableVersion.current(), config, context, instantTime);\n       }\n     }\n     return getTableAndInitCtx(metaClient, operationType, instantTime);\n   }\n \n   // TODO : To enforce priority between table service and ingestion writer, use transactions here and invoke strategy\n-  private void completeTableService(TableService tableService, HoodieCommitMetadata metadata, JavaRDD<WriteStatus> writeStatuses,\n+  private void completeTableService(TableServiceType tableServiceType, HoodieCommitMetadata metadata, JavaRDD<WriteStatus> writeStatuses,\n                                       HoodieTable<T, JavaRDD<HoodieRecord<T>>, JavaRDD<HoodieKey>, JavaRDD<WriteStatus>> table,\n                                       String commitInstant) {\n \n-    switch (tableService) {\n+    switch (tableServiceType) {\n       case CLUSTER:\n         completeClustering((HoodieReplaceCommitMetadata) metadata, writeStatuses, table, commitInstant);\n         break;\n", "next_change": {"commit": "45e931ec410685bcc1ec8dd974560add27dac684", "changed_code": [{"header": "diff --git a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\nindex c68543f1c..022b90f79 100644\n--- a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n+++ b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n", "chunk": "@@ -398,9 +398,8 @@ public class SparkRDDWriteClient<T extends HoodieRecordPayload> extends\n       if (config.getWriteConcurrencyMode().supportsOptimisticConcurrencyControl()) {\n         this.txnManager.beginTransaction();\n         try {\n-          // Ensure no inflight commits\n-          this.rollbackFailedWrites(getInstantsToRollback(metaClient,\n-              HoodieFailedWritesCleaningPolicy.EAGER));\n+          // Ensure no inflight commits by setting EAGER policy and explicitly cleaning all\n+          this.rollbackFailedWrites(getInstantsToRollback(metaClient, HoodieFailedWritesCleaningPolicy.EAGER));\n           new SparkUpgradeDowngrade(metaClient, config, context)\n               .run(metaClient, HoodieTableVersion.current(), config, context, instantTime);\n         } finally {\n", "next_change": {"commit": "c7323ada211503eae62842f5f2eb31769da2b8bc", "changed_code": [{"header": "diff --git a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\nindex 022b90f79..978527cd0 100644\n--- a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n+++ b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n", "chunk": "@@ -398,7 +398,7 @@ public class SparkRDDWriteClient<T extends HoodieRecordPayload> extends\n       if (config.getWriteConcurrencyMode().supportsOptimisticConcurrencyControl()) {\n         this.txnManager.beginTransaction();\n         try {\n-          // Ensure no inflight commits by setting EAGER policy and explicitly cleaning all\n+          // Ensure no inflight commits by setting EAGER policy and explicitly cleaning all failed commits\n           this.rollbackFailedWrites(getInstantsToRollback(metaClient, HoodieFailedWritesCleaningPolicy.EAGER));\n           new SparkUpgradeDowngrade(metaClient, config, context)\n               .run(metaClient, HoodieTableVersion.current(), config, context, instantTime);\n", "next_change": null}]}}]}}, {"header": "diff --git a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\nindex e14542ddd..c68543f1c 100644\n--- a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n+++ b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n", "chunk": "@@ -419,7 +426,7 @@ public class SparkRDDWriteClient<T extends HoodieRecordPayload> extends\n         completeCompaction(metadata, writeStatuses, table, commitInstant);\n         break;\n       default:\n-        throw new IllegalArgumentException(\"This table service is not valid \" + tableService);\n+        throw new IllegalArgumentException(\"This table service is not valid \" + tableServiceType);\n     }\n   }\n \n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc0NzU4MA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587747580", "bodyText": "lets add a method needsUpgradeOrDowngrade()  to the upgradedowngrade class?", "author": "vinothchandar", "createdAt": "2021-03-04T19:14:39Z", "path": "hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java", "diffHunk": "@@ -380,11 +391,40 @@ protected void completeClustering(HoodieReplaceCommitMetadata metadata, JavaRDD<\n   @Override\n   protected HoodieTable<T, JavaRDD<HoodieRecord<T>>, JavaRDD<HoodieKey>, JavaRDD<WriteStatus>> getTableAndInitCtx(WriteOperationType operationType, String instantTime) {\n     HoodieTableMetaClient metaClient = createMetaClient(true);\n-    new SparkUpgradeDowngrade(metaClient, config, context).run(metaClient, HoodieTableVersion.current(), config, context, instantTime);\n-    return getTableAndInitCtx(metaClient, operationType);\n+    if (HoodieTableVersion.current() != metaClient.getTableConfig().getTableVersion()) {", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODE0MTI1Mw==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588141253", "bodyText": "Added", "author": "n3nash", "createdAt": "2021-03-05T09:11:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc0NzU4MA=="}], "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\nindex e14542ddd..c68543f1c 100644\n--- a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n+++ b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n", "chunk": "@@ -391,27 +393,32 @@ public class SparkRDDWriteClient<T extends HoodieRecordPayload> extends\n   @Override\n   protected HoodieTable<T, JavaRDD<HoodieRecord<T>>, JavaRDD<HoodieKey>, JavaRDD<WriteStatus>> getTableAndInitCtx(WriteOperationType operationType, String instantTime) {\n     HoodieTableMetaClient metaClient = createMetaClient(true);\n-    if (HoodieTableVersion.current() != metaClient.getTableConfig().getTableVersion()) {\n-      // TODO : Force clean up of all inflights, do this once pending rollback removal PR is landed\n-      // this.rollbackFailedWrites();\n-      this.txnManager.beginTransaction();\n-      try {\n-        // Ensure no inflight commits\n-        TransactionUtils.resolveConflictIfAnyForUpgradeDowngrade(metaClient);\n-        new SparkUpgradeDowngrade(metaClient, config, context).run(metaClient, HoodieTableVersion.current(), config, context, instantTime);\n-      } finally {\n-        this.txnManager.endTransaction();\n+    AbstractUpgradeDowngrade upgradeDowngrade = new SparkUpgradeDowngrade(metaClient, config, context);\n+    if (upgradeDowngrade.needsUpgradeOrDowngrade(HoodieTableVersion.current())) {\n+      if (config.getWriteConcurrencyMode().supportsOptimisticConcurrencyControl()) {\n+        this.txnManager.beginTransaction();\n+        try {\n+          // Ensure no inflight commits\n+          this.rollbackFailedWrites(getInstantsToRollback(metaClient,\n+              HoodieFailedWritesCleaningPolicy.EAGER));\n+          new SparkUpgradeDowngrade(metaClient, config, context)\n+              .run(metaClient, HoodieTableVersion.current(), config, context, instantTime);\n+        } finally {\n+          this.txnManager.endTransaction();\n+        }\n+      } else {\n+        upgradeDowngrade.run(metaClient, HoodieTableVersion.current(), config, context, instantTime);\n       }\n     }\n     return getTableAndInitCtx(metaClient, operationType, instantTime);\n   }\n \n   // TODO : To enforce priority between table service and ingestion writer, use transactions here and invoke strategy\n-  private void completeTableService(TableService tableService, HoodieCommitMetadata metadata, JavaRDD<WriteStatus> writeStatuses,\n+  private void completeTableService(TableServiceType tableServiceType, HoodieCommitMetadata metadata, JavaRDD<WriteStatus> writeStatuses,\n                                       HoodieTable<T, JavaRDD<HoodieRecord<T>>, JavaRDD<HoodieKey>, JavaRDD<WriteStatus>> table,\n                                       String commitInstant) {\n \n-    switch (tableService) {\n+    switch (tableServiceType) {\n       case CLUSTER:\n         completeClustering((HoodieReplaceCommitMetadata) metadata, writeStatuses, table, commitInstant);\n         break;\n", "next_change": {"commit": "45e931ec410685bcc1ec8dd974560add27dac684", "changed_code": [{"header": "diff --git a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\nindex c68543f1c..022b90f79 100644\n--- a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n+++ b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n", "chunk": "@@ -398,9 +398,8 @@ public class SparkRDDWriteClient<T extends HoodieRecordPayload> extends\n       if (config.getWriteConcurrencyMode().supportsOptimisticConcurrencyControl()) {\n         this.txnManager.beginTransaction();\n         try {\n-          // Ensure no inflight commits\n-          this.rollbackFailedWrites(getInstantsToRollback(metaClient,\n-              HoodieFailedWritesCleaningPolicy.EAGER));\n+          // Ensure no inflight commits by setting EAGER policy and explicitly cleaning all\n+          this.rollbackFailedWrites(getInstantsToRollback(metaClient, HoodieFailedWritesCleaningPolicy.EAGER));\n           new SparkUpgradeDowngrade(metaClient, config, context)\n               .run(metaClient, HoodieTableVersion.current(), config, context, instantTime);\n         } finally {\n", "next_change": {"commit": "c7323ada211503eae62842f5f2eb31769da2b8bc", "changed_code": [{"header": "diff --git a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\nindex 022b90f79..978527cd0 100644\n--- a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n+++ b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n", "chunk": "@@ -398,7 +398,7 @@ public class SparkRDDWriteClient<T extends HoodieRecordPayload> extends\n       if (config.getWriteConcurrencyMode().supportsOptimisticConcurrencyControl()) {\n         this.txnManager.beginTransaction();\n         try {\n-          // Ensure no inflight commits by setting EAGER policy and explicitly cleaning all\n+          // Ensure no inflight commits by setting EAGER policy and explicitly cleaning all failed commits\n           this.rollbackFailedWrites(getInstantsToRollback(metaClient, HoodieFailedWritesCleaningPolicy.EAGER));\n           new SparkUpgradeDowngrade(metaClient, config, context)\n               .run(metaClient, HoodieTableVersion.current(), config, context, instantTime);\n", "next_change": null}]}}]}}, {"header": "diff --git a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\nindex e14542ddd..c68543f1c 100644\n--- a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n+++ b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n", "chunk": "@@ -419,7 +426,7 @@ public class SparkRDDWriteClient<T extends HoodieRecordPayload> extends\n         completeCompaction(metadata, writeStatuses, table, commitInstant);\n         break;\n       default:\n-        throw new IllegalArgumentException(\"This table service is not valid \" + tableService);\n+        throw new IllegalArgumentException(\"This table service is not valid \" + tableServiceType);\n     }\n   }\n \n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc0Nzg5NA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587747894", "bodyText": "should we check concurrency mode before taking these locks?", "author": "vinothchandar", "createdAt": "2021-03-04T19:15:12Z", "path": "hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java", "diffHunk": "@@ -380,11 +391,40 @@ protected void completeClustering(HoodieReplaceCommitMetadata metadata, JavaRDD<\n   @Override\n   protected HoodieTable<T, JavaRDD<HoodieRecord<T>>, JavaRDD<HoodieKey>, JavaRDD<WriteStatus>> getTableAndInitCtx(WriteOperationType operationType, String instantTime) {\n     HoodieTableMetaClient metaClient = createMetaClient(true);\n-    new SparkUpgradeDowngrade(metaClient, config, context).run(metaClient, HoodieTableVersion.current(), config, context, instantTime);\n-    return getTableAndInitCtx(metaClient, operationType);\n+    if (HoodieTableVersion.current() != metaClient.getTableConfig().getTableVersion()) {\n+      // TODO : Force clean up of all inflights, do this once pending rollback removal PR is landed\n+      // this.rollbackFailedWrites();\n+      this.txnManager.beginTransaction();", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\nindex e14542ddd..c68543f1c 100644\n--- a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n+++ b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n", "chunk": "@@ -391,27 +393,32 @@ public class SparkRDDWriteClient<T extends HoodieRecordPayload> extends\n   @Override\n   protected HoodieTable<T, JavaRDD<HoodieRecord<T>>, JavaRDD<HoodieKey>, JavaRDD<WriteStatus>> getTableAndInitCtx(WriteOperationType operationType, String instantTime) {\n     HoodieTableMetaClient metaClient = createMetaClient(true);\n-    if (HoodieTableVersion.current() != metaClient.getTableConfig().getTableVersion()) {\n-      // TODO : Force clean up of all inflights, do this once pending rollback removal PR is landed\n-      // this.rollbackFailedWrites();\n-      this.txnManager.beginTransaction();\n-      try {\n-        // Ensure no inflight commits\n-        TransactionUtils.resolveConflictIfAnyForUpgradeDowngrade(metaClient);\n-        new SparkUpgradeDowngrade(metaClient, config, context).run(metaClient, HoodieTableVersion.current(), config, context, instantTime);\n-      } finally {\n-        this.txnManager.endTransaction();\n+    AbstractUpgradeDowngrade upgradeDowngrade = new SparkUpgradeDowngrade(metaClient, config, context);\n+    if (upgradeDowngrade.needsUpgradeOrDowngrade(HoodieTableVersion.current())) {\n+      if (config.getWriteConcurrencyMode().supportsOptimisticConcurrencyControl()) {\n+        this.txnManager.beginTransaction();\n+        try {\n+          // Ensure no inflight commits\n+          this.rollbackFailedWrites(getInstantsToRollback(metaClient,\n+              HoodieFailedWritesCleaningPolicy.EAGER));\n+          new SparkUpgradeDowngrade(metaClient, config, context)\n+              .run(metaClient, HoodieTableVersion.current(), config, context, instantTime);\n+        } finally {\n+          this.txnManager.endTransaction();\n+        }\n+      } else {\n+        upgradeDowngrade.run(metaClient, HoodieTableVersion.current(), config, context, instantTime);\n       }\n     }\n     return getTableAndInitCtx(metaClient, operationType, instantTime);\n   }\n \n   // TODO : To enforce priority between table service and ingestion writer, use transactions here and invoke strategy\n-  private void completeTableService(TableService tableService, HoodieCommitMetadata metadata, JavaRDD<WriteStatus> writeStatuses,\n+  private void completeTableService(TableServiceType tableServiceType, HoodieCommitMetadata metadata, JavaRDD<WriteStatus> writeStatuses,\n                                       HoodieTable<T, JavaRDD<HoodieRecord<T>>, JavaRDD<HoodieKey>, JavaRDD<WriteStatus>> table,\n                                       String commitInstant) {\n \n-    switch (tableService) {\n+    switch (tableServiceType) {\n       case CLUSTER:\n         completeClustering((HoodieReplaceCommitMetadata) metadata, writeStatuses, table, commitInstant);\n         break;\n", "next_change": {"commit": "45e931ec410685bcc1ec8dd974560add27dac684", "changed_code": [{"header": "diff --git a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\nindex c68543f1c..022b90f79 100644\n--- a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n+++ b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n", "chunk": "@@ -398,9 +398,8 @@ public class SparkRDDWriteClient<T extends HoodieRecordPayload> extends\n       if (config.getWriteConcurrencyMode().supportsOptimisticConcurrencyControl()) {\n         this.txnManager.beginTransaction();\n         try {\n-          // Ensure no inflight commits\n-          this.rollbackFailedWrites(getInstantsToRollback(metaClient,\n-              HoodieFailedWritesCleaningPolicy.EAGER));\n+          // Ensure no inflight commits by setting EAGER policy and explicitly cleaning all\n+          this.rollbackFailedWrites(getInstantsToRollback(metaClient, HoodieFailedWritesCleaningPolicy.EAGER));\n           new SparkUpgradeDowngrade(metaClient, config, context)\n               .run(metaClient, HoodieTableVersion.current(), config, context, instantTime);\n         } finally {\n", "next_change": {"commit": "c7323ada211503eae62842f5f2eb31769da2b8bc", "changed_code": [{"header": "diff --git a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\nindex 022b90f79..978527cd0 100644\n--- a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n+++ b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n", "chunk": "@@ -398,7 +398,7 @@ public class SparkRDDWriteClient<T extends HoodieRecordPayload> extends\n       if (config.getWriteConcurrencyMode().supportsOptimisticConcurrencyControl()) {\n         this.txnManager.beginTransaction();\n         try {\n-          // Ensure no inflight commits by setting EAGER policy and explicitly cleaning all\n+          // Ensure no inflight commits by setting EAGER policy and explicitly cleaning all failed commits\n           this.rollbackFailedWrites(getInstantsToRollback(metaClient, HoodieFailedWritesCleaningPolicy.EAGER));\n           new SparkUpgradeDowngrade(metaClient, config, context)\n               .run(metaClient, HoodieTableVersion.current(), config, context, instantTime);\n", "next_change": null}]}}]}}, {"header": "diff --git a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\nindex e14542ddd..c68543f1c 100644\n--- a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n+++ b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n", "chunk": "@@ -419,7 +426,7 @@ public class SparkRDDWriteClient<T extends HoodieRecordPayload> extends\n         completeCompaction(metadata, writeStatuses, table, commitInstant);\n         break;\n       default:\n-        throw new IllegalArgumentException(\"This table service is not valid \" + tableService);\n+        throw new IllegalArgumentException(\"This table service is not valid \" + tableServiceType);\n     }\n   }\n \n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc0ODM4Nw==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587748387", "bodyText": "comment valid? What should we do about this issue? Can you elabortate?", "author": "vinothchandar", "createdAt": "2021-03-04T19:15:54Z", "path": "hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java", "diffHunk": "@@ -380,11 +391,40 @@ protected void completeClustering(HoodieReplaceCommitMetadata metadata, JavaRDD<\n   @Override\n   protected HoodieTable<T, JavaRDD<HoodieRecord<T>>, JavaRDD<HoodieKey>, JavaRDD<WriteStatus>> getTableAndInitCtx(WriteOperationType operationType, String instantTime) {\n     HoodieTableMetaClient metaClient = createMetaClient(true);\n-    new SparkUpgradeDowngrade(metaClient, config, context).run(metaClient, HoodieTableVersion.current(), config, context, instantTime);\n-    return getTableAndInitCtx(metaClient, operationType);\n+    if (HoodieTableVersion.current() != metaClient.getTableConfig().getTableVersion()) {\n+      // TODO : Force clean up of all inflights, do this once pending rollback removal PR is landed\n+      // this.rollbackFailedWrites();\n+      this.txnManager.beginTransaction();\n+      try {\n+        // Ensure no inflight commits\n+        TransactionUtils.resolveConflictIfAnyForUpgradeDowngrade(metaClient);\n+        new SparkUpgradeDowngrade(metaClient, config, context).run(metaClient, HoodieTableVersion.current(), config, context, instantTime);\n+      } finally {\n+        this.txnManager.endTransaction();\n+      }\n+    }\n+    return getTableAndInitCtx(metaClient, operationType, instantTime);\n   }\n \n-  private HoodieTable<T, JavaRDD<HoodieRecord<T>>, JavaRDD<HoodieKey>, JavaRDD<WriteStatus>> getTableAndInitCtx(HoodieTableMetaClient metaClient, WriteOperationType operationType) {\n+  // TODO : To enforce priority between table service and ingestion writer, use transactions here and invoke strategy", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzg3MzI5NQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587873295", "bodyText": "So basically the following is a use-case for us in production :\n\nWriter starts to write fresh data to files f1,f2, c1 is inflight\nSchedule clustering, c2.cluster for files f1,f2\nc1 and c2 in progress\nc2.cluster finishes\nc1 attempts to finish and notices that c2 has overlapping file ids and aborts\n\nWe want to override the priority of c1 over c2 to avoid violating freshness SLA. A design and PR for this is going to follow after this PR is landed.", "author": "n3nash", "createdAt": "2021-03-04T22:29:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc0ODM4Nw=="}], "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\nindex e14542ddd..c68543f1c 100644\n--- a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n+++ b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n", "chunk": "@@ -391,27 +393,32 @@ public class SparkRDDWriteClient<T extends HoodieRecordPayload> extends\n   @Override\n   protected HoodieTable<T, JavaRDD<HoodieRecord<T>>, JavaRDD<HoodieKey>, JavaRDD<WriteStatus>> getTableAndInitCtx(WriteOperationType operationType, String instantTime) {\n     HoodieTableMetaClient metaClient = createMetaClient(true);\n-    if (HoodieTableVersion.current() != metaClient.getTableConfig().getTableVersion()) {\n-      // TODO : Force clean up of all inflights, do this once pending rollback removal PR is landed\n-      // this.rollbackFailedWrites();\n-      this.txnManager.beginTransaction();\n-      try {\n-        // Ensure no inflight commits\n-        TransactionUtils.resolveConflictIfAnyForUpgradeDowngrade(metaClient);\n-        new SparkUpgradeDowngrade(metaClient, config, context).run(metaClient, HoodieTableVersion.current(), config, context, instantTime);\n-      } finally {\n-        this.txnManager.endTransaction();\n+    AbstractUpgradeDowngrade upgradeDowngrade = new SparkUpgradeDowngrade(metaClient, config, context);\n+    if (upgradeDowngrade.needsUpgradeOrDowngrade(HoodieTableVersion.current())) {\n+      if (config.getWriteConcurrencyMode().supportsOptimisticConcurrencyControl()) {\n+        this.txnManager.beginTransaction();\n+        try {\n+          // Ensure no inflight commits\n+          this.rollbackFailedWrites(getInstantsToRollback(metaClient,\n+              HoodieFailedWritesCleaningPolicy.EAGER));\n+          new SparkUpgradeDowngrade(metaClient, config, context)\n+              .run(metaClient, HoodieTableVersion.current(), config, context, instantTime);\n+        } finally {\n+          this.txnManager.endTransaction();\n+        }\n+      } else {\n+        upgradeDowngrade.run(metaClient, HoodieTableVersion.current(), config, context, instantTime);\n       }\n     }\n     return getTableAndInitCtx(metaClient, operationType, instantTime);\n   }\n \n   // TODO : To enforce priority between table service and ingestion writer, use transactions here and invoke strategy\n-  private void completeTableService(TableService tableService, HoodieCommitMetadata metadata, JavaRDD<WriteStatus> writeStatuses,\n+  private void completeTableService(TableServiceType tableServiceType, HoodieCommitMetadata metadata, JavaRDD<WriteStatus> writeStatuses,\n                                       HoodieTable<T, JavaRDD<HoodieRecord<T>>, JavaRDD<HoodieKey>, JavaRDD<WriteStatus>> table,\n                                       String commitInstant) {\n \n-    switch (tableService) {\n+    switch (tableServiceType) {\n       case CLUSTER:\n         completeClustering((HoodieReplaceCommitMetadata) metadata, writeStatuses, table, commitInstant);\n         break;\n", "next_change": {"commit": "45e931ec410685bcc1ec8dd974560add27dac684", "changed_code": [{"header": "diff --git a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\nindex c68543f1c..022b90f79 100644\n--- a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n+++ b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n", "chunk": "@@ -398,9 +398,8 @@ public class SparkRDDWriteClient<T extends HoodieRecordPayload> extends\n       if (config.getWriteConcurrencyMode().supportsOptimisticConcurrencyControl()) {\n         this.txnManager.beginTransaction();\n         try {\n-          // Ensure no inflight commits\n-          this.rollbackFailedWrites(getInstantsToRollback(metaClient,\n-              HoodieFailedWritesCleaningPolicy.EAGER));\n+          // Ensure no inflight commits by setting EAGER policy and explicitly cleaning all\n+          this.rollbackFailedWrites(getInstantsToRollback(metaClient, HoodieFailedWritesCleaningPolicy.EAGER));\n           new SparkUpgradeDowngrade(metaClient, config, context)\n               .run(metaClient, HoodieTableVersion.current(), config, context, instantTime);\n         } finally {\n", "next_change": {"commit": "c7323ada211503eae62842f5f2eb31769da2b8bc", "changed_code": [{"header": "diff --git a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\nindex 022b90f79..978527cd0 100644\n--- a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n+++ b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n", "chunk": "@@ -398,7 +398,7 @@ public class SparkRDDWriteClient<T extends HoodieRecordPayload> extends\n       if (config.getWriteConcurrencyMode().supportsOptimisticConcurrencyControl()) {\n         this.txnManager.beginTransaction();\n         try {\n-          // Ensure no inflight commits by setting EAGER policy and explicitly cleaning all\n+          // Ensure no inflight commits by setting EAGER policy and explicitly cleaning all failed commits\n           this.rollbackFailedWrites(getInstantsToRollback(metaClient, HoodieFailedWritesCleaningPolicy.EAGER));\n           new SparkUpgradeDowngrade(metaClient, config, context)\n               .run(metaClient, HoodieTableVersion.current(), config, context, instantTime);\n", "next_change": null}]}}]}}, {"header": "diff --git a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\nindex e14542ddd..c68543f1c 100644\n--- a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n+++ b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n", "chunk": "@@ -419,7 +426,7 @@ public class SparkRDDWriteClient<T extends HoodieRecordPayload> extends\n         completeCompaction(metadata, writeStatuses, table, commitInstant);\n         break;\n       default:\n-        throw new IllegalArgumentException(\"This table service is not valid \" + tableService);\n+        throw new IllegalArgumentException(\"This table service is not valid \" + tableServiceType);\n     }\n   }\n \n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc0OTU3MQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587749571", "bodyText": "we lose auto closing by moving to  a regular try-catch. Why is this change needed?", "author": "vinothchandar", "createdAt": "2021-03-04T19:17:38Z", "path": "hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java", "diffHunk": "@@ -401,13 +441,25 @@ protected void completeClustering(HoodieReplaceCommitMetadata metadata, JavaRDD<\n   @Override\n   public void syncTableMetadata() {\n     // Open up the metadata table again, for syncing\n-    try (HoodieTableMetadataWriter writer = SparkHoodieBackedTableMetadataWriter.create(hadoopConf, config, context)) {\n+    try {\n+      HoodieTableMetadataWriter writer =", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzgzMzcyNg==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587833726", "bodyText": "Reverted", "author": "n3nash", "createdAt": "2021-03-04T21:20:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc0OTU3MQ=="}], "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\nindex e14542ddd..c68543f1c 100644\n--- a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n+++ b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n", "chunk": "@@ -441,9 +448,7 @@ public class SparkRDDWriteClient<T extends HoodieRecordPayload> extends\n   @Override\n   public void syncTableMetadata() {\n     // Open up the metadata table again, for syncing\n-    try {\n-      HoodieTableMetadataWriter writer =\n-          SparkHoodieBackedTableMetadataWriter.create(hadoopConf, config, context);\n+    try(HoodieTableMetadataWriter writer = SparkHoodieBackedTableMetadataWriter.create(hadoopConf, config, context)) {\n       LOG.info(\"Successfully synced to metadata table\");\n     } catch (Exception e) {\n       throw new HoodieMetadataException(\"Error syncing to metadata table.\", e);\n", "next_change": {"commit": "630f1410aadd947d3f2c9fa0d6a4f69cd67e1c4f", "changed_code": [{"header": "diff --git a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\nindex c68543f1c..255d5d538 100644\n--- a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n+++ b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n", "chunk": "@@ -448,7 +448,7 @@ public class SparkRDDWriteClient<T extends HoodieRecordPayload> extends\n   @Override\n   public void syncTableMetadata() {\n     // Open up the metadata table again, for syncing\n-    try(HoodieTableMetadataWriter writer = SparkHoodieBackedTableMetadataWriter.create(hadoopConf, config, context)) {\n+    try (HoodieTableMetadataWriter writer = SparkHoodieBackedTableMetadataWriter.create(hadoopConf, config, context)) {\n       LOG.info(\"Successfully synced to metadata table\");\n     } catch (Exception e) {\n       throw new HoodieMetadataException(\"Error syncing to metadata table.\", e);\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc1MDAxOQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587750019", "bodyText": "should we recreate? again, we need to revisit this whole passing of metadatawriter to resolve conflict. Don't understand this part", "author": "vinothchandar", "createdAt": "2021-03-04T19:18:19Z", "path": "hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java", "diffHunk": "@@ -401,13 +441,25 @@ protected void completeClustering(HoodieReplaceCommitMetadata metadata, JavaRDD<\n   @Override\n   public void syncTableMetadata() {\n     // Open up the metadata table again, for syncing\n-    try (HoodieTableMetadataWriter writer = SparkHoodieBackedTableMetadataWriter.create(hadoopConf, config, context)) {\n+    try {\n+      HoodieTableMetadataWriter writer =\n+          SparkHoodieBackedTableMetadataWriter.create(hadoopConf, config, context);\n       LOG.info(\"Successfully synced to metadata table\");\n     } catch (Exception e) {\n       throw new HoodieMetadataException(\"Error syncing to metadata table.\", e);\n     }\n   }\n \n+  @Override\n+  protected void preCommit(String instantTime, HoodieCommitMetadata metadata) {\n+    // Create a Hoodie table after startTxn which encapsulated the commits and files visible.\n+    // Important to create this after the lock to ensure latest commits show up in the timeline without need for reload\n+    HoodieTable table = createTable(config, hadoopConf);", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzgzNDIzOA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587834238", "bodyText": "removed the metadtawriter.", "author": "n3nash", "createdAt": "2021-03-04T21:21:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc1MDAxOQ=="}], "type": "inlineReview", "revised_code": {"commit": "b40c06af091472daa40db8bf777bea1f3d06c16c", "changed_code": [{"header": "diff --git a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\nindex e14542ddd..c68543f1c 100644\n--- a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n+++ b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n", "chunk": "@@ -441,9 +448,7 @@ public class SparkRDDWriteClient<T extends HoodieRecordPayload> extends\n   @Override\n   public void syncTableMetadata() {\n     // Open up the metadata table again, for syncing\n-    try {\n-      HoodieTableMetadataWriter writer =\n-          SparkHoodieBackedTableMetadataWriter.create(hadoopConf, config, context);\n+    try(HoodieTableMetadataWriter writer = SparkHoodieBackedTableMetadataWriter.create(hadoopConf, config, context)) {\n       LOG.info(\"Successfully synced to metadata table\");\n     } catch (Exception e) {\n       throw new HoodieMetadataException(\"Error syncing to metadata table.\", e);\n", "next_change": {"commit": "630f1410aadd947d3f2c9fa0d6a4f69cd67e1c4f", "changed_code": [{"header": "diff --git a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\nindex c68543f1c..255d5d538 100644\n--- a/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n+++ b/hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/client/SparkRDDWriteClient.java\n", "chunk": "@@ -448,7 +448,7 @@ public class SparkRDDWriteClient<T extends HoodieRecordPayload> extends\n   @Override\n   public void syncTableMetadata() {\n     // Open up the metadata table again, for syncing\n-    try(HoodieTableMetadataWriter writer = SparkHoodieBackedTableMetadataWriter.create(hadoopConf, config, context)) {\n+    try (HoodieTableMetadataWriter writer = SparkHoodieBackedTableMetadataWriter.create(hadoopConf, config, context)) {\n       LOG.info(\"Successfully synced to metadata table\");\n     } catch (Exception e) {\n       throw new HoodieMetadataException(\"Error syncing to metadata table.\", e);\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc1MTEwMA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587751100", "bodyText": "I think all this can be removed. from all action executors? can't we take the lock in post commit/write from the write client level?", "author": "vinothchandar", "createdAt": "2021-03-04T19:20:00Z", "path": "hudi-client/hudi-spark-client/src/main/java/org/apache/hudi/table/action/bootstrap/SparkBootstrapCommitActionExecutor.java", "diffHunk": "@@ -222,6 +225,17 @@ protected void commit(Option<Map<String, String>> extraMetadata, HoodieWriteMeta\n     LOG.info(\"Committing metadata bootstrap !!\");\n   }\n \n+  @Override\n+  protected void syncTableMetadata() {", "originalCommit": "27bae91298c897984335b1c6c3b39e758d962e6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzg3MDI3Ng==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r587870276", "bodyText": "This is required due to autoCommit code in BaseCommitActionExecutor. We already have to take a lock in BaseCommitActionExecutor for committing the data, instead of taking a lock again in the write client level, I have moved this sync into the same critical section as commit.", "author": "n3nash", "createdAt": "2021-03-04T22:24:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc1MTEwMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODc3MTY5MQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588771691", "bodyText": "can we please file a ticket for removing this auto commit stuff. it's kind of messy.", "author": "vinothchandar", "createdAt": "2021-03-05T22:56:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc1MTEwMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODkxODE0OQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588918149", "bodyText": "https://issues.apache.org/jira/browse/HUDI-1665", "author": "n3nash", "createdAt": "2021-03-06T19:02:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc1MTEwMA=="}], "type": "inlineReview", "revised_code": null}, {"oid": "b40c06af091472daa40db8bf777bea1f3d06c16c", "url": "https://github.com/apache/hudi/commit/b40c06af091472daa40db8bf777bea1f3d06c16c", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services", "committedDate": "2021-03-05T09:21:08Z", "type": "forcePushed"}, {"oid": "c9ded3690d29b22a910eac381001995297084bcb", "url": "https://github.com/apache/hudi/commit/c9ded3690d29b22a910eac381001995297084bcb", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services", "committedDate": "2021-03-05T09:27:17Z", "type": "forcePushed"}, {"oid": "630f1410aadd947d3f2c9fa0d6a4f69cd67e1c4f", "url": "https://github.com/apache/hudi/commit/630f1410aadd947d3f2c9fa0d6a4f69cd67e1c4f", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services", "committedDate": "2021-03-05T18:05:55Z", "type": "forcePushed"}, {"oid": "4dd32416d378254600bd1a810ed6dc0c2dbec2b6", "url": "https://github.com/apache/hudi/commit/4dd32416d378254600bd1a810ed6dc0c2dbec2b6", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services", "committedDate": "2021-03-05T18:37:24Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODY2MjM4Nw==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588662387", "bodyText": "lets file a JIRA for clustering/concurrent updates.", "author": "vinothchandar", "createdAt": "2021-03-05T20:19:47Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java", "diffHunk": "@@ -0,0 +1,105 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.transaction;\n+\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.model.WriteOperationType;\n+import org.apache.hudi.common.table.timeline.HoodieActiveTimeline;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.table.timeline.HoodieTimeline;\n+import org.apache.hudi.common.util.CollectionUtils;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.exception.HoodieWriteConflictException;\n+import org.apache.hudi.table.HoodieTable;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.util.ConcurrentModificationException;\n+import java.util.HashSet;\n+import java.util.Set;\n+import java.util.stream.Stream;\n+\n+import static org.apache.hudi.common.table.timeline.HoodieTimeline.COMPACTION_ACTION;\n+import static org.apache.hudi.common.table.timeline.HoodieTimeline.REPLACE_COMMIT_ACTION;\n+\n+/**\n+ * This class is a basic implementation of a conflict resolution strategy for concurrent writes {@link ConflictResolutionStrategy}.\n+ */\n+public class SimpleConcurrentFileWritesConflictResolutionStrategy\n+    implements ConflictResolutionStrategy {\n+\n+  private static final Logger LOG = LogManager.getLogger(SimpleConcurrentFileWritesConflictResolutionStrategy.class);\n+\n+  @Override\n+  public Stream<HoodieInstant> getCandidateInstants(HoodieActiveTimeline activeTimeline, HoodieInstant currentInstant,\n+                                                 Option<HoodieInstant> lastSuccessfulInstant) {\n+\n+    // To find which instants are conflicting, we apply the following logic\n+    // 1. Get completed instants timeline only for commits that have happened since the last successful write.\n+    // 2. Get any scheduled or completed compaction or clustering operations that have started and/or finished\n+    // after the current instant. We need to check for write conflicts since they may have mutated the same files\n+    // that are being newly created by the current write.\n+    // NOTE that any commits from table services such as compaction, clustering or cleaning since the\n+    // overlapping of files is handled using MVCC.\n+    Stream<HoodieInstant> completedCommitsInstantStream = activeTimeline\n+        .getCommitsTimeline()\n+        .filterCompletedInstants()\n+        .findInstantsAfter(lastSuccessfulInstant.isPresent() ? lastSuccessfulInstant.get().getTimestamp() : HoodieTimeline.INIT_INSTANT_TS)\n+        .getInstants();\n+\n+    Stream<HoodieInstant> compactionAndClusteringTimeline = activeTimeline\n+        .getTimelineOfActions(CollectionUtils.createSet(REPLACE_COMMIT_ACTION, COMPACTION_ACTION))\n+        .findInstantsAfter(currentInstant.getTimestamp())\n+        .getInstants();\n+    return Stream.concat(completedCommitsInstantStream, compactionAndClusteringTimeline);\n+  }\n+\n+  @Override\n+  public boolean hasConflict(HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation) {\n+    // TODO : UUID's can clash even for insert/insert, handle that case.\n+    Set<String> fileIdsSetForFirstInstant = thisOperation.getMutatedFileIds();\n+    Set<String> fileIdsSetForSecondInstant = otherOperation.getMutatedFileIds();\n+    Set<String> intersection = new HashSet<>(fileIdsSetForFirstInstant);\n+    intersection.retainAll(fileIdsSetForSecondInstant);\n+    if (!intersection.isEmpty()) {\n+      LOG.warn(\"Found conflicting writes between first operation = \" + thisOperation\n+          + \", second operation = \" + otherOperation + \" , intersecting file ids \" + intersection);\n+      return true;\n+    }\n+    return false;\n+  }\n+\n+  @Override\n+  public Option<HoodieCommitMetadata> resolveConflict(HoodieTable table,\n+      HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation) {\n+    // Since compaction is eventually written as commit, we need to ensure\n+    // we handle this during conflict resolution and not treat the commit from compaction operation\n+    // as a regular commit. Regular commit, deltacommits and replace are candidates for conflict\n+    // replace is used for a) clustering without update support b) insert_overwrite both of which are\n+    // candidates for conflict. We need to add CLUSTER here once it supports concurrent updates", "originalCommit": "4dd32416d378254600bd1a810ed6dc0c2dbec2b6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODkxNzg1MA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588917850", "bodyText": "There is already one -> https://issues.apache.org/jira/browse/HUDI-1042", "author": "n3nash", "createdAt": "2021-03-06T18:59:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODY2MjM4Nw=="}], "type": "inlineReview", "revised_code": {"commit": "45e931ec410685bcc1ec8dd974560add27dac684", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nindex f4cfd3c22..e7cad4452 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n", "chunk": "@@ -63,22 +63,23 @@ public class SimpleConcurrentFileWritesConflictResolutionStrategy\n         .findInstantsAfter(lastSuccessfulInstant.isPresent() ? lastSuccessfulInstant.get().getTimestamp() : HoodieTimeline.INIT_INSTANT_TS)\n         .getInstants();\n \n-    Stream<HoodieInstant> compactionAndClusteringTimeline = activeTimeline\n+    Stream<HoodieInstant> compactionAndClusteringPendingTimeline = activeTimeline\n         .getTimelineOfActions(CollectionUtils.createSet(REPLACE_COMMIT_ACTION, COMPACTION_ACTION))\n         .findInstantsAfter(currentInstant.getTimestamp())\n+        .filterInflightsAndRequested()\n         .getInstants();\n-    return Stream.concat(completedCommitsInstantStream, compactionAndClusteringTimeline);\n+    return Stream.concat(completedCommitsInstantStream, compactionAndClusteringPendingTimeline);\n   }\n \n   @Override\n-  public boolean hasConflict(HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation) {\n+  public boolean hasConflict(ConcurrentOperation thisOperation, ConcurrentOperation otherOperation) {\n     // TODO : UUID's can clash even for insert/insert, handle that case.\n     Set<String> fileIdsSetForFirstInstant = thisOperation.getMutatedFileIds();\n     Set<String> fileIdsSetForSecondInstant = otherOperation.getMutatedFileIds();\n     Set<String> intersection = new HashSet<>(fileIdsSetForFirstInstant);\n     intersection.retainAll(fileIdsSetForSecondInstant);\n     if (!intersection.isEmpty()) {\n-      LOG.warn(\"Found conflicting writes between first operation = \" + thisOperation\n+      LOG.info(\"Found conflicting writes between first operation = \" + thisOperation\n           + \", second operation = \" + otherOperation + \" , intersecting file ids \" + intersection);\n       return true;\n     }\n", "next_change": {"commit": "1886bbd803f1a51e3d261705dd1283cfa8caf06b", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nindex e7cad4452..938a40684 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n", "chunk": "@@ -55,8 +55,6 @@ public class SimpleConcurrentFileWritesConflictResolutionStrategy\n     // 2. Get any scheduled or completed compaction or clustering operations that have started and/or finished\n     // after the current instant. We need to check for write conflicts since they may have mutated the same files\n     // that are being newly created by the current write.\n-    // NOTE that any commits from table services such as compaction, clustering or cleaning since the\n-    // overlapping of files is handled using MVCC.\n     Stream<HoodieInstant> completedCommitsInstantStream = activeTimeline\n         .getCommitsTimeline()\n         .filterCompletedInstants()\n", "next_change": {"commit": "461047d03e9b7b73b34536ccf290a24f4aada6b0", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nindex 938a40684..e7cad4452 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n", "chunk": "@@ -55,6 +55,8 @@ public class SimpleConcurrentFileWritesConflictResolutionStrategy\n     // 2. Get any scheduled or completed compaction or clustering operations that have started and/or finished\n     // after the current instant. We need to check for write conflicts since they may have mutated the same files\n     // that are being newly created by the current write.\n+    // NOTE that any commits from table services such as compaction, clustering or cleaning since the\n+    // overlapping of files is handled using MVCC.\n     Stream<HoodieInstant> completedCommitsInstantStream = activeTimeline\n         .getCommitsTimeline()\n         .filterCompletedInstants()\n", "next_change": {"commit": "a466320b7537bf2862df853344e80fbd0be6d16a", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nindex e7cad4452..938a40684 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n", "chunk": "@@ -55,8 +55,6 @@ public class SimpleConcurrentFileWritesConflictResolutionStrategy\n     // 2. Get any scheduled or completed compaction or clustering operations that have started and/or finished\n     // after the current instant. We need to check for write conflicts since they may have mutated the same files\n     // that are being newly created by the current write.\n-    // NOTE that any commits from table services such as compaction, clustering or cleaning since the\n-    // overlapping of files is handled using MVCC.\n     Stream<HoodieInstant> completedCommitsInstantStream = activeTimeline\n         .getCommitsTimeline()\n         .filterCompletedInstants()\n", "next_change": null}]}}]}}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nindex f4cfd3c22..e7cad4452 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n", "chunk": "@@ -87,13 +88,14 @@ public class SimpleConcurrentFileWritesConflictResolutionStrategy\n \n   @Override\n   public Option<HoodieCommitMetadata> resolveConflict(HoodieTable table,\n-      HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation) {\n-    // Since compaction is eventually written as commit, we need to ensure\n-    // we handle this during conflict resolution and not treat the commit from compaction operation\n-    // as a regular commit. Regular commit, deltacommits and replace are candidates for conflict\n-    // replace is used for a) clustering without update support b) insert_overwrite both of which are\n-    // candidates for conflict. We need to add CLUSTER here once it supports concurrent updates\n-    // like COMPACT.\n+      ConcurrentOperation thisOperation, ConcurrentOperation otherOperation) {\n+    // A completed COMPACTION action eventually shows up as a COMMIT action on the timeline.\n+    // We need to ensure we handle this during conflict resolution and not treat the commit from a\n+    // compaction operation as a regular commit. Regular commits & deltacommits are candidates for conflict.\n+    // Since the REPLACE action with CLUSTER operation does not support concurrent updates, we have\n+    // to consider it as conflict if we see overlapping file ids. Once concurrent updates are\n+    // supported for CLUSTER (https://issues.apache.org/jira/browse/HUDI-1042),\n+    // add that to the below check so that concurrent updates do not conflict.\n     if (otherOperation.getOperationType() == WriteOperationType.COMPACT\n         && HoodieTimeline.compareTimestamps(otherOperation.getInstantTimestamp(), HoodieTimeline.LESSER_THAN, thisOperation.getInstantTimestamp())) {\n       return thisOperation.getCommitMetadataOption();\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODY3MTU4NQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588671585", "bodyText": "what about async clustering? would it raise an exception? may be it wont today, given its always picks non conflicting files alreayd?", "author": "vinothchandar", "createdAt": "2021-03-05T20:28:54Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java", "diffHunk": "@@ -0,0 +1,105 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.transaction;\n+\n+import org.apache.hudi.common.model.HoodieCommitMetadata;\n+import org.apache.hudi.common.model.WriteOperationType;\n+import org.apache.hudi.common.table.timeline.HoodieActiveTimeline;\n+import org.apache.hudi.common.table.timeline.HoodieInstant;\n+import org.apache.hudi.common.table.timeline.HoodieTimeline;\n+import org.apache.hudi.common.util.CollectionUtils;\n+import org.apache.hudi.common.util.Option;\n+import org.apache.hudi.exception.HoodieWriteConflictException;\n+import org.apache.hudi.table.HoodieTable;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.util.ConcurrentModificationException;\n+import java.util.HashSet;\n+import java.util.Set;\n+import java.util.stream.Stream;\n+\n+import static org.apache.hudi.common.table.timeline.HoodieTimeline.COMPACTION_ACTION;\n+import static org.apache.hudi.common.table.timeline.HoodieTimeline.REPLACE_COMMIT_ACTION;\n+\n+/**\n+ * This class is a basic implementation of a conflict resolution strategy for concurrent writes {@link ConflictResolutionStrategy}.\n+ */\n+public class SimpleConcurrentFileWritesConflictResolutionStrategy\n+    implements ConflictResolutionStrategy {\n+\n+  private static final Logger LOG = LogManager.getLogger(SimpleConcurrentFileWritesConflictResolutionStrategy.class);\n+\n+  @Override\n+  public Stream<HoodieInstant> getCandidateInstants(HoodieActiveTimeline activeTimeline, HoodieInstant currentInstant,\n+                                                 Option<HoodieInstant> lastSuccessfulInstant) {\n+\n+    // To find which instants are conflicting, we apply the following logic\n+    // 1. Get completed instants timeline only for commits that have happened since the last successful write.\n+    // 2. Get any scheduled or completed compaction or clustering operations that have started and/or finished\n+    // after the current instant. We need to check for write conflicts since they may have mutated the same files\n+    // that are being newly created by the current write.\n+    // NOTE that any commits from table services such as compaction, clustering or cleaning since the\n+    // overlapping of files is handled using MVCC.\n+    Stream<HoodieInstant> completedCommitsInstantStream = activeTimeline\n+        .getCommitsTimeline()\n+        .filterCompletedInstants()\n+        .findInstantsAfter(lastSuccessfulInstant.isPresent() ? lastSuccessfulInstant.get().getTimestamp() : HoodieTimeline.INIT_INSTANT_TS)\n+        .getInstants();\n+\n+    Stream<HoodieInstant> compactionAndClusteringTimeline = activeTimeline\n+        .getTimelineOfActions(CollectionUtils.createSet(REPLACE_COMMIT_ACTION, COMPACTION_ACTION))\n+        .findInstantsAfter(currentInstant.getTimestamp())\n+        .getInstants();\n+    return Stream.concat(completedCommitsInstantStream, compactionAndClusteringTimeline);\n+  }\n+\n+  @Override\n+  public boolean hasConflict(HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation) {\n+    // TODO : UUID's can clash even for insert/insert, handle that case.\n+    Set<String> fileIdsSetForFirstInstant = thisOperation.getMutatedFileIds();\n+    Set<String> fileIdsSetForSecondInstant = otherOperation.getMutatedFileIds();\n+    Set<String> intersection = new HashSet<>(fileIdsSetForFirstInstant);\n+    intersection.retainAll(fileIdsSetForSecondInstant);\n+    if (!intersection.isEmpty()) {\n+      LOG.warn(\"Found conflicting writes between first operation = \" + thisOperation\n+          + \", second operation = \" + otherOperation + \" , intersecting file ids \" + intersection);\n+      return true;\n+    }\n+    return false;\n+  }\n+\n+  @Override\n+  public Option<HoodieCommitMetadata> resolveConflict(HoodieTable table,\n+      HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation) {\n+    // Since compaction is eventually written as commit, we need to ensure\n+    // we handle this during conflict resolution and not treat the commit from compaction operation\n+    // as a regular commit. Regular commit, deltacommits and replace are candidates for conflict\n+    // replace is used for a) clustering without update support b) insert_overwrite both of which are\n+    // candidates for conflict. We need to add CLUSTER here once it supports concurrent updates\n+    // like COMPACT.\n+    if (otherOperation.getOperationType() == WriteOperationType.COMPACT", "originalCommit": "4dd32416d378254600bd1a810ed6dc0c2dbec2b6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODY3MjUyNg==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588672526", "bodyText": "I just want to ensure that async clustering can happen, as long as the the files don't overlap.", "author": "vinothchandar", "createdAt": "2021-03-05T20:29:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODY3MTU4NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODkxNzY0Mw==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588917643", "bodyText": "Yes, they will. I have a test case for it as well.", "author": "n3nash", "createdAt": "2021-03-06T18:57:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODY3MTU4NQ=="}], "type": "inlineReview", "revised_code": {"commit": "45e931ec410685bcc1ec8dd974560add27dac684", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nindex f4cfd3c22..e7cad4452 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n", "chunk": "@@ -63,22 +63,23 @@ public class SimpleConcurrentFileWritesConflictResolutionStrategy\n         .findInstantsAfter(lastSuccessfulInstant.isPresent() ? lastSuccessfulInstant.get().getTimestamp() : HoodieTimeline.INIT_INSTANT_TS)\n         .getInstants();\n \n-    Stream<HoodieInstant> compactionAndClusteringTimeline = activeTimeline\n+    Stream<HoodieInstant> compactionAndClusteringPendingTimeline = activeTimeline\n         .getTimelineOfActions(CollectionUtils.createSet(REPLACE_COMMIT_ACTION, COMPACTION_ACTION))\n         .findInstantsAfter(currentInstant.getTimestamp())\n+        .filterInflightsAndRequested()\n         .getInstants();\n-    return Stream.concat(completedCommitsInstantStream, compactionAndClusteringTimeline);\n+    return Stream.concat(completedCommitsInstantStream, compactionAndClusteringPendingTimeline);\n   }\n \n   @Override\n-  public boolean hasConflict(HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation) {\n+  public boolean hasConflict(ConcurrentOperation thisOperation, ConcurrentOperation otherOperation) {\n     // TODO : UUID's can clash even for insert/insert, handle that case.\n     Set<String> fileIdsSetForFirstInstant = thisOperation.getMutatedFileIds();\n     Set<String> fileIdsSetForSecondInstant = otherOperation.getMutatedFileIds();\n     Set<String> intersection = new HashSet<>(fileIdsSetForFirstInstant);\n     intersection.retainAll(fileIdsSetForSecondInstant);\n     if (!intersection.isEmpty()) {\n-      LOG.warn(\"Found conflicting writes between first operation = \" + thisOperation\n+      LOG.info(\"Found conflicting writes between first operation = \" + thisOperation\n           + \", second operation = \" + otherOperation + \" , intersecting file ids \" + intersection);\n       return true;\n     }\n", "next_change": {"commit": "1886bbd803f1a51e3d261705dd1283cfa8caf06b", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nindex e7cad4452..938a40684 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n", "chunk": "@@ -55,8 +55,6 @@ public class SimpleConcurrentFileWritesConflictResolutionStrategy\n     // 2. Get any scheduled or completed compaction or clustering operations that have started and/or finished\n     // after the current instant. We need to check for write conflicts since they may have mutated the same files\n     // that are being newly created by the current write.\n-    // NOTE that any commits from table services such as compaction, clustering or cleaning since the\n-    // overlapping of files is handled using MVCC.\n     Stream<HoodieInstant> completedCommitsInstantStream = activeTimeline\n         .getCommitsTimeline()\n         .filterCompletedInstants()\n", "next_change": {"commit": "461047d03e9b7b73b34536ccf290a24f4aada6b0", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nindex 938a40684..e7cad4452 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n", "chunk": "@@ -55,6 +55,8 @@ public class SimpleConcurrentFileWritesConflictResolutionStrategy\n     // 2. Get any scheduled or completed compaction or clustering operations that have started and/or finished\n     // after the current instant. We need to check for write conflicts since they may have mutated the same files\n     // that are being newly created by the current write.\n+    // NOTE that any commits from table services such as compaction, clustering or cleaning since the\n+    // overlapping of files is handled using MVCC.\n     Stream<HoodieInstant> completedCommitsInstantStream = activeTimeline\n         .getCommitsTimeline()\n         .filterCompletedInstants()\n", "next_change": {"commit": "a466320b7537bf2862df853344e80fbd0be6d16a", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nindex e7cad4452..938a40684 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n", "chunk": "@@ -55,8 +55,6 @@ public class SimpleConcurrentFileWritesConflictResolutionStrategy\n     // 2. Get any scheduled or completed compaction or clustering operations that have started and/or finished\n     // after the current instant. We need to check for write conflicts since they may have mutated the same files\n     // that are being newly created by the current write.\n-    // NOTE that any commits from table services such as compaction, clustering or cleaning since the\n-    // overlapping of files is handled using MVCC.\n     Stream<HoodieInstant> completedCommitsInstantStream = activeTimeline\n         .getCommitsTimeline()\n         .filterCompletedInstants()\n", "next_change": null}]}}]}}]}}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\nindex f4cfd3c22..e7cad4452 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/SimpleConcurrentFileWritesConflictResolutionStrategy.java\n", "chunk": "@@ -87,13 +88,14 @@ public class SimpleConcurrentFileWritesConflictResolutionStrategy\n \n   @Override\n   public Option<HoodieCommitMetadata> resolveConflict(HoodieTable table,\n-      HoodieCommitOperation thisOperation, HoodieCommitOperation otherOperation) {\n-    // Since compaction is eventually written as commit, we need to ensure\n-    // we handle this during conflict resolution and not treat the commit from compaction operation\n-    // as a regular commit. Regular commit, deltacommits and replace are candidates for conflict\n-    // replace is used for a) clustering without update support b) insert_overwrite both of which are\n-    // candidates for conflict. We need to add CLUSTER here once it supports concurrent updates\n-    // like COMPACT.\n+      ConcurrentOperation thisOperation, ConcurrentOperation otherOperation) {\n+    // A completed COMPACTION action eventually shows up as a COMMIT action on the timeline.\n+    // We need to ensure we handle this during conflict resolution and not treat the commit from a\n+    // compaction operation as a regular commit. Regular commits & deltacommits are candidates for conflict.\n+    // Since the REPLACE action with CLUSTER operation does not support concurrent updates, we have\n+    // to consider it as conflict if we see overlapping file ids. Once concurrent updates are\n+    // supported for CLUSTER (https://issues.apache.org/jira/browse/HUDI-1042),\n+    // add that to the below check so that concurrent updates do not conflict.\n     if (otherOperation.getOperationType() == WriteOperationType.COMPACT\n         && HoodieTimeline.compareTimestamps(otherOperation.getInstantTimestamp(), HoodieTimeline.LESSER_THAN, thisOperation.getInstantTimestamp())) {\n       return thisOperation.getCommitMetadataOption();\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODY3OTM5MA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588679390", "bodyText": "a better validation message, than just the enum name?  (applicable for any such usage)", "author": "vinothchandar", "createdAt": "2021-03-05T20:37:12Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java", "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.transaction.lock;\n+\n+import org.apache.curator.framework.CuratorFramework;\n+import org.apache.curator.framework.CuratorFrameworkFactory;\n+import org.apache.curator.framework.imps.CuratorFrameworkState;\n+import org.apache.curator.framework.recipes.locks.InterProcessMutex;\n+import org.apache.curator.retry.BoundedExponentialBackoffRetry;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.hudi.common.lock.LockProvider;\n+import org.apache.hudi.common.lock.LockState;\n+import org.apache.hudi.common.util.StringUtils;\n+import org.apache.hudi.common.util.ValidationUtils;\n+import org.apache.hudi.exception.HoodieLockException;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_CONNECTION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_SESSION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_NUM_RETRIES_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_BASE_PATH_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECTION_TIMEOUT_MS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECT_URL_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_LOCK_KEY_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_SESSION_TIMEOUT_MS_PROP;\n+\n+/**\n+ * A zookeeper based lock. This {@link LockProvider} implementation allows to lock table operations\n+ * using zookeeper. Users need to have a Zookeeper cluster deployed to be able to use this lock.\n+ */\n+@NotThreadSafe\n+public class ZookeeperBasedLockProvider extends LockProvider {\n+\n+  private static final Logger LOG = LogManager.getLogger(ZookeeperBasedLockProvider.class);\n+\n+  private final CuratorFramework curatorFrameworkClient;\n+  private volatile InterProcessMutex lock = null;\n+\n+  public ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration, final Configuration conf) {\n+    checkRequiredProps(lockConfiguration);\n+    this.lockConfiguration = lockConfiguration;\n+    this.curatorFrameworkClient = CuratorFrameworkFactory.builder()\n+        .connectString(lockConfiguration.getConfig().getString(ZK_CONNECT_URL_PROP))\n+        .retryPolicy(new BoundedExponentialBackoffRetry(lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP),\n+            5000, lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_NUM_RETRIES_PROP)))\n+        .sessionTimeoutMs(lockConfiguration.getConfig().getInteger(ZK_SESSION_TIMEOUT_MS_PROP, DEFAULT_ZK_SESSION_TIMEOUT_MS))\n+        .connectionTimeoutMs(lockConfiguration.getConfig().getInteger(ZK_CONNECTION_TIMEOUT_MS_PROP, DEFAULT_ZK_CONNECTION_TIMEOUT_MS))\n+        .build();\n+    this.curatorFrameworkClient.start();\n+  }\n+\n+  // Only used for testing\n+  public ZookeeperBasedLockProvider(\n+      final LockConfiguration lockConfiguration, final CuratorFramework curatorFrameworkClient) {\n+    checkRequiredProps(lockConfiguration);\n+    this.lockConfiguration = lockConfiguration;\n+    this.curatorFrameworkClient = curatorFrameworkClient;\n+    synchronized (this.curatorFrameworkClient) {\n+      if (this.curatorFrameworkClient.getState() != CuratorFrameworkState.STARTED) {\n+        this.curatorFrameworkClient.start();\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public boolean tryLock(long time, TimeUnit unit) {\n+    LOG.info(generateLogStatement(LockState.ACQUIRING, generateLogSuffixString()));\n+    try {\n+      acquireLock(time, unit);\n+      LOG.info(generateLogStatement(LockState.ACQUIRED, generateLogSuffixString()));\n+    } catch (Exception e) {\n+      throw new HoodieLockException(generateLogStatement(LockState.FAILED_TO_ACQUIRE, generateLogSuffixString()), e);\n+    }\n+    return lock != null && lock.isAcquiredInThisProcess();\n+  }\n+\n+  @Override\n+  public void unlock() {\n+    try {\n+      LOG.info(generateLogStatement(LockState.RELEASING, generateLogSuffixString()));\n+      if (lock == null || !lock.isAcquiredInThisProcess()) {\n+        return;\n+      }\n+      lock.release();\n+      lock = null;\n+      LOG.info(generateLogStatement(LockState.RELEASED, generateLogSuffixString()));\n+    } catch (Exception e) {\n+      throw new HoodieLockException(generateLogStatement(LockState.FAILED_TO_RELEASE, generateLogSuffixString()), e);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    try {\n+      if (lock != null) {\n+        lock.release();\n+        lock = null;\n+      }\n+      this.curatorFrameworkClient.close();\n+    } catch (Exception e) {\n+      LOG.error(generateLogStatement(LockState.FAILED_TO_RELEASE, generateLogSuffixString()));\n+    }\n+  }\n+\n+  @Override\n+  public InterProcessMutex getLock() {\n+    return this.lock;\n+  }\n+\n+  private void acquireLock(long time, TimeUnit unit) throws Exception {\n+    ValidationUtils.checkArgument(this.lock == null, LockState.ALREADY_ACQUIRED.name());", "originalCommit": "4dd32416d378254600bd1a810ed6dc0c2dbec2b6", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "45e931ec410685bcc1ec8dd974560add27dac684", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nindex 5e7ec67fe..60336c53e 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -51,12 +51,13 @@ import static org.apache.hudi.common.config.LockConfiguration.ZK_SESSION_TIMEOUT\n  * using zookeeper. Users need to have a Zookeeper cluster deployed to be able to use this lock.\n  */\n @NotThreadSafe\n-public class ZookeeperBasedLockProvider extends LockProvider {\n+public class ZookeeperBasedLockProvider implements LockProvider<InterProcessMutex> {\n \n   private static final Logger LOG = LogManager.getLogger(ZookeeperBasedLockProvider.class);\n \n   private final CuratorFramework curatorFrameworkClient;\n   private volatile InterProcessMutex lock = null;\n+  protected LockConfiguration lockConfiguration;\n \n   public ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration, final Configuration conf) {\n     checkRequiredProps(lockConfiguration);\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nindex 5e7ec67fe..60336c53e 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -90,6 +91,8 @@ public class ZookeeperBasedLockProvider extends LockProvider {\n     try {\n       acquireLock(time, unit);\n       LOG.info(generateLogStatement(LockState.ACQUIRED, generateLogSuffixString()));\n+    } catch (HoodieLockException e) {\n+      throw e;\n     } catch (Exception e) {\n       throw new HoodieLockException(generateLogStatement(LockState.FAILED_TO_ACQUIRE, generateLogSuffixString()), e);\n     }\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nindex 5e7ec67fe..60336c53e 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -130,7 +133,7 @@ public class ZookeeperBasedLockProvider extends LockProvider {\n   }\n \n   private void acquireLock(long time, TimeUnit unit) throws Exception {\n-    ValidationUtils.checkArgument(this.lock == null, LockState.ALREADY_ACQUIRED.name());\n+    ValidationUtils.checkArgument(this.lock == null, generateLogStatement(LockState.ALREADY_ACQUIRED, generateLogSuffixString()));\n     InterProcessMutex newLock = new InterProcessMutex(\n         this.curatorFrameworkClient, lockConfiguration.getConfig().getString(ZK_BASE_PATH_PROP) + \"/\"\n         + this.lockConfiguration.getConfig().getString(ZK_LOCK_KEY_PROP));\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nindex 5e7ec67fe..60336c53e 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -158,4 +161,8 @@ public class ZookeeperBasedLockProvider extends LockProvider {\n     String lockKey = this.lockConfiguration.getConfig().getString(ZK_LOCK_KEY_PROP);\n     return StringUtils.join(\"ZkBasePath = \", zkBasePath, \", lock key = \", lockKey);\n   }\n+\n+  protected String generateLogStatement(LockState state, String suffix) {\n+    return StringUtils.join(state.name(), \" lock at\", suffix);\n+  }\n }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODY4MTU1NA==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588681554", "bodyText": "this will lead to a LockException being wrapped inside another LockException in tryLock()?", "author": "vinothchandar", "createdAt": "2021-03-05T20:39:28Z", "path": "hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java", "diffHunk": "@@ -0,0 +1,161 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.client.transaction.lock;\n+\n+import org.apache.curator.framework.CuratorFramework;\n+import org.apache.curator.framework.CuratorFrameworkFactory;\n+import org.apache.curator.framework.imps.CuratorFrameworkState;\n+import org.apache.curator.framework.recipes.locks.InterProcessMutex;\n+import org.apache.curator.retry.BoundedExponentialBackoffRetry;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.hudi.common.lock.LockProvider;\n+import org.apache.hudi.common.lock.LockState;\n+import org.apache.hudi.common.util.StringUtils;\n+import org.apache.hudi.common.util.ValidationUtils;\n+import org.apache.hudi.exception.HoodieLockException;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import javax.annotation.concurrent.NotThreadSafe;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_CONNECTION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.DEFAULT_ZK_SESSION_TIMEOUT_MS;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_NUM_RETRIES_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_BASE_PATH_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECTION_TIMEOUT_MS_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_CONNECT_URL_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_LOCK_KEY_PROP;\n+import static org.apache.hudi.common.config.LockConfiguration.ZK_SESSION_TIMEOUT_MS_PROP;\n+\n+/**\n+ * A zookeeper based lock. This {@link LockProvider} implementation allows to lock table operations\n+ * using zookeeper. Users need to have a Zookeeper cluster deployed to be able to use this lock.\n+ */\n+@NotThreadSafe\n+public class ZookeeperBasedLockProvider extends LockProvider {\n+\n+  private static final Logger LOG = LogManager.getLogger(ZookeeperBasedLockProvider.class);\n+\n+  private final CuratorFramework curatorFrameworkClient;\n+  private volatile InterProcessMutex lock = null;\n+\n+  public ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration, final Configuration conf) {\n+    checkRequiredProps(lockConfiguration);\n+    this.lockConfiguration = lockConfiguration;\n+    this.curatorFrameworkClient = CuratorFrameworkFactory.builder()\n+        .connectString(lockConfiguration.getConfig().getString(ZK_CONNECT_URL_PROP))\n+        .retryPolicy(new BoundedExponentialBackoffRetry(lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_RETRY_WAIT_TIME_IN_MILLIS_PROP),\n+            5000, lockConfiguration.getConfig().getInteger(LOCK_ACQUIRE_NUM_RETRIES_PROP)))\n+        .sessionTimeoutMs(lockConfiguration.getConfig().getInteger(ZK_SESSION_TIMEOUT_MS_PROP, DEFAULT_ZK_SESSION_TIMEOUT_MS))\n+        .connectionTimeoutMs(lockConfiguration.getConfig().getInteger(ZK_CONNECTION_TIMEOUT_MS_PROP, DEFAULT_ZK_CONNECTION_TIMEOUT_MS))\n+        .build();\n+    this.curatorFrameworkClient.start();\n+  }\n+\n+  // Only used for testing\n+  public ZookeeperBasedLockProvider(\n+      final LockConfiguration lockConfiguration, final CuratorFramework curatorFrameworkClient) {\n+    checkRequiredProps(lockConfiguration);\n+    this.lockConfiguration = lockConfiguration;\n+    this.curatorFrameworkClient = curatorFrameworkClient;\n+    synchronized (this.curatorFrameworkClient) {\n+      if (this.curatorFrameworkClient.getState() != CuratorFrameworkState.STARTED) {\n+        this.curatorFrameworkClient.start();\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public boolean tryLock(long time, TimeUnit unit) {\n+    LOG.info(generateLogStatement(LockState.ACQUIRING, generateLogSuffixString()));\n+    try {\n+      acquireLock(time, unit);\n+      LOG.info(generateLogStatement(LockState.ACQUIRED, generateLogSuffixString()));\n+    } catch (Exception e) {\n+      throw new HoodieLockException(generateLogStatement(LockState.FAILED_TO_ACQUIRE, generateLogSuffixString()), e);\n+    }\n+    return lock != null && lock.isAcquiredInThisProcess();\n+  }\n+\n+  @Override\n+  public void unlock() {\n+    try {\n+      LOG.info(generateLogStatement(LockState.RELEASING, generateLogSuffixString()));\n+      if (lock == null || !lock.isAcquiredInThisProcess()) {\n+        return;\n+      }\n+      lock.release();\n+      lock = null;\n+      LOG.info(generateLogStatement(LockState.RELEASED, generateLogSuffixString()));\n+    } catch (Exception e) {\n+      throw new HoodieLockException(generateLogStatement(LockState.FAILED_TO_RELEASE, generateLogSuffixString()), e);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    try {\n+      if (lock != null) {\n+        lock.release();\n+        lock = null;\n+      }\n+      this.curatorFrameworkClient.close();\n+    } catch (Exception e) {\n+      LOG.error(generateLogStatement(LockState.FAILED_TO_RELEASE, generateLogSuffixString()));\n+    }\n+  }\n+\n+  @Override\n+  public InterProcessMutex getLock() {\n+    return this.lock;\n+  }\n+\n+  private void acquireLock(long time, TimeUnit unit) throws Exception {\n+    ValidationUtils.checkArgument(this.lock == null, LockState.ALREADY_ACQUIRED.name());\n+    InterProcessMutex newLock = new InterProcessMutex(\n+        this.curatorFrameworkClient, lockConfiguration.getConfig().getString(ZK_BASE_PATH_PROP) + \"/\"\n+        + this.lockConfiguration.getConfig().getString(ZK_LOCK_KEY_PROP));\n+    boolean acquired = newLock.acquire(time, unit);\n+    if (!acquired) {\n+      throw new HoodieLockException(generateLogStatement(LockState.FAILED_TO_ACQUIRE, generateLogSuffixString()));", "originalCommit": "4dd32416d378254600bd1a810ed6dc0c2dbec2b6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODY4MjE3OQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588682179", "bodyText": "Can we handle this specially and just rethrow the lock exception without the wrapping.", "author": "vinothchandar", "createdAt": "2021-03-05T20:40:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODY4MTU1NA=="}], "type": "inlineReview", "revised_code": {"commit": "45e931ec410685bcc1ec8dd974560add27dac684", "changed_code": [{"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nindex 5e7ec67fe..60336c53e 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -51,12 +51,13 @@ import static org.apache.hudi.common.config.LockConfiguration.ZK_SESSION_TIMEOUT\n  * using zookeeper. Users need to have a Zookeeper cluster deployed to be able to use this lock.\n  */\n @NotThreadSafe\n-public class ZookeeperBasedLockProvider extends LockProvider {\n+public class ZookeeperBasedLockProvider implements LockProvider<InterProcessMutex> {\n \n   private static final Logger LOG = LogManager.getLogger(ZookeeperBasedLockProvider.class);\n \n   private final CuratorFramework curatorFrameworkClient;\n   private volatile InterProcessMutex lock = null;\n+  protected LockConfiguration lockConfiguration;\n \n   public ZookeeperBasedLockProvider(final LockConfiguration lockConfiguration, final Configuration conf) {\n     checkRequiredProps(lockConfiguration);\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nindex 5e7ec67fe..60336c53e 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -90,6 +91,8 @@ public class ZookeeperBasedLockProvider extends LockProvider {\n     try {\n       acquireLock(time, unit);\n       LOG.info(generateLogStatement(LockState.ACQUIRED, generateLogSuffixString()));\n+    } catch (HoodieLockException e) {\n+      throw e;\n     } catch (Exception e) {\n       throw new HoodieLockException(generateLogStatement(LockState.FAILED_TO_ACQUIRE, generateLogSuffixString()), e);\n     }\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nindex 5e7ec67fe..60336c53e 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -130,7 +133,7 @@ public class ZookeeperBasedLockProvider extends LockProvider {\n   }\n \n   private void acquireLock(long time, TimeUnit unit) throws Exception {\n-    ValidationUtils.checkArgument(this.lock == null, LockState.ALREADY_ACQUIRED.name());\n+    ValidationUtils.checkArgument(this.lock == null, generateLogStatement(LockState.ALREADY_ACQUIRED, generateLogSuffixString()));\n     InterProcessMutex newLock = new InterProcessMutex(\n         this.curatorFrameworkClient, lockConfiguration.getConfig().getString(ZK_BASE_PATH_PROP) + \"/\"\n         + this.lockConfiguration.getConfig().getString(ZK_LOCK_KEY_PROP));\n", "next_change": null}, {"header": "diff --git a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\nindex 5e7ec67fe..60336c53e 100644\n--- a/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n+++ b/hudi-client/hudi-client-common/src/main/java/org/apache/hudi/client/transaction/lock/ZookeeperBasedLockProvider.java\n", "chunk": "@@ -158,4 +161,8 @@ public class ZookeeperBasedLockProvider extends LockProvider {\n     String lockKey = this.lockConfiguration.getConfig().getString(ZK_LOCK_KEY_PROP);\n     return StringUtils.join(\"ZkBasePath = \", zkBasePath, \", lock key = \", lockKey);\n   }\n+\n+  protected String generateLogStatement(LockState state, String suffix) {\n+    return StringUtils.join(state.name(), \" lock at\", suffix);\n+  }\n }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODc3NTE2Mw==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588775163", "bodyText": "is this a recursive call? won't it recurse infinitely?", "author": "vinothchandar", "createdAt": "2021-03-05T23:06:34Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java", "diffHunk": "@@ -0,0 +1,86 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.lock;\n+\n+import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.hudi.common.util.StringUtils;\n+import org.apache.hudi.exception.HoodieLockException;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.Condition;\n+import java.util.concurrent.locks.Lock;\n+\n+/**\n+ * Pluggable lock implementations using this provider class.\n+ */\n+public abstract class LockProvider<T> implements Lock, AutoCloseable {\n+\n+  private static final Logger LOG = LogManager.getLogger(LockProvider.class);\n+\n+  protected LockConfiguration lockConfiguration;\n+\n+  @Override\n+  public final void lockInterruptibly() {\n+    throw new UnsupportedOperationException();\n+  }\n+\n+  @Override\n+  public final void lock() {\n+    throw new UnsupportedOperationException();\n+  }\n+\n+  @Override\n+  public final boolean tryLock() {\n+    throw new UnsupportedOperationException();\n+  }\n+\n+  @Override\n+  public boolean tryLock(long time, TimeUnit unit) {\n+    try {\n+      return tryLock(time, unit);\n+    } catch (Exception e) {\n+      throw new HoodieLockException(e);\n+    }\n+  }\n+\n+  public T getLock() {\n+    throw new UnsupportedOperationException();\n+  }\n+\n+  @Override\n+  public final Condition newCondition() {\n+    throw new UnsupportedOperationException();\n+  }\n+\n+  @Override\n+  public void close() {\n+    try {\n+      close();", "originalCommit": "4dd32416d378254600bd1a810ed6dc0c2dbec2b6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODg1NzQ5Mw==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588857493", "bodyText": "Intended to super.close()", "author": "n3nash", "createdAt": "2021-03-06T09:13:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODc3NTE2Mw=="}], "type": "inlineReview", "revised_code": {"commit": "45e931ec410685bcc1ec8dd974560add27dac684", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\nindex 4784ffda4..e5cf51691 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n", "chunk": "@@ -18,69 +18,35 @@\n \n package org.apache.hudi.common.lock;\n \n-import org.apache.hudi.common.config.LockConfiguration;\n-import org.apache.hudi.common.util.StringUtils;\n-import org.apache.hudi.exception.HoodieLockException;\n-import org.apache.log4j.LogManager;\n-import org.apache.log4j.Logger;\n-\n-import java.util.concurrent.TimeUnit;\n import java.util.concurrent.locks.Condition;\n import java.util.concurrent.locks.Lock;\n \n /**\n  * Pluggable lock implementations using this provider class.\n  */\n-public abstract class LockProvider<T> implements Lock, AutoCloseable {\n-\n-  private static final Logger LOG = LogManager.getLogger(LockProvider.class);\n-\n-  protected LockConfiguration lockConfiguration;\n+public interface LockProvider<T> extends Lock, AutoCloseable {\n \n   @Override\n-  public final void lockInterruptibly() {\n+  default void lockInterruptibly() {\n     throw new UnsupportedOperationException();\n   }\n \n   @Override\n-  public final void lock() {\n+  default void lock() {\n     throw new UnsupportedOperationException();\n   }\n \n   @Override\n-  public final boolean tryLock() {\n+  default boolean tryLock() {\n     throw new UnsupportedOperationException();\n   }\n \n   @Override\n-  public boolean tryLock(long time, TimeUnit unit) {\n-    try {\n-      return tryLock(time, unit);\n-    } catch (Exception e) {\n-      throw new HoodieLockException(e);\n-    }\n-  }\n-\n-  public T getLock() {\n+  default Condition newCondition() {\n     throw new UnsupportedOperationException();\n   }\n \n-  @Override\n-  public final Condition newCondition() {\n-    throw new UnsupportedOperationException();\n+  default T getLock() {\n+    throw new IllegalArgumentException();\n   }\n-\n-  @Override\n-  public void close() {\n-    try {\n-      close();\n-    } catch (Exception e) {\n-      LOG.error(e);\n-    }\n-  }\n-\n-  protected String generateLogStatement(LockState state, String suffix) {\n-    return StringUtils.join(state.name(), \" lock at\", suffix);\n-  }\n-\n }\n", "next_change": {"commit": "1b41b773c6bb94ac28609bf829e875cefce6e5d3", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\nindex e5cf51691..7d8e52738 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n", "chunk": "@@ -49,4 +49,8 @@ public interface LockProvider<T> extends Lock, AutoCloseable {\n   default T getLock() {\n     throw new IllegalArgumentException();\n   }\n+\n+  @Override\n+  default void close() {\n+  }\n }\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODc3NTI2Nw==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588775267", "bodyText": "same here. infinite loop?", "author": "vinothchandar", "createdAt": "2021-03-05T23:06:50Z", "path": "hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java", "diffHunk": "@@ -0,0 +1,86 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hudi.common.lock;\n+\n+import org.apache.hudi.common.config.LockConfiguration;\n+import org.apache.hudi.common.util.StringUtils;\n+import org.apache.hudi.exception.HoodieLockException;\n+import org.apache.log4j.LogManager;\n+import org.apache.log4j.Logger;\n+\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.Condition;\n+import java.util.concurrent.locks.Lock;\n+\n+/**\n+ * Pluggable lock implementations using this provider class.\n+ */\n+public abstract class LockProvider<T> implements Lock, AutoCloseable {\n+\n+  private static final Logger LOG = LogManager.getLogger(LockProvider.class);\n+\n+  protected LockConfiguration lockConfiguration;\n+\n+  @Override\n+  public final void lockInterruptibly() {\n+    throw new UnsupportedOperationException();\n+  }\n+\n+  @Override\n+  public final void lock() {\n+    throw new UnsupportedOperationException();\n+  }\n+\n+  @Override\n+  public final boolean tryLock() {\n+    throw new UnsupportedOperationException();\n+  }\n+\n+  @Override\n+  public boolean tryLock(long time, TimeUnit unit) {\n+    try {\n+      return tryLock(time, unit);", "originalCommit": "4dd32416d378254600bd1a810ed6dc0c2dbec2b6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODg1NzQ5OQ==", "url": "https://github.com/apache/hudi/pull/2374#discussion_r588857499", "bodyText": "same as above", "author": "n3nash", "createdAt": "2021-03-06T09:13:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4ODc3NTI2Nw=="}], "type": "inlineReview", "revised_code": {"commit": "45e931ec410685bcc1ec8dd974560add27dac684", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\nindex 4784ffda4..e5cf51691 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n", "chunk": "@@ -18,69 +18,35 @@\n \n package org.apache.hudi.common.lock;\n \n-import org.apache.hudi.common.config.LockConfiguration;\n-import org.apache.hudi.common.util.StringUtils;\n-import org.apache.hudi.exception.HoodieLockException;\n-import org.apache.log4j.LogManager;\n-import org.apache.log4j.Logger;\n-\n-import java.util.concurrent.TimeUnit;\n import java.util.concurrent.locks.Condition;\n import java.util.concurrent.locks.Lock;\n \n /**\n  * Pluggable lock implementations using this provider class.\n  */\n-public abstract class LockProvider<T> implements Lock, AutoCloseable {\n-\n-  private static final Logger LOG = LogManager.getLogger(LockProvider.class);\n-\n-  protected LockConfiguration lockConfiguration;\n+public interface LockProvider<T> extends Lock, AutoCloseable {\n \n   @Override\n-  public final void lockInterruptibly() {\n+  default void lockInterruptibly() {\n     throw new UnsupportedOperationException();\n   }\n \n   @Override\n-  public final void lock() {\n+  default void lock() {\n     throw new UnsupportedOperationException();\n   }\n \n   @Override\n-  public final boolean tryLock() {\n+  default boolean tryLock() {\n     throw new UnsupportedOperationException();\n   }\n \n   @Override\n-  public boolean tryLock(long time, TimeUnit unit) {\n-    try {\n-      return tryLock(time, unit);\n-    } catch (Exception e) {\n-      throw new HoodieLockException(e);\n-    }\n-  }\n-\n-  public T getLock() {\n+  default Condition newCondition() {\n     throw new UnsupportedOperationException();\n   }\n \n-  @Override\n-  public final Condition newCondition() {\n-    throw new UnsupportedOperationException();\n+  default T getLock() {\n+    throw new IllegalArgumentException();\n   }\n-\n-  @Override\n-  public void close() {\n-    try {\n-      close();\n-    } catch (Exception e) {\n-      LOG.error(e);\n-    }\n-  }\n-\n-  protected String generateLogStatement(LockState state, String suffix) {\n-    return StringUtils.join(state.name(), \" lock at\", suffix);\n-  }\n-\n }\n", "next_change": {"commit": "1b41b773c6bb94ac28609bf829e875cefce6e5d3", "changed_code": [{"header": "diff --git a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\nindex e5cf51691..7d8e52738 100644\n--- a/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n+++ b/hudi-common/src/main/java/org/apache/hudi/common/lock/LockProvider.java\n", "chunk": "@@ -49,4 +49,8 @@ public interface LockProvider<T> extends Lock, AutoCloseable {\n   default T getLock() {\n     throw new IllegalArgumentException();\n   }\n+\n+  @Override\n+  default void close() {\n+  }\n }\n", "next_change": null}]}}]}}, {"oid": "45e931ec410685bcc1ec8dd974560add27dac684", "url": "https://github.com/apache/hudi/commit/45e931ec410685bcc1ec8dd974560add27dac684", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services", "committedDate": "2021-03-07T00:29:12Z", "type": "forcePushed"}, {"oid": "1b41b773c6bb94ac28609bf829e875cefce6e5d3", "url": "https://github.com/apache/hudi/commit/1b41b773c6bb94ac28609bf829e875cefce6e5d3", "message": "refactor 2", "committedDate": "2021-03-10T08:08:24Z", "type": "forcePushed"}, {"oid": "8cb6bd09678f320038a36b1d84e3b5739fab0a2e", "url": "https://github.com/apache/hudi/commit/8cb6bd09678f320038a36b1d84e3b5739fab0a2e", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services", "committedDate": "2021-03-11T06:03:11Z", "type": "forcePushed"}, {"oid": "c7323ada211503eae62842f5f2eb31769da2b8bc", "url": "https://github.com/apache/hudi/commit/c7323ada211503eae62842f5f2eb31769da2b8bc", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methodologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services\n4. Added Transaction Manager for wrapping actions within transactions", "committedDate": "2021-03-11T07:19:41Z", "type": "forcePushed"}, {"oid": "4888b0f34bbd8a6a55628e517f7e2db8a23ef59c", "url": "https://github.com/apache/hudi/commit/4888b0f34bbd8a6a55628e517f7e2db8a23ef59c", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methodologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services\n4. Added Transaction Manager for wrapping actions within transactions", "committedDate": "2021-03-11T07:28:06Z", "type": "forcePushed"}, {"oid": "9c678ffebf5e065f66f5bc0989b6af829fb3723c", "url": "https://github.com/apache/hudi/commit/9c678ffebf5e065f66f5bc0989b6af829fb3723c", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methodologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services\n4. Added Transaction Manager for wrapping actions within transactions", "committedDate": "2021-03-11T07:39:28Z", "type": "forcePushed"}, {"oid": "1b522ef9c2fec7a32c7a1bfae2039e8f07a60d8f", "url": "https://github.com/apache/hudi/commit/1b522ef9c2fec7a32c7a1bfae2039e8f07a60d8f", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methodologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services\n4. Added Transaction Manager for wrapping actions within transactions", "committedDate": "2021-03-11T19:51:16Z", "type": "forcePushed"}, {"oid": "8b50f955609cf85d32aefc47734a50b011c99339", "url": "https://github.com/apache/hudi/commit/8b50f955609cf85d32aefc47734a50b011c99339", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methodologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services\n4. Added Transaction Manager for wrapping actions within transactions", "committedDate": "2021-03-11T20:37:00Z", "type": "forcePushed"}, {"oid": "02efbb661e7ed13c3614ddee7ab5157623070f7c", "url": "https://github.com/apache/hudi/commit/02efbb661e7ed13c3614ddee7ab5157623070f7c", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methodologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services\n4. Added Transaction Manager for wrapping actions within transactions", "committedDate": "2021-03-12T06:50:43Z", "type": "forcePushed"}, {"oid": "b5c5c987c5fbf8e83ffac9288260ed2242b59c18", "url": "https://github.com/apache/hudi/commit/b5c5c987c5fbf8e83ffac9288260ed2242b59c18", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methodologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services\n4. Added Transaction Manager for wrapping actions within transactions", "committedDate": "2021-03-12T08:08:26Z", "type": "forcePushed"}, {"oid": "47403db3c55938e97a8e9baa21f65d6d09c04ee9", "url": "https://github.com/apache/hudi/commit/47403db3c55938e97a8e9baa21f65d6d09c04ee9", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methodologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services\n4. Added Transaction Manager for wrapping actions within transactions", "committedDate": "2021-03-12T20:04:14Z", "type": "forcePushed"}, {"oid": "99b341e7ae369b856926b129e1f4e89215cc0f49", "url": "https://github.com/apache/hudi/commit/99b341e7ae369b856926b129e1f4e89215cc0f49", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methodologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services\n4. Added Transaction Manager for wrapping actions within transactions", "committedDate": "2021-03-12T20:29:30Z", "type": "forcePushed"}, {"oid": "1886bbd803f1a51e3d261705dd1283cfa8caf06b", "url": "https://github.com/apache/hudi/commit/1886bbd803f1a51e3d261705dd1283cfa8caf06b", "message": "Adding MultiWriter tests for DeltaStreamer", "committedDate": "2021-03-14T09:15:43Z", "type": "forcePushed"}, {"oid": "01577fda0944e2cb710f0907965ca8e602650f8a", "url": "https://github.com/apache/hudi/commit/01577fda0944e2cb710f0907965ca8e602650f8a", "message": "Adding MultiWriter tests for DeltaStreamer", "committedDate": "2021-03-14T09:21:38Z", "type": "forcePushed"}, {"oid": "4e029d324c4ea812ec09acb2a3bcd487b2d35eb8", "url": "https://github.com/apache/hudi/commit/4e029d324c4ea812ec09acb2a3bcd487b2d35eb8", "message": "Adding MultiWriter tests for DeltaStreamer", "committedDate": "2021-03-14T22:19:49Z", "type": "forcePushed"}, {"oid": "9278889bad4fe529a7c403857f20bcd0198322e6", "url": "https://github.com/apache/hudi/commit/9278889bad4fe529a7c403857f20bcd0198322e6", "message": "Adding MultiWriter tests for DeltaStreamer", "committedDate": "2021-03-15T04:02:32Z", "type": "forcePushed"}, {"oid": "461047d03e9b7b73b34536ccf290a24f4aada6b0", "url": "https://github.com/apache/hudi/commit/461047d03e9b7b73b34536ccf290a24f4aada6b0", "message": "[HUDI-845] Added locking capability to allow multiple writers\n1. Added LockProvider API for pluggable lock methodologies\n2. Added Resolution Strategy API to allow for pluggable conflict resolution\n3. Added TableService client API to schedule table services\n4. Added Transaction Manager for wrapping actions within transactions", "committedDate": "2021-03-15T04:06:27Z", "type": "commit"}, {"oid": "a466320b7537bf2862df853344e80fbd0be6d16a", "url": "https://github.com/apache/hudi/commit/a466320b7537bf2862df853344e80fbd0be6d16a", "message": "Adding tests for Deltastreamer and fixing some documentation", "committedDate": "2021-03-15T04:09:56Z", "type": "forcePushed"}, {"oid": "8c092be25de58e65cd339478e9b2c0ba37d20e5e", "url": "https://github.com/apache/hudi/commit/8c092be25de58e65cd339478e9b2c0ba37d20e5e", "message": "Adding tests for Deltastreamer and fixing some documentation", "committedDate": "2021-03-15T04:24:30Z", "type": "forcePushed"}, {"oid": "bbb02ab5c74551803f8003900d066d056646c951", "url": "https://github.com/apache/hudi/commit/bbb02ab5c74551803f8003900d066d056646c951", "message": "Adding tests for Deltastreamer and fixing some documentation", "committedDate": "2021-03-15T04:28:59Z", "type": "forcePushed"}, {"oid": "d47718945d2ad86eb653daafc03f1f74a57b6881", "url": "https://github.com/apache/hudi/commit/d47718945d2ad86eb653daafc03f1f74a57b6881", "message": "Adding tests for Deltastreamer and fixing some documentation", "committedDate": "2021-03-15T06:02:56Z", "type": "forcePushed"}, {"oid": "2a305dc45a1a175ebb07c96b9a9e8c698088283e", "url": "https://github.com/apache/hudi/commit/2a305dc45a1a175ebb07c96b9a9e8c698088283e", "message": "Adding tests for Deltastreamer and fixing some documentation", "committedDate": "2021-03-15T07:13:01Z", "type": "forcePushed"}, {"oid": "f7685b4a61f6b7a7b641af778497b06349e75256", "url": "https://github.com/apache/hudi/commit/f7685b4a61f6b7a7b641af778497b06349e75256", "message": "Adding tests for Deltastreamer and fixing some documentation", "committedDate": "2021-03-15T07:31:36Z", "type": "forcePushed"}, {"oid": "bcc0f5baddc3eefad510441865cbf40a44c9a719", "url": "https://github.com/apache/hudi/commit/bcc0f5baddc3eefad510441865cbf40a44c9a719", "message": "Adding tests for Deltastreamer, fixing some documentation and added metadata overriding", "committedDate": "2021-03-16T07:14:38Z", "type": "forcePushed"}, {"oid": "0e7fbb3ab8c02fbaee04adfc89205d6bee0834ab", "url": "https://github.com/apache/hudi/commit/0e7fbb3ab8c02fbaee04adfc89205d6bee0834ab", "message": "Adding tests for Deltastreamer, fixing some documentation and added metadata overriding", "committedDate": "2021-03-16T17:30:02Z", "type": "commit"}, {"oid": "0e7fbb3ab8c02fbaee04adfc89205d6bee0834ab", "url": "https://github.com/apache/hudi/commit/0e7fbb3ab8c02fbaee04adfc89205d6bee0834ab", "message": "Adding tests for Deltastreamer, fixing some documentation and added metadata overriding", "committedDate": "2021-03-16T17:30:02Z", "type": "forcePushed"}]}