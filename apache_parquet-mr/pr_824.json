{"pr_number": 824, "pr_title": "PARQUET-1920: Fix Parquet writer's memory check interval calculation", "pr_author": "SinghAsDev", "pr_createdAt": "2020-10-07T22:24:05Z", "pr_url": "https://github.com/apache/parquet-mr/pull/824", "timeline": [{"oid": "f7bcc4a64fbb4a23e6f6c5b97dd31f11f15b4c05", "url": "https://github.com/apache/parquet-mr/commit/f7bcc4a64fbb4a23e6f6c5b97dd31f11f15b4c05", "message": "Fix Parquet writer's memory check interval calculation, and throw helpful message while dealing with too large column chunks.", "committedDate": "2020-10-07T22:05:51Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTc3MzkyMQ==", "url": "https://github.com/apache/parquet-mr/pull/824#discussion_r501773921", "body": "nit:\r\n```suggestion\r\n      throw new IOException(\"Page size, \" + size + \", is larger than allowed \" + Integer.MAX_VALUE + \".\" +\r\n        \" Usually caused by a Parquet writer writing too big column chunks on encountering highly skewed dataset.\" +\r\n        \" Please set page.size.row.check.max to a lower value on the writer, default value is 10000.\" +\r\n        \" You can try setting it to \" + (10000 / (size / Integer.MAX_VALUE)) + \" or lower.\");\r\n```", "bodyText": "nit:\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  throw new IOException(\"Page size, \" + size + \", is larger than allowed \" + Integer.MAX_VALUE +\".\" +\n          \n          \n            \n                    \" Usually caused by a Parquet writer writing too big column chunks on encountering highly skewed dataset.\" +\n          \n          \n            \n                    \" Please set page.size.row.check.max to a lower value on the writer, default value is 10000.\" +\n          \n          \n            \n                    \" You can try setting it to \" + (10000 / (size/ Integer.MAX_VALUE)) + \" or lower.\");\n          \n          \n            \n                  throw new IOException(\"Page size, \" + size + \", is larger than allowed \" + Integer.MAX_VALUE + \".\" +\n          \n          \n            \n                    \" Usually caused by a Parquet writer writing too big column chunks on encountering highly skewed dataset.\" +\n          \n          \n            \n                    \" Please set page.size.row.check.max to a lower value on the writer, default value is 10000.\" +\n          \n          \n            \n                    \" You can try setting it to \" + (10000 / (size / Integer.MAX_VALUE)) + \" or lower.\");", "bodyHTML": "<p dir=\"auto\">nit:</p>\n  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">      <span class=\"pl-k\">throw</span> <span class=\"pl-k\">new</span> <span class=\"pl-smi\">IOException</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Page size, <span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">+</span> size <span class=\"pl-k\">+</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>, is larger than allowed <span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">+</span> <span class=\"pl-smi\">Integer</span><span class=\"pl-c1\"><span class=\"pl-k\">.</span>MAX_VALUE</span> <span class=\"pl-k\">+</span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>.<span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">+</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">        <span class=\"pl-s\"><span class=\"pl-pds\">\"</span> Usually caused by a Parquet writer writing too big column chunks on encountering highly skewed dataset.<span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">+</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">        <span class=\"pl-s\"><span class=\"pl-pds\">\"</span> Please set page.size.row.check.max to a lower value on the writer, default value is 10000.<span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">+</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">        <span class=\"pl-s\"><span class=\"pl-pds\">\"</span> You can try setting it to <span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">+</span> (<span class=\"pl-c1\">10000</span> <span class=\"pl-k\">/</span> (size<span class=\"pl-k\">/</span> <span class=\"pl-smi\">Integer</span><span class=\"pl-c1\"><span class=\"pl-k\">.</span>MAX_VALUE</span>)) <span class=\"pl-k\">+</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span> or lower.<span class=\"pl-pds\">\"</span></span>);</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">      <span class=\"pl-k\">throw</span> <span class=\"pl-k\">new</span> <span class=\"pl-smi\">IOException</span>(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Page size, <span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">+</span> size <span class=\"pl-k\">+</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>, is larger than allowed <span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">+</span> <span class=\"pl-smi\">Integer</span><span class=\"pl-c1\"><span class=\"pl-k\">.</span>MAX_VALUE</span> <span class=\"pl-k\">+</span><span class=\"x x-first x-last\"> </span><span class=\"pl-s\"><span class=\"pl-pds\">\"</span>.<span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">+</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">        <span class=\"pl-s\"><span class=\"pl-pds\">\"</span> Usually caused by a Parquet writer writing too big column chunks on encountering highly skewed dataset.<span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">+</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">        <span class=\"pl-s\"><span class=\"pl-pds\">\"</span> Please set page.size.row.check.max to a lower value on the writer, default value is 10000.<span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">+</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">        <span class=\"pl-s\"><span class=\"pl-pds\">\"</span> You can try setting it to <span class=\"pl-pds\">\"</span></span> <span class=\"pl-k\">+</span> (<span class=\"pl-c1\">10000</span> <span class=\"pl-k\">/</span> (size<span class=\"x x-first x-last\"> </span><span class=\"pl-k\">/</span> <span class=\"pl-smi\">Integer</span><span class=\"pl-c1\"><span class=\"pl-k\">.</span>MAX_VALUE</span>)) <span class=\"pl-k\">+</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span> or lower.<span class=\"pl-pds\">\"</span></span>);</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "gszadovszky", "createdAt": "2020-10-08T14:37:51Z", "path": "parquet-common/src/main/java/org/apache/parquet/bytes/BytesInput.java", "diffHunk": "@@ -215,6 +215,13 @@ public static BytesInput copy(BytesInput bytesInput) throws IOException {\n    * @throws IOException if there is an exception reading\n    */\n   public byte[] toByteArray() throws IOException {\n+    long size = size();\n+    if (size > Integer.MAX_VALUE) {\n+      throw new IOException(\"Page size, \" + size + \", is larger than allowed \" + Integer.MAX_VALUE +\".\" +\n+        \" Usually caused by a Parquet writer writing too big column chunks on encountering highly skewed dataset.\" +\n+        \" Please set page.size.row.check.max to a lower value on the writer, default value is 10000.\" +\n+        \" You can try setting it to \" + (10000 / (size/ Integer.MAX_VALUE)) + \" or lower.\");", "originalCommit": "f7bcc4a64fbb4a23e6f6c5b97dd31f11f15b4c05", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "4806f5df9f20f7b60c8ba6d25b15c38277bfe6db", "url": "https://github.com/apache/parquet-mr/commit/4806f5df9f20f7b60c8ba6d25b15c38277bfe6db", "message": "Update parquet-common/src/main/java/org/apache/parquet/bytes/BytesInput.java\n\nCo-authored-by: Gabor Szadovszky <gabor@apache.org>", "committedDate": "2020-10-08T14:56:04Z", "type": "commit"}]}