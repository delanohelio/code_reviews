{"pr_number": 936, "pr_title": "Moved RecordFileParser file system logic to RecordFilePoller", "pr_createdAt": "2020-08-07T02:02:21Z", "pr_url": "https://github.com/hashgraph/hedera-mirror-node/pull/936", "merge_commit": "0ebf5ce7665af79a3a3e2498b60bd5159a139a7d", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzA5NDI5MA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467094290", "body": "This sort can be removed since it's already sorted above.", "bodyText": "This sort can be removed since it's already sorted above.", "bodyHTML": "<p dir=\"auto\">This sort can be removed since it's already sorted above.</p>", "author": "steven-sheehy", "createdAt": "2020-08-07T14:57:55Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java", "diffHunk": "@@ -0,0 +1,121 @@\n+package com.hedera.mirror.importer.parser.record;\n+\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ * \u200b\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ * \u200b\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileNotFoundException;\n+import java.io.InputStream;\n+import java.nio.file.Path;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import javax.inject.Named;\n+import lombok.AllArgsConstructor;\n+import lombok.extern.log4j.Log4j2;\n+import org.apache.commons.io.FileUtils;\n+import org.springframework.scheduling.annotation.Scheduled;\n+\n+import com.hedera.mirror.importer.exception.DuplicateFileException;\n+import com.hedera.mirror.importer.parser.FilePoller;\n+import com.hedera.mirror.importer.parser.domain.StreamFileData;\n+import com.hedera.mirror.importer.util.ShutdownHelper;\n+import com.hedera.mirror.importer.util.Utility;\n+\n+@Log4j2\n+@Named\n+@ConditionalOnRecordParser\n+@AllArgsConstructor\n+public class RecordFilePoller implements FilePoller {\n+\n+    private final RecordParserProperties parserProperties;\n+    private final RecordFileParser recordFileParser;\n+\n+    @Override\n+    @Scheduled(fixedRateString = \"${hedera.mirror.importer.parser.record.frequency:100}\")\n+    public void poll() {\n+        if (ShutdownHelper.isStopping()) {\n+            return;\n+        }\n+        Path path = parserProperties.getValidPath();\n+        log.debug(\"Parsing record files from {}\", path);\n+        try {\n+            File file = path.toFile();\n+            if (file.isDirectory()) {\n+\n+                String[] files = file.list();\n+                Arrays.sort(files);           // sorted by name (timestamp)\n+\n+                // add directory prefix to get full path\n+                List<String> fullPaths = Arrays.asList(files).stream()\n+                        .map(s -> file + \"/\" + s)\n+                        .collect(Collectors.toList());\n+\n+                if (fullPaths != null && fullPaths.size() != 0) {\n+                    log.trace(\"Processing record files: {}\", fullPaths);\n+                    loadRecordFiles(fullPaths);\n+                } else {\n+                    log.debug(\"No files to parse\");\n+                }\n+            } else {\n+                log.error(\"Input parameter is not a folder: {}\", path);\n+            }\n+        } catch (Exception e) {\n+            log.error(\"Error parsing files\", e);\n+        }\n+    }\n+\n+    /**\n+     * read and parse a list of record files\n+     *\n+     * @throws Exception\n+     */\n+    private void loadRecordFiles(List<String> filePaths) {\n+        Collections.sort(filePaths);", "originalCommit": "482f49fce85efd2655cd1826898083f8a8a0ec05", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzY3NjAyOA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467676028", "bodyText": "Removed", "author": "Nana-EC", "createdAt": "2020-08-10T03:47:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzA5NDI5MA=="}], "type": "inlineReview", "revised_code": {"commit": "2ba305984f72c15a7c9551fbc3c82369f518b883", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\nindex e7aa09328..a5bfaf202 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n", "chunk": "@@ -89,17 +85,18 @@ public class RecordFilePoller implements FilePoller {\n      *\n      * @throws Exception\n      */\n-    private void loadRecordFiles(List<String> filePaths) {\n-        Collections.sort(filePaths);\n+    private void loadRecordFiles(String[] filePaths) {\n+        Path validPath = parserProperties.getValidPath();\n         for (String filePath : filePaths) {\n             if (ShutdownHelper.isStopping()) {\n                 return;\n             }\n \n-            File file = new File(filePath);\n+            // get file from full path\n+            File file = validPath.resolve(filePath).toFile();\n \n             try (InputStream fileInputStream = new FileInputStream(file)) {\n-                recordFileParser.parse(new StreamFileData(filePath, fileInputStream));\n+                recordFileParser.parse(new StreamFileData(file.getAbsolutePath(), fileInputStream));\n \n                 if (parserProperties.isKeepFiles()) {\n                     Utility.archiveFile(file, parserProperties.getParsedPath());\n", "next_change": null}]}, "revised_code_in_main": {"commit": "0ebf5ce7665af79a3a3e2498b60bd5159a139a7d", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\nindex e7aa09328..d5b6bf905 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n", "chunk": "@@ -89,17 +81,18 @@ public class RecordFilePoller implements FilePoller {\n      *\n      * @throws Exception\n      */\n-    private void loadRecordFiles(List<String> filePaths) {\n-        Collections.sort(filePaths);\n+    private void loadRecordFiles(String[] filePaths) {\n+        Path validPath = parserProperties.getValidPath();\n         for (String filePath : filePaths) {\n             if (ShutdownHelper.isStopping()) {\n                 return;\n             }\n \n-            File file = new File(filePath);\n+            // get file from full path\n+            File file = validPath.resolve(filePath).toFile();\n \n             try (InputStream fileInputStream = new FileInputStream(file)) {\n-                recordFileParser.parse(new StreamFileData(filePath, fileInputStream));\n+                recordFileParser.parse(new StreamFileData(file.getAbsolutePath(), fileInputStream));\n \n                 if (parserProperties.isKeepFiles()) {\n                     Utility.archiveFile(file, parserProperties.getParsedPath());\n", "next_change": {"commit": "a56ea83364b2c8e38746a5a5048555dad80741d3", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\nindex d5b6bf905..d11a9f4e6 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n", "chunk": "@@ -91,19 +88,16 @@ public class RecordFilePoller implements FilePoller {\n             // get file from full path\n             File file = validPath.resolve(filePath).toFile();\n \n-            try (InputStream fileInputStream = new FileInputStream(file)) {\n-                recordFileParser.parse(new StreamFileData(file.getAbsolutePath(), fileInputStream));\n+            try {\n+                recordFileParser.parse(StreamFileData.from(file));\n \n                 if (parserProperties.isKeepFiles()) {\n                     Utility.archiveFile(file, parserProperties.getParsedPath());\n                 } else {\n                     FileUtils.deleteQuietly(file);\n                 }\n-            } catch (FileNotFoundException e) {\n-                log.warn(\"File does not exist {}\", filePath);\n-                return;\n             } catch (Exception e) {\n-                log.error(String.format(\"Error parsing file %s\", filePath), e);\n+                log.error(\"Error parsing file {}\", filePath, e);\n                 return;\n             }\n         }\n", "next_change": {"commit": "776d39ad57ee5647dbc899964a71777d420dfd55", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\ndeleted file mode 100644\nindex d11a9f4e6..000000000\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n+++ /dev/null\n", "chunk": "@@ -1,105 +0,0 @@\n-package com.hedera.mirror.importer.parser.record;\n-\n-/*-\n- * \u200c\n- * Hedera Mirror Node\n- * \u200b\n- * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n- * \u200b\n- * Licensed under the Apache License, Version 2.0 (the \"License\");\n- * you may not use this file except in compliance with the License.\n- * You may obtain a copy of the License at\n- *\n- *      http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- * \u200d\n- */\n-\n-import java.io.File;\n-import java.nio.file.Path;\n-import java.util.Arrays;\n-import javax.inject.Named;\n-import lombok.AllArgsConstructor;\n-import lombok.extern.log4j.Log4j2;\n-import org.apache.commons.io.FileUtils;\n-import org.springframework.scheduling.annotation.Scheduled;\n-\n-import com.hedera.mirror.importer.domain.StreamFileData;\n-import com.hedera.mirror.importer.parser.FilePoller;\n-import com.hedera.mirror.importer.util.ShutdownHelper;\n-import com.hedera.mirror.importer.util.Utility;\n-\n-@Log4j2\n-@Named\n-@ConditionalOnRecordParser\n-@AllArgsConstructor\n-public class RecordFilePoller implements FilePoller {\n-\n-    private final RecordParserProperties parserProperties;\n-    private final RecordFileParser recordFileParser;\n-\n-    @Override\n-    @Scheduled(fixedDelayString = \"${hedera.mirror.importer.parser.record.frequency:100}\")\n-    public void poll() {\n-        if (ShutdownHelper.isStopping()) {\n-            return;\n-        }\n-        Path path = parserProperties.getValidPath();\n-        log.debug(\"Parsing record files from {}\", path);\n-        try {\n-            File file = path.toFile();\n-            if (file.isDirectory()) {\n-\n-                String[] files = file.list();\n-                if (files == null || files.length == 0) {\n-                    log.debug(\"No files to parse in directory {}\", file.getPath());\n-                    return;\n-                }\n-\n-                Arrays.sort(files);           // sorted by name (timestamp)\n-\n-                log.trace(\"Processing record files: {}\", files);\n-                loadRecordFiles(files);\n-            } else {\n-                log.error(\"Input parameter is not a folder: {}\", path);\n-            }\n-        } catch (Exception e) {\n-            log.error(\"Error parsing files\", e);\n-        }\n-    }\n-\n-    /**\n-     * read and parse a list of record files\n-     *\n-     * @throws Exception\n-     */\n-    private void loadRecordFiles(String[] filePaths) {\n-        Path validPath = parserProperties.getValidPath();\n-        for (String filePath : filePaths) {\n-            if (ShutdownHelper.isStopping()) {\n-                return;\n-            }\n-\n-            // get file from full path\n-            File file = validPath.resolve(filePath).toFile();\n-\n-            try {\n-                recordFileParser.parse(StreamFileData.from(file));\n-\n-                if (parserProperties.isKeepFiles()) {\n-                    Utility.archiveFile(file, parserProperties.getParsedPath());\n-                } else {\n-                    FileUtils.deleteQuietly(file);\n-                }\n-            } catch (Exception e) {\n-                log.error(\"Error parsing file {}\", filePath, e);\n-                return;\n-            }\n-        }\n-    }\n-}\n", "next_change": null}]}}]}}]}, "commits_in_main": [{"oid": "0ebf5ce7665af79a3a3e2498b60bd5159a139a7d", "message": "Merge commit", "committedDate": null}, {"oid": "0a06a359fce5a4e11473cd00fab46bd463ab4748", "committedDate": "2020-09-16 13:39:52 -0500", "message": "Fix polling cloud storage more often than the configured poll period (#1054)"}, {"oid": "a7d4932eb9ea4621d184f40c095857f456e7a496", "committedDate": "2020-11-19 17:35:21 -0600", "message": "Enable log alerts and normalize log statements (#1279)"}, {"oid": "a56ea83364b2c8e38746a5a5048555dad80741d3", "committedDate": "2021-01-05 09:24:38 -0600", "message": "Refactor Record File Reader (#1382)"}, {"oid": "4e6dcf6013cd1efe285cd38178c332ce46d00a80", "committedDate": "2021-01-11 10:42:50 -0600", "message": "Update copyright to 2021 (#1425)"}, {"oid": "ca396a7102a011d9eda5aacec0f814c54ab25a71", "committedDate": "2021-01-27 21:52:21 -0600", "message": "Fix whitespace in license header (#1509)"}, {"oid": "776d39ad57ee5647dbc899964a71777d420dfd55", "committedDate": "2021-02-18 16:38:32 -0600", "message": "Remove filesystem dependency (#1554)"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzA5NjAwNQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467096005", "body": "This can return null. We should return here if so.", "bodyText": "This can return null. We should return here if so.", "bodyHTML": "<p dir=\"auto\">This can return null. We should return here if so.</p>", "author": "steven-sheehy", "createdAt": "2020-08-07T15:00:50Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java", "diffHunk": "@@ -0,0 +1,121 @@\n+package com.hedera.mirror.importer.parser.record;\n+\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ * \u200b\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ * \u200b\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileNotFoundException;\n+import java.io.InputStream;\n+import java.nio.file.Path;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import javax.inject.Named;\n+import lombok.AllArgsConstructor;\n+import lombok.extern.log4j.Log4j2;\n+import org.apache.commons.io.FileUtils;\n+import org.springframework.scheduling.annotation.Scheduled;\n+\n+import com.hedera.mirror.importer.exception.DuplicateFileException;\n+import com.hedera.mirror.importer.parser.FilePoller;\n+import com.hedera.mirror.importer.parser.domain.StreamFileData;\n+import com.hedera.mirror.importer.util.ShutdownHelper;\n+import com.hedera.mirror.importer.util.Utility;\n+\n+@Log4j2\n+@Named\n+@ConditionalOnRecordParser\n+@AllArgsConstructor\n+public class RecordFilePoller implements FilePoller {\n+\n+    private final RecordParserProperties parserProperties;\n+    private final RecordFileParser recordFileParser;\n+\n+    @Override\n+    @Scheduled(fixedRateString = \"${hedera.mirror.importer.parser.record.frequency:100}\")\n+    public void poll() {\n+        if (ShutdownHelper.isStopping()) {\n+            return;\n+        }\n+        Path path = parserProperties.getValidPath();\n+        log.debug(\"Parsing record files from {}\", path);\n+        try {\n+            File file = path.toFile();\n+            if (file.isDirectory()) {\n+\n+                String[] files = file.list();", "originalCommit": "482f49fce85efd2655cd1826898083f8a8a0ec05", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzY3NjA0Mg==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467676042", "bodyText": "Added", "author": "Nana-EC", "createdAt": "2020-08-10T03:47:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzA5NjAwNQ=="}], "type": "inlineReview", "revised_code": {"commit": "2ba305984f72c15a7c9551fbc3c82369f518b883", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\nindex e7aa09328..a5bfaf202 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n", "chunk": "@@ -63,16 +59,16 @@ public class RecordFilePoller implements FilePoller {\n             if (file.isDirectory()) {\n \n                 String[] files = file.list();\n-                Arrays.sort(files);           // sorted by name (timestamp)\n+                if (files == null) {\n+                    log.debug(\"No files found in directory {}\", file.getPath());\n+                    return;\n+                }\n \n-                // add directory prefix to get full path\n-                List<String> fullPaths = Arrays.asList(files).stream()\n-                        .map(s -> file + \"/\" + s)\n-                        .collect(Collectors.toList());\n+                Arrays.sort(files);           // sorted by name (timestamp)\n \n-                if (fullPaths != null && fullPaths.size() != 0) {\n-                    log.trace(\"Processing record files: {}\", fullPaths);\n-                    loadRecordFiles(fullPaths);\n+                if (files.length != 0) {\n+                    log.trace(\"Processing record files: {}\", files);\n+                    loadRecordFiles(files);\n                 } else {\n                     log.debug(\"No files to parse\");\n                 }\n", "next_change": {"commit": "72492b10ad6b2e5e0fb0b9f2c18f738433dff64a", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\nindex a5bfaf202..c5b137b70 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n", "chunk": "@@ -59,19 +59,15 @@ public class RecordFilePoller implements FilePoller {\n             if (file.isDirectory()) {\n \n                 String[] files = file.list();\n-                if (files == null) {\n-                    log.debug(\"No files found in directory {}\", file.getPath());\n+                if (files == null || files.length == 0) {\n+                    log.debug(\"No files to parse in directory {}\", file.getPath());\n                     return;\n                 }\n \n                 Arrays.sort(files);           // sorted by name (timestamp)\n \n-                if (files.length != 0) {\n-                    log.trace(\"Processing record files: {}\", files);\n-                    loadRecordFiles(files);\n-                } else {\n-                    log.debug(\"No files to parse\");\n-                }\n+                log.trace(\"Processing record files: {}\", files);\n+                loadRecordFiles(files);\n             } else {\n                 log.error(\"Input parameter is not a folder: {}\", path);\n             }\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzA5NjY4NA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467096684", "body": "It would be more efficient to not loop over the files twice: once here and once again in `loadRecordFiles()`. Better to just add the valid path inside the loop in loadRecordFiles.", "bodyText": "It would be more efficient to not loop over the files twice: once here and once again in loadRecordFiles(). Better to just add the valid path inside the loop in loadRecordFiles.", "bodyHTML": "<p dir=\"auto\">It would be more efficient to not loop over the files twice: once here and once again in <code>loadRecordFiles()</code>. Better to just add the valid path inside the loop in loadRecordFiles.</p>", "author": "steven-sheehy", "createdAt": "2020-08-07T15:02:00Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java", "diffHunk": "@@ -0,0 +1,121 @@\n+package com.hedera.mirror.importer.parser.record;\n+\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ * \u200b\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ * \u200b\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileNotFoundException;\n+import java.io.InputStream;\n+import java.nio.file.Path;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import javax.inject.Named;\n+import lombok.AllArgsConstructor;\n+import lombok.extern.log4j.Log4j2;\n+import org.apache.commons.io.FileUtils;\n+import org.springframework.scheduling.annotation.Scheduled;\n+\n+import com.hedera.mirror.importer.exception.DuplicateFileException;\n+import com.hedera.mirror.importer.parser.FilePoller;\n+import com.hedera.mirror.importer.parser.domain.StreamFileData;\n+import com.hedera.mirror.importer.util.ShutdownHelper;\n+import com.hedera.mirror.importer.util.Utility;\n+\n+@Log4j2\n+@Named\n+@ConditionalOnRecordParser\n+@AllArgsConstructor\n+public class RecordFilePoller implements FilePoller {\n+\n+    private final RecordParserProperties parserProperties;\n+    private final RecordFileParser recordFileParser;\n+\n+    @Override\n+    @Scheduled(fixedRateString = \"${hedera.mirror.importer.parser.record.frequency:100}\")\n+    public void poll() {\n+        if (ShutdownHelper.isStopping()) {\n+            return;\n+        }\n+        Path path = parserProperties.getValidPath();\n+        log.debug(\"Parsing record files from {}\", path);\n+        try {\n+            File file = path.toFile();\n+            if (file.isDirectory()) {\n+\n+                String[] files = file.list();\n+                Arrays.sort(files);           // sorted by name (timestamp)\n+\n+                // add directory prefix to get full path\n+                List<String> fullPaths = Arrays.asList(files).stream()\n+                        .map(s -> file + \"/\" + s)", "originalCommit": "482f49fce85efd2655cd1826898083f8a8a0ec05", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzY3NjA0Ng==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467676046", "bodyText": "Agreed, removed this additional loop.", "author": "Nana-EC", "createdAt": "2020-08-10T03:47:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzA5NjY4NA=="}], "type": "inlineReview", "revised_code": {"commit": "2ba305984f72c15a7c9551fbc3c82369f518b883", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\nindex e7aa09328..a5bfaf202 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n", "chunk": "@@ -63,16 +59,16 @@ public class RecordFilePoller implements FilePoller {\n             if (file.isDirectory()) {\n \n                 String[] files = file.list();\n-                Arrays.sort(files);           // sorted by name (timestamp)\n+                if (files == null) {\n+                    log.debug(\"No files found in directory {}\", file.getPath());\n+                    return;\n+                }\n \n-                // add directory prefix to get full path\n-                List<String> fullPaths = Arrays.asList(files).stream()\n-                        .map(s -> file + \"/\" + s)\n-                        .collect(Collectors.toList());\n+                Arrays.sort(files);           // sorted by name (timestamp)\n \n-                if (fullPaths != null && fullPaths.size() != 0) {\n-                    log.trace(\"Processing record files: {}\", fullPaths);\n-                    loadRecordFiles(fullPaths);\n+                if (files.length != 0) {\n+                    log.trace(\"Processing record files: {}\", files);\n+                    loadRecordFiles(files);\n                 } else {\n                     log.debug(\"No files to parse\");\n                 }\n", "next_change": {"commit": "72492b10ad6b2e5e0fb0b9f2c18f738433dff64a", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\nindex a5bfaf202..c5b137b70 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n", "chunk": "@@ -59,19 +59,15 @@ public class RecordFilePoller implements FilePoller {\n             if (file.isDirectory()) {\n \n                 String[] files = file.list();\n-                if (files == null) {\n-                    log.debug(\"No files found in directory {}\", file.getPath());\n+                if (files == null || files.length == 0) {\n+                    log.debug(\"No files to parse in directory {}\", file.getPath());\n                     return;\n                 }\n \n                 Arrays.sort(files);           // sorted by name (timestamp)\n \n-                if (files.length != 0) {\n-                    log.trace(\"Processing record files: {}\", files);\n-                    loadRecordFiles(files);\n-                } else {\n-                    log.debug(\"No files to parse\");\n-                }\n+                log.trace(\"Processing record files: {}\", files);\n+                loadRecordFiles(files);\n             } else {\n                 log.error(\"Input parameter is not a folder: {}\", path);\n             }\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzA5OTY4MQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467099681", "body": "Can we change to use `validPath.resolve(s)` here so it's Windows compatible?", "bodyText": "Can we change to use validPath.resolve(s) here so it's Windows compatible?", "bodyHTML": "<p dir=\"auto\">Can we change to use <code>validPath.resolve(s)</code> here so it's Windows compatible?</p>", "author": "steven-sheehy", "createdAt": "2020-08-07T15:07:22Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java", "diffHunk": "@@ -0,0 +1,121 @@\n+package com.hedera.mirror.importer.parser.record;\n+\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ * \u200b\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ * \u200b\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileNotFoundException;\n+import java.io.InputStream;\n+import java.nio.file.Path;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import javax.inject.Named;\n+import lombok.AllArgsConstructor;\n+import lombok.extern.log4j.Log4j2;\n+import org.apache.commons.io.FileUtils;\n+import org.springframework.scheduling.annotation.Scheduled;\n+\n+import com.hedera.mirror.importer.exception.DuplicateFileException;\n+import com.hedera.mirror.importer.parser.FilePoller;\n+import com.hedera.mirror.importer.parser.domain.StreamFileData;\n+import com.hedera.mirror.importer.util.ShutdownHelper;\n+import com.hedera.mirror.importer.util.Utility;\n+\n+@Log4j2\n+@Named\n+@ConditionalOnRecordParser\n+@AllArgsConstructor\n+public class RecordFilePoller implements FilePoller {\n+\n+    private final RecordParserProperties parserProperties;\n+    private final RecordFileParser recordFileParser;\n+\n+    @Override\n+    @Scheduled(fixedRateString = \"${hedera.mirror.importer.parser.record.frequency:100}\")\n+    public void poll() {\n+        if (ShutdownHelper.isStopping()) {\n+            return;\n+        }\n+        Path path = parserProperties.getValidPath();\n+        log.debug(\"Parsing record files from {}\", path);\n+        try {\n+            File file = path.toFile();\n+            if (file.isDirectory()) {\n+\n+                String[] files = file.list();\n+                Arrays.sort(files);           // sorted by name (timestamp)\n+\n+                // add directory prefix to get full path\n+                List<String> fullPaths = Arrays.asList(files).stream()\n+                        .map(s -> file + \"/\" + s)", "originalCommit": "482f49fce85efd2655cd1826898083f8a8a0ec05", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzY3NjA1Mw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467676053", "bodyText": "No need here as this list creation was removed. Added it when creating the File in loadRecordFiles()", "author": "Nana-EC", "createdAt": "2020-08-10T03:47:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzA5OTY4MQ=="}], "type": "inlineReview", "revised_code": {"commit": "2ba305984f72c15a7c9551fbc3c82369f518b883", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\nindex e7aa09328..a5bfaf202 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n", "chunk": "@@ -63,16 +59,16 @@ public class RecordFilePoller implements FilePoller {\n             if (file.isDirectory()) {\n \n                 String[] files = file.list();\n-                Arrays.sort(files);           // sorted by name (timestamp)\n+                if (files == null) {\n+                    log.debug(\"No files found in directory {}\", file.getPath());\n+                    return;\n+                }\n \n-                // add directory prefix to get full path\n-                List<String> fullPaths = Arrays.asList(files).stream()\n-                        .map(s -> file + \"/\" + s)\n-                        .collect(Collectors.toList());\n+                Arrays.sort(files);           // sorted by name (timestamp)\n \n-                if (fullPaths != null && fullPaths.size() != 0) {\n-                    log.trace(\"Processing record files: {}\", fullPaths);\n-                    loadRecordFiles(fullPaths);\n+                if (files.length != 0) {\n+                    log.trace(\"Processing record files: {}\", files);\n+                    loadRecordFiles(files);\n                 } else {\n                     log.debug(\"No files to parse\");\n                 }\n", "next_change": {"commit": "72492b10ad6b2e5e0fb0b9f2c18f738433dff64a", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\nindex a5bfaf202..c5b137b70 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n", "chunk": "@@ -59,19 +59,15 @@ public class RecordFilePoller implements FilePoller {\n             if (file.isDirectory()) {\n \n                 String[] files = file.list();\n-                if (files == null) {\n-                    log.debug(\"No files found in directory {}\", file.getPath());\n+                if (files == null || files.length == 0) {\n+                    log.debug(\"No files to parse in directory {}\", file.getPath());\n                     return;\n                 }\n \n                 Arrays.sort(files);           // sorted by name (timestamp)\n \n-                if (files.length != 0) {\n-                    log.trace(\"Processing record files: {}\", files);\n-                    loadRecordFiles(files);\n-                } else {\n-                    log.debug(\"No files to parse\");\n-                }\n+                log.trace(\"Processing record files: {}\", files);\n+                loadRecordFiles(files);\n             } else {\n                 log.error(\"Input parameter is not a folder: {}\", path);\n             }\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzEwNzgwMQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467107801", "body": "As order is very important here and this approach does not verify that, we should use `InOrder` mock to verify files are processed in order.", "bodyText": "As order is very important here and this approach does not verify that, we should use InOrder mock to verify files are processed in order.", "bodyHTML": "<p dir=\"auto\">As order is very important here and this approach does not verify that, we should use <code>InOrder</code> mock to verify files are processed in order.</p>", "author": "steven-sheehy", "createdAt": "2020-08-07T15:21:38Z", "path": "hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java", "diffHunk": "@@ -0,0 +1,168 @@\n+package com.hedera.mirror.importer.parser.record;\n+\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ * \u200b\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ * \u200b\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.verifyNoInteractions;\n+\n+import java.io.File;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.List;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import com.hedera.mirror.importer.FileCopier;\n+import com.hedera.mirror.importer.MirrorProperties;\n+import com.hedera.mirror.importer.domain.RecordFile;\n+import com.hedera.mirror.importer.domain.StreamType;\n+import com.hedera.mirror.importer.parser.domain.StreamFileData;\n+\n+@ExtendWith(MockitoExtension.class)\n+public class RecordFilePollerTest {\n+\n+    @TempDir\n+    Path dataPath;\n+    @Mock\n+    RecordFileParser recordFileParser;\n+    private FileCopier fileCopier;\n+    private RecordFilePoller recordFilePoller;\n+    private RecordParserProperties parserProperties;\n+\n+    private File file1;\n+    private File file2;\n+    private static final long FILE1_CONSENSUS_START = 1567188600419072000L;\n+    private static final int NUM_TXNS_FILE_1 = 19;\n+    private static final int NUM_TXNS_FILE_2 = 15;\n+    private static RecordFile recordFile1;\n+    private static RecordFile recordFile2;\n+\n+    @BeforeEach\n+    void before() {\n+        var mirrorProperties = new MirrorProperties();\n+        mirrorProperties.setDataPath(dataPath);\n+        parserProperties = new RecordParserProperties(mirrorProperties);\n+        parserProperties.setKeepFiles(false);\n+        parserProperties.init();\n+        recordFilePoller = new RecordFilePoller(parserProperties, recordFileParser);\n+        StreamType streamType = StreamType.RECORD;\n+        fileCopier = FileCopier\n+                .create(Path.of(getClass().getClassLoader().getResource(\"data\").getPath()), dataPath)\n+                .from(streamType.getPath(), \"v2\", \"record0.0.3\")\n+                .filterFiles(\"*.rcd\")\n+                .to(streamType.getPath(), streamType.getValid());\n+        file1 = parserProperties.getValidPath().resolve(\"2019-08-30T18_10_00.419072Z.rcd\").toFile();\n+        file2 = parserProperties.getValidPath().resolve(\"2019-08-30T18_10_05.249678Z.rcd\").toFile();\n+        recordFile1 = new RecordFile(1567188600419072000L, 1567188604906443001L, null, file1.getName(), 0L, 0L,\n+                \"591558e059bd1629ee386c4e35a6875b4c67a096718f5d225772a651042715189414df7db5588495efb2a85dc4a0ffda\",\n+                \"000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\", 2);\n+\n+        recordFile2 = new RecordFile(1567188605249678000L, 1567188609705382001L, null, file2.getName(), 0L, 0L,\n+                \"5ed51baeff204eb6a2a68b76bbaadcb9b6e7074676c1746b99681d075bef009e8d57699baaa6342feec4e83726582d36\",\n+                recordFile1.getFileHash(), 2);\n+    }\n+\n+    @Test\n+    void poll() throws Exception {\n+        // given\n+        fileCopier.copy();\n+\n+        // when\n+        recordFilePoller.poll();\n+\n+        // then\n+        assertAllProcessed();\n+    }\n+\n+    @Test\n+    void pollAndKeepFiles() throws Exception {\n+        // given\n+        parserProperties.setKeepFiles(true);\n+        fileCopier.copy();\n+\n+        // when\n+        recordFilePoller.poll();\n+\n+        // then\n+        assertAllProcessed();\n+    }\n+\n+    @Test\n+    void noFiles() throws Exception {\n+        // when\n+        recordFilePoller.poll();\n+\n+        // then\n+        assertParsedFiles();\n+        verifyNoInteractions(recordFileParser);\n+    }\n+\n+    // Asserts that recordFileParser.parse is called wth exactly the given fileNames.\n+    private void assertParse(String... fileNames) {\n+        ArgumentCaptor<StreamFileData> captor = ArgumentCaptor.forClass(StreamFileData.class);\n+        verify(recordFileParser, times(fileNames.length)).parse(captor.capture());", "originalCommit": "482f49fce85efd2655cd1826898083f8a8a0ec05", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzI0ODY2Ng==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467248666", "bodyText": "Sure, could achieve the same with below, since InOrder will make method less general as you have to have a verify for each occurrence of the method with the expected parameter.\nassertThat(actualArgs)\n                .extracting(StreamFileData::getFilename)\n                .isEqualTo(Arrays.asList(fileNames));", "author": "Nana-EC", "createdAt": "2020-08-07T20:14:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzEwNzgwMQ=="}], "type": "inlineReview", "revised_code": {"commit": "2ba305984f72c15a7c9551fbc3c82369f518b883", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java\nindex 14c7bb619..67c1964a7 100644\n--- a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java\n+++ b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java\n", "chunk": "@@ -120,7 +122,18 @@ public class RecordFilePollerTest {\n         recordFilePoller.poll();\n \n         // then\n-        assertParsedFiles();\n+        verifyNoInteractions(recordFileParser);\n+    }\n+\n+    @Test\n+    void pathNotDirectory() throws Exception {\n+        // when\n+        fileCopier.copy();\n+        parserProperties.getMirrorProperties().setDataPath(dataPath.resolve(\"file.txt\"));\n+        recordFilePoller.poll();\n+\n+        // then\n+        assertValidFiles();\n         verifyNoInteractions(recordFileParser);\n     }\n \n", "next_change": {"commit": "72492b10ad6b2e5e0fb0b9f2c18f738433dff64a", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java\nindex 67c1964a7..8a1529abc 100644\n--- a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java\n+++ b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java\n", "chunk": "@@ -137,6 +142,34 @@ public class RecordFilePollerTest {\n         verifyNoInteractions(recordFileParser);\n     }\n \n+    @Test\n+    void fileNotFoundFromRecordFileParser() {\n+        // given\n+        fileCopier.copy();\n+        RecordParserProperties mockParserProperties = Mockito.mock(RecordParserProperties.class);\n+        doReturn(Path.of(\"/var/folders/tmp\")).when(mockParserProperties).getValidPath();\n+        recordFilePoller = new RecordFilePoller(mockParserProperties, recordFileParser);\n+\n+        // when\n+        recordFilePoller.poll();\n+\n+        // then\n+        assertValidFiles();\n+    }\n+\n+    @Test\n+    void errorFromRecordFileParser() {\n+        // when\n+        fileCopier.copy();\n+        doThrow(ParserException.class).when(recordFileParser).parse(any());\n+\n+        // when\n+        recordFilePoller.poll();\n+\n+        // then\n+        assertValidFiles();\n+    }\n+\n     // Asserts that recordFileParser.parse is called wth exactly the given fileNames.\n     private void assertParse(String... fileNames) {\n         ArgumentCaptor<StreamFileData> captor = ArgumentCaptor.forClass(StreamFileData.class);\n", "next_change": null}]}}, {"header": "diff --git a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java\nindex 14c7bb619..67c1964a7 100644\n--- a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java\n+++ b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java\n", "chunk": "@@ -131,7 +144,7 @@ public class RecordFilePollerTest {\n         List<StreamFileData> actualArgs = captor.getAllValues();\n         assertThat(actualArgs)\n                 .extracting(StreamFileData::getFilename)\n-                .contains(fileNames);\n+                .isEqualTo(Arrays.asList(fileNames));\n     }\n \n     // Asserts that parsed directory contains exactly the files with given fileNames\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzExMjMzMA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467112330", "body": "This exception is already logged in poller, so this log can be removed.", "bodyText": "This exception is already logged in poller, so this log can be removed.", "bodyHTML": "<p dir=\"auto\">This exception is already logged in poller, so this log can be removed.</p>", "author": "steven-sheehy", "createdAt": "2020-08-07T15:29:29Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -165,6 +155,10 @@ public void loadRecordFile(StreamFileData streamFileData) {\n \n             recordParserLatencyMetric(recordFile);\n             success = true;\n+        } catch (Exception ex) {\n+            log.warn(\"Failed to parse {}\", streamFileData.getFilename(), ex);", "originalCommit": "482f49fce85efd2655cd1826898083f8a8a0ec05", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzY3NjEwMw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467676103", "bodyText": "Removed", "author": "Nana-EC", "createdAt": "2020-08-10T03:48:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzExMjMzMA=="}], "type": "inlineReview", "revised_code": {"commit": "2ba305984f72c15a7c9551fbc3c82369f518b883", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 3148d43e0..3caeb34a6 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -155,9 +156,10 @@ public class RecordFileParser implements FileParser {\n \n             recordParserLatencyMetric(recordFile);\n             success = true;\n+        } catch (DuplicateFileException ex) {\n+            log.warn(\"Skipping file {}\", ex);\n         } catch (Exception ex) {\n-            log.warn(\"Failed to parse {}\", streamFileData.getFilename(), ex);\n-            recordStreamFileListener.onError(); // rollback changes\n+            recordStreamFileListener.onError();\n             throw ex;\n         } finally {\n             var elapsedTimeMillis = Duration.between(startTime, Instant.now()).toMillis();\n", "next_change": {"commit": "1f345762e97fe2b4a66de19759ceb96eacc11885", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 3caeb34a6..c28f4fda8 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -164,8 +164,8 @@ public class RecordFileParser implements FileParser {\n         } finally {\n             var elapsedTimeMillis = Duration.between(startTime, Instant.now()).toMillis();\n             var rate = elapsedTimeMillis > 0 ? (int) (1000.0 * counter.get() / elapsedTimeMillis) : 0;\n-            log.info(\"Finished parsing {} transactions from record file {} in {}ms ({}/s)\",\n-                    counter, streamFileData.getFilename(), elapsedTimeMillis, rate);\n+            log.info(\"Finished parsing {} transactions from record file {} in {}ms ({}/s). Success: {}\",\n+                    counter, streamFileData.getFilename(), elapsedTimeMillis, rate, success);\n             parseDurationMetrics.get(success).record(elapsedTimeMillis, TimeUnit.MILLISECONDS);\n         }\n     }\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzEyMjI5Ng==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467122296", "body": "This seems to leak details of the parser. I think it makes more sense to catch DuplicateFileException in the parser and ignore it there.", "bodyText": "This seems to leak details of the parser. I think it makes more sense to catch DuplicateFileException in the parser and ignore it there.", "bodyHTML": "<p dir=\"auto\">This seems to leak details of the parser. I think it makes more sense to catch DuplicateFileException in the parser and ignore it there.</p>", "author": "steven-sheehy", "createdAt": "2020-08-07T15:47:30Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java", "diffHunk": "@@ -0,0 +1,121 @@\n+package com.hedera.mirror.importer.parser.record;\n+\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ * \u200b\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ * \u200b\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileNotFoundException;\n+import java.io.InputStream;\n+import java.nio.file.Path;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import javax.inject.Named;\n+import lombok.AllArgsConstructor;\n+import lombok.extern.log4j.Log4j2;\n+import org.apache.commons.io.FileUtils;\n+import org.springframework.scheduling.annotation.Scheduled;\n+\n+import com.hedera.mirror.importer.exception.DuplicateFileException;\n+import com.hedera.mirror.importer.parser.FilePoller;\n+import com.hedera.mirror.importer.parser.domain.StreamFileData;\n+import com.hedera.mirror.importer.util.ShutdownHelper;\n+import com.hedera.mirror.importer.util.Utility;\n+\n+@Log4j2\n+@Named\n+@ConditionalOnRecordParser\n+@AllArgsConstructor\n+public class RecordFilePoller implements FilePoller {\n+\n+    private final RecordParserProperties parserProperties;\n+    private final RecordFileParser recordFileParser;\n+\n+    @Override\n+    @Scheduled(fixedRateString = \"${hedera.mirror.importer.parser.record.frequency:100}\")\n+    public void poll() {\n+        if (ShutdownHelper.isStopping()) {\n+            return;\n+        }\n+        Path path = parserProperties.getValidPath();\n+        log.debug(\"Parsing record files from {}\", path);\n+        try {\n+            File file = path.toFile();\n+            if (file.isDirectory()) {\n+\n+                String[] files = file.list();\n+                Arrays.sort(files);           // sorted by name (timestamp)\n+\n+                // add directory prefix to get full path\n+                List<String> fullPaths = Arrays.asList(files).stream()\n+                        .map(s -> file + \"/\" + s)\n+                        .collect(Collectors.toList());\n+\n+                if (fullPaths != null && fullPaths.size() != 0) {\n+                    log.trace(\"Processing record files: {}\", fullPaths);\n+                    loadRecordFiles(fullPaths);\n+                } else {\n+                    log.debug(\"No files to parse\");\n+                }\n+            } else {\n+                log.error(\"Input parameter is not a folder: {}\", path);\n+            }\n+        } catch (Exception e) {\n+            log.error(\"Error parsing files\", e);\n+        }\n+    }\n+\n+    /**\n+     * read and parse a list of record files\n+     *\n+     * @throws Exception\n+     */\n+    private void loadRecordFiles(List<String> filePaths) {\n+        Collections.sort(filePaths);\n+        for (String filePath : filePaths) {\n+            if (ShutdownHelper.isStopping()) {\n+                return;\n+            }\n+\n+            File file = new File(filePath);\n+\n+            try (InputStream fileInputStream = new FileInputStream(file)) {\n+                recordFileParser.parse(new StreamFileData(filePath, fileInputStream));\n+\n+                if (parserProperties.isKeepFiles()) {\n+                    Utility.archiveFile(file, parserProperties.getParsedPath());\n+                } else {\n+                    FileUtils.deleteQuietly(file);\n+                }\n+            } catch (FileNotFoundException e) {\n+                log.warn(\"File does not exist {}\", filePath);\n+                return;\n+            } catch (Exception e) {\n+                log.error(\"Error parsing file {}\", filePath, e);\n+                if (!(e instanceof DuplicateFileException)) { // if DuplicateFileException, continue with other", "originalCommit": "482f49fce85efd2655cd1826898083f8a8a0ec05", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzY3NjE5Mw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467676193", "bodyText": "DuplicateFileException catch log and ignore added to parser", "author": "Nana-EC", "createdAt": "2020-08-10T03:48:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzEyMjI5Ng=="}], "type": "inlineReview", "revised_code": {"commit": "2ba305984f72c15a7c9551fbc3c82369f518b883", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\nindex e7aa09328..a5bfaf202 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n", "chunk": "@@ -111,10 +108,6 @@ public class RecordFilePoller implements FilePoller {\n                 return;\n             } catch (Exception e) {\n                 log.error(\"Error parsing file {}\", filePath, e);\n-                if (!(e instanceof DuplicateFileException)) { // if DuplicateFileException, continue with other\n-                    // files\n-                    return;\n-                }\n             }\n         }\n     }\n", "next_change": {"commit": "1f345762e97fe2b4a66de19759ceb96eacc11885", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\nindex a5bfaf202..dd1720ca6 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n", "chunk": "@@ -107,7 +107,7 @@ public class RecordFilePoller implements FilePoller {\n                 log.warn(\"File does not exist {}\", filePath);\n                 return;\n             } catch (Exception e) {\n-                log.error(\"Error parsing file {}\", filePath, e);\n+                log.error(String.format(\"Error parsing file %s\", filePath), e);\n             }\n         }\n     }\n", "next_change": {"commit": "1e52bb6ce52d20fab8c3b45955376252c24fe4cd", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\nindex dd1720ca6..d5b6bf905 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n", "chunk": "@@ -108,6 +104,7 @@ public class RecordFilePoller implements FilePoller {\n                 return;\n             } catch (Exception e) {\n                 log.error(String.format(\"Error parsing file %s\", filePath), e);\n+                return;\n             }\n         }\n     }\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzEzMzA1Mw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467133053", "body": "There's a problem here. In SqlEntityListener we manually manage the commit and that can cause issues. From `connection.setAutoCommit()`:\r\n```\r\nIf this method is called during a transaction and the auto-commit mode is changed, the transaction is committed. If setAutoCommit is called and the auto-commit mode is not changed, the call is a no-op.\r\n```\r\nAlso, I'm not sure the impact of explicitly calling commit on a connection with an outer transaction in progress. It would be better to remove setAutoCommit and not call commit/rollback manually. This annotation should handle it for us. But please verify with tests.\r\n\r\nI'm not sure about the connection and statements in SqlEntityListener. I'm guessing we still need to manually close those but since they're proxied they won't actually close until the outer transaction completes.", "bodyText": "There's a problem here. In SqlEntityListener we manually manage the commit and that can cause issues. From connection.setAutoCommit():\nIf this method is called during a transaction and the auto-commit mode is changed, the transaction is committed. If setAutoCommit is called and the auto-commit mode is not changed, the call is a no-op.\n\nAlso, I'm not sure the impact of explicitly calling commit on a connection with an outer transaction in progress. It would be better to remove setAutoCommit and not call commit/rollback manually. This annotation should handle it for us. But please verify with tests.\nI'm not sure about the connection and statements in SqlEntityListener. I'm guessing we still need to manually close those but since they're proxied they won't actually close until the outer transaction completes.", "bodyHTML": "<p dir=\"auto\">There's a problem here. In SqlEntityListener we manually manage the commit and that can cause issues. From <code>connection.setAutoCommit()</code>:</p>\n<div class=\"snippet-clipboard-content position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"If this method is called during a transaction and the auto-commit mode is changed, the transaction is committed. If setAutoCommit is called and the auto-commit mode is not changed, the call is a no-op.\"><pre><code>If this method is called during a transaction and the auto-commit mode is changed, the transaction is committed. If setAutoCommit is called and the auto-commit mode is not changed, the call is a no-op.\n</code></pre></div>\n<p dir=\"auto\">Also, I'm not sure the impact of explicitly calling commit on a connection with an outer transaction in progress. It would be better to remove setAutoCommit and not call commit/rollback manually. This annotation should handle it for us. But please verify with tests.</p>\n<p dir=\"auto\">I'm not sure about the connection and statements in SqlEntityListener. I'm guessing we still need to manually close those but since they're proxied they won't actually close until the outer transaction completes.</p>", "author": "steven-sheehy", "createdAt": "2020-08-07T16:07:01Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -135,11 +123,13 @@ public RecordFileParser(ApplicationStatusRepository applicationStatusRepository,\n     }\n \n     /**\n-     * Given a service record name, read and parse and return as a list of service record pair\n+     * Given a stream file data representing an rcd file from the service parse record items and persist changes\n      *\n      * @param streamFileData containing information about file to be processed\n      */\n-    public void loadRecordFile(StreamFileData streamFileData) {\n+    @Override\n+    @Transactional", "originalCommit": "482f49fce85efd2655cd1826898083f8a8a0ec05", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzY3NjQ5OQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467676499", "bodyText": "Manual close is good practice, but you're right the outer transaction close will probably handle it.\nI did remove the setAutoCommit", "author": "Nana-EC", "createdAt": "2020-08-10T03:50:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzEzMzA1Mw=="}], "type": "inlineReview", "revised_code": {"commit": "1f345762e97fe2b4a66de19759ceb96eacc11885", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 3148d43e0..c28f4fda8 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -128,7 +129,7 @@ public class RecordFileParser implements FileParser {\n      * @param streamFileData containing information about file to be processed\n      */\n     @Override\n-    @Transactional\n+    @Transactional(rollbackFor = Exception.class)\n     public void parse(StreamFileData streamFileData) {\n         Instant startTime = Instant.now();\n \n", "next_change": {"commit": "1e52bb6ce52d20fab8c3b45955376252c24fe4cd", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex c28f4fda8..89a913f12 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -129,7 +129,7 @@ public class RecordFileParser implements FileParser {\n      * @param streamFileData containing information about file to be processed\n      */\n     @Override\n-    @Transactional(rollbackFor = Exception.class)\n+    @Transactional\n     public void parse(StreamFileData streamFileData) {\n         Instant startTime = Instant.now();\n \n", "next_change": {"commit": "ba7113b865a5b82f3cf74e3c8c06f6979e29dc86", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 89a913f12..d7b968812 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -129,7 +128,6 @@ public class RecordFileParser implements FileParser {\n      * @param streamFileData containing information about file to be processed\n      */\n     @Override\n-    @Transactional\n     public void parse(StreamFileData streamFileData) {\n         Instant startTime = Instant.now();\n \n", "next_change": {"commit": "2f751b76b7302fa4d8b274c54c191ac2bb9d151b", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex d7b968812..de4662fcd 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -131,12 +131,12 @@ public class RecordFileParser implements FileParser {\n     public void parse(StreamFileData streamFileData) {\n         Instant startTime = Instant.now();\n \n-        recordStreamFileListener.onStart(streamFileData);\n         String expectedPrevFileHash =\n                 applicationStatusRepository.findByStatusCode(ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH);\n         AtomicInteger counter = new AtomicInteger(0);\n         boolean success = false;\n         try {\n+            recordStreamFileListener.onStart(streamFileData);\n             Stopwatch stopwatch = Stopwatch.createStarted();\n             RecordFile recordFile = Utility.parseRecordFile(\n                     streamFileData.getFilename(), expectedPrevFileHash,\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzEzMzkxMQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467133911", "body": "Can remove rollback changes comment, considering previous change.", "bodyText": "Can remove rollback changes comment, considering previous change.", "bodyHTML": "<p dir=\"auto\">Can remove rollback changes comment, considering previous change.</p>", "author": "steven-sheehy", "createdAt": "2020-08-07T16:08:36Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -165,6 +155,10 @@ public void loadRecordFile(StreamFileData streamFileData) {\n \n             recordParserLatencyMetric(recordFile);\n             success = true;\n+        } catch (Exception ex) {\n+            log.warn(\"Failed to parse {}\", streamFileData.getFilename(), ex);\n+            recordStreamFileListener.onError(); // rollback changes", "originalCommit": "482f49fce85efd2655cd1826898083f8a8a0ec05", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzY3NjU2OA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467676568", "bodyText": "Removed comment", "author": "Nana-EC", "createdAt": "2020-08-10T03:51:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzEzMzkxMQ=="}], "type": "inlineReview", "revised_code": {"commit": "2ba305984f72c15a7c9551fbc3c82369f518b883", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 3148d43e0..3caeb34a6 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -155,9 +156,10 @@ public class RecordFileParser implements FileParser {\n \n             recordParserLatencyMetric(recordFile);\n             success = true;\n+        } catch (DuplicateFileException ex) {\n+            log.warn(\"Skipping file {}\", ex);\n         } catch (Exception ex) {\n-            log.warn(\"Failed to parse {}\", streamFileData.getFilename(), ex);\n-            recordStreamFileListener.onError(); // rollback changes\n+            recordStreamFileListener.onError();\n             throw ex;\n         } finally {\n             var elapsedTimeMillis = Duration.between(startTime, Instant.now()).toMillis();\n", "next_change": {"commit": "1f345762e97fe2b4a66de19759ceb96eacc11885", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 3caeb34a6..c28f4fda8 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -164,8 +164,8 @@ public class RecordFileParser implements FileParser {\n         } finally {\n             var elapsedTimeMillis = Duration.between(startTime, Instant.now()).toMillis();\n             var rate = elapsedTimeMillis > 0 ? (int) (1000.0 * counter.get() / elapsedTimeMillis) : 0;\n-            log.info(\"Finished parsing {} transactions from record file {} in {}ms ({}/s)\",\n-                    counter, streamFileData.getFilename(), elapsedTimeMillis, rate);\n+            log.info(\"Finished parsing {} transactions from record file {} in {}ms ({}/s). Success: {}\",\n+                    counter, streamFileData.getFilename(), elapsedTimeMillis, rate, success);\n             parseDurationMetrics.get(success).record(elapsedTimeMillis, TimeUnit.MILLISECONDS);\n         }\n     }\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzEzNDUxNg==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467134516", "body": "Unused", "bodyText": "Unused", "bodyHTML": "<p dir=\"auto\">Unused</p>", "author": "steven-sheehy", "createdAt": "2020-08-07T16:09:40Z", "path": "hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java", "diffHunk": "@@ -188,47 +166,63 @@ void bypassHashMismatch() throws Exception {\n         // given\n         parserProperties.getMirrorProperties().setVerifyHashAfter(Instant.parse(\"2019-09-01T00:00:00.000000Z\"));\n         when(applicationStatusRepository.findByStatusCode(LAST_PROCESSED_RECORD_HASH)).thenReturn(\"123\");\n-        fileCopier.copy();\n \n         // when\n-        recordFileParser.parse();\n+        recordFileParser.parse(streamFileData1);\n \n         // then\n-        assertAllProcessed();\n+        verify(recordStreamFileListener, never()).onError();\n+        assertProcessedFile(streamFileData1, recordFile1, NUM_TXNS_FILE_1);\n     }\n \n     @Test\n-    void failureProcessingItemShouldRollback() throws Exception {\n+    void failureProcessingItemShouldRollback() {\n         // given\n-        fileCopier.copy();\n         doThrow(ParserSQLException.class).when(recordItemListener).onItem(any());\n \n         // when\n-        recordFileParser.parse();\n+        Assertions.assertThrows(IllegalArgumentException.class, () -> {\n+            recordFileParser.parse(streamFileData1);\n+        });\n \n         // then\n-        assertValidFiles();\n+        verify(recordStreamFileListener).onStart(streamFileData1);\n+        verify(recordStreamFileListener, never()).onEnd(recordFile1);\n         verify(recordStreamFileListener).onError();\n     }\n \n     @Test\n-    void skipFileOnDuplicateFileException() throws Exception {\n+    void skipFileOnDuplicateFileException() {\n         // given\n-        fileCopier.copy();\n-        String fileName = file1.toString();\n-        recordFileParser.loadRecordFile(new StreamFileData(fileName, new FileInputStream(file1)));\n+        recordFileParser.parse(streamFileData1);\n         doThrow(DuplicateFileException.class).when(recordStreamFileListener).onStart(any());\n \n         // when: load same file again\n         // then: throws exception\n         Assertions.assertThrows(DuplicateFileException.class, () -> {\n-            recordFileParser.loadRecordFile(new StreamFileData(fileName, new FileInputStream(file1)));\n+            recordFileParser.parse(streamFileData1);\n         });\n         verify(recordItemListener, times(NUM_TXNS_FILE_1)).onItem(any());\n         verify(recordStreamFileListener, times(2)).onStart(any());\n         verify(recordStreamFileListener, times(1)).onEnd(any());\n     }\n \n+    @Test\n+    void verifyRollbackOnErrorAfterPersistence() throws Exception {\n+        // given\n+        String fileName = file1.toString();", "originalCommit": "482f49fce85efd2655cd1826898083f8a8a0ec05", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzY3NjYxNQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467676615", "bodyText": "Removed leftover", "author": "Nana-EC", "createdAt": "2020-08-10T03:51:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzEzNDUxNg=="}], "type": "inlineReview", "revised_code": {"commit": "2ba305984f72c15a7c9551fbc3c82369f518b883", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\nindex ab3f2e8ce..293d3430a 100644\n--- a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n+++ b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n", "chunk": "@@ -207,22 +207,6 @@ public class RecordFileParserTest {\n         verify(recordStreamFileListener, times(1)).onEnd(any());\n     }\n \n-    @Test\n-    void verifyRollbackOnErrorAfterPersistence() throws Exception {\n-        // given\n-        String fileName = file1.toString();\n-        doThrow(ParserSQLException.class).when(applicationStatusRepository).updateStatusValue(any(), any());\n-\n-        // when\n-        Assertions.assertThrows(ParserSQLException.class, () -> {\n-            recordFileParser.parse(streamFileData2);\n-        });\n-\n-        // then\n-        assertProcessedFile(streamFileData2, recordFile2, NUM_TXNS_FILE_2);\n-        verify(recordStreamFileListener).onError();\n-    }\n-\n     // Asserts that recordStreamFileListener.onStart is called wth exactly the given fileNames.\n     private void assertOnStart(String... fileNames) {\n         ArgumentCaptor<StreamFileData> captor = ArgumentCaptor.forClass(StreamFileData.class);\n", "next_change": {"commit": "e962d8dd5fe0a06ae248ba04f604c44e24be85ea", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\nindex 293d3430a..cf76749fa 100644\n--- a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n+++ b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n", "chunk": "@@ -191,22 +190,6 @@ public class RecordFileParserTest {\n         verify(recordStreamFileListener).onError();\n     }\n \n-    @Test\n-    void skipFileOnDuplicateFileException() {\n-        // given\n-        recordFileParser.parse(streamFileData1);\n-        doThrow(DuplicateFileException.class).when(recordStreamFileListener).onStart(any());\n-\n-        // when: load same file again\n-        // then: throws exception\n-        Assertions.assertThrows(DuplicateFileException.class, () -> {\n-            recordFileParser.parse(streamFileData1);\n-        });\n-        verify(recordItemListener, times(NUM_TXNS_FILE_1)).onItem(any());\n-        verify(recordStreamFileListener, times(2)).onStart(any());\n-        verify(recordStreamFileListener, times(1)).onEnd(any());\n-    }\n-\n     // Asserts that recordStreamFileListener.onStart is called wth exactly the given fileNames.\n     private void assertOnStart(String... fileNames) {\n         ArgumentCaptor<StreamFileData> captor = ArgumentCaptor.forClass(StreamFileData.class);\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzEzODA0Ng==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467138046", "body": "I don't think it's possible to truly test database rollback with mocks. Since it's probably tricky to convert this to not use mocks, we can probably create a separate integration test file just for the rollback test.", "bodyText": "I don't think it's possible to truly test database rollback with mocks. Since it's probably tricky to convert this to not use mocks, we can probably create a separate integration test file just for the rollback test.", "bodyHTML": "<p dir=\"auto\">I don't think it's possible to truly test database rollback with mocks. Since it's probably tricky to convert this to not use mocks, we can probably create a separate integration test file just for the rollback test.</p>", "author": "steven-sheehy", "createdAt": "2020-08-07T16:16:28Z", "path": "hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java", "diffHunk": "@@ -188,47 +166,63 @@ void bypassHashMismatch() throws Exception {\n         // given\n         parserProperties.getMirrorProperties().setVerifyHashAfter(Instant.parse(\"2019-09-01T00:00:00.000000Z\"));\n         when(applicationStatusRepository.findByStatusCode(LAST_PROCESSED_RECORD_HASH)).thenReturn(\"123\");\n-        fileCopier.copy();\n \n         // when\n-        recordFileParser.parse();\n+        recordFileParser.parse(streamFileData1);\n \n         // then\n-        assertAllProcessed();\n+        verify(recordStreamFileListener, never()).onError();\n+        assertProcessedFile(streamFileData1, recordFile1, NUM_TXNS_FILE_1);\n     }\n \n     @Test\n-    void failureProcessingItemShouldRollback() throws Exception {\n+    void failureProcessingItemShouldRollback() {\n         // given\n-        fileCopier.copy();\n         doThrow(ParserSQLException.class).when(recordItemListener).onItem(any());\n \n         // when\n-        recordFileParser.parse();\n+        Assertions.assertThrows(IllegalArgumentException.class, () -> {\n+            recordFileParser.parse(streamFileData1);\n+        });\n \n         // then\n-        assertValidFiles();\n+        verify(recordStreamFileListener).onStart(streamFileData1);\n+        verify(recordStreamFileListener, never()).onEnd(recordFile1);\n         verify(recordStreamFileListener).onError();\n     }\n \n     @Test\n-    void skipFileOnDuplicateFileException() throws Exception {\n+    void skipFileOnDuplicateFileException() {\n         // given\n-        fileCopier.copy();\n-        String fileName = file1.toString();\n-        recordFileParser.loadRecordFile(new StreamFileData(fileName, new FileInputStream(file1)));\n+        recordFileParser.parse(streamFileData1);\n         doThrow(DuplicateFileException.class).when(recordStreamFileListener).onStart(any());\n \n         // when: load same file again\n         // then: throws exception\n         Assertions.assertThrows(DuplicateFileException.class, () -> {\n-            recordFileParser.loadRecordFile(new StreamFileData(fileName, new FileInputStream(file1)));\n+            recordFileParser.parse(streamFileData1);\n         });\n         verify(recordItemListener, times(NUM_TXNS_FILE_1)).onItem(any());\n         verify(recordStreamFileListener, times(2)).onStart(any());\n         verify(recordStreamFileListener, times(1)).onEnd(any());\n     }\n \n+    @Test\n+    void verifyRollbackOnErrorAfterPersistence() throws Exception {\n+        // given\n+        String fileName = file1.toString();\n+        doThrow(ParserSQLException.class).when(applicationStatusRepository).updateStatusValue(any(), any());", "originalCommit": "482f49fce85efd2655cd1826898083f8a8a0ec05", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzY3Njc1MQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467676751", "bodyText": "Working on integration test.  Parse method makes it a bit tricky to force an error after commit to I'm having to at last mock the applicationStatus Repository call for such a test.", "author": "Nana-EC", "createdAt": "2020-08-10T03:52:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzEzODA0Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODE3MjE5MA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r468172190", "bodyText": "Proving difficult to get a test that captures this.\nMaybe it's sufficient to rely on @transactional functioning correctly based on our configuration.\nI did update RecordFilePrser to use the spring version so we could get coverage for the RunTimeExceptions which are not caught and therefore don't force a rollback when the base @transactional is used.", "author": "Nana-EC", "createdAt": "2020-08-10T20:38:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzEzODA0Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTY1MzYzOQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r469653639", "bodyText": "Added a rollback test to the RecordFileParserIntegrationTest.\nMore importantly verified against a local running parser that the rollback works for both pgcopy and prepared statement produced inserts", "author": "Nana-EC", "createdAt": "2020-08-13T02:03:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzEzODA0Ng=="}], "type": "inlineReview", "revised_code": {"commit": "2ba305984f72c15a7c9551fbc3c82369f518b883", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\nindex ab3f2e8ce..293d3430a 100644\n--- a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n+++ b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n", "chunk": "@@ -207,22 +207,6 @@ public class RecordFileParserTest {\n         verify(recordStreamFileListener, times(1)).onEnd(any());\n     }\n \n-    @Test\n-    void verifyRollbackOnErrorAfterPersistence() throws Exception {\n-        // given\n-        String fileName = file1.toString();\n-        doThrow(ParserSQLException.class).when(applicationStatusRepository).updateStatusValue(any(), any());\n-\n-        // when\n-        Assertions.assertThrows(ParserSQLException.class, () -> {\n-            recordFileParser.parse(streamFileData2);\n-        });\n-\n-        // then\n-        assertProcessedFile(streamFileData2, recordFile2, NUM_TXNS_FILE_2);\n-        verify(recordStreamFileListener).onError();\n-    }\n-\n     // Asserts that recordStreamFileListener.onStart is called wth exactly the given fileNames.\n     private void assertOnStart(String... fileNames) {\n         ArgumentCaptor<StreamFileData> captor = ArgumentCaptor.forClass(StreamFileData.class);\n", "next_change": {"commit": "e962d8dd5fe0a06ae248ba04f604c44e24be85ea", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\nindex 293d3430a..cf76749fa 100644\n--- a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n+++ b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n", "chunk": "@@ -191,22 +190,6 @@ public class RecordFileParserTest {\n         verify(recordStreamFileListener).onError();\n     }\n \n-    @Test\n-    void skipFileOnDuplicateFileException() {\n-        // given\n-        recordFileParser.parse(streamFileData1);\n-        doThrow(DuplicateFileException.class).when(recordStreamFileListener).onStart(any());\n-\n-        // when: load same file again\n-        // then: throws exception\n-        Assertions.assertThrows(DuplicateFileException.class, () -> {\n-            recordFileParser.parse(streamFileData1);\n-        });\n-        verify(recordItemListener, times(NUM_TXNS_FILE_1)).onItem(any());\n-        verify(recordStreamFileListener, times(2)).onStart(any());\n-        verify(recordStreamFileListener, times(1)).onEnd(any());\n-    }\n-\n     // Asserts that recordStreamFileListener.onStart is called wth exactly the given fileNames.\n     private void assertOnStart(String... fileNames) {\n         ArgumentCaptor<StreamFileData> captor = ArgumentCaptor.forClass(StreamFileData.class);\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzEzODA3MQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467138071", "body": "There should be nothing processed, right? This test is suspect.", "bodyText": "There should be nothing processed, right? This test is suspect.", "bodyHTML": "<p dir=\"auto\">There should be nothing processed, right? This test is suspect.</p>", "author": "steven-sheehy", "createdAt": "2020-08-07T16:16:30Z", "path": "hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java", "diffHunk": "@@ -188,47 +166,63 @@ void bypassHashMismatch() throws Exception {\n         // given\n         parserProperties.getMirrorProperties().setVerifyHashAfter(Instant.parse(\"2019-09-01T00:00:00.000000Z\"));\n         when(applicationStatusRepository.findByStatusCode(LAST_PROCESSED_RECORD_HASH)).thenReturn(\"123\");\n-        fileCopier.copy();\n \n         // when\n-        recordFileParser.parse();\n+        recordFileParser.parse(streamFileData1);\n \n         // then\n-        assertAllProcessed();\n+        verify(recordStreamFileListener, never()).onError();\n+        assertProcessedFile(streamFileData1, recordFile1, NUM_TXNS_FILE_1);\n     }\n \n     @Test\n-    void failureProcessingItemShouldRollback() throws Exception {\n+    void failureProcessingItemShouldRollback() {\n         // given\n-        fileCopier.copy();\n         doThrow(ParserSQLException.class).when(recordItemListener).onItem(any());\n \n         // when\n-        recordFileParser.parse();\n+        Assertions.assertThrows(IllegalArgumentException.class, () -> {\n+            recordFileParser.parse(streamFileData1);\n+        });\n \n         // then\n-        assertValidFiles();\n+        verify(recordStreamFileListener).onStart(streamFileData1);\n+        verify(recordStreamFileListener, never()).onEnd(recordFile1);\n         verify(recordStreamFileListener).onError();\n     }\n \n     @Test\n-    void skipFileOnDuplicateFileException() throws Exception {\n+    void skipFileOnDuplicateFileException() {\n         // given\n-        fileCopier.copy();\n-        String fileName = file1.toString();\n-        recordFileParser.loadRecordFile(new StreamFileData(fileName, new FileInputStream(file1)));\n+        recordFileParser.parse(streamFileData1);\n         doThrow(DuplicateFileException.class).when(recordStreamFileListener).onStart(any());\n \n         // when: load same file again\n         // then: throws exception\n         Assertions.assertThrows(DuplicateFileException.class, () -> {\n-            recordFileParser.loadRecordFile(new StreamFileData(fileName, new FileInputStream(file1)));\n+            recordFileParser.parse(streamFileData1);\n         });\n         verify(recordItemListener, times(NUM_TXNS_FILE_1)).onItem(any());\n         verify(recordStreamFileListener, times(2)).onStart(any());\n         verify(recordStreamFileListener, times(1)).onEnd(any());\n     }\n \n+    @Test\n+    void verifyRollbackOnErrorAfterPersistence() throws Exception {\n+        // given\n+        String fileName = file1.toString();\n+        doThrow(ParserSQLException.class).when(applicationStatusRepository).updateStatusValue(any(), any());\n+\n+        // when\n+        Assertions.assertThrows(ParserSQLException.class, () -> {\n+            recordFileParser.parse(streamFileData2);\n+        });\n+\n+        // then\n+        assertProcessedFile(streamFileData2, recordFile2, NUM_TXNS_FILE_2);", "originalCommit": "482f49fce85efd2655cd1826898083f8a8a0ec05", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzY3NzU4OQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467677589", "bodyText": "Actually in this test everything would have been processed as expected, expect after persistence but before file complete an error occurred.\nTest is removed though", "author": "Nana-EC", "createdAt": "2020-08-10T03:57:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzEzODA3MQ=="}], "type": "inlineReview", "revised_code": {"commit": "2ba305984f72c15a7c9551fbc3c82369f518b883", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\nindex ab3f2e8ce..293d3430a 100644\n--- a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n+++ b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n", "chunk": "@@ -207,22 +207,6 @@ public class RecordFileParserTest {\n         verify(recordStreamFileListener, times(1)).onEnd(any());\n     }\n \n-    @Test\n-    void verifyRollbackOnErrorAfterPersistence() throws Exception {\n-        // given\n-        String fileName = file1.toString();\n-        doThrow(ParserSQLException.class).when(applicationStatusRepository).updateStatusValue(any(), any());\n-\n-        // when\n-        Assertions.assertThrows(ParserSQLException.class, () -> {\n-            recordFileParser.parse(streamFileData2);\n-        });\n-\n-        // then\n-        assertProcessedFile(streamFileData2, recordFile2, NUM_TXNS_FILE_2);\n-        verify(recordStreamFileListener).onError();\n-    }\n-\n     // Asserts that recordStreamFileListener.onStart is called wth exactly the given fileNames.\n     private void assertOnStart(String... fileNames) {\n         ArgumentCaptor<StreamFileData> captor = ArgumentCaptor.forClass(StreamFileData.class);\n", "next_change": {"commit": "e962d8dd5fe0a06ae248ba04f604c44e24be85ea", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\nindex 293d3430a..cf76749fa 100644\n--- a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n+++ b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java\n", "chunk": "@@ -191,22 +190,6 @@ public class RecordFileParserTest {\n         verify(recordStreamFileListener).onError();\n     }\n \n-    @Test\n-    void skipFileOnDuplicateFileException() {\n-        // given\n-        recordFileParser.parse(streamFileData1);\n-        doThrow(DuplicateFileException.class).when(recordStreamFileListener).onStart(any());\n-\n-        // when: load same file again\n-        // then: throws exception\n-        Assertions.assertThrows(DuplicateFileException.class, () -> {\n-            recordFileParser.parse(streamFileData1);\n-        });\n-        verify(recordItemListener, times(NUM_TXNS_FILE_1)).onItem(any());\n-        verify(recordStreamFileListener, times(2)).onStart(any());\n-        verify(recordStreamFileListener, times(1)).onEnd(any());\n-    }\n-\n     // Asserts that recordStreamFileListener.onStart is called wth exactly the given fileNames.\n     private void assertOnStart(String... fileNames) {\n         ArgumentCaptor<StreamFileData> captor = ArgumentCaptor.forClass(StreamFileData.class);\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzEzODQzNw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467138437", "body": "Please add a test for not a directory. Would also be good to check code coverage report and see if any other paths not tested.", "bodyText": "Please add a test for not a directory. Would also be good to check code coverage report and see if any other paths not tested.", "bodyHTML": "<p dir=\"auto\">Please add a test for not a directory. Would also be good to check code coverage report and see if any other paths not tested.</p>", "author": "steven-sheehy", "createdAt": "2020-08-07T16:17:07Z", "path": "hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java", "diffHunk": "@@ -0,0 +1,168 @@\n+package com.hedera.mirror.importer.parser.record;\n+\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ * \u200b\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ * \u200b\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.verifyNoInteractions;\n+\n+import java.io.File;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.List;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import com.hedera.mirror.importer.FileCopier;\n+import com.hedera.mirror.importer.MirrorProperties;\n+import com.hedera.mirror.importer.domain.RecordFile;\n+import com.hedera.mirror.importer.domain.StreamType;\n+import com.hedera.mirror.importer.parser.domain.StreamFileData;\n+\n+@ExtendWith(MockitoExtension.class)\n+public class RecordFilePollerTest {\n+\n+    @TempDir\n+    Path dataPath;\n+    @Mock\n+    RecordFileParser recordFileParser;\n+    private FileCopier fileCopier;\n+    private RecordFilePoller recordFilePoller;\n+    private RecordParserProperties parserProperties;\n+\n+    private File file1;\n+    private File file2;\n+    private static final long FILE1_CONSENSUS_START = 1567188600419072000L;\n+    private static final int NUM_TXNS_FILE_1 = 19;\n+    private static final int NUM_TXNS_FILE_2 = 15;\n+    private static RecordFile recordFile1;\n+    private static RecordFile recordFile2;\n+\n+    @BeforeEach\n+    void before() {\n+        var mirrorProperties = new MirrorProperties();\n+        mirrorProperties.setDataPath(dataPath);\n+        parserProperties = new RecordParserProperties(mirrorProperties);\n+        parserProperties.setKeepFiles(false);\n+        parserProperties.init();\n+        recordFilePoller = new RecordFilePoller(parserProperties, recordFileParser);\n+        StreamType streamType = StreamType.RECORD;\n+        fileCopier = FileCopier\n+                .create(Path.of(getClass().getClassLoader().getResource(\"data\").getPath()), dataPath)\n+                .from(streamType.getPath(), \"v2\", \"record0.0.3\")\n+                .filterFiles(\"*.rcd\")\n+                .to(streamType.getPath(), streamType.getValid());\n+        file1 = parserProperties.getValidPath().resolve(\"2019-08-30T18_10_00.419072Z.rcd\").toFile();\n+        file2 = parserProperties.getValidPath().resolve(\"2019-08-30T18_10_05.249678Z.rcd\").toFile();\n+        recordFile1 = new RecordFile(1567188600419072000L, 1567188604906443001L, null, file1.getName(), 0L, 0L,\n+                \"591558e059bd1629ee386c4e35a6875b4c67a096718f5d225772a651042715189414df7db5588495efb2a85dc4a0ffda\",\n+                \"000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\", 2);\n+\n+        recordFile2 = new RecordFile(1567188605249678000L, 1567188609705382001L, null, file2.getName(), 0L, 0L,\n+                \"5ed51baeff204eb6a2a68b76bbaadcb9b6e7074676c1746b99681d075bef009e8d57699baaa6342feec4e83726582d36\",\n+                recordFile1.getFileHash(), 2);\n+    }\n+\n+    @Test\n+    void poll() throws Exception {\n+        // given\n+        fileCopier.copy();\n+\n+        // when\n+        recordFilePoller.poll();\n+\n+        // then\n+        assertAllProcessed();\n+    }\n+\n+    @Test\n+    void pollAndKeepFiles() throws Exception {\n+        // given\n+        parserProperties.setKeepFiles(true);\n+        fileCopier.copy();\n+\n+        // when\n+        recordFilePoller.poll();\n+\n+        // then\n+        assertAllProcessed();\n+    }\n+\n+    @Test\n+    void noFiles() throws Exception {\n+        // when\n+        recordFilePoller.poll();\n+\n+        // then\n+        assertParsedFiles();\n+        verifyNoInteractions(recordFileParser);\n+    }\n+", "originalCommit": "482f49fce85efd2655cd1826898083f8a8a0ec05", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzY3ODQ3MQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r467678471", "bodyText": "Added not a directory test. Adding more to increase coverage for Poller.", "author": "Nana-EC", "createdAt": "2020-08-10T04:03:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzEzODQzNw=="}], "type": "inlineReview", "revised_code": {"commit": "2ba305984f72c15a7c9551fbc3c82369f518b883", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java\nindex 14c7bb619..67c1964a7 100644\n--- a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java\n+++ b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java\n", "chunk": "@@ -120,7 +122,18 @@ public class RecordFilePollerTest {\n         recordFilePoller.poll();\n \n         // then\n-        assertParsedFiles();\n+        verifyNoInteractions(recordFileParser);\n+    }\n+\n+    @Test\n+    void pathNotDirectory() throws Exception {\n+        // when\n+        fileCopier.copy();\n+        parserProperties.getMirrorProperties().setDataPath(dataPath.resolve(\"file.txt\"));\n+        recordFilePoller.poll();\n+\n+        // then\n+        assertValidFiles();\n         verifyNoInteractions(recordFileParser);\n     }\n \n", "next_change": {"commit": "72492b10ad6b2e5e0fb0b9f2c18f738433dff64a", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java\nindex 67c1964a7..8a1529abc 100644\n--- a/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java\n+++ b/hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFilePollerTest.java\n", "chunk": "@@ -137,6 +142,34 @@ public class RecordFilePollerTest {\n         verifyNoInteractions(recordFileParser);\n     }\n \n+    @Test\n+    void fileNotFoundFromRecordFileParser() {\n+        // given\n+        fileCopier.copy();\n+        RecordParserProperties mockParserProperties = Mockito.mock(RecordParserProperties.class);\n+        doReturn(Path.of(\"/var/folders/tmp\")).when(mockParserProperties).getValidPath();\n+        recordFilePoller = new RecordFilePoller(mockParserProperties, recordFileParser);\n+\n+        // when\n+        recordFilePoller.poll();\n+\n+        // then\n+        assertValidFiles();\n+    }\n+\n+    @Test\n+    void errorFromRecordFileParser() {\n+        // when\n+        fileCopier.copy();\n+        doThrow(ParserException.class).when(recordFileParser).parse(any());\n+\n+        // when\n+        recordFilePoller.poll();\n+\n+        // then\n+        assertValidFiles();\n+    }\n+\n     // Asserts that recordFileParser.parse is called wth exactly the given fileNames.\n     private void assertParse(String... fileNames) {\n         ArgumentCaptor<StreamFileData> captor = ArgumentCaptor.forClass(StreamFileData.class);\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODIxMzgyNw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r468213827", "body": "This is missing a return statement. We don't want to continue to the next file if a parsing error on current file.", "bodyText": "This is missing a return statement. We don't want to continue to the next file if a parsing error on current file.", "bodyHTML": "<p dir=\"auto\">This is missing a return statement. We don't want to continue to the next file if a parsing error on current file.</p>", "author": "steven-sheehy", "createdAt": "2020-08-10T22:09:24Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java", "diffHunk": "@@ -0,0 +1,110 @@\n+package com.hedera.mirror.importer.parser.record;\n+\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ * \u200b\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ * \u200b\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileNotFoundException;\n+import java.io.InputStream;\n+import java.nio.file.Path;\n+import java.util.Arrays;\n+import javax.inject.Named;\n+import lombok.AllArgsConstructor;\n+import lombok.extern.log4j.Log4j2;\n+import org.apache.commons.io.FileUtils;\n+import org.springframework.scheduling.annotation.Scheduled;\n+\n+import com.hedera.mirror.importer.parser.FilePoller;\n+import com.hedera.mirror.importer.parser.domain.StreamFileData;\n+import com.hedera.mirror.importer.util.ShutdownHelper;\n+import com.hedera.mirror.importer.util.Utility;\n+\n+@Log4j2\n+@Named\n+@ConditionalOnRecordParser\n+@AllArgsConstructor\n+public class RecordFilePoller implements FilePoller {\n+\n+    private final RecordParserProperties parserProperties;\n+    private final RecordFileParser recordFileParser;\n+\n+    @Override\n+    @Scheduled(fixedRateString = \"${hedera.mirror.importer.parser.record.frequency:100}\")\n+    public void poll() {\n+        if (ShutdownHelper.isStopping()) {\n+            return;\n+        }\n+        Path path = parserProperties.getValidPath();\n+        log.debug(\"Parsing record files from {}\", path);\n+        try {\n+            File file = path.toFile();\n+            if (file.isDirectory()) {\n+\n+                String[] files = file.list();\n+                if (files == null || files.length == 0) {\n+                    log.debug(\"No files to parse in directory {}\", file.getPath());\n+                    return;\n+                }\n+\n+                Arrays.sort(files);           // sorted by name (timestamp)\n+\n+                log.trace(\"Processing record files: {}\", files);\n+                loadRecordFiles(files);\n+            } else {\n+                log.error(\"Input parameter is not a folder: {}\", path);\n+            }\n+        } catch (Exception e) {\n+            log.error(\"Error parsing files\", e);\n+        }\n+    }\n+\n+    /**\n+     * read and parse a list of record files\n+     *\n+     * @throws Exception\n+     */\n+    private void loadRecordFiles(String[] filePaths) {\n+        Path validPath = parserProperties.getValidPath();\n+        for (String filePath : filePaths) {\n+            if (ShutdownHelper.isStopping()) {\n+                return;\n+            }\n+\n+            // get file from full path\n+            File file = validPath.resolve(filePath).toFile();\n+\n+            try (InputStream fileInputStream = new FileInputStream(file)) {\n+                recordFileParser.parse(new StreamFileData(file.getAbsolutePath(), fileInputStream));\n+\n+                if (parserProperties.isKeepFiles()) {\n+                    Utility.archiveFile(file, parserProperties.getParsedPath());\n+                } else {\n+                    FileUtils.deleteQuietly(file);\n+                }\n+            } catch (FileNotFoundException e) {\n+                log.warn(\"File does not exist {}\", filePath);\n+                return;\n+            } catch (Exception e) {\n+                log.error(String.format(\"Error parsing file %s\", filePath), e);", "originalCommit": "d83065ef5dd67f75f00548058af9bd067ab89a0b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5bb96f354bf15cbf85e8f6e4364f78d9eaa604e0", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\nindex c5b137b70..e7aa09328 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n", "chunk": "@@ -103,7 +110,11 @@ public class RecordFilePoller implements FilePoller {\n                 log.warn(\"File does not exist {}\", filePath);\n                 return;\n             } catch (Exception e) {\n-                log.error(String.format(\"Error parsing file %s\", filePath), e);\n+                log.error(\"Error parsing file {}\", filePath, e);\n+                if (!(e instanceof DuplicateFileException)) { // if DuplicateFileException, continue with other\n+                    // files\n+                    return;\n+                }\n             }\n         }\n     }\n", "next_change": {"commit": "2ba305984f72c15a7c9551fbc3c82369f518b883", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\nindex e7aa09328..a5bfaf202 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n", "chunk": "@@ -111,10 +108,6 @@ public class RecordFilePoller implements FilePoller {\n                 return;\n             } catch (Exception e) {\n                 log.error(\"Error parsing file {}\", filePath, e);\n-                if (!(e instanceof DuplicateFileException)) { // if DuplicateFileException, continue with other\n-                    // files\n-                    return;\n-                }\n             }\n         }\n     }\n", "next_change": {"commit": "1f345762e97fe2b4a66de19759ceb96eacc11885", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\nindex a5bfaf202..dd1720ca6 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n", "chunk": "@@ -107,7 +107,7 @@ public class RecordFilePoller implements FilePoller {\n                 log.warn(\"File does not exist {}\", filePath);\n                 return;\n             } catch (Exception e) {\n-                log.error(\"Error parsing file {}\", filePath, e);\n+                log.error(String.format(\"Error parsing file %s\", filePath), e);\n             }\n         }\n     }\n", "next_change": {"commit": "1e52bb6ce52d20fab8c3b45955376252c24fe4cd", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\nindex dd1720ca6..d5b6bf905 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFilePoller.java\n", "chunk": "@@ -108,6 +104,7 @@ public class RecordFilePoller implements FilePoller {\n                 return;\n             } catch (Exception e) {\n                 log.error(String.format(\"Error parsing file %s\", filePath), e);\n+                return;\n             }\n         }\n     }\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODIzNjk1MQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r468236951", "body": "Should remove rollbackFor. I don't see a reason to exclude Error.", "bodyText": "Should remove rollbackFor. I don't see a reason to exclude Error.", "bodyHTML": "<p dir=\"auto\">Should remove rollbackFor. I don't see a reason to exclude Error.</p>", "author": "steven-sheehy", "createdAt": "2020-08-10T23:17:20Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -135,11 +124,13 @@ public RecordFileParser(ApplicationStatusRepository applicationStatusRepository,\n     }\n \n     /**\n-     * Given a service record name, read and parse and return as a list of service record pair\n+     * Given a stream file data representing an rcd file from the service parse record items and persist changes\n      *\n      * @param streamFileData containing information about file to be processed\n      */\n-    public void loadRecordFile(StreamFileData streamFileData) {\n+    @Override\n+    @Transactional(rollbackFor = Exception.class)", "originalCommit": "d83065ef5dd67f75f00548058af9bd067ab89a0b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODI0MDcwMA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r468240700", "bodyText": "My understanding was without this RuntimeExceptions wouldn't result in a rollback. But yeah excluding Errors was not an intended impact.", "author": "Nana-EC", "createdAt": "2020-08-10T23:29:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODIzNjk1MQ=="}], "type": "inlineReview", "revised_code": {"commit": "5bb96f354bf15cbf85e8f6e4364f78d9eaa604e0", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex c28f4fda8..3148d43e0 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -129,7 +128,7 @@ public class RecordFileParser implements FileParser {\n      * @param streamFileData containing information about file to be processed\n      */\n     @Override\n-    @Transactional(rollbackFor = Exception.class)\n+    @Transactional\n     public void parse(StreamFileData streamFileData) {\n         Instant startTime = Instant.now();\n \n", "next_change": {"commit": "1f345762e97fe2b4a66de19759ceb96eacc11885", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 3148d43e0..c28f4fda8 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -128,7 +129,7 @@ public class RecordFileParser implements FileParser {\n      * @param streamFileData containing information about file to be processed\n      */\n     @Override\n-    @Transactional\n+    @Transactional(rollbackFor = Exception.class)\n     public void parse(StreamFileData streamFileData) {\n         Instant startTime = Instant.now();\n \n", "next_change": {"commit": "1e52bb6ce52d20fab8c3b45955376252c24fe4cd", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex c28f4fda8..89a913f12 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -129,7 +129,7 @@ public class RecordFileParser implements FileParser {\n      * @param streamFileData containing information about file to be processed\n      */\n     @Override\n-    @Transactional(rollbackFor = Exception.class)\n+    @Transactional\n     public void parse(StreamFileData streamFileData) {\n         Instant startTime = Instant.now();\n \n", "next_change": {"commit": "ba7113b865a5b82f3cf74e3c8c06f6979e29dc86", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 89a913f12..d7b968812 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -129,7 +128,6 @@ public class RecordFileParser implements FileParser {\n      * @param streamFileData containing information about file to be processed\n      */\n     @Override\n-    @Transactional\n     public void parse(StreamFileData streamFileData) {\n         Instant startTime = Instant.now();\n \n", "next_change": {"commit": "2f751b76b7302fa4d8b274c54c191ac2bb9d151b", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex d7b968812..de4662fcd 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -131,12 +131,12 @@ public class RecordFileParser implements FileParser {\n     public void parse(StreamFileData streamFileData) {\n         Instant startTime = Instant.now();\n \n-        recordStreamFileListener.onStart(streamFileData);\n         String expectedPrevFileHash =\n                 applicationStatusRepository.findByStatusCode(ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH);\n         AtomicInteger counter = new AtomicInteger(0);\n         boolean success = false;\n         try {\n+            recordStreamFileListener.onStart(streamFileData);\n             Stopwatch stopwatch = Stopwatch.createStarted();\n             RecordFile recordFile = Utility.parseRecordFile(\n                     streamFileData.getFilename(), expectedPrevFileHash,\n", "next_change": null}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODIzNzY3Nw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r468237677", "body": "I think it's fine to just log this instead of rethrow. Also, because we want to ensure `cleanup()` is always called.", "bodyText": "I think it's fine to just log this instead of rethrow. Also, because we want to ensure cleanup() is always called.", "bodyHTML": "<p dir=\"auto\">I think it's fine to just log this instead of rethrow. Also, because we want to ensure <code>cleanup()</code> is always called.</p>", "author": "steven-sheehy", "createdAt": "2020-08-10T23:19:52Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java", "diffHunk": "@@ -198,9 +184,11 @@ private void executeBatch(PreparedStatement ps, String entity) {\n \n     private void closeConnectionAndStatements() {\n         try {\n-            sqlInsertEntityId.close();\n-            sqlNotifyTopicMessage.close();\n-            connection.close();\n+            if (connection != null) {\n+                sqlInsertEntityId.close();\n+                sqlNotifyTopicMessage.close();\n+                connection.close();\n+            }\n         } catch (SQLException e) {\n             throw new ParserSQLException(\"Error closing connection\", e);", "originalCommit": "d83065ef5dd67f75f00548058af9bd067ab89a0b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5bb96f354bf15cbf85e8f6e4364f78d9eaa604e0", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 5166bb8d6..08a960576 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -184,11 +200,9 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n \n     private void closeConnectionAndStatements() {\n         try {\n-            if (connection != null) {\n-                sqlInsertEntityId.close();\n-                sqlNotifyTopicMessage.close();\n-                connection.close();\n-            }\n+            sqlInsertEntityId.close();\n+            sqlNotifyTopicMessage.close();\n+            connection.close();\n         } catch (SQLException e) {\n             throw new ParserSQLException(\"Error closing connection\", e);\n         }\n", "next_change": {"commit": "2ba305984f72c15a7c9551fbc3c82369f518b883", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 08a960576..5166bb8d6 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -200,9 +184,11 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n \n     private void closeConnectionAndStatements() {\n         try {\n-            sqlInsertEntityId.close();\n-            sqlNotifyTopicMessage.close();\n-            connection.close();\n+            if (connection != null) {\n+                sqlInsertEntityId.close();\n+                sqlNotifyTopicMessage.close();\n+                connection.close();\n+            }\n         } catch (SQLException e) {\n             throw new ParserSQLException(\"Error closing connection\", e);\n         }\n", "next_change": {"commit": "1e52bb6ce52d20fab8c3b45955376252c24fe4cd", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 5166bb8d6..06ce2def5 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -190,7 +190,7 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n                 connection.close();\n             }\n         } catch (SQLException e) {\n-            throw new ParserSQLException(\"Error closing connection\", e);\n+            log.error(\"Error closing connection\", e);\n         }\n     }\n \n", "next_change": {"commit": "2b2939cc5c9779e6d415c9d1e674f37356378ab8", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 06ce2def5..d4adc3dec 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -182,15 +188,13 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         }\n     }\n \n-    private void closeConnectionAndStatements() {\n+    private void closeQuietly(Statement statement) {\n         try {\n-            if (connection != null) {\n-                sqlInsertEntityId.close();\n-                sqlNotifyTopicMessage.close();\n-                connection.close();\n+            if (statement != null) {\n+                statement.close();\n             }\n-        } catch (SQLException e) {\n-            log.error(\"Error closing connection\", e);\n+        } catch (Exception e) {\n+            log.warn(\"Error closing statement\", e);\n         }\n     }\n \n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjQxMzI2OQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r472413269", "body": "I believe moving this into SqlEntityListener breaks PubSub as it doesn't update the last processed hash.", "bodyText": "I believe moving this into SqlEntityListener breaks PubSub as it doesn't update the last processed hash.", "bodyHTML": "<p dir=\"auto\">I believe moving this into SqlEntityListener breaks PubSub as it doesn't update the last processed hash.</p>", "author": "steven-sheehy", "createdAt": "2020-08-18T18:57:20Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -160,16 +149,19 @@ public void loadRecordFile(StreamFileData streamFileData) {\n             recordFile.setLoadStart(startTime.getEpochSecond());\n             recordFile.setLoadEnd(Instant.now().getEpochSecond());\n             recordStreamFileListener.onEnd(recordFile);\n-            applicationStatusRepository.updateStatusValue(\n-                    ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, recordFile.getFileHash());", "originalCommit": "1784e6532764d38f2188cdacb62970cf3f4feba0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE2NTQ4NA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r474165484", "bodyText": "Good point", "author": "Nana-EC", "createdAt": "2020-08-20T17:47:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjQxMzI2OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDQ2OTEzNQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r474469135", "bodyText": "I think it's more important for SqlEntityListener to have control of the db writes. So I stuck with this and added the hash update to the pubs flow", "author": "Nana-EC", "createdAt": "2020-08-21T07:29:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjQxMzI2OQ=="}], "type": "inlineReview", "revised_code": {"commit": "5bb96f354bf15cbf85e8f6e4364f78d9eaa604e0", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex de4662fcd..3148d43e0 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -149,19 +150,20 @@ public class RecordFileParser implements FileParser {\n             recordFile.setLoadStart(startTime.getEpochSecond());\n             recordFile.setLoadEnd(Instant.now().getEpochSecond());\n             recordStreamFileListener.onEnd(recordFile);\n+            applicationStatusRepository.updateStatusValue(\n+                    ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, recordFile.getFileHash());\n \n             recordParserLatencyMetric(recordFile);\n             success = true;\n-        } catch (DuplicateFileException ex) {\n-            log.warn(String.format(\"Skipping file %s\", streamFileData.getFilename()), ex);\n         } catch (Exception ex) {\n-            recordStreamFileListener.onError(); // rollback\n+            log.warn(\"Failed to parse {}\", streamFileData.getFilename(), ex);\n+            recordStreamFileListener.onError(); // rollback changes\n             throw ex;\n         } finally {\n             var elapsedTimeMillis = Duration.between(startTime, Instant.now()).toMillis();\n             var rate = elapsedTimeMillis > 0 ? (int) (1000.0 * counter.get() / elapsedTimeMillis) : 0;\n-            log.info(\"Finished parsing {} transactions from record file {} in {}ms ({}/s). Success: {}\",\n-                    counter, streamFileData.getFilename(), elapsedTimeMillis, rate, success);\n+            log.info(\"Finished parsing {} transactions from record file {} in {}ms ({}/s)\",\n+                    counter, streamFileData.getFilename(), elapsedTimeMillis, rate);\n             parseDurationMetrics.get(success).record(elapsedTimeMillis, TimeUnit.MILLISECONDS);\n         }\n     }\n", "next_change": {"commit": "1f345762e97fe2b4a66de19759ceb96eacc11885", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 3148d43e0..c28f4fda8 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -155,15 +156,16 @@ public class RecordFileParser implements FileParser {\n \n             recordParserLatencyMetric(recordFile);\n             success = true;\n+        } catch (DuplicateFileException ex) {\n+            log.warn(\"Skipping file {}\", ex);\n         } catch (Exception ex) {\n-            log.warn(\"Failed to parse {}\", streamFileData.getFilename(), ex);\n-            recordStreamFileListener.onError(); // rollback changes\n+            recordStreamFileListener.onError();\n             throw ex;\n         } finally {\n             var elapsedTimeMillis = Duration.between(startTime, Instant.now()).toMillis();\n             var rate = elapsedTimeMillis > 0 ? (int) (1000.0 * counter.get() / elapsedTimeMillis) : 0;\n-            log.info(\"Finished parsing {} transactions from record file {} in {}ms ({}/s)\",\n-                    counter, streamFileData.getFilename(), elapsedTimeMillis, rate);\n+            log.info(\"Finished parsing {} transactions from record file {} in {}ms ({}/s). Success: {}\",\n+                    counter, streamFileData.getFilename(), elapsedTimeMillis, rate, success);\n             parseDurationMetrics.get(success).record(elapsedTimeMillis, TimeUnit.MILLISECONDS);\n         }\n     }\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjQxNjk1Ng==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r472416956", "body": "nit: Would prefer parameters be named the same as the fields as most of the other fields are.", "bodyText": "nit: Would prefer parameters be named the same as the fields as most of the other fields are.", "bodyHTML": "<p dir=\"auto\">nit: Would prefer parameters be named the same as the fields as most of the other fields are.</p>", "author": "steven-sheehy", "createdAt": "2020-08-18T19:04:26Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java", "diffHunk": "@@ -95,13 +105,20 @@\n     private PreparedStatement sqlNotifyTopicMessage;\n     private Connection connection;\n     private long batchCount;\n+    private RecordFile partialRecordFile;\n \n     public SqlEntityListener(SqlProperties properties, DataSource dataSource,\n                              RecordFileRepository recordFileRepository, MeterRegistry meterRegistry,\n-                             @Qualifier(CacheConfiguration.NEVER_EXPIRE_LARGE) CacheManager cacheManager) {\n+                             @Qualifier(CacheConfiguration.NEVER_EXPIRE_LARGE) CacheManager cacheManager,\n+                             ApplicationStatusRepository applicationStatusRepository,\n+                             TransactionRepository transactionRepository,\n+                             RecordParserProperties parserProps) {\n         this.dataSource = dataSource;\n+        this.applicationStatusRepository = applicationStatusRepository;\n         this.recordFileRepository = recordFileRepository;\n+        this.transactionRepository = transactionRepository;\n         sqlProperties = properties;\n+        parserProperties = parserProps;", "originalCommit": "1784e6532764d38f2188cdacb62970cf3f4feba0", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5bb96f354bf15cbf85e8f6e4364f78d9eaa604e0", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex e1ff29af0..08a960576 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -105,20 +96,13 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n     private PreparedStatement sqlNotifyTopicMessage;\n     private Connection connection;\n     private long batchCount;\n-    private RecordFile partialRecordFile;\n \n     public SqlEntityListener(SqlProperties properties, DataSource dataSource,\n                              RecordFileRepository recordFileRepository, MeterRegistry meterRegistry,\n-                             @Qualifier(CacheConfiguration.NEVER_EXPIRE_LARGE) CacheManager cacheManager,\n-                             ApplicationStatusRepository applicationStatusRepository,\n-                             TransactionRepository transactionRepository,\n-                             RecordParserProperties parserProps) {\n+                             @Qualifier(CacheConfiguration.NEVER_EXPIRE_LARGE) CacheManager cacheManager) {\n         this.dataSource = dataSource;\n-        this.applicationStatusRepository = applicationStatusRepository;\n         this.recordFileRepository = recordFileRepository;\n-        this.transactionRepository = transactionRepository;\n         sqlProperties = properties;\n-        parserProperties = parserProps;\n         entityCache = cacheManager.getCache(CacheConfiguration.NEVER_EXPIRE_LARGE);\n \n         transactionPgCopy = new PgCopy<>(Transaction.class, meterRegistry, properties);\n", "next_change": {"commit": "2f751b76b7302fa4d8b274c54c191ac2bb9d151b", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 08a960576..e1ff29af0 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -96,13 +105,20 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n     private PreparedStatement sqlNotifyTopicMessage;\n     private Connection connection;\n     private long batchCount;\n+    private RecordFile partialRecordFile;\n \n     public SqlEntityListener(SqlProperties properties, DataSource dataSource,\n                              RecordFileRepository recordFileRepository, MeterRegistry meterRegistry,\n-                             @Qualifier(CacheConfiguration.NEVER_EXPIRE_LARGE) CacheManager cacheManager) {\n+                             @Qualifier(CacheConfiguration.NEVER_EXPIRE_LARGE) CacheManager cacheManager,\n+                             ApplicationStatusRepository applicationStatusRepository,\n+                             TransactionRepository transactionRepository,\n+                             RecordParserProperties parserProps) {\n         this.dataSource = dataSource;\n+        this.applicationStatusRepository = applicationStatusRepository;\n         this.recordFileRepository = recordFileRepository;\n+        this.transactionRepository = transactionRepository;\n         sqlProperties = properties;\n+        parserProperties = parserProps;\n         entityCache = cacheManager.getCache(CacheConfiguration.NEVER_EXPIRE_LARGE);\n \n         transactionPgCopy = new PgCopy<>(Transaction.class, meterRegistry, properties);\n", "next_change": {"commit": "2b2939cc5c9779e6d415c9d1e674f37356378ab8", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex e1ff29af0..d4adc3dec 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -105,29 +98,24 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n     private PreparedStatement sqlNotifyTopicMessage;\n     private Connection connection;\n     private long batchCount;\n-    private RecordFile partialRecordFile;\n \n-    public SqlEntityListener(SqlProperties properties, DataSource dataSource,\n+    public SqlEntityListener(SqlProperties sqlProperties, DataSource dataSource,\n                              RecordFileRepository recordFileRepository, MeterRegistry meterRegistry,\n                              @Qualifier(CacheConfiguration.NEVER_EXPIRE_LARGE) CacheManager cacheManager,\n-                             ApplicationStatusRepository applicationStatusRepository,\n-                             TransactionRepository transactionRepository,\n-                             RecordParserProperties parserProps) {\n+                             ApplicationStatusRepository applicationStatusRepository) {\n         this.dataSource = dataSource;\n         this.applicationStatusRepository = applicationStatusRepository;\n         this.recordFileRepository = recordFileRepository;\n-        this.transactionRepository = transactionRepository;\n-        sqlProperties = properties;\n-        parserProperties = parserProps;\n+        this.sqlProperties = sqlProperties;\n         entityCache = cacheManager.getCache(CacheConfiguration.NEVER_EXPIRE_LARGE);\n \n-        transactionPgCopy = new PgCopy<>(Transaction.class, meterRegistry, properties);\n-        cryptoTransferPgCopy = new PgCopy<>(CryptoTransfer.class, meterRegistry, properties);\n-        nonFeeTransferPgCopy = new PgCopy<>(NonFeeTransfer.class, meterRegistry, properties);\n-        fileDataPgCopy = new PgCopy<>(FileData.class, meterRegistry, properties);\n-        contractResultPgCopy = new PgCopy<>(ContractResult.class, meterRegistry, properties);\n-        liveHashPgCopy = new PgCopy<>(LiveHash.class, meterRegistry, properties);\n-        topicMessagePgCopy = new PgCopy<>(TopicMessage.class, meterRegistry, properties);\n+        transactionPgCopy = new PgCopy<>(Transaction.class, meterRegistry, sqlProperties);\n+        cryptoTransferPgCopy = new PgCopy<>(CryptoTransfer.class, meterRegistry, sqlProperties);\n+        nonFeeTransferPgCopy = new PgCopy<>(NonFeeTransfer.class, meterRegistry, sqlProperties);\n+        fileDataPgCopy = new PgCopy<>(FileData.class, meterRegistry, sqlProperties);\n+        contractResultPgCopy = new PgCopy<>(ContractResult.class, meterRegistry, sqlProperties);\n+        liveHashPgCopy = new PgCopy<>(LiveHash.class, meterRegistry, sqlProperties);\n+        topicMessagePgCopy = new PgCopy<>(TopicMessage.class, meterRegistry, sqlProperties);\n \n         transactions = new ArrayList<>();\n         cryptoTransfers = new ArrayList<>();\n", "next_change": {"commit": "e962d8dd5fe0a06ae248ba04f604c44e24be85ea", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex d4adc3dec..97b154805 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -123,21 +125,16 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         fileData = new ArrayList<>();\n         contractResults = new ArrayList<>();\n         liveHashes = new ArrayList<>();\n-        entityIds = new HashSet<>();\n+        entityIds = new ArrayList<>();\n         topicMessages = new ArrayList<>();\n     }\n \n     @Override\n     public void onStart(StreamFileData streamFileData) {\n         try {\n-            cleanup();\n+            cleanup(false, true);\n             connection = DataSourceUtils.getConnection(dataSource);\n \n-            sqlInsertEntityId = connection.prepareStatement(\"INSERT INTO t_entities \" +\n-                    \"(id, entity_shard, entity_realm, entity_num, fk_entity_type_id) \" +\n-                    \"VALUES (?, ?, ?, ?, ?) \" +\n-                    \"ON CONFLICT DO NOTHING\");\n-\n             sqlNotifyTopicMessage = connection.prepareStatement(\"select pg_notify('topic_message', ?)\");\n         } catch (SQLException e) {\n             throw new ParserSQLException(\"Error setting up connection to database\", e);\n", "next_change": {"commit": "cab3a93ee3e294ad55a39b4f1501658c574f035d", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 97b154805..adba9f368 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -141,6 +142,7 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         }\n     }\n \n+    @Transactional\n     @Override\n     public void onEnd(RecordFile recordFile) {\n         executeBatches();\n", "next_change": {"commit": "b4cc3eb744b66c38142331083132933c04c42c6e", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex adba9f368..b8d4e420c 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -141,8 +140,7 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n             throw new ParserSQLException(\"Error setting up connection to database\", e);\n         }\n     }\n-\n-    @Transactional\n+    \n     @Override\n     public void onEnd(RecordFile recordFile) {\n         executeBatches();\n", "next_change": {"commit": "e969c08a4d361fcc7d24aa828f08a0033611ed2b", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex b8d4e420c..97b154805 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -140,7 +140,7 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n             throw new ParserSQLException(\"Error setting up connection to database\", e);\n         }\n     }\n-    \n+\n     @Override\n     public void onEnd(RecordFile recordFile) {\n         executeBatches();\n", "next_change": {"commit": "3eedeade2e3496808da55fc270a1dc5619a4a4f5", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 97b154805..2867187cd 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -145,43 +147,34 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n     public void onEnd(RecordFile recordFile) {\n         executeBatches();\n \n-        boolean releaseConnection = false;\n         try {\n             recordFileRepository.save(recordFile);\n             applicationStatusRepository.updateStatusValue(\n                     ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, recordFile.getFileHash());\n-            releaseConnection = true;\n         } finally {\n-            cleanup(false, releaseConnection);\n+            cleanup();\n         }\n     }\n \n     @Override\n     public void onError() {\n-        cleanup(true, true);\n+        cleanup();\n     }\n \n-    private void cleanup(boolean isRollBackCleanup, boolean releaseConnection) {\n-        if (isRollBackCleanup) {\n-            // evict entities from cache from this round of batches as they were rolled back\n-            entityIds.forEach(entityId -> entityCache.evict(entityId.getId()));\n-        }\n-\n+    private void cleanup() {\n         closeQuietly(sqlNotifyTopicMessage);\n         sqlNotifyTopicMessage = null;\n         batchCount = 0;\n         contractResults.clear();\n         cryptoTransfers.clear();\n+        entityIds.clear();\n         fileData.clear();\n         liveHashes.clear();\n         nonFeeTransfers.clear();\n         topicMessages.clear();\n         transactions.clear();\n \n-        if (releaseConnection) {\n-            entityIds.clear();\n-            DataSourceUtils.releaseConnection(connection, dataSource);\n-        }\n+        DataSourceUtils.releaseConnection(connection, dataSource);\n     }\n \n     private void executeBatch(PreparedStatement ps, String entity) {\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjQyNTk0OQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r472425949", "body": "Turns out `record_file.name` has a unique constraint so this can't happen. Remove", "bodyText": "Turns out record_file.name has a unique constraint so this can't happen. Remove", "bodyHTML": "<p dir=\"auto\">Turns out <code>record_file.name</code> has a unique constraint so this can't happen. Remove</p>", "author": "steven-sheehy", "createdAt": "2020-08-18T19:20:42Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -160,16 +149,19 @@ public void loadRecordFile(StreamFileData streamFileData) {\n             recordFile.setLoadStart(startTime.getEpochSecond());\n             recordFile.setLoadEnd(Instant.now().getEpochSecond());\n             recordStreamFileListener.onEnd(recordFile);\n-            applicationStatusRepository.updateStatusValue(\n-                    ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, recordFile.getFileHash());\n \n             recordParserLatencyMetric(recordFile);\n             success = true;\n+        } catch (DuplicateFileException ex) {", "originalCommit": "1784e6532764d38f2188cdacb62970cf3f4feba0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE3MDc4Mw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r474170783", "bodyText": "Removed", "author": "Nana-EC", "createdAt": "2020-08-20T17:57:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjQyNTk0OQ=="}], "type": "inlineReview", "revised_code": {"commit": "5bb96f354bf15cbf85e8f6e4364f78d9eaa604e0", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex de4662fcd..3148d43e0 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -149,19 +150,20 @@ public class RecordFileParser implements FileParser {\n             recordFile.setLoadStart(startTime.getEpochSecond());\n             recordFile.setLoadEnd(Instant.now().getEpochSecond());\n             recordStreamFileListener.onEnd(recordFile);\n+            applicationStatusRepository.updateStatusValue(\n+                    ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, recordFile.getFileHash());\n \n             recordParserLatencyMetric(recordFile);\n             success = true;\n-        } catch (DuplicateFileException ex) {\n-            log.warn(String.format(\"Skipping file %s\", streamFileData.getFilename()), ex);\n         } catch (Exception ex) {\n-            recordStreamFileListener.onError(); // rollback\n+            log.warn(\"Failed to parse {}\", streamFileData.getFilename(), ex);\n+            recordStreamFileListener.onError(); // rollback changes\n             throw ex;\n         } finally {\n             var elapsedTimeMillis = Duration.between(startTime, Instant.now()).toMillis();\n             var rate = elapsedTimeMillis > 0 ? (int) (1000.0 * counter.get() / elapsedTimeMillis) : 0;\n-            log.info(\"Finished parsing {} transactions from record file {} in {}ms ({}/s). Success: {}\",\n-                    counter, streamFileData.getFilename(), elapsedTimeMillis, rate, success);\n+            log.info(\"Finished parsing {} transactions from record file {} in {}ms ({}/s)\",\n+                    counter, streamFileData.getFilename(), elapsedTimeMillis, rate);\n             parseDurationMetrics.get(success).record(elapsedTimeMillis, TimeUnit.MILLISECONDS);\n         }\n     }\n", "next_change": {"commit": "1f345762e97fe2b4a66de19759ceb96eacc11885", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\nindex 3148d43e0..c28f4fda8 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java\n", "chunk": "@@ -155,15 +156,16 @@ public class RecordFileParser implements FileParser {\n \n             recordParserLatencyMetric(recordFile);\n             success = true;\n+        } catch (DuplicateFileException ex) {\n+            log.warn(\"Skipping file {}\", ex);\n         } catch (Exception ex) {\n-            log.warn(\"Failed to parse {}\", streamFileData.getFilename(), ex);\n-            recordStreamFileListener.onError(); // rollback changes\n+            recordStreamFileListener.onError();\n             throw ex;\n         } finally {\n             var elapsedTimeMillis = Duration.between(startTime, Instant.now()).toMillis();\n             var rate = elapsedTimeMillis > 0 ? (int) (1000.0 * counter.get() / elapsedTimeMillis) : 0;\n-            log.info(\"Finished parsing {} transactions from record file {} in {}ms ({}/s)\",\n-                    counter, streamFileData.getFilename(), elapsedTimeMillis, rate);\n+            log.info(\"Finished parsing {} transactions from record file {} in {}ms ({}/s). Success: {}\",\n+                    counter, streamFileData.getFilename(), elapsedTimeMillis, rate, success);\n             parseDurationMetrics.get(success).record(elapsedTimeMillis, TimeUnit.MILLISECONDS);\n         }\n     }\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUxMDU0Ng==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r472510546", "body": "name is unique so this repository method can only ever return one entry. Should be adjusted to return single optional and handle method be adjusted.", "bodyText": "name is unique so this repository method can only ever return one entry. Should be adjusted to return single optional and handle method be adjusted.", "bodyHTML": "<p dir=\"auto\">name is unique so this repository method can only ever return one entry. Should be adjusted to return single optional and handle method be adjusted.</p>", "author": "steven-sheehy", "createdAt": "2020-08-18T21:43:59Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java", "diffHunk": "@@ -120,14 +137,18 @@ public SqlEntityListener(SqlProperties properties, DataSource dataSource,\n         liveHashes = new ArrayList<>();\n         entityIds = new HashSet<>();\n         topicMessages = new ArrayList<>();\n+        partialRecordFile = null;\n     }\n \n     @Override\n     public void onStart(StreamFileData streamFileData) {\n         String fileName = FilenameUtils.getName(streamFileData.getFilename());\n \n-        if (recordFileRepository.findByName(fileName).size() > 0) {\n-            throw new DuplicateFileException(\"File already exists in the database: \" + fileName);\n+        List<RecordFile> matchingRecords = recordFileRepository.findByName(fileName);", "originalCommit": "1784e6532764d38f2188cdacb62970cf3f4feba0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE2NjkzNQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r474166935", "bodyText": "Handle method removed :)", "author": "Nana-EC", "createdAt": "2020-08-20T17:50:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUxMDU0Ng=="}], "type": "inlineReview", "revised_code": {"commit": "5bb96f354bf15cbf85e8f6e4364f78d9eaa604e0", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex e1ff29af0..08a960576 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -137,18 +121,14 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         liveHashes = new ArrayList<>();\n         entityIds = new HashSet<>();\n         topicMessages = new ArrayList<>();\n-        partialRecordFile = null;\n     }\n \n     @Override\n     public void onStart(StreamFileData streamFileData) {\n         String fileName = FilenameUtils.getName(streamFileData.getFilename());\n \n-        List<RecordFile> matchingRecords = recordFileRepository.findByName(fileName);\n-        partialRecordFile = null;\n-        if (matchingRecords.size() > 0) {\n-            partialRecordFile = matchingRecords.get(0); // cache to avoid jpa exception\n-            handleDuplicateOrPartiallyProcessedRecordFile(partialRecordFile);\n+        if (recordFileRepository.findByName(fileName).size() > 0) {\n+            throw new DuplicateFileException(\"File already exists in the database: \" + fileName);\n         }\n \n         try {\n", "next_change": {"commit": "2ba305984f72c15a7c9551fbc3c82369f518b883", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 08a960576..5166bb8d6 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -134,7 +133,6 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         try {\n             cleanup();\n             connection = dataSource.getConnection();\n-            connection.setAutoCommit(false);\n             connection.setClientInfo(\"ApplicationName\", getClass().getSimpleName());\n \n             sqlInsertEntityId = connection.prepareStatement(\"INSERT INTO t_entities \" +\n", "next_change": {"commit": "ba7113b865a5b82f3cf74e3c8c06f6979e29dc86", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 5166bb8d6..1afedc206 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -133,6 +133,7 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         try {\n             cleanup();\n             connection = dataSource.getConnection();\n+            connection.setAutoCommit(false);\n             connection.setClientInfo(\"ApplicationName\", getClass().getSimpleName());\n \n             sqlInsertEntityId = connection.prepareStatement(\"INSERT INTO t_entities \" +\n", "next_change": {"commit": "2b2939cc5c9779e6d415c9d1e674f37356378ab8", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 1afedc206..d4adc3dec 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -124,17 +129,9 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n \n     @Override\n     public void onStart(StreamFileData streamFileData) {\n-        String fileName = FilenameUtils.getName(streamFileData.getFilename());\n-\n-        if (recordFileRepository.findByName(fileName).size() > 0) {\n-            throw new DuplicateFileException(\"File already exists in the database: \" + fileName);\n-        }\n-\n         try {\n             cleanup();\n-            connection = dataSource.getConnection();\n-            connection.setAutoCommit(false);\n-            connection.setClientInfo(\"ApplicationName\", getClass().getSimpleName());\n+            connection = DataSourceUtils.getConnection(dataSource);\n \n             sqlInsertEntityId = connection.prepareStatement(\"INSERT INTO t_entities \" +\n                     \"(id, entity_shard, entity_realm, entity_num, fk_entity_type_id) \" +\n", "next_change": {"commit": "e962d8dd5fe0a06ae248ba04f604c44e24be85ea", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex d4adc3dec..97b154805 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -123,21 +125,16 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         fileData = new ArrayList<>();\n         contractResults = new ArrayList<>();\n         liveHashes = new ArrayList<>();\n-        entityIds = new HashSet<>();\n+        entityIds = new ArrayList<>();\n         topicMessages = new ArrayList<>();\n     }\n \n     @Override\n     public void onStart(StreamFileData streamFileData) {\n         try {\n-            cleanup();\n+            cleanup(false, true);\n             connection = DataSourceUtils.getConnection(dataSource);\n \n-            sqlInsertEntityId = connection.prepareStatement(\"INSERT INTO t_entities \" +\n-                    \"(id, entity_shard, entity_realm, entity_num, fk_entity_type_id) \" +\n-                    \"VALUES (?, ?, ?, ?, ?) \" +\n-                    \"ON CONFLICT DO NOTHING\");\n-\n             sqlNotifyTopicMessage = connection.prepareStatement(\"select pg_notify('topic_message', ?)\");\n         } catch (SQLException e) {\n             throw new ParserSQLException(\"Error setting up connection to database\", e);\n", "next_change": {"commit": "cab3a93ee3e294ad55a39b4f1501658c574f035d", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 97b154805..adba9f368 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -141,6 +142,7 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         }\n     }\n \n+    @Transactional\n     @Override\n     public void onEnd(RecordFile recordFile) {\n         executeBatches();\n", "next_change": {"commit": "b4cc3eb744b66c38142331083132933c04c42c6e", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex adba9f368..b8d4e420c 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -141,8 +140,7 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n             throw new ParserSQLException(\"Error setting up connection to database\", e);\n         }\n     }\n-\n-    @Transactional\n+    \n     @Override\n     public void onEnd(RecordFile recordFile) {\n         executeBatches();\n", "next_change": {"commit": "e969c08a4d361fcc7d24aa828f08a0033611ed2b", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex b8d4e420c..97b154805 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -140,7 +140,7 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n             throw new ParserSQLException(\"Error setting up connection to database\", e);\n         }\n     }\n-    \n+\n     @Override\n     public void onEnd(RecordFile recordFile) {\n         executeBatches();\n", "next_change": {"commit": "3eedeade2e3496808da55fc270a1dc5619a4a4f5", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 97b154805..2867187cd 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -145,43 +147,34 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n     public void onEnd(RecordFile recordFile) {\n         executeBatches();\n \n-        boolean releaseConnection = false;\n         try {\n             recordFileRepository.save(recordFile);\n             applicationStatusRepository.updateStatusValue(\n                     ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, recordFile.getFileHash());\n-            releaseConnection = true;\n         } finally {\n-            cleanup(false, releaseConnection);\n+            cleanup();\n         }\n     }\n \n     @Override\n     public void onError() {\n-        cleanup(true, true);\n+        cleanup();\n     }\n \n-    private void cleanup(boolean isRollBackCleanup, boolean releaseConnection) {\n-        if (isRollBackCleanup) {\n-            // evict entities from cache from this round of batches as they were rolled back\n-            entityIds.forEach(entityId -> entityCache.evict(entityId.getId()));\n-        }\n-\n+    private void cleanup() {\n         closeQuietly(sqlNotifyTopicMessage);\n         sqlNotifyTopicMessage = null;\n         batchCount = 0;\n         contractResults.clear();\n         cryptoTransfers.clear();\n+        entityIds.clear();\n         fileData.clear();\n         liveHashes.clear();\n         nonFeeTransfers.clear();\n         topicMessages.clear();\n         transactions.clear();\n \n-        if (releaseConnection) {\n-            entityIds.clear();\n-            DataSourceUtils.releaseConnection(connection, dataSource);\n-        }\n+        DataSourceUtils.releaseConnection(connection, dataSource);\n     }\n \n     private void executeBatch(PreparedStatement ps, String entity) {\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzEwMDAyMA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r473100020", "body": "Filesystem is case sensitive so comparison should be as well.", "bodyText": "Filesystem is case sensitive so comparison should be as well.", "bodyHTML": "<p dir=\"auto\">Filesystem is case sensitive so comparison should be as well.</p>", "author": "steven-sheehy", "createdAt": "2020-08-19T15:04:41Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java", "diffHunk": "@@ -314,6 +339,65 @@ private void notifyTopicMessages() {\n         executeBatch(sqlNotifyTopicMessage, \"topic notifications\");\n     }\n \n+    /**\n+     * Handle purely duplicate file in addition to faulty transaction management between spring repositories and manual\n+     * java sql operations. Check whether the given file was partially processed and matches the last record file\n+     * processed where the record_file table was updated but application_status table LAST_PROCESSED_RECORD_HASH was not\n+     * updated. If so update application_status table LAST_PROCESSED_RECORD_HASH appropriately with correct hash. Also\n+     * handle case where transaction data was rolled bach but not record_file entry\n+     *\n+     * @param recordFile record file object that was partially processed file\n+     */\n+    private void handleDuplicateOrPartiallyProcessedRecordFile(RecordFile recordFile) {\n+        // handle faulty transaction management between spring repositories and manual java sql operations\n+        DuplicateFileException duplicateFileException = new DuplicateFileException(\"File already exists in the \" +\n+                \"database: \" + recordFile.getName());\n+        RecordFile latestRecordFile = recordFileRepository.findTopByOrderByConsensusEndDesc().get();\n+        String lastRecordFileHash =\n+                applicationStatusRepository.findByStatusCode(ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH);\n+\n+        // check if latest record file is a match processed file by comparing name and hash\n+        if (latestRecordFile.getName().equalsIgnoreCase(recordFile.getName()) &&", "originalCommit": "1784e6532764d38f2188cdacb62970cf3f4feba0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE2NzM5MQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r474167391", "bodyText": "No longer applicable.", "author": "Nana-EC", "createdAt": "2020-08-20T17:51:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzEwMDAyMA=="}], "type": "inlineReview", "revised_code": {"commit": "5bb96f354bf15cbf85e8f6e4364f78d9eaa604e0", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex e1ff29af0..08a960576 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -339,65 +316,6 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         executeBatch(sqlNotifyTopicMessage, \"topic notifications\");\n     }\n \n-    /**\n-     * Handle purely duplicate file in addition to faulty transaction management between spring repositories and manual\n-     * java sql operations. Check whether the given file was partially processed and matches the last record file\n-     * processed where the record_file table was updated but application_status table LAST_PROCESSED_RECORD_HASH was not\n-     * updated. If so update application_status table LAST_PROCESSED_RECORD_HASH appropriately with correct hash. Also\n-     * handle case where transaction data was rolled bach but not record_file entry\n-     *\n-     * @param recordFile record file object that was partially processed file\n-     */\n-    private void handleDuplicateOrPartiallyProcessedRecordFile(RecordFile recordFile) {\n-        // handle faulty transaction management between spring repositories and manual java sql operations\n-        DuplicateFileException duplicateFileException = new DuplicateFileException(\"File already exists in the \" +\n-                \"database: \" + recordFile.getName());\n-        RecordFile latestRecordFile = recordFileRepository.findTopByOrderByConsensusEndDesc().get();\n-        String lastRecordFileHash =\n-                applicationStatusRepository.findByStatusCode(ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH);\n-\n-        // check if latest record file is a match processed file by comparing name and hash\n-        if (latestRecordFile.getName().equalsIgnoreCase(recordFile.getName()) &&\n-                !Utility.verifyHashChain(\n-                        latestRecordFile.getFileHash(),\n-                        lastRecordFileHash,\n-                        parserProperties.getMirrorProperties().getVerifyHashAfter(),\n-                        recordFile.getName())) {\n-\n-            // check if this file is next in line of hash chain\n-            // Assumes application status updates after record_file update which is current process\n-            if (Utility.verifyHashChain(\n-                    latestRecordFile.getPreviousHash(),\n-                    lastRecordFileHash,\n-                    parserProperties.getMirrorProperties().getVerifyHashAfter(),\n-                    recordFile.getName())) {\n-                // application_status outdated\n-                log.debug(\"Duplicate file failed to update applicationStatus on previous processing, updating now!\");\n-                applicationStatusRepository.updateStatusValue(\n-                        ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, latestRecordFile.getFileHash());\n-                throw duplicateFileException;\n-            } else {\n-                // very unlikely edge case\n-                log.warn(\"Latest file already exists but has mismatched hash for expectedPrevFileHash: \", recordFile\n-                        .getName());\n-                throw new HashMismatchException(recordFile.getName(), lastRecordFileHash, latestRecordFile\n-                        .getFileHash());\n-            }\n-        } else {\n-            // check if transactions are already present\n-            if (transactionRepository.existsById(recordFile.getConsensusStart()) &&\n-                    transactionRepository.existsById(recordFile.getConsensusEnd())) {\n-                throw duplicateFileException;\n-            }\n-        }\n-\n-        // allow file processing but update to previous hash\n-        applicationStatusRepository.updateStatusValue(\n-                ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, latestRecordFile.getPreviousHash());\n-        log.debug(\"Transactions from partially processed record file {} were not persisted! Reprocessing...\",\n-                recordFile.getName());\n-    }\n-\n     enum F_ENTITY_ID {\n         ZERO, // column indices start at 1, this creates the necessary offset\n         ID, ENTITY_SHARD, ENTITY_REALM, ENTITY_NUM, TYPE\n", "next_change": {"commit": "2f751b76b7302fa4d8b274c54c191ac2bb9d151b", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 08a960576..e1ff29af0 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -316,6 +339,65 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         executeBatch(sqlNotifyTopicMessage, \"topic notifications\");\n     }\n \n+    /**\n+     * Handle purely duplicate file in addition to faulty transaction management between spring repositories and manual\n+     * java sql operations. Check whether the given file was partially processed and matches the last record file\n+     * processed where the record_file table was updated but application_status table LAST_PROCESSED_RECORD_HASH was not\n+     * updated. If so update application_status table LAST_PROCESSED_RECORD_HASH appropriately with correct hash. Also\n+     * handle case where transaction data was rolled bach but not record_file entry\n+     *\n+     * @param recordFile record file object that was partially processed file\n+     */\n+    private void handleDuplicateOrPartiallyProcessedRecordFile(RecordFile recordFile) {\n+        // handle faulty transaction management between spring repositories and manual java sql operations\n+        DuplicateFileException duplicateFileException = new DuplicateFileException(\"File already exists in the \" +\n+                \"database: \" + recordFile.getName());\n+        RecordFile latestRecordFile = recordFileRepository.findTopByOrderByConsensusEndDesc().get();\n+        String lastRecordFileHash =\n+                applicationStatusRepository.findByStatusCode(ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH);\n+\n+        // check if latest record file is a match processed file by comparing name and hash\n+        if (latestRecordFile.getName().equalsIgnoreCase(recordFile.getName()) &&\n+                !Utility.verifyHashChain(\n+                        latestRecordFile.getFileHash(),\n+                        lastRecordFileHash,\n+                        parserProperties.getMirrorProperties().getVerifyHashAfter(),\n+                        recordFile.getName())) {\n+\n+            // check if this file is next in line of hash chain\n+            // Assumes application status updates after record_file update which is current process\n+            if (Utility.verifyHashChain(\n+                    latestRecordFile.getPreviousHash(),\n+                    lastRecordFileHash,\n+                    parserProperties.getMirrorProperties().getVerifyHashAfter(),\n+                    recordFile.getName())) {\n+                // application_status outdated\n+                log.debug(\"Duplicate file failed to update applicationStatus on previous processing, updating now!\");\n+                applicationStatusRepository.updateStatusValue(\n+                        ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, latestRecordFile.getFileHash());\n+                throw duplicateFileException;\n+            } else {\n+                // very unlikely edge case\n+                log.warn(\"Latest file already exists but has mismatched hash for expectedPrevFileHash: \", recordFile\n+                        .getName());\n+                throw new HashMismatchException(recordFile.getName(), lastRecordFileHash, latestRecordFile\n+                        .getFileHash());\n+            }\n+        } else {\n+            // check if transactions are already present\n+            if (transactionRepository.existsById(recordFile.getConsensusStart()) &&\n+                    transactionRepository.existsById(recordFile.getConsensusEnd())) {\n+                throw duplicateFileException;\n+            }\n+        }\n+\n+        // allow file processing but update to previous hash\n+        applicationStatusRepository.updateStatusValue(\n+                ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, latestRecordFile.getPreviousHash());\n+        log.debug(\"Transactions from partially processed record file {} were not persisted! Reprocessing...\",\n+                recordFile.getName());\n+    }\n+\n     enum F_ENTITY_ID {\n         ZERO, // column indices start at 1, this creates the necessary offset\n         ID, ENTITY_SHARD, ENTITY_REALM, ENTITY_NUM, TYPE\n", "next_change": {"commit": "2b2939cc5c9779e6d415c9d1e674f37356378ab8", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex e1ff29af0..d4adc3dec 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -339,65 +306,6 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         executeBatch(sqlNotifyTopicMessage, \"topic notifications\");\n     }\n \n-    /**\n-     * Handle purely duplicate file in addition to faulty transaction management between spring repositories and manual\n-     * java sql operations. Check whether the given file was partially processed and matches the last record file\n-     * processed where the record_file table was updated but application_status table LAST_PROCESSED_RECORD_HASH was not\n-     * updated. If so update application_status table LAST_PROCESSED_RECORD_HASH appropriately with correct hash. Also\n-     * handle case where transaction data was rolled bach but not record_file entry\n-     *\n-     * @param recordFile record file object that was partially processed file\n-     */\n-    private void handleDuplicateOrPartiallyProcessedRecordFile(RecordFile recordFile) {\n-        // handle faulty transaction management between spring repositories and manual java sql operations\n-        DuplicateFileException duplicateFileException = new DuplicateFileException(\"File already exists in the \" +\n-                \"database: \" + recordFile.getName());\n-        RecordFile latestRecordFile = recordFileRepository.findTopByOrderByConsensusEndDesc().get();\n-        String lastRecordFileHash =\n-                applicationStatusRepository.findByStatusCode(ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH);\n-\n-        // check if latest record file is a match processed file by comparing name and hash\n-        if (latestRecordFile.getName().equalsIgnoreCase(recordFile.getName()) &&\n-                !Utility.verifyHashChain(\n-                        latestRecordFile.getFileHash(),\n-                        lastRecordFileHash,\n-                        parserProperties.getMirrorProperties().getVerifyHashAfter(),\n-                        recordFile.getName())) {\n-\n-            // check if this file is next in line of hash chain\n-            // Assumes application status updates after record_file update which is current process\n-            if (Utility.verifyHashChain(\n-                    latestRecordFile.getPreviousHash(),\n-                    lastRecordFileHash,\n-                    parserProperties.getMirrorProperties().getVerifyHashAfter(),\n-                    recordFile.getName())) {\n-                // application_status outdated\n-                log.debug(\"Duplicate file failed to update applicationStatus on previous processing, updating now!\");\n-                applicationStatusRepository.updateStatusValue(\n-                        ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, latestRecordFile.getFileHash());\n-                throw duplicateFileException;\n-            } else {\n-                // very unlikely edge case\n-                log.warn(\"Latest file already exists but has mismatched hash for expectedPrevFileHash: \", recordFile\n-                        .getName());\n-                throw new HashMismatchException(recordFile.getName(), lastRecordFileHash, latestRecordFile\n-                        .getFileHash());\n-            }\n-        } else {\n-            // check if transactions are already present\n-            if (transactionRepository.existsById(recordFile.getConsensusStart()) &&\n-                    transactionRepository.existsById(recordFile.getConsensusEnd())) {\n-                throw duplicateFileException;\n-            }\n-        }\n-\n-        // allow file processing but update to previous hash\n-        applicationStatusRepository.updateStatusValue(\n-                ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, latestRecordFile.getPreviousHash());\n-        log.debug(\"Transactions from partially processed record file {} were not persisted! Reprocessing...\",\n-                recordFile.getName());\n-    }\n-\n     enum F_ENTITY_ID {\n         ZERO, // column indices start at 1, this creates the necessary offset\n         ID, ENTITY_SHARD, ENTITY_REALM, ENTITY_NUM, TYPE\n", "next_change": {"commit": "e962d8dd5fe0a06ae248ba04f604c44e24be85ea", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex d4adc3dec..97b154805 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -298,16 +289,13 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n     }\n \n     private void persistEntities() {\n-        executeBatch(sqlInsertEntityId, \"entities\");\n-        entityIds.forEach(entityId -> entityCache.put(entityId.getId(), null));\n+        Stopwatch stopwatch = Stopwatch.createStarted();\n+        entityIds.forEach(entityId -> entityRepository.insertEntityId(entityId));\n+        log.info(\"Inserted {} entities in {}\", entityIds.size(), stopwatch);\n+        entityIds.forEach(entityId -> entityCache.put(entityId, null));\n     }\n \n     private void notifyTopicMessages() {\n         executeBatch(sqlNotifyTopicMessage, \"topic notifications\");\n     }\n-\n-    enum F_ENTITY_ID {\n-        ZERO, // column indices start at 1, this creates the necessary offset\n-        ID, ENTITY_SHARD, ENTITY_REALM, ENTITY_NUM, TYPE\n-    }\n }\n", "next_change": {"commit": "3eedeade2e3496808da55fc270a1dc5619a4a4f5", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 97b154805..2867187cd 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -290,9 +288,11 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n \n     private void persistEntities() {\n         Stopwatch stopwatch = Stopwatch.createStarted();\n-        entityIds.forEach(entityId -> entityRepository.insertEntityId(entityId));\n+        entityIds.forEach(entityId -> {\n+            entityRepository.insertEntityId(entityId);\n+            entityCache.put(entityId, null);\n+        });\n         log.info(\"Inserted {} entities in {}\", entityIds.size(), stopwatch);\n-        entityIds.forEach(entityId -> entityCache.put(entityId, null));\n     }\n \n     private void notifyTopicMessages() {\n", "next_change": null}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzEwMzMzMg==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r473103332", "body": "I don't see any point to this method. It only recovers from the scenario when record file saves but application status does not. This scenario can be easily handled by putting a `@Transactional` on `onEnd()` to ensure they're committed together. There shouldn't be any problem with that approach since they're both repositories.", "bodyText": "I don't see any point to this method. It only recovers from the scenario when record file saves but application status does not. This scenario can be easily handled by putting a @Transactional on onEnd() to ensure they're committed together. There shouldn't be any problem with that approach since they're both repositories.", "bodyHTML": "<p dir=\"auto\">I don't see any point to this method. It only recovers from the scenario when record file saves but application status does not. This scenario can be easily handled by putting a <code>@Transactional</code> on <code>onEnd()</code> to ensure they're committed together. There shouldn't be any problem with that approach since they're both repositories.</p>", "author": "steven-sheehy", "createdAt": "2020-08-19T15:09:18Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java", "diffHunk": "@@ -314,6 +339,65 @@ private void notifyTopicMessages() {\n         executeBatch(sqlNotifyTopicMessage, \"topic notifications\");\n     }\n \n+    /**\n+     * Handle purely duplicate file in addition to faulty transaction management between spring repositories and manual\n+     * java sql operations. Check whether the given file was partially processed and matches the last record file\n+     * processed where the record_file table was updated but application_status table LAST_PROCESSED_RECORD_HASH was not\n+     * updated. If so update application_status table LAST_PROCESSED_RECORD_HASH appropriately with correct hash. Also\n+     * handle case where transaction data was rolled bach but not record_file entry\n+     *\n+     * @param recordFile record file object that was partially processed file\n+     */\n+    private void handleDuplicateOrPartiallyProcessedRecordFile(RecordFile recordFile) {", "originalCommit": "1784e6532764d38f2188cdacb62970cf3f4feba0", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5bb96f354bf15cbf85e8f6e4364f78d9eaa604e0", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex e1ff29af0..08a960576 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -339,65 +316,6 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         executeBatch(sqlNotifyTopicMessage, \"topic notifications\");\n     }\n \n-    /**\n-     * Handle purely duplicate file in addition to faulty transaction management between spring repositories and manual\n-     * java sql operations. Check whether the given file was partially processed and matches the last record file\n-     * processed where the record_file table was updated but application_status table LAST_PROCESSED_RECORD_HASH was not\n-     * updated. If so update application_status table LAST_PROCESSED_RECORD_HASH appropriately with correct hash. Also\n-     * handle case where transaction data was rolled bach but not record_file entry\n-     *\n-     * @param recordFile record file object that was partially processed file\n-     */\n-    private void handleDuplicateOrPartiallyProcessedRecordFile(RecordFile recordFile) {\n-        // handle faulty transaction management between spring repositories and manual java sql operations\n-        DuplicateFileException duplicateFileException = new DuplicateFileException(\"File already exists in the \" +\n-                \"database: \" + recordFile.getName());\n-        RecordFile latestRecordFile = recordFileRepository.findTopByOrderByConsensusEndDesc().get();\n-        String lastRecordFileHash =\n-                applicationStatusRepository.findByStatusCode(ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH);\n-\n-        // check if latest record file is a match processed file by comparing name and hash\n-        if (latestRecordFile.getName().equalsIgnoreCase(recordFile.getName()) &&\n-                !Utility.verifyHashChain(\n-                        latestRecordFile.getFileHash(),\n-                        lastRecordFileHash,\n-                        parserProperties.getMirrorProperties().getVerifyHashAfter(),\n-                        recordFile.getName())) {\n-\n-            // check if this file is next in line of hash chain\n-            // Assumes application status updates after record_file update which is current process\n-            if (Utility.verifyHashChain(\n-                    latestRecordFile.getPreviousHash(),\n-                    lastRecordFileHash,\n-                    parserProperties.getMirrorProperties().getVerifyHashAfter(),\n-                    recordFile.getName())) {\n-                // application_status outdated\n-                log.debug(\"Duplicate file failed to update applicationStatus on previous processing, updating now!\");\n-                applicationStatusRepository.updateStatusValue(\n-                        ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, latestRecordFile.getFileHash());\n-                throw duplicateFileException;\n-            } else {\n-                // very unlikely edge case\n-                log.warn(\"Latest file already exists but has mismatched hash for expectedPrevFileHash: \", recordFile\n-                        .getName());\n-                throw new HashMismatchException(recordFile.getName(), lastRecordFileHash, latestRecordFile\n-                        .getFileHash());\n-            }\n-        } else {\n-            // check if transactions are already present\n-            if (transactionRepository.existsById(recordFile.getConsensusStart()) &&\n-                    transactionRepository.existsById(recordFile.getConsensusEnd())) {\n-                throw duplicateFileException;\n-            }\n-        }\n-\n-        // allow file processing but update to previous hash\n-        applicationStatusRepository.updateStatusValue(\n-                ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, latestRecordFile.getPreviousHash());\n-        log.debug(\"Transactions from partially processed record file {} were not persisted! Reprocessing...\",\n-                recordFile.getName());\n-    }\n-\n     enum F_ENTITY_ID {\n         ZERO, // column indices start at 1, this creates the necessary offset\n         ID, ENTITY_SHARD, ENTITY_REALM, ENTITY_NUM, TYPE\n", "next_change": {"commit": "2f751b76b7302fa4d8b274c54c191ac2bb9d151b", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 08a960576..e1ff29af0 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -316,6 +339,65 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         executeBatch(sqlNotifyTopicMessage, \"topic notifications\");\n     }\n \n+    /**\n+     * Handle purely duplicate file in addition to faulty transaction management between spring repositories and manual\n+     * java sql operations. Check whether the given file was partially processed and matches the last record file\n+     * processed where the record_file table was updated but application_status table LAST_PROCESSED_RECORD_HASH was not\n+     * updated. If so update application_status table LAST_PROCESSED_RECORD_HASH appropriately with correct hash. Also\n+     * handle case where transaction data was rolled bach but not record_file entry\n+     *\n+     * @param recordFile record file object that was partially processed file\n+     */\n+    private void handleDuplicateOrPartiallyProcessedRecordFile(RecordFile recordFile) {\n+        // handle faulty transaction management between spring repositories and manual java sql operations\n+        DuplicateFileException duplicateFileException = new DuplicateFileException(\"File already exists in the \" +\n+                \"database: \" + recordFile.getName());\n+        RecordFile latestRecordFile = recordFileRepository.findTopByOrderByConsensusEndDesc().get();\n+        String lastRecordFileHash =\n+                applicationStatusRepository.findByStatusCode(ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH);\n+\n+        // check if latest record file is a match processed file by comparing name and hash\n+        if (latestRecordFile.getName().equalsIgnoreCase(recordFile.getName()) &&\n+                !Utility.verifyHashChain(\n+                        latestRecordFile.getFileHash(),\n+                        lastRecordFileHash,\n+                        parserProperties.getMirrorProperties().getVerifyHashAfter(),\n+                        recordFile.getName())) {\n+\n+            // check if this file is next in line of hash chain\n+            // Assumes application status updates after record_file update which is current process\n+            if (Utility.verifyHashChain(\n+                    latestRecordFile.getPreviousHash(),\n+                    lastRecordFileHash,\n+                    parserProperties.getMirrorProperties().getVerifyHashAfter(),\n+                    recordFile.getName())) {\n+                // application_status outdated\n+                log.debug(\"Duplicate file failed to update applicationStatus on previous processing, updating now!\");\n+                applicationStatusRepository.updateStatusValue(\n+                        ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, latestRecordFile.getFileHash());\n+                throw duplicateFileException;\n+            } else {\n+                // very unlikely edge case\n+                log.warn(\"Latest file already exists but has mismatched hash for expectedPrevFileHash: \", recordFile\n+                        .getName());\n+                throw new HashMismatchException(recordFile.getName(), lastRecordFileHash, latestRecordFile\n+                        .getFileHash());\n+            }\n+        } else {\n+            // check if transactions are already present\n+            if (transactionRepository.existsById(recordFile.getConsensusStart()) &&\n+                    transactionRepository.existsById(recordFile.getConsensusEnd())) {\n+                throw duplicateFileException;\n+            }\n+        }\n+\n+        // allow file processing but update to previous hash\n+        applicationStatusRepository.updateStatusValue(\n+                ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, latestRecordFile.getPreviousHash());\n+        log.debug(\"Transactions from partially processed record file {} were not persisted! Reprocessing...\",\n+                recordFile.getName());\n+    }\n+\n     enum F_ENTITY_ID {\n         ZERO, // column indices start at 1, this creates the necessary offset\n         ID, ENTITY_SHARD, ENTITY_REALM, ENTITY_NUM, TYPE\n", "next_change": {"commit": "2b2939cc5c9779e6d415c9d1e674f37356378ab8", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex e1ff29af0..d4adc3dec 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -339,65 +306,6 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n         executeBatch(sqlNotifyTopicMessage, \"topic notifications\");\n     }\n \n-    /**\n-     * Handle purely duplicate file in addition to faulty transaction management between spring repositories and manual\n-     * java sql operations. Check whether the given file was partially processed and matches the last record file\n-     * processed where the record_file table was updated but application_status table LAST_PROCESSED_RECORD_HASH was not\n-     * updated. If so update application_status table LAST_PROCESSED_RECORD_HASH appropriately with correct hash. Also\n-     * handle case where transaction data was rolled bach but not record_file entry\n-     *\n-     * @param recordFile record file object that was partially processed file\n-     */\n-    private void handleDuplicateOrPartiallyProcessedRecordFile(RecordFile recordFile) {\n-        // handle faulty transaction management between spring repositories and manual java sql operations\n-        DuplicateFileException duplicateFileException = new DuplicateFileException(\"File already exists in the \" +\n-                \"database: \" + recordFile.getName());\n-        RecordFile latestRecordFile = recordFileRepository.findTopByOrderByConsensusEndDesc().get();\n-        String lastRecordFileHash =\n-                applicationStatusRepository.findByStatusCode(ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH);\n-\n-        // check if latest record file is a match processed file by comparing name and hash\n-        if (latestRecordFile.getName().equalsIgnoreCase(recordFile.getName()) &&\n-                !Utility.verifyHashChain(\n-                        latestRecordFile.getFileHash(),\n-                        lastRecordFileHash,\n-                        parserProperties.getMirrorProperties().getVerifyHashAfter(),\n-                        recordFile.getName())) {\n-\n-            // check if this file is next in line of hash chain\n-            // Assumes application status updates after record_file update which is current process\n-            if (Utility.verifyHashChain(\n-                    latestRecordFile.getPreviousHash(),\n-                    lastRecordFileHash,\n-                    parserProperties.getMirrorProperties().getVerifyHashAfter(),\n-                    recordFile.getName())) {\n-                // application_status outdated\n-                log.debug(\"Duplicate file failed to update applicationStatus on previous processing, updating now!\");\n-                applicationStatusRepository.updateStatusValue(\n-                        ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, latestRecordFile.getFileHash());\n-                throw duplicateFileException;\n-            } else {\n-                // very unlikely edge case\n-                log.warn(\"Latest file already exists but has mismatched hash for expectedPrevFileHash: \", recordFile\n-                        .getName());\n-                throw new HashMismatchException(recordFile.getName(), lastRecordFileHash, latestRecordFile\n-                        .getFileHash());\n-            }\n-        } else {\n-            // check if transactions are already present\n-            if (transactionRepository.existsById(recordFile.getConsensusStart()) &&\n-                    transactionRepository.existsById(recordFile.getConsensusEnd())) {\n-                throw duplicateFileException;\n-            }\n-        }\n-\n-        // allow file processing but update to previous hash\n-        applicationStatusRepository.updateStatusValue(\n-                ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, latestRecordFile.getPreviousHash());\n-        log.debug(\"Transactions from partially processed record file {} were not persisted! Reprocessing...\",\n-                recordFile.getName());\n-    }\n-\n     enum F_ENTITY_ID {\n         ZERO, // column indices start at 1, this creates the necessary offset\n         ID, ENTITY_SHARD, ENTITY_REALM, ENTITY_NUM, TYPE\n", "next_change": {"commit": "e962d8dd5fe0a06ae248ba04f604c44e24be85ea", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex d4adc3dec..97b154805 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -298,16 +289,13 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n     }\n \n     private void persistEntities() {\n-        executeBatch(sqlInsertEntityId, \"entities\");\n-        entityIds.forEach(entityId -> entityCache.put(entityId.getId(), null));\n+        Stopwatch stopwatch = Stopwatch.createStarted();\n+        entityIds.forEach(entityId -> entityRepository.insertEntityId(entityId));\n+        log.info(\"Inserted {} entities in {}\", entityIds.size(), stopwatch);\n+        entityIds.forEach(entityId -> entityCache.put(entityId, null));\n     }\n \n     private void notifyTopicMessages() {\n         executeBatch(sqlNotifyTopicMessage, \"topic notifications\");\n     }\n-\n-    enum F_ENTITY_ID {\n-        ZERO, // column indices start at 1, this creates the necessary offset\n-        ID, ENTITY_SHARD, ENTITY_REALM, ENTITY_NUM, TYPE\n-    }\n }\n", "next_change": {"commit": "3eedeade2e3496808da55fc270a1dc5619a4a4f5", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 97b154805..2867187cd 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -290,9 +288,11 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n \n     private void persistEntities() {\n         Stopwatch stopwatch = Stopwatch.createStarted();\n-        entityIds.forEach(entityId -> entityRepository.insertEntityId(entityId));\n+        entityIds.forEach(entityId -> {\n+            entityRepository.insertEntityId(entityId);\n+            entityCache.put(entityId, null);\n+        });\n         log.info(\"Inserted {} entities in {}\", entityIds.size(), stopwatch);\n-        entityIds.forEach(entityId -> entityCache.put(entityId, null));\n     }\n \n     private void notifyTopicMessages() {\n", "next_change": null}]}}]}}]}}]}}]}}, {"oid": "5bb96f354bf15cbf85e8f6e4364f78d9eaa604e0", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/5bb96f354bf15cbf85e8f6e4364f78d9eaa604e0", "message": "Moved RecordFileParser file system logic to RecordFilePoller\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-08-21T07:11:32Z", "type": "commit"}, {"oid": "3b23462bdfa1fc2dd0371e85e5153ad447f8a828", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/3b23462bdfa1fc2dd0371e85e5153ad447f8a828", "message": "Removed transactional from SqlEntityListener.OnEnd\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-08-21T07:11:32Z", "type": "commit"}, {"oid": "2ba305984f72c15a7c9551fbc3c82369f518b883", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/2ba305984f72c15a7c9551fbc3c82369f518b883", "message": "Addressed feedback if poller and parser\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-08-21T07:11:33Z", "type": "commit"}, {"oid": "1f345762e97fe2b4a66de19759ceb96eacc11885", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/1f345762e97fe2b4a66de19759ceb96eacc11885", "message": "Cleaned up a bit\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-08-21T07:11:33Z", "type": "commit"}, {"oid": "72492b10ad6b2e5e0fb0b9f2c18f738433dff64a", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/72492b10ad6b2e5e0fb0b9f2c18f738433dff64a", "message": "Added poller tests\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-08-21T07:11:33Z", "type": "commit"}, {"oid": "1e52bb6ce52d20fab8c3b45955376252c24fe4cd", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/1e52bb6ce52d20fab8c3b45955376252c24fe4cd", "message": "Addressed additional feedback\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-08-21T07:11:33Z", "type": "commit"}, {"oid": "ba7113b865a5b82f3cf74e3c8c06f6979e29dc86", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/ba7113b865a5b82f3cf74e3c8c06f6979e29dc86", "message": "Reverted to autocommit false, fixed rollback test\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-08-21T07:11:33Z", "type": "commit"}, {"oid": "2f751b76b7302fa4d8b274c54c191ac2bb9d151b", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/2f751b76b7302fa4d8b274c54c191ac2bb9d151b", "message": "Add logic to handle and recover from transaction management issues\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-08-21T07:11:33Z", "type": "commit"}, {"oid": "06cadc07aaf127073e2d82d093dc4605b1db342a", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/06cadc07aaf127073e2d82d093dc4605b1db342a", "message": "Increased hikari max pool size andrenamed some tests\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-08-21T07:11:33Z", "type": "commit"}, {"oid": "2b2939cc5c9779e6d415c9d1e674f37356378ab8", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/2b2939cc5c9779e6d415c9d1e674f37356378ab8", "message": "Use @Transactional\n\nSigned-off-by: Steven Sheehy <steven.sheehy@hedera.com>", "committedDate": "2020-08-21T07:11:33Z", "type": "commit"}, {"oid": "e962d8dd5fe0a06ae248ba04f604c44e24be85ea", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/e962d8dd5fe0a06ae248ba04f604c44e24be85ea", "message": "Add release connection, convert entity persistence to use repositories and fixed tests\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-08-21T07:11:33Z", "type": "commit"}, {"oid": "cab3a93ee3e294ad55a39b4f1501658c574f035d", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/cab3a93ee3e294ad55a39b4f1501658c574f035d", "message": "Moved RecordFileParser file system logic to RecordFilePoller\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-08-21T07:16:13Z", "type": "commit"}, {"oid": "b4cc3eb744b66c38142331083132933c04c42c6e", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/b4cc3eb744b66c38142331083132933c04c42c6e", "message": "Removed transactional from SqlEntityListener.OnEnd\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-08-21T07:16:14Z", "type": "commit"}, {"oid": "e969c08a4d361fcc7d24aa828f08a0033611ed2b", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/e969c08a4d361fcc7d24aa828f08a0033611ed2b", "message": "Addressed feedback if poller and parser\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-08-21T07:21:28Z", "type": "commit"}, {"oid": "a43a5910249d6663de2bd74846727eb02670ff0e", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/a43a5910249d6663de2bd74846727eb02670ff0e", "message": "Cleaned up a bit\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-08-21T07:22:13Z", "type": "commit"}, {"oid": "a396e69ac30e7a9aa88358fde0acce5ba73e25f2", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/a396e69ac30e7a9aa88358fde0acce5ba73e25f2", "message": "Addressed additional feedback\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-08-21T07:22:30Z", "type": "commit"}, {"oid": "674faa4bcf2cccf21461e998fc75b46eea872ee9", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/674faa4bcf2cccf21461e998fc75b46eea872ee9", "message": "Reverted to autocommit false, fixed rollback test\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-08-21T07:23:37Z", "type": "commit"}, {"oid": "ee307fc75600692c03bbb6379b6e6d8ec296ad41", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/ee307fc75600692c03bbb6379b6e6d8ec296ad41", "message": "Add logic to handle and recover from transaction management issues\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-08-21T07:25:08Z", "type": "commit"}, {"oid": "18c528c8a2e88b244409a5792d3151d2858da0d5", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/18c528c8a2e88b244409a5792d3151d2858da0d5", "message": "Use @Transactional\n\nSigned-off-by: Steven Sheehy <steven.sheehy@hedera.com>", "committedDate": "2020-08-21T07:27:06Z", "type": "commit"}, {"oid": "18c528c8a2e88b244409a5792d3151d2858da0d5", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/18c528c8a2e88b244409a5792d3151d2858da0d5", "message": "Use @Transactional\n\nSigned-off-by: Steven Sheehy <steven.sheehy@hedera.com>", "committedDate": "2020-08-21T07:27:06Z", "type": "forcePushed"}, {"oid": "8f6e32df0462a0038977243d94254f453359b232", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/8f6e32df0462a0038977243d94254f453359b232", "message": "Removed duplicate file check from RecordParser and reverted back to HashSet for entityIds in SqlENtityListener\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-08-21T15:35:16Z", "type": "commit"}, {"oid": "93ad6221c56a7010f711163484f0bd61c42f4054", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/93ad6221c56a7010f711163484f0bd61c42f4054", "message": "Removed extra cache manager storage\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-08-21T15:38:50Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDgyOTgzMg==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r474829832", "body": "This is not quite correct. If we inserted `0.0.2` during a previous file then get a rollback error next file it would be unnecessarily removed even though it exists in db. Please wrap `entityCache` with `transactionAwareCacheDecorator` instead.\r\n\r\nOr remove `entityCache` and `entityIds` and put `@Cacheable(cacheManager = CacheConfiguration.NEVER_EXPIRE_LARGE)` on `entityRepository.insertEntityId()`.", "bodyText": "This is not quite correct. If we inserted 0.0.2 during a previous file then get a rollback error next file it would be unnecessarily removed even though it exists in db. Please wrap entityCache with transactionAwareCacheDecorator instead.\nOr remove entityCache and entityIds and put @Cacheable(cacheManager = CacheConfiguration.NEVER_EXPIRE_LARGE) on entityRepository.insertEntityId().", "bodyHTML": "<p dir=\"auto\">This is not quite correct. If we inserted <code>0.0.2</code> during a previous file then get a rollback error next file it would be unnecessarily removed even though it exists in db. Please wrap <code>entityCache</code> with <code>transactionAwareCacheDecorator</code> instead.</p>\n<p dir=\"auto\">Or remove <code>entityCache</code> and <code>entityIds</code> and put <code>@Cacheable(cacheManager = CacheConfiguration.NEVER_EXPIRE_LARGE)</code> on <code>entityRepository.insertEntityId()</code>.</p>", "author": "steven-sheehy", "createdAt": "2020-08-21T17:24:47Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java", "diffHunk": "@@ -151,39 +146,43 @@ public void onStart(StreamFileData streamFileData) {\n     public void onEnd(RecordFile recordFile) {\n         executeBatches();\n \n+        boolean releaseConnection = false;\n         try {\n-            connection.commit();\n             recordFileRepository.save(recordFile);\n-            closeConnectionAndStatements();\n-        } catch (SQLException e) {\n-            throw new ParserSQLException(e);\n+            applicationStatusRepository.updateStatusValue(\n+                    ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, recordFile.getFileHash());\n+            releaseConnection = true;\n+        } finally {\n+            cleanup(false, releaseConnection);\n         }\n     }\n \n     @Override\n     public void onError() {\n-        try {\n-            if (connection != null) {\n-                connection.rollback();\n-                closeConnectionAndStatements();\n-            }\n-        } catch (SQLException e) {\n-            log.error(\"Exception while rolling transaction back\", e);\n-        } finally {\n-            cleanup();\n-        }\n+        cleanup(true, true);\n     }\n \n-    private void cleanup() {\n+    private void cleanup(boolean isRollBackCleanup, boolean releaseConnection) {\n+        if (isRollBackCleanup) {\n+            // evict entities from cache from this round of batches as they were rolled back\n+            entityIds.forEach(entityId -> entityCache.evict(entityId.getId()));", "originalCommit": "93ad6221c56a7010f711163484f0bd61c42f4054", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk5OTQ1MQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r474999451", "bodyText": "True, Applying the cache on successful cases of entityRepository.insertEntityId encapsulates the desired outcome", "author": "Nana-EC", "createdAt": "2020-08-21T22:42:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDgyOTgzMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE0NDg2Nw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r475144867", "bodyText": "Ended up going with transactionAwareCacheDecorator as @Cacheable on repository on wasn't rolling back.", "author": "Nana-EC", "createdAt": "2020-08-22T22:31:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDgyOTgzMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE1NzY0NQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r475157645", "bodyText": "You missed my comment above that you need to Please also wrap all CacheManagers in a TransactionAwareCacheManagerProxy so they are transaction aware via annotations. This needs to be done regardless of approach here. I'm not sure if a TransactionAwareCacheManagerProxy also needs a transactionAwareCacheDecorator when used without annotations. Probably not.", "author": "steven-sheehy", "createdAt": "2020-08-23T01:44:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDgyOTgzMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTcyMjU0OQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r475722549", "bodyText": "Good call, missed this.\nAdopted the TransactionAwareCacheManagerProxy and yeah with that the transactionAwareCacheDecorator is not needed", "author": "Nana-EC", "createdAt": "2020-08-24T16:01:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDgyOTgzMg=="}], "type": "inlineReview", "revised_code": {"commit": "3eedeade2e3496808da55fc270a1dc5619a4a4f5", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 3a44e9282..2867187cd 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -146,43 +147,34 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n     public void onEnd(RecordFile recordFile) {\n         executeBatches();\n \n-        boolean releaseConnection = false;\n         try {\n             recordFileRepository.save(recordFile);\n             applicationStatusRepository.updateStatusValue(\n                     ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, recordFile.getFileHash());\n-            releaseConnection = true;\n         } finally {\n-            cleanup(false, releaseConnection);\n+            cleanup();\n         }\n     }\n \n     @Override\n     public void onError() {\n-        cleanup(true, true);\n+        cleanup();\n     }\n \n-    private void cleanup(boolean isRollBackCleanup, boolean releaseConnection) {\n-        if (isRollBackCleanup) {\n-            // evict entities from cache from this round of batches as they were rolled back\n-            entityIds.forEach(entityId -> entityCache.evict(entityId.getId()));\n-        }\n-\n+    private void cleanup() {\n         closeQuietly(sqlNotifyTopicMessage);\n         sqlNotifyTopicMessage = null;\n         batchCount = 0;\n         contractResults.clear();\n         cryptoTransfers.clear();\n+        entityIds.clear();\n         fileData.clear();\n         liveHashes.clear();\n         nonFeeTransfers.clear();\n         topicMessages.clear();\n         transactions.clear();\n \n-        if (releaseConnection) {\n-            entityIds.clear();\n-            DataSourceUtils.releaseConnection(connection, dataSource);\n-        }\n+        DataSourceUtils.releaseConnection(connection, dataSource);\n     }\n \n     private void executeBatch(PreparedStatement ps, String entity) {\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDgzNTIzNw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r474835237", "body": "I think we should always clear entityIds and release connection. The connection doesn't really get released, it just gets a reference decremented since it's wrapped in an outer connection.", "bodyText": "I think we should always clear entityIds and release connection. The connection doesn't really get released, it just gets a reference decremented since it's wrapped in an outer connection.", "bodyHTML": "<p dir=\"auto\">I think we should always clear entityIds and release connection. The connection doesn't really get released, it just gets a reference decremented since it's wrapped in an outer connection.</p>", "author": "steven-sheehy", "createdAt": "2020-08-21T17:36:02Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java", "diffHunk": "@@ -151,39 +146,43 @@ public void onStart(StreamFileData streamFileData) {\n     public void onEnd(RecordFile recordFile) {\n         executeBatches();\n \n+        boolean releaseConnection = false;\n         try {\n-            connection.commit();\n             recordFileRepository.save(recordFile);\n-            closeConnectionAndStatements();\n-        } catch (SQLException e) {\n-            throw new ParserSQLException(e);\n+            applicationStatusRepository.updateStatusValue(\n+                    ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, recordFile.getFileHash());\n+            releaseConnection = true;\n+        } finally {\n+            cleanup(false, releaseConnection);\n         }\n     }\n \n     @Override\n     public void onError() {\n-        try {\n-            if (connection != null) {\n-                connection.rollback();\n-                closeConnectionAndStatements();\n-            }\n-        } catch (SQLException e) {\n-            log.error(\"Exception while rolling transaction back\", e);\n-        } finally {\n-            cleanup();\n-        }\n+        cleanup(true, true);\n     }\n \n-    private void cleanup() {\n+    private void cleanup(boolean isRollBackCleanup, boolean releaseConnection) {\n+        if (isRollBackCleanup) {\n+            // evict entities from cache from this round of batches as they were rolled back\n+            entityIds.forEach(entityId -> entityCache.evict(entityId.getId()));\n+        }\n+\n+        closeQuietly(sqlNotifyTopicMessage);\n+        sqlNotifyTopicMessage = null;\n         batchCount = 0;\n         contractResults.clear();\n         cryptoTransfers.clear();\n-        entityIds.clear();\n         fileData.clear();\n         liveHashes.clear();\n         nonFeeTransfers.clear();\n         topicMessages.clear();\n         transactions.clear();\n+\n+        if (releaseConnection) {\n+            entityIds.clear();\n+            DataSourceUtils.releaseConnection(connection, dataSource);", "originalCommit": "93ad6221c56a7010f711163484f0bd61c42f4054", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk5NjcxOA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r474996718", "bodyText": "Holding onto entities till end of file allowed for the right entityIds to be evicted from cache.\nWith the other approach you suggested I can revert this.\nThe release connection to decrement the reference seems to be necessary otherwise the connections stay open and the pool gets filled up with active connections.", "author": "Nana-EC", "createdAt": "2020-08-21T22:31:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDgzNTIzNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk5NzMyNg==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r474997326", "bodyText": "Right, I didn't suggest to remove releaseConnection but to always releaseConnection.", "author": "steven-sheehy", "createdAt": "2020-08-21T22:34:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDgzNTIzNw=="}], "type": "inlineReview", "revised_code": {"commit": "3eedeade2e3496808da55fc270a1dc5619a4a4f5", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 3a44e9282..2867187cd 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -146,43 +147,34 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n     public void onEnd(RecordFile recordFile) {\n         executeBatches();\n \n-        boolean releaseConnection = false;\n         try {\n             recordFileRepository.save(recordFile);\n             applicationStatusRepository.updateStatusValue(\n                     ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, recordFile.getFileHash());\n-            releaseConnection = true;\n         } finally {\n-            cleanup(false, releaseConnection);\n+            cleanup();\n         }\n     }\n \n     @Override\n     public void onError() {\n-        cleanup(true, true);\n+        cleanup();\n     }\n \n-    private void cleanup(boolean isRollBackCleanup, boolean releaseConnection) {\n-        if (isRollBackCleanup) {\n-            // evict entities from cache from this round of batches as they were rolled back\n-            entityIds.forEach(entityId -> entityCache.evict(entityId.getId()));\n-        }\n-\n+    private void cleanup() {\n         closeQuietly(sqlNotifyTopicMessage);\n         sqlNotifyTopicMessage = null;\n         batchCount = 0;\n         contractResults.clear();\n         cryptoTransfers.clear();\n+        entityIds.clear();\n         fileData.clear();\n         liveHashes.clear();\n         nonFeeTransfers.clear();\n         topicMessages.clear();\n         transactions.clear();\n \n-        if (releaseConnection) {\n-            entityIds.clear();\n-            DataSourceUtils.releaseConnection(connection, dataSource);\n-        }\n+        DataSourceUtils.releaseConnection(connection, dataSource);\n     }\n \n     private void executeBatch(PreparedStatement ps, String entity) {\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk1MjE1MA==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r474952150", "body": "This breaks encapsulation of `SqlEntityListener` since now it relies on `EntityRecordItemListener` to populate the same cache for this to work. So if `SqlEntityListener` is used outside of this scope, say from a test, it would not be functionally correct. \r\n\r\nBetter option would be to add a `@CachePut` to `entityRepository.save()` that updates the entity id cache. You can use `@Caching` to group.", "bodyText": "This breaks encapsulation of SqlEntityListener since now it relies on EntityRecordItemListener to populate the same cache for this to work. So if SqlEntityListener is used outside of this scope, say from a test, it would not be functionally correct.\nBetter option would be to add a @CachePut to entityRepository.save() that updates the entity id cache. You can use @Caching to group.", "bodyHTML": "<p dir=\"auto\">This breaks encapsulation of <code>SqlEntityListener</code> since now it relies on <code>EntityRecordItemListener</code> to populate the same cache for this to work. So if <code>SqlEntityListener</code> is used outside of this scope, say from a test, it would not be functionally correct.</p>\n<p dir=\"auto\">Better option would be to add a <code>@CachePut</code> to <code>entityRepository.save()</code> that updates the entity id cache. You can use <code>@Caching</code> to group.</p>", "author": "steven-sheehy", "createdAt": "2020-08-21T20:42:09Z", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java", "diffHunk": "@@ -241,22 +240,7 @@ public void onTransaction(Transaction transaction) throws ImporterException {\n \n     @Override\n     public void onEntityId(EntityId entityId) throws ImporterException {\n-        // add entities not found in cache to list of entities to be persisted\n-        if (entityCache.get(entityId.getId()) != null) {\n-            return;\n-        }\n-\n-        try {\n-            sqlInsertEntityId.setLong(F_ENTITY_ID.ID.ordinal(), entityId.getId());\n-            sqlInsertEntityId.setLong(F_ENTITY_ID.ENTITY_SHARD.ordinal(), entityId.getShardNum());\n-            sqlInsertEntityId.setLong(F_ENTITY_ID.ENTITY_REALM.ordinal(), entityId.getRealmNum());\n-            sqlInsertEntityId.setLong(F_ENTITY_ID.ENTITY_NUM.ordinal(), entityId.getEntityNum());\n-            sqlInsertEntityId.setLong(F_ENTITY_ID.TYPE.ordinal(), entityId.getType());\n-            sqlInsertEntityId.addBatch();\n-            entityIds.add(entityId);\n-        } catch (SQLException e) {\n-            throw new ParserSQLException(e);\n-        }\n+        entityIds.add(entityId);", "originalCommit": "93ad6221c56a7010f711163484f0bd61c42f4054", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk5NzM0MQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r474997341", "bodyText": "Fair point.", "author": "Nana-EC", "createdAt": "2020-08-21T22:34:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk1MjE1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE0NDkwMw==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r475144903", "bodyText": "Put cache management in SqlEntityListener using the recommended transactionAwareCacheDecorator .", "author": "Nana-EC", "createdAt": "2020-08-22T22:31:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk1MjE1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTY5OTIxOQ==", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/936#discussion_r475699219", "bodyText": "Do we want to cache entityRepository.save() as mentioned above?", "author": "steven-sheehy", "createdAt": "2020-08-24T15:27:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk1MjE1MA=="}], "type": "inlineReview", "revised_code": {"commit": "3eedeade2e3496808da55fc270a1dc5619a4a4f5", "changed_code": [{"header": "diff --git a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\nindex 3a44e9282..2867187cd 100644\n--- a/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n+++ b/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n", "chunk": "@@ -240,6 +232,11 @@ public class SqlEntityListener implements EntityListener, RecordStreamFileListen\n \n     @Override\n     public void onEntityId(EntityId entityId) throws ImporterException {\n+        // only insert entities not found in cache\n+        if (entityCache.get(entityId.getId()) != null) {\n+            return;\n+        }\n+\n         entityIds.add(entityId);\n     }\n \n", "next_change": null}]}}, {"oid": "3eedeade2e3496808da55fc270a1dc5619a4a4f5", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/3eedeade2e3496808da55fc270a1dc5619a4a4f5", "message": "Moved cache management back to SqlEntityListener and utilized TransactionAwareCacheDecorator to account for rollbacks\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-08-22T22:33:50Z", "type": "commit"}, {"oid": "30af6fa95cf88d42cf2393bb8e73576501308910", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/30af6fa95cf88d42cf2393bb8e73576501308910", "message": "Removed unused recordfilerepository method\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-08-22T22:39:32Z", "type": "commit"}, {"oid": "f77fdb95bbb25fc658f21b1d5919af8a8c7049c1", "url": "https://github.com/hashgraph/hedera-mirror-node/commit/f77fdb95bbb25fc658f21b1d5919af8a8c7049c1", "message": "Wrapped cachemanagers in TransactionAwareCacheManagerProxy\n\nSigned-off-by: Nana-EC <56320167+Nana-EC@users.noreply.github.com>", "committedDate": "2020-08-24T16:01:11Z", "type": "commit"}]}