{"pr_number": 772, "pr_title": "Initial commit of step and timestep support for data retrieval", "pr_author": "hbs", "pr_createdAt": "2020-06-05T21:26:03Z", "pr_url": "https://github.com/senx/warp10-platform/pull/772", "merge_commit": "67019d40559484d9cf2daf23cf83d122822ff274", "timeline": [{"oid": "590b26d2cbe9c6cbd9e134169a3eb34c7e59f79c", "url": "https://github.com/senx/warp10-platform/commit/590b26d2cbe9c6cbd9e134169a3eb34c7e59f79c", "message": "Initial commit of step and timestep support for data retrieval", "committedDate": "2020-06-05T21:25:29Z", "type": "commit"}, {"oid": "f898837edfc47f079963b72bf9e5dcf223773a39", "url": "https://github.com/senx/warp10-platform/commit/f898837edfc47f079963b72bf9e5dcf223773a39", "message": "Fixed stepping", "committedDate": "2020-06-05T21:57:47Z", "type": "commit"}, {"oid": "c8bfc3d7553dee6c470c06f08cd609e23014f2ed", "url": "https://github.com/senx/warp10-platform/commit/c8bfc3d7553dee6c470c06f08cd609e23014f2ed", "message": "Added unconditional seek when applying timestep", "committedDate": "2020-06-05T22:09:46Z", "type": "commit"}, {"oid": "dfd6e2f4e27c476f431638e3fe5b52d541af13f7", "url": "https://github.com/senx/warp10-platform/commit/dfd6e2f4e27c476f431638e3fe5b52d541af13f7", "message": "Refactored to introduce FetchRequest to simplify signatures", "committedDate": "2020-06-06T07:28:59Z", "type": "commit"}, {"oid": "845eb5f6c87f71e59c19b2331ef453a1d9f34fc0", "url": "https://github.com/senx/warp10-platform/commit/845eb5f6c87f71e59c19b2331ef453a1d9f34fc0", "message": "Added comments", "committedDate": "2020-06-06T07:31:24Z", "type": "commit"}, {"oid": "5126dc10079ad11bd4b5c7492f155a6a37dbbcb6", "url": "https://github.com/senx/warp10-platform/commit/5126dc10079ad11bd4b5c7492f155a6a37dbbcb6", "message": "Commented FetchRequest fields", "committedDate": "2020-06-06T07:48:45Z", "type": "commit"}, {"oid": "3e372e39ca060fae471a41649d37145f2ebabf81", "url": "https://github.com/senx/warp10-platform/commit/3e372e39ca060fae471a41649d37145f2ebabf81", "message": "Added TODO", "committedDate": "2020-06-06T14:54:51Z", "type": "commit"}, {"oid": "54d9d3342ac97883b72d0272709c77d58d347b62", "url": "https://github.com/senx/warp10-platform/commit/54d9d3342ac97883b72d0272709c77d58d347b62", "message": "Added support for step/timestep/sample/skip in SlicedRowFilterGTSDecoderIterator", "committedDate": "2020-06-07T13:54:38Z", "type": "commit"}, {"oid": "ee091ddcdc596477e812058c73a376097f4f42b6", "url": "https://github.com/senx/warp10-platform/commit/ee091ddcdc596477e812058c73a376097f4f42b6", "message": "Cleaned imports", "committedDate": "2020-06-07T13:55:58Z", "type": "commit"}, {"oid": "b6ca925b699873c98a623266908a564b16c613bb", "url": "https://github.com/senx/warp10-platform/commit/b6ca925b699873c98a623266908a564b16c613bb", "message": "Disabled use of filter when fetching by count with step/timestep/skip/sample", "committedDate": "2020-06-07T14:01:10Z", "type": "commit"}, {"oid": "e07598603051ad7fa838f08bfec01a2aa247f958", "url": "https://github.com/senx/warp10-platform/commit/e07598603051ad7fa838f08bfec01a2aa247f958", "message": "Added support for advanced fetch parameters in Warp10InputFormat", "committedDate": "2020-06-09T21:01:26Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTM4MDA0OA==", "url": "https://github.com/senx/warp10-platform/pull/772#discussion_r441380048", "body": "1 is a valid value, although it does nothing different than not specifying step at all.", "bodyText": "1 is a valid value, although it does nothing different than not specifying step at all.", "bodyHTML": "<p dir=\"auto\">1 is a valid value, although it does nothing different than not specifying step at all.</p>", "author": "ftence", "createdAt": "2020-06-17T08:39:58Z", "path": "warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java", "diffHunk": "@@ -314,6 +343,38 @@ public void handle(String target, Request baseRequest, HttpServletRequest req, H\n         skip = Long.parseLong(skipParam);        \n       }\n       \n+      if (null != stepParam) {\n+        step = Long.parseLong(stepParam);\n+        if (step <= 1) {\n+          throw new WarpScriptException(\"Parameter '\" + Constants.HTTP_PARAM_STEP + \"' cannot be <= 1.\");\n+        }", "originalCommit": "e07598603051ad7fa838f08bfec01a2aa247f958", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "879ad4092491eda3b08f942710d5bdc6b1e90c69", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java b/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\nindex 0a3de908..3023566c 100644\n--- a/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\n+++ b/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\n", "chunk": "@@ -345,33 +347,29 @@ public class EgressFetchHandler extends AbstractHandler {\n       \n       if (null != stepParam) {\n         step = Long.parseLong(stepParam);\n-        if (step <= 1) {\n-          throw new WarpScriptException(\"Parameter '\" + Constants.HTTP_PARAM_STEP + \"' cannot be <= 1.\");\n+        if (step < 1) {\n+          throw new WarpScriptException(\"Parameter '\" + Constants.HTTP_PARAM_STEP + \"' cannot be < 1.\");\n         }\n       }\n       \n       if (null != timestepParam) {\n         if (timestepParam.startsWith(\"P\")) {\n-          // Should be a ISO8601 duration\n-          ReadWritablePeriod period = new MutablePeriod();\n-\n-          ISOPeriodFormat.standard().getParser().parseInto(period, timestepParam, 0, Locale.US);\n-\n-          Period p = period.toPeriod();\n+          \n+          ADDDURATION.ReadWritablePeriodWithSubSecondOffset periodWithSubSec = ADDDURATION.durationToPeriod(timestepParam);\n+          \n+          ReadWritablePeriod p = periodWithSubSec.getPeriod();\n \n-          if (p.getMonths() != 0 || p.getYears() != 0) {\n+          if (p.get(DurationFieldType.months()) != 0 || p.get(DurationFieldType.years()) != 0) {\n             throw new WarpScriptException(\"No support for ambiguous durations containing years or months, please convert those to days.\");\n           }\n \n-          Duration duration = p.toDurationFrom(new Instant());\n-\n-          timestep = duration.getMillis() * Constants.TIME_UNITS_PER_MS;\n+          timestep = periodWithSubSec.getPeriod().toPeriod().toDurationFrom(new Instant()).getMillis() * Constants.TIME_UNITS_PER_MS + periodWithSubSec.getOffset();\n         } else {\n           timestep = Long.parseLong(timestepParam);\n         }\n         \n-        if (timestep <= 1) {\n-          throw new WarpScriptException(\"Parameter '\" + Constants.HTTP_PARAM_TIMESTEP + \"' cannot be <= 1.\");\n+        if (timestep < 1) {\n+          throw new WarpScriptException(\"Parameter '\" + Constants.HTTP_PARAM_TIMESTEP + \"' cannot be < 1.\");\n         }\n       }\n       \n", "next_change": null}]}, "revised_code_in_main": {"commit": "67019d40559484d9cf2daf23cf83d122822ff274", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java b/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\nindex 0a3de908..3023566c 100644\n--- a/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\n+++ b/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\n", "chunk": "@@ -345,33 +347,29 @@ public class EgressFetchHandler extends AbstractHandler {\n       \n       if (null != stepParam) {\n         step = Long.parseLong(stepParam);\n-        if (step <= 1) {\n-          throw new WarpScriptException(\"Parameter '\" + Constants.HTTP_PARAM_STEP + \"' cannot be <= 1.\");\n+        if (step < 1) {\n+          throw new WarpScriptException(\"Parameter '\" + Constants.HTTP_PARAM_STEP + \"' cannot be < 1.\");\n         }\n       }\n       \n       if (null != timestepParam) {\n         if (timestepParam.startsWith(\"P\")) {\n-          // Should be a ISO8601 duration\n-          ReadWritablePeriod period = new MutablePeriod();\n-\n-          ISOPeriodFormat.standard().getParser().parseInto(period, timestepParam, 0, Locale.US);\n-\n-          Period p = period.toPeriod();\n+          \n+          ADDDURATION.ReadWritablePeriodWithSubSecondOffset periodWithSubSec = ADDDURATION.durationToPeriod(timestepParam);\n+          \n+          ReadWritablePeriod p = periodWithSubSec.getPeriod();\n \n-          if (p.getMonths() != 0 || p.getYears() != 0) {\n+          if (p.get(DurationFieldType.months()) != 0 || p.get(DurationFieldType.years()) != 0) {\n             throw new WarpScriptException(\"No support for ambiguous durations containing years or months, please convert those to days.\");\n           }\n \n-          Duration duration = p.toDurationFrom(new Instant());\n-\n-          timestep = duration.getMillis() * Constants.TIME_UNITS_PER_MS;\n+          timestep = periodWithSubSec.getPeriod().toPeriod().toDurationFrom(new Instant()).getMillis() * Constants.TIME_UNITS_PER_MS + periodWithSubSec.getOffset();\n         } else {\n           timestep = Long.parseLong(timestepParam);\n         }\n         \n-        if (timestep <= 1) {\n-          throw new WarpScriptException(\"Parameter '\" + Constants.HTTP_PARAM_TIMESTEP + \"' cannot be <= 1.\");\n+        if (timestep < 1) {\n+          throw new WarpScriptException(\"Parameter '\" + Constants.HTTP_PARAM_TIMESTEP + \"' cannot be < 1.\");\n         }\n       }\n       \n", "next_change": {"commit": "aa34e708809bd88e4d61ed05e78594349ad8bc53", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java b/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\nindex 3023566c..bebb9d49 100644\n--- a/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\n+++ b/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\n", "chunk": "@@ -369,7 +375,8 @@ public class EgressFetchHandler extends AbstractHandler {\n         }\n         \n         if (timestep < 1) {\n-          throw new WarpScriptException(\"Parameter '\" + Constants.HTTP_PARAM_TIMESTEP + \"' cannot be < 1.\");\n+          httpStatusCode = HttpServletResponse.SC_BAD_REQUEST;\n+          throw new IOException(\"Parameter '\" + Constants.HTTP_PARAM_TIMESTEP + \"' cannot be < 1.\");\n         }\n       }\n       \n", "next_change": {"commit": "74a9671e6abedd2b5bb1f0baa0dcadf72f0f3d58", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java b/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\nindex bebb9d49..8818617f 100644\n--- a/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\n+++ b/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\n", "chunk": "@@ -373,13 +373,13 @@ public class EgressFetchHandler extends AbstractHandler {\n         } else {\n           timestep = Long.parseLong(timestepParam);\n         }\n-        \n+\n         if (timestep < 1) {\n           httpStatusCode = HttpServletResponse.SC_BAD_REQUEST;\n           throw new IOException(\"Parameter '\" + Constants.HTTP_PARAM_TIMESTEP + \"' cannot be < 1.\");\n         }\n       }\n-      \n+\n       if (null != sampleParam) {\n         sample = Double.parseDouble(sampleParam);\n       }\n", "next_change": {"commit": "e826ea374df18f9d0ff413872ebf5ddd1ad0bd17", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java b/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\nindex 8818617f..8f5a7546 100644\n--- a/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\n+++ b/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\n", "chunk": "@@ -373,13 +373,13 @@ public class EgressFetchHandler extends AbstractHandler {\n         } else {\n           timestep = Long.parseLong(timestepParam);\n         }\n-\n+        \n         if (timestep < 1) {\n           httpStatusCode = HttpServletResponse.SC_BAD_REQUEST;\n           throw new IOException(\"Parameter '\" + Constants.HTTP_PARAM_TIMESTEP + \"' cannot be < 1.\");\n         }\n       }\n-\n+      \n       if (null != sampleParam) {\n         sample = Double.parseDouble(sampleParam);\n       }\n", "next_change": {"commit": "ca6bdb3976d3b4a2f7bc13725de60be114969521", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java b/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\nindex 8f5a7546..c726bf26 100644\n--- a/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\n+++ b/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\n", "chunk": "@@ -373,13 +373,13 @@ public class EgressFetchHandler extends AbstractHandler {\n         } else {\n           timestep = Long.parseLong(timestepParam);\n         }\n-        \n+\n         if (timestep < 1) {\n           httpStatusCode = HttpServletResponse.SC_BAD_REQUEST;\n           throw new IOException(\"Parameter '\" + Constants.HTTP_PARAM_TIMESTEP + \"' cannot be < 1.\");\n         }\n       }\n-      \n+\n       if (null != sampleParam) {\n         sample = Double.parseDouble(sampleParam);\n       }\n", "next_change": null}]}}]}}]}}]}}]}, "commits_in_main": [{"oid": "67019d40559484d9cf2daf23cf83d122822ff274", "message": "Merge commit", "committedDate": null}, {"oid": "a0ce525c9e1ce3800077185cdcb8e40b012ea9ba", "committedDate": "2020-07-16 15:47:06 +0200", "message": "Added fix for split fetching in which case rtoken is null"}, {"oid": "0ccbdeb7d82c7c49179bf1dfb45a9f2bc7b4e22a", "committedDate": "2020-09-18 12:30:12 +0200", "message": "Reuse Random instance for onetimepad generation"}, {"oid": "be074ce3244a4dd07116f984d387c2f102ae7baf", "committedDate": "2020-09-18 12:34:32 +0200", "message": "Use ThreadLocalRandom to avoid contention"}, {"oid": "551d6c7b184d9874baa236fb282d165fb4c8fc19", "committedDate": "2020-10-09 11:22:20 +0200", "message": "Added support for fetching HBase cell TTLs."}, {"oid": "aa34e708809bd88e4d61ed05e78594349ad8bc53", "committedDate": "2020-11-09 17:14:53 +0100", "message": "400 error codes and clearer status messages for bad parameters"}, {"oid": "7b68e8cd0a3fbbede7181a68ac308ca213e762bc", "committedDate": "2020-11-10 17:18:57 +0100", "message": "More detailled error messages for /update"}, {"oid": "2c4cb6dd7d03ffc3cff1bcc54acc7d5ea63a1721", "committedDate": "2020-12-08 11:59:58 +0100", "message": "Remove dead code"}, {"oid": "5391746198caf205379f27ed8869286209c6bc54", "committedDate": "2021-04-21 11:26:20 +0200", "message": "Add .noauth, .nometa and .nofetch attributes for read tokens"}, {"oid": "fcf98bc9b20399739c3007cceb18e129dc683b3e", "committedDate": "2021-04-27 12:32:10 +0200", "message": "Change .nometa to .nofind for read tokens"}, {"oid": "74a9671e6abedd2b5bb1f0baa0dcadf72f0f3d58", "committedDate": "2021-07-09 10:53:57 +0200", "message": "Added support for token attributes in EgressFetchHandler"}, {"oid": "e826ea374df18f9d0ff413872ebf5ddd1ad0bd17", "committedDate": "2021-07-12 15:23:43 +0200", "message": "Remove unused variables and fields"}, {"oid": "ca6bdb3976d3b4a2f7bc13725de60be114969521", "committedDate": "2021-07-13 11:12:49 +0200", "message": "Addressed PR comments"}, {"oid": "f21f8f77ac3618283721a8321564afa8a332dad0", "committedDate": "2021-07-16 14:11:10 +0200", "message": "Resolved merge conflict"}, {"oid": "757d17217c94c854df32481d400ca77850496e82", "committedDate": "2021-10-14 00:40:43 +0200", "message": "Added gskip/gcount parameters"}, {"oid": "a736b000b485c80f73ff1212f27ec3c7f4873ae9", "committedDate": "2021-10-19 16:22:11 +0200", "message": "Addressed PR comments. Added params gskip/gcount to FETCH and FIND"}, {"oid": "3eb7452f98d09229b0fbe0e73f83827fb2560c5e", "committedDate": "2021-10-20 15:27:36 +0200", "message": "Fixed conditional bug. Changed HashSet instances into LinkedHashSet to retain order"}, {"oid": "cf48879d1384d14870b40e2a67ce12043c685acf", "committedDate": "2022-01-25 23:16:11 +0100", "message": "Modified the cases when the GTS cache file is used"}, {"oid": "f879aefc9399136e4fd07b5a58f1b2b8cecf879b", "committedDate": "2022-05-09 17:39:32 +0200", "message": "Added buffered version of encodeTo{Stream,Writer}. Changed EgressFetchHandler to use it with 100000 bytes buffer."}, {"oid": "f394f837d748835f9afdf8d6b1b6df9b4faec875", "committedDate": "2022-05-20 17:06:22 +0200", "message": "Modified to use stable buffer"}, {"oid": "11df13673124d676b001c194be72b18a655b3ca0", "committedDate": "2022-06-23 09:56:13 +0200", "message": "Added header indicating the time unit used by the platform"}, {"oid": "9cd68aa9bce8b19e1c990f5ddd2b1fc473b60dd2", "committedDate": "2022-08-29 13:58:00 +0200", "message": "Added propagation of ReadToken in GTSSplit"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTM4MjA3Mw==", "url": "https://github.com/senx/warp10-platform/pull/772#discussion_r441382073", "body": "1 is valid.", "bodyText": "1 is valid.", "bodyHTML": "<p dir=\"auto\">1 is valid.</p>", "author": "ftence", "createdAt": "2020-06-17T08:43:04Z", "path": "warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java", "diffHunk": "@@ -314,6 +343,38 @@ public void handle(String target, Request baseRequest, HttpServletRequest req, H\n         skip = Long.parseLong(skipParam);        \n       }\n       \n+      if (null != stepParam) {\n+        step = Long.parseLong(stepParam);\n+        if (step <= 1) {\n+          throw new WarpScriptException(\"Parameter '\" + Constants.HTTP_PARAM_STEP + \"' cannot be <= 1.\");\n+        }\n+      }\n+      \n+      if (null != timestepParam) {\n+        if (timestepParam.startsWith(\"P\")) {\n+          // Should be a ISO8601 duration\n+          ReadWritablePeriod period = new MutablePeriod();\n+\n+          ISOPeriodFormat.standard().getParser().parseInto(period, timestepParam, 0, Locale.US);\n+\n+          Period p = period.toPeriod();\n+\n+          if (p.getMonths() != 0 || p.getYears() != 0) {\n+            throw new WarpScriptException(\"No support for ambiguous durations containing years or months, please convert those to days.\");\n+          }\n+\n+          Duration duration = p.toDurationFrom(new Instant());\n+\n+          timestep = duration.getMillis() * Constants.TIME_UNITS_PER_MS;\n+        } else {\n+          timestep = Long.parseLong(timestepParam);\n+        }\n+        \n+        if (timestep <= 1) {\n+          throw new WarpScriptException(\"Parameter '\" + Constants.HTTP_PARAM_TIMESTEP + \"' cannot be <= 1.\");\n+        }", "originalCommit": "e07598603051ad7fa838f08bfec01a2aa247f958", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "879ad4092491eda3b08f942710d5bdc6b1e90c69", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java b/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\nindex 0a3de908..3023566c 100644\n--- a/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\n+++ b/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\n", "chunk": "@@ -345,33 +347,29 @@ public class EgressFetchHandler extends AbstractHandler {\n       \n       if (null != stepParam) {\n         step = Long.parseLong(stepParam);\n-        if (step <= 1) {\n-          throw new WarpScriptException(\"Parameter '\" + Constants.HTTP_PARAM_STEP + \"' cannot be <= 1.\");\n+        if (step < 1) {\n+          throw new WarpScriptException(\"Parameter '\" + Constants.HTTP_PARAM_STEP + \"' cannot be < 1.\");\n         }\n       }\n       \n       if (null != timestepParam) {\n         if (timestepParam.startsWith(\"P\")) {\n-          // Should be a ISO8601 duration\n-          ReadWritablePeriod period = new MutablePeriod();\n-\n-          ISOPeriodFormat.standard().getParser().parseInto(period, timestepParam, 0, Locale.US);\n-\n-          Period p = period.toPeriod();\n+          \n+          ADDDURATION.ReadWritablePeriodWithSubSecondOffset periodWithSubSec = ADDDURATION.durationToPeriod(timestepParam);\n+          \n+          ReadWritablePeriod p = periodWithSubSec.getPeriod();\n \n-          if (p.getMonths() != 0 || p.getYears() != 0) {\n+          if (p.get(DurationFieldType.months()) != 0 || p.get(DurationFieldType.years()) != 0) {\n             throw new WarpScriptException(\"No support for ambiguous durations containing years or months, please convert those to days.\");\n           }\n \n-          Duration duration = p.toDurationFrom(new Instant());\n-\n-          timestep = duration.getMillis() * Constants.TIME_UNITS_PER_MS;\n+          timestep = periodWithSubSec.getPeriod().toPeriod().toDurationFrom(new Instant()).getMillis() * Constants.TIME_UNITS_PER_MS + periodWithSubSec.getOffset();\n         } else {\n           timestep = Long.parseLong(timestepParam);\n         }\n         \n-        if (timestep <= 1) {\n-          throw new WarpScriptException(\"Parameter '\" + Constants.HTTP_PARAM_TIMESTEP + \"' cannot be <= 1.\");\n+        if (timestep < 1) {\n+          throw new WarpScriptException(\"Parameter '\" + Constants.HTTP_PARAM_TIMESTEP + \"' cannot be < 1.\");\n         }\n       }\n       \n", "next_change": null}]}, "revised_code_in_main": {"commit": "67019d40559484d9cf2daf23cf83d122822ff274", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java b/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\nindex 0a3de908..3023566c 100644\n--- a/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\n+++ b/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\n", "chunk": "@@ -345,33 +347,29 @@ public class EgressFetchHandler extends AbstractHandler {\n       \n       if (null != stepParam) {\n         step = Long.parseLong(stepParam);\n-        if (step <= 1) {\n-          throw new WarpScriptException(\"Parameter '\" + Constants.HTTP_PARAM_STEP + \"' cannot be <= 1.\");\n+        if (step < 1) {\n+          throw new WarpScriptException(\"Parameter '\" + Constants.HTTP_PARAM_STEP + \"' cannot be < 1.\");\n         }\n       }\n       \n       if (null != timestepParam) {\n         if (timestepParam.startsWith(\"P\")) {\n-          // Should be a ISO8601 duration\n-          ReadWritablePeriod period = new MutablePeriod();\n-\n-          ISOPeriodFormat.standard().getParser().parseInto(period, timestepParam, 0, Locale.US);\n-\n-          Period p = period.toPeriod();\n+          \n+          ADDDURATION.ReadWritablePeriodWithSubSecondOffset periodWithSubSec = ADDDURATION.durationToPeriod(timestepParam);\n+          \n+          ReadWritablePeriod p = periodWithSubSec.getPeriod();\n \n-          if (p.getMonths() != 0 || p.getYears() != 0) {\n+          if (p.get(DurationFieldType.months()) != 0 || p.get(DurationFieldType.years()) != 0) {\n             throw new WarpScriptException(\"No support for ambiguous durations containing years or months, please convert those to days.\");\n           }\n \n-          Duration duration = p.toDurationFrom(new Instant());\n-\n-          timestep = duration.getMillis() * Constants.TIME_UNITS_PER_MS;\n+          timestep = periodWithSubSec.getPeriod().toPeriod().toDurationFrom(new Instant()).getMillis() * Constants.TIME_UNITS_PER_MS + periodWithSubSec.getOffset();\n         } else {\n           timestep = Long.parseLong(timestepParam);\n         }\n         \n-        if (timestep <= 1) {\n-          throw new WarpScriptException(\"Parameter '\" + Constants.HTTP_PARAM_TIMESTEP + \"' cannot be <= 1.\");\n+        if (timestep < 1) {\n+          throw new WarpScriptException(\"Parameter '\" + Constants.HTTP_PARAM_TIMESTEP + \"' cannot be < 1.\");\n         }\n       }\n       \n", "next_change": {"commit": "aa34e708809bd88e4d61ed05e78594349ad8bc53", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java b/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\nindex 3023566c..bebb9d49 100644\n--- a/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\n+++ b/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\n", "chunk": "@@ -369,7 +375,8 @@ public class EgressFetchHandler extends AbstractHandler {\n         }\n         \n         if (timestep < 1) {\n-          throw new WarpScriptException(\"Parameter '\" + Constants.HTTP_PARAM_TIMESTEP + \"' cannot be < 1.\");\n+          httpStatusCode = HttpServletResponse.SC_BAD_REQUEST;\n+          throw new IOException(\"Parameter '\" + Constants.HTTP_PARAM_TIMESTEP + \"' cannot be < 1.\");\n         }\n       }\n       \n", "next_change": {"commit": "74a9671e6abedd2b5bb1f0baa0dcadf72f0f3d58", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java b/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\nindex bebb9d49..8818617f 100644\n--- a/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\n+++ b/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\n", "chunk": "@@ -373,13 +373,13 @@ public class EgressFetchHandler extends AbstractHandler {\n         } else {\n           timestep = Long.parseLong(timestepParam);\n         }\n-        \n+\n         if (timestep < 1) {\n           httpStatusCode = HttpServletResponse.SC_BAD_REQUEST;\n           throw new IOException(\"Parameter '\" + Constants.HTTP_PARAM_TIMESTEP + \"' cannot be < 1.\");\n         }\n       }\n-      \n+\n       if (null != sampleParam) {\n         sample = Double.parseDouble(sampleParam);\n       }\n", "next_change": {"commit": "e826ea374df18f9d0ff413872ebf5ddd1ad0bd17", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java b/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\nindex 8818617f..8f5a7546 100644\n--- a/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\n+++ b/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\n", "chunk": "@@ -373,13 +373,13 @@ public class EgressFetchHandler extends AbstractHandler {\n         } else {\n           timestep = Long.parseLong(timestepParam);\n         }\n-\n+        \n         if (timestep < 1) {\n           httpStatusCode = HttpServletResponse.SC_BAD_REQUEST;\n           throw new IOException(\"Parameter '\" + Constants.HTTP_PARAM_TIMESTEP + \"' cannot be < 1.\");\n         }\n       }\n-\n+      \n       if (null != sampleParam) {\n         sample = Double.parseDouble(sampleParam);\n       }\n", "next_change": {"commit": "ca6bdb3976d3b4a2f7bc13725de60be114969521", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java b/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\nindex 8f5a7546..c726bf26 100644\n--- a/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\n+++ b/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\n", "chunk": "@@ -373,13 +373,13 @@ public class EgressFetchHandler extends AbstractHandler {\n         } else {\n           timestep = Long.parseLong(timestepParam);\n         }\n-        \n+\n         if (timestep < 1) {\n           httpStatusCode = HttpServletResponse.SC_BAD_REQUEST;\n           throw new IOException(\"Parameter '\" + Constants.HTTP_PARAM_TIMESTEP + \"' cannot be < 1.\");\n         }\n       }\n-      \n+\n       if (null != sampleParam) {\n         sample = Double.parseDouble(sampleParam);\n       }\n", "next_change": null}]}}]}}]}}]}}]}, "commits_in_main": [{"oid": "67019d40559484d9cf2daf23cf83d122822ff274", "message": "Merge commit", "committedDate": null}, {"oid": "a0ce525c9e1ce3800077185cdcb8e40b012ea9ba", "committedDate": "2020-07-16 15:47:06 +0200", "message": "Added fix for split fetching in which case rtoken is null"}, {"oid": "0ccbdeb7d82c7c49179bf1dfb45a9f2bc7b4e22a", "committedDate": "2020-09-18 12:30:12 +0200", "message": "Reuse Random instance for onetimepad generation"}, {"oid": "be074ce3244a4dd07116f984d387c2f102ae7baf", "committedDate": "2020-09-18 12:34:32 +0200", "message": "Use ThreadLocalRandom to avoid contention"}, {"oid": "551d6c7b184d9874baa236fb282d165fb4c8fc19", "committedDate": "2020-10-09 11:22:20 +0200", "message": "Added support for fetching HBase cell TTLs."}, {"oid": "aa34e708809bd88e4d61ed05e78594349ad8bc53", "committedDate": "2020-11-09 17:14:53 +0100", "message": "400 error codes and clearer status messages for bad parameters"}, {"oid": "7b68e8cd0a3fbbede7181a68ac308ca213e762bc", "committedDate": "2020-11-10 17:18:57 +0100", "message": "More detailled error messages for /update"}, {"oid": "2c4cb6dd7d03ffc3cff1bcc54acc7d5ea63a1721", "committedDate": "2020-12-08 11:59:58 +0100", "message": "Remove dead code"}, {"oid": "5391746198caf205379f27ed8869286209c6bc54", "committedDate": "2021-04-21 11:26:20 +0200", "message": "Add .noauth, .nometa and .nofetch attributes for read tokens"}, {"oid": "fcf98bc9b20399739c3007cceb18e129dc683b3e", "committedDate": "2021-04-27 12:32:10 +0200", "message": "Change .nometa to .nofind for read tokens"}, {"oid": "74a9671e6abedd2b5bb1f0baa0dcadf72f0f3d58", "committedDate": "2021-07-09 10:53:57 +0200", "message": "Added support for token attributes in EgressFetchHandler"}, {"oid": "e826ea374df18f9d0ff413872ebf5ddd1ad0bd17", "committedDate": "2021-07-12 15:23:43 +0200", "message": "Remove unused variables and fields"}, {"oid": "ca6bdb3976d3b4a2f7bc13725de60be114969521", "committedDate": "2021-07-13 11:12:49 +0200", "message": "Addressed PR comments"}, {"oid": "f21f8f77ac3618283721a8321564afa8a332dad0", "committedDate": "2021-07-16 14:11:10 +0200", "message": "Resolved merge conflict"}, {"oid": "757d17217c94c854df32481d400ca77850496e82", "committedDate": "2021-10-14 00:40:43 +0200", "message": "Added gskip/gcount parameters"}, {"oid": "a736b000b485c80f73ff1212f27ec3c7f4873ae9", "committedDate": "2021-10-19 16:22:11 +0200", "message": "Addressed PR comments. Added params gskip/gcount to FETCH and FIND"}, {"oid": "3eb7452f98d09229b0fbe0e73f83827fb2560c5e", "committedDate": "2021-10-20 15:27:36 +0200", "message": "Fixed conditional bug. Changed HashSet instances into LinkedHashSet to retain order"}, {"oid": "cf48879d1384d14870b40e2a67ce12043c685acf", "committedDate": "2022-01-25 23:16:11 +0100", "message": "Modified the cases when the GTS cache file is used"}, {"oid": "f879aefc9399136e4fd07b5a58f1b2b8cecf879b", "committedDate": "2022-05-09 17:39:32 +0200", "message": "Added buffered version of encodeTo{Stream,Writer}. Changed EgressFetchHandler to use it with 100000 bytes buffer."}, {"oid": "f394f837d748835f9afdf8d6b1b6df9b4faec875", "committedDate": "2022-05-20 17:06:22 +0200", "message": "Modified to use stable buffer"}, {"oid": "11df13673124d676b001c194be72b18a655b3ca0", "committedDate": "2022-06-23 09:56:13 +0200", "message": "Added header indicating the time unit used by the platform"}, {"oid": "9cd68aa9bce8b19e1c990f5ddd2b1fc473b60dd2", "committedDate": "2022-08-29 13:58:00 +0200", "message": "Added propagation of ReadToken in GTSSplit"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTQwMDQ2Nw==", "url": "https://github.com/senx/warp10-platform/pull/772#discussion_r441400467", "body": "Better use\r\n```\r\nADDDURATION.ReadWritablePeriodWithSubSecondOffset periodWithSubSec = ADDDURATION.durationToPeriod(timestepParam);\r\n// Check that the period does not have months or year\r\ntimestep = periodWithSubSec.getPeriod().toPeriod().toDurationFrom(new Instant()).getMillis() * Constants.TIME_UNITS_PER_MS + periodWithSubSec.getOffset();\r\n```\r\nto allow sub-millisecond precision with ISO 8601 representation.", "bodyText": "Better use\nADDDURATION.ReadWritablePeriodWithSubSecondOffset periodWithSubSec = ADDDURATION.durationToPeriod(timestepParam);\n// Check that the period does not have months or year\ntimestep = periodWithSubSec.getPeriod().toPeriod().toDurationFrom(new Instant()).getMillis() * Constants.TIME_UNITS_PER_MS + periodWithSubSec.getOffset();\n\nto allow sub-millisecond precision with ISO 8601 representation.", "bodyHTML": "<p dir=\"auto\">Better use</p>\n<div class=\"snippet-clipboard-content position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"ADDDURATION.ReadWritablePeriodWithSubSecondOffset periodWithSubSec = ADDDURATION.durationToPeriod(timestepParam);\n// Check that the period does not have months or year\ntimestep = periodWithSubSec.getPeriod().toPeriod().toDurationFrom(new Instant()).getMillis() * Constants.TIME_UNITS_PER_MS + periodWithSubSec.getOffset();\n\"><pre><code>ADDDURATION.ReadWritablePeriodWithSubSecondOffset periodWithSubSec = ADDDURATION.durationToPeriod(timestepParam);\n// Check that the period does not have months or year\ntimestep = periodWithSubSec.getPeriod().toPeriod().toDurationFrom(new Instant()).getMillis() * Constants.TIME_UNITS_PER_MS + periodWithSubSec.getOffset();\n</code></pre></div>\n<p dir=\"auto\">to allow sub-millisecond precision with ISO 8601 representation.</p>", "author": "ftence", "createdAt": "2020-06-17T09:12:09Z", "path": "warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java", "diffHunk": "@@ -314,6 +343,38 @@ public void handle(String target, Request baseRequest, HttpServletRequest req, H\n         skip = Long.parseLong(skipParam);        \n       }\n       \n+      if (null != stepParam) {\n+        step = Long.parseLong(stepParam);\n+        if (step <= 1) {\n+          throw new WarpScriptException(\"Parameter '\" + Constants.HTTP_PARAM_STEP + \"' cannot be <= 1.\");\n+        }\n+      }\n+      \n+      if (null != timestepParam) {\n+        if (timestepParam.startsWith(\"P\")) {\n+          // Should be a ISO8601 duration\n+          ReadWritablePeriod period = new MutablePeriod();\n+\n+          ISOPeriodFormat.standard().getParser().parseInto(period, timestepParam, 0, Locale.US);\n+\n+          Period p = period.toPeriod();\n+\n+          if (p.getMonths() != 0 || p.getYears() != 0) {\n+            throw new WarpScriptException(\"No support for ambiguous durations containing years or months, please convert those to days.\");\n+          }\n+\n+          Duration duration = p.toDurationFrom(new Instant());\n+\n+          timestep = duration.getMillis() * Constants.TIME_UNITS_PER_MS;", "originalCommit": "e07598603051ad7fa838f08bfec01a2aa247f958", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "879ad4092491eda3b08f942710d5bdc6b1e90c69", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java b/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\nindex 0a3de908..3023566c 100644\n--- a/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\n+++ b/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\n", "chunk": "@@ -345,33 +347,29 @@ public class EgressFetchHandler extends AbstractHandler {\n       \n       if (null != stepParam) {\n         step = Long.parseLong(stepParam);\n-        if (step <= 1) {\n-          throw new WarpScriptException(\"Parameter '\" + Constants.HTTP_PARAM_STEP + \"' cannot be <= 1.\");\n+        if (step < 1) {\n+          throw new WarpScriptException(\"Parameter '\" + Constants.HTTP_PARAM_STEP + \"' cannot be < 1.\");\n         }\n       }\n       \n       if (null != timestepParam) {\n         if (timestepParam.startsWith(\"P\")) {\n-          // Should be a ISO8601 duration\n-          ReadWritablePeriod period = new MutablePeriod();\n-\n-          ISOPeriodFormat.standard().getParser().parseInto(period, timestepParam, 0, Locale.US);\n-\n-          Period p = period.toPeriod();\n+          \n+          ADDDURATION.ReadWritablePeriodWithSubSecondOffset periodWithSubSec = ADDDURATION.durationToPeriod(timestepParam);\n+          \n+          ReadWritablePeriod p = periodWithSubSec.getPeriod();\n \n-          if (p.getMonths() != 0 || p.getYears() != 0) {\n+          if (p.get(DurationFieldType.months()) != 0 || p.get(DurationFieldType.years()) != 0) {\n             throw new WarpScriptException(\"No support for ambiguous durations containing years or months, please convert those to days.\");\n           }\n \n-          Duration duration = p.toDurationFrom(new Instant());\n-\n-          timestep = duration.getMillis() * Constants.TIME_UNITS_PER_MS;\n+          timestep = periodWithSubSec.getPeriod().toPeriod().toDurationFrom(new Instant()).getMillis() * Constants.TIME_UNITS_PER_MS + periodWithSubSec.getOffset();\n         } else {\n           timestep = Long.parseLong(timestepParam);\n         }\n         \n-        if (timestep <= 1) {\n-          throw new WarpScriptException(\"Parameter '\" + Constants.HTTP_PARAM_TIMESTEP + \"' cannot be <= 1.\");\n+        if (timestep < 1) {\n+          throw new WarpScriptException(\"Parameter '\" + Constants.HTTP_PARAM_TIMESTEP + \"' cannot be < 1.\");\n         }\n       }\n       \n", "next_change": null}]}, "revised_code_in_main": {"commit": "67019d40559484d9cf2daf23cf83d122822ff274", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java b/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\nindex 0a3de908..3023566c 100644\n--- a/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\n+++ b/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\n", "chunk": "@@ -345,33 +347,29 @@ public class EgressFetchHandler extends AbstractHandler {\n       \n       if (null != stepParam) {\n         step = Long.parseLong(stepParam);\n-        if (step <= 1) {\n-          throw new WarpScriptException(\"Parameter '\" + Constants.HTTP_PARAM_STEP + \"' cannot be <= 1.\");\n+        if (step < 1) {\n+          throw new WarpScriptException(\"Parameter '\" + Constants.HTTP_PARAM_STEP + \"' cannot be < 1.\");\n         }\n       }\n       \n       if (null != timestepParam) {\n         if (timestepParam.startsWith(\"P\")) {\n-          // Should be a ISO8601 duration\n-          ReadWritablePeriod period = new MutablePeriod();\n-\n-          ISOPeriodFormat.standard().getParser().parseInto(period, timestepParam, 0, Locale.US);\n-\n-          Period p = period.toPeriod();\n+          \n+          ADDDURATION.ReadWritablePeriodWithSubSecondOffset periodWithSubSec = ADDDURATION.durationToPeriod(timestepParam);\n+          \n+          ReadWritablePeriod p = periodWithSubSec.getPeriod();\n \n-          if (p.getMonths() != 0 || p.getYears() != 0) {\n+          if (p.get(DurationFieldType.months()) != 0 || p.get(DurationFieldType.years()) != 0) {\n             throw new WarpScriptException(\"No support for ambiguous durations containing years or months, please convert those to days.\");\n           }\n \n-          Duration duration = p.toDurationFrom(new Instant());\n-\n-          timestep = duration.getMillis() * Constants.TIME_UNITS_PER_MS;\n+          timestep = periodWithSubSec.getPeriod().toPeriod().toDurationFrom(new Instant()).getMillis() * Constants.TIME_UNITS_PER_MS + periodWithSubSec.getOffset();\n         } else {\n           timestep = Long.parseLong(timestepParam);\n         }\n         \n-        if (timestep <= 1) {\n-          throw new WarpScriptException(\"Parameter '\" + Constants.HTTP_PARAM_TIMESTEP + \"' cannot be <= 1.\");\n+        if (timestep < 1) {\n+          throw new WarpScriptException(\"Parameter '\" + Constants.HTTP_PARAM_TIMESTEP + \"' cannot be < 1.\");\n         }\n       }\n       \n", "next_change": {"commit": "aa34e708809bd88e4d61ed05e78594349ad8bc53", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java b/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\nindex 3023566c..bebb9d49 100644\n--- a/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\n+++ b/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\n", "chunk": "@@ -369,7 +375,8 @@ public class EgressFetchHandler extends AbstractHandler {\n         }\n         \n         if (timestep < 1) {\n-          throw new WarpScriptException(\"Parameter '\" + Constants.HTTP_PARAM_TIMESTEP + \"' cannot be < 1.\");\n+          httpStatusCode = HttpServletResponse.SC_BAD_REQUEST;\n+          throw new IOException(\"Parameter '\" + Constants.HTTP_PARAM_TIMESTEP + \"' cannot be < 1.\");\n         }\n       }\n       \n", "next_change": {"commit": "74a9671e6abedd2b5bb1f0baa0dcadf72f0f3d58", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java b/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\nindex bebb9d49..8818617f 100644\n--- a/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\n+++ b/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\n", "chunk": "@@ -373,13 +373,13 @@ public class EgressFetchHandler extends AbstractHandler {\n         } else {\n           timestep = Long.parseLong(timestepParam);\n         }\n-        \n+\n         if (timestep < 1) {\n           httpStatusCode = HttpServletResponse.SC_BAD_REQUEST;\n           throw new IOException(\"Parameter '\" + Constants.HTTP_PARAM_TIMESTEP + \"' cannot be < 1.\");\n         }\n       }\n-      \n+\n       if (null != sampleParam) {\n         sample = Double.parseDouble(sampleParam);\n       }\n", "next_change": {"commit": "e826ea374df18f9d0ff413872ebf5ddd1ad0bd17", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java b/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\nindex 8818617f..8f5a7546 100644\n--- a/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\n+++ b/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\n", "chunk": "@@ -373,13 +373,13 @@ public class EgressFetchHandler extends AbstractHandler {\n         } else {\n           timestep = Long.parseLong(timestepParam);\n         }\n-\n+        \n         if (timestep < 1) {\n           httpStatusCode = HttpServletResponse.SC_BAD_REQUEST;\n           throw new IOException(\"Parameter '\" + Constants.HTTP_PARAM_TIMESTEP + \"' cannot be < 1.\");\n         }\n       }\n-\n+      \n       if (null != sampleParam) {\n         sample = Double.parseDouble(sampleParam);\n       }\n", "next_change": {"commit": "ca6bdb3976d3b4a2f7bc13725de60be114969521", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java b/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\nindex 8f5a7546..c726bf26 100644\n--- a/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\n+++ b/warp10/src/main/java/io/warp10/continuum/egress/EgressFetchHandler.java\n", "chunk": "@@ -373,13 +373,13 @@ public class EgressFetchHandler extends AbstractHandler {\n         } else {\n           timestep = Long.parseLong(timestepParam);\n         }\n-        \n+\n         if (timestep < 1) {\n           httpStatusCode = HttpServletResponse.SC_BAD_REQUEST;\n           throw new IOException(\"Parameter '\" + Constants.HTTP_PARAM_TIMESTEP + \"' cannot be < 1.\");\n         }\n       }\n-      \n+\n       if (null != sampleParam) {\n         sample = Double.parseDouble(sampleParam);\n       }\n", "next_change": null}]}}]}}]}}]}}]}, "commits_in_main": [{"oid": "67019d40559484d9cf2daf23cf83d122822ff274", "message": "Merge commit", "committedDate": null}, {"oid": "a0ce525c9e1ce3800077185cdcb8e40b012ea9ba", "committedDate": "2020-07-16 15:47:06 +0200", "message": "Added fix for split fetching in which case rtoken is null"}, {"oid": "0ccbdeb7d82c7c49179bf1dfb45a9f2bc7b4e22a", "committedDate": "2020-09-18 12:30:12 +0200", "message": "Reuse Random instance for onetimepad generation"}, {"oid": "be074ce3244a4dd07116f984d387c2f102ae7baf", "committedDate": "2020-09-18 12:34:32 +0200", "message": "Use ThreadLocalRandom to avoid contention"}, {"oid": "551d6c7b184d9874baa236fb282d165fb4c8fc19", "committedDate": "2020-10-09 11:22:20 +0200", "message": "Added support for fetching HBase cell TTLs."}, {"oid": "aa34e708809bd88e4d61ed05e78594349ad8bc53", "committedDate": "2020-11-09 17:14:53 +0100", "message": "400 error codes and clearer status messages for bad parameters"}, {"oid": "7b68e8cd0a3fbbede7181a68ac308ca213e762bc", "committedDate": "2020-11-10 17:18:57 +0100", "message": "More detailled error messages for /update"}, {"oid": "2c4cb6dd7d03ffc3cff1bcc54acc7d5ea63a1721", "committedDate": "2020-12-08 11:59:58 +0100", "message": "Remove dead code"}, {"oid": "5391746198caf205379f27ed8869286209c6bc54", "committedDate": "2021-04-21 11:26:20 +0200", "message": "Add .noauth, .nometa and .nofetch attributes for read tokens"}, {"oid": "fcf98bc9b20399739c3007cceb18e129dc683b3e", "committedDate": "2021-04-27 12:32:10 +0200", "message": "Change .nometa to .nofind for read tokens"}, {"oid": "74a9671e6abedd2b5bb1f0baa0dcadf72f0f3d58", "committedDate": "2021-07-09 10:53:57 +0200", "message": "Added support for token attributes in EgressFetchHandler"}, {"oid": "e826ea374df18f9d0ff413872ebf5ddd1ad0bd17", "committedDate": "2021-07-12 15:23:43 +0200", "message": "Remove unused variables and fields"}, {"oid": "ca6bdb3976d3b4a2f7bc13725de60be114969521", "committedDate": "2021-07-13 11:12:49 +0200", "message": "Addressed PR comments"}, {"oid": "f21f8f77ac3618283721a8321564afa8a332dad0", "committedDate": "2021-07-16 14:11:10 +0200", "message": "Resolved merge conflict"}, {"oid": "757d17217c94c854df32481d400ca77850496e82", "committedDate": "2021-10-14 00:40:43 +0200", "message": "Added gskip/gcount parameters"}, {"oid": "a736b000b485c80f73ff1212f27ec3c7f4873ae9", "committedDate": "2021-10-19 16:22:11 +0200", "message": "Addressed PR comments. Added params gskip/gcount to FETCH and FIND"}, {"oid": "3eb7452f98d09229b0fbe0e73f83827fb2560c5e", "committedDate": "2021-10-20 15:27:36 +0200", "message": "Fixed conditional bug. Changed HashSet instances into LinkedHashSet to retain order"}, {"oid": "cf48879d1384d14870b40e2a67ce12043c685acf", "committedDate": "2022-01-25 23:16:11 +0100", "message": "Modified the cases when the GTS cache file is used"}, {"oid": "f879aefc9399136e4fd07b5a58f1b2b8cecf879b", "committedDate": "2022-05-09 17:39:32 +0200", "message": "Added buffered version of encodeTo{Stream,Writer}. Changed EgressFetchHandler to use it with 100000 bytes buffer."}, {"oid": "f394f837d748835f9afdf8d6b1b6df9b4faec875", "committedDate": "2022-05-20 17:06:22 +0200", "message": "Modified to use stable buffer"}, {"oid": "11df13673124d676b001c194be72b18a655b3ca0", "committedDate": "2022-06-23 09:56:13 +0200", "message": "Added header indicating the time unit used by the platform"}, {"oid": "9cd68aa9bce8b19e1c990f5ddd2b1fc473b60dd2", "committedDate": "2022-08-29 13:58:00 +0200", "message": "Added propagation of ReadToken in GTSSplit"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTQwODMzOA==", "url": "https://github.com/senx/warp10-platform/pull/772#discussion_r441408338", "body": "Update the javadoc to reflect that this function takes only one parameter, leaving the description of its fields.\r\nAlso change `then` to `thents`.", "bodyText": "Update the javadoc to reflect that this function takes only one parameter, leaving the description of its fields.\nAlso change then to thents.", "bodyHTML": "<p dir=\"auto\">Update the javadoc to reflect that this function takes only one parameter, leaving the description of its fields.<br>\nAlso change <code>then</code> to <code>thents</code>.</p>", "author": "ftence", "createdAt": "2020-06-17T09:24:49Z", "path": "warp10/src/main/java/io/warp10/continuum/store/StoreClient.java", "diffHunk": "@@ -36,13 +35,15 @@\n    * @param then Start timestamp (included)\n    * @param count Number of datapoints to fetch. 0 is a valid value if you want to fetch only boundaries. Use -1 to specify you are not fetching by count.\n    * @param skip Number of datapoints to skip before returning values\n+   * @param step Index offset between two datapoints, defaults to 1, i.e. return every data point\n+   * @param timestep Minimum time offset between datapoints, defaults to 1 time unit\n    * @param sample Double value representing the sampling rate. Use 1.0D for returning all values. Valid values are ] 0.0D, 1.0D ]\n    * @param writeTimestamp Flag indicating we are interested in the HBase cell timestamp\n    * @param preBoundary Size of the pre boundary in number of values\n    * @param postBoundary Size of the post boundary in number of values\n    * @return\n    * @throws IOException\n    */\n-  public GTSDecoderIterator fetch(ReadToken token, final List<Metadata> metadatas, final long now, final long then, long count, long skip, double sample, boolean writeTimestamp, final long preBoundary, final long postBoundary) throws IOException;\n+  public GTSDecoderIterator fetch(FetchRequest req) throws IOException; //ReadToken token, final List<Metadata> metadatas, final long now, final long then, long count, long skip, long step, long timestep, double sample, boolean writeTimestamp, final long preBoundary, final long postBoundary) throws IOException;", "originalCommit": "e07598603051ad7fa838f08bfec01a2aa247f958", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "879ad4092491eda3b08f942710d5bdc6b1e90c69", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/store/StoreClient.java b/warp10/src/main/java/io/warp10/continuum/store/StoreClient.java\nindex 5385eb5c..8066f5d0 100644\n--- a/warp10/src/main/java/io/warp10/continuum/store/StoreClient.java\n+++ b/warp10/src/main/java/io/warp10/continuum/store/StoreClient.java\n", "chunk": "@@ -28,22 +28,22 @@ public interface StoreClient {\n   public void store(GTSEncoder encoder) throws IOException;\n   public long delete(WriteToken token, Metadata metadata, long start, long end) throws IOException;\n   /**\n-   * \n-   * @param token Read token to use for reading data\n-   * @param metadatas List of Metadata for the GTS to fetch\n-   * @param now End timestamp (included)\n-   * @param then Start timestamp (included)\n-   * @param count Number of datapoints to fetch. 0 is a valid value if you want to fetch only boundaries. Use -1 to specify you are not fetching by count.\n-   * @param skip Number of datapoints to skip before returning values\n-   * @param step Index offset between two datapoints, defaults to 1, i.e. return every data point\n-   * @param timestep Minimum time offset between datapoints, defaults to 1 time unit\n-   * @param sample Double value representing the sampling rate. Use 1.0D for returning all values. Valid values are ] 0.0D, 1.0D ]\n-   * @param writeTimestamp Flag indicating we are interested in the HBase cell timestamp\n-   * @param preBoundary Size of the pre boundary in number of values\n-   * @param postBoundary Size of the post boundary in number of values\n+   * @param req FetchRequest instance containing the following elements:\n+   *   token Read token to use for reading data\n+   *   metadatas List of Metadata for the GTS to fetch\n+   *   now End timestamp (included)\n+   *   thents Start timestamp (included)\n+   *   count Number of datapoints to fetch. 0 is a valid value if you want to fetch only boundaries. Use -1 to specify you are not fetching by count.\n+   *   skip Number of datapoints to skip before returning values\n+   *   step Index offset between two datapoints, defaults to 1, i.e. return every data point\n+   *   timestep Minimum time offset between datapoints, defaults to 1 time unit\n+   *   sample Double value representing the sampling rate. Use 1.0D for returning all values. Valid values are ] 0.0D, 1.0D ]\n+   *   writeTimestamp Flag indicating we are interested in the HBase cell timestamp\n+   *   preBoundary Size of the pre boundary in number of values\n+   *   postBoundary Size of the post boundary in number of values\n    * @return\n    * @throws IOException\n    */\n-  public GTSDecoderIterator fetch(FetchRequest req) throws IOException; //ReadToken token, final List<Metadata> metadatas, final long now, final long then, long count, long skip, long step, long timestep, double sample, boolean writeTimestamp, final long preBoundary, final long postBoundary) throws IOException;\n+  public GTSDecoderIterator fetch(FetchRequest req) throws IOException;\n   public void addPlasmaHandler(StandalonePlasmaHandlerInterface handler);\n }\n", "next_change": null}]}, "revised_code_in_main": {"commit": "67019d40559484d9cf2daf23cf83d122822ff274", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/store/StoreClient.java b/warp10/src/main/java/io/warp10/continuum/store/StoreClient.java\nindex 5385eb5c..8066f5d0 100644\n--- a/warp10/src/main/java/io/warp10/continuum/store/StoreClient.java\n+++ b/warp10/src/main/java/io/warp10/continuum/store/StoreClient.java\n", "chunk": "@@ -28,22 +28,22 @@ public interface StoreClient {\n   public void store(GTSEncoder encoder) throws IOException;\n   public long delete(WriteToken token, Metadata metadata, long start, long end) throws IOException;\n   /**\n-   * \n-   * @param token Read token to use for reading data\n-   * @param metadatas List of Metadata for the GTS to fetch\n-   * @param now End timestamp (included)\n-   * @param then Start timestamp (included)\n-   * @param count Number of datapoints to fetch. 0 is a valid value if you want to fetch only boundaries. Use -1 to specify you are not fetching by count.\n-   * @param skip Number of datapoints to skip before returning values\n-   * @param step Index offset between two datapoints, defaults to 1, i.e. return every data point\n-   * @param timestep Minimum time offset between datapoints, defaults to 1 time unit\n-   * @param sample Double value representing the sampling rate. Use 1.0D for returning all values. Valid values are ] 0.0D, 1.0D ]\n-   * @param writeTimestamp Flag indicating we are interested in the HBase cell timestamp\n-   * @param preBoundary Size of the pre boundary in number of values\n-   * @param postBoundary Size of the post boundary in number of values\n+   * @param req FetchRequest instance containing the following elements:\n+   *   token Read token to use for reading data\n+   *   metadatas List of Metadata for the GTS to fetch\n+   *   now End timestamp (included)\n+   *   thents Start timestamp (included)\n+   *   count Number of datapoints to fetch. 0 is a valid value if you want to fetch only boundaries. Use -1 to specify you are not fetching by count.\n+   *   skip Number of datapoints to skip before returning values\n+   *   step Index offset between two datapoints, defaults to 1, i.e. return every data point\n+   *   timestep Minimum time offset between datapoints, defaults to 1 time unit\n+   *   sample Double value representing the sampling rate. Use 1.0D for returning all values. Valid values are ] 0.0D, 1.0D ]\n+   *   writeTimestamp Flag indicating we are interested in the HBase cell timestamp\n+   *   preBoundary Size of the pre boundary in number of values\n+   *   postBoundary Size of the post boundary in number of values\n    * @return\n    * @throws IOException\n    */\n-  public GTSDecoderIterator fetch(FetchRequest req) throws IOException; //ReadToken token, final List<Metadata> metadatas, final long now, final long then, long count, long skip, long step, long timestep, double sample, boolean writeTimestamp, final long preBoundary, final long postBoundary) throws IOException;\n+  public GTSDecoderIterator fetch(FetchRequest req) throws IOException;\n   public void addPlasmaHandler(StandalonePlasmaHandlerInterface handler);\n }\n", "next_change": {"commit": "8108f6bdb84db8e1fb1e7eb5e42f32228cab2d27", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/store/StoreClient.java b/warp10/src/main/java/io/warp10/continuum/store/StoreClient.java\nindex 8066f5d0..333ead59 100644\n--- a/warp10/src/main/java/io/warp10/continuum/store/StoreClient.java\n+++ b/warp10/src/main/java/io/warp10/continuum/store/StoreClient.java\n", "chunk": "@@ -41,8 +41,6 @@ public interface StoreClient {\n    *   writeTimestamp Flag indicating we are interested in the HBase cell timestamp\n    *   preBoundary Size of the pre boundary in number of values\n    *   postBoundary Size of the post boundary in number of values\n-   * @return\n-   * @throws IOException\n    */\n   public GTSDecoderIterator fetch(FetchRequest req) throws IOException;\n   public void addPlasmaHandler(StandalonePlasmaHandlerInterface handler);\n", "next_change": null}]}}]}, "commits_in_main": [{"oid": "67019d40559484d9cf2daf23cf83d122822ff274", "message": "Merge commit", "committedDate": null}, {"oid": "8108f6bdb84db8e1fb1e7eb5e42f32228cab2d27", "committedDate": "2021-02-23 20:01:01 +0100", "message": "Fix javadoc warnings"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTQ5NzQ5Mg==", "url": "https://github.com/senx/warp10-platform/pull/772#discussion_r441497492", "body": "You should factorize the `FetchRequest` construction, making sure to use the copy constructor.\r\nOnly `preBoundary`, `postBoundary`, `step`, `timestep`, `sample`, `skip` and `count` may have been modified, so setting the other fields after the copy constructor is not necessary.", "bodyText": "You should factorize the FetchRequest construction, making sure to use the copy constructor.\nOnly preBoundary, postBoundary, step, timestep, sample, skip and count may have been modified, so setting the other fields after the copy constructor is not necessary.", "bodyHTML": "<p dir=\"auto\">You should factorize the <code>FetchRequest</code> construction, making sure to use the copy constructor.<br>\nOnly <code>preBoundary</code>, <code>postBoundary</code>, <code>step</code>, <code>timestep</code>, <code>sample</code>, <code>skip</code> and <code>count</code> may have been modified, so setting the other fields after the copy constructor is not necessary.</p>", "author": "ftence", "createdAt": "2020-06-17T12:12:25Z", "path": "warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java", "diffHunk": "@@ -209,48 +210,75 @@ public GTSDecoderIterator fetch(final ReadToken token, final List<Metadata> meta\n     // applied in order and the results returned by calls to 'next'.\n \n     //\n-    // DON'T use SlicedRowFilterGTSDecoterIterator when using a value count based approach with a value of 'now'\n-    // which is not congruent to 0 modulo DEFAULT_MODULUS, because we may then have datapoints after 'now' and would then\n-    // need to do a full scan of every classId/labelsId in metadatas as the SlicedRowFilter does not interpret the read data\n-    // and is thus unable to read the timestamp\n-    // Don't use the filter when skip is > 0 or sample < 1.0D\n-    //\n-    // Only use SlicedRowFilter when not having a value count approach or when 'now' is congruent to 0 modulo DEFAULT_MODULUS\n-    // or equal to Long.MAX_VALUE (EPOCHEND)\n+    // We cannot use SlicedRowFilterGTSDecoderIterator when fetching a pre or post boundary.\n+    // We cannot use it also when requesting a given number of values WITH the use of\n+    // either step/timestep/skip/sample.\n     //\n-    \n+\n     boolean optimized = false;\n     \n     if (useHBaseFilter && metadatas.size() > this.hbaseFilterThreshold) {\n       if (count > 0 && Long.MIN_VALUE == then) {\n         // If we are fetching per count only (i.e. time range ends at Long.MIN_VALUE)\n-        optimized = true;\n-      } else if (-1 == count) {\n+        // use the filter unless step/timestep/skip/sample are defined\n+        if (step <= 1L && timestep <= 1L && 1.0D == sample && 0L == skip) {\n+          optimized = true;\n+        }\n+      } else if (-1L == count) {\n         // When not fetching by count but by time range, use the filter\n         optimized = true;\n       }\n     }\n \n-    // If sampling or skipping, don't use the filter\n-    if (0 != skip || 1.0D != sample) {\n-      optimized = false;\n-    }\n-    \n     // When fetching boundaries, the optimized scanners cannot be used\n     if (preBoundary > 0 || postBoundary > 0) {\n       optimized = false;\n     }\n     \n     if (metadatas.size() < ParallelGTSDecoderIteratorWrapper.getMinGTSPerScanner() || !ParallelGTSDecoderIteratorWrapper.useParallelScanners()) {\n       if (optimized) {\n-        //return new SlicedRowFilterGTSDecoderIterator(now, timespan, metadatas, this.conn, this.tableName, this.colfam, this.keystore, metadatas.size() <= blockcacheThreshold);\n-        long timespan = count > 0 ? -count : (now - then + 1);\n-        return new OptimizedSlicedRowFilterGTSDecoderIterator(now, timespan, metadatas, this.conn, this.tableName, this.colfam, writeTimestamp, this.keystore, metadatas.size() <= blockcacheThreshold);\n+        FetchRequest freq = new FetchRequest(req);\n+        freq.setToken(req.getToken());\n+        freq.setNow(now);\n+        freq.setThents(then);\n+        freq.setCount(count);\n+        freq.setSkip(skip);\n+        freq.setStep(step);\n+        freq.setTimestep(timestep);\n+        freq.setSample(sample);\n+        freq.setMetadatas(metadatas);\n+        freq.setPreBoundary(preBoundary);\n+        freq.setPostBoundary(postBoundary);", "originalCommit": "e07598603051ad7fa838f08bfec01a2aa247f958", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "879ad4092491eda3b08f942710d5bdc6b1e90c69", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java b/warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java\nindex 8957b5c5..78df4efe 100644\n--- a/warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java\n+++ b/warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java\n", "chunk": "@@ -235,50 +233,25 @@ public class HBaseStoreClient implements StoreClient {\n       optimized = false;\n     }\n     \n+    FetchRequest freq = new FetchRequest(req);\n+    freq.setCount(count);\n+    freq.setSkip(skip);\n+    freq.setStep(step);\n+    freq.setTimestep(timestep);\n+    freq.setSample(sample);\n+    freq.setPreBoundary(preBoundary);\n+    freq.setPostBoundary(postBoundary);\n+\n+    boolean useBlockCache = metadatas.size() <= blockcacheThreshold;\n+\n     if (metadatas.size() < ParallelGTSDecoderIteratorWrapper.getMinGTSPerScanner() || !ParallelGTSDecoderIteratorWrapper.useParallelScanners()) {\n       if (optimized) {\n-        FetchRequest freq = new FetchRequest(req);\n-        freq.setToken(req.getToken());\n-        freq.setNow(now);\n-        freq.setThents(then);\n-        freq.setCount(count);\n-        freq.setSkip(skip);\n-        freq.setStep(step);\n-        freq.setTimestep(timestep);\n-        freq.setSample(sample);\n-        freq.setMetadatas(metadatas);\n-        freq.setPreBoundary(preBoundary);\n-        freq.setPostBoundary(postBoundary);\n-        return new OptimizedSlicedRowFilterGTSDecoderIterator(freq, this.conn, this.tableName, this.colfam, this.keystore, metadatas.size() <= blockcacheThreshold);\n+        return new OptimizedSlicedRowFilterGTSDecoderIterator(freq, this.conn, this.tableName, this.colfam, this.keystore, useBlockCache);\n       } else {\n-        FetchRequest freq = new FetchRequest();\n-        freq.setToken(req.getToken());\n-        freq.setNow(now);\n-        freq.setThents(then);\n-        freq.setCount(count);\n-        freq.setSkip(skip);\n-        freq.setStep(step);\n-        freq.setTimestep(timestep);\n-        freq.setSample(sample);\n-        freq.setMetadatas(metadatas);\n-        freq.setPreBoundary(preBoundary);\n-        freq.setPostBoundary(postBoundary);\n-        return new MultiScanGTSDecoderIterator(freq, this.conn, this.tableName, colfam, this.keystore, metadatas.size() < blockcacheThreshold);      \n+        return new MultiScanGTSDecoderIterator(freq, this.conn, this.tableName, colfam, this.keystore, useBlockCache);      \n       }      \n     } else {\n-      FetchRequest freq = new FetchRequest();\n-      freq.setToken(req.getToken());\n-      freq.setNow(now);\n-      freq.setThents(then);\n-      freq.setCount(count);\n-      freq.setSkip(skip);\n-      freq.setStep(step);\n-      freq.setTimestep(timestep);\n-      freq.setSample(sample);\n-      freq.setMetadatas(metadatas);\n-      freq.setPreBoundary(preBoundary);\n-      freq.setPostBoundary(postBoundary);\n-      return new ParallelGTSDecoderIteratorWrapper(freq, optimized, keystore, this.conn, this.tableName, this.colfam, metadatas.size() < blockcacheThreshold);\n+      return new ParallelGTSDecoderIteratorWrapper(freq, optimized, keystore, this.conn, this.tableName, this.colfam, useBlockCache);\n     }\n   }\n \n", "next_change": null}]}, "revised_code_in_main": {"commit": "67019d40559484d9cf2daf23cf83d122822ff274", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java b/warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java\nindex 8957b5c5..78df4efe 100644\n--- a/warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java\n+++ b/warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java\n", "chunk": "@@ -235,50 +233,25 @@ public class HBaseStoreClient implements StoreClient {\n       optimized = false;\n     }\n     \n+    FetchRequest freq = new FetchRequest(req);\n+    freq.setCount(count);\n+    freq.setSkip(skip);\n+    freq.setStep(step);\n+    freq.setTimestep(timestep);\n+    freq.setSample(sample);\n+    freq.setPreBoundary(preBoundary);\n+    freq.setPostBoundary(postBoundary);\n+\n+    boolean useBlockCache = metadatas.size() <= blockcacheThreshold;\n+\n     if (metadatas.size() < ParallelGTSDecoderIteratorWrapper.getMinGTSPerScanner() || !ParallelGTSDecoderIteratorWrapper.useParallelScanners()) {\n       if (optimized) {\n-        FetchRequest freq = new FetchRequest(req);\n-        freq.setToken(req.getToken());\n-        freq.setNow(now);\n-        freq.setThents(then);\n-        freq.setCount(count);\n-        freq.setSkip(skip);\n-        freq.setStep(step);\n-        freq.setTimestep(timestep);\n-        freq.setSample(sample);\n-        freq.setMetadatas(metadatas);\n-        freq.setPreBoundary(preBoundary);\n-        freq.setPostBoundary(postBoundary);\n-        return new OptimizedSlicedRowFilterGTSDecoderIterator(freq, this.conn, this.tableName, this.colfam, this.keystore, metadatas.size() <= blockcacheThreshold);\n+        return new OptimizedSlicedRowFilterGTSDecoderIterator(freq, this.conn, this.tableName, this.colfam, this.keystore, useBlockCache);\n       } else {\n-        FetchRequest freq = new FetchRequest();\n-        freq.setToken(req.getToken());\n-        freq.setNow(now);\n-        freq.setThents(then);\n-        freq.setCount(count);\n-        freq.setSkip(skip);\n-        freq.setStep(step);\n-        freq.setTimestep(timestep);\n-        freq.setSample(sample);\n-        freq.setMetadatas(metadatas);\n-        freq.setPreBoundary(preBoundary);\n-        freq.setPostBoundary(postBoundary);\n-        return new MultiScanGTSDecoderIterator(freq, this.conn, this.tableName, colfam, this.keystore, metadatas.size() < blockcacheThreshold);      \n+        return new MultiScanGTSDecoderIterator(freq, this.conn, this.tableName, colfam, this.keystore, useBlockCache);      \n       }      \n     } else {\n-      FetchRequest freq = new FetchRequest();\n-      freq.setToken(req.getToken());\n-      freq.setNow(now);\n-      freq.setThents(then);\n-      freq.setCount(count);\n-      freq.setSkip(skip);\n-      freq.setStep(step);\n-      freq.setTimestep(timestep);\n-      freq.setSample(sample);\n-      freq.setMetadatas(metadatas);\n-      freq.setPreBoundary(preBoundary);\n-      freq.setPostBoundary(postBoundary);\n-      return new ParallelGTSDecoderIteratorWrapper(freq, optimized, keystore, this.conn, this.tableName, this.colfam, metadatas.size() < blockcacheThreshold);\n+      return new ParallelGTSDecoderIteratorWrapper(freq, optimized, keystore, this.conn, this.tableName, this.colfam, useBlockCache);\n     }\n   }\n \n", "next_change": null}]}, "commits_in_main": [{"oid": "67019d40559484d9cf2daf23cf83d122822ff274", "message": "Merge commit", "committedDate": null}, {"oid": "e6738cc7a0795d42b7ec3de8769a8878ccc9aa64", "committedDate": "2020-07-29 22:48:12 +0200", "message": "Modified code so list of Metadatas is not deep copied when cloning FetchRequest"}, {"oid": "68d900dca0810a7dd53b694b74bf01ef55618574", "committedDate": "2020-10-19 16:58:35 +0200", "message": "Added flag to control parallel scanners in order to preserve GTS order."}, {"oid": "8108f6bdb84db8e1fb1e7eb5e42f32228cab2d27", "committedDate": "2021-02-23 20:01:01 +0100", "message": "Fix javadoc warnings"}, {"oid": "e826ea374df18f9d0ff413872ebf5ddd1ad0bd17", "committedDate": "2021-07-12 15:23:43 +0200", "message": "Remove unused variables and fields"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTQ5ODE1MQ==", "url": "https://github.com/senx/warp10-platform/pull/772#discussion_r441498151", "body": "`blockcacheThreshold` comparison is not the exactly the same as the one used in `OptimizedSlicedRowFilterGTSDecoderIterator`.", "bodyText": "blockcacheThreshold comparison is not the exactly the same as the one used in OptimizedSlicedRowFilterGTSDecoderIterator.", "bodyHTML": "<p dir=\"auto\"><code>blockcacheThreshold</code> comparison is not the exactly the same as the one used in <code>OptimizedSlicedRowFilterGTSDecoderIterator</code>.</p>", "author": "ftence", "createdAt": "2020-06-17T12:13:40Z", "path": "warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java", "diffHunk": "@@ -209,48 +210,75 @@ public GTSDecoderIterator fetch(final ReadToken token, final List<Metadata> meta\n     // applied in order and the results returned by calls to 'next'.\n \n     //\n-    // DON'T use SlicedRowFilterGTSDecoterIterator when using a value count based approach with a value of 'now'\n-    // which is not congruent to 0 modulo DEFAULT_MODULUS, because we may then have datapoints after 'now' and would then\n-    // need to do a full scan of every classId/labelsId in metadatas as the SlicedRowFilter does not interpret the read data\n-    // and is thus unable to read the timestamp\n-    // Don't use the filter when skip is > 0 or sample < 1.0D\n-    //\n-    // Only use SlicedRowFilter when not having a value count approach or when 'now' is congruent to 0 modulo DEFAULT_MODULUS\n-    // or equal to Long.MAX_VALUE (EPOCHEND)\n+    // We cannot use SlicedRowFilterGTSDecoderIterator when fetching a pre or post boundary.\n+    // We cannot use it also when requesting a given number of values WITH the use of\n+    // either step/timestep/skip/sample.\n     //\n-    \n+\n     boolean optimized = false;\n     \n     if (useHBaseFilter && metadatas.size() > this.hbaseFilterThreshold) {\n       if (count > 0 && Long.MIN_VALUE == then) {\n         // If we are fetching per count only (i.e. time range ends at Long.MIN_VALUE)\n-        optimized = true;\n-      } else if (-1 == count) {\n+        // use the filter unless step/timestep/skip/sample are defined\n+        if (step <= 1L && timestep <= 1L && 1.0D == sample && 0L == skip) {\n+          optimized = true;\n+        }\n+      } else if (-1L == count) {\n         // When not fetching by count but by time range, use the filter\n         optimized = true;\n       }\n     }\n \n-    // If sampling or skipping, don't use the filter\n-    if (0 != skip || 1.0D != sample) {\n-      optimized = false;\n-    }\n-    \n     // When fetching boundaries, the optimized scanners cannot be used\n     if (preBoundary > 0 || postBoundary > 0) {\n       optimized = false;\n     }\n     \n     if (metadatas.size() < ParallelGTSDecoderIteratorWrapper.getMinGTSPerScanner() || !ParallelGTSDecoderIteratorWrapper.useParallelScanners()) {\n       if (optimized) {\n-        //return new SlicedRowFilterGTSDecoderIterator(now, timespan, metadatas, this.conn, this.tableName, this.colfam, this.keystore, metadatas.size() <= blockcacheThreshold);\n-        long timespan = count > 0 ? -count : (now - then + 1);\n-        return new OptimizedSlicedRowFilterGTSDecoderIterator(now, timespan, metadatas, this.conn, this.tableName, this.colfam, writeTimestamp, this.keystore, metadatas.size() <= blockcacheThreshold);\n+        FetchRequest freq = new FetchRequest(req);\n+        freq.setToken(req.getToken());\n+        freq.setNow(now);\n+        freq.setThents(then);\n+        freq.setCount(count);\n+        freq.setSkip(skip);\n+        freq.setStep(step);\n+        freq.setTimestep(timestep);\n+        freq.setSample(sample);\n+        freq.setMetadatas(metadatas);\n+        freq.setPreBoundary(preBoundary);\n+        freq.setPostBoundary(postBoundary);\n+        return new OptimizedSlicedRowFilterGTSDecoderIterator(freq, this.conn, this.tableName, this.colfam, this.keystore, metadatas.size() <= blockcacheThreshold);\n       } else {\n-        return new MultiScanGTSDecoderIterator(token, now, then, count, skip, sample, metadatas, this.conn, this.tableName, colfam, writeTimestamp, this.keystore, metadatas.size() < blockcacheThreshold, preBoundary, postBoundary);      \n+        FetchRequest freq = new FetchRequest();\n+        freq.setToken(req.getToken());\n+        freq.setNow(now);\n+        freq.setThents(then);\n+        freq.setCount(count);\n+        freq.setSkip(skip);\n+        freq.setStep(step);\n+        freq.setTimestep(timestep);\n+        freq.setSample(sample);\n+        freq.setMetadatas(metadatas);\n+        freq.setPreBoundary(preBoundary);\n+        freq.setPostBoundary(postBoundary);\n+        return new MultiScanGTSDecoderIterator(freq, this.conn, this.tableName, colfam, this.keystore, metadatas.size() < blockcacheThreshold);      ", "originalCommit": "e07598603051ad7fa838f08bfec01a2aa247f958", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "879ad4092491eda3b08f942710d5bdc6b1e90c69", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java b/warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java\nindex 8957b5c5..78df4efe 100644\n--- a/warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java\n+++ b/warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java\n", "chunk": "@@ -235,50 +233,25 @@ public class HBaseStoreClient implements StoreClient {\n       optimized = false;\n     }\n     \n+    FetchRequest freq = new FetchRequest(req);\n+    freq.setCount(count);\n+    freq.setSkip(skip);\n+    freq.setStep(step);\n+    freq.setTimestep(timestep);\n+    freq.setSample(sample);\n+    freq.setPreBoundary(preBoundary);\n+    freq.setPostBoundary(postBoundary);\n+\n+    boolean useBlockCache = metadatas.size() <= blockcacheThreshold;\n+\n     if (metadatas.size() < ParallelGTSDecoderIteratorWrapper.getMinGTSPerScanner() || !ParallelGTSDecoderIteratorWrapper.useParallelScanners()) {\n       if (optimized) {\n-        FetchRequest freq = new FetchRequest(req);\n-        freq.setToken(req.getToken());\n-        freq.setNow(now);\n-        freq.setThents(then);\n-        freq.setCount(count);\n-        freq.setSkip(skip);\n-        freq.setStep(step);\n-        freq.setTimestep(timestep);\n-        freq.setSample(sample);\n-        freq.setMetadatas(metadatas);\n-        freq.setPreBoundary(preBoundary);\n-        freq.setPostBoundary(postBoundary);\n-        return new OptimizedSlicedRowFilterGTSDecoderIterator(freq, this.conn, this.tableName, this.colfam, this.keystore, metadatas.size() <= blockcacheThreshold);\n+        return new OptimizedSlicedRowFilterGTSDecoderIterator(freq, this.conn, this.tableName, this.colfam, this.keystore, useBlockCache);\n       } else {\n-        FetchRequest freq = new FetchRequest();\n-        freq.setToken(req.getToken());\n-        freq.setNow(now);\n-        freq.setThents(then);\n-        freq.setCount(count);\n-        freq.setSkip(skip);\n-        freq.setStep(step);\n-        freq.setTimestep(timestep);\n-        freq.setSample(sample);\n-        freq.setMetadatas(metadatas);\n-        freq.setPreBoundary(preBoundary);\n-        freq.setPostBoundary(postBoundary);\n-        return new MultiScanGTSDecoderIterator(freq, this.conn, this.tableName, colfam, this.keystore, metadatas.size() < blockcacheThreshold);      \n+        return new MultiScanGTSDecoderIterator(freq, this.conn, this.tableName, colfam, this.keystore, useBlockCache);      \n       }      \n     } else {\n-      FetchRequest freq = new FetchRequest();\n-      freq.setToken(req.getToken());\n-      freq.setNow(now);\n-      freq.setThents(then);\n-      freq.setCount(count);\n-      freq.setSkip(skip);\n-      freq.setStep(step);\n-      freq.setTimestep(timestep);\n-      freq.setSample(sample);\n-      freq.setMetadatas(metadatas);\n-      freq.setPreBoundary(preBoundary);\n-      freq.setPostBoundary(postBoundary);\n-      return new ParallelGTSDecoderIteratorWrapper(freq, optimized, keystore, this.conn, this.tableName, this.colfam, metadatas.size() < blockcacheThreshold);\n+      return new ParallelGTSDecoderIteratorWrapper(freq, optimized, keystore, this.conn, this.tableName, this.colfam, useBlockCache);\n     }\n   }\n \n", "next_change": null}]}, "revised_code_in_main": {"commit": "67019d40559484d9cf2daf23cf83d122822ff274", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java b/warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java\nindex 8957b5c5..78df4efe 100644\n--- a/warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java\n+++ b/warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java\n", "chunk": "@@ -235,50 +233,25 @@ public class HBaseStoreClient implements StoreClient {\n       optimized = false;\n     }\n     \n+    FetchRequest freq = new FetchRequest(req);\n+    freq.setCount(count);\n+    freq.setSkip(skip);\n+    freq.setStep(step);\n+    freq.setTimestep(timestep);\n+    freq.setSample(sample);\n+    freq.setPreBoundary(preBoundary);\n+    freq.setPostBoundary(postBoundary);\n+\n+    boolean useBlockCache = metadatas.size() <= blockcacheThreshold;\n+\n     if (metadatas.size() < ParallelGTSDecoderIteratorWrapper.getMinGTSPerScanner() || !ParallelGTSDecoderIteratorWrapper.useParallelScanners()) {\n       if (optimized) {\n-        FetchRequest freq = new FetchRequest(req);\n-        freq.setToken(req.getToken());\n-        freq.setNow(now);\n-        freq.setThents(then);\n-        freq.setCount(count);\n-        freq.setSkip(skip);\n-        freq.setStep(step);\n-        freq.setTimestep(timestep);\n-        freq.setSample(sample);\n-        freq.setMetadatas(metadatas);\n-        freq.setPreBoundary(preBoundary);\n-        freq.setPostBoundary(postBoundary);\n-        return new OptimizedSlicedRowFilterGTSDecoderIterator(freq, this.conn, this.tableName, this.colfam, this.keystore, metadatas.size() <= blockcacheThreshold);\n+        return new OptimizedSlicedRowFilterGTSDecoderIterator(freq, this.conn, this.tableName, this.colfam, this.keystore, useBlockCache);\n       } else {\n-        FetchRequest freq = new FetchRequest();\n-        freq.setToken(req.getToken());\n-        freq.setNow(now);\n-        freq.setThents(then);\n-        freq.setCount(count);\n-        freq.setSkip(skip);\n-        freq.setStep(step);\n-        freq.setTimestep(timestep);\n-        freq.setSample(sample);\n-        freq.setMetadatas(metadatas);\n-        freq.setPreBoundary(preBoundary);\n-        freq.setPostBoundary(postBoundary);\n-        return new MultiScanGTSDecoderIterator(freq, this.conn, this.tableName, colfam, this.keystore, metadatas.size() < blockcacheThreshold);      \n+        return new MultiScanGTSDecoderIterator(freq, this.conn, this.tableName, colfam, this.keystore, useBlockCache);      \n       }      \n     } else {\n-      FetchRequest freq = new FetchRequest();\n-      freq.setToken(req.getToken());\n-      freq.setNow(now);\n-      freq.setThents(then);\n-      freq.setCount(count);\n-      freq.setSkip(skip);\n-      freq.setStep(step);\n-      freq.setTimestep(timestep);\n-      freq.setSample(sample);\n-      freq.setMetadatas(metadatas);\n-      freq.setPreBoundary(preBoundary);\n-      freq.setPostBoundary(postBoundary);\n-      return new ParallelGTSDecoderIteratorWrapper(freq, optimized, keystore, this.conn, this.tableName, this.colfam, metadatas.size() < blockcacheThreshold);\n+      return new ParallelGTSDecoderIteratorWrapper(freq, optimized, keystore, this.conn, this.tableName, this.colfam, useBlockCache);\n     }\n   }\n \n", "next_change": null}]}, "commits_in_main": [{"oid": "67019d40559484d9cf2daf23cf83d122822ff274", "message": "Merge commit", "committedDate": null}, {"oid": "e6738cc7a0795d42b7ec3de8769a8878ccc9aa64", "committedDate": "2020-07-29 22:48:12 +0200", "message": "Modified code so list of Metadatas is not deep copied when cloning FetchRequest"}, {"oid": "68d900dca0810a7dd53b694b74bf01ef55618574", "committedDate": "2020-10-19 16:58:35 +0200", "message": "Added flag to control parallel scanners in order to preserve GTS order."}, {"oid": "8108f6bdb84db8e1fb1e7eb5e42f32228cab2d27", "committedDate": "2021-02-23 20:01:01 +0100", "message": "Fix javadoc warnings"}, {"oid": "e826ea374df18f9d0ff413872ebf5ddd1ad0bd17", "committedDate": "2021-07-12 15:23:43 +0200", "message": "Remove unused variables and fields"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTQ5ODIwNw==", "url": "https://github.com/senx/warp10-platform/pull/772#discussion_r441498207", "body": "`blockcacheThreshold` comparison is not the exactly the same as the one used in `OptimizedSlicedRowFilterGTSDecoderIterator`.", "bodyText": "blockcacheThreshold comparison is not the exactly the same as the one used in OptimizedSlicedRowFilterGTSDecoderIterator.", "bodyHTML": "<p dir=\"auto\"><code>blockcacheThreshold</code> comparison is not the exactly the same as the one used in <code>OptimizedSlicedRowFilterGTSDecoderIterator</code>.</p>", "author": "ftence", "createdAt": "2020-06-17T12:13:46Z", "path": "warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java", "diffHunk": "@@ -209,48 +210,75 @@ public GTSDecoderIterator fetch(final ReadToken token, final List<Metadata> meta\n     // applied in order and the results returned by calls to 'next'.\n \n     //\n-    // DON'T use SlicedRowFilterGTSDecoterIterator when using a value count based approach with a value of 'now'\n-    // which is not congruent to 0 modulo DEFAULT_MODULUS, because we may then have datapoints after 'now' and would then\n-    // need to do a full scan of every classId/labelsId in metadatas as the SlicedRowFilter does not interpret the read data\n-    // and is thus unable to read the timestamp\n-    // Don't use the filter when skip is > 0 or sample < 1.0D\n-    //\n-    // Only use SlicedRowFilter when not having a value count approach or when 'now' is congruent to 0 modulo DEFAULT_MODULUS\n-    // or equal to Long.MAX_VALUE (EPOCHEND)\n+    // We cannot use SlicedRowFilterGTSDecoderIterator when fetching a pre or post boundary.\n+    // We cannot use it also when requesting a given number of values WITH the use of\n+    // either step/timestep/skip/sample.\n     //\n-    \n+\n     boolean optimized = false;\n     \n     if (useHBaseFilter && metadatas.size() > this.hbaseFilterThreshold) {\n       if (count > 0 && Long.MIN_VALUE == then) {\n         // If we are fetching per count only (i.e. time range ends at Long.MIN_VALUE)\n-        optimized = true;\n-      } else if (-1 == count) {\n+        // use the filter unless step/timestep/skip/sample are defined\n+        if (step <= 1L && timestep <= 1L && 1.0D == sample && 0L == skip) {\n+          optimized = true;\n+        }\n+      } else if (-1L == count) {\n         // When not fetching by count but by time range, use the filter\n         optimized = true;\n       }\n     }\n \n-    // If sampling or skipping, don't use the filter\n-    if (0 != skip || 1.0D != sample) {\n-      optimized = false;\n-    }\n-    \n     // When fetching boundaries, the optimized scanners cannot be used\n     if (preBoundary > 0 || postBoundary > 0) {\n       optimized = false;\n     }\n     \n     if (metadatas.size() < ParallelGTSDecoderIteratorWrapper.getMinGTSPerScanner() || !ParallelGTSDecoderIteratorWrapper.useParallelScanners()) {\n       if (optimized) {\n-        //return new SlicedRowFilterGTSDecoderIterator(now, timespan, metadatas, this.conn, this.tableName, this.colfam, this.keystore, metadatas.size() <= blockcacheThreshold);\n-        long timespan = count > 0 ? -count : (now - then + 1);\n-        return new OptimizedSlicedRowFilterGTSDecoderIterator(now, timespan, metadatas, this.conn, this.tableName, this.colfam, writeTimestamp, this.keystore, metadatas.size() <= blockcacheThreshold);\n+        FetchRequest freq = new FetchRequest(req);\n+        freq.setToken(req.getToken());\n+        freq.setNow(now);\n+        freq.setThents(then);\n+        freq.setCount(count);\n+        freq.setSkip(skip);\n+        freq.setStep(step);\n+        freq.setTimestep(timestep);\n+        freq.setSample(sample);\n+        freq.setMetadatas(metadatas);\n+        freq.setPreBoundary(preBoundary);\n+        freq.setPostBoundary(postBoundary);\n+        return new OptimizedSlicedRowFilterGTSDecoderIterator(freq, this.conn, this.tableName, this.colfam, this.keystore, metadatas.size() <= blockcacheThreshold);\n       } else {\n-        return new MultiScanGTSDecoderIterator(token, now, then, count, skip, sample, metadatas, this.conn, this.tableName, colfam, writeTimestamp, this.keystore, metadatas.size() < blockcacheThreshold, preBoundary, postBoundary);      \n+        FetchRequest freq = new FetchRequest();\n+        freq.setToken(req.getToken());\n+        freq.setNow(now);\n+        freq.setThents(then);\n+        freq.setCount(count);\n+        freq.setSkip(skip);\n+        freq.setStep(step);\n+        freq.setTimestep(timestep);\n+        freq.setSample(sample);\n+        freq.setMetadatas(metadatas);\n+        freq.setPreBoundary(preBoundary);\n+        freq.setPostBoundary(postBoundary);\n+        return new MultiScanGTSDecoderIterator(freq, this.conn, this.tableName, colfam, this.keystore, metadatas.size() < blockcacheThreshold);      \n       }      \n     } else {\n-      return new ParallelGTSDecoderIteratorWrapper(optimized, token, now, then, count, skip, sample, metadatas, keystore, this.conn, this.tableName, this.colfam, writeTimestamp, metadatas.size() < blockcacheThreshold, preBoundary, postBoundary);\n+      FetchRequest freq = new FetchRequest();\n+      freq.setToken(req.getToken());\n+      freq.setNow(now);\n+      freq.setThents(then);\n+      freq.setCount(count);\n+      freq.setSkip(skip);\n+      freq.setStep(step);\n+      freq.setTimestep(timestep);\n+      freq.setSample(sample);\n+      freq.setMetadatas(metadatas);\n+      freq.setPreBoundary(preBoundary);\n+      freq.setPostBoundary(postBoundary);\n+      return new ParallelGTSDecoderIteratorWrapper(freq, optimized, keystore, this.conn, this.tableName, this.colfam, metadatas.size() < blockcacheThreshold);", "originalCommit": "e07598603051ad7fa838f08bfec01a2aa247f958", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "879ad4092491eda3b08f942710d5bdc6b1e90c69", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java b/warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java\nindex 8957b5c5..78df4efe 100644\n--- a/warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java\n+++ b/warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java\n", "chunk": "@@ -235,50 +233,25 @@ public class HBaseStoreClient implements StoreClient {\n       optimized = false;\n     }\n     \n+    FetchRequest freq = new FetchRequest(req);\n+    freq.setCount(count);\n+    freq.setSkip(skip);\n+    freq.setStep(step);\n+    freq.setTimestep(timestep);\n+    freq.setSample(sample);\n+    freq.setPreBoundary(preBoundary);\n+    freq.setPostBoundary(postBoundary);\n+\n+    boolean useBlockCache = metadatas.size() <= blockcacheThreshold;\n+\n     if (metadatas.size() < ParallelGTSDecoderIteratorWrapper.getMinGTSPerScanner() || !ParallelGTSDecoderIteratorWrapper.useParallelScanners()) {\n       if (optimized) {\n-        FetchRequest freq = new FetchRequest(req);\n-        freq.setToken(req.getToken());\n-        freq.setNow(now);\n-        freq.setThents(then);\n-        freq.setCount(count);\n-        freq.setSkip(skip);\n-        freq.setStep(step);\n-        freq.setTimestep(timestep);\n-        freq.setSample(sample);\n-        freq.setMetadatas(metadatas);\n-        freq.setPreBoundary(preBoundary);\n-        freq.setPostBoundary(postBoundary);\n-        return new OptimizedSlicedRowFilterGTSDecoderIterator(freq, this.conn, this.tableName, this.colfam, this.keystore, metadatas.size() <= blockcacheThreshold);\n+        return new OptimizedSlicedRowFilterGTSDecoderIterator(freq, this.conn, this.tableName, this.colfam, this.keystore, useBlockCache);\n       } else {\n-        FetchRequest freq = new FetchRequest();\n-        freq.setToken(req.getToken());\n-        freq.setNow(now);\n-        freq.setThents(then);\n-        freq.setCount(count);\n-        freq.setSkip(skip);\n-        freq.setStep(step);\n-        freq.setTimestep(timestep);\n-        freq.setSample(sample);\n-        freq.setMetadatas(metadatas);\n-        freq.setPreBoundary(preBoundary);\n-        freq.setPostBoundary(postBoundary);\n-        return new MultiScanGTSDecoderIterator(freq, this.conn, this.tableName, colfam, this.keystore, metadatas.size() < blockcacheThreshold);      \n+        return new MultiScanGTSDecoderIterator(freq, this.conn, this.tableName, colfam, this.keystore, useBlockCache);      \n       }      \n     } else {\n-      FetchRequest freq = new FetchRequest();\n-      freq.setToken(req.getToken());\n-      freq.setNow(now);\n-      freq.setThents(then);\n-      freq.setCount(count);\n-      freq.setSkip(skip);\n-      freq.setStep(step);\n-      freq.setTimestep(timestep);\n-      freq.setSample(sample);\n-      freq.setMetadatas(metadatas);\n-      freq.setPreBoundary(preBoundary);\n-      freq.setPostBoundary(postBoundary);\n-      return new ParallelGTSDecoderIteratorWrapper(freq, optimized, keystore, this.conn, this.tableName, this.colfam, metadatas.size() < blockcacheThreshold);\n+      return new ParallelGTSDecoderIteratorWrapper(freq, optimized, keystore, this.conn, this.tableName, this.colfam, useBlockCache);\n     }\n   }\n \n", "next_change": null}]}, "revised_code_in_main": {"commit": "67019d40559484d9cf2daf23cf83d122822ff274", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java b/warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java\nindex 8957b5c5..78df4efe 100644\n--- a/warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java\n+++ b/warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java\n", "chunk": "@@ -235,50 +233,25 @@ public class HBaseStoreClient implements StoreClient {\n       optimized = false;\n     }\n     \n+    FetchRequest freq = new FetchRequest(req);\n+    freq.setCount(count);\n+    freq.setSkip(skip);\n+    freq.setStep(step);\n+    freq.setTimestep(timestep);\n+    freq.setSample(sample);\n+    freq.setPreBoundary(preBoundary);\n+    freq.setPostBoundary(postBoundary);\n+\n+    boolean useBlockCache = metadatas.size() <= blockcacheThreshold;\n+\n     if (metadatas.size() < ParallelGTSDecoderIteratorWrapper.getMinGTSPerScanner() || !ParallelGTSDecoderIteratorWrapper.useParallelScanners()) {\n       if (optimized) {\n-        FetchRequest freq = new FetchRequest(req);\n-        freq.setToken(req.getToken());\n-        freq.setNow(now);\n-        freq.setThents(then);\n-        freq.setCount(count);\n-        freq.setSkip(skip);\n-        freq.setStep(step);\n-        freq.setTimestep(timestep);\n-        freq.setSample(sample);\n-        freq.setMetadatas(metadatas);\n-        freq.setPreBoundary(preBoundary);\n-        freq.setPostBoundary(postBoundary);\n-        return new OptimizedSlicedRowFilterGTSDecoderIterator(freq, this.conn, this.tableName, this.colfam, this.keystore, metadatas.size() <= blockcacheThreshold);\n+        return new OptimizedSlicedRowFilterGTSDecoderIterator(freq, this.conn, this.tableName, this.colfam, this.keystore, useBlockCache);\n       } else {\n-        FetchRequest freq = new FetchRequest();\n-        freq.setToken(req.getToken());\n-        freq.setNow(now);\n-        freq.setThents(then);\n-        freq.setCount(count);\n-        freq.setSkip(skip);\n-        freq.setStep(step);\n-        freq.setTimestep(timestep);\n-        freq.setSample(sample);\n-        freq.setMetadatas(metadatas);\n-        freq.setPreBoundary(preBoundary);\n-        freq.setPostBoundary(postBoundary);\n-        return new MultiScanGTSDecoderIterator(freq, this.conn, this.tableName, colfam, this.keystore, metadatas.size() < blockcacheThreshold);      \n+        return new MultiScanGTSDecoderIterator(freq, this.conn, this.tableName, colfam, this.keystore, useBlockCache);      \n       }      \n     } else {\n-      FetchRequest freq = new FetchRequest();\n-      freq.setToken(req.getToken());\n-      freq.setNow(now);\n-      freq.setThents(then);\n-      freq.setCount(count);\n-      freq.setSkip(skip);\n-      freq.setStep(step);\n-      freq.setTimestep(timestep);\n-      freq.setSample(sample);\n-      freq.setMetadatas(metadatas);\n-      freq.setPreBoundary(preBoundary);\n-      freq.setPostBoundary(postBoundary);\n-      return new ParallelGTSDecoderIteratorWrapper(freq, optimized, keystore, this.conn, this.tableName, this.colfam, metadatas.size() < blockcacheThreshold);\n+      return new ParallelGTSDecoderIteratorWrapper(freq, optimized, keystore, this.conn, this.tableName, this.colfam, useBlockCache);\n     }\n   }\n \n", "next_change": null}]}, "commits_in_main": [{"oid": "67019d40559484d9cf2daf23cf83d122822ff274", "message": "Merge commit", "committedDate": null}, {"oid": "e6738cc7a0795d42b7ec3de8769a8878ccc9aa64", "committedDate": "2020-07-29 22:48:12 +0200", "message": "Modified code so list of Metadatas is not deep copied when cloning FetchRequest"}, {"oid": "68d900dca0810a7dd53b694b74bf01ef55618574", "committedDate": "2020-10-19 16:58:35 +0200", "message": "Added flag to control parallel scanners in order to preserve GTS order."}, {"oid": "8108f6bdb84db8e1fb1e7eb5e42f32228cab2d27", "committedDate": "2021-02-23 20:01:01 +0100", "message": "Fix javadoc warnings"}, {"oid": "e826ea374df18f9d0ff413872ebf5ddd1ad0bd17", "committedDate": "2021-07-12 15:23:43 +0200", "message": "Remove unused variables and fields"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTQ5ODU0Nw==", "url": "https://github.com/senx/warp10-platform/pull/772#discussion_r441498547", "body": "Factorize or use copy constructor because `writeTimestamp` is not copied.", "bodyText": "Factorize or use copy constructor because writeTimestamp is not copied.", "bodyHTML": "<p dir=\"auto\">Factorize or use copy constructor because <code>writeTimestamp</code> is not copied.</p>", "author": "ftence", "createdAt": "2020-06-17T12:14:28Z", "path": "warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java", "diffHunk": "@@ -209,48 +210,75 @@ public GTSDecoderIterator fetch(final ReadToken token, final List<Metadata> meta\n     // applied in order and the results returned by calls to 'next'.\n \n     //\n-    // DON'T use SlicedRowFilterGTSDecoterIterator when using a value count based approach with a value of 'now'\n-    // which is not congruent to 0 modulo DEFAULT_MODULUS, because we may then have datapoints after 'now' and would then\n-    // need to do a full scan of every classId/labelsId in metadatas as the SlicedRowFilter does not interpret the read data\n-    // and is thus unable to read the timestamp\n-    // Don't use the filter when skip is > 0 or sample < 1.0D\n-    //\n-    // Only use SlicedRowFilter when not having a value count approach or when 'now' is congruent to 0 modulo DEFAULT_MODULUS\n-    // or equal to Long.MAX_VALUE (EPOCHEND)\n+    // We cannot use SlicedRowFilterGTSDecoderIterator when fetching a pre or post boundary.\n+    // We cannot use it also when requesting a given number of values WITH the use of\n+    // either step/timestep/skip/sample.\n     //\n-    \n+\n     boolean optimized = false;\n     \n     if (useHBaseFilter && metadatas.size() > this.hbaseFilterThreshold) {\n       if (count > 0 && Long.MIN_VALUE == then) {\n         // If we are fetching per count only (i.e. time range ends at Long.MIN_VALUE)\n-        optimized = true;\n-      } else if (-1 == count) {\n+        // use the filter unless step/timestep/skip/sample are defined\n+        if (step <= 1L && timestep <= 1L && 1.0D == sample && 0L == skip) {\n+          optimized = true;\n+        }\n+      } else if (-1L == count) {\n         // When not fetching by count but by time range, use the filter\n         optimized = true;\n       }\n     }\n \n-    // If sampling or skipping, don't use the filter\n-    if (0 != skip || 1.0D != sample) {\n-      optimized = false;\n-    }\n-    \n     // When fetching boundaries, the optimized scanners cannot be used\n     if (preBoundary > 0 || postBoundary > 0) {\n       optimized = false;\n     }\n     \n     if (metadatas.size() < ParallelGTSDecoderIteratorWrapper.getMinGTSPerScanner() || !ParallelGTSDecoderIteratorWrapper.useParallelScanners()) {\n       if (optimized) {\n-        //return new SlicedRowFilterGTSDecoderIterator(now, timespan, metadatas, this.conn, this.tableName, this.colfam, this.keystore, metadatas.size() <= blockcacheThreshold);\n-        long timespan = count > 0 ? -count : (now - then + 1);\n-        return new OptimizedSlicedRowFilterGTSDecoderIterator(now, timespan, metadatas, this.conn, this.tableName, this.colfam, writeTimestamp, this.keystore, metadatas.size() <= blockcacheThreshold);\n+        FetchRequest freq = new FetchRequest(req);\n+        freq.setToken(req.getToken());\n+        freq.setNow(now);\n+        freq.setThents(then);\n+        freq.setCount(count);\n+        freq.setSkip(skip);\n+        freq.setStep(step);\n+        freq.setTimestep(timestep);\n+        freq.setSample(sample);\n+        freq.setMetadatas(metadatas);\n+        freq.setPreBoundary(preBoundary);\n+        freq.setPostBoundary(postBoundary);\n+        return new OptimizedSlicedRowFilterGTSDecoderIterator(freq, this.conn, this.tableName, this.colfam, this.keystore, metadatas.size() <= blockcacheThreshold);\n       } else {\n-        return new MultiScanGTSDecoderIterator(token, now, then, count, skip, sample, metadatas, this.conn, this.tableName, colfam, writeTimestamp, this.keystore, metadatas.size() < blockcacheThreshold, preBoundary, postBoundary);      \n+        FetchRequest freq = new FetchRequest();", "originalCommit": "e07598603051ad7fa838f08bfec01a2aa247f958", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "879ad4092491eda3b08f942710d5bdc6b1e90c69", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java b/warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java\nindex 8957b5c5..78df4efe 100644\n--- a/warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java\n+++ b/warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java\n", "chunk": "@@ -235,50 +233,25 @@ public class HBaseStoreClient implements StoreClient {\n       optimized = false;\n     }\n     \n+    FetchRequest freq = new FetchRequest(req);\n+    freq.setCount(count);\n+    freq.setSkip(skip);\n+    freq.setStep(step);\n+    freq.setTimestep(timestep);\n+    freq.setSample(sample);\n+    freq.setPreBoundary(preBoundary);\n+    freq.setPostBoundary(postBoundary);\n+\n+    boolean useBlockCache = metadatas.size() <= blockcacheThreshold;\n+\n     if (metadatas.size() < ParallelGTSDecoderIteratorWrapper.getMinGTSPerScanner() || !ParallelGTSDecoderIteratorWrapper.useParallelScanners()) {\n       if (optimized) {\n-        FetchRequest freq = new FetchRequest(req);\n-        freq.setToken(req.getToken());\n-        freq.setNow(now);\n-        freq.setThents(then);\n-        freq.setCount(count);\n-        freq.setSkip(skip);\n-        freq.setStep(step);\n-        freq.setTimestep(timestep);\n-        freq.setSample(sample);\n-        freq.setMetadatas(metadatas);\n-        freq.setPreBoundary(preBoundary);\n-        freq.setPostBoundary(postBoundary);\n-        return new OptimizedSlicedRowFilterGTSDecoderIterator(freq, this.conn, this.tableName, this.colfam, this.keystore, metadatas.size() <= blockcacheThreshold);\n+        return new OptimizedSlicedRowFilterGTSDecoderIterator(freq, this.conn, this.tableName, this.colfam, this.keystore, useBlockCache);\n       } else {\n-        FetchRequest freq = new FetchRequest();\n-        freq.setToken(req.getToken());\n-        freq.setNow(now);\n-        freq.setThents(then);\n-        freq.setCount(count);\n-        freq.setSkip(skip);\n-        freq.setStep(step);\n-        freq.setTimestep(timestep);\n-        freq.setSample(sample);\n-        freq.setMetadatas(metadatas);\n-        freq.setPreBoundary(preBoundary);\n-        freq.setPostBoundary(postBoundary);\n-        return new MultiScanGTSDecoderIterator(freq, this.conn, this.tableName, colfam, this.keystore, metadatas.size() < blockcacheThreshold);      \n+        return new MultiScanGTSDecoderIterator(freq, this.conn, this.tableName, colfam, this.keystore, useBlockCache);      \n       }      \n     } else {\n-      FetchRequest freq = new FetchRequest();\n-      freq.setToken(req.getToken());\n-      freq.setNow(now);\n-      freq.setThents(then);\n-      freq.setCount(count);\n-      freq.setSkip(skip);\n-      freq.setStep(step);\n-      freq.setTimestep(timestep);\n-      freq.setSample(sample);\n-      freq.setMetadatas(metadatas);\n-      freq.setPreBoundary(preBoundary);\n-      freq.setPostBoundary(postBoundary);\n-      return new ParallelGTSDecoderIteratorWrapper(freq, optimized, keystore, this.conn, this.tableName, this.colfam, metadatas.size() < blockcacheThreshold);\n+      return new ParallelGTSDecoderIteratorWrapper(freq, optimized, keystore, this.conn, this.tableName, this.colfam, useBlockCache);\n     }\n   }\n \n", "next_change": null}]}, "revised_code_in_main": {"commit": "67019d40559484d9cf2daf23cf83d122822ff274", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java b/warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java\nindex 8957b5c5..78df4efe 100644\n--- a/warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java\n+++ b/warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java\n", "chunk": "@@ -235,50 +233,25 @@ public class HBaseStoreClient implements StoreClient {\n       optimized = false;\n     }\n     \n+    FetchRequest freq = new FetchRequest(req);\n+    freq.setCount(count);\n+    freq.setSkip(skip);\n+    freq.setStep(step);\n+    freq.setTimestep(timestep);\n+    freq.setSample(sample);\n+    freq.setPreBoundary(preBoundary);\n+    freq.setPostBoundary(postBoundary);\n+\n+    boolean useBlockCache = metadatas.size() <= blockcacheThreshold;\n+\n     if (metadatas.size() < ParallelGTSDecoderIteratorWrapper.getMinGTSPerScanner() || !ParallelGTSDecoderIteratorWrapper.useParallelScanners()) {\n       if (optimized) {\n-        FetchRequest freq = new FetchRequest(req);\n-        freq.setToken(req.getToken());\n-        freq.setNow(now);\n-        freq.setThents(then);\n-        freq.setCount(count);\n-        freq.setSkip(skip);\n-        freq.setStep(step);\n-        freq.setTimestep(timestep);\n-        freq.setSample(sample);\n-        freq.setMetadatas(metadatas);\n-        freq.setPreBoundary(preBoundary);\n-        freq.setPostBoundary(postBoundary);\n-        return new OptimizedSlicedRowFilterGTSDecoderIterator(freq, this.conn, this.tableName, this.colfam, this.keystore, metadatas.size() <= blockcacheThreshold);\n+        return new OptimizedSlicedRowFilterGTSDecoderIterator(freq, this.conn, this.tableName, this.colfam, this.keystore, useBlockCache);\n       } else {\n-        FetchRequest freq = new FetchRequest();\n-        freq.setToken(req.getToken());\n-        freq.setNow(now);\n-        freq.setThents(then);\n-        freq.setCount(count);\n-        freq.setSkip(skip);\n-        freq.setStep(step);\n-        freq.setTimestep(timestep);\n-        freq.setSample(sample);\n-        freq.setMetadatas(metadatas);\n-        freq.setPreBoundary(preBoundary);\n-        freq.setPostBoundary(postBoundary);\n-        return new MultiScanGTSDecoderIterator(freq, this.conn, this.tableName, colfam, this.keystore, metadatas.size() < blockcacheThreshold);      \n+        return new MultiScanGTSDecoderIterator(freq, this.conn, this.tableName, colfam, this.keystore, useBlockCache);      \n       }      \n     } else {\n-      FetchRequest freq = new FetchRequest();\n-      freq.setToken(req.getToken());\n-      freq.setNow(now);\n-      freq.setThents(then);\n-      freq.setCount(count);\n-      freq.setSkip(skip);\n-      freq.setStep(step);\n-      freq.setTimestep(timestep);\n-      freq.setSample(sample);\n-      freq.setMetadatas(metadatas);\n-      freq.setPreBoundary(preBoundary);\n-      freq.setPostBoundary(postBoundary);\n-      return new ParallelGTSDecoderIteratorWrapper(freq, optimized, keystore, this.conn, this.tableName, this.colfam, metadatas.size() < blockcacheThreshold);\n+      return new ParallelGTSDecoderIteratorWrapper(freq, optimized, keystore, this.conn, this.tableName, this.colfam, useBlockCache);\n     }\n   }\n \n", "next_change": null}]}, "commits_in_main": [{"oid": "67019d40559484d9cf2daf23cf83d122822ff274", "message": "Merge commit", "committedDate": null}, {"oid": "e6738cc7a0795d42b7ec3de8769a8878ccc9aa64", "committedDate": "2020-07-29 22:48:12 +0200", "message": "Modified code so list of Metadatas is not deep copied when cloning FetchRequest"}, {"oid": "68d900dca0810a7dd53b694b74bf01ef55618574", "committedDate": "2020-10-19 16:58:35 +0200", "message": "Added flag to control parallel scanners in order to preserve GTS order."}, {"oid": "8108f6bdb84db8e1fb1e7eb5e42f32228cab2d27", "committedDate": "2021-02-23 20:01:01 +0100", "message": "Fix javadoc warnings"}, {"oid": "e826ea374df18f9d0ff413872ebf5ddd1ad0bd17", "committedDate": "2021-07-12 15:23:43 +0200", "message": "Remove unused variables and fields"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTQ5ODYwMg==", "url": "https://github.com/senx/warp10-platform/pull/772#discussion_r441498602", "body": "Factorize or use copy constructor because `writeTimestamp` is not copied.", "bodyText": "Factorize or use copy constructor because writeTimestamp is not copied.", "bodyHTML": "<p dir=\"auto\">Factorize or use copy constructor because <code>writeTimestamp</code> is not copied.</p>", "author": "ftence", "createdAt": "2020-06-17T12:14:33Z", "path": "warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java", "diffHunk": "@@ -209,48 +210,75 @@ public GTSDecoderIterator fetch(final ReadToken token, final List<Metadata> meta\n     // applied in order and the results returned by calls to 'next'.\n \n     //\n-    // DON'T use SlicedRowFilterGTSDecoterIterator when using a value count based approach with a value of 'now'\n-    // which is not congruent to 0 modulo DEFAULT_MODULUS, because we may then have datapoints after 'now' and would then\n-    // need to do a full scan of every classId/labelsId in metadatas as the SlicedRowFilter does not interpret the read data\n-    // and is thus unable to read the timestamp\n-    // Don't use the filter when skip is > 0 or sample < 1.0D\n-    //\n-    // Only use SlicedRowFilter when not having a value count approach or when 'now' is congruent to 0 modulo DEFAULT_MODULUS\n-    // or equal to Long.MAX_VALUE (EPOCHEND)\n+    // We cannot use SlicedRowFilterGTSDecoderIterator when fetching a pre or post boundary.\n+    // We cannot use it also when requesting a given number of values WITH the use of\n+    // either step/timestep/skip/sample.\n     //\n-    \n+\n     boolean optimized = false;\n     \n     if (useHBaseFilter && metadatas.size() > this.hbaseFilterThreshold) {\n       if (count > 0 && Long.MIN_VALUE == then) {\n         // If we are fetching per count only (i.e. time range ends at Long.MIN_VALUE)\n-        optimized = true;\n-      } else if (-1 == count) {\n+        // use the filter unless step/timestep/skip/sample are defined\n+        if (step <= 1L && timestep <= 1L && 1.0D == sample && 0L == skip) {\n+          optimized = true;\n+        }\n+      } else if (-1L == count) {\n         // When not fetching by count but by time range, use the filter\n         optimized = true;\n       }\n     }\n \n-    // If sampling or skipping, don't use the filter\n-    if (0 != skip || 1.0D != sample) {\n-      optimized = false;\n-    }\n-    \n     // When fetching boundaries, the optimized scanners cannot be used\n     if (preBoundary > 0 || postBoundary > 0) {\n       optimized = false;\n     }\n     \n     if (metadatas.size() < ParallelGTSDecoderIteratorWrapper.getMinGTSPerScanner() || !ParallelGTSDecoderIteratorWrapper.useParallelScanners()) {\n       if (optimized) {\n-        //return new SlicedRowFilterGTSDecoderIterator(now, timespan, metadatas, this.conn, this.tableName, this.colfam, this.keystore, metadatas.size() <= blockcacheThreshold);\n-        long timespan = count > 0 ? -count : (now - then + 1);\n-        return new OptimizedSlicedRowFilterGTSDecoderIterator(now, timespan, metadatas, this.conn, this.tableName, this.colfam, writeTimestamp, this.keystore, metadatas.size() <= blockcacheThreshold);\n+        FetchRequest freq = new FetchRequest(req);\n+        freq.setToken(req.getToken());\n+        freq.setNow(now);\n+        freq.setThents(then);\n+        freq.setCount(count);\n+        freq.setSkip(skip);\n+        freq.setStep(step);\n+        freq.setTimestep(timestep);\n+        freq.setSample(sample);\n+        freq.setMetadatas(metadatas);\n+        freq.setPreBoundary(preBoundary);\n+        freq.setPostBoundary(postBoundary);\n+        return new OptimizedSlicedRowFilterGTSDecoderIterator(freq, this.conn, this.tableName, this.colfam, this.keystore, metadatas.size() <= blockcacheThreshold);\n       } else {\n-        return new MultiScanGTSDecoderIterator(token, now, then, count, skip, sample, metadatas, this.conn, this.tableName, colfam, writeTimestamp, this.keystore, metadatas.size() < blockcacheThreshold, preBoundary, postBoundary);      \n+        FetchRequest freq = new FetchRequest();\n+        freq.setToken(req.getToken());\n+        freq.setNow(now);\n+        freq.setThents(then);\n+        freq.setCount(count);\n+        freq.setSkip(skip);\n+        freq.setStep(step);\n+        freq.setTimestep(timestep);\n+        freq.setSample(sample);\n+        freq.setMetadatas(metadatas);\n+        freq.setPreBoundary(preBoundary);\n+        freq.setPostBoundary(postBoundary);\n+        return new MultiScanGTSDecoderIterator(freq, this.conn, this.tableName, colfam, this.keystore, metadatas.size() < blockcacheThreshold);      \n       }      \n     } else {\n-      return new ParallelGTSDecoderIteratorWrapper(optimized, token, now, then, count, skip, sample, metadatas, keystore, this.conn, this.tableName, this.colfam, writeTimestamp, metadatas.size() < blockcacheThreshold, preBoundary, postBoundary);\n+      FetchRequest freq = new FetchRequest();", "originalCommit": "e07598603051ad7fa838f08bfec01a2aa247f958", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "879ad4092491eda3b08f942710d5bdc6b1e90c69", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java b/warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java\nindex 8957b5c5..78df4efe 100644\n--- a/warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java\n+++ b/warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java\n", "chunk": "@@ -235,50 +233,25 @@ public class HBaseStoreClient implements StoreClient {\n       optimized = false;\n     }\n     \n+    FetchRequest freq = new FetchRequest(req);\n+    freq.setCount(count);\n+    freq.setSkip(skip);\n+    freq.setStep(step);\n+    freq.setTimestep(timestep);\n+    freq.setSample(sample);\n+    freq.setPreBoundary(preBoundary);\n+    freq.setPostBoundary(postBoundary);\n+\n+    boolean useBlockCache = metadatas.size() <= blockcacheThreshold;\n+\n     if (metadatas.size() < ParallelGTSDecoderIteratorWrapper.getMinGTSPerScanner() || !ParallelGTSDecoderIteratorWrapper.useParallelScanners()) {\n       if (optimized) {\n-        FetchRequest freq = new FetchRequest(req);\n-        freq.setToken(req.getToken());\n-        freq.setNow(now);\n-        freq.setThents(then);\n-        freq.setCount(count);\n-        freq.setSkip(skip);\n-        freq.setStep(step);\n-        freq.setTimestep(timestep);\n-        freq.setSample(sample);\n-        freq.setMetadatas(metadatas);\n-        freq.setPreBoundary(preBoundary);\n-        freq.setPostBoundary(postBoundary);\n-        return new OptimizedSlicedRowFilterGTSDecoderIterator(freq, this.conn, this.tableName, this.colfam, this.keystore, metadatas.size() <= blockcacheThreshold);\n+        return new OptimizedSlicedRowFilterGTSDecoderIterator(freq, this.conn, this.tableName, this.colfam, this.keystore, useBlockCache);\n       } else {\n-        FetchRequest freq = new FetchRequest();\n-        freq.setToken(req.getToken());\n-        freq.setNow(now);\n-        freq.setThents(then);\n-        freq.setCount(count);\n-        freq.setSkip(skip);\n-        freq.setStep(step);\n-        freq.setTimestep(timestep);\n-        freq.setSample(sample);\n-        freq.setMetadatas(metadatas);\n-        freq.setPreBoundary(preBoundary);\n-        freq.setPostBoundary(postBoundary);\n-        return new MultiScanGTSDecoderIterator(freq, this.conn, this.tableName, colfam, this.keystore, metadatas.size() < blockcacheThreshold);      \n+        return new MultiScanGTSDecoderIterator(freq, this.conn, this.tableName, colfam, this.keystore, useBlockCache);      \n       }      \n     } else {\n-      FetchRequest freq = new FetchRequest();\n-      freq.setToken(req.getToken());\n-      freq.setNow(now);\n-      freq.setThents(then);\n-      freq.setCount(count);\n-      freq.setSkip(skip);\n-      freq.setStep(step);\n-      freq.setTimestep(timestep);\n-      freq.setSample(sample);\n-      freq.setMetadatas(metadatas);\n-      freq.setPreBoundary(preBoundary);\n-      freq.setPostBoundary(postBoundary);\n-      return new ParallelGTSDecoderIteratorWrapper(freq, optimized, keystore, this.conn, this.tableName, this.colfam, metadatas.size() < blockcacheThreshold);\n+      return new ParallelGTSDecoderIteratorWrapper(freq, optimized, keystore, this.conn, this.tableName, this.colfam, useBlockCache);\n     }\n   }\n \n", "next_change": null}]}, "revised_code_in_main": {"commit": "67019d40559484d9cf2daf23cf83d122822ff274", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java b/warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java\nindex 8957b5c5..78df4efe 100644\n--- a/warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java\n+++ b/warp10/src/main/java/io/warp10/continuum/egress/HBaseStoreClient.java\n", "chunk": "@@ -235,50 +233,25 @@ public class HBaseStoreClient implements StoreClient {\n       optimized = false;\n     }\n     \n+    FetchRequest freq = new FetchRequest(req);\n+    freq.setCount(count);\n+    freq.setSkip(skip);\n+    freq.setStep(step);\n+    freq.setTimestep(timestep);\n+    freq.setSample(sample);\n+    freq.setPreBoundary(preBoundary);\n+    freq.setPostBoundary(postBoundary);\n+\n+    boolean useBlockCache = metadatas.size() <= blockcacheThreshold;\n+\n     if (metadatas.size() < ParallelGTSDecoderIteratorWrapper.getMinGTSPerScanner() || !ParallelGTSDecoderIteratorWrapper.useParallelScanners()) {\n       if (optimized) {\n-        FetchRequest freq = new FetchRequest(req);\n-        freq.setToken(req.getToken());\n-        freq.setNow(now);\n-        freq.setThents(then);\n-        freq.setCount(count);\n-        freq.setSkip(skip);\n-        freq.setStep(step);\n-        freq.setTimestep(timestep);\n-        freq.setSample(sample);\n-        freq.setMetadatas(metadatas);\n-        freq.setPreBoundary(preBoundary);\n-        freq.setPostBoundary(postBoundary);\n-        return new OptimizedSlicedRowFilterGTSDecoderIterator(freq, this.conn, this.tableName, this.colfam, this.keystore, metadatas.size() <= blockcacheThreshold);\n+        return new OptimizedSlicedRowFilterGTSDecoderIterator(freq, this.conn, this.tableName, this.colfam, this.keystore, useBlockCache);\n       } else {\n-        FetchRequest freq = new FetchRequest();\n-        freq.setToken(req.getToken());\n-        freq.setNow(now);\n-        freq.setThents(then);\n-        freq.setCount(count);\n-        freq.setSkip(skip);\n-        freq.setStep(step);\n-        freq.setTimestep(timestep);\n-        freq.setSample(sample);\n-        freq.setMetadatas(metadatas);\n-        freq.setPreBoundary(preBoundary);\n-        freq.setPostBoundary(postBoundary);\n-        return new MultiScanGTSDecoderIterator(freq, this.conn, this.tableName, colfam, this.keystore, metadatas.size() < blockcacheThreshold);      \n+        return new MultiScanGTSDecoderIterator(freq, this.conn, this.tableName, colfam, this.keystore, useBlockCache);      \n       }      \n     } else {\n-      FetchRequest freq = new FetchRequest();\n-      freq.setToken(req.getToken());\n-      freq.setNow(now);\n-      freq.setThents(then);\n-      freq.setCount(count);\n-      freq.setSkip(skip);\n-      freq.setStep(step);\n-      freq.setTimestep(timestep);\n-      freq.setSample(sample);\n-      freq.setMetadatas(metadatas);\n-      freq.setPreBoundary(preBoundary);\n-      freq.setPostBoundary(postBoundary);\n-      return new ParallelGTSDecoderIteratorWrapper(freq, optimized, keystore, this.conn, this.tableName, this.colfam, metadatas.size() < blockcacheThreshold);\n+      return new ParallelGTSDecoderIteratorWrapper(freq, optimized, keystore, this.conn, this.tableName, this.colfam, useBlockCache);\n     }\n   }\n \n", "next_change": null}]}, "commits_in_main": [{"oid": "67019d40559484d9cf2daf23cf83d122822ff274", "message": "Merge commit", "committedDate": null}, {"oid": "e6738cc7a0795d42b7ec3de8769a8878ccc9aa64", "committedDate": "2020-07-29 22:48:12 +0200", "message": "Modified code so list of Metadatas is not deep copied when cloning FetchRequest"}, {"oid": "68d900dca0810a7dd53b694b74bf01ef55618574", "committedDate": "2020-10-19 16:58:35 +0200", "message": "Added flag to control parallel scanners in order to preserve GTS order."}, {"oid": "8108f6bdb84db8e1fb1e7eb5e42f32228cab2d27", "committedDate": "2021-02-23 20:01:01 +0100", "message": "Fix javadoc warnings"}, {"oid": "e826ea374df18f9d0ff413872ebf5ddd1ad0bd17", "committedDate": "2021-07-12 15:23:43 +0200", "message": "Remove unused variables and fields"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUwMDAzMA==", "url": "https://github.com/senx/warp10-platform/pull/772#discussion_r441500030", "body": "Is there a reason not to use the `1L` default value?", "bodyText": "Is there a reason not to use the 1L default value?", "bodyHTML": "<p dir=\"auto\">Is there a reason not to use the <code>1L</code> default value?</p>", "author": "ftence", "createdAt": "2020-06-17T12:17:13Z", "path": "warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java", "diffHunk": "@@ -94,25 +95,36 @@\n   private long count = -1;\n   private long skip = 0;\n   private double sample = 1.0D;\n+  private long step = -1L;\n+  private long timestep = -1L;", "originalCommit": "e07598603051ad7fa838f08bfec01a2aa247f958", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "879ad4092491eda3b08f942710d5bdc6b1e90c69", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java b/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\nindex 3329a8ee..5030cf55 100644\n--- a/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\n+++ b/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\n", "chunk": "@@ -95,8 +95,8 @@ public class MultiScanGTSDecoderIterator extends GTSDecoderIterator {\n   private long count = -1;\n   private long skip = 0;\n   private double sample = 1.0D;\n-  private long step = -1L;\n-  private long timestep = -1L;\n+  private long step = 1L;\n+  private long timestep = 1L;\n   \n   private long nextTimestamp = Long.MAX_VALUE;\n   private long steps = 0L;\n", "next_change": null}]}, "revised_code_in_main": {"commit": "67019d40559484d9cf2daf23cf83d122822ff274", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java b/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\nindex 3329a8ee..55f1ea0a 100644\n--- a/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\n+++ b/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\n", "chunk": "@@ -95,8 +95,8 @@ public class MultiScanGTSDecoderIterator extends GTSDecoderIterator {\n   private long count = -1;\n   private long skip = 0;\n   private double sample = 1.0D;\n-  private long step = -1L;\n-  private long timestep = -1L;\n+  private long step = 1L;\n+  private long timestep = 1L;\n   \n   private long nextTimestamp = Long.MAX_VALUE;\n   private long steps = 0L;\n", "next_change": null}]}, "commits_in_main": [{"oid": "67019d40559484d9cf2daf23cf83d122822ff274", "message": "Merge commit", "committedDate": null}, {"oid": "551d6c7b184d9874baa236fb282d165fb4c8fc19", "committedDate": "2020-10-09 11:22:20 +0200", "message": "Added support for fetching HBase cell TTLs."}, {"oid": "b85ba7585354c1a93145a000b4e4ba8760cfdc26", "committedDate": "2020-10-12 17:55:15 +0200", "message": "Changed the way the TTL is accessed"}, {"oid": "aab710c7c8534a2f52edc3564a35903184b9af30", "committedDate": "2020-10-13 15:15:09 +0200", "message": "Addressed PR comments."}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUxMDQyNw==", "url": "https://github.com/senx/warp10-platform/pull/772#discussion_r441510427", "body": "Typo.", "bodyText": "Typo.", "bodyHTML": "<p dir=\"auto\">Typo.</p>", "author": "ftence", "createdAt": "2020-06-17T12:35:42Z", "path": "warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java", "diffHunk": "@@ -426,6 +514,7 @@ public boolean hasNext() {\n             return false;\n           }\n \n+          // 128buts", "originalCommit": "e07598603051ad7fa838f08bfec01a2aa247f958", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "879ad4092491eda3b08f942710d5bdc6b1e90c69", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java b/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\nindex b08de148..a976cc72 100644\n--- a/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\n+++ b/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\n", "chunk": "@@ -514,7 +515,7 @@ public class StandaloneStoreClient implements StoreClient {\n             return false;\n           }\n \n-          // 128buts\n+          // 128bits\n           startrow = new byte[Constants.HBASE_RAW_DATA_KEY_PREFIX.length + 8 + 8 + 8];\n           ByteBuffer bb = ByteBuffer.wrap(startrow).order(ByteOrder.BIG_ENDIAN);\n           bb.put(Constants.HBASE_RAW_DATA_KEY_PREFIX);\n", "next_change": null}]}, "revised_code_in_main": {"commit": "67019d40559484d9cf2daf23cf83d122822ff274", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java b/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\nindex b08de148..dedaf065 100644\n--- a/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\n+++ b/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\n", "chunk": "@@ -514,7 +515,7 @@ public class StandaloneStoreClient implements StoreClient {\n             return false;\n           }\n \n-          // 128buts\n+          // 128bits\n           startrow = new byte[Constants.HBASE_RAW_DATA_KEY_PREFIX.length + 8 + 8 + 8];\n           ByteBuffer bb = ByteBuffer.wrap(startrow).order(ByteOrder.BIG_ENDIAN);\n           bb.put(Constants.HBASE_RAW_DATA_KEY_PREFIX);\n", "next_change": null}]}, "commits_in_main": [{"oid": "67019d40559484d9cf2daf23cf83d122822ff274", "message": "Merge commit", "committedDate": null}, {"oid": "3278f804361426912bb99824452c1808c1359d49", "committedDate": "2020-10-14 21:29:11 +0200", "message": "Fixed possible deadlock in doOffline during a delete"}, {"oid": "7e9444a6cf22c1843e90345ee9c2e4de97aa57cc", "committedDate": "2020-10-14 23:28:38 +0200", "message": "Added writeUnlocked to use for deletes to avoid deadlock in doOffline"}, {"oid": "8893fcfa43ec1004a6ad1ec8319cf9d324f1a8e9", "committedDate": "2021-01-19 17:50:15 +0100", "message": "Fix conditions to allow postboundary when at the end of the keyspace"}, {"oid": "df8b3f86f63a132d560b01807c7df69179eabb9e", "committedDate": "2021-03-16 13:17:53 +0100", "message": "Fix fields reinitialization when handling a new GTS"}, {"oid": "476264a63117e1b45ed6c8fdd0cb5acb419901d7", "committedDate": "2021-07-07 15:01:48 +0200", "message": "Exposed options for controlling cache and checksums when deleting data"}, {"oid": "13b516eb487a08297af14f2762902457a65adadf", "committedDate": "2021-07-09 08:52:23 +0200", "message": "Fixed batch closing and write method called."}, {"oid": "f84a8b5337f7b24272558e0d9c55032305c6efd8", "committedDate": "2021-07-09 17:29:44 +0200", "message": "Resolved conflict"}, {"oid": "8efab4d85ed5bc685243821d6cef21a5704fd7b2", "committedDate": "2021-07-15 16:54:56 +0200", "message": "Addressed PR comments"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUxNjUzOQ==", "url": "https://github.com/senx/warp10-platform/pull/772#discussion_r441516539", "body": "Shouldn't it be `timestamp` instead of `basets`?", "bodyText": "Shouldn't it be timestamp instead of basets?", "bodyHTML": "<p dir=\"auto\">Shouldn't it be <code>timestamp</code> instead of <code>basets</code>?</p>", "author": "ftence", "createdAt": "2020-06-17T12:45:58Z", "path": "warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java", "diffHunk": "@@ -414,10 +428,36 @@ public GTSDecoder next() {\n                   continue;\n                 }\n                 \n+                // The timestamp is still after the one we expect\n+                if (basets > nextTimestamp && !preBoundaryScan && !postBoundaryScan) {", "originalCommit": "e07598603051ad7fa838f08bfec01a2aa247f958", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjkxMzE1NQ==", "url": "https://github.com/senx/warp10-platform/pull/772#discussion_r442913155", "bodyText": "They are actually the same when DEFAULT_MODULUS==1", "author": "hbs", "createdAt": "2020-06-19T15:42:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUxNjUzOQ=="}], "type": "inlineReview", "revised_code": {"commit": "879ad4092491eda3b08f942710d5bdc6b1e90c69", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java b/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\nindex 3329a8ee..5030cf55 100644\n--- a/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\n+++ b/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\n", "chunk": "@@ -422,43 +408,47 @@ public class MultiScanGTSDecoderIterator extends GTSDecoderIterator {\n                         \n             if (preBoundaryScan || postBoundaryScan || (timestamp <= now && timestamp >= then)) {\n               try {\n-                // Skip\n-                if (toskip > 0 && !preBoundaryScan && !postBoundaryScan) {\n-                  toskip--;\n-                  continue;\n-                }\n-                \n-                // The timestamp is still after the one we expect\n-                if (basets > nextTimestamp && !preBoundaryScan && !postBoundaryScan) {\n-                  continue;\n-                }\n+                if (!preBoundaryScan && !postBoundaryScan) {\n+                  // Skip\n+                  if (toskip > 0) {\n+                    toskip--;\n+                    continue;\n+                  }\n \n-                //\n-                // Compute the new value of nextTimestamp if timestep is set\n-                //\n-                if (hasTimestep) {\n-                  try {\n-                    nextTimestamp = Math.addExact(basets, -timestep);\n-                  } catch (ArithmeticException ae) {\n-                    nextTimestamp = Long.MIN_VALUE;\n-                  }                 \n-                }\n+                  // The timestamp is still after the one we expect\n+                  if (timestamp > nextTimestamp) {\n+                    continue;\n+                  }\n+                  \n+                  //\n+                  // Compute the new value of nextTimestamp if timestep is set\n+                  //\n+                  if (hasTimestep) {\n+                    try {\n+                      nextTimestamp = Math.subtractExact(timestamp, timestep);\n+                    } catch (ArithmeticException ae) {\n+                      nextTimestamp = Long.MIN_VALUE;\n+                      // set nvalues to 0 so we stop after the current value\n+                      nvalues = 0L;\n+                    }\n+                  }\n+                  \n+                  // We have not yet stepped over enough entries\n+                  if (steps > 0) {\n+                    steps--;\n+                    continue;\n+                  }\n+                  \n+                  if (hasStep) {\n+                    steps = step - 1L;\n+                  }\n \n-                // We have not yet stepped over enough entries\n-                if (steps > 0 && !preBoundaryScan && !postBoundaryScan) {\n-                  steps--;\n-                  continue;\n+                  // Sample if we have to\n+                  if (1.0D != sample && prng.nextDouble() > sample) {\n+                    continue;\n+                  }                               \n                 }\n-                \n-                if (hasStep) {\n-                  steps = step - 1L;\n-                }\n-\n-                // Sample if we have to\n-                if (1.0D != sample && !preBoundaryScan && !postBoundaryScan && prng.nextDouble() > sample) {\n-                  continue;\n-                }                               \n-                \n+                                \n                 if (writeTimestamp) {\n                   encoder.addValue(timestamp, decoder.getLocation(), decoder.getElevation(), cell.getTimestamp() * Constants.TIME_UNITS_PER_MS);\n                 } else {\n", "next_change": null}]}, "revised_code_in_main": {"commit": "67019d40559484d9cf2daf23cf83d122822ff274", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java b/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\nindex 3329a8ee..55f1ea0a 100644\n--- a/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\n+++ b/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\n", "chunk": "@@ -422,43 +408,47 @@ public class MultiScanGTSDecoderIterator extends GTSDecoderIterator {\n                         \n             if (preBoundaryScan || postBoundaryScan || (timestamp <= now && timestamp >= then)) {\n               try {\n-                // Skip\n-                if (toskip > 0 && !preBoundaryScan && !postBoundaryScan) {\n-                  toskip--;\n-                  continue;\n-                }\n-                \n-                // The timestamp is still after the one we expect\n-                if (basets > nextTimestamp && !preBoundaryScan && !postBoundaryScan) {\n-                  continue;\n-                }\n+                if (!preBoundaryScan && !postBoundaryScan) {\n+                  // Skip\n+                  if (toskip > 0) {\n+                    toskip--;\n+                    continue;\n+                  }\n \n-                //\n-                // Compute the new value of nextTimestamp if timestep is set\n-                //\n-                if (hasTimestep) {\n-                  try {\n-                    nextTimestamp = Math.addExact(basets, -timestep);\n-                  } catch (ArithmeticException ae) {\n-                    nextTimestamp = Long.MIN_VALUE;\n-                  }                 \n-                }\n+                  // The timestamp is still after the one we expect\n+                  if (timestamp > nextTimestamp) {\n+                    continue;\n+                  }\n+                  \n+                  //\n+                  // Compute the new value of nextTimestamp if timestep is set\n+                  //\n+                  if (hasTimestep) {\n+                    try {\n+                      nextTimestamp = Math.subtractExact(timestamp, timestep);\n+                    } catch (ArithmeticException ae) {\n+                      nextTimestamp = Long.MIN_VALUE;\n+                      // set nvalues to 0 so we stop after the current value\n+                      nvalues = 0L;\n+                    }\n+                  }\n+                  \n+                  // We have not yet stepped over enough entries\n+                  if (steps > 0) {\n+                    steps--;\n+                    continue;\n+                  }\n+                  \n+                  if (hasStep) {\n+                    steps = step - 1L;\n+                  }\n \n-                // We have not yet stepped over enough entries\n-                if (steps > 0 && !preBoundaryScan && !postBoundaryScan) {\n-                  steps--;\n-                  continue;\n+                  // Sample if we have to\n+                  if (1.0D != sample && prng.nextDouble() > sample) {\n+                    continue;\n+                  }                               \n                 }\n-                \n-                if (hasStep) {\n-                  steps = step - 1L;\n-                }\n-\n-                // Sample if we have to\n-                if (1.0D != sample && !preBoundaryScan && !postBoundaryScan && prng.nextDouble() > sample) {\n-                  continue;\n-                }                               \n-                \n+                                \n                 if (writeTimestamp) {\n                   encoder.addValue(timestamp, decoder.getLocation(), decoder.getElevation(), cell.getTimestamp() * Constants.TIME_UNITS_PER_MS);\n                 } else {\n", "next_change": {"commit": "551d6c7b184d9874baa236fb282d165fb4c8fc19", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java b/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\nindex 55f1ea0a..ab079e0a 100644\n--- a/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\n+++ b/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\n", "chunk": "@@ -448,9 +454,27 @@ public class MultiScanGTSDecoderIterator extends GTSDecoderIterator {\n                     continue;\n                   }                               \n                 }\n-                                \n+\n                 if (writeTimestamp) {\n                   encoder.addValue(timestamp, decoder.getLocation(), decoder.getElevation(), cell.getTimestamp() * Constants.TIME_UNITS_PER_MS);\n+                } else if (fetchTTL) {\n+                  Iterator<Tag> iter = CellUtil.tagsIterator(cell.getTagsArray(), cell.getTagsOffset(), cell.getTagsLength());\n+                  boolean hasTTL = false;\n+                  while (iter.hasNext()) {\n+                    Tag t = iter.next();\n+                    if (TagType.TTL_TAG_TYPE != t.getType()) {\n+                      continue;\n+                    }\n+                    if (Bytes.SIZEOF_LONG == t.getTagLength()) {\n+                      long ttl = Bytes.toLong(t.getBuffer(), t.getTagOffset(), t.getTagLength());\n+                      encoder.addValue(timestamp, decoder.getLocation(), decoder.getElevation(), ttl * Constants.TIME_UNITS_PER_MS);\n+                      hasTTL = true;\n+                    }\n+                    break;\n+                  }\n+                  if (!hasTTL) {\n+                    encoder.addValue(timestamp, decoder.getLocation(), decoder.getElevation(), Long.MAX_VALUE);\n+                  }\n                 } else {\n                   encoder.addValue(timestamp, decoder.getLocation(), decoder.getElevation(), decoder.getBinaryValue());\n                 }\n", "next_change": {"commit": "aab710c7c8534a2f52edc3564a35903184b9af30", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java b/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\nindex ab079e0a..dac708ca 100644\n--- a/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\n+++ b/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\n", "chunk": "@@ -458,21 +458,11 @@ public class MultiScanGTSDecoderIterator extends GTSDecoderIterator {\n                 if (writeTimestamp) {\n                   encoder.addValue(timestamp, decoder.getLocation(), decoder.getElevation(), cell.getTimestamp() * Constants.TIME_UNITS_PER_MS);\n                 } else if (fetchTTL) {\n-                  Iterator<Tag> iter = CellUtil.tagsIterator(cell.getTagsArray(), cell.getTagsOffset(), cell.getTagsLength());\n-                  boolean hasTTL = false;\n-                  while (iter.hasNext()) {\n-                    Tag t = iter.next();\n-                    if (TagType.TTL_TAG_TYPE != t.getType()) {\n-                      continue;\n-                    }\n-                    if (Bytes.SIZEOF_LONG == t.getTagLength()) {\n-                      long ttl = Bytes.toLong(t.getBuffer(), t.getTagOffset(), t.getTagLength());\n-                      encoder.addValue(timestamp, decoder.getLocation(), decoder.getElevation(), ttl * Constants.TIME_UNITS_PER_MS);\n-                      hasTTL = true;\n-                    }\n-                    break;\n-                  }\n-                  if (!hasTTL) {\n+                  Tag tag = Tag.getTag(cell.getTagsArray(), cell.getTagsOffset(), cell.getTagsLength(), TagType.TTL_TAG_TYPE);\n+                  if (null != tag && Bytes.SIZEOF_LONG == tag.getTagLength()) {\n+                    long ttl = Bytes.toLong(tag.getBuffer(), tag.getTagOffset(), tag.getTagLength());\n+                    encoder.addValue(timestamp, decoder.getLocation(), decoder.getElevation(), ttl * Constants.TIME_UNITS_PER_MS);\n+                  } else {\n                     encoder.addValue(timestamp, decoder.getLocation(), decoder.getElevation(), Long.MAX_VALUE);\n                   }\n                 } else {\n", "next_change": null}]}}]}}]}, "commits_in_main": [{"oid": "67019d40559484d9cf2daf23cf83d122822ff274", "message": "Merge commit", "committedDate": null}, {"oid": "551d6c7b184d9874baa236fb282d165fb4c8fc19", "committedDate": "2020-10-09 11:22:20 +0200", "message": "Added support for fetching HBase cell TTLs."}, {"oid": "b85ba7585354c1a93145a000b4e4ba8760cfdc26", "committedDate": "2020-10-12 17:55:15 +0200", "message": "Changed the way the TTL is accessed"}, {"oid": "aab710c7c8534a2f52edc3564a35903184b9af30", "committedDate": "2020-10-13 15:15:09 +0200", "message": "Addressed PR comments."}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUxNjg1Nw==", "url": "https://github.com/senx/warp10-platform/pull/772#discussion_r441516857", "body": "Shouldn't it be `timestamp` instead of `basets`?\r\nAlso why not use `subtractExact`?", "bodyText": "Shouldn't it be timestamp instead of basets?\nAlso why not use subtractExact?", "bodyHTML": "<p dir=\"auto\">Shouldn't it be <code>timestamp</code> instead of <code>basets</code>?<br>\nAlso why not use <code>subtractExact</code>?</p>", "author": "ftence", "createdAt": "2020-06-17T12:46:28Z", "path": "warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java", "diffHunk": "@@ -414,10 +428,36 @@ public GTSDecoder next() {\n                   continue;\n                 }\n                 \n+                // The timestamp is still after the one we expect\n+                if (basets > nextTimestamp && !preBoundaryScan && !postBoundaryScan) {\n+                  continue;\n+                }\n+\n+                //\n+                // Compute the new value of nextTimestamp if timestep is set\n+                //\n+                if (hasTimestep) {\n+                  try {\n+                    nextTimestamp = Math.addExact(basets, -timestep);", "originalCommit": "e07598603051ad7fa838f08bfec01a2aa247f958", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "879ad4092491eda3b08f942710d5bdc6b1e90c69", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java b/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\nindex 3329a8ee..5030cf55 100644\n--- a/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\n+++ b/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\n", "chunk": "@@ -422,43 +408,47 @@ public class MultiScanGTSDecoderIterator extends GTSDecoderIterator {\n                         \n             if (preBoundaryScan || postBoundaryScan || (timestamp <= now && timestamp >= then)) {\n               try {\n-                // Skip\n-                if (toskip > 0 && !preBoundaryScan && !postBoundaryScan) {\n-                  toskip--;\n-                  continue;\n-                }\n-                \n-                // The timestamp is still after the one we expect\n-                if (basets > nextTimestamp && !preBoundaryScan && !postBoundaryScan) {\n-                  continue;\n-                }\n+                if (!preBoundaryScan && !postBoundaryScan) {\n+                  // Skip\n+                  if (toskip > 0) {\n+                    toskip--;\n+                    continue;\n+                  }\n \n-                //\n-                // Compute the new value of nextTimestamp if timestep is set\n-                //\n-                if (hasTimestep) {\n-                  try {\n-                    nextTimestamp = Math.addExact(basets, -timestep);\n-                  } catch (ArithmeticException ae) {\n-                    nextTimestamp = Long.MIN_VALUE;\n-                  }                 \n-                }\n+                  // The timestamp is still after the one we expect\n+                  if (timestamp > nextTimestamp) {\n+                    continue;\n+                  }\n+                  \n+                  //\n+                  // Compute the new value of nextTimestamp if timestep is set\n+                  //\n+                  if (hasTimestep) {\n+                    try {\n+                      nextTimestamp = Math.subtractExact(timestamp, timestep);\n+                    } catch (ArithmeticException ae) {\n+                      nextTimestamp = Long.MIN_VALUE;\n+                      // set nvalues to 0 so we stop after the current value\n+                      nvalues = 0L;\n+                    }\n+                  }\n+                  \n+                  // We have not yet stepped over enough entries\n+                  if (steps > 0) {\n+                    steps--;\n+                    continue;\n+                  }\n+                  \n+                  if (hasStep) {\n+                    steps = step - 1L;\n+                  }\n \n-                // We have not yet stepped over enough entries\n-                if (steps > 0 && !preBoundaryScan && !postBoundaryScan) {\n-                  steps--;\n-                  continue;\n+                  // Sample if we have to\n+                  if (1.0D != sample && prng.nextDouble() > sample) {\n+                    continue;\n+                  }                               \n                 }\n-                \n-                if (hasStep) {\n-                  steps = step - 1L;\n-                }\n-\n-                // Sample if we have to\n-                if (1.0D != sample && !preBoundaryScan && !postBoundaryScan && prng.nextDouble() > sample) {\n-                  continue;\n-                }                               \n-                \n+                                \n                 if (writeTimestamp) {\n                   encoder.addValue(timestamp, decoder.getLocation(), decoder.getElevation(), cell.getTimestamp() * Constants.TIME_UNITS_PER_MS);\n                 } else {\n", "next_change": null}]}, "revised_code_in_main": {"commit": "67019d40559484d9cf2daf23cf83d122822ff274", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java b/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\nindex 3329a8ee..55f1ea0a 100644\n--- a/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\n+++ b/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\n", "chunk": "@@ -422,43 +408,47 @@ public class MultiScanGTSDecoderIterator extends GTSDecoderIterator {\n                         \n             if (preBoundaryScan || postBoundaryScan || (timestamp <= now && timestamp >= then)) {\n               try {\n-                // Skip\n-                if (toskip > 0 && !preBoundaryScan && !postBoundaryScan) {\n-                  toskip--;\n-                  continue;\n-                }\n-                \n-                // The timestamp is still after the one we expect\n-                if (basets > nextTimestamp && !preBoundaryScan && !postBoundaryScan) {\n-                  continue;\n-                }\n+                if (!preBoundaryScan && !postBoundaryScan) {\n+                  // Skip\n+                  if (toskip > 0) {\n+                    toskip--;\n+                    continue;\n+                  }\n \n-                //\n-                // Compute the new value of nextTimestamp if timestep is set\n-                //\n-                if (hasTimestep) {\n-                  try {\n-                    nextTimestamp = Math.addExact(basets, -timestep);\n-                  } catch (ArithmeticException ae) {\n-                    nextTimestamp = Long.MIN_VALUE;\n-                  }                 \n-                }\n+                  // The timestamp is still after the one we expect\n+                  if (timestamp > nextTimestamp) {\n+                    continue;\n+                  }\n+                  \n+                  //\n+                  // Compute the new value of nextTimestamp if timestep is set\n+                  //\n+                  if (hasTimestep) {\n+                    try {\n+                      nextTimestamp = Math.subtractExact(timestamp, timestep);\n+                    } catch (ArithmeticException ae) {\n+                      nextTimestamp = Long.MIN_VALUE;\n+                      // set nvalues to 0 so we stop after the current value\n+                      nvalues = 0L;\n+                    }\n+                  }\n+                  \n+                  // We have not yet stepped over enough entries\n+                  if (steps > 0) {\n+                    steps--;\n+                    continue;\n+                  }\n+                  \n+                  if (hasStep) {\n+                    steps = step - 1L;\n+                  }\n \n-                // We have not yet stepped over enough entries\n-                if (steps > 0 && !preBoundaryScan && !postBoundaryScan) {\n-                  steps--;\n-                  continue;\n+                  // Sample if we have to\n+                  if (1.0D != sample && prng.nextDouble() > sample) {\n+                    continue;\n+                  }                               \n                 }\n-                \n-                if (hasStep) {\n-                  steps = step - 1L;\n-                }\n-\n-                // Sample if we have to\n-                if (1.0D != sample && !preBoundaryScan && !postBoundaryScan && prng.nextDouble() > sample) {\n-                  continue;\n-                }                               \n-                \n+                                \n                 if (writeTimestamp) {\n                   encoder.addValue(timestamp, decoder.getLocation(), decoder.getElevation(), cell.getTimestamp() * Constants.TIME_UNITS_PER_MS);\n                 } else {\n", "next_change": {"commit": "551d6c7b184d9874baa236fb282d165fb4c8fc19", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java b/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\nindex 55f1ea0a..ab079e0a 100644\n--- a/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\n+++ b/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\n", "chunk": "@@ -448,9 +454,27 @@ public class MultiScanGTSDecoderIterator extends GTSDecoderIterator {\n                     continue;\n                   }                               \n                 }\n-                                \n+\n                 if (writeTimestamp) {\n                   encoder.addValue(timestamp, decoder.getLocation(), decoder.getElevation(), cell.getTimestamp() * Constants.TIME_UNITS_PER_MS);\n+                } else if (fetchTTL) {\n+                  Iterator<Tag> iter = CellUtil.tagsIterator(cell.getTagsArray(), cell.getTagsOffset(), cell.getTagsLength());\n+                  boolean hasTTL = false;\n+                  while (iter.hasNext()) {\n+                    Tag t = iter.next();\n+                    if (TagType.TTL_TAG_TYPE != t.getType()) {\n+                      continue;\n+                    }\n+                    if (Bytes.SIZEOF_LONG == t.getTagLength()) {\n+                      long ttl = Bytes.toLong(t.getBuffer(), t.getTagOffset(), t.getTagLength());\n+                      encoder.addValue(timestamp, decoder.getLocation(), decoder.getElevation(), ttl * Constants.TIME_UNITS_PER_MS);\n+                      hasTTL = true;\n+                    }\n+                    break;\n+                  }\n+                  if (!hasTTL) {\n+                    encoder.addValue(timestamp, decoder.getLocation(), decoder.getElevation(), Long.MAX_VALUE);\n+                  }\n                 } else {\n                   encoder.addValue(timestamp, decoder.getLocation(), decoder.getElevation(), decoder.getBinaryValue());\n                 }\n", "next_change": {"commit": "aab710c7c8534a2f52edc3564a35903184b9af30", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java b/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\nindex ab079e0a..dac708ca 100644\n--- a/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\n+++ b/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\n", "chunk": "@@ -458,21 +458,11 @@ public class MultiScanGTSDecoderIterator extends GTSDecoderIterator {\n                 if (writeTimestamp) {\n                   encoder.addValue(timestamp, decoder.getLocation(), decoder.getElevation(), cell.getTimestamp() * Constants.TIME_UNITS_PER_MS);\n                 } else if (fetchTTL) {\n-                  Iterator<Tag> iter = CellUtil.tagsIterator(cell.getTagsArray(), cell.getTagsOffset(), cell.getTagsLength());\n-                  boolean hasTTL = false;\n-                  while (iter.hasNext()) {\n-                    Tag t = iter.next();\n-                    if (TagType.TTL_TAG_TYPE != t.getType()) {\n-                      continue;\n-                    }\n-                    if (Bytes.SIZEOF_LONG == t.getTagLength()) {\n-                      long ttl = Bytes.toLong(t.getBuffer(), t.getTagOffset(), t.getTagLength());\n-                      encoder.addValue(timestamp, decoder.getLocation(), decoder.getElevation(), ttl * Constants.TIME_UNITS_PER_MS);\n-                      hasTTL = true;\n-                    }\n-                    break;\n-                  }\n-                  if (!hasTTL) {\n+                  Tag tag = Tag.getTag(cell.getTagsArray(), cell.getTagsOffset(), cell.getTagsLength(), TagType.TTL_TAG_TYPE);\n+                  if (null != tag && Bytes.SIZEOF_LONG == tag.getTagLength()) {\n+                    long ttl = Bytes.toLong(tag.getBuffer(), tag.getTagOffset(), tag.getTagLength());\n+                    encoder.addValue(timestamp, decoder.getLocation(), decoder.getElevation(), ttl * Constants.TIME_UNITS_PER_MS);\n+                  } else {\n                     encoder.addValue(timestamp, decoder.getLocation(), decoder.getElevation(), Long.MAX_VALUE);\n                   }\n                 } else {\n", "next_change": null}]}}]}}]}, "commits_in_main": [{"oid": "67019d40559484d9cf2daf23cf83d122822ff274", "message": "Merge commit", "committedDate": null}, {"oid": "551d6c7b184d9874baa236fb282d165fb4c8fc19", "committedDate": "2020-10-09 11:22:20 +0200", "message": "Added support for fetching HBase cell TTLs."}, {"oid": "b85ba7585354c1a93145a000b4e4ba8760cfdc26", "committedDate": "2020-10-12 17:55:15 +0200", "message": "Changed the way the TTL is accessed"}, {"oid": "aab710c7c8534a2f52edc3564a35903184b9af30", "committedDate": "2020-10-13 15:15:09 +0200", "message": "Addressed PR comments."}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUyMDIzNg==", "url": "https://github.com/senx/warp10-platform/pull/772#discussion_r441520236", "body": "This is a valid timestamp, should we set `nvalues` to 0 to avoid returning the data at `Long.MIN_VALUE` timestamp?", "bodyText": "This is a valid timestamp, should we set nvalues to 0 to avoid returning the data at Long.MIN_VALUE timestamp?", "bodyHTML": "<p dir=\"auto\">This is a valid timestamp, should we set <code>nvalues</code> to 0 to avoid returning the data at <code>Long.MIN_VALUE</code> timestamp?</p>", "author": "ftence", "createdAt": "2020-06-17T12:52:06Z", "path": "warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java", "diffHunk": "@@ -414,10 +428,36 @@ public GTSDecoder next() {\n                   continue;\n                 }\n                 \n+                // The timestamp is still after the one we expect\n+                if (basets > nextTimestamp && !preBoundaryScan && !postBoundaryScan) {\n+                  continue;\n+                }\n+\n+                //\n+                // Compute the new value of nextTimestamp if timestep is set\n+                //\n+                if (hasTimestep) {\n+                  try {\n+                    nextTimestamp = Math.addExact(basets, -timestep);\n+                  } catch (ArithmeticException ae) {\n+                    nextTimestamp = Long.MIN_VALUE;", "originalCommit": "e07598603051ad7fa838f08bfec01a2aa247f958", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "879ad4092491eda3b08f942710d5bdc6b1e90c69", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java b/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\nindex 3329a8ee..5030cf55 100644\n--- a/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\n+++ b/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\n", "chunk": "@@ -422,43 +408,47 @@ public class MultiScanGTSDecoderIterator extends GTSDecoderIterator {\n                         \n             if (preBoundaryScan || postBoundaryScan || (timestamp <= now && timestamp >= then)) {\n               try {\n-                // Skip\n-                if (toskip > 0 && !preBoundaryScan && !postBoundaryScan) {\n-                  toskip--;\n-                  continue;\n-                }\n-                \n-                // The timestamp is still after the one we expect\n-                if (basets > nextTimestamp && !preBoundaryScan && !postBoundaryScan) {\n-                  continue;\n-                }\n+                if (!preBoundaryScan && !postBoundaryScan) {\n+                  // Skip\n+                  if (toskip > 0) {\n+                    toskip--;\n+                    continue;\n+                  }\n \n-                //\n-                // Compute the new value of nextTimestamp if timestep is set\n-                //\n-                if (hasTimestep) {\n-                  try {\n-                    nextTimestamp = Math.addExact(basets, -timestep);\n-                  } catch (ArithmeticException ae) {\n-                    nextTimestamp = Long.MIN_VALUE;\n-                  }                 \n-                }\n+                  // The timestamp is still after the one we expect\n+                  if (timestamp > nextTimestamp) {\n+                    continue;\n+                  }\n+                  \n+                  //\n+                  // Compute the new value of nextTimestamp if timestep is set\n+                  //\n+                  if (hasTimestep) {\n+                    try {\n+                      nextTimestamp = Math.subtractExact(timestamp, timestep);\n+                    } catch (ArithmeticException ae) {\n+                      nextTimestamp = Long.MIN_VALUE;\n+                      // set nvalues to 0 so we stop after the current value\n+                      nvalues = 0L;\n+                    }\n+                  }\n+                  \n+                  // We have not yet stepped over enough entries\n+                  if (steps > 0) {\n+                    steps--;\n+                    continue;\n+                  }\n+                  \n+                  if (hasStep) {\n+                    steps = step - 1L;\n+                  }\n \n-                // We have not yet stepped over enough entries\n-                if (steps > 0 && !preBoundaryScan && !postBoundaryScan) {\n-                  steps--;\n-                  continue;\n+                  // Sample if we have to\n+                  if (1.0D != sample && prng.nextDouble() > sample) {\n+                    continue;\n+                  }                               \n                 }\n-                \n-                if (hasStep) {\n-                  steps = step - 1L;\n-                }\n-\n-                // Sample if we have to\n-                if (1.0D != sample && !preBoundaryScan && !postBoundaryScan && prng.nextDouble() > sample) {\n-                  continue;\n-                }                               \n-                \n+                                \n                 if (writeTimestamp) {\n                   encoder.addValue(timestamp, decoder.getLocation(), decoder.getElevation(), cell.getTimestamp() * Constants.TIME_UNITS_PER_MS);\n                 } else {\n", "next_change": null}]}, "revised_code_in_main": {"commit": "67019d40559484d9cf2daf23cf83d122822ff274", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java b/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\nindex 3329a8ee..55f1ea0a 100644\n--- a/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\n+++ b/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\n", "chunk": "@@ -422,43 +408,47 @@ public class MultiScanGTSDecoderIterator extends GTSDecoderIterator {\n                         \n             if (preBoundaryScan || postBoundaryScan || (timestamp <= now && timestamp >= then)) {\n               try {\n-                // Skip\n-                if (toskip > 0 && !preBoundaryScan && !postBoundaryScan) {\n-                  toskip--;\n-                  continue;\n-                }\n-                \n-                // The timestamp is still after the one we expect\n-                if (basets > nextTimestamp && !preBoundaryScan && !postBoundaryScan) {\n-                  continue;\n-                }\n+                if (!preBoundaryScan && !postBoundaryScan) {\n+                  // Skip\n+                  if (toskip > 0) {\n+                    toskip--;\n+                    continue;\n+                  }\n \n-                //\n-                // Compute the new value of nextTimestamp if timestep is set\n-                //\n-                if (hasTimestep) {\n-                  try {\n-                    nextTimestamp = Math.addExact(basets, -timestep);\n-                  } catch (ArithmeticException ae) {\n-                    nextTimestamp = Long.MIN_VALUE;\n-                  }                 \n-                }\n+                  // The timestamp is still after the one we expect\n+                  if (timestamp > nextTimestamp) {\n+                    continue;\n+                  }\n+                  \n+                  //\n+                  // Compute the new value of nextTimestamp if timestep is set\n+                  //\n+                  if (hasTimestep) {\n+                    try {\n+                      nextTimestamp = Math.subtractExact(timestamp, timestep);\n+                    } catch (ArithmeticException ae) {\n+                      nextTimestamp = Long.MIN_VALUE;\n+                      // set nvalues to 0 so we stop after the current value\n+                      nvalues = 0L;\n+                    }\n+                  }\n+                  \n+                  // We have not yet stepped over enough entries\n+                  if (steps > 0) {\n+                    steps--;\n+                    continue;\n+                  }\n+                  \n+                  if (hasStep) {\n+                    steps = step - 1L;\n+                  }\n \n-                // We have not yet stepped over enough entries\n-                if (steps > 0 && !preBoundaryScan && !postBoundaryScan) {\n-                  steps--;\n-                  continue;\n+                  // Sample if we have to\n+                  if (1.0D != sample && prng.nextDouble() > sample) {\n+                    continue;\n+                  }                               \n                 }\n-                \n-                if (hasStep) {\n-                  steps = step - 1L;\n-                }\n-\n-                // Sample if we have to\n-                if (1.0D != sample && !preBoundaryScan && !postBoundaryScan && prng.nextDouble() > sample) {\n-                  continue;\n-                }                               \n-                \n+                                \n                 if (writeTimestamp) {\n                   encoder.addValue(timestamp, decoder.getLocation(), decoder.getElevation(), cell.getTimestamp() * Constants.TIME_UNITS_PER_MS);\n                 } else {\n", "next_change": {"commit": "551d6c7b184d9874baa236fb282d165fb4c8fc19", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java b/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\nindex 55f1ea0a..ab079e0a 100644\n--- a/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\n+++ b/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\n", "chunk": "@@ -448,9 +454,27 @@ public class MultiScanGTSDecoderIterator extends GTSDecoderIterator {\n                     continue;\n                   }                               \n                 }\n-                                \n+\n                 if (writeTimestamp) {\n                   encoder.addValue(timestamp, decoder.getLocation(), decoder.getElevation(), cell.getTimestamp() * Constants.TIME_UNITS_PER_MS);\n+                } else if (fetchTTL) {\n+                  Iterator<Tag> iter = CellUtil.tagsIterator(cell.getTagsArray(), cell.getTagsOffset(), cell.getTagsLength());\n+                  boolean hasTTL = false;\n+                  while (iter.hasNext()) {\n+                    Tag t = iter.next();\n+                    if (TagType.TTL_TAG_TYPE != t.getType()) {\n+                      continue;\n+                    }\n+                    if (Bytes.SIZEOF_LONG == t.getTagLength()) {\n+                      long ttl = Bytes.toLong(t.getBuffer(), t.getTagOffset(), t.getTagLength());\n+                      encoder.addValue(timestamp, decoder.getLocation(), decoder.getElevation(), ttl * Constants.TIME_UNITS_PER_MS);\n+                      hasTTL = true;\n+                    }\n+                    break;\n+                  }\n+                  if (!hasTTL) {\n+                    encoder.addValue(timestamp, decoder.getLocation(), decoder.getElevation(), Long.MAX_VALUE);\n+                  }\n                 } else {\n                   encoder.addValue(timestamp, decoder.getLocation(), decoder.getElevation(), decoder.getBinaryValue());\n                 }\n", "next_change": {"commit": "aab710c7c8534a2f52edc3564a35903184b9af30", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java b/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\nindex ab079e0a..dac708ca 100644\n--- a/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\n+++ b/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\n", "chunk": "@@ -458,21 +458,11 @@ public class MultiScanGTSDecoderIterator extends GTSDecoderIterator {\n                 if (writeTimestamp) {\n                   encoder.addValue(timestamp, decoder.getLocation(), decoder.getElevation(), cell.getTimestamp() * Constants.TIME_UNITS_PER_MS);\n                 } else if (fetchTTL) {\n-                  Iterator<Tag> iter = CellUtil.tagsIterator(cell.getTagsArray(), cell.getTagsOffset(), cell.getTagsLength());\n-                  boolean hasTTL = false;\n-                  while (iter.hasNext()) {\n-                    Tag t = iter.next();\n-                    if (TagType.TTL_TAG_TYPE != t.getType()) {\n-                      continue;\n-                    }\n-                    if (Bytes.SIZEOF_LONG == t.getTagLength()) {\n-                      long ttl = Bytes.toLong(t.getBuffer(), t.getTagOffset(), t.getTagLength());\n-                      encoder.addValue(timestamp, decoder.getLocation(), decoder.getElevation(), ttl * Constants.TIME_UNITS_PER_MS);\n-                      hasTTL = true;\n-                    }\n-                    break;\n-                  }\n-                  if (!hasTTL) {\n+                  Tag tag = Tag.getTag(cell.getTagsArray(), cell.getTagsOffset(), cell.getTagsLength(), TagType.TTL_TAG_TYPE);\n+                  if (null != tag && Bytes.SIZEOF_LONG == tag.getTagLength()) {\n+                    long ttl = Bytes.toLong(tag.getBuffer(), tag.getTagOffset(), tag.getTagLength());\n+                    encoder.addValue(timestamp, decoder.getLocation(), decoder.getElevation(), ttl * Constants.TIME_UNITS_PER_MS);\n+                  } else {\n                     encoder.addValue(timestamp, decoder.getLocation(), decoder.getElevation(), Long.MAX_VALUE);\n                   }\n                 } else {\n", "next_change": null}]}}]}}]}, "commits_in_main": [{"oid": "67019d40559484d9cf2daf23cf83d122822ff274", "message": "Merge commit", "committedDate": null}, {"oid": "551d6c7b184d9874baa236fb282d165fb4c8fc19", "committedDate": "2020-10-09 11:22:20 +0200", "message": "Added support for fetching HBase cell TTLs."}, {"oid": "b85ba7585354c1a93145a000b4e4ba8760cfdc26", "committedDate": "2020-10-12 17:55:15 +0200", "message": "Changed the way the TTL is accessed"}, {"oid": "aab710c7c8534a2f52edc3564a35903184b9af30", "committedDate": "2020-10-13 15:15:09 +0200", "message": "Addressed PR comments."}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUyMjQ2Mw==", "url": "https://github.com/senx/warp10-platform/pull/772#discussion_r441522463", "body": "I think `&& !preBoundaryScan && !postBoundaryScan` should be added. Better, enclose the few conditionals sharing this.", "bodyText": "I think && !preBoundaryScan && !postBoundaryScan should be added. Better, enclose the few conditionals sharing this.", "bodyHTML": "<p dir=\"auto\">I think <code>&amp;&amp; !preBoundaryScan &amp;&amp; !postBoundaryScan</code> should be added. Better, enclose the few conditionals sharing this.</p>", "author": "ftence", "createdAt": "2020-06-17T12:55:37Z", "path": "warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java", "diffHunk": "@@ -414,10 +428,36 @@ public GTSDecoder next() {\n                   continue;\n                 }\n                 \n+                // The timestamp is still after the one we expect\n+                if (basets > nextTimestamp && !preBoundaryScan && !postBoundaryScan) {\n+                  continue;\n+                }\n+\n+                //\n+                // Compute the new value of nextTimestamp if timestep is set\n+                //\n+                if (hasTimestep) {", "originalCommit": "e07598603051ad7fa838f08bfec01a2aa247f958", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "879ad4092491eda3b08f942710d5bdc6b1e90c69", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java b/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\nindex 3329a8ee..5030cf55 100644\n--- a/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\n+++ b/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\n", "chunk": "@@ -422,43 +408,47 @@ public class MultiScanGTSDecoderIterator extends GTSDecoderIterator {\n                         \n             if (preBoundaryScan || postBoundaryScan || (timestamp <= now && timestamp >= then)) {\n               try {\n-                // Skip\n-                if (toskip > 0 && !preBoundaryScan && !postBoundaryScan) {\n-                  toskip--;\n-                  continue;\n-                }\n-                \n-                // The timestamp is still after the one we expect\n-                if (basets > nextTimestamp && !preBoundaryScan && !postBoundaryScan) {\n-                  continue;\n-                }\n+                if (!preBoundaryScan && !postBoundaryScan) {\n+                  // Skip\n+                  if (toskip > 0) {\n+                    toskip--;\n+                    continue;\n+                  }\n \n-                //\n-                // Compute the new value of nextTimestamp if timestep is set\n-                //\n-                if (hasTimestep) {\n-                  try {\n-                    nextTimestamp = Math.addExact(basets, -timestep);\n-                  } catch (ArithmeticException ae) {\n-                    nextTimestamp = Long.MIN_VALUE;\n-                  }                 \n-                }\n+                  // The timestamp is still after the one we expect\n+                  if (timestamp > nextTimestamp) {\n+                    continue;\n+                  }\n+                  \n+                  //\n+                  // Compute the new value of nextTimestamp if timestep is set\n+                  //\n+                  if (hasTimestep) {\n+                    try {\n+                      nextTimestamp = Math.subtractExact(timestamp, timestep);\n+                    } catch (ArithmeticException ae) {\n+                      nextTimestamp = Long.MIN_VALUE;\n+                      // set nvalues to 0 so we stop after the current value\n+                      nvalues = 0L;\n+                    }\n+                  }\n+                  \n+                  // We have not yet stepped over enough entries\n+                  if (steps > 0) {\n+                    steps--;\n+                    continue;\n+                  }\n+                  \n+                  if (hasStep) {\n+                    steps = step - 1L;\n+                  }\n \n-                // We have not yet stepped over enough entries\n-                if (steps > 0 && !preBoundaryScan && !postBoundaryScan) {\n-                  steps--;\n-                  continue;\n+                  // Sample if we have to\n+                  if (1.0D != sample && prng.nextDouble() > sample) {\n+                    continue;\n+                  }                               \n                 }\n-                \n-                if (hasStep) {\n-                  steps = step - 1L;\n-                }\n-\n-                // Sample if we have to\n-                if (1.0D != sample && !preBoundaryScan && !postBoundaryScan && prng.nextDouble() > sample) {\n-                  continue;\n-                }                               \n-                \n+                                \n                 if (writeTimestamp) {\n                   encoder.addValue(timestamp, decoder.getLocation(), decoder.getElevation(), cell.getTimestamp() * Constants.TIME_UNITS_PER_MS);\n                 } else {\n", "next_change": null}]}, "revised_code_in_main": {"commit": "67019d40559484d9cf2daf23cf83d122822ff274", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java b/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\nindex 3329a8ee..55f1ea0a 100644\n--- a/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\n+++ b/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\n", "chunk": "@@ -422,43 +408,47 @@ public class MultiScanGTSDecoderIterator extends GTSDecoderIterator {\n                         \n             if (preBoundaryScan || postBoundaryScan || (timestamp <= now && timestamp >= then)) {\n               try {\n-                // Skip\n-                if (toskip > 0 && !preBoundaryScan && !postBoundaryScan) {\n-                  toskip--;\n-                  continue;\n-                }\n-                \n-                // The timestamp is still after the one we expect\n-                if (basets > nextTimestamp && !preBoundaryScan && !postBoundaryScan) {\n-                  continue;\n-                }\n+                if (!preBoundaryScan && !postBoundaryScan) {\n+                  // Skip\n+                  if (toskip > 0) {\n+                    toskip--;\n+                    continue;\n+                  }\n \n-                //\n-                // Compute the new value of nextTimestamp if timestep is set\n-                //\n-                if (hasTimestep) {\n-                  try {\n-                    nextTimestamp = Math.addExact(basets, -timestep);\n-                  } catch (ArithmeticException ae) {\n-                    nextTimestamp = Long.MIN_VALUE;\n-                  }                 \n-                }\n+                  // The timestamp is still after the one we expect\n+                  if (timestamp > nextTimestamp) {\n+                    continue;\n+                  }\n+                  \n+                  //\n+                  // Compute the new value of nextTimestamp if timestep is set\n+                  //\n+                  if (hasTimestep) {\n+                    try {\n+                      nextTimestamp = Math.subtractExact(timestamp, timestep);\n+                    } catch (ArithmeticException ae) {\n+                      nextTimestamp = Long.MIN_VALUE;\n+                      // set nvalues to 0 so we stop after the current value\n+                      nvalues = 0L;\n+                    }\n+                  }\n+                  \n+                  // We have not yet stepped over enough entries\n+                  if (steps > 0) {\n+                    steps--;\n+                    continue;\n+                  }\n+                  \n+                  if (hasStep) {\n+                    steps = step - 1L;\n+                  }\n \n-                // We have not yet stepped over enough entries\n-                if (steps > 0 && !preBoundaryScan && !postBoundaryScan) {\n-                  steps--;\n-                  continue;\n+                  // Sample if we have to\n+                  if (1.0D != sample && prng.nextDouble() > sample) {\n+                    continue;\n+                  }                               \n                 }\n-                \n-                if (hasStep) {\n-                  steps = step - 1L;\n-                }\n-\n-                // Sample if we have to\n-                if (1.0D != sample && !preBoundaryScan && !postBoundaryScan && prng.nextDouble() > sample) {\n-                  continue;\n-                }                               \n-                \n+                                \n                 if (writeTimestamp) {\n                   encoder.addValue(timestamp, decoder.getLocation(), decoder.getElevation(), cell.getTimestamp() * Constants.TIME_UNITS_PER_MS);\n                 } else {\n", "next_change": {"commit": "551d6c7b184d9874baa236fb282d165fb4c8fc19", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java b/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\nindex 55f1ea0a..ab079e0a 100644\n--- a/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\n+++ b/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\n", "chunk": "@@ -448,9 +454,27 @@ public class MultiScanGTSDecoderIterator extends GTSDecoderIterator {\n                     continue;\n                   }                               \n                 }\n-                                \n+\n                 if (writeTimestamp) {\n                   encoder.addValue(timestamp, decoder.getLocation(), decoder.getElevation(), cell.getTimestamp() * Constants.TIME_UNITS_PER_MS);\n+                } else if (fetchTTL) {\n+                  Iterator<Tag> iter = CellUtil.tagsIterator(cell.getTagsArray(), cell.getTagsOffset(), cell.getTagsLength());\n+                  boolean hasTTL = false;\n+                  while (iter.hasNext()) {\n+                    Tag t = iter.next();\n+                    if (TagType.TTL_TAG_TYPE != t.getType()) {\n+                      continue;\n+                    }\n+                    if (Bytes.SIZEOF_LONG == t.getTagLength()) {\n+                      long ttl = Bytes.toLong(t.getBuffer(), t.getTagOffset(), t.getTagLength());\n+                      encoder.addValue(timestamp, decoder.getLocation(), decoder.getElevation(), ttl * Constants.TIME_UNITS_PER_MS);\n+                      hasTTL = true;\n+                    }\n+                    break;\n+                  }\n+                  if (!hasTTL) {\n+                    encoder.addValue(timestamp, decoder.getLocation(), decoder.getElevation(), Long.MAX_VALUE);\n+                  }\n                 } else {\n                   encoder.addValue(timestamp, decoder.getLocation(), decoder.getElevation(), decoder.getBinaryValue());\n                 }\n", "next_change": {"commit": "aab710c7c8534a2f52edc3564a35903184b9af30", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java b/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\nindex ab079e0a..dac708ca 100644\n--- a/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\n+++ b/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\n", "chunk": "@@ -458,21 +458,11 @@ public class MultiScanGTSDecoderIterator extends GTSDecoderIterator {\n                 if (writeTimestamp) {\n                   encoder.addValue(timestamp, decoder.getLocation(), decoder.getElevation(), cell.getTimestamp() * Constants.TIME_UNITS_PER_MS);\n                 } else if (fetchTTL) {\n-                  Iterator<Tag> iter = CellUtil.tagsIterator(cell.getTagsArray(), cell.getTagsOffset(), cell.getTagsLength());\n-                  boolean hasTTL = false;\n-                  while (iter.hasNext()) {\n-                    Tag t = iter.next();\n-                    if (TagType.TTL_TAG_TYPE != t.getType()) {\n-                      continue;\n-                    }\n-                    if (Bytes.SIZEOF_LONG == t.getTagLength()) {\n-                      long ttl = Bytes.toLong(t.getBuffer(), t.getTagOffset(), t.getTagLength());\n-                      encoder.addValue(timestamp, decoder.getLocation(), decoder.getElevation(), ttl * Constants.TIME_UNITS_PER_MS);\n-                      hasTTL = true;\n-                    }\n-                    break;\n-                  }\n-                  if (!hasTTL) {\n+                  Tag tag = Tag.getTag(cell.getTagsArray(), cell.getTagsOffset(), cell.getTagsLength(), TagType.TTL_TAG_TYPE);\n+                  if (null != tag && Bytes.SIZEOF_LONG == tag.getTagLength()) {\n+                    long ttl = Bytes.toLong(tag.getBuffer(), tag.getTagOffset(), tag.getTagLength());\n+                    encoder.addValue(timestamp, decoder.getLocation(), decoder.getElevation(), ttl * Constants.TIME_UNITS_PER_MS);\n+                  } else {\n                     encoder.addValue(timestamp, decoder.getLocation(), decoder.getElevation(), Long.MAX_VALUE);\n                   }\n                 } else {\n", "next_change": null}]}}]}}]}, "commits_in_main": [{"oid": "67019d40559484d9cf2daf23cf83d122822ff274", "message": "Merge commit", "committedDate": null}, {"oid": "551d6c7b184d9874baa236fb282d165fb4c8fc19", "committedDate": "2020-10-09 11:22:20 +0200", "message": "Added support for fetching HBase cell TTLs."}, {"oid": "b85ba7585354c1a93145a000b4e4ba8760cfdc26", "committedDate": "2020-10-12 17:55:15 +0200", "message": "Changed the way the TTL is accessed"}, {"oid": "aab710c7c8534a2f52edc3564a35903184b9af30", "committedDate": "2020-10-13 15:15:09 +0200", "message": "Addressed PR comments."}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTUzODExNw==", "url": "https://github.com/senx/warp10-platform/pull/772#discussion_r441538117", "body": "`this.count >= 0 ?`", "bodyText": "this.count >= 0 ?", "bodyHTML": "<p dir=\"auto\"><code>this.count &gt;= 0 ?</code></p>", "author": "ftence", "createdAt": "2020-06-17T13:19:39Z", "path": "warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java", "diffHunk": "@@ -93,24 +107,39 @@\n   private static byte[] prefix = Constants.HBASE_RAW_DATA_KEY_PREFIX;\n \n   private final boolean writeTimestamp;\n+  private final boolean hasStep;\n+  private final boolean hasTimestep;\n+  private final boolean hasSample;\n+  private long skip = 0L;\n+  private long steps = 0L;\n+  private final long step;\n+  private final long timestep;\n+  private long nextTimestamp = Long.MAX_VALUE;\n+  private final double sample;\n   \n-  public SlicedRowFilterGTSDecoderIterator(long now, long timespan, List<Metadata> metadatas, Connection conn, TableName tableName, byte[] colfam, boolean writeTimestamp, KeyStore keystore, boolean useBlockCache) {\n+  private Random prng = null;\n+\n+  public SlicedRowFilterGTSDecoderIterator(FetchRequest req, Connection conn, TableName tableName, byte[] colfam, KeyStore keystore, boolean useBlockCache) {\n       \n+    this.request = req;\n     this.keystore = keystore;\n-    this.now = now;\n-    this.timespan = timespan;\n+    this.now = req.getNow();\n+    this.then = req.getThents();\n+    this.count = req.getCount();\n+    this.sample = req.getSample();\n+    this.hasSample = this.sample < 1.0D;\n+    this.prng = hasSample ? new Random() : null;\n+    this.hasStep = req.getStep() > 1L;\n+    this.steps = req.getStep() - 1L;\n+    this.step = hasStep ? req.getStep() : 1L;\n+    this.hasTimestep = req.getTimestep() > 1L;\n+    this.timestep = this.hasTimestep ? req.getTimestep() : 1L;\n+    this.nextTimestamp = Long.MAX_VALUE;\n+    this.skip = req.getSkip();\n+    this.nvalues = this.count > 0 ? this.count : Long.MAX_VALUE;", "originalCommit": "e07598603051ad7fa838f08bfec01a2aa247f958", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "879ad4092491eda3b08f942710d5bdc6b1e90c69", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java b/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\nindex c033518d..f7c6ffe3 100644\n--- a/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\n+++ b/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\n", "chunk": "@@ -136,7 +133,7 @@ public class SlicedRowFilterGTSDecoderIterator extends GTSDecoderIterator implem\n     this.timestep = this.hasTimestep ? req.getTimestep() : 1L;\n     this.nextTimestamp = Long.MAX_VALUE;\n     this.skip = req.getSkip();\n-    this.nvalues = this.count > 0 ? this.count : Long.MAX_VALUE;\n+    this.nvalues = this.count >= 0 ? this.count : Long.MAX_VALUE;\n     this.hbaseAESKey = keystore.getKey(KeyStore.AES_HBASE_DATA);\n     this.writeTimestamp = req.isWriteTimestamp();\n     List<Metadata> metadatas = req.getMetadatas();\n", "next_change": null}]}, "revised_code_in_main": {"commit": "67019d40559484d9cf2daf23cf83d122822ff274", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java b/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\nindex c033518d..a20d2102 100644\n--- a/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\n+++ b/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\n", "chunk": "@@ -130,13 +127,13 @@ public class SlicedRowFilterGTSDecoderIterator extends GTSDecoderIterator implem\n     this.hasSample = this.sample < 1.0D;\n     this.prng = hasSample ? new Random() : null;\n     this.hasStep = req.getStep() > 1L;\n-    this.steps = req.getStep() - 1L;\n+    this.steps = 0L;\n     this.step = hasStep ? req.getStep() : 1L;\n     this.hasTimestep = req.getTimestep() > 1L;\n     this.timestep = this.hasTimestep ? req.getTimestep() : 1L;\n     this.nextTimestamp = Long.MAX_VALUE;\n     this.skip = req.getSkip();\n-    this.nvalues = this.count > 0 ? this.count : Long.MAX_VALUE;\n+    this.nvalues = this.count >= 0 ? this.count : Long.MAX_VALUE;\n     this.hbaseAESKey = keystore.getKey(KeyStore.AES_HBASE_DATA);\n     this.writeTimestamp = req.isWriteTimestamp();\n     List<Metadata> metadatas = req.getMetadatas();\n", "next_change": {"commit": "551d6c7b184d9874baa236fb282d165fb4c8fc19", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java b/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\nindex a20d2102..cded28ff 100644\n--- a/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\n+++ b/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\n", "chunk": "@@ -136,6 +140,7 @@ public class SlicedRowFilterGTSDecoderIterator extends GTSDecoderIterator implem\n     this.nvalues = this.count >= 0 ? this.count : Long.MAX_VALUE;\n     this.hbaseAESKey = keystore.getKey(KeyStore.AES_HBASE_DATA);\n     this.writeTimestamp = req.isWriteTimestamp();\n+    this.fetchTTL = req.isTTL();\n     List<Metadata> metadatas = req.getMetadatas();\n     \n     //\n", "next_change": null}]}}]}, "commits_in_main": [{"oid": "67019d40559484d9cf2daf23cf83d122822ff274", "message": "Merge commit", "committedDate": null}, {"oid": "551d6c7b184d9874baa236fb282d165fb4c8fc19", "committedDate": "2020-10-09 11:22:20 +0200", "message": "Added support for fetching HBase cell TTLs."}, {"oid": "b85ba7585354c1a93145a000b4e4ba8760cfdc26", "committedDate": "2020-10-12 17:55:15 +0200", "message": "Changed the way the TTL is accessed"}, {"oid": "aab710c7c8534a2f52edc3564a35903184b9af30", "committedDate": "2020-10-13 15:15:09 +0200", "message": "Addressed PR comments."}, {"oid": "af1b59eca2ba863201d0ba10053e2d9d41107a02", "committedDate": "2021-07-09 16:01:15 +0200", "message": "Clean binary search implementation in SlicedRowFilter"}, {"oid": "a3c8881ee677f662ac9402f7571b20030003bd90", "committedDate": "2021-07-09 16:08:18 +0200", "message": "Updated copyright"}, {"oid": "e826ea374df18f9d0ff413872ebf5ddd1ad0bd17", "committedDate": "2021-07-12 15:23:43 +0200", "message": "Remove unused variables and fields"}, {"oid": "97981237e5fbd2ca4f8991cc267c9cb476d448cd", "committedDate": "2021-09-08 16:29:23 +0200", "message": "Merge branch 'master' into slicedrowfilter_binarysearch"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTU0MTA5Ng==", "url": "https://github.com/senx/warp10-platform/pull/772#discussion_r441541096", "body": "`count >= 0 ?`", "bodyText": "count >= 0 ?", "bodyHTML": "<p dir=\"auto\"><code>count &gt;= 0 ?</code></p>", "author": "ftence", "createdAt": "2020-06-17T13:23:48Z", "path": "warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java", "diffHunk": "@@ -131,18 +160,19 @@ public SlicedRowFilterGTSDecoderIterator(long now, long timespan, List<Metadata>\n     List<Pair<byte[], byte[]>> ranges = new ArrayList<Pair<byte[], byte[]>>();\n     \n     for (Metadata metadata: metadatas) {\n-      byte[][] keys = getKeys(metadata, now, timespan);\n+      byte[][] keys = getKeys(metadata, now, then);\n       byte[] lower = keys[0];\n       byte[] upper = keys[1];\n       \n-      this.metadatas.put(new String(Arrays.copyOfRange(lower, prefix.length, prefix.length + 16), StandardCharsets.ISO_8859_1), metadata);\n+      // Store the Metadata under a key containing both class and labels id in a 16 character string\n+      this.metadatas.put(new String(lower, prefix.length, 16, StandardCharsets.ISO_8859_1), metadata);\n       \n       Pair<byte[],byte[]> range = new Pair<byte[],byte[]>(lower, upper);\n       \n       ranges.add(range);\n     }\n                 \n-    SlicedRowFilter filter = new SlicedRowFilter(bounds, ranges, timespan < 0 ? -timespan : Long.MAX_VALUE);\n+    SlicedRowFilter filter = new SlicedRowFilter(bounds, ranges, count > 0 ? count : Long.MAX_VALUE);", "originalCommit": "e07598603051ad7fa838f08bfec01a2aa247f958", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "879ad4092491eda3b08f942710d5bdc6b1e90c69", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java b/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\nindex c033518d..f7c6ffe3 100644\n--- a/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\n+++ b/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\n", "chunk": "@@ -172,7 +169,7 @@ public class SlicedRowFilterGTSDecoderIterator extends GTSDecoderIterator implem\n       ranges.add(range);\n     }\n                 \n-    SlicedRowFilter filter = new SlicedRowFilter(bounds, ranges, count > 0 ? count : Long.MAX_VALUE);\n+    SlicedRowFilter filter = new SlicedRowFilter(bounds, ranges, count >= 0 ? count : Long.MAX_VALUE);\n \n     //\n     // Create scanner. The start key is the lower bound of the first range\n", "next_change": null}]}, "revised_code_in_main": {"commit": "67019d40559484d9cf2daf23cf83d122822ff274", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java b/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\nindex c033518d..a20d2102 100644\n--- a/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\n+++ b/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\n", "chunk": "@@ -172,7 +169,7 @@ public class SlicedRowFilterGTSDecoderIterator extends GTSDecoderIterator implem\n       ranges.add(range);\n     }\n                 \n-    SlicedRowFilter filter = new SlicedRowFilter(bounds, ranges, count > 0 ? count : Long.MAX_VALUE);\n+    SlicedRowFilter filter = new SlicedRowFilter(bounds, ranges, count >= 0 ? count : Long.MAX_VALUE);\n \n     //\n     // Create scanner. The start key is the lower bound of the first range\n", "next_change": null}]}, "commits_in_main": [{"oid": "67019d40559484d9cf2daf23cf83d122822ff274", "message": "Merge commit", "committedDate": null}, {"oid": "551d6c7b184d9874baa236fb282d165fb4c8fc19", "committedDate": "2020-10-09 11:22:20 +0200", "message": "Added support for fetching HBase cell TTLs."}, {"oid": "b85ba7585354c1a93145a000b4e4ba8760cfdc26", "committedDate": "2020-10-12 17:55:15 +0200", "message": "Changed the way the TTL is accessed"}, {"oid": "aab710c7c8534a2f52edc3564a35903184b9af30", "committedDate": "2020-10-13 15:15:09 +0200", "message": "Addressed PR comments."}, {"oid": "af1b59eca2ba863201d0ba10053e2d9d41107a02", "committedDate": "2021-07-09 16:01:15 +0200", "message": "Clean binary search implementation in SlicedRowFilter"}, {"oid": "a3c8881ee677f662ac9402f7571b20030003bd90", "committedDate": "2021-07-09 16:08:18 +0200", "message": "Updated copyright"}, {"oid": "e826ea374df18f9d0ff413872ebf5ddd1ad0bd17", "committedDate": "2021-07-12 15:23:43 +0200", "message": "Remove unused variables and fields"}, {"oid": "97981237e5fbd2ca4f8991cc267c9cb476d448cd", "committedDate": "2021-09-08 16:29:23 +0200", "message": "Merge branch 'master' into slicedrowfilter_binarysearch"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTU0MjM0Mw==", "url": "https://github.com/senx/warp10-platform/pull/772#discussion_r441542343", "body": "`ZERO_BYTES` and `ONES_BYTES` fields can now be removed.", "bodyText": "ZERO_BYTES and ONES_BYTES fields can now be removed.", "bodyHTML": "<p dir=\"auto\"><code>ZERO_BYTES</code> and <code>ONES_BYTES</code> fields can now be removed.</p>", "author": "ftence", "createdAt": "2020-06-17T13:25:25Z", "path": "warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java", "diffHunk": "@@ -192,21 +222,9 @@ public SlicedRowFilterGTSDecoderIterator(long now, long timespan, List<Metadata>\n     // Set lower/upper timestamps\n     //\n     \n-    long modulus = Constants.DEFAULT_MODULUS;\n-  \n-    if (Long.MAX_VALUE == now) {\n-      System.arraycopy(ZERO_BYTES, 0, lower, prefix.length + 16, 8);\n-    } else {\n-      System.arraycopy(Longs.toByteArray(Long.MAX_VALUE - (now - (now % modulus))), 0, lower, prefix.length + 16, 8);        \n-    }\n-    \n-    if (timespan < 0) {\n-      System.arraycopy(ONES_BYTES, 0, upper, prefix.length + 16, 8);                \n-    } else {\n-      // Last timestamp does not need to be offset by modulus as it is the case when using a scanner, because\n-      // SlicedRowFilter upper bound is included, not excluded.\n-      System.arraycopy(Longs.toByteArray(Long.MAX_VALUE - ((now - timespan) - ((now - timespan) % modulus))), 0, upper, prefix.length + 16, 8);        \n-    }\n+    System.arraycopy(Longs.toByteArray(Long.MAX_VALUE - now), 0, lower, prefix.length + 8 + 8, 8);        \n+    // SlicedRowFilter upper bound is included\n+    System.arraycopy(Longs.toByteArray(Long.MAX_VALUE - then), 0, upper, prefix.length + 8 + 8, 8);        ", "originalCommit": "e07598603051ad7fa838f08bfec01a2aa247f958", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null, "revised_code_in_main": null, "commits_in_main": [{"oid": "67019d40559484d9cf2daf23cf83d122822ff274", "message": "Merge commit", "committedDate": null}, {"oid": "551d6c7b184d9874baa236fb282d165fb4c8fc19", "committedDate": "2020-10-09 11:22:20 +0200", "message": "Added support for fetching HBase cell TTLs."}, {"oid": "b85ba7585354c1a93145a000b4e4ba8760cfdc26", "committedDate": "2020-10-12 17:55:15 +0200", "message": "Changed the way the TTL is accessed"}, {"oid": "aab710c7c8534a2f52edc3564a35903184b9af30", "committedDate": "2020-10-13 15:15:09 +0200", "message": "Addressed PR comments."}, {"oid": "af1b59eca2ba863201d0ba10053e2d9d41107a02", "committedDate": "2021-07-09 16:01:15 +0200", "message": "Clean binary search implementation in SlicedRowFilter"}, {"oid": "a3c8881ee677f662ac9402f7571b20030003bd90", "committedDate": "2021-07-09 16:08:18 +0200", "message": "Updated copyright"}, {"oid": "e826ea374df18f9d0ff413872ebf5ddd1ad0bd17", "committedDate": "2021-07-12 15:23:43 +0200", "message": "Remove unused variables and fields"}, {"oid": "97981237e5fbd2ca4f8991cc267c9cb476d448cd", "committedDate": "2021-09-08 16:29:23 +0200", "message": "Merge branch 'master' into slicedrowfilter_binarysearch"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTU4Mzk5NA==", "url": "https://github.com/senx/warp10-platform/pull/772#discussion_r441583994", "body": "`this.count >= 0 ?`", "bodyText": "this.count >= 0 ?", "bodyHTML": "<p dir=\"auto\"><code>this.count &gt;= 0 ?</code></p>", "author": "ftence", "createdAt": "2020-06-17T14:21:58Z", "path": "warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java", "diffHunk": "@@ -246,19 +269,42 @@ public GTSDecoder next() {\n         resultCount++;\n       }\n \n-      // Encode this in ISO_8859_1 so we are sure every possible byte sequence is valid\n-      // FIXME(hbs): instead of doing a Arrays.copyOfRange, use new String(byte[],offset,len,charset)\n-      String classlabelsid = new String(Arrays.copyOfRange(result.getRow(), Constants.HBASE_RAW_DATA_KEY_PREFIX.length, Constants.HBASE_RAW_DATA_KEY_PREFIX.length + 16), StandardCharsets.ISO_8859_1);\n+      //\n+      // Compare the class and labels id with those in currentGTS\n+      // If they differ, recompute currentGTSString\n+      //\n+      \n+      if (0 != Bytes.compareTo(currentGTS, 0, 16, result.getRow(), Constants.HBASE_RAW_DATA_KEY_PREFIX.length, 16)) {\n+        System.arraycopy(result.getRow(), Constants.HBASE_RAW_DATA_KEY_PREFIX.length, currentGTS, 0, currentGTS.length);\n+        currentGTSString = new String(currentGTS, StandardCharsets.ISO_8859_1);\n+      }\n+\n+      String classlabelsid = currentGTSString;\n     \n+      //\n+      // Extract the Metadata associated with the current row\n+      //\n       Metadata metadata = this.metadatas.get(classlabelsid);\n \n       //\n-      // The current row is for a different GTS, return the current encoder and record the current result\n-      //\n-      \n-      if (encoder.size() > 0 && (encoder.getClassId() != metadata.getClassId() || encoder.getLabelsId() != metadata.getLabelsId())) {\n+      // The current row is for a different GTS.\n+      // If the current encoder has data, return it and record the current result for the next call to 'next'\n+      // If the current encoder has no data (which could happen if we have reached the requested number of results),\n+      // update the metadata\n+      //      \n+      if ((encoder.getClassId() != metadata.getClassId() || encoder.getLabelsId() != metadata.getLabelsId())) {\n+        // Save result in pendingresult as we have not yet read the associated cells\n         this.pendingresult = result;\n-        return encoder.getDecoder();\n+        //\n+        // Reset fetch parameters\n+        //\n+        this.nvalues = this.count > 0 ? this.count : Long.MAX_VALUE;", "originalCommit": "e07598603051ad7fa838f08bfec01a2aa247f958", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "879ad4092491eda3b08f942710d5bdc6b1e90c69", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java b/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\nindex c033518d..f7c6ffe3 100644\n--- a/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\n+++ b/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\n", "chunk": "@@ -298,7 +295,7 @@ public class SlicedRowFilterGTSDecoderIterator extends GTSDecoderIterator implem\n         //\n         // Reset fetch parameters\n         //\n-        this.nvalues = this.count > 0 ? this.count : Long.MAX_VALUE;\n+        this.nvalues = this.count >= 0 ? this.count : Long.MAX_VALUE;\n         this.skip = this.request.getSkip();\n         this.steps = this.hasStep ? this.request.getStep() - 1 : 0L;\n         this.nextTimestamp = Long.MAX_VALUE;\n", "next_change": {"commit": "abe989e9748cdc10aca949f409ca0bbbf6a2b3a8", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java b/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\nindex f7c6ffe3..b003357d 100644\n--- a/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\n+++ b/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\n", "chunk": "@@ -290,16 +290,16 @@ public class SlicedRowFilterGTSDecoderIterator extends GTSDecoderIterator implem\n       // update the metadata\n       //      \n       if ((encoder.getClassId() != metadata.getClassId() || encoder.getLabelsId() != metadata.getLabelsId())) {\n-        // Save result in pendingresult as we have not yet read the associated cells\n-        this.pendingresult = result;\n         //\n         // Reset fetch parameters\n         //\n         this.nvalues = this.count >= 0 ? this.count : Long.MAX_VALUE;\n         this.skip = this.request.getSkip();\n-        this.steps = this.hasStep ? this.request.getStep() - 1 : 0L;\n+        this.steps = 0L;\n         this.nextTimestamp = Long.MAX_VALUE;\n         if (encoder.size() > 0) {\n+          // Save result in pendingresult as we have not yet read the associated cells\n+          this.pendingresult = result;\n           return encoder.getDecoder();\n         }\n       }\n", "next_change": null}]}}]}, "revised_code_in_main": {"commit": "67019d40559484d9cf2daf23cf83d122822ff274", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java b/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\nindex c033518d..a20d2102 100644\n--- a/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\n+++ b/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\n", "chunk": "@@ -293,16 +290,16 @@ public class SlicedRowFilterGTSDecoderIterator extends GTSDecoderIterator implem\n       // update the metadata\n       //      \n       if ((encoder.getClassId() != metadata.getClassId() || encoder.getLabelsId() != metadata.getLabelsId())) {\n-        // Save result in pendingresult as we have not yet read the associated cells\n-        this.pendingresult = result;\n         //\n         // Reset fetch parameters\n         //\n-        this.nvalues = this.count > 0 ? this.count : Long.MAX_VALUE;\n+        this.nvalues = this.count >= 0 ? this.count : Long.MAX_VALUE;\n         this.skip = this.request.getSkip();\n-        this.steps = this.hasStep ? this.request.getStep() - 1 : 0L;\n+        this.steps = 0L;\n         this.nextTimestamp = Long.MAX_VALUE;\n         if (encoder.size() > 0) {\n+          // Save result in pendingresult as we have not yet read the associated cells\n+          this.pendingresult = result;\n           return encoder.getDecoder();\n         }\n       }\n", "next_change": null}]}, "commits_in_main": [{"oid": "67019d40559484d9cf2daf23cf83d122822ff274", "message": "Merge commit", "committedDate": null}, {"oid": "551d6c7b184d9874baa236fb282d165fb4c8fc19", "committedDate": "2020-10-09 11:22:20 +0200", "message": "Added support for fetching HBase cell TTLs."}, {"oid": "b85ba7585354c1a93145a000b4e4ba8760cfdc26", "committedDate": "2020-10-12 17:55:15 +0200", "message": "Changed the way the TTL is accessed"}, {"oid": "aab710c7c8534a2f52edc3564a35903184b9af30", "committedDate": "2020-10-13 15:15:09 +0200", "message": "Addressed PR comments."}, {"oid": "af1b59eca2ba863201d0ba10053e2d9d41107a02", "committedDate": "2021-07-09 16:01:15 +0200", "message": "Clean binary search implementation in SlicedRowFilter"}, {"oid": "a3c8881ee677f662ac9402f7571b20030003bd90", "committedDate": "2021-07-09 16:08:18 +0200", "message": "Updated copyright"}, {"oid": "e826ea374df18f9d0ff413872ebf5ddd1ad0bd17", "committedDate": "2021-07-12 15:23:43 +0200", "message": "Remove unused variables and fields"}, {"oid": "97981237e5fbd2ca4f8991cc267c9cb476d448cd", "committedDate": "2021-09-08 16:29:23 +0200", "message": "Merge branch 'master' into slicedrowfilter_binarysearch"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTYwMDU0OA==", "url": "https://github.com/senx/warp10-platform/pull/772#discussion_r441600548", "body": "If you want to remove this kind of code, you left it in MultiScanGTSDecoderIterator, lines 385-410. ", "bodyText": "If you want to remove this kind of code, you left it in MultiScanGTSDecoderIterator, lines 385-410.", "bodyHTML": "<p dir=\"auto\">If you want to remove this kind of code, you left it in MultiScanGTSDecoderIterator, lines 385-410.</p>", "author": "ftence", "createdAt": "2020-06-17T14:43:51Z", "path": "warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java", "diffHunk": "@@ -276,40 +322,28 @@ public GTSDecoder next() {\n           Cell cell = cscanner.current();\n           cellCount++;\n           \n+          // Simply ignore the values if we already collected enough\n+          if (nvalues <= 0) {\n+            continue;\n+          }\n+          \n           //\n-          // Extract timestamp base from column qualifier\n-          // This is true even for packed readings, those have a base timestamp of 0L\n+          // Extract timestamp from row key\n           //\n \n-          long basets = Long.MAX_VALUE;\n-          \n-          if (1 == Constants.DEFAULT_MODULUS) {\n-            // 128BITS\n-            byte[] data = cell.getRowArray();\n-            int offset = cell.getRowOffset();\n-            offset += Constants.HBASE_RAW_DATA_KEY_PREFIX.length + 8 + 8; // Add 'prefix' + 'classId' + 'labelsId' to row key offset\n-            long delta = data[offset] & 0xFF;\n-            delta <<= 8; delta |= (data[offset + 1] & 0xFFL);\n-            delta <<= 8; delta |= (data[offset + 2] & 0xFFL);\n-            delta <<= 8; delta |= (data[offset + 3] & 0xFFL);\n-            delta <<= 8; delta |= (data[offset + 4] & 0xFFL);\n-            delta <<= 8; delta |= (data[offset + 5] & 0xFFL);\n-            delta <<= 8; delta |= (data[offset + 6] & 0xFFL);\n-            delta <<= 8; delta |= (data[offset + 7] & 0xFFL);\n-            basets -= delta;              \n-          } else {\n-            byte[] data = cell.getQualifierArray();\n-            int offset = cell.getQualifierOffset();\n-            long delta = data[offset] & 0xFFL;\n-            delta <<= 8; delta |= (data[offset + 1] & 0xFFL);\n-            delta <<= 8; delta |= (data[offset + 2] & 0xFFL);\n-            delta <<= 8; delta |= (data[offset + 3] & 0xFFL);\n-            delta <<= 8; delta |= (data[offset + 4] & 0xFFL);\n-            delta <<= 8; delta |= (data[offset + 5] & 0xFFL);\n-            delta <<= 8; delta |= (data[offset + 6] & 0xFFL);\n-            delta <<= 8; delta |= (data[offset + 7] & 0xFFL);\n-            basets -= delta;                            \n-          }\n+          // 128BITS\n+          byte[] data = cell.getRowArray();\n+          int offset = cell.getRowOffset();\n+          offset += Constants.HBASE_RAW_DATA_KEY_PREFIX.length + 8 + 8; // Add 'prefix' + 'classId' + 'labelsId' to row key offset\n+          long delta = data[offset] & 0xFF;\n+          delta <<= 8; delta |= (data[offset + 1] & 0xFFL);\n+          delta <<= 8; delta |= (data[offset + 2] & 0xFFL);\n+          delta <<= 8; delta |= (data[offset + 3] & 0xFFL);\n+          delta <<= 8; delta |= (data[offset + 4] & 0xFFL);\n+          delta <<= 8; delta |= (data[offset + 5] & 0xFFL);\n+          delta <<= 8; delta |= (data[offset + 6] & 0xFFL);\n+          delta <<= 8; delta |= (data[offset + 7] & 0xFFL);\n+          long basets = Long.MAX_VALUE - delta;              ", "originalCommit": "e07598603051ad7fa838f08bfec01a2aa247f958", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null, "revised_code_in_main": null, "commits_in_main": [{"oid": "67019d40559484d9cf2daf23cf83d122822ff274", "message": "Merge commit", "committedDate": null}, {"oid": "551d6c7b184d9874baa236fb282d165fb4c8fc19", "committedDate": "2020-10-09 11:22:20 +0200", "message": "Added support for fetching HBase cell TTLs."}, {"oid": "b85ba7585354c1a93145a000b4e4ba8760cfdc26", "committedDate": "2020-10-12 17:55:15 +0200", "message": "Changed the way the TTL is accessed"}, {"oid": "aab710c7c8534a2f52edc3564a35903184b9af30", "committedDate": "2020-10-13 15:15:09 +0200", "message": "Addressed PR comments."}, {"oid": "af1b59eca2ba863201d0ba10053e2d9d41107a02", "committedDate": "2021-07-09 16:01:15 +0200", "message": "Clean binary search implementation in SlicedRowFilter"}, {"oid": "a3c8881ee677f662ac9402f7571b20030003bd90", "committedDate": "2021-07-09 16:08:18 +0200", "message": "Updated copyright"}, {"oid": "e826ea374df18f9d0ff413872ebf5ddd1ad0bd17", "committedDate": "2021-07-12 15:23:43 +0200", "message": "Remove unused variables and fields"}, {"oid": "97981237e5fbd2ca4f8991cc267c9cb476d448cd", "committedDate": "2021-09-08 16:29:23 +0200", "message": "Merge branch 'master' into slicedrowfilter_binarysearch"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTYxNDQ2OA==", "url": "https://github.com/senx/warp10-platform/pull/772#discussion_r441614468", "body": "Same comments:\r\n- `basets` vs `timestamp`\r\n- `addExact` vs `subtractExact`\r\n- Long.MIN_VALUE is a valid timestamp", "bodyText": "Same comments:\n\nbasets vs timestamp\naddExact vs subtractExact\nLong.MIN_VALUE is a valid timestamp", "bodyHTML": "<p dir=\"auto\">Same comments:</p>\n<ul dir=\"auto\">\n<li><code>basets</code> vs <code>timestamp</code></li>\n<li><code>addExact</code> vs <code>subtractExact</code></li>\n<li>Long.MIN_VALUE is a valid timestamp</li>\n</ul>", "author": "ftence", "createdAt": "2020-06-17T15:01:31Z", "path": "warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java", "diffHunk": "@@ -321,7 +355,63 @@ public GTSDecoder next() {\n                     \n           while(decoder.next() && nvalues > 0) {\n             long timestamp = decoder.getTimestamp();\n-            if (timestamp <= now && (timespan < 0 || (timestamp > (now - timespan)))) {\n+            \n+            //\n+            // Only consider values if they are within the requested range\n+            // This should always be the case but better err on the side of caution sometimes\n+            //\n+            if (timestamp <= now && timestamp >= then) {\n+\n+              //\n+              // Skip datapoints\n+              //\n+              \n+              if (this.skip > 0) {\n+                this.skip--;\n+                continue;\n+              }\n+              \n+              //\n+              // Check that the datapoint timestamp is compatible with the timestep parameter, i.e. it is at least\n+              // 'timestep' time units before the previous one we selected\n+              //\n+              \n+              if (basets > nextTimestamp) {\n+                continue;\n+              }\n+\n+              //\n+              // Compute the new value of nextTimestamp if timestep is set\n+              //\n+              if (hasTimestep) {\n+                try {\n+                  nextTimestamp = Math.addExact(basets, -this.timestep);\n+                } catch (ArithmeticException ae) {\n+                  nextTimestamp = Long.MIN_VALUE;\n+                }\n+              }", "originalCommit": "e07598603051ad7fa838f08bfec01a2aa247f958", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "879ad4092491eda3b08f942710d5bdc6b1e90c69", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java b/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\nindex c033518d..f7c6ffe3 100644\n--- a/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\n+++ b/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\n", "chunk": "@@ -385,9 +382,10 @@ public class SlicedRowFilterGTSDecoderIterator extends GTSDecoderIterator implem\n               //\n               if (hasTimestep) {\n                 try {\n-                  nextTimestamp = Math.addExact(basets, -this.timestep);\n+                  nextTimestamp = Math.subtractExact(timestamp, this.timestep);\n                 } catch (ArithmeticException ae) {\n                   nextTimestamp = Long.MIN_VALUE;\n+                  nvalues = 0L;\n                 }\n               }\n                           \n", "next_change": null}]}, "revised_code_in_main": {"commit": "67019d40559484d9cf2daf23cf83d122822ff274", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java b/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\nindex c033518d..a20d2102 100644\n--- a/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\n+++ b/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\n", "chunk": "@@ -385,9 +382,10 @@ public class SlicedRowFilterGTSDecoderIterator extends GTSDecoderIterator implem\n               //\n               if (hasTimestep) {\n                 try {\n-                  nextTimestamp = Math.addExact(basets, -this.timestep);\n+                  nextTimestamp = Math.subtractExact(timestamp, this.timestep);\n                 } catch (ArithmeticException ae) {\n                   nextTimestamp = Long.MIN_VALUE;\n+                  nvalues = 0L;\n                 }\n               }\n                           \n", "next_change": null}]}, "commits_in_main": [{"oid": "67019d40559484d9cf2daf23cf83d122822ff274", "message": "Merge commit", "committedDate": null}, {"oid": "551d6c7b184d9874baa236fb282d165fb4c8fc19", "committedDate": "2020-10-09 11:22:20 +0200", "message": "Added support for fetching HBase cell TTLs."}, {"oid": "b85ba7585354c1a93145a000b4e4ba8760cfdc26", "committedDate": "2020-10-12 17:55:15 +0200", "message": "Changed the way the TTL is accessed"}, {"oid": "aab710c7c8534a2f52edc3564a35903184b9af30", "committedDate": "2020-10-13 15:15:09 +0200", "message": "Addressed PR comments."}, {"oid": "af1b59eca2ba863201d0ba10053e2d9d41107a02", "committedDate": "2021-07-09 16:01:15 +0200", "message": "Clean binary search implementation in SlicedRowFilter"}, {"oid": "a3c8881ee677f662ac9402f7571b20030003bd90", "committedDate": "2021-07-09 16:08:18 +0200", "message": "Updated copyright"}, {"oid": "e826ea374df18f9d0ff413872ebf5ddd1ad0bd17", "committedDate": "2021-07-12 15:23:43 +0200", "message": "Remove unused variables and fields"}, {"oid": "97981237e5fbd2ca4f8991cc267c9cb476d448cd", "committedDate": "2021-09-08 16:29:23 +0200", "message": "Merge branch 'master' into slicedrowfilter_binarysearch"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTY0NjA3MA==", "url": "https://github.com/senx/warp10-platform/pull/772#discussion_r441646070", "body": "Already tested in `paramsFromMap`.\r\n(Also used `timestep` instead of `step`).", "bodyText": "Already tested in paramsFromMap.\n(Also used timestep instead of step).", "bodyHTML": "<p dir=\"auto\">Already tested in <code>paramsFromMap</code>.<br>\n(Also used <code>timestep</code> instead of <code>step</code>).</p>", "author": "ftence", "createdAt": "2020-06-17T15:44:50Z", "path": "warp10/src/main/java/io/warp10/script/functions/FETCH.java", "diffHunk": "@@ -446,7 +449,24 @@ public Object apply(WarpScriptStack stack) throws WarpScriptException {\n         }\n \n         long then = (long) params.get(PARAM_START);\n-        long skip = (long) params.getOrDefault(PARAM_SKIP, 0L);        \n+        long skip = (long) params.getOrDefault(PARAM_SKIP, 0L);\n+        long timestep = 1L;\n+        long step = 1L;\n+        \n+        if (params.containsKey(PARAM_TIMESTEP)) {\n+          timestep = (long) params.get(PARAM_TIMESTEP);\n+          if (timestep <= 1) {\n+            throw new WarpScriptException(getName() + \" parameter '\" + PARAM_TIMESTEP + \"' cannot be <= 1.\");\n+          }\n+        }\n+        \n+        if (params.containsKey(PARAM_STEP)) {\n+          step = (long) params.get(PARAM_STEP);\n+          \n+          if (timestep <= 1) {\n+            throw new WarpScriptException(getName() + \" parameter '\" + PARAM_STEP + \"' cannot be <= 1.\");            \n+          }\n+        }", "originalCommit": "e07598603051ad7fa838f08bfec01a2aa247f958", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "879ad4092491eda3b08f942710d5bdc6b1e90c69", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/script/functions/FETCH.java b/warp10/src/main/java/io/warp10/script/functions/FETCH.java\nindex 363c70ca..781e6347 100644\n--- a/warp10/src/main/java/io/warp10/script/functions/FETCH.java\n+++ b/warp10/src/main/java/io/warp10/script/functions/FETCH.java\n", "chunk": "@@ -455,18 +455,12 @@ public class FETCH extends NamedWarpScriptFunction implements WarpScriptStackFun\n         \n         if (params.containsKey(PARAM_TIMESTEP)) {\n           timestep = (long) params.get(PARAM_TIMESTEP);\n-          if (timestep <= 1) {\n-            throw new WarpScriptException(getName() + \" parameter '\" + PARAM_TIMESTEP + \"' cannot be <= 1.\");\n-          }\n         }\n         \n         if (params.containsKey(PARAM_STEP)) {\n           step = (long) params.get(PARAM_STEP);\n-          \n-          if (timestep <= 1) {\n-            throw new WarpScriptException(getName() + \" parameter '\" + PARAM_STEP + \"' cannot be <= 1.\");            \n-          }\n         }\n+\n         double sample = (double) params.getOrDefault(PARAM_SAMPLE, 1.0D);\n         \n         TYPE type = (TYPE) params.get(PARAM_TYPE);\n", "next_change": null}]}, "revised_code_in_main": {"commit": "67019d40559484d9cf2daf23cf83d122822ff274", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/script/functions/FETCH.java b/warp10/src/main/java/io/warp10/script/functions/FETCH.java\nindex 363c70ca..b5748c6a 100644\n--- a/warp10/src/main/java/io/warp10/script/functions/FETCH.java\n+++ b/warp10/src/main/java/io/warp10/script/functions/FETCH.java\n", "chunk": "@@ -455,18 +455,12 @@ public class FETCH extends NamedWarpScriptFunction implements WarpScriptStackFun\n         \n         if (params.containsKey(PARAM_TIMESTEP)) {\n           timestep = (long) params.get(PARAM_TIMESTEP);\n-          if (timestep <= 1) {\n-            throw new WarpScriptException(getName() + \" parameter '\" + PARAM_TIMESTEP + \"' cannot be <= 1.\");\n-          }\n         }\n         \n         if (params.containsKey(PARAM_STEP)) {\n           step = (long) params.get(PARAM_STEP);\n-          \n-          if (timestep <= 1) {\n-            throw new WarpScriptException(getName() + \" parameter '\" + PARAM_STEP + \"' cannot be <= 1.\");            \n-          }\n         }\n+\n         double sample = (double) params.getOrDefault(PARAM_SAMPLE, 1.0D);\n         \n         TYPE type = (TYPE) params.get(PARAM_TYPE);\n", "next_change": {"commit": "bac1b37dad8f131029215e15be238968ce8deb99", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/script/functions/FETCH.java b/warp10/src/main/java/io/warp10/script/functions/FETCH.java\nindex b5748c6a..b325ba3e 100644\n--- a/warp10/src/main/java/io/warp10/script/functions/FETCH.java\n+++ b/warp10/src/main/java/io/warp10/script/functions/FETCH.java\n", "chunk": "@@ -449,18 +495,7 @@ public class FETCH extends NamedWarpScriptFunction implements WarpScriptStackFun\n         }\n \n         long then = (long) params.get(PARAM_START);\n-        long skip = (long) params.getOrDefault(PARAM_SKIP, 0L);\n-        long timestep = 1L;\n-        long step = 1L;\n-        \n-        if (params.containsKey(PARAM_TIMESTEP)) {\n-          timestep = (long) params.get(PARAM_TIMESTEP);\n-        }\n-        \n-        if (params.containsKey(PARAM_STEP)) {\n-          step = (long) params.get(PARAM_STEP);\n-        }\n-\n+        long skip = (long) params.getOrDefault(PARAM_SKIP, 0L);        \n         double sample = (double) params.getOrDefault(PARAM_SAMPLE, 1.0D);\n         \n         TYPE type = (TYPE) params.get(PARAM_TYPE);\n", "next_change": {"commit": "e126ef9071a16208c0791945ed71d802b88f1bc3", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/script/functions/FETCH.java b/warp10/src/main/java/io/warp10/script/functions/FETCH.java\nindex b325ba3e..2cec3527 100644\n--- a/warp10/src/main/java/io/warp10/script/functions/FETCH.java\n+++ b/warp10/src/main/java/io/warp10/script/functions/FETCH.java\n", "chunk": "@@ -495,7 +495,18 @@ public class FETCH extends NamedWarpScriptFunction implements WarpScriptStackFun\n         }\n \n         long then = (long) params.get(PARAM_START);\n-        long skip = (long) params.getOrDefault(PARAM_SKIP, 0L);        \n+        long skip = (long) params.getOrDefault(PARAM_SKIP, 0L);\n+        long timestep = 1L;\n+        long step = 1L;\n+        \n+        if (params.containsKey(PARAM_TIMESTEP)) {\n+          timestep = (long) params.get(PARAM_TIMESTEP);\n+        }\n+        \n+        if (params.containsKey(PARAM_STEP)) {\n+          step = (long) params.get(PARAM_STEP);\n+        }\n+\n         double sample = (double) params.getOrDefault(PARAM_SAMPLE, 1.0D);\n         \n         TYPE type = (TYPE) params.get(PARAM_TYPE);\n", "next_change": {"commit": "7f1f411b42ba257811ed7443293c2129eaa62afb", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/script/functions/FETCH.java b/warp10/src/main/java/io/warp10/script/functions/FETCH.java\nindex 2cec3527..0f36d1d5 100644\n--- a/warp10/src/main/java/io/warp10/script/functions/FETCH.java\n+++ b/warp10/src/main/java/io/warp10/script/functions/FETCH.java\n", "chunk": "@@ -498,17 +515,17 @@ public class FETCH extends NamedWarpScriptFunction implements WarpScriptStackFun\n         long skip = (long) params.getOrDefault(PARAM_SKIP, 0L);\n         long timestep = 1L;\n         long step = 1L;\n-        \n+\n         if (params.containsKey(PARAM_TIMESTEP)) {\n           timestep = (long) params.get(PARAM_TIMESTEP);\n         }\n-        \n+\n         if (params.containsKey(PARAM_STEP)) {\n           step = (long) params.get(PARAM_STEP);\n         }\n \n         double sample = (double) params.getOrDefault(PARAM_SAMPLE, 1.0D);\n-        \n+\n         TYPE type = (TYPE) params.get(PARAM_TYPE);\n \n         if (null != this.forcedType) {\n", "next_change": null}]}}]}}]}}]}, "commits_in_main": [{"oid": "67019d40559484d9cf2daf23cf83d122822ff274", "message": "Merge commit", "committedDate": null}, {"oid": "bac1b37dad8f131029215e15be238968ce8deb99", "committedDate": "2020-06-20 15:43:23 +0200", "message": "Initial commit of labels priority support"}, {"oid": "32ef8e5f0c4dd54fa889e905d583d8b418c09e92", "committedDate": "2020-07-07 16:47:42 +0200", "message": "Addressed PR comments"}, {"oid": "e126ef9071a16208c0791945ed71d802b88f1bc3", "committedDate": "2020-07-28 08:55:35 +0200", "message": "Merge branch 'master' into directory-match"}, {"oid": "551d6c7b184d9874baa236fb282d165fb4c8fc19", "committedDate": "2020-10-09 11:22:20 +0200", "message": "Added support for fetching HBase cell TTLs."}, {"oid": "7f1f411b42ba257811ed7443293c2129eaa62afb", "committedDate": "2021-02-10 09:16:07 +0100", "message": "Added support for FETCH to return GTSEncoders"}, {"oid": "422508048439eee2ff235734c484cd038d51d9dc", "committedDate": "2021-02-10 15:49:55 +0100", "message": "Addressed PR comment"}, {"oid": "5391746198caf205379f27ed8869286209c6bc54", "committedDate": "2021-04-21 11:26:20 +0200", "message": "Add .noauth, .nometa and .nofetch attributes for read tokens"}, {"oid": "f37f2517302d88a7f952ba4f8023214f1cc76fd1", "committedDate": "2021-04-21 19:26:26 +0200", "message": "Add function name and cause to the WSE"}, {"oid": "fcf98bc9b20399739c3007cceb18e129dc683b3e", "committedDate": "2021-04-27 12:32:10 +0200", "message": "Change .nometa to .nofind for read tokens"}, {"oid": "df2d4ff8f00f630f3fd1cd01492bb3cfe63235cf", "committedDate": "2021-05-03 14:48:47 +0200", "message": "Merge pull request #955 from ftence/rtoken_noauth"}, {"oid": "741c6bcdea66d186d33e5e554e7edf4548d3fc34", "committedDate": "2021-07-09 08:49:42 +0200", "message": "Added token attributes for controling various FETCH parameters"}, {"oid": "74a9671e6abedd2b5bb1f0baa0dcadf72f0f3d58", "committedDate": "2021-07-09 10:53:57 +0200", "message": "Added support for token attributes in EgressFetchHandler"}, {"oid": "e826ea374df18f9d0ff413872ebf5ddd1ad0bd17", "committedDate": "2021-07-12 15:23:43 +0200", "message": "Remove unused variables and fields"}, {"oid": "ca6bdb3976d3b4a2f7bc13725de60be114969521", "committedDate": "2021-07-13 11:12:49 +0200", "message": "Addressed PR comments"}, {"oid": "1b6bc07dbe0c323cfed1f9ecef2eeb65c67bd2c0", "committedDate": "2021-07-15 17:34:28 +0200", "message": "Addressed PR comments"}, {"oid": "f21f8f77ac3618283721a8321564afa8a332dad0", "committedDate": "2021-07-16 14:11:10 +0200", "message": "Resolved merge conflict"}, {"oid": "26002aeed308fffbfca57e8b4c49f6eca9048f77", "committedDate": "2021-08-10 09:45:09 +0200", "message": "Error message fallbacks to classname when exception have no message"}, {"oid": "07d6674455d859d58ee5b060b9d4f02aa3081722", "committedDate": "2021-08-24 15:33:58 +0200", "message": "Added checking of thread interruption to allow for early exit from scanning loops."}, {"oid": "d5e7140597be27e5c42e4c95c3b1e3b6f1fc6d06", "committedDate": "2021-08-24 16:04:42 +0200", "message": "Resolved conflict"}, {"oid": "16a1dac87d320a08cb0bb058dadb81ba75302fe2", "committedDate": "2021-08-24 16:14:40 +0200", "message": "Addressed PR comments"}, {"oid": "ae4f9a237a7ff94b66585daecf0edd47287409fc", "committedDate": "2021-08-25 11:00:15 +0200", "message": "Merge pull request #989 from hbs/token.fetchattributes"}, {"oid": "a736b000b485c80f73ff1212f27ec3c7f4873ae9", "committedDate": "2021-10-19 16:22:11 +0200", "message": "Addressed PR comments. Added params gskip/gcount to FETCH and FIND"}, {"oid": "fa3abe832a7c7bfc43e0a77b1da64f1c493252e4", "committedDate": "2021-10-19 17:00:31 +0200", "message": "Renamed variable"}, {"oid": "3eb7452f98d09229b0fbe0e73f83827fb2560c5e", "committedDate": "2021-10-20 15:27:36 +0200", "message": "Fixed conditional bug. Changed HashSet instances into LinkedHashSet to retain order"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTY0OTQ3Mg==", "url": "https://github.com/senx/warp10-platform/pull/772#discussion_r441649472", "body": "`step < 1L`", "bodyText": "step < 1L", "bodyHTML": "<p dir=\"auto\"><code>step &lt; 1L</code></p>", "author": "ftence", "createdAt": "2020-06-17T15:49:51Z", "path": "warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java", "diffHunk": "@@ -127,6 +140,21 @@ public GTSDecoderIterator fetch(final ReadToken token, final List<Metadata> meta\n       throw new RuntimeException(\"No support for write timestamp retrieval.\");\n     }\n     \n+    if (step <= 1L) {", "originalCommit": "e07598603051ad7fa838f08bfec01a2aa247f958", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "879ad4092491eda3b08f942710d5bdc6b1e90c69", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java b/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\nindex b08de148..a976cc72 100644\n--- a/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\n+++ b/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\n", "chunk": "@@ -140,11 +140,11 @@ public class StandaloneStoreClient implements StoreClient {\n       throw new RuntimeException(\"No support for write timestamp retrieval.\");\n     }\n     \n-    if (step <= 1L) {\n+    if (step < 1L) {\n       step = 1L;\n     }\n     \n-    if (timestep <= 1L) {\n+    if (timestep < 1L) {\n       timestep = 1L;\n     }\n     \n", "next_change": null}]}, "revised_code_in_main": {"commit": "67019d40559484d9cf2daf23cf83d122822ff274", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java b/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\nindex b08de148..dedaf065 100644\n--- a/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\n+++ b/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\n", "chunk": "@@ -140,11 +140,11 @@ public class StandaloneStoreClient implements StoreClient {\n       throw new RuntimeException(\"No support for write timestamp retrieval.\");\n     }\n     \n-    if (step <= 1L) {\n+    if (step < 1L) {\n       step = 1L;\n     }\n     \n-    if (timestep <= 1L) {\n+    if (timestep < 1L) {\n       timestep = 1L;\n     }\n     \n", "next_change": {"commit": "476264a63117e1b45ed6c8fdd0cb5acb419901d7", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java b/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\nindex dedaf065..4a3f6181 100644\n--- a/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\n+++ b/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\n", "chunk": "@@ -110,44 +115,44 @@ public class StandaloneStoreClient implements StoreClient {\n     if (postBoundary < 0) {\n       postBoundary = 0;\n     }\n-     \n+\n     if (sample <= 0.0D || sample > 1.0D) {\n       sample = 1.0D;\n     }\n-    \n+\n     if (skip < 0) {\n       skip = 0;\n     }\n-    \n+\n     if (count < -1L) {\n       count = -1L;\n     }\n-        \n+\n     //\n     // If we are fetching up to Long.MAX_VALUE, then don't fetch a post boundary\n     if (Long.MAX_VALUE == now) {\n       postBoundary = 0;\n     }\n-    \n+\n     //\n     // If we are fetching from Long.MIN_VALUE, then don't fetch a pre boundary\n     //\n     if (Long.MIN_VALUE == then) {\n       preBoundary = 0;\n     }\n-    \n+\n     if (writeTimestamp) {\n       throw new RuntimeException(\"No support for write timestamp retrieval.\");\n     }\n-    \n+\n     if (step < 1L) {\n       step = 1L;\n     }\n-    \n+\n     if (timestep < 1L) {\n       timestep = 1L;\n     }\n-    \n+\n     final boolean hasStep = 1L != step;\n     final boolean hasTimestep = 1L != timestep;\n     final long fstep = step;\n", "next_change": null}]}}]}, "commits_in_main": [{"oid": "67019d40559484d9cf2daf23cf83d122822ff274", "message": "Merge commit", "committedDate": null}, {"oid": "3278f804361426912bb99824452c1808c1359d49", "committedDate": "2020-10-14 21:29:11 +0200", "message": "Fixed possible deadlock in doOffline during a delete"}, {"oid": "7e9444a6cf22c1843e90345ee9c2e4de97aa57cc", "committedDate": "2020-10-14 23:28:38 +0200", "message": "Added writeUnlocked to use for deletes to avoid deadlock in doOffline"}, {"oid": "8893fcfa43ec1004a6ad1ec8319cf9d324f1a8e9", "committedDate": "2021-01-19 17:50:15 +0100", "message": "Fix conditions to allow postboundary when at the end of the keyspace"}, {"oid": "df8b3f86f63a132d560b01807c7df69179eabb9e", "committedDate": "2021-03-16 13:17:53 +0100", "message": "Fix fields reinitialization when handling a new GTS"}, {"oid": "476264a63117e1b45ed6c8fdd0cb5acb419901d7", "committedDate": "2021-07-07 15:01:48 +0200", "message": "Exposed options for controlling cache and checksums when deleting data"}, {"oid": "13b516eb487a08297af14f2762902457a65adadf", "committedDate": "2021-07-09 08:52:23 +0200", "message": "Fixed batch closing and write method called."}, {"oid": "f84a8b5337f7b24272558e0d9c55032305c6efd8", "committedDate": "2021-07-09 17:29:44 +0200", "message": "Resolved conflict"}, {"oid": "8efab4d85ed5bc685243821d6cef21a5704fd7b2", "committedDate": "2021-07-15 16:54:56 +0200", "message": "Addressed PR comments"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTY0OTc1Nw==", "url": "https://github.com/senx/warp10-platform/pull/772#discussion_r441649757", "body": "`timestep < 1L`", "bodyText": "timestep < 1L", "bodyHTML": "<p dir=\"auto\"><code>timestep &lt; 1L</code></p>", "author": "ftence", "createdAt": "2020-06-17T15:50:15Z", "path": "warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java", "diffHunk": "@@ -127,6 +140,21 @@ public GTSDecoderIterator fetch(final ReadToken token, final List<Metadata> meta\n       throw new RuntimeException(\"No support for write timestamp retrieval.\");\n     }\n     \n+    if (step <= 1L) {\n+      step = 1L;\n+    }\n+    \n+    if (timestep <= 1L) {", "originalCommit": "e07598603051ad7fa838f08bfec01a2aa247f958", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "879ad4092491eda3b08f942710d5bdc6b1e90c69", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java b/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\nindex b08de148..a976cc72 100644\n--- a/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\n+++ b/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\n", "chunk": "@@ -140,11 +140,11 @@ public class StandaloneStoreClient implements StoreClient {\n       throw new RuntimeException(\"No support for write timestamp retrieval.\");\n     }\n     \n-    if (step <= 1L) {\n+    if (step < 1L) {\n       step = 1L;\n     }\n     \n-    if (timestep <= 1L) {\n+    if (timestep < 1L) {\n       timestep = 1L;\n     }\n     \n", "next_change": null}]}, "revised_code_in_main": {"commit": "67019d40559484d9cf2daf23cf83d122822ff274", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java b/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\nindex b08de148..dedaf065 100644\n--- a/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\n+++ b/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\n", "chunk": "@@ -140,11 +140,11 @@ public class StandaloneStoreClient implements StoreClient {\n       throw new RuntimeException(\"No support for write timestamp retrieval.\");\n     }\n     \n-    if (step <= 1L) {\n+    if (step < 1L) {\n       step = 1L;\n     }\n     \n-    if (timestep <= 1L) {\n+    if (timestep < 1L) {\n       timestep = 1L;\n     }\n     \n", "next_change": {"commit": "476264a63117e1b45ed6c8fdd0cb5acb419901d7", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java b/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\nindex dedaf065..4a3f6181 100644\n--- a/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\n+++ b/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\n", "chunk": "@@ -110,44 +115,44 @@ public class StandaloneStoreClient implements StoreClient {\n     if (postBoundary < 0) {\n       postBoundary = 0;\n     }\n-     \n+\n     if (sample <= 0.0D || sample > 1.0D) {\n       sample = 1.0D;\n     }\n-    \n+\n     if (skip < 0) {\n       skip = 0;\n     }\n-    \n+\n     if (count < -1L) {\n       count = -1L;\n     }\n-        \n+\n     //\n     // If we are fetching up to Long.MAX_VALUE, then don't fetch a post boundary\n     if (Long.MAX_VALUE == now) {\n       postBoundary = 0;\n     }\n-    \n+\n     //\n     // If we are fetching from Long.MIN_VALUE, then don't fetch a pre boundary\n     //\n     if (Long.MIN_VALUE == then) {\n       preBoundary = 0;\n     }\n-    \n+\n     if (writeTimestamp) {\n       throw new RuntimeException(\"No support for write timestamp retrieval.\");\n     }\n-    \n+\n     if (step < 1L) {\n       step = 1L;\n     }\n-    \n+\n     if (timestep < 1L) {\n       timestep = 1L;\n     }\n-    \n+\n     final boolean hasStep = 1L != step;\n     final boolean hasTimestep = 1L != timestep;\n     final long fstep = step;\n", "next_change": null}]}}]}, "commits_in_main": [{"oid": "67019d40559484d9cf2daf23cf83d122822ff274", "message": "Merge commit", "committedDate": null}, {"oid": "3278f804361426912bb99824452c1808c1359d49", "committedDate": "2020-10-14 21:29:11 +0200", "message": "Fixed possible deadlock in doOffline during a delete"}, {"oid": "7e9444a6cf22c1843e90345ee9c2e4de97aa57cc", "committedDate": "2020-10-14 23:28:38 +0200", "message": "Added writeUnlocked to use for deletes to avoid deadlock in doOffline"}, {"oid": "8893fcfa43ec1004a6ad1ec8319cf9d324f1a8e9", "committedDate": "2021-01-19 17:50:15 +0100", "message": "Fix conditions to allow postboundary when at the end of the keyspace"}, {"oid": "df8b3f86f63a132d560b01807c7df69179eabb9e", "committedDate": "2021-03-16 13:17:53 +0100", "message": "Fix fields reinitialization when handling a new GTS"}, {"oid": "476264a63117e1b45ed6c8fdd0cb5acb419901d7", "committedDate": "2021-07-07 15:01:48 +0200", "message": "Exposed options for controlling cache and checksums when deleting data"}, {"oid": "13b516eb487a08297af14f2762902457a65adadf", "committedDate": "2021-07-09 08:52:23 +0200", "message": "Fixed batch closing and write method called."}, {"oid": "f84a8b5337f7b24272558e0d9c55032305c6efd8", "committedDate": "2021-07-09 17:29:44 +0200", "message": "Resolved conflict"}, {"oid": "8efab4d85ed5bc685243821d6cef21a5704fd7b2", "committedDate": "2021-07-15 16:54:56 +0200", "message": "Addressed PR comments"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTY1NTE3OA==", "url": "https://github.com/senx/warp10-platform/pull/772#discussion_r441655178", "body": "Same comments:\r\n- `subtractExact`\r\n- `Long.MIN_VALUE` is a valid timestamp", "bodyText": "Same comments:\n\nsubtractExact\nLong.MIN_VALUE is a valid timestamp", "bodyHTML": "<p dir=\"auto\">Same comments:</p>\n<ul dir=\"auto\">\n<li><code>subtractExact</code></li>\n<li><code>Long.MIN_VALUE</code> is a valid timestamp</li>\n</ul>", "author": "ftence", "createdAt": "2020-06-17T15:58:16Z", "path": "warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java", "diffHunk": "@@ -323,6 +355,62 @@ public GTSDecoder next() {\n               continue;\n             }\n             \n+            //\n+            // Check that the datapoint timestamp is compatible with the timestep parameter, i.e. it is at least\n+            // 'timestep' time units before the previous one we selected\n+            //\n+            \n+            if (basets > nextTimestamp) {\n+              continue;\n+            }\n+\n+            //\n+            // Compute the new value of nextTimestamp if timestep is set\n+            //\n+            if (hasTimestep) {\n+              try {\n+                nextTimestamp = Math.addExact(basets, -timestep);\n+              } catch (ArithmeticException ae) {\n+                nextTimestamp = Long.MIN_VALUE;\n+              }", "originalCommit": "e07598603051ad7fa838f08bfec01a2aa247f958", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "879ad4092491eda3b08f942710d5bdc6b1e90c69", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java b/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\nindex b08de148..a976cc72 100644\n--- a/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\n+++ b/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\n", "chunk": "@@ -369,9 +369,10 @@ public class StandaloneStoreClient implements StoreClient {\n             //\n             if (hasTimestep) {\n               try {\n-                nextTimestamp = Math.addExact(basets, -timestep);\n+                nextTimestamp = Math.subtractExact(basets, timestep);\n               } catch (ArithmeticException ae) {\n                 nextTimestamp = Long.MIN_VALUE;\n+                nvalues = 0L;\n               }\n              \n               // TODO(hbs): should we apply a heuristics to determine if we should seek or not?\n", "next_change": null}]}, "revised_code_in_main": {"commit": "67019d40559484d9cf2daf23cf83d122822ff274", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java b/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\nindex b08de148..dedaf065 100644\n--- a/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\n+++ b/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\n", "chunk": "@@ -369,9 +369,10 @@ public class StandaloneStoreClient implements StoreClient {\n             //\n             if (hasTimestep) {\n               try {\n-                nextTimestamp = Math.addExact(basets, -timestep);\n+                nextTimestamp = Math.subtractExact(basets, timestep);\n               } catch (ArithmeticException ae) {\n                 nextTimestamp = Long.MIN_VALUE;\n+                nvalues = 0L;\n               }\n              \n               // TODO(hbs): should we apply a heuristics to determine if we should seek or not?\n", "next_change": {"commit": "df8b3f86f63a132d560b01807c7df69179eabb9e", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java b/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\nindex dedaf065..b7177f48 100644\n--- a/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\n+++ b/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\n", "chunk": "@@ -369,7 +390,7 @@ public class StandaloneStoreClient implements StoreClient {\n             //\n             if (hasTimestep) {\n               try {\n-                nextTimestamp = Math.subtractExact(basets, timestep);\n+                nextTimestamp = Math.subtractExact(basets, ftimestep);\n               } catch (ArithmeticException ae) {\n                 nextTimestamp = Long.MIN_VALUE;\n                 nvalues = 0L;\n", "next_change": {"commit": "476264a63117e1b45ed6c8fdd0cb5acb419901d7", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java b/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\nindex b7177f48..4a3f6181 100644\n--- a/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\n+++ b/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\n", "chunk": "@@ -395,7 +401,7 @@ public class StandaloneStoreClient implements StoreClient {\n                 nextTimestamp = Long.MIN_VALUE;\n                 nvalues = 0L;\n               }\n-             \n+\n               // TODO(hbs): should we apply a heuristics to determine if we should seek or not?\n \n               long rowts = Long.MAX_VALUE - nextTimestamp;\n", "next_change": null}]}}]}}]}, "commits_in_main": [{"oid": "67019d40559484d9cf2daf23cf83d122822ff274", "message": "Merge commit", "committedDate": null}, {"oid": "3278f804361426912bb99824452c1808c1359d49", "committedDate": "2020-10-14 21:29:11 +0200", "message": "Fixed possible deadlock in doOffline during a delete"}, {"oid": "7e9444a6cf22c1843e90345ee9c2e4de97aa57cc", "committedDate": "2020-10-14 23:28:38 +0200", "message": "Added writeUnlocked to use for deletes to avoid deadlock in doOffline"}, {"oid": "8893fcfa43ec1004a6ad1ec8319cf9d324f1a8e9", "committedDate": "2021-01-19 17:50:15 +0100", "message": "Fix conditions to allow postboundary when at the end of the keyspace"}, {"oid": "df8b3f86f63a132d560b01807c7df69179eabb9e", "committedDate": "2021-03-16 13:17:53 +0100", "message": "Fix fields reinitialization when handling a new GTS"}, {"oid": "476264a63117e1b45ed6c8fdd0cb5acb419901d7", "committedDate": "2021-07-07 15:01:48 +0200", "message": "Exposed options for controlling cache and checksums when deleting data"}, {"oid": "13b516eb487a08297af14f2762902457a65adadf", "committedDate": "2021-07-09 08:52:23 +0200", "message": "Fixed batch closing and write method called."}, {"oid": "f84a8b5337f7b24272558e0d9c55032305c6efd8", "committedDate": "2021-07-09 17:29:44 +0200", "message": "Resolved conflict"}, {"oid": "8efab4d85ed5bc685243821d6cef21a5704fd7b2", "committedDate": "2021-07-15 16:54:56 +0200", "message": "Addressed PR comments"}]}, {"oid": "879ad4092491eda3b08f942710d5bdc6b1e90c69", "url": "https://github.com/senx/warp10-platform/commit/879ad4092491eda3b08f942710d5bdc6b1e90c69", "message": "Addressed PR comments", "committedDate": "2020-06-19T17:06:51Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkyNzQ3OA==", "url": "https://github.com/senx/warp10-platform/pull/772#discussion_r448927478", "body": "Should be initialized to `0L`, else it will skip the first `step - 1` points found.", "bodyText": "Should be initialized to 0L, else it will skip the first step - 1 points found.", "bodyHTML": "<p dir=\"auto\">Should be initialized to <code>0L</code>, else it will skip the first <code>step - 1</code> points found.</p>", "author": "ftence", "createdAt": "2020-07-02T11:14:04Z", "path": "warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java", "diffHunk": "@@ -230,6 +242,8 @@ public boolean hasNext() {\n     \n     nvalues = count >= 0 ? count : Long.MAX_VALUE;\n     toskip = skip;\n+    steps = hasStep ? step - 1L : 0L;", "originalCommit": "879ad4092491eda3b08f942710d5bdc6b1e90c69", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "abe989e9748cdc10aca949f409ca0bbbf6a2b3a8", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java b/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\nindex 5030cf55..55f1ea0a 100644\n--- a/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\n+++ b/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\n", "chunk": "@@ -242,7 +242,7 @@ public class MultiScanGTSDecoderIterator extends GTSDecoderIterator {\n     \n     nvalues = count >= 0 ? count : Long.MAX_VALUE;\n     toskip = skip;\n-    steps = hasStep ? step - 1L : 0L;\n+    steps = 0L;\n     nextTimestamp = Long.MAX_VALUE;\n     \n     Scan scan = new Scan();\n", "next_change": null}]}, "revised_code_in_main": {"commit": "67019d40559484d9cf2daf23cf83d122822ff274", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java b/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\nindex 5030cf55..55f1ea0a 100644\n--- a/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\n+++ b/warp10/src/main/java/io/warp10/continuum/store/MultiScanGTSDecoderIterator.java\n", "chunk": "@@ -242,7 +242,7 @@ public class MultiScanGTSDecoderIterator extends GTSDecoderIterator {\n     \n     nvalues = count >= 0 ? count : Long.MAX_VALUE;\n     toskip = skip;\n-    steps = hasStep ? step - 1L : 0L;\n+    steps = 0L;\n     nextTimestamp = Long.MAX_VALUE;\n     \n     Scan scan = new Scan();\n", "next_change": null}]}, "commits_in_main": [{"oid": "67019d40559484d9cf2daf23cf83d122822ff274", "message": "Merge commit", "committedDate": null}, {"oid": "551d6c7b184d9874baa236fb282d165fb4c8fc19", "committedDate": "2020-10-09 11:22:20 +0200", "message": "Added support for fetching HBase cell TTLs."}, {"oid": "b85ba7585354c1a93145a000b4e4ba8760cfdc26", "committedDate": "2020-10-12 17:55:15 +0200", "message": "Changed the way the TTL is accessed"}, {"oid": "aab710c7c8534a2f52edc3564a35903184b9af30", "committedDate": "2020-10-13 15:15:09 +0200", "message": "Addressed PR comments."}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk3MTk4Nw==", "url": "https://github.com/senx/warp10-platform/pull/772#discussion_r448971987", "body": "Change `getSkip` to `getStep`.", "bodyText": "Change getSkip to getStep.", "bodyHTML": "<p dir=\"auto\">Change <code>getSkip</code> to <code>getStep</code>.</p>", "author": "ftence", "createdAt": "2020-07-02T12:41:35Z", "path": "warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java", "diffHunk": "@@ -88,8 +89,20 @@ public StandaloneStoreClient(DB db, KeyStore keystore, Properties properties) {\n   }\n   \n   @Override\n-  public GTSDecoderIterator fetch(final ReadToken token, final List<Metadata> metadatas, final long now, final long then, long count, long skip, double sample, boolean writeTimestamp, long preBoundary, long postBoundary) {\n-\n+  public GTSDecoderIterator fetch(FetchRequest req) {\n+    final ReadToken token = req.getToken();\n+    final List<Metadata> metadatas = req.getMetadatas();\n+    final long now = req.getNow();\n+    final long then = req.getThents();\n+    long count = req.getCount();\n+    long skip = req.getSkip();\n+    long step = req.getSkip();", "originalCommit": "879ad4092491eda3b08f942710d5bdc6b1e90c69", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "abe989e9748cdc10aca949f409ca0bbbf6a2b3a8", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java b/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\nindex a976cc72..dedaf065 100644\n--- a/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\n+++ b/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\n", "chunk": "@@ -96,7 +96,7 @@ public class StandaloneStoreClient implements StoreClient {\n     final long then = req.getThents();\n     long count = req.getCount();\n     long skip = req.getSkip();\n-    long step = req.getSkip();\n+    long step = req.getStep();\n     long timestep = req.getTimestep();\n     double sample = req.getSample();\n     long preBoundary = req.getPreBoundary();\n", "next_change": null}]}, "revised_code_in_main": {"commit": "67019d40559484d9cf2daf23cf83d122822ff274", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java b/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\nindex a976cc72..dedaf065 100644\n--- a/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\n+++ b/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\n", "chunk": "@@ -96,7 +96,7 @@ public class StandaloneStoreClient implements StoreClient {\n     final long then = req.getThents();\n     long count = req.getCount();\n     long skip = req.getSkip();\n-    long step = req.getSkip();\n+    long step = req.getStep();\n     long timestep = req.getTimestep();\n     double sample = req.getSample();\n     long preBoundary = req.getPreBoundary();\n", "next_change": {"commit": "476264a63117e1b45ed6c8fdd0cb5acb419901d7", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java b/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\nindex dedaf065..4a3f6181 100644\n--- a/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\n+++ b/warp10/src/main/java/io/warp10/standalone/StandaloneStoreClient.java\n", "chunk": "@@ -102,7 +107,7 @@ public class StandaloneStoreClient implements StoreClient {\n     long preBoundary = req.getPreBoundary();\n     long postBoundary = req.getPostBoundary();\n     final boolean writeTimestamp = req.isWriteTimestamp();\n-    \n+\n     if (preBoundary < 0) {\n       preBoundary = 0;\n     }\n", "next_change": null}]}}]}, "commits_in_main": [{"oid": "67019d40559484d9cf2daf23cf83d122822ff274", "message": "Merge commit", "committedDate": null}, {"oid": "3278f804361426912bb99824452c1808c1359d49", "committedDate": "2020-10-14 21:29:11 +0200", "message": "Fixed possible deadlock in doOffline during a delete"}, {"oid": "7e9444a6cf22c1843e90345ee9c2e4de97aa57cc", "committedDate": "2020-10-14 23:28:38 +0200", "message": "Added writeUnlocked to use for deletes to avoid deadlock in doOffline"}, {"oid": "8893fcfa43ec1004a6ad1ec8319cf9d324f1a8e9", "committedDate": "2021-01-19 17:50:15 +0100", "message": "Fix conditions to allow postboundary when at the end of the keyspace"}, {"oid": "df8b3f86f63a132d560b01807c7df69179eabb9e", "committedDate": "2021-03-16 13:17:53 +0100", "message": "Fix fields reinitialization when handling a new GTS"}, {"oid": "476264a63117e1b45ed6c8fdd0cb5acb419901d7", "committedDate": "2021-07-07 15:01:48 +0200", "message": "Exposed options for controlling cache and checksums when deleting data"}, {"oid": "13b516eb487a08297af14f2762902457a65adadf", "committedDate": "2021-07-09 08:52:23 +0200", "message": "Fixed batch closing and write method called."}, {"oid": "f84a8b5337f7b24272558e0d9c55032305c6efd8", "committedDate": "2021-07-09 17:29:44 +0200", "message": "Resolved conflict"}, {"oid": "8efab4d85ed5bc685243821d6cef21a5704fd7b2", "committedDate": "2021-07-15 16:54:56 +0200", "message": "Addressed PR comments"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTA5NzY5MA==", "url": "https://github.com/senx/warp10-platform/pull/772#discussion_r449097690", "body": "Initialize it to 0L else the first `this.request.getStep() - 1` will be stepped over.", "bodyText": "Initialize it to 0L else the first this.request.getStep() - 1 will be stepped over.", "bodyHTML": "<p dir=\"auto\">Initialize it to 0L else the first <code>this.request.getStep() - 1</code> will be stepped over.</p>", "author": "ftence", "createdAt": "2020-07-02T15:38:57Z", "path": "warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java", "diffHunk": "@@ -246,19 +266,42 @@ public GTSDecoder next() {\n         resultCount++;\n       }\n \n-      // Encode this in ISO_8859_1 so we are sure every possible byte sequence is valid\n-      // FIXME(hbs): instead of doing a Arrays.copyOfRange, use new String(byte[],offset,len,charset)\n-      String classlabelsid = new String(Arrays.copyOfRange(result.getRow(), Constants.HBASE_RAW_DATA_KEY_PREFIX.length, Constants.HBASE_RAW_DATA_KEY_PREFIX.length + 16), StandardCharsets.ISO_8859_1);\n+      //\n+      // Compare the class and labels id with those in currentGTS\n+      // If they differ, recompute currentGTSString\n+      //\n+      \n+      if (0 != Bytes.compareTo(currentGTS, 0, 16, result.getRow(), Constants.HBASE_RAW_DATA_KEY_PREFIX.length, 16)) {\n+        System.arraycopy(result.getRow(), Constants.HBASE_RAW_DATA_KEY_PREFIX.length, currentGTS, 0, currentGTS.length);\n+        currentGTSString = new String(currentGTS, StandardCharsets.ISO_8859_1);\n+      }\n+\n+      String classlabelsid = currentGTSString;\n     \n+      //\n+      // Extract the Metadata associated with the current row\n+      //\n       Metadata metadata = this.metadatas.get(classlabelsid);\n \n       //\n-      // The current row is for a different GTS, return the current encoder and record the current result\n-      //\n-      \n-      if (encoder.size() > 0 && (encoder.getClassId() != metadata.getClassId() || encoder.getLabelsId() != metadata.getLabelsId())) {\n+      // The current row is for a different GTS.\n+      // If the current encoder has data, return it and record the current result for the next call to 'next'\n+      // If the current encoder has no data (which could happen if we have reached the requested number of results),\n+      // update the metadata\n+      //      \n+      if ((encoder.getClassId() != metadata.getClassId() || encoder.getLabelsId() != metadata.getLabelsId())) {\n+        // Save result in pendingresult as we have not yet read the associated cells\n         this.pendingresult = result;\n-        return encoder.getDecoder();\n+        //\n+        // Reset fetch parameters\n+        //\n+        this.nvalues = this.count >= 0 ? this.count : Long.MAX_VALUE;\n+        this.skip = this.request.getSkip();\n+        this.steps = this.hasStep ? this.request.getStep() - 1 : 0L;", "originalCommit": "879ad4092491eda3b08f942710d5bdc6b1e90c69", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "abe989e9748cdc10aca949f409ca0bbbf6a2b3a8", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java b/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\nindex f7c6ffe3..b003357d 100644\n--- a/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\n+++ b/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\n", "chunk": "@@ -290,16 +290,16 @@ public class SlicedRowFilterGTSDecoderIterator extends GTSDecoderIterator implem\n       // update the metadata\n       //      \n       if ((encoder.getClassId() != metadata.getClassId() || encoder.getLabelsId() != metadata.getLabelsId())) {\n-        // Save result in pendingresult as we have not yet read the associated cells\n-        this.pendingresult = result;\n         //\n         // Reset fetch parameters\n         //\n         this.nvalues = this.count >= 0 ? this.count : Long.MAX_VALUE;\n         this.skip = this.request.getSkip();\n-        this.steps = this.hasStep ? this.request.getStep() - 1 : 0L;\n+        this.steps = 0L;\n         this.nextTimestamp = Long.MAX_VALUE;\n         if (encoder.size() > 0) {\n+          // Save result in pendingresult as we have not yet read the associated cells\n+          this.pendingresult = result;\n           return encoder.getDecoder();\n         }\n       }\n", "next_change": null}]}, "revised_code_in_main": {"commit": "67019d40559484d9cf2daf23cf83d122822ff274", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java b/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\nindex f7c6ffe3..a20d2102 100644\n--- a/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\n+++ b/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\n", "chunk": "@@ -290,16 +290,16 @@ public class SlicedRowFilterGTSDecoderIterator extends GTSDecoderIterator implem\n       // update the metadata\n       //      \n       if ((encoder.getClassId() != metadata.getClassId() || encoder.getLabelsId() != metadata.getLabelsId())) {\n-        // Save result in pendingresult as we have not yet read the associated cells\n-        this.pendingresult = result;\n         //\n         // Reset fetch parameters\n         //\n         this.nvalues = this.count >= 0 ? this.count : Long.MAX_VALUE;\n         this.skip = this.request.getSkip();\n-        this.steps = this.hasStep ? this.request.getStep() - 1 : 0L;\n+        this.steps = 0L;\n         this.nextTimestamp = Long.MAX_VALUE;\n         if (encoder.size() > 0) {\n+          // Save result in pendingresult as we have not yet read the associated cells\n+          this.pendingresult = result;\n           return encoder.getDecoder();\n         }\n       }\n", "next_change": null}]}, "commits_in_main": [{"oid": "67019d40559484d9cf2daf23cf83d122822ff274", "message": "Merge commit", "committedDate": null}, {"oid": "551d6c7b184d9874baa236fb282d165fb4c8fc19", "committedDate": "2020-10-09 11:22:20 +0200", "message": "Added support for fetching HBase cell TTLs."}, {"oid": "b85ba7585354c1a93145a000b4e4ba8760cfdc26", "committedDate": "2020-10-12 17:55:15 +0200", "message": "Changed the way the TTL is accessed"}, {"oid": "aab710c7c8534a2f52edc3564a35903184b9af30", "committedDate": "2020-10-13 15:15:09 +0200", "message": "Addressed PR comments."}, {"oid": "af1b59eca2ba863201d0ba10053e2d9d41107a02", "committedDate": "2021-07-09 16:01:15 +0200", "message": "Clean binary search implementation in SlicedRowFilter"}, {"oid": "a3c8881ee677f662ac9402f7571b20030003bd90", "committedDate": "2021-07-09 16:08:18 +0200", "message": "Updated copyright"}, {"oid": "e826ea374df18f9d0ff413872ebf5ddd1ad0bd17", "committedDate": "2021-07-12 15:23:43 +0200", "message": "Remove unused variables and fields"}, {"oid": "97981237e5fbd2ca4f8991cc267c9cb476d448cd", "committedDate": "2021-09-08 16:29:23 +0200", "message": "Merge branch 'master' into slicedrowfilter_binarysearch"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTEwNjY0Mw==", "url": "https://github.com/senx/warp10-platform/pull/772#discussion_r449106643", "body": "Do that only if `encoder.size() > 0` ie. move that in the `if` few lines below.\r\n\r\nThis one is tricky and took me a lot of time to debug:\r\nIf `encoder` has empty metadata (first metadata in the list) it is considered as a change of metadata. Thus it will not trigger the `return` in the `if` below and `result` will be processed. However, `result` will be also stored in `pendingresult` so it will be reprocessed, resulting in duplicate datapoints in the resulting decoder.", "bodyText": "Do that only if encoder.size() > 0 ie. move that in the if few lines below.\nThis one is tricky and took me a lot of time to debug:\nIf encoder has empty metadata (first metadata in the list) it is considered as a change of metadata. Thus it will not trigger the return in the if below and result will be processed. However, result will be also stored in pendingresult so it will be reprocessed, resulting in duplicate datapoints in the resulting decoder.", "bodyHTML": "<p dir=\"auto\">Do that only if <code>encoder.size() &gt; 0</code> ie. move that in the <code>if</code> few lines below.</p>\n<p dir=\"auto\">This one is tricky and took me a lot of time to debug:<br>\nIf <code>encoder</code> has empty metadata (first metadata in the list) it is considered as a change of metadata. Thus it will not trigger the <code>return</code> in the <code>if</code> below and <code>result</code> will be processed. However, <code>result</code> will be also stored in <code>pendingresult</code> so it will be reprocessed, resulting in duplicate datapoints in the resulting decoder.</p>", "author": "ftence", "createdAt": "2020-07-02T15:46:16Z", "path": "warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java", "diffHunk": "@@ -246,19 +266,42 @@ public GTSDecoder next() {\n         resultCount++;\n       }\n \n-      // Encode this in ISO_8859_1 so we are sure every possible byte sequence is valid\n-      // FIXME(hbs): instead of doing a Arrays.copyOfRange, use new String(byte[],offset,len,charset)\n-      String classlabelsid = new String(Arrays.copyOfRange(result.getRow(), Constants.HBASE_RAW_DATA_KEY_PREFIX.length, Constants.HBASE_RAW_DATA_KEY_PREFIX.length + 16), StandardCharsets.ISO_8859_1);\n+      //\n+      // Compare the class and labels id with those in currentGTS\n+      // If they differ, recompute currentGTSString\n+      //\n+      \n+      if (0 != Bytes.compareTo(currentGTS, 0, 16, result.getRow(), Constants.HBASE_RAW_DATA_KEY_PREFIX.length, 16)) {\n+        System.arraycopy(result.getRow(), Constants.HBASE_RAW_DATA_KEY_PREFIX.length, currentGTS, 0, currentGTS.length);\n+        currentGTSString = new String(currentGTS, StandardCharsets.ISO_8859_1);\n+      }\n+\n+      String classlabelsid = currentGTSString;\n     \n+      //\n+      // Extract the Metadata associated with the current row\n+      //\n       Metadata metadata = this.metadatas.get(classlabelsid);\n \n       //\n-      // The current row is for a different GTS, return the current encoder and record the current result\n-      //\n-      \n-      if (encoder.size() > 0 && (encoder.getClassId() != metadata.getClassId() || encoder.getLabelsId() != metadata.getLabelsId())) {\n+      // The current row is for a different GTS.\n+      // If the current encoder has data, return it and record the current result for the next call to 'next'\n+      // If the current encoder has no data (which could happen if we have reached the requested number of results),\n+      // update the metadata\n+      //      \n+      if ((encoder.getClassId() != metadata.getClassId() || encoder.getLabelsId() != metadata.getLabelsId())) {\n+        // Save result in pendingresult as we have not yet read the associated cells\n         this.pendingresult = result;", "originalCommit": "879ad4092491eda3b08f942710d5bdc6b1e90c69", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTIwMzIxNw==", "url": "https://github.com/senx/warp10-platform/pull/772#discussion_r449203217", "bodyText": "Comment is for line this.pendingresult = result;, GitHub messed this up.", "author": "ftence", "createdAt": "2020-07-02T18:39:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTEwNjY0Mw=="}], "type": "inlineReview", "revised_code": {"commit": "abe989e9748cdc10aca949f409ca0bbbf6a2b3a8", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java b/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\nindex f7c6ffe3..b003357d 100644\n--- a/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\n+++ b/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\n", "chunk": "@@ -290,16 +290,16 @@ public class SlicedRowFilterGTSDecoderIterator extends GTSDecoderIterator implem\n       // update the metadata\n       //      \n       if ((encoder.getClassId() != metadata.getClassId() || encoder.getLabelsId() != metadata.getLabelsId())) {\n-        // Save result in pendingresult as we have not yet read the associated cells\n-        this.pendingresult = result;\n         //\n         // Reset fetch parameters\n         //\n         this.nvalues = this.count >= 0 ? this.count : Long.MAX_VALUE;\n         this.skip = this.request.getSkip();\n-        this.steps = this.hasStep ? this.request.getStep() - 1 : 0L;\n+        this.steps = 0L;\n         this.nextTimestamp = Long.MAX_VALUE;\n         if (encoder.size() > 0) {\n+          // Save result in pendingresult as we have not yet read the associated cells\n+          this.pendingresult = result;\n           return encoder.getDecoder();\n         }\n       }\n", "next_change": null}]}, "revised_code_in_main": {"commit": "67019d40559484d9cf2daf23cf83d122822ff274", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java b/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\nindex f7c6ffe3..a20d2102 100644\n--- a/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\n+++ b/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\n", "chunk": "@@ -290,16 +290,16 @@ public class SlicedRowFilterGTSDecoderIterator extends GTSDecoderIterator implem\n       // update the metadata\n       //      \n       if ((encoder.getClassId() != metadata.getClassId() || encoder.getLabelsId() != metadata.getLabelsId())) {\n-        // Save result in pendingresult as we have not yet read the associated cells\n-        this.pendingresult = result;\n         //\n         // Reset fetch parameters\n         //\n         this.nvalues = this.count >= 0 ? this.count : Long.MAX_VALUE;\n         this.skip = this.request.getSkip();\n-        this.steps = this.hasStep ? this.request.getStep() - 1 : 0L;\n+        this.steps = 0L;\n         this.nextTimestamp = Long.MAX_VALUE;\n         if (encoder.size() > 0) {\n+          // Save result in pendingresult as we have not yet read the associated cells\n+          this.pendingresult = result;\n           return encoder.getDecoder();\n         }\n       }\n", "next_change": null}]}, "commits_in_main": [{"oid": "67019d40559484d9cf2daf23cf83d122822ff274", "message": "Merge commit", "committedDate": null}, {"oid": "551d6c7b184d9874baa236fb282d165fb4c8fc19", "committedDate": "2020-10-09 11:22:20 +0200", "message": "Added support for fetching HBase cell TTLs."}, {"oid": "b85ba7585354c1a93145a000b4e4ba8760cfdc26", "committedDate": "2020-10-12 17:55:15 +0200", "message": "Changed the way the TTL is accessed"}, {"oid": "aab710c7c8534a2f52edc3564a35903184b9af30", "committedDate": "2020-10-13 15:15:09 +0200", "message": "Addressed PR comments."}, {"oid": "af1b59eca2ba863201d0ba10053e2d9d41107a02", "committedDate": "2021-07-09 16:01:15 +0200", "message": "Clean binary search implementation in SlicedRowFilter"}, {"oid": "a3c8881ee677f662ac9402f7571b20030003bd90", "committedDate": "2021-07-09 16:08:18 +0200", "message": "Updated copyright"}, {"oid": "e826ea374df18f9d0ff413872ebf5ddd1ad0bd17", "committedDate": "2021-07-12 15:23:43 +0200", "message": "Remove unused variables and fields"}, {"oid": "97981237e5fbd2ca4f8991cc267c9cb476d448cd", "committedDate": "2021-09-08 16:29:23 +0200", "message": "Merge branch 'master' into slicedrowfilter_binarysearch"}]}, {"oid": "335b626c2012946bb076b0943e41bdfdae1a58e9", "url": "https://github.com/senx/warp10-platform/commit/335b626c2012946bb076b0943e41bdfdae1a58e9", "message": "Merge branch 'master' of github.com:senx/warp10-platform into step-timestep", "committedDate": "2020-07-06T12:40:14Z", "type": "commit"}, {"oid": "abe989e9748cdc10aca949f409ca0bbbf6a2b3a8", "url": "https://github.com/senx/warp10-platform/commit/abe989e9748cdc10aca949f409ca0bbbf6a2b3a8", "message": "Addressed PR comments", "committedDate": "2020-07-06T12:58:23Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDgyOTkwMg==", "url": "https://github.com/senx/warp10-platform/pull/772#discussion_r450829902", "body": "I forgot this one, initialize to 0L to avoid stepping over the first values, even if it's not used yet.", "bodyText": "I forgot this one, initialize to 0L to avoid stepping over the first values, even if it's not used yet.", "bodyHTML": "<p dir=\"auto\">I forgot this one, initialize to 0L to avoid stepping over the first values, even if it's not used yet.</p>", "author": "ftence", "createdAt": "2020-07-07T12:35:34Z", "path": "warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java", "diffHunk": "@@ -87,30 +101,42 @@\n    */\n   private Result pendingresult = null;\n   \n-  private static final byte[] ZERO_BYTES = Longs.toByteArray(0L);\n-  private static final byte[] ONES_BYTES = Longs.toByteArray(0xffffffffffffffffL);\n-  \n   private static byte[] prefix = Constants.HBASE_RAW_DATA_KEY_PREFIX;\n \n   private final boolean writeTimestamp;\n+  private final boolean hasStep;\n+  private final boolean hasTimestep;\n+  private final boolean hasSample;\n+  private long skip = 0L;\n+  private long steps = 0L;\n+  private final long step;\n+  private final long timestep;\n+  private long nextTimestamp = Long.MAX_VALUE;\n+  private final double sample;\n   \n-  public SlicedRowFilterGTSDecoderIterator(long now, long timespan, List<Metadata> metadatas, Connection conn, TableName tableName, byte[] colfam, boolean writeTimestamp, KeyStore keystore, boolean useBlockCache) {\n+  private Random prng = null;\n+\n+  public SlicedRowFilterGTSDecoderIterator(FetchRequest req, Connection conn, TableName tableName, byte[] colfam, KeyStore keystore, boolean useBlockCache) {\n       \n+    this.request = req;\n     this.keystore = keystore;\n-    this.now = now;\n-    this.timespan = timespan;\n+    this.now = req.getNow();\n+    this.then = req.getThents();\n+    this.count = req.getCount();\n+    this.sample = req.getSample();\n+    this.hasSample = this.sample < 1.0D;\n+    this.prng = hasSample ? new Random() : null;\n+    this.hasStep = req.getStep() > 1L;\n+    this.steps = req.getStep() - 1L;", "originalCommit": "abe989e9748cdc10aca949f409ca0bbbf6a2b3a8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "40b530a5da3c781394f6518b678b8935f53d58a0", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java b/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\nindex b003357d..a20d2102 100644\n--- a/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\n+++ b/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\n", "chunk": "@@ -127,7 +127,7 @@ public class SlicedRowFilterGTSDecoderIterator extends GTSDecoderIterator implem\n     this.hasSample = this.sample < 1.0D;\n     this.prng = hasSample ? new Random() : null;\n     this.hasStep = req.getStep() > 1L;\n-    this.steps = req.getStep() - 1L;\n+    this.steps = 0L;\n     this.step = hasStep ? req.getStep() : 1L;\n     this.hasTimestep = req.getTimestep() > 1L;\n     this.timestep = this.hasTimestep ? req.getTimestep() : 1L;\n", "next_change": null}]}, "revised_code_in_main": {"commit": "67019d40559484d9cf2daf23cf83d122822ff274", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java b/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\nindex b003357d..a20d2102 100644\n--- a/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\n+++ b/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\n", "chunk": "@@ -127,7 +127,7 @@ public class SlicedRowFilterGTSDecoderIterator extends GTSDecoderIterator implem\n     this.hasSample = this.sample < 1.0D;\n     this.prng = hasSample ? new Random() : null;\n     this.hasStep = req.getStep() > 1L;\n-    this.steps = req.getStep() - 1L;\n+    this.steps = 0L;\n     this.step = hasStep ? req.getStep() : 1L;\n     this.hasTimestep = req.getTimestep() > 1L;\n     this.timestep = this.hasTimestep ? req.getTimestep() : 1L;\n", "next_change": {"commit": "551d6c7b184d9874baa236fb282d165fb4c8fc19", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java b/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\nindex a20d2102..cded28ff 100644\n--- a/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\n+++ b/warp10/src/main/java/io/warp10/continuum/store/SlicedRowFilterGTSDecoderIterator.java\n", "chunk": "@@ -136,6 +140,7 @@ public class SlicedRowFilterGTSDecoderIterator extends GTSDecoderIterator implem\n     this.nvalues = this.count >= 0 ? this.count : Long.MAX_VALUE;\n     this.hbaseAESKey = keystore.getKey(KeyStore.AES_HBASE_DATA);\n     this.writeTimestamp = req.isWriteTimestamp();\n+    this.fetchTTL = req.isTTL();\n     List<Metadata> metadatas = req.getMetadatas();\n     \n     //\n", "next_change": null}]}}]}, "commits_in_main": [{"oid": "67019d40559484d9cf2daf23cf83d122822ff274", "message": "Merge commit", "committedDate": null}, {"oid": "551d6c7b184d9874baa236fb282d165fb4c8fc19", "committedDate": "2020-10-09 11:22:20 +0200", "message": "Added support for fetching HBase cell TTLs."}, {"oid": "b85ba7585354c1a93145a000b4e4ba8760cfdc26", "committedDate": "2020-10-12 17:55:15 +0200", "message": "Changed the way the TTL is accessed"}, {"oid": "aab710c7c8534a2f52edc3564a35903184b9af30", "committedDate": "2020-10-13 15:15:09 +0200", "message": "Addressed PR comments."}, {"oid": "af1b59eca2ba863201d0ba10053e2d9d41107a02", "committedDate": "2021-07-09 16:01:15 +0200", "message": "Clean binary search implementation in SlicedRowFilter"}, {"oid": "a3c8881ee677f662ac9402f7571b20030003bd90", "committedDate": "2021-07-09 16:08:18 +0200", "message": "Updated copyright"}, {"oid": "e826ea374df18f9d0ff413872ebf5ddd1ad0bd17", "committedDate": "2021-07-12 15:23:43 +0200", "message": "Remove unused variables and fields"}, {"oid": "97981237e5fbd2ca4f8991cc267c9cb476d448cd", "committedDate": "2021-09-08 16:29:23 +0200", "message": "Merge branch 'master' into slicedrowfilter_binarysearch"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDgzMjkzOA==", "url": "https://github.com/senx/warp10-platform/pull/772#discussion_r450832938", "body": "`getStep` instead of `getSkip`.", "bodyText": "getStep instead of getSkip.", "bodyHTML": "<p dir=\"auto\"><code>getStep</code> instead of <code>getSkip</code>.</p>", "author": "ftence", "createdAt": "2020-07-07T12:40:48Z", "path": "warp10/src/main/java/io/warp10/standalone/StandaloneChunkedMemoryStore.java", "diffHunk": "@@ -146,8 +146,22 @@ public void run() {\n   }\n   \n   @Override\n-  public GTSDecoderIterator fetch(final ReadToken token, final List<Metadata> metadatas, final long now, final long then, final long count, final long skip, final double sample, boolean writeTimestamp, final long preBoundary, final long postBoundary) {\n-\n+  public GTSDecoderIterator fetch(FetchRequest req) {\n+    final List<Metadata> metadatas = req.getMetadatas();\n+    final long now = req.getNow();\n+    final long then = req.getThents();\n+    final long count = req.getCount();\n+    final long skip = req.getSkip();\n+    long step = req.getSkip();", "originalCommit": "abe989e9748cdc10aca949f409ca0bbbf6a2b3a8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "40b530a5da3c781394f6518b678b8935f53d58a0", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/standalone/StandaloneChunkedMemoryStore.java b/warp10/src/main/java/io/warp10/standalone/StandaloneChunkedMemoryStore.java\nindex ab1ba50d..bb55083e 100644\n--- a/warp10/src/main/java/io/warp10/standalone/StandaloneChunkedMemoryStore.java\n+++ b/warp10/src/main/java/io/warp10/standalone/StandaloneChunkedMemoryStore.java\n", "chunk": "@@ -152,7 +152,7 @@ public class StandaloneChunkedMemoryStore extends Thread implements StoreClient\n     final long then = req.getThents();\n     final long count = req.getCount();\n     final long skip = req.getSkip();\n-    long step = req.getSkip();\n+    long step = req.getStep();\n     long timestep = req.getTimestep();\n     final double sample = req.getSample();\n     final long preBoundary = req.getPreBoundary();\n", "next_change": null}]}, "revised_code_in_main": {"commit": "67019d40559484d9cf2daf23cf83d122822ff274", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/standalone/StandaloneChunkedMemoryStore.java b/warp10/src/main/java/io/warp10/standalone/StandaloneChunkedMemoryStore.java\nindex ab1ba50d..bb55083e 100644\n--- a/warp10/src/main/java/io/warp10/standalone/StandaloneChunkedMemoryStore.java\n+++ b/warp10/src/main/java/io/warp10/standalone/StandaloneChunkedMemoryStore.java\n", "chunk": "@@ -152,7 +152,7 @@ public class StandaloneChunkedMemoryStore extends Thread implements StoreClient\n     final long then = req.getThents();\n     final long count = req.getCount();\n     final long skip = req.getSkip();\n-    long step = req.getSkip();\n+    long step = req.getStep();\n     long timestep = req.getTimestep();\n     final double sample = req.getSample();\n     final long preBoundary = req.getPreBoundary();\n", "next_change": {"commit": "57838bac07d064ee4e53d78e5734d2f02165a167", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/standalone/StandaloneChunkedMemoryStore.java b/warp10/src/main/java/io/warp10/standalone/StandaloneChunkedMemoryStore.java\nindex bb55083e..749efa03 100644\n--- a/warp10/src/main/java/io/warp10/standalone/StandaloneChunkedMemoryStore.java\n+++ b/warp10/src/main/java/io/warp10/standalone/StandaloneChunkedMemoryStore.java\n", "chunk": "@@ -159,50 +163,50 @@ public class StandaloneChunkedMemoryStore extends Thread implements StoreClient\n     final long postBoundary = req.getPostBoundary();\n \n     if (step > 1L || timestep > 1L) {\n-      throw new RuntimeException(\"Parameters 'step' and 'timestep' are not supported by the in-memory store.\"); \n+      throw new RuntimeException(\"Parameters 'step' and 'timestep' are not supported by the in-memory store.\");\n     }\n-    \n+\n     GTSDecoderIterator iterator = new GTSDecoderIterator() {\n \n       private int idx = 0;\n-      \n+\n       private GTSDecoder decoder = null;\n-      \n+\n       private CapacityExtractorOutputStream extractor = new CapacityExtractorOutputStream();\n-      \n+\n       @Override\n       public void close() throws Exception {}\n-      \n+\n       @Override\n       public void remove() {}\n-      \n+\n       @Override\n       public GTSDecoder next() {\n         GTSDecoder dec = this.decoder;\n         this.decoder = null;\n         return dec;\n       }\n-      \n+\n       @Override\n-      public boolean hasNext() {  \n-        \n+      public boolean hasNext() {\n+\n         if (null != this.decoder) {\n           return true;\n         }\n-        \n+\n         // 128 bits\n         byte[] bytes = new byte[16];\n-        \n+\n         while(true) {\n           if (idx >= metadatas.size()) {\n             return false;\n           }\n-          \n+\n           while(idx < metadatas.size()) {\n             long id = metadatas.get(idx).getClassId();\n-            \n+\n             int bidx = 0;\n-            \n+\n             bytes[bidx++] = (byte) ((id >> 56) & 0xff);\n             bytes[bidx++] = (byte) ((id >> 48) & 0xff);\n             bytes[bidx++] = (byte) ((id >> 40) & 0xff);\n", "next_change": {"commit": "1c0982b75c264a7cecb1043f1e5495f4af0eb248", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/standalone/StandaloneChunkedMemoryStore.java b/warp10/src/main/java/io/warp10/standalone/StandaloneChunkedMemoryStore.java\nindex 749efa03..8b95b09b 100644\n--- a/warp10/src/main/java/io/warp10/standalone/StandaloneChunkedMemoryStore.java\n+++ b/warp10/src/main/java/io/warp10/standalone/StandaloneChunkedMemoryStore.java\n", "chunk": "@@ -203,29 +203,7 @@ public class StandaloneChunkedMemoryStore extends Thread implements StoreClient\n           }\n \n           while(idx < metadatas.size()) {\n-            long id = metadatas.get(idx).getClassId();\n-\n-            int bidx = 0;\n-\n-            bytes[bidx++] = (byte) ((id >> 56) & 0xff);\n-            bytes[bidx++] = (byte) ((id >> 48) & 0xff);\n-            bytes[bidx++] = (byte) ((id >> 40) & 0xff);\n-            bytes[bidx++] = (byte) ((id >> 32) & 0xff);\n-            bytes[bidx++] = (byte) ((id >> 24) & 0xff);\n-            bytes[bidx++] = (byte) ((id >> 16) & 0xff);\n-            bytes[bidx++] = (byte) ((id >> 8) & 0xff);\n-            bytes[bidx++] = (byte) (id & 0xff);\n-\n-            id = metadatas.get(idx).getLabelsId();\n-\n-            bytes[bidx++] = (byte) ((id >> 56) & 0xff);\n-            bytes[bidx++] = (byte) ((id >> 48) & 0xff);\n-            bytes[bidx++] = (byte) ((id >> 40) & 0xff);\n-            bytes[bidx++] = (byte) ((id >> 32) & 0xff);\n-            bytes[bidx++] = (byte) ((id >> 24) & 0xff);\n-            bytes[bidx++] = (byte) ((id >> 16) & 0xff);\n-            bytes[bidx++] = (byte) ((id >> 8) & 0xff);\n-            bytes[bidx++] = (byte) (id & 0xff);\n+            GTSHelper.fillGTSIds(bytes, 0, metadatas.get(idx).getClassId(), metadatas.get(idx).getLabelsId());\n \n             BigInteger clslbls = new BigInteger(bytes);\n \n", "next_change": null}]}}]}}]}, "commits_in_main": [{"oid": "67019d40559484d9cf2daf23cf83d122822ff274", "message": "Merge commit", "committedDate": null}, {"oid": "efed07b50b0234f63473d7348dcbc9f84501bb48", "committedDate": "2020-09-21 15:29:18 +0200", "message": "Remove unneeded check because metadata is always non-null"}, {"oid": "57838bac07d064ee4e53d78e5734d2f02165a167", "committedDate": "2020-10-09 18:36:15 +0200", "message": "Improve log management"}, {"oid": "8021a591e1142ba4feb57fd6d45ff1de0c906dff", "committedDate": "2021-05-10 12:16:17 +0200", "message": "Replace printStackTrace with LOG.error when relevant"}, {"oid": "1c0982b75c264a7cecb1043f1e5495f4af0eb248", "committedDate": "2021-08-11 16:54:26 +0200", "message": "Use fillGTSIds where possible"}]}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDgzNDk3OQ==", "url": "https://github.com/senx/warp10-platform/pull/772#discussion_r450834979", "body": "`getStep` instead of `getSkip`.", "bodyText": "getStep instead of getSkip.", "bodyHTML": "<p dir=\"auto\"><code>getStep</code> instead of <code>getSkip</code>.</p>", "author": "ftence", "createdAt": "2020-07-07T12:44:11Z", "path": "warp10/src/main/java/io/warp10/standalone/StandaloneMemoryStore.java", "diffHunk": "@@ -134,7 +134,17 @@ public void run() {\n   }\n   \n   @Override\n-  public GTSDecoderIterator fetch(final ReadToken token, final List<Metadata> metadatas, final long now, final long then, final long count, final long skip, final double sample, boolean writeTimestamp, final long preBoundary, final long postBoundary) {\n+  public GTSDecoderIterator fetch(FetchRequest req) {\n+    final List<Metadata> metadatas = req.getMetadatas();\n+    final long now = req.getNow();\n+    final long then = req.getThents();\n+    final long count = req.getCount();\n+    final long skip = req.getSkip();\n+    long step = req.getSkip();", "originalCommit": "abe989e9748cdc10aca949f409ca0bbbf6a2b3a8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "40b530a5da3c781394f6518b678b8935f53d58a0", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/standalone/StandaloneMemoryStore.java b/warp10/src/main/java/io/warp10/standalone/StandaloneMemoryStore.java\nindex 67387e1b..a48aa1ef 100644\n--- a/warp10/src/main/java/io/warp10/standalone/StandaloneMemoryStore.java\n+++ b/warp10/src/main/java/io/warp10/standalone/StandaloneMemoryStore.java\n", "chunk": "@@ -140,7 +140,7 @@ public class StandaloneMemoryStore extends Thread implements StoreClient {\n     final long then = req.getThents();\n     final long count = req.getCount();\n     final long skip = req.getSkip();\n-    long step = req.getSkip();\n+    long step = req.getStep();\n     long timestep = req.getTimestep();\n     final double sample = req.getSample();\n     final long preBoundary = req.getPreBoundary();\n", "next_change": null}]}, "revised_code_in_main": {"commit": "67019d40559484d9cf2daf23cf83d122822ff274", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/standalone/StandaloneMemoryStore.java b/warp10/src/main/java/io/warp10/standalone/StandaloneMemoryStore.java\nindex 67387e1b..a48aa1ef 100644\n--- a/warp10/src/main/java/io/warp10/standalone/StandaloneMemoryStore.java\n+++ b/warp10/src/main/java/io/warp10/standalone/StandaloneMemoryStore.java\n", "chunk": "@@ -140,7 +140,7 @@ public class StandaloneMemoryStore extends Thread implements StoreClient {\n     final long then = req.getThents();\n     final long count = req.getCount();\n     final long skip = req.getSkip();\n-    long step = req.getSkip();\n+    long step = req.getStep();\n     long timestep = req.getTimestep();\n     final double sample = req.getSample();\n     final long preBoundary = req.getPreBoundary();\n", "next_change": {"commit": "57838bac07d064ee4e53d78e5734d2f02165a167", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/standalone/StandaloneMemoryStore.java b/warp10/src/main/java/io/warp10/standalone/StandaloneMemoryStore.java\nindex a48aa1ef..98c38052 100644\n--- a/warp10/src/main/java/io/warp10/standalone/StandaloneMemoryStore.java\n+++ b/warp10/src/main/java/io/warp10/standalone/StandaloneMemoryStore.java\n", "chunk": "@@ -149,68 +153,70 @@ public class StandaloneMemoryStore extends Thread implements StoreClient {\n     if (0 != preBoundary || 0 != postBoundary) {\n       throw new RuntimeException(\"Boundary retrieval is not supported by the current data store.\");\n     }\n-  \n+\n     if (0 != skip) {\n       throw new RuntimeException(\"Unsupported skip operation.\");\n     }\n-    \n+\n     if (step > 1L || timestep > 1L) {\n-      throw new RuntimeException(\"Parameters 'step' and 'timestep' are not supported by the in-memory store.\"); \n+      throw new RuntimeException(\"Parameters 'step' and 'timestep' are not supported by the in-memory store.\");\n     }\n \n     if (1.0D != sample) {\n       throw new RuntimeException(\"Unsupported sample operation.\");\n     }\n-    \n+\n     long tspan = 0;\n-    \n+\n     if (count > 0) {\n       tspan = -count;\n     } else {\n       tspan = now - then + 1;\n     }\n-    \n+\n     final long timespan = tspan;\n-    \n+\n     GTSDecoderIterator iterator = new GTSDecoderIterator() {\n \n       private int idx = 0;\n-      \n+\n       private GTSDecoder decoder = null;\n-      \n+\n       private long nvalues = Long.MAX_VALUE;\n-      \n+\n       @Override\n-      public void close() throws Exception {}\n-      \n+      public void close() throws Exception {\n+      }\n+\n       @Override\n-      public void remove() {}\n-      \n+      public void remove() {\n+      }\n+\n       @Override\n       public GTSDecoder next() {\n         return this.decoder;\n       }\n-      \n+\n       @Override\n-      public boolean hasNext() {  \n-        \n+      public boolean hasNext() {\n+\n         byte[] bytes = new byte[16];\n-        \n-        while(true) {\n+\n+        while (true) {\n           if (idx >= metadatas.size()) {\n             return false;\n           }\n-          \n-          while(idx < metadatas.size()) {\n+\n+          while (idx < metadatas.size()) {\n             //ByteBuffer bb = ByteBuffer.wrap(new byte[16]).order(ByteOrder.BIG_ENDIAN);\n             //bb.putLong(metadatas.get(idx).getClassId());\n             //bb.putLong(metadatas.get(idx).getLabelsId());\n             //BigInteger clslbls = new BigInteger(bb.array());\n \n             long id = metadatas.get(idx).getClassId();\n-            \n+\n             int bidx = 0;\n-            \n+\n             bytes[bidx++] = (byte) ((id >> 56) & 0xff);\n             bytes[bidx++] = (byte) ((id >> 48) & 0xff);\n             bytes[bidx++] = (byte) ((id >> 40) & 0xff);\n", "next_change": {"commit": "1c0982b75c264a7cecb1043f1e5495f4af0eb248", "changed_code": [{"header": "diff --git a/warp10/src/main/java/io/warp10/standalone/StandaloneMemoryStore.java b/warp10/src/main/java/io/warp10/standalone/StandaloneMemoryStore.java\nindex 98c38052..0047494f 100644\n--- a/warp10/src/main/java/io/warp10/standalone/StandaloneMemoryStore.java\n+++ b/warp10/src/main/java/io/warp10/standalone/StandaloneMemoryStore.java\n", "chunk": "@@ -208,34 +208,7 @@ public class StandaloneMemoryStore extends Thread implements StoreClient {\n           }\n \n           while (idx < metadatas.size()) {\n-            //ByteBuffer bb = ByteBuffer.wrap(new byte[16]).order(ByteOrder.BIG_ENDIAN);\n-            //bb.putLong(metadatas.get(idx).getClassId());\n-            //bb.putLong(metadatas.get(idx).getLabelsId());\n-            //BigInteger clslbls = new BigInteger(bb.array());\n-\n-            long id = metadatas.get(idx).getClassId();\n-\n-            int bidx = 0;\n-\n-            bytes[bidx++] = (byte) ((id >> 56) & 0xff);\n-            bytes[bidx++] = (byte) ((id >> 48) & 0xff);\n-            bytes[bidx++] = (byte) ((id >> 40) & 0xff);\n-            bytes[bidx++] = (byte) ((id >> 32) & 0xff);\n-            bytes[bidx++] = (byte) ((id >> 24) & 0xff);\n-            bytes[bidx++] = (byte) ((id >> 16) & 0xff);\n-            bytes[bidx++] = (byte) ((id >> 8) & 0xff);\n-            bytes[bidx++] = (byte) (id & 0xff);\n-\n-            id = metadatas.get(idx).getLabelsId();\n-\n-            bytes[bidx++] = (byte) ((id >> 56) & 0xff);\n-            bytes[bidx++] = (byte) ((id >> 48) & 0xff);\n-            bytes[bidx++] = (byte) ((id >> 40) & 0xff);\n-            bytes[bidx++] = (byte) ((id >> 32) & 0xff);\n-            bytes[bidx++] = (byte) ((id >> 24) & 0xff);\n-            bytes[bidx++] = (byte) ((id >> 16) & 0xff);\n-            bytes[bidx++] = (byte) ((id >> 8) & 0xff);\n-            bytes[bidx++] = (byte) (id & 0xff);\n+            GTSHelper.fillGTSIds(bytes, 0, metadatas.get(idx).getClassId(), metadatas.get(idx).getLabelsId());\n \n             BigInteger clslbls = new BigInteger(bytes);\n \n", "next_change": null}]}}]}}]}, "commits_in_main": [{"oid": "67019d40559484d9cf2daf23cf83d122822ff274", "message": "Merge commit", "committedDate": null}, {"oid": "efed07b50b0234f63473d7348dcbc9f84501bb48", "committedDate": "2020-09-21 15:29:18 +0200", "message": "Remove unneeded check because metadata is always non-null"}, {"oid": "2f7acfd0dfdab2b928b806bc5ae3c3a6227382b6", "committedDate": "2020-09-22 15:11:11 +0200", "message": "Fix integer divisions"}, {"oid": "57838bac07d064ee4e53d78e5734d2f02165a167", "committedDate": "2020-10-09 18:36:15 +0200", "message": "Improve log management"}, {"oid": "8021a591e1142ba4feb57fd6d45ff1de0c906dff", "committedDate": "2021-05-10 12:16:17 +0200", "message": "Replace printStackTrace with LOG.error when relevant"}, {"oid": "1c0982b75c264a7cecb1043f1e5495f4af0eb248", "committedDate": "2021-08-11 16:54:26 +0200", "message": "Use fillGTSIds where possible"}]}, {"oid": "40b530a5da3c781394f6518b678b8935f53d58a0", "url": "https://github.com/senx/warp10-platform/commit/40b530a5da3c781394f6518b678b8935f53d58a0", "message": "Addressed PR comments", "committedDate": "2020-07-07T14:22:39Z", "type": "commit"}]}