{"pr_number": 1514, "pr_title": "Issue-1511: Read errors out with multiple DeleteFile entries after UPSERT", "pr_author": "mehtaashish23", "pr_createdAt": "2020-09-26T01:00:08Z", "pr_url": "https://github.com/apache/iceberg/pull/1514", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjI1MTAwNg==", "url": "https://github.com/apache/iceberg/pull/1514#discussion_r496251006", "body": "There is no `equals` and `hashCode` implementation for `CharSequence`, so it can't be used reliably as a map key to deduplicate.\r\n\r\nAlso, the only thing you need from the file instance is the key metadata, so you could keep a map of string path to key metadata, like this:\r\n\r\n```java\r\n    Map<String, ByteBuffer> keyMetadata = Maps.newHashMap();\r\n    task.files().stream()\r\n        .flatMap(fileScanTask -> Stream.concat(Stream.of(fileScanTask.file()), fileScanTask.deletes().stream()))\r\n        .forEach(file -> keyMetadata.put(file.path().toString(), file.keyMetadata()));\r\n    Stream<EncryptedInputFile> encrypted = keyMetadata.entrySet().stream()\r\n        .map(entry -> EncryptedFiles.encryptedInput(io.newInputFile(entry.getKey()), entry.getValue()));\r\n```", "bodyText": "There is no equals and hashCode implementation for CharSequence, so it can't be used reliably as a map key to deduplicate.\nAlso, the only thing you need from the file instance is the key metadata, so you could keep a map of string path to key metadata, like this:\n    Map<String, ByteBuffer> keyMetadata = Maps.newHashMap();\n    task.files().stream()\n        .flatMap(fileScanTask -> Stream.concat(Stream.of(fileScanTask.file()), fileScanTask.deletes().stream()))\n        .forEach(file -> keyMetadata.put(file.path().toString(), file.keyMetadata()));\n    Stream<EncryptedInputFile> encrypted = keyMetadata.entrySet().stream()\n        .map(entry -> EncryptedFiles.encryptedInput(io.newInputFile(entry.getKey()), entry.getValue()));", "bodyHTML": "<p dir=\"auto\">There is no <code>equals</code> and <code>hashCode</code> implementation for <code>CharSequence</code>, so it can't be used reliably as a map key to deduplicate.</p>\n<p dir=\"auto\">Also, the only thing you need from the file instance is the key metadata, so you could keep a map of string path to key metadata, like this:</p>\n<div class=\"highlight highlight-source-java position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"    Map&lt;String, ByteBuffer&gt; keyMetadata = Maps.newHashMap();\n    task.files().stream()\n        .flatMap(fileScanTask -&gt; Stream.concat(Stream.of(fileScanTask.file()), fileScanTask.deletes().stream()))\n        .forEach(file -&gt; keyMetadata.put(file.path().toString(), file.keyMetadata()));\n    Stream&lt;EncryptedInputFile&gt; encrypted = keyMetadata.entrySet().stream()\n        .map(entry -&gt; EncryptedFiles.encryptedInput(io.newInputFile(entry.getKey()), entry.getValue()));\n\"><pre>    <span class=\"pl-k\">Map&lt;<span class=\"pl-smi\">String</span>, <span class=\"pl-smi\">ByteBuffer</span>&gt;</span> keyMetadata <span class=\"pl-k\">=</span> <span class=\"pl-smi\">Maps</span><span class=\"pl-k\">.</span>newHashMap();\n    task<span class=\"pl-k\">.</span>files()<span class=\"pl-k\">.</span>stream()\n        .flatMap(fileScanTask <span class=\"pl-k\">-</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-smi\">Stream</span><span class=\"pl-k\">.</span>concat(<span class=\"pl-smi\">Stream</span><span class=\"pl-k\">.</span>of(fileScanTask<span class=\"pl-k\">.</span>file()), fileScanTask<span class=\"pl-k\">.</span>deletes()<span class=\"pl-k\">.</span>stream()))\n        .forEach(file <span class=\"pl-k\">-</span><span class=\"pl-k\">&gt;</span> keyMetadata<span class=\"pl-k\">.</span>put(file<span class=\"pl-k\">.</span>path()<span class=\"pl-k\">.</span>toString(), file<span class=\"pl-k\">.</span>keyMetadata()));\n    <span class=\"pl-k\">Stream&lt;<span class=\"pl-smi\">EncryptedInputFile</span>&gt;</span> encrypted <span class=\"pl-k\">=</span> keyMetadata<span class=\"pl-k\">.</span>entrySet()<span class=\"pl-k\">.</span>stream()\n        .map(entry <span class=\"pl-k\">-</span><span class=\"pl-k\">&gt;</span> <span class=\"pl-smi\">EncryptedFiles</span><span class=\"pl-k\">.</span>encryptedInput(io<span class=\"pl-k\">.</span>newInputFile(entry<span class=\"pl-k\">.</span>getKey()), entry<span class=\"pl-k\">.</span>getValue()));</pre></div>", "author": "rdblue", "createdAt": "2020-09-28T21:44:39Z", "path": "spark/src/main/java/org/apache/iceberg/spark/source/BaseDataReader.java", "diffHunk": "@@ -58,9 +60,12 @@\n \n   BaseDataReader(CombinedScanTask task, FileIO io, EncryptionManager encryptionManager) {\n     this.tasks = task.files().iterator();\n-    Stream<EncryptedInputFile> encrypted = task.files().stream()\n-        .flatMap(fileScanTask -> Stream.concat(Stream.of(fileScanTask.file()), fileScanTask.deletes().stream()))\n-        .map(file -> EncryptedFiles.encryptedInput(io.newInputFile(file.path().toString()), file.keyMetadata()));\n+    Map<CharSequence, DeleteFile> uniqueDeleteFileMap = Maps.newHashMap();", "originalCommit": "e2fa9ac689d8776526a0d754a09878f5a0b668bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjI1OTg2NA==", "url": "https://github.com/apache/iceberg/pull/1514#discussion_r496259864", "bodyText": "I actually started with deduping both DataFile and DeleteFile, but thought of keeping it just for DeleteFile, to not touch other workflows. will follow your recommendation. Thanks!", "author": "mehtaashish23", "createdAt": "2020-09-28T21:58:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjI1MTAwNg=="}], "type": "inlineReview"}, {"oid": "d89f92d11d1268bc180916d10d762221966c793d", "url": "https://github.com/apache/iceberg/commit/d89f92d11d1268bc180916d10d762221966c793d", "message": "Issue-1511: Read errors out with multiple DeleteFile entries after UPSERT", "committedDate": "2020-10-05T17:19:18Z", "type": "commit"}, {"oid": "e60d3ab2f7bbebd7f6632b5bf7f24c42170b3e6a", "url": "https://github.com/apache/iceberg/commit/e60d3ab2f7bbebd7f6632b5bf7f24c42170b3e6a", "message": "Issue-1511: Read errors out with multiple DeleteFile entries after UPSERT\n\nReview Feedback", "committedDate": "2020-10-05T17:25:37Z", "type": "commit"}, {"oid": "f8195893dc53ff2067b8da55fbc533a23dcb3224", "url": "https://github.com/apache/iceberg/commit/f8195893dc53ff2067b8da55fbc533a23dcb3224", "message": "Issue-1511: Read errors out with multiple DeleteFile entries after UPSERT\n\nResolving conflict", "committedDate": "2020-10-05T18:23:23Z", "type": "commit"}, {"oid": "f8195893dc53ff2067b8da55fbc533a23dcb3224", "url": "https://github.com/apache/iceberg/commit/f8195893dc53ff2067b8da55fbc533a23dcb3224", "message": "Issue-1511: Read errors out with multiple DeleteFile entries after UPSERT\n\nResolving conflict", "committedDate": "2020-10-05T18:23:23Z", "type": "forcePushed"}]}