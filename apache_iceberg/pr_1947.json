{"pr_number": 1947, "pr_title": "Spark MERGE INTO Support (copy-on-write implementation)", "pr_author": "dilipbiswal", "pr_createdAt": "2020-12-16T22:36:08Z", "pr_url": "https://github.com/apache/iceberg/pull/1947", "timeline": [{"oid": "76ea61f0321a7b4de250e448722f7893bd52296f", "url": "https://github.com/apache/iceberg/commit/76ea61f0321a7b4de250e448722f7893bd52296f", "message": "Code review + base infrastructure", "committedDate": "2021-01-04T07:36:37Z", "type": "forcePushed"}, {"oid": "13889694c2fa750aae742ff207061ce40bf66504", "url": "https://github.com/apache/iceberg/commit/13889694c2fa750aae742ff207061ce40bf66504", "message": "Code review + base infrastructure", "committedDate": "2021-01-05T06:48:22Z", "type": "forcePushed"}, {"oid": "148744edd876f823e18bf4f9ae5f2a58f4c55f65", "url": "https://github.com/apache/iceberg/commit/148744edd876f823e18bf4f9ae5f2a58f4c55f65", "message": "Code review + base infrastructure", "committedDate": "2021-01-11T09:00:38Z", "type": "forcePushed"}, {"oid": "946bbded4eb82639a9e3db7fb90172dab827508c", "url": "https://github.com/apache/iceberg/commit/946bbded4eb82639a9e3db7fb90172dab827508c", "message": "Code review + base infrastructure", "committedDate": "2021-01-12T05:34:17Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODU2NjIyNg==", "url": "https://github.com/apache/iceberg/pull/1947#discussion_r558566226", "body": "@dilipbiswal, could you move these tests to `TestMerge` that was introduced recently?", "bodyText": "@dilipbiswal, could you move these tests to TestMerge that was introduced recently?", "bodyHTML": "<p dir=\"auto\"><a class=\"user-mention\" data-hovercard-type=\"user\" data-hovercard-url=\"/users/dilipbiswal/hovercard\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/dilipbiswal\">@dilipbiswal</a>, could you move these tests to <code>TestMerge</code> that was introduced recently?</p>", "author": "aokolnychyi", "createdAt": "2021-01-15T20:07:09Z", "path": "spark3-extensions/src/test/java/org/apache/iceberg/spark/extensions/TestMergeIntoTable.java", "diffHunk": "@@ -0,0 +1,267 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.extensions;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.TableProperties;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.spark.sql.Dataset;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.catalyst.analysis.NoSuchTableException;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Assume;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+\n+import static org.apache.iceberg.TableProperties.DEFAULT_FILE_FORMAT;\n+import static org.apache.iceberg.TableProperties.PARQUET_VECTORIZATION_ENABLED;\n+\n+public class TestMergeIntoTable extends SparkRowLevelOperationsTestBase {", "originalCommit": "946bbded4eb82639a9e3db7fb90172dab827508c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTA5NDk1OQ==", "url": "https://github.com/apache/iceberg/pull/1947#discussion_r559094959", "bodyText": "@aokolnychyi If you are ok, i want to create a final pr to remove this test case and merge to TestMerge since the other two prs also add tests to this class. I want them to rebase okay without much trouble. Let me know please.", "author": "dilipbiswal", "createdAt": "2021-01-17T08:10:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODU2NjIyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTgzNDM0Ng==", "url": "https://github.com/apache/iceberg/pull/1947#discussion_r559834346", "bodyText": "Sounds fine to me.", "author": "rdblue", "createdAt": "2021-01-18T23:27:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODU2NjIyNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODc0Nzc0Mg==", "url": "https://github.com/apache/iceberg/pull/1947#discussion_r558747742", "body": "Why is this passing an empty string?", "bodyText": "Why is this passing an empty string?", "bodyHTML": "<p dir=\"auto\">Why is this passing an empty string?</p>", "author": "rdblue", "createdAt": "2021-01-16T01:38:08Z", "path": "spark3-extensions/src/test/java/org/apache/iceberg/spark/extensions/TestMergeIntoTable.java", "diffHunk": "@@ -0,0 +1,267 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.extensions;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.TableProperties;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.spark.sql.Dataset;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.catalyst.analysis.NoSuchTableException;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Assume;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+\n+import static org.apache.iceberg.TableProperties.DEFAULT_FILE_FORMAT;\n+import static org.apache.iceberg.TableProperties.PARQUET_VECTORIZATION_ENABLED;\n+\n+public class TestMergeIntoTable extends SparkRowLevelOperationsTestBase {\n+  private final String sourceName;\n+  private final String targetName;\n+\n+  public TestMergeIntoTable(String catalogName, String implementation, Map<String, String> config,\n+                            String fileFormat, Boolean vectorized) {\n+    super(catalogName, implementation, config, fileFormat, vectorized);\n+    this.sourceName = tableName(\"source\");\n+    this.targetName = tableName(\"target\");\n+  }\n+\n+  @BeforeClass\n+  public static void setupSparkConf() {\n+    spark.conf().set(\"spark.sql.shuffle.partitions\", \"4\");\n+  }\n+\n+  protected Map<String, String> extraTableProperties() {\n+    return ImmutableMap.of(TableProperties.DELETE_MODE, \"copy-on-write\");\n+  }\n+\n+  @After\n+  public void removeTables() {\n+    sql(\"DROP TABLE IF EXISTS %s\", targetName);\n+    sql(\"DROP TABLE IF EXISTS %s\", sourceName);\n+  }\n+\n+  @Test\n+  public void testEmptyTargetInsertAllNonMatchingRows() throws NoSuchTableException {\n+    createAndInitUnPartitionedTargetTable(targetName);\n+    createAndInitSourceTable(sourceName);\n+    append(sourceName, new Employee(1, \"emp-id-1\"), new Employee(2, \"emp-id-2\"), new Employee(3, \"emp-id-3\"));\n+    String sqlText = \"MERGE INTO \" + targetName + \" AS target \\n\" +\n+                     \"USING \" + sourceName + \" AS source \\n\" +\n+                     \"ON target.id = source.id \\n\" +\n+                     \"WHEN NOT MATCHED THEN INSERT * \";\n+\n+    sql(sqlText, \"\");\n+    sql(\"SELECT * FROM %s ORDER BY id, dep\", targetName);\n+    assertEquals(\"Should have expected rows\",\n+            ImmutableList.of(row(1, \"emp-id-1\"), row(2, \"emp-id-2\"), row(3, \"emp-id-3\")),\n+            sql(\"SELECT * FROM %s ORDER BY id ASC NULLS LAST\", targetName));\n+  }\n+\n+  @Test\n+  public void testEmptyTargetInsertOnlyMatchingRows() throws NoSuchTableException {\n+    createAndInitUnPartitionedTargetTable(targetName);\n+    createAndInitSourceTable(sourceName);\n+    append(sourceName, new Employee(1, \"emp-id-1\"), new Employee(2, \"emp-id-2\"), new Employee(3, \"emp-id-3\"));\n+    String sqlText = \"MERGE INTO \" + targetName + \" AS target \\n\" +\n+                     \"USING \" + sourceName + \" AS source \\n\" +\n+                     \"ON target.id = source.id \\n\" +\n+                     \"WHEN NOT MATCHED AND (source.id >= 2) THEN INSERT * \";\n+\n+    sql(sqlText, \"\");\n+    List<Object[]> res = sql(\"SELECT * FROM %s ORDER BY id, dep\", targetName);\n+    assertEquals(\"Should have expected rows\",\n+            ImmutableList.of(row(2, \"emp-id-2\"), row(3, \"emp-id-3\")),\n+            sql(\"SELECT * FROM %s ORDER BY id ASC NULLS LAST\", targetName));\n+  }\n+\n+  @Test\n+  public void testOnlyUpdate() throws NoSuchTableException {\n+    createAndInitUnPartitionedTargetTable(targetName);\n+    createAndInitSourceTable(sourceName);\n+    append(targetName, new Employee(1, \"emp-id-one\"), new Employee(6, \"emp-id-6\"));\n+    append(sourceName, new Employee(2, \"emp-id-2\"), new Employee(1, \"emp-id-1\"), new Employee(6, \"emp-id-6\"));\n+    String sqlText = \"MERGE INTO \" + targetName + \" AS target \\n\" +\n+            \"USING \" + sourceName + \" AS source \\n\" +\n+            \"ON target.id = source.id \\n\" +\n+            \"WHEN MATCHED AND target.id = 1 THEN UPDATE SET * \";\n+\n+    sql(sqlText, \"\");\n+    List<Object[]> res = sql(\"SELECT * FROM %s ORDER BY id, dep\", targetName);\n+    assertEquals(\"Should have expected rows\",\n+            ImmutableList.of(row(1, \"emp-id-1\"), row(6, \"emp-id-6\")),\n+            sql(\"SELECT * FROM %s ORDER BY id ASC NULLS LAST\", targetName));\n+  }\n+\n+  @Test\n+  public void testOnlyDelete() throws NoSuchTableException {\n+    createAndInitUnPartitionedTargetTable(targetName);\n+    createAndInitSourceTable(sourceName);\n+    append(targetName, new Employee(1, \"emp-id-one\"), new Employee(6, \"emp-id-6\"));\n+    append(sourceName, new Employee(2, \"emp-id-2\"), new Employee(1, \"emp-id-1\"), new Employee(6, \"emp-id-6\"));\n+    String sqlText = \"MERGE INTO \" + targetName + \" AS target \\n\" +\n+            \"USING \" + sourceName + \" AS source \\n\" +\n+            \"ON target.id = source.id \\n\" +\n+            \"WHEN MATCHED AND target.id = 6 THEN DELETE\";\n+\n+    sql(sqlText, \"\");", "originalCommit": "946bbded4eb82639a9e3db7fb90172dab827508c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTAzNTk3OQ==", "url": "https://github.com/apache/iceberg/pull/1947#discussion_r559035979", "bodyText": "@rdblue Sorry.. don't know why i was doing it. Will remove.", "author": "dilipbiswal", "createdAt": "2021-01-16T20:25:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODc0Nzc0Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODc0NzkxNw==", "url": "https://github.com/apache/iceberg/pull/1947#discussion_r558747917", "body": "Why did you choose to include the newlines?", "bodyText": "Why did you choose to include the newlines?", "bodyHTML": "<p dir=\"auto\">Why did you choose to include the newlines?</p>", "author": "rdblue", "createdAt": "2021-01-16T01:38:29Z", "path": "spark3-extensions/src/test/java/org/apache/iceberg/spark/extensions/TestMergeIntoTable.java", "diffHunk": "@@ -0,0 +1,267 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.extensions;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.TableProperties;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.spark.sql.Dataset;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.catalyst.analysis.NoSuchTableException;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Assume;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+\n+import static org.apache.iceberg.TableProperties.DEFAULT_FILE_FORMAT;\n+import static org.apache.iceberg.TableProperties.PARQUET_VECTORIZATION_ENABLED;\n+\n+public class TestMergeIntoTable extends SparkRowLevelOperationsTestBase {\n+  private final String sourceName;\n+  private final String targetName;\n+\n+  public TestMergeIntoTable(String catalogName, String implementation, Map<String, String> config,\n+                            String fileFormat, Boolean vectorized) {\n+    super(catalogName, implementation, config, fileFormat, vectorized);\n+    this.sourceName = tableName(\"source\");\n+    this.targetName = tableName(\"target\");\n+  }\n+\n+  @BeforeClass\n+  public static void setupSparkConf() {\n+    spark.conf().set(\"spark.sql.shuffle.partitions\", \"4\");\n+  }\n+\n+  protected Map<String, String> extraTableProperties() {\n+    return ImmutableMap.of(TableProperties.DELETE_MODE, \"copy-on-write\");\n+  }\n+\n+  @After\n+  public void removeTables() {\n+    sql(\"DROP TABLE IF EXISTS %s\", targetName);\n+    sql(\"DROP TABLE IF EXISTS %s\", sourceName);\n+  }\n+\n+  @Test\n+  public void testEmptyTargetInsertAllNonMatchingRows() throws NoSuchTableException {\n+    createAndInitUnPartitionedTargetTable(targetName);\n+    createAndInitSourceTable(sourceName);\n+    append(sourceName, new Employee(1, \"emp-id-1\"), new Employee(2, \"emp-id-2\"), new Employee(3, \"emp-id-3\"));\n+    String sqlText = \"MERGE INTO \" + targetName + \" AS target \\n\" +\n+                     \"USING \" + sourceName + \" AS source \\n\" +\n+                     \"ON target.id = source.id \\n\" +\n+                     \"WHEN NOT MATCHED THEN INSERT * \";\n+\n+    sql(sqlText, \"\");\n+    sql(\"SELECT * FROM %s ORDER BY id, dep\", targetName);\n+    assertEquals(\"Should have expected rows\",\n+            ImmutableList.of(row(1, \"emp-id-1\"), row(2, \"emp-id-2\"), row(3, \"emp-id-3\")),\n+            sql(\"SELECT * FROM %s ORDER BY id ASC NULLS LAST\", targetName));\n+  }\n+\n+  @Test\n+  public void testEmptyTargetInsertOnlyMatchingRows() throws NoSuchTableException {\n+    createAndInitUnPartitionedTargetTable(targetName);\n+    createAndInitSourceTable(sourceName);\n+    append(sourceName, new Employee(1, \"emp-id-1\"), new Employee(2, \"emp-id-2\"), new Employee(3, \"emp-id-3\"));\n+    String sqlText = \"MERGE INTO \" + targetName + \" AS target \\n\" +\n+                     \"USING \" + sourceName + \" AS source \\n\" +\n+                     \"ON target.id = source.id \\n\" +\n+                     \"WHEN NOT MATCHED AND (source.id >= 2) THEN INSERT * \";\n+\n+    sql(sqlText, \"\");\n+    List<Object[]> res = sql(\"SELECT * FROM %s ORDER BY id, dep\", targetName);\n+    assertEquals(\"Should have expected rows\",\n+            ImmutableList.of(row(2, \"emp-id-2\"), row(3, \"emp-id-3\")),\n+            sql(\"SELECT * FROM %s ORDER BY id ASC NULLS LAST\", targetName));\n+  }\n+\n+  @Test\n+  public void testOnlyUpdate() throws NoSuchTableException {\n+    createAndInitUnPartitionedTargetTable(targetName);\n+    createAndInitSourceTable(sourceName);\n+    append(targetName, new Employee(1, \"emp-id-one\"), new Employee(6, \"emp-id-6\"));\n+    append(sourceName, new Employee(2, \"emp-id-2\"), new Employee(1, \"emp-id-1\"), new Employee(6, \"emp-id-6\"));\n+    String sqlText = \"MERGE INTO \" + targetName + \" AS target \\n\" +\n+            \"USING \" + sourceName + \" AS source \\n\" +\n+            \"ON target.id = source.id \\n\" +\n+            \"WHEN MATCHED AND target.id = 1 THEN UPDATE SET * \";\n+\n+    sql(sqlText, \"\");\n+    List<Object[]> res = sql(\"SELECT * FROM %s ORDER BY id, dep\", targetName);\n+    assertEquals(\"Should have expected rows\",\n+            ImmutableList.of(row(1, \"emp-id-1\"), row(6, \"emp-id-6\")),\n+            sql(\"SELECT * FROM %s ORDER BY id ASC NULLS LAST\", targetName));\n+  }\n+\n+  @Test\n+  public void testOnlyDelete() throws NoSuchTableException {\n+    createAndInitUnPartitionedTargetTable(targetName);\n+    createAndInitSourceTable(sourceName);\n+    append(targetName, new Employee(1, \"emp-id-one\"), new Employee(6, \"emp-id-6\"));\n+    append(sourceName, new Employee(2, \"emp-id-2\"), new Employee(1, \"emp-id-1\"), new Employee(6, \"emp-id-6\"));\n+    String sqlText = \"MERGE INTO \" + targetName + \" AS target \\n\" +", "originalCommit": "946bbded4eb82639a9e3db7fb90172dab827508c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTAzNjE1Mg==", "url": "https://github.com/apache/iceberg/pull/1947#discussion_r559036152", "bodyText": "@rdblue i guess, its not required. I thought if we print out the SQL as part of some error or debugging, it will just format better. I will remove the newlines.", "author": "dilipbiswal", "createdAt": "2021-01-16T20:27:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODc0NzkxNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTA1MjkxOQ==", "url": "https://github.com/apache/iceberg/pull/1947#discussion_r559052919", "bodyText": "I'm fine either way, it was just a surprise.", "author": "rdblue", "createdAt": "2021-01-16T23:34:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODc0NzkxNw=="}], "type": "inlineReview"}, {"oid": "9db80c8f340b2e9c3e11f19a0a687d411c8dbc29", "url": "https://github.com/apache/iceberg/commit/9db80c8f340b2e9c3e11f19a0a687d411c8dbc29", "message": "Spark MERGE INTO Support (copy-on-write implementation", "committedDate": "2021-01-17T08:17:29Z", "type": "commit"}, {"oid": "d82afba8da1da306791e82969c12fb6da0b2f0de", "url": "https://github.com/apache/iceberg/commit/d82afba8da1da306791e82969c12fb6da0b2f0de", "message": "Rebase + Scalastyle + cleancompile", "committedDate": "2021-01-17T08:17:29Z", "type": "commit"}, {"oid": "35f68137c102c9609754c83b8a11a462fd5a8e1f", "url": "https://github.com/apache/iceberg/commit/35f68137c102c9609754c83b8a11a462fd5a8e1f", "message": "Code review + base infrastructure", "committedDate": "2021-01-17T08:17:29Z", "type": "commit"}, {"oid": "c92a2d8e3854ee25d02c87477f33932aa4b6401e", "url": "https://github.com/apache/iceberg/commit/c92a2d8e3854ee25d02c87477f33932aa4b6401e", "message": "Code review comments", "committedDate": "2021-01-17T08:17:29Z", "type": "forcePushed"}, {"oid": "9cb2e86f1962fc02b65065253f5ab3c3c18ade09", "url": "https://github.com/apache/iceberg/commit/9cb2e86f1962fc02b65065253f5ab3c3c18ade09", "message": "Code review comments (Round-2)", "committedDate": "2021-01-17T08:46:12Z", "type": "commit"}, {"oid": "9cb2e86f1962fc02b65065253f5ab3c3c18ade09", "url": "https://github.com/apache/iceberg/commit/9cb2e86f1962fc02b65065253f5ab3c3c18ade09", "message": "Code review comments (Round-2)", "committedDate": "2021-01-17T08:46:12Z", "type": "forcePushed"}, {"oid": "227a1081dfc460840c0c611a01d6eb5fed9de15f", "url": "https://github.com/apache/iceberg/commit/227a1081dfc460840c0c611a01d6eb5fed9de15f", "message": "Missed code review comments", "committedDate": "2021-01-18T22:58:47Z", "type": "commit"}, {"oid": "9f264b752cb6a1c81133985d139f3cdb4b42b008", "url": "https://github.com/apache/iceberg/commit/9f264b752cb6a1c81133985d139f3cdb4b42b008", "message": "More review", "committedDate": "2021-01-18T23:03:17Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTgzNDQ1Mw==", "url": "https://github.com/apache/iceberg/pull/1947#discussion_r559834453", "body": "This should be the merge equivalent.", "bodyText": "This should be the merge equivalent.", "bodyHTML": "<p dir=\"auto\">This should be the merge equivalent.</p>", "author": "rdblue", "createdAt": "2021-01-18T23:27:26Z", "path": "spark3-extensions/src/test/java/org/apache/iceberg/spark/extensions/TestMergeIntoTable.java", "diffHunk": "@@ -0,0 +1,267 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.extensions;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.TableProperties;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.spark.sql.Dataset;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.catalyst.analysis.NoSuchTableException;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Assume;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+\n+import static org.apache.iceberg.TableProperties.DEFAULT_FILE_FORMAT;\n+import static org.apache.iceberg.TableProperties.PARQUET_VECTORIZATION_ENABLED;\n+\n+public class TestMergeIntoTable extends SparkRowLevelOperationsTestBase {\n+  private final String sourceName;\n+  private final String targetName;\n+\n+  public TestMergeIntoTable(String catalogName, String implementation, Map<String, String> config,\n+                            String fileFormat, Boolean vectorized) {\n+    super(catalogName, implementation, config, fileFormat, vectorized);\n+    this.sourceName = tableName(\"source\");\n+    this.targetName = tableName(\"target\");\n+  }\n+\n+  @BeforeClass\n+  public static void setupSparkConf() {\n+    spark.conf().set(\"spark.sql.shuffle.partitions\", \"4\");\n+  }\n+\n+  protected Map<String, String> extraTableProperties() {\n+    return ImmutableMap.of(TableProperties.DELETE_MODE, \"copy-on-write\");", "originalCommit": "227a1081dfc460840c0c611a01d6eb5fed9de15f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "6f293356f830d1fe05056bfd820cc470b1de6110", "url": "https://github.com/apache/iceberg/commit/6f293356f830d1fe05056bfd820cc470b1de6110", "message": "Review - contd.", "committedDate": "2021-01-18T23:38:24Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTgzNzM4OA==", "url": "https://github.com/apache/iceberg/pull/1947#discussion_r559837388", "body": "I don't think that there is a need to test this with both Hive and Hadoop catalogs or with all 3 formats, since the main thing that needs to be tested is conversion and Spark behavior. Also, this doesn't test partitioned tables at all. To fix those, I think this should customize parameters:\r\n\r\n```java\r\n  @Parameterized.Parameters(\r\n      name = \"catalogName = {0}, implementation = {1}, config = {2}, format = {3}, vectorized = {4}, partitioned = {5}\")\r\n  public static Object[][] parameters() {\r\n    return new Object[][] {\r\n        { \"testhive\", SparkCatalog.class.getName(),\r\n            ImmutableMap.of(\r\n                \"type\", \"hive\",\r\n                \"default-namespace\", \"default\"\r\n            ),\r\n            \"parquet\",\r\n            true,\r\n            false\r\n        },\r\n        { \"spark_catalog\", SparkSessionCatalog.class.getName(),\r\n            ImmutableMap.of(\r\n                \"type\", \"hive\",\r\n                \"default-namespace\", \"default\",\r\n                \"clients\", \"1\",\r\n                \"parquet-enabled\", \"false\",\r\n                \"cache-enabled\", \"false\" // Spark will delete tables using v1, leaving the cache out of sync\r\n            ),\r\n            \"parquet\",\r\n            false,\r\n            true\r\n        }\r\n    };\r\n  }\r\n\r\n  public TestMergeIntoTable(String catalogName, String implementation, Map<String, String> config,\r\n                            String fileFormat, Boolean vectorized, Boolean partitioned) {\r\n    super(catalogName, implementation, config, fileFormat, vectorized);\r\n    this.partitioned = partitioned;\r\n    this.sourceName = tableName(\"source\");\r\n    this.targetName = tableName(\"target\");\r\n  }\r\n```\r\n\r\nI also added a `partitioned` boolean and moved all of the `createAndInit` calls into a `@Before`:\r\n\r\n```java\r\n  @Before\r\n  public void createTables() {\r\n    if (partitioned) {\r\n      createAndInitPartitionedTargetTable(targetName);\r\n    } else {\r\n      createAndInitUnPartitionedTargetTable(targetName);\r\n    }\r\n    createAndInitSourceTable(sourceName);\r\n  }\r\n```\r\n\r\nWith those changes, tests run faster and cover partitioned tables.", "bodyText": "I don't think that there is a need to test this with both Hive and Hadoop catalogs or with all 3 formats, since the main thing that needs to be tested is conversion and Spark behavior. Also, this doesn't test partitioned tables at all. To fix those, I think this should customize parameters:\n  @Parameterized.Parameters(\n      name = \"catalogName = {0}, implementation = {1}, config = {2}, format = {3}, vectorized = {4}, partitioned = {5}\")\n  public static Object[][] parameters() {\n    return new Object[][] {\n        { \"testhive\", SparkCatalog.class.getName(),\n            ImmutableMap.of(\n                \"type\", \"hive\",\n                \"default-namespace\", \"default\"\n            ),\n            \"parquet\",\n            true,\n            false\n        },\n        { \"spark_catalog\", SparkSessionCatalog.class.getName(),\n            ImmutableMap.of(\n                \"type\", \"hive\",\n                \"default-namespace\", \"default\",\n                \"clients\", \"1\",\n                \"parquet-enabled\", \"false\",\n                \"cache-enabled\", \"false\" // Spark will delete tables using v1, leaving the cache out of sync\n            ),\n            \"parquet\",\n            false,\n            true\n        }\n    };\n  }\n\n  public TestMergeIntoTable(String catalogName, String implementation, Map<String, String> config,\n                            String fileFormat, Boolean vectorized, Boolean partitioned) {\n    super(catalogName, implementation, config, fileFormat, vectorized);\n    this.partitioned = partitioned;\n    this.sourceName = tableName(\"source\");\n    this.targetName = tableName(\"target\");\n  }\nI also added a partitioned boolean and moved all of the createAndInit calls into a @Before:\n  @Before\n  public void createTables() {\n    if (partitioned) {\n      createAndInitPartitionedTargetTable(targetName);\n    } else {\n      createAndInitUnPartitionedTargetTable(targetName);\n    }\n    createAndInitSourceTable(sourceName);\n  }\nWith those changes, tests run faster and cover partitioned tables.", "bodyHTML": "<p dir=\"auto\">I don't think that there is a need to test this with both Hive and Hadoop catalogs or with all 3 formats, since the main thing that needs to be tested is conversion and Spark behavior. Also, this doesn't test partitioned tables at all. To fix those, I think this should customize parameters:</p>\n<div class=\"highlight highlight-source-java position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"  @Parameterized.Parameters(\n      name = &quot;catalogName = {0}, implementation = {1}, config = {2}, format = {3}, vectorized = {4}, partitioned = {5}&quot;)\n  public static Object[][] parameters() {\n    return new Object[][] {\n        { &quot;testhive&quot;, SparkCatalog.class.getName(),\n            ImmutableMap.of(\n                &quot;type&quot;, &quot;hive&quot;,\n                &quot;default-namespace&quot;, &quot;default&quot;\n            ),\n            &quot;parquet&quot;,\n            true,\n            false\n        },\n        { &quot;spark_catalog&quot;, SparkSessionCatalog.class.getName(),\n            ImmutableMap.of(\n                &quot;type&quot;, &quot;hive&quot;,\n                &quot;default-namespace&quot;, &quot;default&quot;,\n                &quot;clients&quot;, &quot;1&quot;,\n                &quot;parquet-enabled&quot;, &quot;false&quot;,\n                &quot;cache-enabled&quot;, &quot;false&quot; // Spark will delete tables using v1, leaving the cache out of sync\n            ),\n            &quot;parquet&quot;,\n            false,\n            true\n        }\n    };\n  }\n\n  public TestMergeIntoTable(String catalogName, String implementation, Map&lt;String, String&gt; config,\n                            String fileFormat, Boolean vectorized, Boolean partitioned) {\n    super(catalogName, implementation, config, fileFormat, vectorized);\n    this.partitioned = partitioned;\n    this.sourceName = tableName(&quot;source&quot;);\n    this.targetName = tableName(&quot;target&quot;);\n  }\n\"><pre>  <span class=\"pl-k\">@Parameterized.Parameters</span>(\n      <span class=\"pl-c1\">name</span> <span class=\"pl-k\">=</span> <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>catalogName = {0}, implementation = {1}, config = {2}, format = {3}, vectorized = {4}, partitioned = {5}<span class=\"pl-pds\">\"</span></span>)\n  <span class=\"pl-k\">public</span> <span class=\"pl-k\">static</span> <span class=\"pl-k\">Object</span>[][] parameters() {\n    <span class=\"pl-k\">return</span> <span class=\"pl-k\">new</span> <span class=\"pl-smi\">Object</span>[][] {\n        { <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>testhive<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-smi\">SparkCatalog</span><span class=\"pl-k\">.</span>class<span class=\"pl-k\">.</span>getName(),\n            <span class=\"pl-smi\">ImmutableMap</span><span class=\"pl-k\">.</span>of(\n                <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>type<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>hive<span class=\"pl-pds\">\"</span></span>,\n                <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>default-namespace<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>default<span class=\"pl-pds\">\"</span></span>\n            ),\n            <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>parquet<span class=\"pl-pds\">\"</span></span>,\n            <span class=\"pl-c1\">true</span>,\n            <span class=\"pl-c1\">false</span>\n        },\n        { <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>spark_catalog<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-smi\">SparkSessionCatalog</span><span class=\"pl-k\">.</span>class<span class=\"pl-k\">.</span>getName(),\n            <span class=\"pl-smi\">ImmutableMap</span><span class=\"pl-k\">.</span>of(\n                <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>type<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>hive<span class=\"pl-pds\">\"</span></span>,\n                <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>default-namespace<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>default<span class=\"pl-pds\">\"</span></span>,\n                <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>clients<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>1<span class=\"pl-pds\">\"</span></span>,\n                <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>parquet-enabled<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>false<span class=\"pl-pds\">\"</span></span>,\n                <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>cache-enabled<span class=\"pl-pds\">\"</span></span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>false<span class=\"pl-pds\">\"</span></span> <span class=\"pl-c\"><span class=\"pl-c\">//</span> Spark will delete tables using v1, leaving the cache out of sync</span>\n            ),\n            <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>parquet<span class=\"pl-pds\">\"</span></span>,\n            <span class=\"pl-c1\">false</span>,\n            <span class=\"pl-c1\">true</span>\n        }\n    };\n  }\n\n  <span class=\"pl-k\">public</span> TestMergeIntoTable(<span class=\"pl-smi\">String</span> catalogName, <span class=\"pl-smi\">String</span> implementation, <span class=\"pl-k\">Map&lt;<span class=\"pl-smi\">String</span>, <span class=\"pl-smi\">String</span>&gt;</span> config,\n                            <span class=\"pl-smi\">String</span> fileFormat, <span class=\"pl-smi\">Boolean</span> vectorized, <span class=\"pl-smi\">Boolean</span> partitioned) {\n    <span class=\"pl-c1\">super</span>(catalogName, implementation, config, fileFormat, vectorized);\n    <span class=\"pl-c1\">this</span><span class=\"pl-k\">.</span>partitioned <span class=\"pl-k\">=</span> partitioned;\n    <span class=\"pl-c1\">this</span><span class=\"pl-k\">.</span>sourceName <span class=\"pl-k\">=</span> tableName(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>source<span class=\"pl-pds\">\"</span></span>);\n    <span class=\"pl-c1\">this</span><span class=\"pl-k\">.</span>targetName <span class=\"pl-k\">=</span> tableName(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>target<span class=\"pl-pds\">\"</span></span>);\n  }</pre></div>\n<p dir=\"auto\">I also added a <code>partitioned</code> boolean and moved all of the <code>createAndInit</code> calls into a <code>@Before</code>:</p>\n<div class=\"highlight highlight-source-java position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"  @Before\n  public void createTables() {\n    if (partitioned) {\n      createAndInitPartitionedTargetTable(targetName);\n    } else {\n      createAndInitUnPartitionedTargetTable(targetName);\n    }\n    createAndInitSourceTable(sourceName);\n  }\n\"><pre>  <span class=\"pl-k\">@Before</span>\n  <span class=\"pl-k\">public</span> <span class=\"pl-k\">void</span> createTables() {\n    <span class=\"pl-k\">if</span> (partitioned) {\n      createAndInitPartitionedTargetTable(targetName);\n    } <span class=\"pl-k\">else</span> {\n      createAndInitUnPartitionedTargetTable(targetName);\n    }\n    createAndInitSourceTable(sourceName);\n  }</pre></div>\n<p dir=\"auto\">With those changes, tests run faster and cover partitioned tables.</p>", "author": "rdblue", "createdAt": "2021-01-18T23:40:27Z", "path": "spark3-extensions/src/test/java/org/apache/iceberg/spark/extensions/TestMergeIntoTable.java", "diffHunk": "@@ -0,0 +1,267 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.extensions;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.TableProperties;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.spark.sql.Dataset;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.catalyst.analysis.NoSuchTableException;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Assume;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+\n+import static org.apache.iceberg.TableProperties.DEFAULT_FILE_FORMAT;\n+import static org.apache.iceberg.TableProperties.PARQUET_VECTORIZATION_ENABLED;\n+\n+public class TestMergeIntoTable extends SparkRowLevelOperationsTestBase {\n+  private final String sourceName;\n+  private final String targetName;\n+\n+  public TestMergeIntoTable(String catalogName, String implementation, Map<String, String> config,", "originalCommit": "227a1081dfc460840c0c611a01d6eb5fed9de15f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTgzOTk3Nw==", "url": "https://github.com/apache/iceberg/pull/1947#discussion_r559839977", "bodyText": "@rdblue Ryan, i had added the partitioning test cases in the grouby/sort pr ? I wasn't doing it via parameter as i was testing individual part and sort expressions. Can you please take a quick look ? I am thinking how those tests work with the proposed changes of creating tables in @before and also with the introduction of partition parameter.", "author": "dilipbiswal", "createdAt": "2021-01-18T23:52:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTgzNzM4OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTg0MjY2Mg==", "url": "https://github.com/apache/iceberg/pull/1947#discussion_r559842662", "bodyText": "Okay, sounds fine to me. Let's still make the parameter changes, but remove the partitioned parameter.", "author": "rdblue", "createdAt": "2021-01-19T00:06:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTgzNzM4OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTg0Mjk3Mg==", "url": "https://github.com/apache/iceberg/pull/1947#discussion_r559842972", "bodyText": "ok.. will do. thank you Ryan for doing such a thorough review. Really appreciate !!", "author": "dilipbiswal", "createdAt": "2021-01-19T00:07:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTgzNzM4OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTgzODUwMQ==", "url": "https://github.com/apache/iceberg/pull/1947#discussion_r559838501", "body": "Rather than embedding the names directly, you can pass them to the `sql` method, like `removeTables` does:\r\n\r\n```java\r\nsql(\"MERGE INTO %s AS target USING %s AS source ...\", targetName, sourceName);\r\n```", "bodyText": "Rather than embedding the names directly, you can pass them to the sql method, like removeTables does:\nsql(\"MERGE INTO %s AS target USING %s AS source ...\", targetName, sourceName);", "bodyHTML": "<p dir=\"auto\">Rather than embedding the names directly, you can pass them to the <code>sql</code> method, like <code>removeTables</code> does:</p>\n<div class=\"highlight highlight-source-java position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"sql(&quot;MERGE INTO %s AS target USING %s AS source ...&quot;, targetName, sourceName);\n\"><pre>sql(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>MERGE INTO %s AS target USING %s AS source ...<span class=\"pl-pds\">\"</span></span>, targetName, sourceName);</pre></div>", "author": "rdblue", "createdAt": "2021-01-18T23:45:55Z", "path": "spark3-extensions/src/test/java/org/apache/iceberg/spark/extensions/TestMergeIntoTable.java", "diffHunk": "@@ -0,0 +1,267 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.extensions;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.TableProperties;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.spark.sql.Dataset;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.catalyst.analysis.NoSuchTableException;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Assume;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+\n+import static org.apache.iceberg.TableProperties.DEFAULT_FILE_FORMAT;\n+import static org.apache.iceberg.TableProperties.PARQUET_VECTORIZATION_ENABLED;\n+\n+public class TestMergeIntoTable extends SparkRowLevelOperationsTestBase {\n+  private final String sourceName;\n+  private final String targetName;\n+\n+  public TestMergeIntoTable(String catalogName, String implementation, Map<String, String> config,\n+                            String fileFormat, Boolean vectorized) {\n+    super(catalogName, implementation, config, fileFormat, vectorized);\n+    this.sourceName = tableName(\"source\");\n+    this.targetName = tableName(\"target\");\n+  }\n+\n+  @BeforeClass\n+  public static void setupSparkConf() {\n+    spark.conf().set(\"spark.sql.shuffle.partitions\", \"4\");\n+  }\n+\n+  protected Map<String, String> extraTableProperties() {\n+    return ImmutableMap.of(TableProperties.DELETE_MODE, \"copy-on-write\");\n+  }\n+\n+  @After\n+  public void removeTables() {\n+    sql(\"DROP TABLE IF EXISTS %s\", targetName);\n+    sql(\"DROP TABLE IF EXISTS %s\", sourceName);\n+  }\n+\n+  @Test\n+  public void testEmptyTargetInsertAllNonMatchingRows() throws NoSuchTableException {\n+    createAndInitUnPartitionedTargetTable(targetName);\n+    createAndInitSourceTable(sourceName);\n+    append(sourceName, new Employee(1, \"emp-id-1\"), new Employee(2, \"emp-id-2\"), new Employee(3, \"emp-id-3\"));\n+    String sqlText = \"MERGE INTO \" + targetName + \" AS target \" +\n+                     \"USING \" + sourceName + \" AS source \" +", "originalCommit": "227a1081dfc460840c0c611a01d6eb5fed9de15f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTgzODcxNQ==", "url": "https://github.com/apache/iceberg/pull/1947#discussion_r559838715", "body": "This select has no effect, can you remove it?", "bodyText": "This select has no effect, can you remove it?", "bodyHTML": "<p dir=\"auto\">This select has no effect, can you remove it?</p>", "author": "rdblue", "createdAt": "2021-01-18T23:46:58Z", "path": "spark3-extensions/src/test/java/org/apache/iceberg/spark/extensions/TestMergeIntoTable.java", "diffHunk": "@@ -0,0 +1,267 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.extensions;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.TableProperties;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.spark.sql.Dataset;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.catalyst.analysis.NoSuchTableException;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Assume;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+\n+import static org.apache.iceberg.TableProperties.DEFAULT_FILE_FORMAT;\n+import static org.apache.iceberg.TableProperties.PARQUET_VECTORIZATION_ENABLED;\n+\n+public class TestMergeIntoTable extends SparkRowLevelOperationsTestBase {\n+  private final String sourceName;\n+  private final String targetName;\n+\n+  public TestMergeIntoTable(String catalogName, String implementation, Map<String, String> config,\n+                            String fileFormat, Boolean vectorized) {\n+    super(catalogName, implementation, config, fileFormat, vectorized);\n+    this.sourceName = tableName(\"source\");\n+    this.targetName = tableName(\"target\");\n+  }\n+\n+  @BeforeClass\n+  public static void setupSparkConf() {\n+    spark.conf().set(\"spark.sql.shuffle.partitions\", \"4\");\n+  }\n+\n+  protected Map<String, String> extraTableProperties() {\n+    return ImmutableMap.of(TableProperties.DELETE_MODE, \"copy-on-write\");\n+  }\n+\n+  @After\n+  public void removeTables() {\n+    sql(\"DROP TABLE IF EXISTS %s\", targetName);\n+    sql(\"DROP TABLE IF EXISTS %s\", sourceName);\n+  }\n+\n+  @Test\n+  public void testEmptyTargetInsertAllNonMatchingRows() throws NoSuchTableException {\n+    createAndInitUnPartitionedTargetTable(targetName);\n+    createAndInitSourceTable(sourceName);\n+    append(sourceName, new Employee(1, \"emp-id-1\"), new Employee(2, \"emp-id-2\"), new Employee(3, \"emp-id-3\"));\n+    String sqlText = \"MERGE INTO \" + targetName + \" AS target \" +\n+                     \"USING \" + sourceName + \" AS source \" +\n+                     \"ON target.id = source.id \" +\n+                     \"WHEN NOT MATCHED THEN INSERT * \";\n+\n+    sql(sqlText);\n+    sql(\"SELECT * FROM %s ORDER BY id, dep\", targetName);", "originalCommit": "227a1081dfc460840c0c611a01d6eb5fed9de15f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTgzOTQ2Ng==", "url": "https://github.com/apache/iceberg/pull/1947#discussion_r559839466", "bodyText": "Looks like there are other cases where SELECT statements run but are not used. Can you remove all of them?", "author": "rdblue", "createdAt": "2021-01-18T23:50:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTgzODcxNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTgzOTA3OQ==", "url": "https://github.com/apache/iceberg/pull/1947#discussion_r559839079", "body": "`res` is not used in this test or others. Can you remove this line?", "bodyText": "res is not used in this test or others. Can you remove this line?", "bodyHTML": "<p dir=\"auto\"><code>res</code> is not used in this test or others. Can you remove this line?</p>", "author": "rdblue", "createdAt": "2021-01-18T23:48:26Z", "path": "spark3-extensions/src/test/java/org/apache/iceberg/spark/extensions/TestMergeIntoTable.java", "diffHunk": "@@ -0,0 +1,267 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.extensions;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.TableProperties;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.spark.sql.Dataset;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.catalyst.analysis.NoSuchTableException;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Assume;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+\n+import static org.apache.iceberg.TableProperties.DEFAULT_FILE_FORMAT;\n+import static org.apache.iceberg.TableProperties.PARQUET_VECTORIZATION_ENABLED;\n+\n+public class TestMergeIntoTable extends SparkRowLevelOperationsTestBase {\n+  private final String sourceName;\n+  private final String targetName;\n+\n+  public TestMergeIntoTable(String catalogName, String implementation, Map<String, String> config,\n+                            String fileFormat, Boolean vectorized) {\n+    super(catalogName, implementation, config, fileFormat, vectorized);\n+    this.sourceName = tableName(\"source\");\n+    this.targetName = tableName(\"target\");\n+  }\n+\n+  @BeforeClass\n+  public static void setupSparkConf() {\n+    spark.conf().set(\"spark.sql.shuffle.partitions\", \"4\");\n+  }\n+\n+  protected Map<String, String> extraTableProperties() {\n+    return ImmutableMap.of(TableProperties.DELETE_MODE, \"copy-on-write\");\n+  }\n+\n+  @After\n+  public void removeTables() {\n+    sql(\"DROP TABLE IF EXISTS %s\", targetName);\n+    sql(\"DROP TABLE IF EXISTS %s\", sourceName);\n+  }\n+\n+  @Test\n+  public void testEmptyTargetInsertAllNonMatchingRows() throws NoSuchTableException {\n+    createAndInitUnPartitionedTargetTable(targetName);\n+    createAndInitSourceTable(sourceName);\n+    append(sourceName, new Employee(1, \"emp-id-1\"), new Employee(2, \"emp-id-2\"), new Employee(3, \"emp-id-3\"));\n+    String sqlText = \"MERGE INTO \" + targetName + \" AS target \" +\n+                     \"USING \" + sourceName + \" AS source \" +\n+                     \"ON target.id = source.id \" +\n+                     \"WHEN NOT MATCHED THEN INSERT * \";\n+\n+    sql(sqlText);\n+    sql(\"SELECT * FROM %s ORDER BY id, dep\", targetName);\n+    assertEquals(\"Should have expected rows\",\n+            ImmutableList.of(row(1, \"emp-id-1\"), row(2, \"emp-id-2\"), row(3, \"emp-id-3\")),\n+            sql(\"SELECT * FROM %s ORDER BY id ASC NULLS LAST\", targetName));\n+  }\n+\n+  @Test\n+  public void testEmptyTargetInsertOnlyMatchingRows() throws NoSuchTableException {\n+    createAndInitUnPartitionedTargetTable(targetName);\n+    createAndInitSourceTable(sourceName);\n+    append(sourceName, new Employee(1, \"emp-id-1\"), new Employee(2, \"emp-id-2\"), new Employee(3, \"emp-id-3\"));\n+    String sqlText = \"MERGE INTO \" + targetName + \" AS target \" +\n+                     \"USING \" + sourceName + \" AS source \" +\n+                     \"ON target.id = source.id \" +\n+                     \"WHEN NOT MATCHED AND (source.id >= 2) THEN INSERT * \";\n+\n+    sql(sqlText);\n+    List<Object[]> res = sql(\"SELECT * FROM %s ORDER BY id, dep\", targetName);", "originalCommit": "227a1081dfc460840c0c611a01d6eb5fed9de15f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTgzOTM5Mg==", "url": "https://github.com/apache/iceberg/pull/1947#discussion_r559839392", "bodyText": "@rdblue sorry... had used this for debugging and forgot to remove it later.", "author": "dilipbiswal", "createdAt": "2021-01-18T23:49:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTgzOTA3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTg0MTU5Nw==", "url": "https://github.com/apache/iceberg/pull/1947#discussion_r559841597", "body": "The employee dep is identical for both records with id 6, so the assertion can't distinguish between the case where employee 6 is replaced or not. Could you update the original target data to `emp-id-six` and assert that it is unchanged because of the `target.id = 1` requirement?", "bodyText": "The employee dep is identical for both records with id 6, so the assertion can't distinguish between the case where employee 6 is replaced or not. Could you update the original target data to emp-id-six and assert that it is unchanged because of the target.id = 1 requirement?", "bodyHTML": "<p dir=\"auto\">The employee dep is identical for both records with id 6, so the assertion can't distinguish between the case where employee 6 is replaced or not. Could you update the original target data to <code>emp-id-six</code> and assert that it is unchanged because of the <code>target.id = 1</code> requirement?</p>", "author": "rdblue", "createdAt": "2021-01-19T00:00:44Z", "path": "spark3-extensions/src/test/java/org/apache/iceberg/spark/extensions/TestMergeIntoTable.java", "diffHunk": "@@ -0,0 +1,267 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.extensions;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.TableProperties;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.spark.sql.Dataset;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.catalyst.analysis.NoSuchTableException;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Assume;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+\n+import static org.apache.iceberg.TableProperties.DEFAULT_FILE_FORMAT;\n+import static org.apache.iceberg.TableProperties.PARQUET_VECTORIZATION_ENABLED;\n+\n+public class TestMergeIntoTable extends SparkRowLevelOperationsTestBase {\n+  private final String sourceName;\n+  private final String targetName;\n+\n+  public TestMergeIntoTable(String catalogName, String implementation, Map<String, String> config,\n+                            String fileFormat, Boolean vectorized) {\n+    super(catalogName, implementation, config, fileFormat, vectorized);\n+    this.sourceName = tableName(\"source\");\n+    this.targetName = tableName(\"target\");\n+  }\n+\n+  @BeforeClass\n+  public static void setupSparkConf() {\n+    spark.conf().set(\"spark.sql.shuffle.partitions\", \"4\");\n+  }\n+\n+  protected Map<String, String> extraTableProperties() {\n+    return ImmutableMap.of(TableProperties.DELETE_MODE, \"copy-on-write\");\n+  }\n+\n+  @After\n+  public void removeTables() {\n+    sql(\"DROP TABLE IF EXISTS %s\", targetName);\n+    sql(\"DROP TABLE IF EXISTS %s\", sourceName);\n+  }\n+\n+  @Test\n+  public void testEmptyTargetInsertAllNonMatchingRows() throws NoSuchTableException {\n+    createAndInitUnPartitionedTargetTable(targetName);\n+    createAndInitSourceTable(sourceName);\n+    append(sourceName, new Employee(1, \"emp-id-1\"), new Employee(2, \"emp-id-2\"), new Employee(3, \"emp-id-3\"));\n+    String sqlText = \"MERGE INTO \" + targetName + \" AS target \" +\n+                     \"USING \" + sourceName + \" AS source \" +\n+                     \"ON target.id = source.id \" +\n+                     \"WHEN NOT MATCHED THEN INSERT * \";\n+\n+    sql(sqlText);\n+    sql(\"SELECT * FROM %s ORDER BY id, dep\", targetName);\n+    assertEquals(\"Should have expected rows\",\n+            ImmutableList.of(row(1, \"emp-id-1\"), row(2, \"emp-id-2\"), row(3, \"emp-id-3\")),\n+            sql(\"SELECT * FROM %s ORDER BY id ASC NULLS LAST\", targetName));\n+  }\n+\n+  @Test\n+  public void testEmptyTargetInsertOnlyMatchingRows() throws NoSuchTableException {\n+    createAndInitUnPartitionedTargetTable(targetName);\n+    createAndInitSourceTable(sourceName);\n+    append(sourceName, new Employee(1, \"emp-id-1\"), new Employee(2, \"emp-id-2\"), new Employee(3, \"emp-id-3\"));\n+    String sqlText = \"MERGE INTO \" + targetName + \" AS target \" +\n+                     \"USING \" + sourceName + \" AS source \" +\n+                     \"ON target.id = source.id \" +\n+                     \"WHEN NOT MATCHED AND (source.id >= 2) THEN INSERT * \";\n+\n+    sql(sqlText);\n+    List<Object[]> res = sql(\"SELECT * FROM %s ORDER BY id, dep\", targetName);\n+    assertEquals(\"Should have expected rows\",\n+            ImmutableList.of(row(2, \"emp-id-2\"), row(3, \"emp-id-3\")),\n+            sql(\"SELECT * FROM %s ORDER BY id ASC NULLS LAST\", targetName));\n+  }\n+\n+  @Test\n+  public void testOnlyUpdate() throws NoSuchTableException {\n+    createAndInitUnPartitionedTargetTable(targetName);\n+    createAndInitSourceTable(sourceName);\n+    append(targetName, new Employee(1, \"emp-id-one\"), new Employee(6, \"emp-id-6\"));", "originalCommit": "227a1081dfc460840c0c611a01d6eb5fed9de15f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "d7caece5de862437092fbbd58702f41fc66d8fdd", "url": "https://github.com/apache/iceberg/commit/d7caece5de862437092fbbd58702f41fc66d8fdd", "message": "Code review", "committedDate": "2021-01-19T01:00:46Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTg2MzQ3MA==", "url": "https://github.com/apache/iceberg/pull/1947#discussion_r559863470", "body": "Nit: it looks like there are unnecessary string literals. `\" \" + \"MERGE ...\"` can be updated to `\" MERGE ...\"`.", "bodyText": "Nit: it looks like there are unnecessary string literals. \" \" + \"MERGE ...\" can be updated to \" MERGE ...\".", "bodyHTML": "<p dir=\"auto\">Nit: it looks like there are unnecessary string literals. <code>\" \" + \"MERGE ...\"</code> can be updated to <code>\" MERGE ...\"</code>.</p>", "author": "rdblue", "createdAt": "2021-01-19T01:39:07Z", "path": "spark3-extensions/src/test/java/org/apache/iceberg/spark/extensions/TestMergeIntoTable.java", "diffHunk": "@@ -0,0 +1,275 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.extensions;\n+\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.TableProperties;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.spark.SparkCatalog;\n+import org.apache.iceberg.spark.SparkSessionCatalog;\n+import org.apache.spark.sql.Dataset;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.catalyst.analysis.NoSuchTableException;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Assume;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import org.junit.runners.Parameterized;\n+\n+import static org.apache.iceberg.TableProperties.DEFAULT_FILE_FORMAT;\n+import static org.apache.iceberg.TableProperties.PARQUET_VECTORIZATION_ENABLED;\n+\n+public class TestMergeIntoTable extends SparkRowLevelOperationsTestBase {\n+  private final String sourceName;\n+  private final String targetName;\n+\n+  @Parameterized.Parameters(\n+      name = \"catalogName = {0}, implementation = {1}, config = {2}, format = {3}, vectorized = {4}\")\n+  public static Object[][] parameters() {\n+    return new Object[][] {\n+        { \"testhive\", SparkCatalog.class.getName(),\n+            ImmutableMap.of(\n+                \"type\", \"hive\",\n+                \"default-namespace\", \"default\"\n+            ),\n+            \"parquet\",\n+            true\n+        },\n+        { \"spark_catalog\", SparkSessionCatalog.class.getName(),\n+            ImmutableMap.of(\n+                \"type\", \"hive\",\n+                \"default-namespace\", \"default\",\n+                \"clients\", \"1\",\n+                \"parquet-enabled\", \"false\",\n+                \"cache-enabled\", \"false\" // Spark will delete tables using v1, leaving the cache out of sync\n+            ),\n+            \"parquet\",\n+            false\n+        }\n+    };\n+  }\n+\n+  public TestMergeIntoTable(String catalogName, String implementation, Map<String, String> config,\n+                            String fileFormat, Boolean vectorized) {\n+    super(catalogName, implementation, config, fileFormat, vectorized);\n+    this.sourceName = tableName(\"source\");\n+    this.targetName = tableName(\"target\");\n+  }\n+\n+  @BeforeClass\n+  public static void setupSparkConf() {\n+    spark.conf().set(\"spark.sql.shuffle.partitions\", \"4\");\n+  }\n+\n+  protected Map<String, String> extraTableProperties() {\n+    return ImmutableMap.of(TableProperties.MERGE_MODE, TableProperties.MERGE_MODE_DEFAULT);\n+  }\n+\n+  @Before\n+  public void createTables() {\n+    createAndInitUnPartitionedTargetTable(targetName);\n+    createAndInitSourceTable(sourceName);\n+  }\n+\n+  @After\n+  public void removeTables() {\n+    sql(\"DROP TABLE IF EXISTS %s\", targetName);\n+    sql(\"DROP TABLE IF EXISTS %s\", sourceName);\n+  }\n+\n+  @Test\n+  public void testEmptyTargetInsertAllNonMatchingRows() throws NoSuchTableException {\n+    append(sourceName, new Employee(1, \"emp-id-1\"), new Employee(2, \"emp-id-2\"), new Employee(3, \"emp-id-3\"));\n+    String sqlText = \"MERGE INTO %s AS target \" +\n+                     \"USING %s AS source \" +\n+                     \"ON target.id = source.id \" +\n+                     \"WHEN NOT MATCHED THEN INSERT * \";\n+\n+    sql(sqlText, targetName, sourceName);\n+    assertEquals(\"Should have expected rows\",\n+            ImmutableList.of(row(1, \"emp-id-1\"), row(2, \"emp-id-2\"), row(3, \"emp-id-3\")),\n+            sql(\"SELECT * FROM %s ORDER BY id ASC NULLS LAST\", targetName));\n+  }\n+\n+  @Test\n+  public void testEmptyTargetInsertOnlyMatchingRows() throws NoSuchTableException {\n+    append(sourceName, new Employee(1, \"emp-id-1\"), new Employee(2, \"emp-id-2\"), new Employee(3, \"emp-id-3\"));\n+    String sqlText = \"MERGE INTO %s AS target \" +\n+                     \"USING %s AS source \" +\n+                     \"ON target.id = source.id \" +\n+                     \"WHEN NOT MATCHED AND (source.id >= 2) THEN INSERT * \";\n+\n+    sql(sqlText, targetName, sourceName);\n+    assertEquals(\"Should have expected rows\",\n+            ImmutableList.of(row(2, \"emp-id-2\"), row(3, \"emp-id-3\")),\n+            sql(\"SELECT * FROM %s ORDER BY id ASC NULLS LAST\", targetName));\n+  }\n+\n+  @Test\n+  public void testOnlyUpdate() throws NoSuchTableException {\n+    append(targetName, new Employee(1, \"emp-id-one\"), new Employee(6, \"emp-id-six\"));\n+    append(sourceName, new Employee(2, \"emp-id-2\"), new Employee(1, \"emp-id-1\"), new Employee(6, \"emp-id-6\"));\n+    String sqlText = \"MERGE INTO %s AS target \" +\n+            \"USING %s AS source \" +\n+            \"ON target.id = source.id \" +\n+            \"WHEN MATCHED AND target.id = 1 THEN UPDATE SET * \";\n+\n+    sql(sqlText, targetName, sourceName);\n+    assertEquals(\"Should have expected rows\",\n+            ImmutableList.of(row(1, \"emp-id-1\"), row(6, \"emp-id-six\")),\n+            sql(\"SELECT * FROM %s ORDER BY id ASC NULLS LAST\", targetName));\n+  }\n+\n+  @Test\n+  public void testOnlyDelete() throws NoSuchTableException {\n+    append(targetName, new Employee(1, \"emp-id-one\"), new Employee(6, \"emp-id-6\"));\n+    append(sourceName, new Employee(2, \"emp-id-2\"), new Employee(1, \"emp-id-1\"), new Employee(6, \"emp-id-6\"));\n+    String sqlText = \"MERGE INTO %s AS target \" +\n+            \"USING %s AS source \" +\n+            \"ON target.id = source.id \" +\n+            \"WHEN MATCHED AND target.id = 6 THEN DELETE\";\n+\n+    sql(sqlText, targetName, sourceName);\n+    assertEquals(\"Should have expected rows\",\n+            ImmutableList.of(row(1, \"emp-id-one\")),\n+            sql(\"SELECT * FROM %s ORDER BY id ASC NULLS LAST\", targetName));\n+  }\n+\n+  @Test\n+  public void testAllCauses() throws NoSuchTableException {\n+    append(targetName, new Employee(1, \"emp-id-one\"), new Employee(6, \"emp-id-6\"));\n+    append(sourceName, new Employee(2, \"emp-id-2\"), new Employee(1, \"emp-id-1\"), new Employee(6, \"emp-id-6\"));\n+    String sqlText = \"MERGE INTO %s AS target \" +\n+                     \"USING %s AS source \" +\n+                     \"ON target.id = source.id \" +\n+                     \"WHEN MATCHED AND target.id = 1 THEN UPDATE SET * \" +\n+                     \"WHEN MATCHED AND target.id = 6 THEN DELETE \" +\n+                     \"WHEN NOT MATCHED AND source.id = 2 THEN INSERT * \";\n+\n+    sql(sqlText, targetName, sourceName);\n+    assertEquals(\"Should have expected rows\",\n+            ImmutableList.of(row(1, \"emp-id-1\"), row(2, \"emp-id-2\")),\n+            sql(\"SELECT * FROM %s ORDER BY id ASC NULLS LAST\", targetName));\n+  }\n+\n+  @Test\n+  public void testAllCausesWithExplicitColumnSpecification() throws NoSuchTableException {\n+    append(targetName, new Employee(1, \"emp-id-one\"), new Employee(6, \"emp-id-6\"));\n+    append(sourceName, new Employee(2, \"emp-id-2\"), new Employee(1, \"emp-id-1\"), new Employee(6, \"emp-id-6\"));\n+    String sqlText = \"MERGE INTO %s AS target \" +\n+            \"USING %s AS source \" +\n+            \"ON target.id = source.id \" +\n+            \"WHEN MATCHED AND target.id = 1 THEN UPDATE SET target.id = source.id, target.dep = source.dep \" +\n+            \"WHEN MATCHED AND target.id = 6 THEN DELETE \" +\n+            \"WHEN NOT MATCHED AND source.id = 2 THEN INSERT (target.id, target.dep) VALUES (source.id, source.dep) \";\n+\n+    sql(sqlText, targetName, sourceName);\n+    assertEquals(\"Should have expected rows\",\n+            ImmutableList.of(row(1, \"emp-id-1\"), row(2, \"emp-id-2\")),\n+            sql(\"SELECT * FROM %s ORDER BY id ASC NULLS LAST\", targetName));\n+  }\n+\n+  @Test\n+  public void testSourceCTE() throws NoSuchTableException {\n+    Assume.assumeFalse(catalogName.equalsIgnoreCase(\"testhadoop\"));\n+    Assume.assumeFalse(catalogName.equalsIgnoreCase(\"testhive\"));\n+\n+    append(targetName, new Employee(2, \"emp-id-two\"), new Employee(6, \"emp-id-6\"));\n+    append(sourceName, new Employee(2, \"emp-id-3\"), new Employee(1, \"emp-id-2\"), new Employee(5, \"emp-id-6\"));\n+    String sourceCTE = \"WITH cte1 AS (SELECT id + 1 AS id, dep FROM source)\";\n+    String sqlText = sourceCTE + \" \" + \"MERGE INTO %s AS target \" +", "originalCommit": "d7caece5de862437092fbbd58702f41fc66d8fdd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "9fadc1d85e60d70f91b180bd5352903916cc13fb", "url": "https://github.com/apache/iceberg/commit/9fadc1d85e60d70f91b180bd5352903916cc13fb", "message": "More review", "committedDate": "2021-01-19T02:23:08Z", "type": "commit"}]}