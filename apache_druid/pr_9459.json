{"pr_number": 9459, "pr_title": "Ability to Delete task logs and segments from S3", "pr_author": "zachjsh", "pr_createdAt": "2020-03-05T08:10:53Z", "pr_url": "https://github.com/apache/druid/pull/9459", "timeline": [{"oid": "914510f1cf7bc3f1de0a08a2e2127ffb807a04f2", "url": "https://github.com/apache/druid/commit/914510f1cf7bc3f1de0a08a2e2127ffb807a04f2", "message": "Ability to Delete task logs and segments from S3\n\n* implement ability to delete all tasks logs or all task logs\n  written before a particular date when written to S3\n* implement ability to delete all segments from S3 deep storage\n* upgrade version of aws SDK in use", "committedDate": "2020-03-05T08:09:00Z", "type": "commit"}, {"oid": "5d505a1d23d79c88261011d5abd9d670401b107b", "url": "https://github.com/apache/druid/commit/5d505a1d23d79c88261011d5abd9d670401b107b", "message": "* update licenses for updated AWS SDK version", "committedDate": "2020-03-05T08:14:22Z", "type": "commit"}, {"oid": "2af8070937c585eefa012a1dec96751fa0e562fc", "url": "https://github.com/apache/druid/commit/2af8070937c585eefa012a1dec96751fa0e562fc", "message": "* fix bug in iterating through results from S3\n* revert back to original version of AWS SDK", "committedDate": "2020-03-06T00:57:34Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODY4MjM3OQ==", "url": "https://github.com/apache/druid/pull/9459#discussion_r388682379", "body": "Hmm, this block is almost identical to the block in `S3TaskLogs.killOlderThan`, and both partially very close to what `ObjectSummaryIterator` is providing.\r\n\r\nI think it would be nicer if this class and `S3TaskLogs` could use `ObjectSummaryIterator`, and if the method that does the bulk key delete can be put in a shared method in `S3Utils`.\r\n\r\nCan I recommend something like this in `S3Utils`?\r\n```java\r\n  public static void deleteObjectsInPath(\r\n      ServerSideEncryptingAmazonS3 s3Client,\r\n      S3InputDataConfig config,\r\n      String bucket,\r\n      String prefix,\r\n      Predicate<S3ObjectSummary> filter\r\n  )\r\n      throws Exception\r\n  {\r\n    final List<DeleteObjectsRequest.KeyVersion> keysToDelete = new ArrayList<>(config.getMaxListingLength());\r\n    final ObjectSummaryIterator iterator = new ObjectSummaryIterator(\r\n        s3Client,\r\n        ImmutableList.of(new CloudObjectLocation(bucket, prefix).toUri(\"s3\")),\r\n        config.getMaxListingLength()\r\n    );\r\n\r\n    while (iterator.hasNext()) {\r\n      final S3ObjectSummary nextObject = iterator.next();\r\n      if (filter.apply(nextObject)) {\r\n        keysToDelete.add(new DeleteObjectsRequest.KeyVersion(nextObject.getKey()));\r\n        if (keysToDelete.size() == config.getMaxListingLength()) {\r\n          deleteBucketKeys(s3Client, bucket, keysToDelete);\r\n          keysToDelete.clear();\r\n        }\r\n      }\r\n    }\r\n\r\n    if (keysToDelete.size() > 0) {\r\n      deleteBucketKeys(s3Client, bucket, keysToDelete);\r\n    }\r\n  }\r\n\r\n  public static void deleteBucketKeys(\r\n      ServerSideEncryptingAmazonS3 s3Client,\r\n      String bucket,\r\n      List<DeleteObjectsRequest.KeyVersion> keysToDelete\r\n  )\r\n      throws Exception\r\n  {\r\n    DeleteObjectsRequest deleteRequest = new DeleteObjectsRequest(bucket).withKeys(keysToDelete);\r\n    S3Utils.retryS3Operation(() -> {\r\n      s3Client.deleteObjects(deleteRequest);\r\n      return null;\r\n    });\r\n  }\r\n```\r\nThen, not only does it share all the code for listing objects, it also pushes down the retry to the specific API calls to list and delete, instead of wrapping the entire loop, which I think is better.\r\n\r\nIf you make a change like this, then the kill calls become something like:\r\n```java\r\n  @Override\r\n  public void killAll() throws IOException\r\n  {\r\n    try {\r\n      S3Utils.deleteObjectsInPath(\r\n          s3Client,\r\n          inputDataConfig,\r\n          segmentPusherConfig.getBucket(),\r\n          segmentPusherConfig.getBaseKey(),\r\n          Predicates.alwaysTrue()\r\n      );\r\n    }\r\n    catch (Exception e) {\r\n      log.error(\"Error occurred while deleting segment files from s3. Error: %s\", e.getMessage());\r\n      throw new IOException(e);\r\n    }\r\n  }\r\n```\r\nand \r\n```java\r\n  @Override\r\n  public void killOlderThan(long timestamp) throws IOException\r\n  {\r\n    try {\r\n      S3Utils.deleteObjectsInPath(\r\n          service,\r\n          inputDataConfig,\r\n          config.getS3Bucket(),\r\n          config.getS3Prefix(),\r\n          (object) -> object.getLastModified().getTime() < timestamp\r\n      );\r\n    }\r\n    catch (Exception e) {\r\n      log.error(\"Error occurred while deleting task log files from s3. Error: %s\", e.getMessage());\r\n      throw new IOException(e);\r\n    }\r\n  }\r\n```\r\n\r\n`ObjectSummaryIterator` currently will skip things it thinks are directories, if this is _not_ desirable for deleting segments and task logs, then I would suggest maybe pushing down the predicate to the `ObjectSummaryIterator` so that the existing users can filter out directories, and your usages can get everything or filter by timestamp as appropriate. In addition, if it shouldn't skip directories, it would probably be worth adding a test for what happens when one is present in the list objects response, if not present.\r\n\r\ndisclaimer: I didn't test this in real s3, but did run unit tests which passed after some modifications to expected calls, but would still recommend to review these snippets first to make sure they are correct.\r\n\r\nWhat do you think?", "bodyText": "Hmm, this block is almost identical to the block in S3TaskLogs.killOlderThan, and both partially very close to what ObjectSummaryIterator is providing.\nI think it would be nicer if this class and S3TaskLogs could use ObjectSummaryIterator, and if the method that does the bulk key delete can be put in a shared method in S3Utils.\nCan I recommend something like this in S3Utils?\n  public static void deleteObjectsInPath(\n      ServerSideEncryptingAmazonS3 s3Client,\n      S3InputDataConfig config,\n      String bucket,\n      String prefix,\n      Predicate<S3ObjectSummary> filter\n  )\n      throws Exception\n  {\n    final List<DeleteObjectsRequest.KeyVersion> keysToDelete = new ArrayList<>(config.getMaxListingLength());\n    final ObjectSummaryIterator iterator = new ObjectSummaryIterator(\n        s3Client,\n        ImmutableList.of(new CloudObjectLocation(bucket, prefix).toUri(\"s3\")),\n        config.getMaxListingLength()\n    );\n\n    while (iterator.hasNext()) {\n      final S3ObjectSummary nextObject = iterator.next();\n      if (filter.apply(nextObject)) {\n        keysToDelete.add(new DeleteObjectsRequest.KeyVersion(nextObject.getKey()));\n        if (keysToDelete.size() == config.getMaxListingLength()) {\n          deleteBucketKeys(s3Client, bucket, keysToDelete);\n          keysToDelete.clear();\n        }\n      }\n    }\n\n    if (keysToDelete.size() > 0) {\n      deleteBucketKeys(s3Client, bucket, keysToDelete);\n    }\n  }\n\n  public static void deleteBucketKeys(\n      ServerSideEncryptingAmazonS3 s3Client,\n      String bucket,\n      List<DeleteObjectsRequest.KeyVersion> keysToDelete\n  )\n      throws Exception\n  {\n    DeleteObjectsRequest deleteRequest = new DeleteObjectsRequest(bucket).withKeys(keysToDelete);\n    S3Utils.retryS3Operation(() -> {\n      s3Client.deleteObjects(deleteRequest);\n      return null;\n    });\n  }\nThen, not only does it share all the code for listing objects, it also pushes down the retry to the specific API calls to list and delete, instead of wrapping the entire loop, which I think is better.\nIf you make a change like this, then the kill calls become something like:\n  @Override\n  public void killAll() throws IOException\n  {\n    try {\n      S3Utils.deleteObjectsInPath(\n          s3Client,\n          inputDataConfig,\n          segmentPusherConfig.getBucket(),\n          segmentPusherConfig.getBaseKey(),\n          Predicates.alwaysTrue()\n      );\n    }\n    catch (Exception e) {\n      log.error(\"Error occurred while deleting segment files from s3. Error: %s\", e.getMessage());\n      throw new IOException(e);\n    }\n  }\nand\n  @Override\n  public void killOlderThan(long timestamp) throws IOException\n  {\n    try {\n      S3Utils.deleteObjectsInPath(\n          service,\n          inputDataConfig,\n          config.getS3Bucket(),\n          config.getS3Prefix(),\n          (object) -> object.getLastModified().getTime() < timestamp\n      );\n    }\n    catch (Exception e) {\n      log.error(\"Error occurred while deleting task log files from s3. Error: %s\", e.getMessage());\n      throw new IOException(e);\n    }\n  }\nObjectSummaryIterator currently will skip things it thinks are directories, if this is not desirable for deleting segments and task logs, then I would suggest maybe pushing down the predicate to the ObjectSummaryIterator so that the existing users can filter out directories, and your usages can get everything or filter by timestamp as appropriate. In addition, if it shouldn't skip directories, it would probably be worth adding a test for what happens when one is present in the list objects response, if not present.\ndisclaimer: I didn't test this in real s3, but did run unit tests which passed after some modifications to expected calls, but would still recommend to review these snippets first to make sure they are correct.\nWhat do you think?", "bodyHTML": "<p dir=\"auto\">Hmm, this block is almost identical to the block in <code>S3TaskLogs.killOlderThan</code>, and both partially very close to what <code>ObjectSummaryIterator</code> is providing.</p>\n<p dir=\"auto\">I think it would be nicer if this class and <code>S3TaskLogs</code> could use <code>ObjectSummaryIterator</code>, and if the method that does the bulk key delete can be put in a shared method in <code>S3Utils</code>.</p>\n<p dir=\"auto\">Can I recommend something like this in <code>S3Utils</code>?</p>\n<div class=\"highlight highlight-source-java position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"  public static void deleteObjectsInPath(\n      ServerSideEncryptingAmazonS3 s3Client,\n      S3InputDataConfig config,\n      String bucket,\n      String prefix,\n      Predicate&lt;S3ObjectSummary&gt; filter\n  )\n      throws Exception\n  {\n    final List&lt;DeleteObjectsRequest.KeyVersion&gt; keysToDelete = new ArrayList&lt;&gt;(config.getMaxListingLength());\n    final ObjectSummaryIterator iterator = new ObjectSummaryIterator(\n        s3Client,\n        ImmutableList.of(new CloudObjectLocation(bucket, prefix).toUri(&quot;s3&quot;)),\n        config.getMaxListingLength()\n    );\n\n    while (iterator.hasNext()) {\n      final S3ObjectSummary nextObject = iterator.next();\n      if (filter.apply(nextObject)) {\n        keysToDelete.add(new DeleteObjectsRequest.KeyVersion(nextObject.getKey()));\n        if (keysToDelete.size() == config.getMaxListingLength()) {\n          deleteBucketKeys(s3Client, bucket, keysToDelete);\n          keysToDelete.clear();\n        }\n      }\n    }\n\n    if (keysToDelete.size() &gt; 0) {\n      deleteBucketKeys(s3Client, bucket, keysToDelete);\n    }\n  }\n\n  public static void deleteBucketKeys(\n      ServerSideEncryptingAmazonS3 s3Client,\n      String bucket,\n      List&lt;DeleteObjectsRequest.KeyVersion&gt; keysToDelete\n  )\n      throws Exception\n  {\n    DeleteObjectsRequest deleteRequest = new DeleteObjectsRequest(bucket).withKeys(keysToDelete);\n    S3Utils.retryS3Operation(() -&gt; {\n      s3Client.deleteObjects(deleteRequest);\n      return null;\n    });\n  }\n\"><pre>  <span class=\"pl-k\">public</span> <span class=\"pl-k\">static</span> <span class=\"pl-k\">void</span> deleteObjectsInPath(\n      <span class=\"pl-smi\">ServerSideEncryptingAmazonS3</span> s3Client,\n      <span class=\"pl-smi\">S3InputDataConfig</span> config,\n      <span class=\"pl-smi\">String</span> bucket,\n      <span class=\"pl-smi\">String</span> prefix,\n      <span class=\"pl-k\">Predicate&lt;<span class=\"pl-smi\">S3ObjectSummary</span>&gt;</span> filter\n  )\n      throws <span class=\"pl-smi\">Exception</span>\n  {\n    <span class=\"pl-k\">final</span> <span class=\"pl-k\">List&lt;<span class=\"pl-smi\">DeleteObjectsRequest</span>.</span><span class=\"pl-smi\">KeyVersion</span><span class=\"pl-k\">&gt;</span> keysToDelete <span class=\"pl-k\">=</span> <span class=\"pl-k\">new</span> <span class=\"pl-k\">ArrayList&lt;&gt;</span>(config<span class=\"pl-k\">.</span>getMaxListingLength());\n    <span class=\"pl-k\">final</span> <span class=\"pl-smi\">ObjectSummaryIterator</span> iterator <span class=\"pl-k\">=</span> <span class=\"pl-k\">new</span> <span class=\"pl-smi\">ObjectSummaryIterator</span>(\n        s3Client,\n        <span class=\"pl-smi\">ImmutableList</span><span class=\"pl-k\">.</span>of(<span class=\"pl-k\">new</span> <span class=\"pl-smi\">CloudObjectLocation</span>(bucket, prefix)<span class=\"pl-k\">.</span>toUri(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>s3<span class=\"pl-pds\">\"</span></span>)),\n        config<span class=\"pl-k\">.</span>getMaxListingLength()\n    );\n\n    <span class=\"pl-k\">while</span> (iterator<span class=\"pl-k\">.</span>hasNext()) {\n      <span class=\"pl-k\">final</span> <span class=\"pl-smi\">S3ObjectSummary</span> nextObject <span class=\"pl-k\">=</span> iterator<span class=\"pl-k\">.</span>next();\n      <span class=\"pl-k\">if</span> (filter<span class=\"pl-k\">.</span>apply(nextObject)) {\n        keysToDelete<span class=\"pl-k\">.</span>add(<span class=\"pl-k\">new</span> <span class=\"pl-smi\">DeleteObjectsRequest</span>.<span class=\"pl-smi\">KeyVersion</span>(nextObject<span class=\"pl-k\">.</span>getKey()));\n        <span class=\"pl-k\">if</span> (keysToDelete<span class=\"pl-k\">.</span>size() <span class=\"pl-k\">==</span> config<span class=\"pl-k\">.</span>getMaxListingLength()) {\n          deleteBucketKeys(s3Client, bucket, keysToDelete);\n          keysToDelete<span class=\"pl-k\">.</span>clear();\n        }\n      }\n    }\n\n    <span class=\"pl-k\">if</span> (keysToDelete<span class=\"pl-k\">.</span>size() <span class=\"pl-k\">&gt;</span> <span class=\"pl-c1\">0</span>) {\n      deleteBucketKeys(s3Client, bucket, keysToDelete);\n    }\n  }\n\n  <span class=\"pl-k\">public</span> <span class=\"pl-k\">static</span> <span class=\"pl-k\">void</span> deleteBucketKeys(\n      <span class=\"pl-smi\">ServerSideEncryptingAmazonS3</span> s3Client,\n      <span class=\"pl-smi\">String</span> bucket,\n      <span class=\"pl-k\">List&lt;<span class=\"pl-smi\">DeleteObjectsRequest</span>.</span><span class=\"pl-smi\">KeyVersion</span><span class=\"pl-k\">&gt;</span> keysToDelete\n  )\n      throws <span class=\"pl-smi\">Exception</span>\n  {\n    <span class=\"pl-smi\">DeleteObjectsRequest</span> deleteRequest <span class=\"pl-k\">=</span> <span class=\"pl-k\">new</span> <span class=\"pl-smi\">DeleteObjectsRequest</span>(bucket)<span class=\"pl-k\">.</span>withKeys(keysToDelete);\n    <span class=\"pl-smi\">S3Utils</span><span class=\"pl-k\">.</span>retryS3Operation(() <span class=\"pl-k\">-</span><span class=\"pl-k\">&gt;</span> {\n      s3Client<span class=\"pl-k\">.</span>deleteObjects(deleteRequest);\n      <span class=\"pl-k\">return</span> <span class=\"pl-c1\">null</span>;\n    });\n  }</pre></div>\n<p dir=\"auto\">Then, not only does it share all the code for listing objects, it also pushes down the retry to the specific API calls to list and delete, instead of wrapping the entire loop, which I think is better.</p>\n<p dir=\"auto\">If you make a change like this, then the kill calls become something like:</p>\n<div class=\"highlight highlight-source-java position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"  @Override\n  public void killAll() throws IOException\n  {\n    try {\n      S3Utils.deleteObjectsInPath(\n          s3Client,\n          inputDataConfig,\n          segmentPusherConfig.getBucket(),\n          segmentPusherConfig.getBaseKey(),\n          Predicates.alwaysTrue()\n      );\n    }\n    catch (Exception e) {\n      log.error(&quot;Error occurred while deleting segment files from s3. Error: %s&quot;, e.getMessage());\n      throw new IOException(e);\n    }\n  }\n\"><pre>  <span class=\"pl-k\">@Override</span>\n  <span class=\"pl-k\">public</span> <span class=\"pl-k\">void</span> killAll() throws <span class=\"pl-smi\">IOException</span>\n  {\n    <span class=\"pl-k\">try</span> {\n      <span class=\"pl-smi\">S3Utils</span><span class=\"pl-k\">.</span>deleteObjectsInPath(\n          s3Client,\n          inputDataConfig,\n          segmentPusherConfig<span class=\"pl-k\">.</span>getBucket(),\n          segmentPusherConfig<span class=\"pl-k\">.</span>getBaseKey(),\n          <span class=\"pl-smi\">Predicates</span><span class=\"pl-k\">.</span>alwaysTrue()\n      );\n    }\n    <span class=\"pl-k\">catch</span> (<span class=\"pl-smi\">Exception</span> e) {\n      log<span class=\"pl-k\">.</span>error(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Error occurred while deleting segment files from s3. Error: %s<span class=\"pl-pds\">\"</span></span>, e<span class=\"pl-k\">.</span>getMessage());\n      <span class=\"pl-k\">throw</span> <span class=\"pl-k\">new</span> <span class=\"pl-smi\">IOException</span>(e);\n    }\n  }</pre></div>\n<p dir=\"auto\">and</p>\n<div class=\"highlight highlight-source-java position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"  @Override\n  public void killOlderThan(long timestamp) throws IOException\n  {\n    try {\n      S3Utils.deleteObjectsInPath(\n          service,\n          inputDataConfig,\n          config.getS3Bucket(),\n          config.getS3Prefix(),\n          (object) -&gt; object.getLastModified().getTime() &lt; timestamp\n      );\n    }\n    catch (Exception e) {\n      log.error(&quot;Error occurred while deleting task log files from s3. Error: %s&quot;, e.getMessage());\n      throw new IOException(e);\n    }\n  }\n\"><pre>  <span class=\"pl-k\">@Override</span>\n  <span class=\"pl-k\">public</span> <span class=\"pl-k\">void</span> killOlderThan(<span class=\"pl-k\">long</span> timestamp) throws <span class=\"pl-smi\">IOException</span>\n  {\n    <span class=\"pl-k\">try</span> {\n      <span class=\"pl-smi\">S3Utils</span><span class=\"pl-k\">.</span>deleteObjectsInPath(\n          service,\n          inputDataConfig,\n          config<span class=\"pl-k\">.</span>getS3Bucket(),\n          config<span class=\"pl-k\">.</span>getS3Prefix(),\n          (object) <span class=\"pl-k\">-</span><span class=\"pl-k\">&gt;</span> object<span class=\"pl-k\">.</span>getLastModified()<span class=\"pl-k\">.</span>getTime() <span class=\"pl-k\">&lt;</span> timestamp\n      );\n    }\n    <span class=\"pl-k\">catch</span> (<span class=\"pl-smi\">Exception</span> e) {\n      log<span class=\"pl-k\">.</span>error(<span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Error occurred while deleting task log files from s3. Error: %s<span class=\"pl-pds\">\"</span></span>, e<span class=\"pl-k\">.</span>getMessage());\n      <span class=\"pl-k\">throw</span> <span class=\"pl-k\">new</span> <span class=\"pl-smi\">IOException</span>(e);\n    }\n  }</pre></div>\n<p dir=\"auto\"><code>ObjectSummaryIterator</code> currently will skip things it thinks are directories, if this is <em>not</em> desirable for deleting segments and task logs, then I would suggest maybe pushing down the predicate to the <code>ObjectSummaryIterator</code> so that the existing users can filter out directories, and your usages can get everything or filter by timestamp as appropriate. In addition, if it shouldn't skip directories, it would probably be worth adding a test for what happens when one is present in the list objects response, if not present.</p>\n<p dir=\"auto\">disclaimer: I didn't test this in real s3, but did run unit tests which passed after some modifications to expected calls, but would still recommend to review these snippets first to make sure they are correct.</p>\n<p dir=\"auto\">What do you think?</p>", "author": "clintropolis", "createdAt": "2020-03-06T02:25:42Z", "path": "extensions-core/s3-extensions/src/main/java/org/apache/druid/storage/s3/S3DataSegmentKiller.java", "diffHunk": "@@ -69,8 +85,48 @@ public void kill(DataSegment segment) throws SegmentLoadingException\n   }\n \n   @Override\n-  public void killAll()\n+  public void killAll() throws IOException\n   {\n-    throw new UnsupportedOperationException(\"not implemented\");\n+    try {\n+      S3Utils.retryS3Operation(\n+          () -> {\n+            String bucketName = segmentPusherConfig.getBucket();", "originalCommit": "2af8070937c585eefa012a1dec96751fa0e562fc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODgwNTU4MQ==", "url": "https://github.com/apache/druid/pull/9459#discussion_r388805581", "bodyText": "Good point about reusing the object iterator, I actually thought about that before, not sure why I decided against. As you said its good that all the listing code is shared in this case. I believe that I would want to skip directories in this case too, so that should be good here as well. Thanks for the suggestion", "author": "zachjsh", "createdAt": "2020-03-06T09:47:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODY4MjM3OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDAzOTI0NQ==", "url": "https://github.com/apache/druid/pull/9459#discussion_r390039245", "bodyText": "done", "author": "zachjsh", "createdAt": "2020-03-10T00:53:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODY4MjM3OQ=="}], "type": "inlineReview", "revised_code": {"commit": "345c22e98636cb96bb500f07bb06d937b6c3c782", "changed_code": [{"header": "diff --git a/extensions-core/s3-extensions/src/main/java/org/apache/druid/storage/s3/S3DataSegmentKiller.java b/extensions-core/s3-extensions/src/main/java/org/apache/druid/storage/s3/S3DataSegmentKiller.java\nindex 9fed147015..cffc3d3639 100644\n--- a/extensions-core/s3-extensions/src/main/java/org/apache/druid/storage/s3/S3DataSegmentKiller.java\n+++ b/extensions-core/s3-extensions/src/main/java/org/apache/druid/storage/s3/S3DataSegmentKiller.java\n", "chunk": "@@ -87,41 +82,16 @@ public class S3DataSegmentKiller implements DataSegmentKiller\n   @Override\n   public void killAll() throws IOException\n   {\n+    log.info(\"Deleting all segment files from s3 location [bucket: '%s' prefix: '%s']\",\n+             segmentPusherConfig.getBucket(), segmentPusherConfig.getBaseKey()\n+    );\n     try {\n-      S3Utils.retryS3Operation(\n-          () -> {\n-            String bucketName = segmentPusherConfig.getBucket();\n-            String prefix = segmentPusherConfig.getBaseKey();\n-            int maxListingLength = inputDataConfig.getMaxListingLength();\n-            ListObjectsV2Result result;\n-            String continuationToken = null;\n-            do {\n-              log.info(\"Deleting batch of %d segment files from s3 location [bucket: %s    prefix: %s].\",\n-                       maxListingLength, bucketName, prefix\n-              );\n-              ListObjectsV2Request request = new ListObjectsV2Request()\n-                  .withBucketName(bucketName)\n-                  .withPrefix(prefix)\n-                  .withContinuationToken(continuationToken)\n-                  .withMaxKeys(maxListingLength);\n-\n-              result = s3Client.listObjectsV2(request);\n-              List<S3ObjectSummary> objectSummaries = result.getObjectSummaries();\n-\n-              List<DeleteObjectsRequest.KeyVersion> keyVersionsToDelete =\n-                  objectSummaries.stream()\n-                                 .map(x -> new DeleteObjectsRequest.KeyVersion(x.getKey()))\n-                                 .collect(Collectors.toList());\n-\n-              DeleteObjectsRequest deleteRequest = new DeleteObjectsRequest(bucketName)\n-                  .withBucketName(bucketName)\n-                  .withKeys(keyVersionsToDelete);\n-              s3Client.deleteObjects(deleteRequest);\n-\n-              continuationToken = result.getNextContinuationToken();\n-            } while (result.isTruncated());\n-            return null;\n-          }\n+      S3Utils.deleteObjectsInPath(\n+          s3Client,\n+          inputDataConfig,\n+          segmentPusherConfig.getBucket(),\n+          segmentPusherConfig.getBaseKey(),\n+          Predicates.alwaysTrue()\n       );\n     }\n     catch (Exception e) {\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODY4NDk4OA==", "url": "https://github.com/apache/druid/pull/9459#discussion_r388684988", "body": "I think these `expect`/`expectLastCall` lines can be collapsed into the form of:\r\n```\r\nEasyMock.expect(request.getBucketName()).andReturn(bucket).anyTimes();\r\n```\r\n\r\nplus a handful of other places in the tests.", "bodyText": "I think these expect/expectLastCall lines can be collapsed into the form of:\nEasyMock.expect(request.getBucketName()).andReturn(bucket).anyTimes();\n\nplus a handful of other places in the tests.", "bodyHTML": "<p dir=\"auto\">I think these <code>expect</code>/<code>expectLastCall</code> lines can be collapsed into the form of:</p>\n<div class=\"snippet-clipboard-content position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"EasyMock.expect(request.getBucketName()).andReturn(bucket).anyTimes();\n\"><pre><code>EasyMock.expect(request.getBucketName()).andReturn(bucket).anyTimes();\n</code></pre></div>\n<p dir=\"auto\">plus a handful of other places in the tests.</p>", "author": "clintropolis", "createdAt": "2020-03-06T02:36:43Z", "path": "extensions-core/s3-extensions/src/test/java/org/apache/druid/storage/s3/S3TestUtils.java", "diffHunk": "@@ -0,0 +1,212 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.storage.s3;\n+\n+import com.amazonaws.services.s3.model.DeleteObjectsRequest;\n+import com.amazonaws.services.s3.model.ListObjectsV2Request;\n+import com.amazonaws.services.s3.model.ListObjectsV2Result;\n+import com.amazonaws.services.s3.model.S3ObjectSummary;\n+import junit.framework.AssertionFailedError;\n+import org.apache.commons.collections4.map.HashedMap;\n+import org.easymock.EasyMock;\n+import org.easymock.EasyMockSupport;\n+import org.easymock.IArgumentMatcher;\n+import org.easymock.IExpectationSetters;\n+\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+public class S3TestUtils extends EasyMockSupport\n+{\n+  public static ListObjectsV2Request listObjectsV2RequestArgumentMatcher(ListObjectsV2Request listObjectsV2Request)\n+  {\n+    EasyMock.reportMatcher(new IArgumentMatcher()\n+    {\n+      @Override\n+      public boolean matches(Object argument)\n+      {\n+\n+        return argument instanceof ListObjectsV2Request\n+               && listObjectsV2Request.getBucketName().equals(((ListObjectsV2Request) argument).getBucketName())\n+               && listObjectsV2Request.getPrefix().equals(((ListObjectsV2Request) argument).getPrefix())\n+               && ((listObjectsV2Request.getContinuationToken() == null\n+                    && ((ListObjectsV2Request) argument).getContinuationToken() == null)\n+                   || (listObjectsV2Request.getContinuationToken()\n+                                           .equals(((ListObjectsV2Request) argument).getContinuationToken())))\n+               && listObjectsV2Request.getMaxKeys().equals(((ListObjectsV2Request) argument).getMaxKeys());\n+      }\n+\n+      @Override\n+      public void appendTo(StringBuffer buffer)\n+      {\n+        String str = \"ListObjectsV2Request(\\\"bucketName:\\\" \\\"\"\n+                     + listObjectsV2Request.getBucketName()\n+                     + \"\\\", \\\"prefix:\\\"\"\n+                     + listObjectsV2Request.getPrefix()\n+                     + \"\\\", \\\"continuationToken:\\\"\"\n+                     + listObjectsV2Request.getContinuationToken()\n+                     + \"\\\", \\\"maxKeys:\\\"\"\n+                     + listObjectsV2Request.getMaxKeys()\n+                     + \"\\\")\";\n+        buffer.append(str);\n+      }\n+    });\n+    return null;\n+  }\n+\n+  public static DeleteObjectsRequest deleteObjectsRequestArgumentMatcher(DeleteObjectsRequest deleteObjectsRequest)\n+  {\n+    EasyMock.reportMatcher(new IArgumentMatcher()\n+    {\n+      @Override\n+      public boolean matches(Object argument)\n+      {\n+\n+        boolean matches = argument instanceof DeleteObjectsRequest\n+                          && deleteObjectsRequest.getBucketName()\n+                                                 .equals(((DeleteObjectsRequest) argument).getBucketName())\n+                          && deleteObjectsRequest.getKeys().size() == ((DeleteObjectsRequest) argument).getKeys()\n+                                                                                                       .size();\n+        if (matches) {\n+          Map<String, String> expectedKeysAndVersions = deleteObjectsRequest.getKeys().stream().collect(\n+              Collectors.toMap(DeleteObjectsRequest.KeyVersion::getKey, x -> {\n+                return x.getVersion() == null ? \"null\" : x.getVersion();\n+              }));\n+          Map<String, String> actualKeysAndVersions = ((DeleteObjectsRequest) argument).getKeys().stream().collect(\n+              Collectors.toMap(DeleteObjectsRequest.KeyVersion::getKey, x -> {\n+                return x.getVersion() == null ? \"null\" : x.getVersion();\n+              }));\n+          matches = expectedKeysAndVersions.equals(actualKeysAndVersions);\n+        }\n+        return matches;\n+      }\n+\n+      @Override\n+      public void appendTo(StringBuffer buffer)\n+      {\n+        String str = \"DeleteObjectsRequest(\\\"bucketName:\\\" \\\"\"\n+                     + deleteObjectsRequest.getBucketName()\n+                     + \"\\\", \\\"keys:\\\"\"\n+                     + deleteObjectsRequest.getKeys()\n+                     + \"\\\")\";\n+        buffer.append(str);\n+      }\n+    });\n+    return null;\n+  }\n+\n+  public static S3ObjectSummary mockS3ObjectSummary(long lastModified, String key)\n+  {\n+    S3ObjectSummary objectSummary = EasyMock.createMock(S3ObjectSummary.class);\n+    EasyMock.expect(objectSummary.getLastModified()).andReturn(new Date(lastModified));\n+    EasyMock.expectLastCall().anyTimes();\n+    EasyMock.expect(objectSummary.getKey()).andReturn(key);\n+    EasyMock.expectLastCall().anyTimes();\n+    return objectSummary;\n+  }\n+\n+  public static ListObjectsV2Request mockRequest(\n+      String bucket,\n+      String prefix,\n+      int maxKeys,\n+      String continuationToken\n+  )\n+  {\n+    ListObjectsV2Request request = EasyMock.createMock(ListObjectsV2Request.class);\n+    EasyMock.expect(request.getBucketName()).andReturn(bucket);\n+    EasyMock.expectLastCall().anyTimes();", "originalCommit": "2af8070937c585eefa012a1dec96751fa0e562fc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODgwNTc5NA==", "url": "https://github.com/apache/druid/pull/9459#discussion_r388805794", "bodyText": "Yes, you're right, noticing it in other places in the code. I will simplify, thanks", "author": "zachjsh", "createdAt": "2020-03-06T09:48:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODY4NDk4OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDAzOTI4Mw==", "url": "https://github.com/apache/druid/pull/9459#discussion_r390039283", "bodyText": "done", "author": "zachjsh", "createdAt": "2020-03-10T00:54:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODY4NDk4OA=="}], "type": "inlineReview", "revised_code": {"commit": "345c22e98636cb96bb500f07bb06d937b6c3c782", "changed_code": [{"header": "diff --git a/extensions-core/s3-extensions/src/test/java/org/apache/druid/storage/s3/S3TestUtils.java b/extensions-core/s3-extensions/src/test/java/org/apache/druid/storage/s3/S3TestUtils.java\nindex b605ee3d60..165dec42f9 100644\n--- a/extensions-core/s3-extensions/src/test/java/org/apache/druid/storage/s3/S3TestUtils.java\n+++ b/extensions-core/s3-extensions/src/test/java/org/apache/druid/storage/s3/S3TestUtils.java\n", "chunk": "@@ -114,99 +85,96 @@ public class S3TestUtils extends EasyMockSupport\n     return null;\n   }\n \n-  public static S3ObjectSummary mockS3ObjectSummary(long lastModified, String key)\n+  public static void expectListObjects(\n+      ServerSideEncryptingAmazonS3 s3Client,\n+      URI prefix,\n+      List<S3ObjectSummary> objectSummaries)\n   {\n-    S3ObjectSummary objectSummary = EasyMock.createMock(S3ObjectSummary.class);\n-    EasyMock.expect(objectSummary.getLastModified()).andReturn(new Date(lastModified));\n-    EasyMock.expectLastCall().anyTimes();\n-    EasyMock.expect(objectSummary.getKey()).andReturn(key);\n-    EasyMock.expectLastCall().anyTimes();\n-    return objectSummary;\n-  }\n+    final ListObjectsV2Result result = new ListObjectsV2Result();\n+    result.setBucketName(prefix.getAuthority());\n+    result.setKeyCount(objectSummaries.size());\n+    for (S3ObjectSummary objectSummary : objectSummaries) {\n+      result.getObjectSummaries().add(objectSummary);\n+    }\n \n-  public static ListObjectsV2Request mockRequest(\n-      String bucket,\n-      String prefix,\n-      int maxKeys,\n-      String continuationToken\n-  )\n-  {\n-    ListObjectsV2Request request = EasyMock.createMock(ListObjectsV2Request.class);\n-    EasyMock.expect(request.getBucketName()).andReturn(bucket);\n-    EasyMock.expectLastCall().anyTimes();\n-    EasyMock.expect(request.getPrefix()).andReturn(prefix);\n-    EasyMock.expectLastCall().anyTimes();\n-    EasyMock.expect(request.getMaxKeys()).andReturn(maxKeys);\n-    EasyMock.expectLastCall().anyTimes();\n-    EasyMock.expect(request.getContinuationToken()).andReturn(continuationToken);\n-    EasyMock.expectLastCall().anyTimes();\n-    return request;\n+    EasyMock.expect(\n+        s3Client.listObjectsV2(matchListObjectsRequest(prefix))\n+    ).andReturn(result).once();\n   }\n \n-  public static ListObjectsV2Result mockResult(\n-      String continuationToken,\n-      boolean isTruncated,\n-      List<S3ObjectSummary> objectSummaries\n+  public static void mockS3ClientDeleteObjects(\n+      ServerSideEncryptingAmazonS3 s3Client,\n+      List<DeleteObjectsRequest> deleteRequestsExpected,\n+      Map<DeleteObjectsRequest, Exception> requestToException\n   )\n   {\n-    ListObjectsV2Result result = EasyMock.createMock(ListObjectsV2Result.class);\n-    EasyMock.expect(result.getNextContinuationToken()).andReturn(continuationToken);\n-    EasyMock.expectLastCall().anyTimes();\n-    EasyMock.expect(result.isTruncated()).andReturn(isTruncated);\n-    EasyMock.expectLastCall().anyTimes();\n-    EasyMock.expect(result.getObjectSummaries()).andReturn(objectSummaries);\n-    return result;\n-  }\n+    Map<DeleteObjectsRequest, IExpectationSetters<DeleteObjectsRequest>> requestToResultExpectationSetter = new HashedMap<>();\n \n-  public static ServerSideEncryptingAmazonS3 mockS3ClientListObjectsV2(\n-      Map<ListObjectsV2Request, ListObjectsV2Result> requestsToResults,\n-      Map<ListObjectsV2Request, Exception> requestsToExceptions\n-  )\n-  {\n-    Map<ListObjectsV2Request, IExpectationSetters<ListObjectsV2Result>> requestToResultExpectationSetter = new HashedMap<>();\n-    ServerSideEncryptingAmazonS3 s3Client = EasyMock.createMock(ServerSideEncryptingAmazonS3.class);\n-    for (Map.Entry<ListObjectsV2Request, Exception> requestsAndErrors : requestsToExceptions.entrySet()) {\n-      ListObjectsV2Request request = requestsAndErrors.getKey();\n+    for (Map.Entry<DeleteObjectsRequest, Exception> requestsAndErrors : requestToException.entrySet()) {\n+      DeleteObjectsRequest request = requestsAndErrors.getKey();\n       Exception exception = requestsAndErrors.getValue();\n-      IExpectationSetters<ListObjectsV2Result> resultExpectationSetter = requestToResultExpectationSetter.get(request);\n+      IExpectationSetters<DeleteObjectsRequest> resultExpectationSetter = requestToResultExpectationSetter.get(request);\n       if (resultExpectationSetter == null) {\n-        s3Client.listObjectsV2(\n-            S3TestUtils.listObjectsV2RequestArgumentMatcher(request));\n-        resultExpectationSetter = EasyMock.<ListObjectsV2Result>expectLastCall().andThrow(exception);\n+        s3Client.deleteObjects(\n+            S3TestUtils.deleteObjectsRequestArgumentMatcher(request));\n+        resultExpectationSetter = EasyMock.<DeleteObjectsRequest>expectLastCall().andThrow(exception);\n         requestToResultExpectationSetter.put(request, resultExpectationSetter);\n       } else {\n         resultExpectationSetter.andThrow(exception);\n       }\n     }\n \n-    for (Map.Entry<ListObjectsV2Request, ListObjectsV2Result> requestsAndResults : requestsToResults.entrySet()) {\n-      ListObjectsV2Request request = requestsAndResults.getKey();\n-      ListObjectsV2Result result = requestsAndResults.getValue();\n-      IExpectationSetters<ListObjectsV2Result> resultExpectationSetter = requestToResultExpectationSetter.get(request);\n+    for (DeleteObjectsRequest request : deleteRequestsExpected) {\n+      IExpectationSetters<DeleteObjectsRequest> resultExpectationSetter = requestToResultExpectationSetter.get(request);\n       if (resultExpectationSetter == null) {\n-        resultExpectationSetter = EasyMock.expect(s3Client.listObjectsV2(\n-            S3TestUtils.listObjectsV2RequestArgumentMatcher(request)));\n+        s3Client.deleteObjects(S3TestUtils.deleteObjectsRequestArgumentMatcher(request));\n+        resultExpectationSetter = EasyMock.expectLastCall();\n         requestToResultExpectationSetter.put(request, resultExpectationSetter);\n       }\n-      resultExpectationSetter.andReturn(result);\n+      resultExpectationSetter.andVoid();\n     }\n-    return s3Client;\n   }\n \n-  public static void mockS3ClientDeleteObjects(\n-      ServerSideEncryptingAmazonS3 s3Client,\n-      List<DeleteObjectsRequest> deleteRequestsExpected,\n-      List<DeleteObjectsRequest> deleteRequestsNotExpected\n-  )\n+  public static ListObjectsV2Request matchListObjectsRequest(final URI prefixUri)\n   {\n-    for (DeleteObjectsRequest deleteRequestExpected : deleteRequestsExpected) {\n-      s3Client.deleteObjects(S3TestUtils.deleteObjectsRequestArgumentMatcher(deleteRequestExpected));\n-      EasyMock.expectLastCall();\n-    }\n+    // Use an IArgumentMatcher to verify that the request has the correct bucket and prefix.\n+    EasyMock.reportMatcher(\n+        new IArgumentMatcher()\n+        {\n+          @Override\n+          public boolean matches(Object argument)\n+          {\n+            if (!(argument instanceof ListObjectsV2Request)) {\n+              return false;\n+            }\n+\n+            final ListObjectsV2Request request = (ListObjectsV2Request) argument;\n+            return prefixUri.getAuthority().equals(request.getBucketName())\n+                   && S3Utils.extractS3Key(prefixUri).equals(request.getPrefix());\n+          }\n+\n+          @Override\n+          public void appendTo(StringBuffer buffer)\n+          {\n+            buffer.append(\"<request for prefix [\").append(prefixUri).append(\"]>\");\n+          }\n+        }\n+    );\n \n-    for (DeleteObjectsRequest deleteRequestNotExpected : deleteRequestsNotExpected) {\n-      s3Client.deleteObjects(S3TestUtils.deleteObjectsRequestArgumentMatcher(deleteRequestNotExpected));\n-      EasyMock.expectLastCall().andThrow(new AssertionFailedError()).anyTimes();\n-    }\n+    return null;\n+  }\n+\n+  public static S3ObjectSummary newS3ObjectSummary(\n+      String bucket,\n+      String key,\n+      long lastModifiedTimestamp)\n+  {\n+    S3ObjectSummary objectSummary = new S3ObjectSummary();\n+    objectSummary.setBucketName(bucket);\n+    objectSummary.setKey(key);\n+    objectSummary.setLastModified(new Date(lastModifiedTimestamp));\n+    objectSummary.setETag(\"etag\");\n+    objectSummary.setSize(CONTENT.length);\n+    return objectSummary;\n   }\n }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODY4NjE4OQ==", "url": "https://github.com/apache/druid/pull/9459#discussion_r388686189", "body": "I have mixed feelings about this class. It seems to exist in service of testing `S3TaskLogs.killAll`, but isn't that kind of leaking what is basically a test fixture, into the production code? Since the `killAll` method does nothing but delegate to the other call that takes an explicit timestamp, is this abstraction really worth having?\r\n\r\nOn the other hand, I can see an argument for using something like this to control system time, and I guess we already have similar situations sometimes when `@VisibleForTesting` are _only_ used by tests, so I'm not strictly against using this, just thinking out loud to have the discussion.\r\n\r\nIn the very least I think it should be renamed `CurrentTimeMillisSupplier` to indicate what time it is supplying, and add javadocs to describe its intended usage to ease testing.\r\n\r\nDoes this need to be setup in the module so that it gets injected into `S3TaskLogs`? (or did I miss that somewhere?)", "bodyText": "I have mixed feelings about this class. It seems to exist in service of testing S3TaskLogs.killAll, but isn't that kind of leaking what is basically a test fixture, into the production code? Since the killAll method does nothing but delegate to the other call that takes an explicit timestamp, is this abstraction really worth having?\nOn the other hand, I can see an argument for using something like this to control system time, and I guess we already have similar situations sometimes when @VisibleForTesting are only used by tests, so I'm not strictly against using this, just thinking out loud to have the discussion.\nIn the very least I think it should be renamed CurrentTimeMillisSupplier to indicate what time it is supplying, and add javadocs to describe its intended usage to ease testing.\nDoes this need to be setup in the module so that it gets injected into S3TaskLogs? (or did I miss that somewhere?)", "bodyHTML": "<p dir=\"auto\">I have mixed feelings about this class. It seems to exist in service of testing <code>S3TaskLogs.killAll</code>, but isn't that kind of leaking what is basically a test fixture, into the production code? Since the <code>killAll</code> method does nothing but delegate to the other call that takes an explicit timestamp, is this abstraction really worth having?</p>\n<p dir=\"auto\">On the other hand, I can see an argument for using something like this to control system time, and I guess we already have similar situations sometimes when <code>@VisibleForTesting</code> are <em>only</em> used by tests, so I'm not strictly against using this, just thinking out loud to have the discussion.</p>\n<p dir=\"auto\">In the very least I think it should be renamed <code>CurrentTimeMillisSupplier</code> to indicate what time it is supplying, and add javadocs to describe its intended usage to ease testing.</p>\n<p dir=\"auto\">Does this need to be setup in the module so that it gets injected into <code>S3TaskLogs</code>? (or did I miss that somewhere?)</p>", "author": "clintropolis", "createdAt": "2020-03-06T02:42:07Z", "path": "core/src/main/java/org/apache/druid/common/utils/TimeSupplier.java", "diffHunk": "@@ -0,0 +1,32 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+\n+package org.apache.druid.common.utils;\n+\n+import java.util.function.Supplier;\n+\n+public class TimeSupplier implements Supplier<Long>", "originalCommit": "2af8070937c585eefa012a1dec96751fa0e562fc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODgwNzgzOQ==", "url": "https://github.com/apache/druid/pull/9459#discussion_r388807839", "bodyText": "You're right that in this case that most of the logic here lives in killOlderThan which killAll delegates to, thought I think that a supplier for current time could be useful in other cases. I will change name and add javadocs to make its purpose more clear. You didn't miss the binding, there is none. This works since it is not an interface. Should I make an interface for this and explicitly bind this implementation to the interface? What would be a good module to do this in?", "author": "zachjsh", "createdAt": "2020-03-06T09:51:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODY4NjE4OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE4NDYyNQ==", "url": "https://github.com/apache/druid/pull/9459#discussion_r389184625", "bodyText": "You didn't miss the binding, there is none. This works since it is not an interface. Should I make an interface for this and explicitly bind this implementation to the interface? What would be a good module to do this in?\n\nOh yeah, my bad, I'm not a guice wizard and forget how things work sometimes \ud83d\ude1c. No reason to make an interface if only one implementation i think as long as everything works \ud83d\udc4d", "author": "clintropolis", "createdAt": "2020-03-06T23:00:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODY4NjE4OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTE4NTY5OA==", "url": "https://github.com/apache/druid/pull/9459#discussion_r389185698", "bodyText": "This should be LongSupplier instead.", "author": "jihoonson", "createdAt": "2020-03-06T23:03:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODY4NjE4OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDAzOTMxMw==", "url": "https://github.com/apache/druid/pull/9459#discussion_r390039313", "bodyText": "done", "author": "zachjsh", "createdAt": "2020-03-10T00:54:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODY4NjE4OQ=="}], "type": "inlineReview", "revised_code": {"commit": "345c22e98636cb96bb500f07bb06d937b6c3c782", "changed_code": [{"header": "diff --git a/core/src/main/java/org/apache/druid/common/utils/TimeSupplier.java b/core/src/main/java/org/apache/druid/common/utils/CurrentTimeMillisSupplier.java\nsimilarity index 87%\nrename from core/src/main/java/org/apache/druid/common/utils/TimeSupplier.java\nrename to core/src/main/java/org/apache/druid/common/utils/CurrentTimeMillisSupplier.java\nindex 08fa6b14ef..d540c781e0 100644\n--- a/core/src/main/java/org/apache/druid/common/utils/TimeSupplier.java\n+++ b/core/src/main/java/org/apache/druid/common/utils/CurrentTimeMillisSupplier.java\n", "chunk": "@@ -20,12 +20,12 @@\n \n package org.apache.druid.common.utils;\n \n-import java.util.function.Supplier;\n+import java.util.function.LongSupplier;\n \n-public class TimeSupplier implements Supplier<Long>\n+public class CurrentTimeMillisSupplier implements LongSupplier\n {\n   @Override\n-  public Long get()\n+  public long getAsLong()\n   {\n     return System.currentTimeMillis();\n   }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODY5MTYxNA==", "url": "https://github.com/apache/druid/pull/9459#discussion_r388691614", "body": "`log.info` is a bit too informative for this operation I think, inside the loop at least. If you need to log anything, I suggest just counting the number of keys actually deleted and reporting the total at the end outside of the loop, or just a single message before the loop happens indicating that a some deletes are going to happen.", "bodyText": "log.info is a bit too informative for this operation I think, inside the loop at least. If you need to log anything, I suggest just counting the number of keys actually deleted and reporting the total at the end outside of the loop, or just a single message before the loop happens indicating that a some deletes are going to happen.", "bodyHTML": "<p dir=\"auto\"><code>log.info</code> is a bit too informative for this operation I think, inside the loop at least. If you need to log anything, I suggest just counting the number of keys actually deleted and reporting the total at the end outside of the loop, or just a single message before the loop happens indicating that a some deletes are going to happen.</p>", "author": "clintropolis", "createdAt": "2020-03-06T03:04:47Z", "path": "extensions-core/s3-extensions/src/main/java/org/apache/druid/storage/s3/S3DataSegmentKiller.java", "diffHunk": "@@ -69,8 +85,48 @@ public void kill(DataSegment segment) throws SegmentLoadingException\n   }\n \n   @Override\n-  public void killAll()\n+  public void killAll() throws IOException\n   {\n-    throw new UnsupportedOperationException(\"not implemented\");\n+    try {\n+      S3Utils.retryS3Operation(\n+          () -> {\n+            String bucketName = segmentPusherConfig.getBucket();\n+            String prefix = segmentPusherConfig.getBaseKey();\n+            int maxListingLength = inputDataConfig.getMaxListingLength();\n+            ListObjectsV2Result result;\n+            String continuationToken = null;\n+            do {\n+              log.info(\"Deleting batch of %d segment files from s3 location [bucket: %s    prefix: %s].\",", "originalCommit": "2af8070937c585eefa012a1dec96751fa0e562fc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODgwODMyNQ==", "url": "https://github.com/apache/druid/pull/9459#discussion_r388808325", "bodyText": "Yeah I agree, I will log only once per invocation", "author": "zachjsh", "createdAt": "2020-03-06T09:52:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODY5MTYxNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDAzOTMzNw==", "url": "https://github.com/apache/druid/pull/9459#discussion_r390039337", "bodyText": "done", "author": "zachjsh", "createdAt": "2020-03-10T00:54:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODY5MTYxNA=="}], "type": "inlineReview", "revised_code": {"commit": "345c22e98636cb96bb500f07bb06d937b6c3c782", "changed_code": [{"header": "diff --git a/extensions-core/s3-extensions/src/main/java/org/apache/druid/storage/s3/S3DataSegmentKiller.java b/extensions-core/s3-extensions/src/main/java/org/apache/druid/storage/s3/S3DataSegmentKiller.java\nindex 9fed147015..cffc3d3639 100644\n--- a/extensions-core/s3-extensions/src/main/java/org/apache/druid/storage/s3/S3DataSegmentKiller.java\n+++ b/extensions-core/s3-extensions/src/main/java/org/apache/druid/storage/s3/S3DataSegmentKiller.java\n", "chunk": "@@ -87,41 +82,16 @@ public class S3DataSegmentKiller implements DataSegmentKiller\n   @Override\n   public void killAll() throws IOException\n   {\n+    log.info(\"Deleting all segment files from s3 location [bucket: '%s' prefix: '%s']\",\n+             segmentPusherConfig.getBucket(), segmentPusherConfig.getBaseKey()\n+    );\n     try {\n-      S3Utils.retryS3Operation(\n-          () -> {\n-            String bucketName = segmentPusherConfig.getBucket();\n-            String prefix = segmentPusherConfig.getBaseKey();\n-            int maxListingLength = inputDataConfig.getMaxListingLength();\n-            ListObjectsV2Result result;\n-            String continuationToken = null;\n-            do {\n-              log.info(\"Deleting batch of %d segment files from s3 location [bucket: %s    prefix: %s].\",\n-                       maxListingLength, bucketName, prefix\n-              );\n-              ListObjectsV2Request request = new ListObjectsV2Request()\n-                  .withBucketName(bucketName)\n-                  .withPrefix(prefix)\n-                  .withContinuationToken(continuationToken)\n-                  .withMaxKeys(maxListingLength);\n-\n-              result = s3Client.listObjectsV2(request);\n-              List<S3ObjectSummary> objectSummaries = result.getObjectSummaries();\n-\n-              List<DeleteObjectsRequest.KeyVersion> keyVersionsToDelete =\n-                  objectSummaries.stream()\n-                                 .map(x -> new DeleteObjectsRequest.KeyVersion(x.getKey()))\n-                                 .collect(Collectors.toList());\n-\n-              DeleteObjectsRequest deleteRequest = new DeleteObjectsRequest(bucketName)\n-                  .withBucketName(bucketName)\n-                  .withKeys(keyVersionsToDelete);\n-              s3Client.deleteObjects(deleteRequest);\n-\n-              continuationToken = result.getNextContinuationToken();\n-            } while (result.isTruncated());\n-            return null;\n-          }\n+      S3Utils.deleteObjectsInPath(\n+          s3Client,\n+          inputDataConfig,\n+          segmentPusherConfig.getBucket(),\n+          segmentPusherConfig.getBaseKey(),\n+          Predicates.alwaysTrue()\n       );\n     }\n     catch (Exception e) {\n", "next_change": null}]}}, {"oid": "345c22e98636cb96bb500f07bb06d937b6c3c782", "url": "https://github.com/apache/druid/commit/345c22e98636cb96bb500f07bb06d937b6c3c782", "message": "* Address review comments", "committedDate": "2020-03-10T00:52:51Z", "type": "commit"}, {"oid": "1c54e4cddfc0c2fa09259078c645e8465b61b12b", "url": "https://github.com/apache/druid/commit/1c54e4cddfc0c2fa09259078c645e8465b61b12b", "message": "* Fix failing dependency check", "committedDate": "2020-03-10T07:01:59Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDA2NjQyOA==", "url": "https://github.com/apache/druid/pull/9459#discussion_r390066428", "body": "nit: this can be private actually (my bad)", "bodyText": "nit: this can be private actually (my bad)", "bodyHTML": "<p dir=\"auto\">nit: this can be private actually (my bad)</p>", "author": "clintropolis", "createdAt": "2020-03-10T02:45:57Z", "path": "extensions-core/s3-extensions/src/main/java/org/apache/druid/storage/s3/S3Utils.java", "diffHunk": "@@ -200,6 +204,54 @@ public static S3ObjectSummary getSingleObjectSummary(ServerSideEncryptingAmazonS\n     return objectSummary;\n   }\n \n+  public static void deleteObjectsInPath(\n+      ServerSideEncryptingAmazonS3 s3Client,\n+      S3InputDataConfig config,\n+      String bucket,\n+      String prefix,\n+      Predicate<S3ObjectSummary> filter\n+  )\n+      throws Exception\n+  {\n+    final List<DeleteObjectsRequest.KeyVersion> keysToDelete = new ArrayList<>(config.getMaxListingLength());\n+    final ObjectSummaryIterator iterator = new ObjectSummaryIterator(\n+        s3Client,\n+        ImmutableList.of(new CloudObjectLocation(bucket, prefix).toUri(\"s3\")),\n+        config.getMaxListingLength()\n+    );\n+\n+    while (iterator.hasNext()) {\n+      final S3ObjectSummary nextObject = iterator.next();\n+      if (filter.apply(nextObject)) {\n+        keysToDelete.add(new DeleteObjectsRequest.KeyVersion(nextObject.getKey()));\n+        if (keysToDelete.size() == config.getMaxListingLength()) {\n+          deleteBucketKeys(s3Client, bucket, keysToDelete);\n+          log.info(\"Deleted %d files\", keysToDelete.size());\n+          keysToDelete.clear();\n+        }\n+      }\n+    }\n+\n+    if (keysToDelete.size() > 0) {\n+      deleteBucketKeys(s3Client, bucket, keysToDelete);\n+      log.info(\"Deleted %d files\", keysToDelete.size());\n+    }\n+  }\n+\n+  public static void deleteBucketKeys(", "originalCommit": "345c22e98636cb96bb500f07bb06d937b6c3c782", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDUzODU1Mw==", "url": "https://github.com/apache/druid/pull/9459#discussion_r390538553", "bodyText": "I'll get this in the next change which should be coming shortly.", "author": "zachjsh", "createdAt": "2020-03-10T18:51:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDA2NjQyOA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDA2NzA3Nw==", "url": "https://github.com/apache/druid/pull/9459#discussion_r390067077", "body": "nit: javadocs describing this method would be nice", "bodyText": "nit: javadocs describing this method would be nice", "bodyHTML": "<p dir=\"auto\">nit: javadocs describing this method would be nice</p>", "author": "clintropolis", "createdAt": "2020-03-10T02:48:36Z", "path": "extensions-core/s3-extensions/src/main/java/org/apache/druid/storage/s3/S3Utils.java", "diffHunk": "@@ -200,6 +204,54 @@ public static S3ObjectSummary getSingleObjectSummary(ServerSideEncryptingAmazonS\n     return objectSummary;\n   }\n \n+  public static void deleteObjectsInPath(", "originalCommit": "345c22e98636cb96bb500f07bb06d937b6c3c782", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDUzODU2NA==", "url": "https://github.com/apache/druid/pull/9459#discussion_r390538564", "bodyText": "I'll get this in the next change which should be coming shortly.", "author": "zachjsh", "createdAt": "2020-03-10T18:51:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDA2NzA3Nw=="}], "type": "inlineReview", "revised_code": null}]}