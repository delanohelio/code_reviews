{"pr_number": 2288, "pr_title": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer", "pr_author": "fjtirado", "pr_createdAt": "2020-10-19T09:36:08Z", "pr_url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288", "merge_commit": "1032eeb870afeea6dd9a9211b894badb4f1874d6", "timeline": [{"oid": "d79eae8548866858e58088e3ea29b2dd33025563", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/d79eae8548866858e58088e3ea29b2dd33025563", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-10-20T16:18:03Z", "type": "forcePushed"}, {"oid": "573a3a77f45f7b7ac38d9b9da851be60e02abaeb", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/573a3a77f45f7b7ac38d9b9da851be60e02abaeb", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-10-21T11:36:02Z", "type": "forcePushed"}, {"oid": "e21df6112b0f9b0c88cb5129cabfa94de9e4a525", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/e21df6112b0f9b0c88cb5129cabfa94de9e4a525", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-10-21T14:57:34Z", "type": "forcePushed"}, {"oid": "67f19ebca307e4d3c223b704c040d024d16bc600", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/67f19ebca307e4d3c223b704c040d024d16bc600", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-10-21T15:29:59Z", "type": "forcePushed"}, {"oid": "e29dee4abca91ee94fa1028d6837290b9e0d3f50", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/e29dee4abca91ee94fa1028d6837290b9e0d3f50", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-10-22T14:20:14Z", "type": "forcePushed"}, {"oid": "c42d9cdb39dda016b37754a2dae093952e4b3f9e", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/c42d9cdb39dda016b37754a2dae093952e4b3f9e", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-10-22T14:42:23Z", "type": "forcePushed"}, {"oid": "8f38cf875fcfa8c2a275bc5f38fd1782bce3c269", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/8f38cf875fcfa8c2a275bc5f38fd1782bce3c269", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-10-23T17:26:57Z", "type": "forcePushed"}, {"oid": "34ff698efbf4c1aa19008897dcfaaba18a3b5596", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/34ff698efbf4c1aa19008897dcfaaba18a3b5596", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-10-23T18:41:27Z", "type": "forcePushed"}, {"oid": "81f1268ab2d93b5505f2ea402ec93fc39cb3053c", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/81f1268ab2d93b5505f2ea402ec93fc39cb3053c", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-10-26T10:20:05Z", "type": "forcePushed"}, {"oid": "0d1dddbc5234e2dbf427989466eca1e4551e98b3", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/0d1dddbc5234e2dbf427989466eca1e4551e98b3", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-10-26T13:33:02Z", "type": "forcePushed"}, {"oid": "3bd246b0b13958748a0ef793ea34a08c7665d8cd", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/3bd246b0b13958748a0ef793ea34a08c7665d8cd", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-10-26T15:54:34Z", "type": "forcePushed"}, {"oid": "0081d4a8a9f0dd1e67a9543658a4a24dce8026bf", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/0081d4a8a9f0dd1e67a9543658a4a24dce8026bf", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-10-26T15:59:52Z", "type": "forcePushed"}, {"oid": "7f7818850b0c9eb4a87da0f7fec7cce1a97e767c", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/7f7818850b0c9eb4a87da0f7fec7cce1a97e767c", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-10-26T16:06:38Z", "type": "forcePushed"}, {"oid": "810d0ff22b517a4abd002d813b18888d4f4c98f1", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/810d0ff22b517a4abd002d813b18888d4f4c98f1", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-10-26T16:28:03Z", "type": "forcePushed"}, {"oid": "be3cb973510d04f8aabe096d1c4d01db934e719f", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/be3cb973510d04f8aabe096d1c4d01db934e719f", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-10-26T18:00:43Z", "type": "forcePushed"}, {"oid": "f3abdf0ed5d9cf68bae2eaa5e40b553d23af532a", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/f3abdf0ed5d9cf68bae2eaa5e40b553d23af532a", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-10-27T08:17:03Z", "type": "forcePushed"}, {"oid": "af57f54bddf624b72405dba9b935ead67b97fb89", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/af57f54bddf624b72405dba9b935ead67b97fb89", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-10-28T17:15:41Z", "type": "forcePushed"}, {"oid": "702567a869b50937e72c6dd7c121751cda401833", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/702567a869b50937e72c6dd7c121751cda401833", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-10-30T08:13:55Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDk3Mjk5Nw==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r514972997", "body": "Maybe it's worth checking `node` is not null to avoid any potential NPE", "bodyText": "Maybe it's worth checking node is not null to avoid any potential NPE", "bodyHTML": "<p dir=\"auto\">Maybe it's worth checking <code>node</code> is not null to avoid any potential NPE</p>", "author": "afalhambra", "createdAt": "2020-10-30T09:37:07Z", "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/CloudEvent.java", "diffHunk": "@@ -0,0 +1,96 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.text.SimpleDateFormat;\n+import java.util.Date;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n+class CloudEvent<T> {\n+\n+    private static ObjectMapper mapper = new ObjectMapper()\n+            .setDateFormat(new SimpleDateFormat(System.getProperty(\n+                    KafkaServerExtension.KAFKA_EXTENSION_PREFIX + \"json.date_format\", System.getProperty(\n+                            \"org.kie.server.json.date_format\",\n+                            \"yyyy-MM-dd'T'HH:mm:ss.SSSZ\"))));\n+\n+    private String specVersion;\n+    private Date time;\n+    private String id;\n+    private String type;\n+    private String source;\n+    private T data;\n+\n+    public static <T> CloudEvent<T> read(byte[] bytes, Class<T> type) throws IOException, ParseException {\n+        JsonNode node = mapper.readTree(bytes);\n+        CloudEvent<T> cloudEvent = new CloudEvent<>();\n+        if (node.has(\"id\")) {", "originalCommit": "702567a869b50937e72c6dd7c121751cda401833", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTE2OTIxMg==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515169212", "bodyText": "I believe readTree hardly retursn null, hence there is not point in checking", "author": "fjtirado", "createdAt": "2020-10-30T15:10:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDk3Mjk5Nw=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDk4OTE2Mg==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r514989162", "body": "Does it make to have it defined as `public`? As we already have a public method `getExtensionName` already defined? maybe it's useful to use it in a static context? just wondering.", "bodyText": "Does it make to have it defined as public? As we already have a public method getExtensionName already defined? maybe it's useful to use it in a static context? just wondering.", "bodyHTML": "<p dir=\"auto\">Does it make to have it defined as <code>public</code>? As we already have a public method <code>getExtensionName</code> already defined? maybe it's useful to use it in a static context? just wondering.</p>", "author": "afalhambra", "createdAt": "2020-10-30T10:06:15Z", "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java", "diffHunk": "@@ -0,0 +1,307 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+*/\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.time.Duration;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.function.BiConsumer;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.serialization.ByteArrayDeserializer;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentEventListener;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedAsset;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.jbpm.services.api.model.SignalDesc;\n+import org.jbpm.services.api.model.SignalType;\n+import org.kie.server.api.KieServerConstants;\n+import org.kie.server.services.api.KieContainerInstance;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.api.SupportedTransports;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.kie.server.services.jbpm.JbpmKieServerExtension;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KafkaServerExtension implements KieServerExtension, DeploymentEventListener, Runnable {\n+\n+    public static final String EXTENSION_NAME = \"Kafka\";", "originalCommit": "702567a869b50937e72c6dd7c121751cda401833", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTE3MDE0MA==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515170140", "bodyText": "Here Im just following what has been done in other extensions. It makes sense in static context, as for example, in the code it is used the EXTENSION_NAME of BPMNServerExtension", "author": "fjtirado", "createdAt": "2020-10-30T15:12:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDk4OTE2Mg=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTAwMTY4Mg==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515001682", "body": "Should we instead try to force user to specify a port number through properties? I mean, by removing this default port number?", "bodyText": "Should we instead try to force user to specify a port number through properties? I mean, by removing this default port number?", "bodyHTML": "<p dir=\"auto\">Should we instead try to force user to specify a port number through properties? I mean, by removing this default port number?</p>", "author": "afalhambra", "createdAt": "2020-10-30T10:29:56Z", "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java", "diffHunk": "@@ -0,0 +1,307 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+*/\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.time.Duration;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.function.BiConsumer;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.serialization.ByteArrayDeserializer;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentEventListener;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedAsset;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.jbpm.services.api.model.SignalDesc;\n+import org.jbpm.services.api.model.SignalType;\n+import org.kie.server.api.KieServerConstants;\n+import org.kie.server.services.api.KieContainerInstance;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.api.SupportedTransports;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.kie.server.services.jbpm.JbpmKieServerExtension;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KafkaServerExtension implements KieServerExtension, DeploymentEventListener, Runnable {\n+\n+    public static final String EXTENSION_NAME = \"Kafka\";\n+    static final String KAFKA_EXTENSION_PREFIX = \"org.kie.server.jbpm-kafka.ext.\";\n+    static final String TOPIC_PREFIX = KAFKA_EXTENSION_PREFIX + \"topics.\";\n+    private static final Logger logger = LoggerFactory.getLogger(KafkaServerExtension.class);\n+\n+    private AtomicBoolean initialized = new AtomicBoolean();\n+    private Consumer<String, byte[]> consumer;\n+    private ListenerSupport deploymentService;\n+    private ProcessService processService;\n+    private ScheduledExecutorService pollService;\n+    private ExecutorService notifyService;\n+\n+    private Map<String, SignalInfo> topic2Signal = new ConcurrentHashMap<>();\n+\n+    @Override\n+    public boolean isInitialized() {\n+        return initialized.get();\n+    }\n+\n+    @Override\n+    public boolean isActive() {\n+        return !Boolean.getBoolean(KieServerConstants.KIE_KAFKA_SERVER_EXT_DISABLED);\n+    }\n+\n+    @Override\n+    public void init(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (initialized.getAndSet(true)) {\n+            return;\n+        }\n+        pollService = Executors.newSingleThreadScheduledExecutor();\n+        notifyService = Executors.newCachedThreadPool();\n+        consumer = getKafkaConsumer();\n+        KieServerExtension jbpmExt = registry.getServerExtension(JbpmKieServerExtension.EXTENSION_NAME);\n+        if (jbpmExt == null) {\n+            throw new IllegalStateException(\"Cannot find extension \" + JbpmKieServerExtension.EXTENSION_NAME);\n+        }\n+\n+        for (Object service : jbpmExt.getServices()) {\n+            if (deploymentService == null && DeploymentService.class.isAssignableFrom(service.getClass())) {\n+                deploymentService = (ListenerSupport) service;\n+            } else if (processService == null && ProcessService.class.isAssignableFrom(service.getClass())) {\n+                processService = (ProcessService) service;\n+            }\n+            if (deploymentService != null && processService != null) {\n+                break;\n+            }\n+        }\n+        if (deploymentService == null) {\n+            throw new IllegalStateException(\"Cannot find deployment service\");\n+        }\n+        if (processService == null) {\n+            throw new IllegalStateException(\"Cannot find process service\");\n+        }\n+        deploymentService.addListener(this);\n+    }\n+\n+    @Override\n+    public void destroy(KieServerImpl kieServer, KieServerRegistry registry) {\n+        pollService.shutdownNow();\n+        pollService = null;\n+        notifyService.shutdownNow();\n+        notifyService = null;\n+        if (deploymentService != null) {\n+            deploymentService.removeListener(this);\n+            deploymentService = null;\n+        }\n+        if (consumer != null) {\n+            consumer.close();\n+            consumer = null;\n+        }\n+        initialized.set(false);\n+    }\n+\n+    protected Consumer<String, byte[]> getKafkaConsumer() {\n+        Map<String, Object> props = new HashMap<>();\n+        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, System.getProperty(\n+                KAFKA_EXTENSION_PREFIX + \"boopstrap.servers\", \"localhost:9092\"));", "originalCommit": "702567a869b50937e72c6dd7c121751cda401833", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTE3MDUwOQ==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515170509", "bodyText": "for Kafka, host and port are specified together.", "author": "fjtirado", "createdAt": "2020-10-30T15:12:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTAwMTY4Mg=="}], "type": "inlineReview", "revised_code": {"commit": "5162c4b335dc9d4e66a42d45755478723f9ecd40", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\nindex 297a72059..2911ced89 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n", "chunk": "@@ -135,7 +135,7 @@ public class KafkaServerExtension implements KieServerExtension, DeploymentEvent\n         Map<String, Object> props = new HashMap<>();\n         props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, System.getProperty(\n                 KAFKA_EXTENSION_PREFIX + \"boopstrap.servers\", \"localhost:9092\"));\n-        // read only commited events\n+        // read only committed events\n         props.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, IsolationLevel.READ_COMMITTED.toString().toLowerCase());\n         // do not automatically create topics by default\n         props.put(ConsumerConfig.ALLOW_AUTO_CREATE_TOPICS_CONFIG, Boolean.getBoolean(\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTAwMTg1Nw==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515001857", "body": "typo\r\n```suggestion\r\n        // read only committed events\r\n```", "bodyText": "typo\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    // read only commited events\n          \n          \n            \n                    // read only committed events", "bodyHTML": "<p dir=\"auto\">typo</p>\n  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">        <span class=\"pl-c\"><span class=\"pl-c\">//</span> read only <span class=\"x x-first x-last\">commited</span> events</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">        <span class=\"pl-c\"><span class=\"pl-c\">//</span> read only <span class=\"x x-first x-last\">committed</span> events</span></td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "afalhambra", "createdAt": "2020-10-30T10:30:17Z", "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java", "diffHunk": "@@ -0,0 +1,307 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+*/\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.time.Duration;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.function.BiConsumer;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.serialization.ByteArrayDeserializer;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentEventListener;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedAsset;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.jbpm.services.api.model.SignalDesc;\n+import org.jbpm.services.api.model.SignalType;\n+import org.kie.server.api.KieServerConstants;\n+import org.kie.server.services.api.KieContainerInstance;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.api.SupportedTransports;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.kie.server.services.jbpm.JbpmKieServerExtension;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KafkaServerExtension implements KieServerExtension, DeploymentEventListener, Runnable {\n+\n+    public static final String EXTENSION_NAME = \"Kafka\";\n+    static final String KAFKA_EXTENSION_PREFIX = \"org.kie.server.jbpm-kafka.ext.\";\n+    static final String TOPIC_PREFIX = KAFKA_EXTENSION_PREFIX + \"topics.\";\n+    private static final Logger logger = LoggerFactory.getLogger(KafkaServerExtension.class);\n+\n+    private AtomicBoolean initialized = new AtomicBoolean();\n+    private Consumer<String, byte[]> consumer;\n+    private ListenerSupport deploymentService;\n+    private ProcessService processService;\n+    private ScheduledExecutorService pollService;\n+    private ExecutorService notifyService;\n+\n+    private Map<String, SignalInfo> topic2Signal = new ConcurrentHashMap<>();\n+\n+    @Override\n+    public boolean isInitialized() {\n+        return initialized.get();\n+    }\n+\n+    @Override\n+    public boolean isActive() {\n+        return !Boolean.getBoolean(KieServerConstants.KIE_KAFKA_SERVER_EXT_DISABLED);\n+    }\n+\n+    @Override\n+    public void init(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (initialized.getAndSet(true)) {\n+            return;\n+        }\n+        pollService = Executors.newSingleThreadScheduledExecutor();\n+        notifyService = Executors.newCachedThreadPool();\n+        consumer = getKafkaConsumer();\n+        KieServerExtension jbpmExt = registry.getServerExtension(JbpmKieServerExtension.EXTENSION_NAME);\n+        if (jbpmExt == null) {\n+            throw new IllegalStateException(\"Cannot find extension \" + JbpmKieServerExtension.EXTENSION_NAME);\n+        }\n+\n+        for (Object service : jbpmExt.getServices()) {\n+            if (deploymentService == null && DeploymentService.class.isAssignableFrom(service.getClass())) {\n+                deploymentService = (ListenerSupport) service;\n+            } else if (processService == null && ProcessService.class.isAssignableFrom(service.getClass())) {\n+                processService = (ProcessService) service;\n+            }\n+            if (deploymentService != null && processService != null) {\n+                break;\n+            }\n+        }\n+        if (deploymentService == null) {\n+            throw new IllegalStateException(\"Cannot find deployment service\");\n+        }\n+        if (processService == null) {\n+            throw new IllegalStateException(\"Cannot find process service\");\n+        }\n+        deploymentService.addListener(this);\n+    }\n+\n+    @Override\n+    public void destroy(KieServerImpl kieServer, KieServerRegistry registry) {\n+        pollService.shutdownNow();\n+        pollService = null;\n+        notifyService.shutdownNow();\n+        notifyService = null;\n+        if (deploymentService != null) {\n+            deploymentService.removeListener(this);\n+            deploymentService = null;\n+        }\n+        if (consumer != null) {\n+            consumer.close();\n+            consumer = null;\n+        }\n+        initialized.set(false);\n+    }\n+\n+    protected Consumer<String, byte[]> getKafkaConsumer() {\n+        Map<String, Object> props = new HashMap<>();\n+        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, System.getProperty(\n+                KAFKA_EXTENSION_PREFIX + \"boopstrap.servers\", \"localhost:9092\"));\n+        // read only commited events", "originalCommit": "702567a869b50937e72c6dd7c121751cda401833", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5162c4b335dc9d4e66a42d45755478723f9ecd40", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\nindex 297a72059..2911ced89 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n", "chunk": "@@ -135,7 +135,7 @@ public class KafkaServerExtension implements KieServerExtension, DeploymentEvent\n         Map<String, Object> props = new HashMap<>();\n         props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, System.getProperty(\n                 KAFKA_EXTENSION_PREFIX + \"boopstrap.servers\", \"localhost:9092\"));\n-        // read only commited events\n+        // read only committed events\n         props.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, IsolationLevel.READ_COMMITTED.toString().toLowerCase());\n         // do not automatically create topics by default\n         props.put(ConsumerConfig.ALLOW_AUTO_CREATE_TOPICS_CONFIG, Boolean.getBoolean(\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTAyNDY4Ng==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515024686", "body": "Red Hat copyright is missing.", "bodyText": "Red Hat copyright is missing.", "bodyHTML": "<p dir=\"auto\">Red Hat copyright is missing.</p>", "author": "afalhambra", "createdAt": "2020-10-30T11:15:48Z", "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java", "diffHunk": "@@ -0,0 +1,149 @@\n+package org.kie.server.services.jbpm.kafka;", "originalCommit": "702567a869b50937e72c6dd7c121751cda401833", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "13c42b110a2fa2f9b6077c14c2094fea8dcc20b2", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KafkaServerExtensionTest.java\nsimilarity index 80%\nrename from kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\nrename to kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KafkaServerExtensionTest.java\nindex 3cd6e9637..beafada5d 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KafkaServerExtensionTest.java\n", "chunk": "@@ -1,3 +1,18 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n package org.kie.server.services.jbpm.kafka;\n \n import java.util.Arrays;\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTAyNTcyNg==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515025726", "body": "Can be replaced with empty diamonds\r\n```suggestion\r\n        private MockConsumer<String, byte[]> consumer = new MockConsumer<>(OffsetResetStrategy.EARLIEST);\r\n```", "bodyText": "Can be replaced with empty diamonds\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    private MockConsumer<String, byte[]> consumer = new MockConsumer<String, byte[]>(OffsetResetStrategy.EARLIEST);\n          \n          \n            \n                    private MockConsumer<String, byte[]> consumer = new MockConsumer<>(OffsetResetStrategy.EARLIEST);", "bodyHTML": "<p dir=\"auto\">Can be replaced with empty diamonds</p>\n  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">        <span class=\"pl-k\">private</span> <span class=\"pl-k\">MockConsumer&lt;<span class=\"pl-smi\">String</span>, byte[]&gt;</span> consumer <span class=\"pl-k\">=</span> <span class=\"pl-k\">new</span> <span class=\"pl-k\">MockConsumer&lt;<span class=\"pl-smi x x-first\">String</span><span class=\"x x-last\">, byte[]</span>&gt;</span>(<span class=\"pl-smi\">OffsetResetStrategy</span><span class=\"pl-c1\"><span class=\"pl-k\">.</span>EARLIEST</span>);</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">        <span class=\"pl-k\">private</span> <span class=\"pl-k\">MockConsumer&lt;<span class=\"pl-smi\">String</span>, byte[]&gt;</span> consumer <span class=\"pl-k\">=</span> <span class=\"pl-k\">new</span> <span class=\"pl-k\">MockConsumer&lt;&gt;</span>(<span class=\"pl-smi\">OffsetResetStrategy</span><span class=\"pl-c1\"><span class=\"pl-k\">.</span>EARLIEST</span>);</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "afalhambra", "createdAt": "2020-10-30T11:17:43Z", "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java", "diffHunk": "@@ -0,0 +1,149 @@\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.MockConsumer;\n+import org.apache.kafka.clients.consumer.OffsetResetStrategy;\n+import org.apache.kafka.common.TopicPartition;\n+import org.jbpm.bpmn2.core.Message;\n+import org.jbpm.bpmn2.core.Signal;\n+import org.jbpm.kie.services.impl.model.SignalDescImpl;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedUnit;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.mockito.Mockito;\n+import org.mockito.verification.VerificationMode;\n+\n+import static org.junit.Assert.assertTrue;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.timeout;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+import static org.mockito.Mockito.withSettings;\n+\n+public class KakfaServerExtensionTest {\n+\n+    private static class MockKafkaServerExtension extends KafkaServerExtension {\n+\n+        private MockConsumer<String, byte[]> consumer = new MockConsumer<String, byte[]>(OffsetResetStrategy.EARLIEST);", "originalCommit": "702567a869b50937e72c6dd7c121751cda401833", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "13c42b110a2fa2f9b6077c14c2094fea8dcc20b2", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KafkaServerExtensionTest.java\nsimilarity index 80%\nrename from kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\nrename to kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KafkaServerExtensionTest.java\nindex 3cd6e9637..beafada5d 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KafkaServerExtensionTest.java\n", "chunk": "@@ -37,11 +53,11 @@ import static org.mockito.Mockito.verify;\n import static org.mockito.Mockito.when;\n import static org.mockito.Mockito.withSettings;\n \n-public class KakfaServerExtensionTest {\n+public class KafkaServerExtensionTest {\n \n     private static class MockKafkaServerExtension extends KafkaServerExtension {\n \n-        private MockConsumer<String, byte[]> consumer = new MockConsumer<String, byte[]>(OffsetResetStrategy.EARLIEST);\n+        private MockConsumer<String, byte[]> consumer = new MockConsumer<>(OffsetResetStrategy.EARLIEST);\n \n         protected Consumer<String, byte[]> getKafkaConsumer() {\n             return consumer;\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTAyNzMxMA==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515027310", "body": "Typo\r\n```suggestion\r\npublic class KafkaServerExtensionTest {\r\n```", "bodyText": "Typo\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            public class KakfaServerExtensionTest {\n          \n          \n            \n            public class KafkaServerExtensionTest {", "bodyHTML": "<p dir=\"auto\">Typo</p>\n  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\"><span class=\"pl-k\">public</span> <span class=\"pl-k\">class</span> <span class=\"pl-en x x-first x-last\">KakfaServerExtensionTest</span> {</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\"><span class=\"pl-k\">public</span> <span class=\"pl-k\">class</span> <span class=\"pl-en x x-first x-last\">KafkaServerExtensionTest</span> {</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "afalhambra", "createdAt": "2020-10-30T11:20:22Z", "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java", "diffHunk": "@@ -0,0 +1,149 @@\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.MockConsumer;\n+import org.apache.kafka.clients.consumer.OffsetResetStrategy;\n+import org.apache.kafka.common.TopicPartition;\n+import org.jbpm.bpmn2.core.Message;\n+import org.jbpm.bpmn2.core.Signal;\n+import org.jbpm.kie.services.impl.model.SignalDescImpl;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedUnit;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.mockito.Mockito;\n+import org.mockito.verification.VerificationMode;\n+\n+import static org.junit.Assert.assertTrue;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.timeout;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+import static org.mockito.Mockito.withSettings;\n+\n+public class KakfaServerExtensionTest {", "originalCommit": "702567a869b50937e72c6dd7c121751cda401833", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "13c42b110a2fa2f9b6077c14c2094fea8dcc20b2", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KafkaServerExtensionTest.java\nsimilarity index 80%\nrename from kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\nrename to kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KafkaServerExtensionTest.java\nindex 3cd6e9637..beafada5d 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KafkaServerExtensionTest.java\n", "chunk": "@@ -37,11 +53,11 @@ import static org.mockito.Mockito.verify;\n import static org.mockito.Mockito.when;\n import static org.mockito.Mockito.withSettings;\n \n-public class KakfaServerExtensionTest {\n+public class KafkaServerExtensionTest {\n \n     private static class MockKafkaServerExtension extends KafkaServerExtension {\n \n-        private MockConsumer<String, byte[]> consumer = new MockConsumer<String, byte[]>(OffsetResetStrategy.EARLIEST);\n+        private MockConsumer<String, byte[]> consumer = new MockConsumer<>(OffsetResetStrategy.EARLIEST);\n \n         protected Consumer<String, byte[]> getKafkaConsumer() {\n             return consumer;\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTAyOTI5Ng==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515029296", "body": "Checked exception is not thrown within this method\r\n```suggestion\r\n    public void testKafkaServerExecutorMessage() {\r\n```", "bodyText": "Checked exception is not thrown within this method\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public void testKafkaServerExecutorMessage() throws InterruptedException {\n          \n          \n            \n                public void testKafkaServerExecutorMessage() {", "bodyHTML": "<p dir=\"auto\">Checked exception is not thrown within this method</p>\n  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">    <span class=\"pl-k\">public</span> <span class=\"pl-k\">void</span> testKafkaServerExecutorMessage() <span class=\"x x-first\">throws </span><span class=\"pl-smi x\">InterruptedException</span><span class=\"x x-last\"> </span>{</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">    <span class=\"pl-k\">public</span> <span class=\"pl-k\">void</span> testKafkaServerExecutorMessage() {</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "afalhambra", "createdAt": "2020-10-30T11:24:06Z", "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java", "diffHunk": "@@ -0,0 +1,149 @@\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.MockConsumer;\n+import org.apache.kafka.clients.consumer.OffsetResetStrategy;\n+import org.apache.kafka.common.TopicPartition;\n+import org.jbpm.bpmn2.core.Message;\n+import org.jbpm.bpmn2.core.Signal;\n+import org.jbpm.kie.services.impl.model.SignalDescImpl;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedUnit;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.mockito.Mockito;\n+import org.mockito.verification.VerificationMode;\n+\n+import static org.junit.Assert.assertTrue;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.timeout;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+import static org.mockito.Mockito.withSettings;\n+\n+public class KakfaServerExtensionTest {\n+\n+    private static class MockKafkaServerExtension extends KafkaServerExtension {\n+\n+        private MockConsumer<String, byte[]> consumer = new MockConsumer<String, byte[]>(OffsetResetStrategy.EARLIEST);\n+\n+        protected Consumer<String, byte[]> getKafkaConsumer() {\n+            return consumer;\n+        }\n+\n+        public MockConsumer<String, byte[]> getMockConsumer() {\n+            return consumer;\n+        }\n+    }\n+\n+    private ProcessService processService;\n+    private MockKafkaServerExtension extension;\n+    private KieServerImpl server;\n+    private KieServerRegistry registry;\n+    private DeployedUnit deployedUnit;\n+    private ProcessDefinition processDefinition;\n+\n+    @Before\n+    public void setup() {\n+        extension = new MockKafkaServerExtension();\n+        server = mock(KieServerImpl.class);\n+        registry = mock(KieServerRegistry.class);\n+        KieServerExtension serverExtension = mock(KieServerExtension.class);\n+\n+        when(registry.getServerExtension(Mockito.anyString())).thenReturn(serverExtension);\n+        ListenerSupport deployService = mock(ListenerSupport.class, withSettings().extraInterfaces(\n+                DeploymentService.class));\n+        processService = mock(ProcessService.class);\n+        when(serverExtension.getServices()).thenReturn(Arrays.asList(deployService, processService));\n+        extension.init(server, registry);\n+        extension.serverStarted();\n+        deployedUnit = mock(DeployedUnit.class);\n+        processDefinition = mock(ProcessDefinition.class);\n+        when(deployedUnit.getDeployedAssets()).thenReturn(Collections.singletonList(processDefinition));\n+    }\n+\n+    @After\n+    public void close() {\n+        extension.destroy(server, registry);\n+    }\n+\n+    @Test\n+    public void testKafkaServerExecutorSignal() throws InterruptedException {\n+        when(processDefinition.getSignalsMetadata()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+                new Signal(\"MySignal\", \"MySignal\", \"String\"))));\n+        when(deployedUnit.getDeployedAssets()).thenReturn(Collections.singletonList(processDefinition));\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy\", deployedUnit));\n+        publishEvent(\"MySignal\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"javierito\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy\", \"MySignal\", \"javierito\");\n+    }\n+\n+    @Test\n+    public void testKafkaServerExecutorMessage() throws InterruptedException {", "originalCommit": "702567a869b50937e72c6dd7c121751cda401833", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5162c4b335dc9d4e66a42d45755478723f9ecd40", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\nindex 3cd6e9637..3300b55d2 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\n", "chunk": "@@ -94,7 +94,7 @@ public class KakfaServerExtensionTest {\n     }\n \n     @Test\n-    public void testKafkaServerExecutorMessage() throws InterruptedException {\n+    public void testKafkaServerExecutorMessage() {\n \n         Message msg = new Message(\"MyMessage\");\n         msg.setName(\"Hello\");\n", "next_change": {"commit": "13c42b110a2fa2f9b6077c14c2094fea8dcc20b2", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KafkaServerExtensionTest.java\nsimilarity index 83%\nrename from kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\nrename to kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KafkaServerExtensionTest.java\nindex 3300b55d2..beafada5d 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KafkaServerExtensionTest.java\n", "chunk": "@@ -99,7 +115,7 @@ public class KakfaServerExtensionTest {\n         Message msg = new Message(\"MyMessage\");\n         msg.setName(\"Hello\");\n         msg.setType(\"String\");\n-        when(processDefinition.getSignalsMetadata()).thenReturn(Collections.singletonList(SignalDescImpl.from(msg)));\n+        when(processDefinition.getMessagesDesc()).thenReturn(Collections.singletonList(MessageDescImpl.from(msg)));\n         extension.onDeploy(new DeploymentEvent(\"MyDeploy\", deployedUnit));\n         publishEvent(\"Hello\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"pepe\\\"}\");\n         verify(processService, getTimeout()).signalEvent(\"MyDeploy\", \"Message-Hello\", \"pepe\");\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTAyOTUwNw==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515029507", "body": "Checked exception is not thrown within this method\r\n\r\n```suggestion\r\n    public void testKafkaServerExecutorMessageTopic() {\r\n```", "bodyText": "Checked exception is not thrown within this method\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public void testKafkaServerExecutorMessageTopic() throws InterruptedException {\n          \n          \n            \n                public void testKafkaServerExecutorMessageTopic() {", "bodyHTML": "<p dir=\"auto\">Checked exception is not thrown within this method</p>\n  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">    <span class=\"pl-k\">public</span> <span class=\"pl-k\">void</span> testKafkaServerExecutorMessageTopic() <span class=\"x x-first\">throws </span><span class=\"pl-smi x\">InterruptedException</span><span class=\"x x-last\"> </span>{</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">    <span class=\"pl-k\">public</span> <span class=\"pl-k\">void</span> testKafkaServerExecutorMessageTopic() {</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "afalhambra", "createdAt": "2020-10-30T11:24:27Z", "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java", "diffHunk": "@@ -0,0 +1,149 @@\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.MockConsumer;\n+import org.apache.kafka.clients.consumer.OffsetResetStrategy;\n+import org.apache.kafka.common.TopicPartition;\n+import org.jbpm.bpmn2.core.Message;\n+import org.jbpm.bpmn2.core.Signal;\n+import org.jbpm.kie.services.impl.model.SignalDescImpl;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedUnit;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.mockito.Mockito;\n+import org.mockito.verification.VerificationMode;\n+\n+import static org.junit.Assert.assertTrue;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.timeout;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+import static org.mockito.Mockito.withSettings;\n+\n+public class KakfaServerExtensionTest {\n+\n+    private static class MockKafkaServerExtension extends KafkaServerExtension {\n+\n+        private MockConsumer<String, byte[]> consumer = new MockConsumer<String, byte[]>(OffsetResetStrategy.EARLIEST);\n+\n+        protected Consumer<String, byte[]> getKafkaConsumer() {\n+            return consumer;\n+        }\n+\n+        public MockConsumer<String, byte[]> getMockConsumer() {\n+            return consumer;\n+        }\n+    }\n+\n+    private ProcessService processService;\n+    private MockKafkaServerExtension extension;\n+    private KieServerImpl server;\n+    private KieServerRegistry registry;\n+    private DeployedUnit deployedUnit;\n+    private ProcessDefinition processDefinition;\n+\n+    @Before\n+    public void setup() {\n+        extension = new MockKafkaServerExtension();\n+        server = mock(KieServerImpl.class);\n+        registry = mock(KieServerRegistry.class);\n+        KieServerExtension serverExtension = mock(KieServerExtension.class);\n+\n+        when(registry.getServerExtension(Mockito.anyString())).thenReturn(serverExtension);\n+        ListenerSupport deployService = mock(ListenerSupport.class, withSettings().extraInterfaces(\n+                DeploymentService.class));\n+        processService = mock(ProcessService.class);\n+        when(serverExtension.getServices()).thenReturn(Arrays.asList(deployService, processService));\n+        extension.init(server, registry);\n+        extension.serverStarted();\n+        deployedUnit = mock(DeployedUnit.class);\n+        processDefinition = mock(ProcessDefinition.class);\n+        when(deployedUnit.getDeployedAssets()).thenReturn(Collections.singletonList(processDefinition));\n+    }\n+\n+    @After\n+    public void close() {\n+        extension.destroy(server, registry);\n+    }\n+\n+    @Test\n+    public void testKafkaServerExecutorSignal() throws InterruptedException {\n+        when(processDefinition.getSignalsMetadata()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+                new Signal(\"MySignal\", \"MySignal\", \"String\"))));\n+        when(deployedUnit.getDeployedAssets()).thenReturn(Collections.singletonList(processDefinition));\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy\", deployedUnit));\n+        publishEvent(\"MySignal\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"javierito\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy\", \"MySignal\", \"javierito\");\n+    }\n+\n+    @Test\n+    public void testKafkaServerExecutorMessage() throws InterruptedException {\n+\n+        Message msg = new Message(\"MyMessage\");\n+        msg.setName(\"Hello\");\n+        msg.setType(\"String\");\n+        when(processDefinition.getSignalsMetadata()).thenReturn(Collections.singletonList(SignalDescImpl.from(msg)));\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy\", deployedUnit));\n+        publishEvent(\"Hello\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"pepe\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy\", \"Message-Hello\", \"pepe\");\n+    }\n+\n+    @Test\n+    public void testKafkaServerExecutorMessageTopic() throws InterruptedException {", "originalCommit": "702567a869b50937e72c6dd7c121751cda401833", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTE3MTY4MQ==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515171681", "bodyText": "good catch", "author": "fjtirado", "createdAt": "2020-10-30T15:14:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTAyOTUwNw=="}], "type": "inlineReview", "revised_code": {"commit": "5162c4b335dc9d4e66a42d45755478723f9ecd40", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\nindex 3cd6e9637..3300b55d2 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\n", "chunk": "@@ -106,7 +106,7 @@ public class KakfaServerExtensionTest {\n     }\n \n     @Test\n-    public void testKafkaServerExecutorMessageTopic() throws InterruptedException {\n+    public void testKafkaServerExecutorMessageTopic() {\n \n         final String topicProperty = KafkaServerExtension.TOPIC_PREFIX + \"Hello\";\n         System.setProperty(topicProperty, \"MyTopic\");\n", "next_change": {"commit": "13c42b110a2fa2f9b6077c14c2094fea8dcc20b2", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KafkaServerExtensionTest.java\nsimilarity index 83%\nrename from kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\nrename to kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KafkaServerExtensionTest.java\nindex 3300b55d2..beafada5d 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KafkaServerExtensionTest.java\n", "chunk": "@@ -114,7 +130,7 @@ public class KakfaServerExtensionTest {\n             Message msg = new Message(\"MyMessage\");\n             msg.setName(\"Hello\");\n             msg.setType(\"String\");\n-            when(processDefinition.getSignalsMetadata()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+            when(processDefinition.getMessagesDesc()).thenReturn(Collections.singletonList(MessageDescImpl.from(\n                     msg)));\n             extension.onDeploy(new DeploymentEvent(\"MyDeploy\", deployedUnit));\n             publishEvent(\"MyTopic\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"pepe\\\"}\");\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTAyOTY3MA==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515029670", "body": "Checked exception is not thrown within this method\r\n\r\n```suggestion\r\n    public void testKafkaServerExecutorSignal() {\r\n```", "bodyText": "Checked exception is not thrown within this method\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public void testKafkaServerExecutorSignal() throws InterruptedException {\n          \n          \n            \n                public void testKafkaServerExecutorSignal() {", "bodyHTML": "<p dir=\"auto\">Checked exception is not thrown within this method</p>\n  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">    <span class=\"pl-k\">public</span> <span class=\"pl-k\">void</span> testKafkaServerExecutorSignal() <span class=\"x x-first\">throws </span><span class=\"pl-smi x\">InterruptedException</span><span class=\"x x-last\"> </span>{</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">    <span class=\"pl-k\">public</span> <span class=\"pl-k\">void</span> testKafkaServerExecutorSignal() {</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "afalhambra", "createdAt": "2020-10-30T11:24:44Z", "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java", "diffHunk": "@@ -0,0 +1,149 @@\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.MockConsumer;\n+import org.apache.kafka.clients.consumer.OffsetResetStrategy;\n+import org.apache.kafka.common.TopicPartition;\n+import org.jbpm.bpmn2.core.Message;\n+import org.jbpm.bpmn2.core.Signal;\n+import org.jbpm.kie.services.impl.model.SignalDescImpl;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedUnit;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.mockito.Mockito;\n+import org.mockito.verification.VerificationMode;\n+\n+import static org.junit.Assert.assertTrue;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.timeout;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+import static org.mockito.Mockito.withSettings;\n+\n+public class KakfaServerExtensionTest {\n+\n+    private static class MockKafkaServerExtension extends KafkaServerExtension {\n+\n+        private MockConsumer<String, byte[]> consumer = new MockConsumer<String, byte[]>(OffsetResetStrategy.EARLIEST);\n+\n+        protected Consumer<String, byte[]> getKafkaConsumer() {\n+            return consumer;\n+        }\n+\n+        public MockConsumer<String, byte[]> getMockConsumer() {\n+            return consumer;\n+        }\n+    }\n+\n+    private ProcessService processService;\n+    private MockKafkaServerExtension extension;\n+    private KieServerImpl server;\n+    private KieServerRegistry registry;\n+    private DeployedUnit deployedUnit;\n+    private ProcessDefinition processDefinition;\n+\n+    @Before\n+    public void setup() {\n+        extension = new MockKafkaServerExtension();\n+        server = mock(KieServerImpl.class);\n+        registry = mock(KieServerRegistry.class);\n+        KieServerExtension serverExtension = mock(KieServerExtension.class);\n+\n+        when(registry.getServerExtension(Mockito.anyString())).thenReturn(serverExtension);\n+        ListenerSupport deployService = mock(ListenerSupport.class, withSettings().extraInterfaces(\n+                DeploymentService.class));\n+        processService = mock(ProcessService.class);\n+        when(serverExtension.getServices()).thenReturn(Arrays.asList(deployService, processService));\n+        extension.init(server, registry);\n+        extension.serverStarted();\n+        deployedUnit = mock(DeployedUnit.class);\n+        processDefinition = mock(ProcessDefinition.class);\n+        when(deployedUnit.getDeployedAssets()).thenReturn(Collections.singletonList(processDefinition));\n+    }\n+\n+    @After\n+    public void close() {\n+        extension.destroy(server, registry);\n+    }\n+\n+    @Test\n+    public void testKafkaServerExecutorSignal() throws InterruptedException {", "originalCommit": "702567a869b50937e72c6dd7c121751cda401833", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5162c4b335dc9d4e66a42d45755478723f9ecd40", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\nindex 3cd6e9637..3300b55d2 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\n", "chunk": "@@ -84,7 +84,7 @@ public class KakfaServerExtensionTest {\n     }\n \n     @Test\n-    public void testKafkaServerExecutorSignal() throws InterruptedException {\n+    public void testKafkaServerExecutorSignal() {\n         when(processDefinition.getSignalsMetadata()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n                 new Signal(\"MySignal\", \"MySignal\", \"String\"))));\n         when(deployedUnit.getDeployedAssets()).thenReturn(Collections.singletonList(processDefinition));\n", "next_change": {"commit": "13c42b110a2fa2f9b6077c14c2094fea8dcc20b2", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KafkaServerExtensionTest.java\nsimilarity index 83%\nrename from kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\nrename to kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KafkaServerExtensionTest.java\nindex 3300b55d2..beafada5d 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KafkaServerExtensionTest.java\n", "chunk": "@@ -85,7 +101,7 @@ public class KakfaServerExtensionTest {\n \n     @Test\n     public void testKafkaServerExecutorSignal() {\n-        when(processDefinition.getSignalsMetadata()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+        when(processDefinition.getSignalsDesc()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n                 new Signal(\"MySignal\", \"MySignal\", \"String\"))));\n         when(deployedUnit.getDeployedAssets()).thenReturn(Collections.singletonList(processDefinition));\n         extension.onDeploy(new DeploymentEvent(\"MyDeploy\", deployedUnit));\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTAzNjk2OQ==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515036969", "body": "Can be replaced with empty diamonds\r\n```suggestion\r\n        Map<TopicPartition, Long> partitionsBeginningMap = new HashMap<>();\r\n        Map<TopicPartition, Long> partitionsEndMap = new HashMap<>();\r\n```", "bodyText": "Can be replaced with empty diamonds\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    Map<TopicPartition, Long> partitionsBeginningMap = new HashMap<TopicPartition, Long>();\n          \n          \n            \n                    Map<TopicPartition, Long> partitionsEndMap = new HashMap<TopicPartition, Long>();\n          \n          \n            \n                    Map<TopicPartition, Long> partitionsBeginningMap = new HashMap<>();\n          \n          \n            \n                    Map<TopicPartition, Long> partitionsEndMap = new HashMap<>();", "bodyHTML": "<p dir=\"auto\">Can be replaced with empty diamonds</p>\n  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">        <span class=\"pl-k\">Map&lt;<span class=\"pl-smi\">TopicPartition</span>, <span class=\"pl-smi\">Long</span>&gt;</span> partitionsBeginningMap <span class=\"pl-k\">=</span> <span class=\"pl-k\">new</span> <span class=\"pl-k\">HashMap&lt;<span class=\"pl-smi x x-first\">TopicPartition</span><span class=\"x\">, </span><span class=\"pl-smi x x-last\">Long</span>&gt;</span>();</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">        <span class=\"pl-k\">Map&lt;<span class=\"pl-smi\">TopicPartition</span>, <span class=\"pl-smi\">Long</span>&gt;</span> partitionsEndMap <span class=\"pl-k\">=</span> <span class=\"pl-k\">new</span> <span class=\"pl-k\">HashMap&lt;<span class=\"pl-smi x x-first\">TopicPartition</span><span class=\"x\">, </span><span class=\"pl-smi x x-last\">Long</span>&gt;</span>();</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">        <span class=\"pl-k\">Map&lt;<span class=\"pl-smi\">TopicPartition</span>, <span class=\"pl-smi\">Long</span>&gt;</span> partitionsBeginningMap <span class=\"pl-k\">=</span> <span class=\"pl-k\">new</span> <span class=\"pl-k\">HashMap&lt;&gt;</span>();</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">        <span class=\"pl-k\">Map&lt;<span class=\"pl-smi\">TopicPartition</span>, <span class=\"pl-smi\">Long</span>&gt;</span> partitionsEndMap <span class=\"pl-k\">=</span> <span class=\"pl-k\">new</span> <span class=\"pl-k\">HashMap&lt;&gt;</span>();</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "afalhambra", "createdAt": "2020-10-30T11:38:38Z", "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java", "diffHunk": "@@ -0,0 +1,149 @@\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.MockConsumer;\n+import org.apache.kafka.clients.consumer.OffsetResetStrategy;\n+import org.apache.kafka.common.TopicPartition;\n+import org.jbpm.bpmn2.core.Message;\n+import org.jbpm.bpmn2.core.Signal;\n+import org.jbpm.kie.services.impl.model.SignalDescImpl;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedUnit;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.mockito.Mockito;\n+import org.mockito.verification.VerificationMode;\n+\n+import static org.junit.Assert.assertTrue;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.timeout;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+import static org.mockito.Mockito.withSettings;\n+\n+public class KakfaServerExtensionTest {\n+\n+    private static class MockKafkaServerExtension extends KafkaServerExtension {\n+\n+        private MockConsumer<String, byte[]> consumer = new MockConsumer<String, byte[]>(OffsetResetStrategy.EARLIEST);\n+\n+        protected Consumer<String, byte[]> getKafkaConsumer() {\n+            return consumer;\n+        }\n+\n+        public MockConsumer<String, byte[]> getMockConsumer() {\n+            return consumer;\n+        }\n+    }\n+\n+    private ProcessService processService;\n+    private MockKafkaServerExtension extension;\n+    private KieServerImpl server;\n+    private KieServerRegistry registry;\n+    private DeployedUnit deployedUnit;\n+    private ProcessDefinition processDefinition;\n+\n+    @Before\n+    public void setup() {\n+        extension = new MockKafkaServerExtension();\n+        server = mock(KieServerImpl.class);\n+        registry = mock(KieServerRegistry.class);\n+        KieServerExtension serverExtension = mock(KieServerExtension.class);\n+\n+        when(registry.getServerExtension(Mockito.anyString())).thenReturn(serverExtension);\n+        ListenerSupport deployService = mock(ListenerSupport.class, withSettings().extraInterfaces(\n+                DeploymentService.class));\n+        processService = mock(ProcessService.class);\n+        when(serverExtension.getServices()).thenReturn(Arrays.asList(deployService, processService));\n+        extension.init(server, registry);\n+        extension.serverStarted();\n+        deployedUnit = mock(DeployedUnit.class);\n+        processDefinition = mock(ProcessDefinition.class);\n+        when(deployedUnit.getDeployedAssets()).thenReturn(Collections.singletonList(processDefinition));\n+    }\n+\n+    @After\n+    public void close() {\n+        extension.destroy(server, registry);\n+    }\n+\n+    @Test\n+    public void testKafkaServerExecutorSignal() throws InterruptedException {\n+        when(processDefinition.getSignalsMetadata()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+                new Signal(\"MySignal\", \"MySignal\", \"String\"))));\n+        when(deployedUnit.getDeployedAssets()).thenReturn(Collections.singletonList(processDefinition));\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy\", deployedUnit));\n+        publishEvent(\"MySignal\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"javierito\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy\", \"MySignal\", \"javierito\");\n+    }\n+\n+    @Test\n+    public void testKafkaServerExecutorMessage() throws InterruptedException {\n+\n+        Message msg = new Message(\"MyMessage\");\n+        msg.setName(\"Hello\");\n+        msg.setType(\"String\");\n+        when(processDefinition.getSignalsMetadata()).thenReturn(Collections.singletonList(SignalDescImpl.from(msg)));\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy\", deployedUnit));\n+        publishEvent(\"Hello\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"pepe\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy\", \"Message-Hello\", \"pepe\");\n+    }\n+\n+    @Test\n+    public void testKafkaServerExecutorMessageTopic() throws InterruptedException {\n+\n+        final String topicProperty = KafkaServerExtension.TOPIC_PREFIX + \"Hello\";\n+        System.setProperty(topicProperty, \"MyTopic\");\n+        try {\n+            Message msg = new Message(\"MyMessage\");\n+            msg.setName(\"Hello\");\n+            msg.setType(\"String\");\n+            when(processDefinition.getSignalsMetadata()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+                    msg)));\n+            extension.onDeploy(new DeploymentEvent(\"MyDeploy\", deployedUnit));\n+            publishEvent(\"MyTopic\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"pepe\\\"}\");\n+            verify(processService, getTimeout()).signalEvent(\"MyDeploy\", \"Message-Hello\", \"pepe\");\n+        } finally {\n+            System.clearProperty(topicProperty);\n+        }\n+    }\n+\n+    private VerificationMode getTimeout() {\n+        return timeout(Long.getLong(KafkaServerExtension.KAFKA_EXTENSION_PREFIX + \"poll.interval\", 1L) * 2000).times(1);\n+    }\n+\n+    private void publishEvent(String topic, String cloudEventText) {\n+        Set<String> topics = extension.getMockConsumer().subscription();\n+        assertTrue(\"Topic \" + topic + \" not found\", topics.contains(topic));\n+        List<TopicPartition> partitions = Collections.singletonList(new TopicPartition(topic, 0));\n+        extension.getMockConsumer().rebalance(partitions);\n+        Map<TopicPartition, Long> partitionsBeginningMap = new HashMap<TopicPartition, Long>();\n+        Map<TopicPartition, Long> partitionsEndMap = new HashMap<TopicPartition, Long>();", "originalCommit": "702567a869b50937e72c6dd7c121751cda401833", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5162c4b335dc9d4e66a42d45755478723f9ecd40", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\nindex 3cd6e9637..3300b55d2 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\n", "chunk": "@@ -133,16 +133,16 @@ public class KakfaServerExtensionTest {\n         assertTrue(\"Topic \" + topic + \" not found\", topics.contains(topic));\n         List<TopicPartition> partitions = Collections.singletonList(new TopicPartition(topic, 0));\n         extension.getMockConsumer().rebalance(partitions);\n-        Map<TopicPartition, Long> partitionsBeginningMap = new HashMap<TopicPartition, Long>();\n-        Map<TopicPartition, Long> partitionsEndMap = new HashMap<TopicPartition, Long>();\n+        Map<TopicPartition, Long> partitionsBeginningMap = new HashMap<>();\n+        Map<TopicPartition, Long> partitionsEndMap = new HashMap<>();\n         long records = 10L;\n         for (TopicPartition partition : partitions) {\n-            partitionsBeginningMap.put(partition, 0l);\n+            partitionsBeginningMap.put(partition, 0L);\n             partitionsEndMap.put(partition, records);\n         }\n         extension.getMockConsumer().updateBeginningOffsets(partitionsBeginningMap);\n         extension.getMockConsumer().updateEndOffsets(partitionsEndMap);\n-        extension.getMockConsumer().addRecord(new ConsumerRecord<String, byte[]>(topic, 0, 0L, \"\",\n+        extension.getMockConsumer().addRecord(new ConsumerRecord<>(topic, 0, 0L, \"\",\n                 cloudEventText.getBytes()));\n     }\n \n", "next_change": {"commit": "02a8f2440ed9ecc0abc0702a1a04c97f91f348f9", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\nindex 3300b55d2..674143227 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\n", "chunk": "@@ -135,10 +135,9 @@ public class KakfaServerExtensionTest {\n         extension.getMockConsumer().rebalance(partitions);\n         Map<TopicPartition, Long> partitionsBeginningMap = new HashMap<>();\n         Map<TopicPartition, Long> partitionsEndMap = new HashMap<>();\n-        long records = 10L;\n         for (TopicPartition partition : partitions) {\n             partitionsBeginningMap.put(partition, 0L);\n-            partitionsEndMap.put(partition, records);\n+            partitionsEndMap.put(partition, 1L);\n         }\n         extension.getMockConsumer().updateBeginningOffsets(partitionsBeginningMap);\n         extension.getMockConsumer().updateEndOffsets(partitionsEndMap);\n", "next_change": {"commit": "1ab6958fe0bfbaf2245278de193e40219f168da9", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KafkaServerExtensionTest.java\nsimilarity index 63%\nrename from kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\nrename to kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KafkaServerExtensionTest.java\nindex 674143227..772892124 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KafkaServerExtensionTest.java\n", "chunk": "@@ -124,24 +143,45 @@ public class KakfaServerExtensionTest {\n         }\n     }\n \n+    @Test\n+    public void testWithDestroy() {\n+        when(processDefinition.getSignalsDesc()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+                new Signal(\"MySignal\", \"MySignal\", \"String\"))));\n+        Message msg = new Message(\"MyMessage\");\n+        msg.setName(\"Hello2\");\n+        msg.setType(\"String\");\n+        when(processDefinition.getMessagesDesc()).thenReturn(Collections.singletonList(MessageDescImpl.from(\n+                msg)));\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy1\", deployedUnit));\n+        publishEvent(\"MySignal\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"javierito\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy1\", \"MySignal\", \"javierito\");\n+        extension.destroy(server, registry);\n+        mockConsumer = new MockConsumer<String, byte[]>(OffsetResetStrategy.EARLIEST);\n+        extension.setKafkaConsumer(mockConsumer);\n+        extension.init(server, registry);\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy2\", deployedUnit));\n+        publishEvent(\"Hello2\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"pepe\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy2\", \"Message-Hello2\", \"pepe\");\n+    }\n+\n     private VerificationMode getTimeout() {\n         return timeout(Long.getLong(KafkaServerExtension.KAFKA_EXTENSION_PREFIX + \"poll.interval\", 1L) * 2000).times(1);\n     }\n \n     private void publishEvent(String topic, String cloudEventText) {\n-        Set<String> topics = extension.getMockConsumer().subscription();\n+        Set<String> topics = mockConsumer.subscription();\n         assertTrue(\"Topic \" + topic + \" not found\", topics.contains(topic));\n         List<TopicPartition> partitions = Collections.singletonList(new TopicPartition(topic, 0));\n-        extension.getMockConsumer().rebalance(partitions);\n+        mockConsumer.rebalance(partitions);\n         Map<TopicPartition, Long> partitionsBeginningMap = new HashMap<>();\n         Map<TopicPartition, Long> partitionsEndMap = new HashMap<>();\n         for (TopicPartition partition : partitions) {\n             partitionsBeginningMap.put(partition, 0L);\n             partitionsEndMap.put(partition, 1L);\n         }\n-        extension.getMockConsumer().updateBeginningOffsets(partitionsBeginningMap);\n-        extension.getMockConsumer().updateEndOffsets(partitionsEndMap);\n-        extension.getMockConsumer().addRecord(new ConsumerRecord<>(topic, 0, 0L, \"\",\n+        mockConsumer.updateBeginningOffsets(partitionsBeginningMap);\n+        mockConsumer.updateEndOffsets(partitionsEndMap);\n+        mockConsumer.addRecord(new ConsumerRecord<>(topic, 0, 0L, \"\",\n                 cloudEventText.getBytes()));\n     }\n \n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTAzNzIyNA==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515037224", "body": "same as above\r\n```suggestion\r\n        extension.getMockConsumer().addRecord(new ConsumerRecord<>(topic, 0, 0L, \"\",\r\n```", "bodyText": "same as above\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    extension.getMockConsumer().addRecord(new ConsumerRecord<String, byte[]>(topic, 0, 0L, \"\",\n          \n          \n            \n                    extension.getMockConsumer().addRecord(new ConsumerRecord<>(topic, 0, 0L, \"\",", "bodyHTML": "<p dir=\"auto\">same as above</p>\n  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">        extension<span class=\"pl-k\">.</span>getMockConsumer()<span class=\"pl-k\">.</span>addRecord(<span class=\"pl-k\">new</span> <span class=\"pl-k\">ConsumerRecord&lt;<span class=\"pl-smi x x-first\">String</span><span class=\"x x-last\">, byte[]</span>&gt;</span>(topic, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0L</span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>,</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">        extension<span class=\"pl-k\">.</span>getMockConsumer()<span class=\"pl-k\">.</span>addRecord(<span class=\"pl-k\">new</span> <span class=\"pl-k\">ConsumerRecord&lt;&gt;</span>(topic, <span class=\"pl-c1\">0</span>, <span class=\"pl-c1\">0L</span>, <span class=\"pl-s\"><span class=\"pl-pds\">\"</span><span class=\"pl-pds\">\"</span></span>,</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "afalhambra", "createdAt": "2020-10-30T11:39:07Z", "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java", "diffHunk": "@@ -0,0 +1,149 @@\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.MockConsumer;\n+import org.apache.kafka.clients.consumer.OffsetResetStrategy;\n+import org.apache.kafka.common.TopicPartition;\n+import org.jbpm.bpmn2.core.Message;\n+import org.jbpm.bpmn2.core.Signal;\n+import org.jbpm.kie.services.impl.model.SignalDescImpl;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedUnit;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.mockito.Mockito;\n+import org.mockito.verification.VerificationMode;\n+\n+import static org.junit.Assert.assertTrue;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.timeout;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+import static org.mockito.Mockito.withSettings;\n+\n+public class KakfaServerExtensionTest {\n+\n+    private static class MockKafkaServerExtension extends KafkaServerExtension {\n+\n+        private MockConsumer<String, byte[]> consumer = new MockConsumer<String, byte[]>(OffsetResetStrategy.EARLIEST);\n+\n+        protected Consumer<String, byte[]> getKafkaConsumer() {\n+            return consumer;\n+        }\n+\n+        public MockConsumer<String, byte[]> getMockConsumer() {\n+            return consumer;\n+        }\n+    }\n+\n+    private ProcessService processService;\n+    private MockKafkaServerExtension extension;\n+    private KieServerImpl server;\n+    private KieServerRegistry registry;\n+    private DeployedUnit deployedUnit;\n+    private ProcessDefinition processDefinition;\n+\n+    @Before\n+    public void setup() {\n+        extension = new MockKafkaServerExtension();\n+        server = mock(KieServerImpl.class);\n+        registry = mock(KieServerRegistry.class);\n+        KieServerExtension serverExtension = mock(KieServerExtension.class);\n+\n+        when(registry.getServerExtension(Mockito.anyString())).thenReturn(serverExtension);\n+        ListenerSupport deployService = mock(ListenerSupport.class, withSettings().extraInterfaces(\n+                DeploymentService.class));\n+        processService = mock(ProcessService.class);\n+        when(serverExtension.getServices()).thenReturn(Arrays.asList(deployService, processService));\n+        extension.init(server, registry);\n+        extension.serverStarted();\n+        deployedUnit = mock(DeployedUnit.class);\n+        processDefinition = mock(ProcessDefinition.class);\n+        when(deployedUnit.getDeployedAssets()).thenReturn(Collections.singletonList(processDefinition));\n+    }\n+\n+    @After\n+    public void close() {\n+        extension.destroy(server, registry);\n+    }\n+\n+    @Test\n+    public void testKafkaServerExecutorSignal() throws InterruptedException {\n+        when(processDefinition.getSignalsMetadata()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+                new Signal(\"MySignal\", \"MySignal\", \"String\"))));\n+        when(deployedUnit.getDeployedAssets()).thenReturn(Collections.singletonList(processDefinition));\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy\", deployedUnit));\n+        publishEvent(\"MySignal\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"javierito\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy\", \"MySignal\", \"javierito\");\n+    }\n+\n+    @Test\n+    public void testKafkaServerExecutorMessage() throws InterruptedException {\n+\n+        Message msg = new Message(\"MyMessage\");\n+        msg.setName(\"Hello\");\n+        msg.setType(\"String\");\n+        when(processDefinition.getSignalsMetadata()).thenReturn(Collections.singletonList(SignalDescImpl.from(msg)));\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy\", deployedUnit));\n+        publishEvent(\"Hello\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"pepe\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy\", \"Message-Hello\", \"pepe\");\n+    }\n+\n+    @Test\n+    public void testKafkaServerExecutorMessageTopic() throws InterruptedException {\n+\n+        final String topicProperty = KafkaServerExtension.TOPIC_PREFIX + \"Hello\";\n+        System.setProperty(topicProperty, \"MyTopic\");\n+        try {\n+            Message msg = new Message(\"MyMessage\");\n+            msg.setName(\"Hello\");\n+            msg.setType(\"String\");\n+            when(processDefinition.getSignalsMetadata()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+                    msg)));\n+            extension.onDeploy(new DeploymentEvent(\"MyDeploy\", deployedUnit));\n+            publishEvent(\"MyTopic\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"pepe\\\"}\");\n+            verify(processService, getTimeout()).signalEvent(\"MyDeploy\", \"Message-Hello\", \"pepe\");\n+        } finally {\n+            System.clearProperty(topicProperty);\n+        }\n+    }\n+\n+    private VerificationMode getTimeout() {\n+        return timeout(Long.getLong(KafkaServerExtension.KAFKA_EXTENSION_PREFIX + \"poll.interval\", 1L) * 2000).times(1);\n+    }\n+\n+    private void publishEvent(String topic, String cloudEventText) {\n+        Set<String> topics = extension.getMockConsumer().subscription();\n+        assertTrue(\"Topic \" + topic + \" not found\", topics.contains(topic));\n+        List<TopicPartition> partitions = Collections.singletonList(new TopicPartition(topic, 0));\n+        extension.getMockConsumer().rebalance(partitions);\n+        Map<TopicPartition, Long> partitionsBeginningMap = new HashMap<TopicPartition, Long>();\n+        Map<TopicPartition, Long> partitionsEndMap = new HashMap<TopicPartition, Long>();\n+        long records = 10L;\n+        for (TopicPartition partition : partitions) {\n+            partitionsBeginningMap.put(partition, 0l);\n+            partitionsEndMap.put(partition, records);\n+        }\n+        extension.getMockConsumer().updateBeginningOffsets(partitionsBeginningMap);\n+        extension.getMockConsumer().updateEndOffsets(partitionsEndMap);\n+        extension.getMockConsumer().addRecord(new ConsumerRecord<String, byte[]>(topic, 0, 0L, \"\",", "originalCommit": "702567a869b50937e72c6dd7c121751cda401833", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5162c4b335dc9d4e66a42d45755478723f9ecd40", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\nindex 3cd6e9637..3300b55d2 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\n", "chunk": "@@ -133,16 +133,16 @@ public class KakfaServerExtensionTest {\n         assertTrue(\"Topic \" + topic + \" not found\", topics.contains(topic));\n         List<TopicPartition> partitions = Collections.singletonList(new TopicPartition(topic, 0));\n         extension.getMockConsumer().rebalance(partitions);\n-        Map<TopicPartition, Long> partitionsBeginningMap = new HashMap<TopicPartition, Long>();\n-        Map<TopicPartition, Long> partitionsEndMap = new HashMap<TopicPartition, Long>();\n+        Map<TopicPartition, Long> partitionsBeginningMap = new HashMap<>();\n+        Map<TopicPartition, Long> partitionsEndMap = new HashMap<>();\n         long records = 10L;\n         for (TopicPartition partition : partitions) {\n-            partitionsBeginningMap.put(partition, 0l);\n+            partitionsBeginningMap.put(partition, 0L);\n             partitionsEndMap.put(partition, records);\n         }\n         extension.getMockConsumer().updateBeginningOffsets(partitionsBeginningMap);\n         extension.getMockConsumer().updateEndOffsets(partitionsEndMap);\n-        extension.getMockConsumer().addRecord(new ConsumerRecord<String, byte[]>(topic, 0, 0L, \"\",\n+        extension.getMockConsumer().addRecord(new ConsumerRecord<>(topic, 0, 0L, \"\",\n                 cloudEventText.getBytes()));\n     }\n \n", "next_change": {"commit": "02a8f2440ed9ecc0abc0702a1a04c97f91f348f9", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\nindex 3300b55d2..674143227 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\n", "chunk": "@@ -135,10 +135,9 @@ public class KakfaServerExtensionTest {\n         extension.getMockConsumer().rebalance(partitions);\n         Map<TopicPartition, Long> partitionsBeginningMap = new HashMap<>();\n         Map<TopicPartition, Long> partitionsEndMap = new HashMap<>();\n-        long records = 10L;\n         for (TopicPartition partition : partitions) {\n             partitionsBeginningMap.put(partition, 0L);\n-            partitionsEndMap.put(partition, records);\n+            partitionsEndMap.put(partition, 1L);\n         }\n         extension.getMockConsumer().updateBeginningOffsets(partitionsBeginningMap);\n         extension.getMockConsumer().updateEndOffsets(partitionsEndMap);\n", "next_change": {"commit": "1ab6958fe0bfbaf2245278de193e40219f168da9", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KafkaServerExtensionTest.java\nsimilarity index 63%\nrename from kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\nrename to kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KafkaServerExtensionTest.java\nindex 674143227..772892124 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KafkaServerExtensionTest.java\n", "chunk": "@@ -124,24 +143,45 @@ public class KakfaServerExtensionTest {\n         }\n     }\n \n+    @Test\n+    public void testWithDestroy() {\n+        when(processDefinition.getSignalsDesc()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+                new Signal(\"MySignal\", \"MySignal\", \"String\"))));\n+        Message msg = new Message(\"MyMessage\");\n+        msg.setName(\"Hello2\");\n+        msg.setType(\"String\");\n+        when(processDefinition.getMessagesDesc()).thenReturn(Collections.singletonList(MessageDescImpl.from(\n+                msg)));\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy1\", deployedUnit));\n+        publishEvent(\"MySignal\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"javierito\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy1\", \"MySignal\", \"javierito\");\n+        extension.destroy(server, registry);\n+        mockConsumer = new MockConsumer<String, byte[]>(OffsetResetStrategy.EARLIEST);\n+        extension.setKafkaConsumer(mockConsumer);\n+        extension.init(server, registry);\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy2\", deployedUnit));\n+        publishEvent(\"Hello2\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"pepe\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy2\", \"Message-Hello2\", \"pepe\");\n+    }\n+\n     private VerificationMode getTimeout() {\n         return timeout(Long.getLong(KafkaServerExtension.KAFKA_EXTENSION_PREFIX + \"poll.interval\", 1L) * 2000).times(1);\n     }\n \n     private void publishEvent(String topic, String cloudEventText) {\n-        Set<String> topics = extension.getMockConsumer().subscription();\n+        Set<String> topics = mockConsumer.subscription();\n         assertTrue(\"Topic \" + topic + \" not found\", topics.contains(topic));\n         List<TopicPartition> partitions = Collections.singletonList(new TopicPartition(topic, 0));\n-        extension.getMockConsumer().rebalance(partitions);\n+        mockConsumer.rebalance(partitions);\n         Map<TopicPartition, Long> partitionsBeginningMap = new HashMap<>();\n         Map<TopicPartition, Long> partitionsEndMap = new HashMap<>();\n         for (TopicPartition partition : partitions) {\n             partitionsBeginningMap.put(partition, 0L);\n             partitionsEndMap.put(partition, 1L);\n         }\n-        extension.getMockConsumer().updateBeginningOffsets(partitionsBeginningMap);\n-        extension.getMockConsumer().updateEndOffsets(partitionsEndMap);\n-        extension.getMockConsumer().addRecord(new ConsumerRecord<>(topic, 0, 0L, \"\",\n+        mockConsumer.updateBeginningOffsets(partitionsBeginningMap);\n+        mockConsumer.updateEndOffsets(partitionsEndMap);\n+        mockConsumer.addRecord(new ConsumerRecord<>(topic, 0, 0L, \"\",\n                 cloudEventText.getBytes()));\n     }\n \n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTAzNzQwNg==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515037406", "body": "```suggestion\r\n            partitionsBeginningMap.put(partition, 0L);\r\n```", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        partitionsBeginningMap.put(partition, 0l);\n          \n          \n            \n                        partitionsBeginningMap.put(partition, 0L);", "bodyHTML": "  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">            partitionsBeginningMap<span class=\"pl-k\">.</span>put(partition, <span class=\"pl-c1 x x-first x-last\">0l</span>);</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">            partitionsBeginningMap<span class=\"pl-k\">.</span>put(partition, <span class=\"pl-c1 x x-first x-last\">0L</span>);</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "afalhambra", "createdAt": "2020-10-30T11:39:27Z", "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java", "diffHunk": "@@ -0,0 +1,149 @@\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.MockConsumer;\n+import org.apache.kafka.clients.consumer.OffsetResetStrategy;\n+import org.apache.kafka.common.TopicPartition;\n+import org.jbpm.bpmn2.core.Message;\n+import org.jbpm.bpmn2.core.Signal;\n+import org.jbpm.kie.services.impl.model.SignalDescImpl;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedUnit;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.mockito.Mockito;\n+import org.mockito.verification.VerificationMode;\n+\n+import static org.junit.Assert.assertTrue;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.timeout;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+import static org.mockito.Mockito.withSettings;\n+\n+public class KakfaServerExtensionTest {\n+\n+    private static class MockKafkaServerExtension extends KafkaServerExtension {\n+\n+        private MockConsumer<String, byte[]> consumer = new MockConsumer<String, byte[]>(OffsetResetStrategy.EARLIEST);\n+\n+        protected Consumer<String, byte[]> getKafkaConsumer() {\n+            return consumer;\n+        }\n+\n+        public MockConsumer<String, byte[]> getMockConsumer() {\n+            return consumer;\n+        }\n+    }\n+\n+    private ProcessService processService;\n+    private MockKafkaServerExtension extension;\n+    private KieServerImpl server;\n+    private KieServerRegistry registry;\n+    private DeployedUnit deployedUnit;\n+    private ProcessDefinition processDefinition;\n+\n+    @Before\n+    public void setup() {\n+        extension = new MockKafkaServerExtension();\n+        server = mock(KieServerImpl.class);\n+        registry = mock(KieServerRegistry.class);\n+        KieServerExtension serverExtension = mock(KieServerExtension.class);\n+\n+        when(registry.getServerExtension(Mockito.anyString())).thenReturn(serverExtension);\n+        ListenerSupport deployService = mock(ListenerSupport.class, withSettings().extraInterfaces(\n+                DeploymentService.class));\n+        processService = mock(ProcessService.class);\n+        when(serverExtension.getServices()).thenReturn(Arrays.asList(deployService, processService));\n+        extension.init(server, registry);\n+        extension.serverStarted();\n+        deployedUnit = mock(DeployedUnit.class);\n+        processDefinition = mock(ProcessDefinition.class);\n+        when(deployedUnit.getDeployedAssets()).thenReturn(Collections.singletonList(processDefinition));\n+    }\n+\n+    @After\n+    public void close() {\n+        extension.destroy(server, registry);\n+    }\n+\n+    @Test\n+    public void testKafkaServerExecutorSignal() throws InterruptedException {\n+        when(processDefinition.getSignalsMetadata()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+                new Signal(\"MySignal\", \"MySignal\", \"String\"))));\n+        when(deployedUnit.getDeployedAssets()).thenReturn(Collections.singletonList(processDefinition));\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy\", deployedUnit));\n+        publishEvent(\"MySignal\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"javierito\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy\", \"MySignal\", \"javierito\");\n+    }\n+\n+    @Test\n+    public void testKafkaServerExecutorMessage() throws InterruptedException {\n+\n+        Message msg = new Message(\"MyMessage\");\n+        msg.setName(\"Hello\");\n+        msg.setType(\"String\");\n+        when(processDefinition.getSignalsMetadata()).thenReturn(Collections.singletonList(SignalDescImpl.from(msg)));\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy\", deployedUnit));\n+        publishEvent(\"Hello\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"pepe\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy\", \"Message-Hello\", \"pepe\");\n+    }\n+\n+    @Test\n+    public void testKafkaServerExecutorMessageTopic() throws InterruptedException {\n+\n+        final String topicProperty = KafkaServerExtension.TOPIC_PREFIX + \"Hello\";\n+        System.setProperty(topicProperty, \"MyTopic\");\n+        try {\n+            Message msg = new Message(\"MyMessage\");\n+            msg.setName(\"Hello\");\n+            msg.setType(\"String\");\n+            when(processDefinition.getSignalsMetadata()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+                    msg)));\n+            extension.onDeploy(new DeploymentEvent(\"MyDeploy\", deployedUnit));\n+            publishEvent(\"MyTopic\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"pepe\\\"}\");\n+            verify(processService, getTimeout()).signalEvent(\"MyDeploy\", \"Message-Hello\", \"pepe\");\n+        } finally {\n+            System.clearProperty(topicProperty);\n+        }\n+    }\n+\n+    private VerificationMode getTimeout() {\n+        return timeout(Long.getLong(KafkaServerExtension.KAFKA_EXTENSION_PREFIX + \"poll.interval\", 1L) * 2000).times(1);\n+    }\n+\n+    private void publishEvent(String topic, String cloudEventText) {\n+        Set<String> topics = extension.getMockConsumer().subscription();\n+        assertTrue(\"Topic \" + topic + \" not found\", topics.contains(topic));\n+        List<TopicPartition> partitions = Collections.singletonList(new TopicPartition(topic, 0));\n+        extension.getMockConsumer().rebalance(partitions);\n+        Map<TopicPartition, Long> partitionsBeginningMap = new HashMap<TopicPartition, Long>();\n+        Map<TopicPartition, Long> partitionsEndMap = new HashMap<TopicPartition, Long>();\n+        long records = 10L;\n+        for (TopicPartition partition : partitions) {\n+            partitionsBeginningMap.put(partition, 0l);", "originalCommit": "702567a869b50937e72c6dd7c121751cda401833", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5162c4b335dc9d4e66a42d45755478723f9ecd40", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\nindex 3cd6e9637..3300b55d2 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\n", "chunk": "@@ -133,16 +133,16 @@ public class KakfaServerExtensionTest {\n         assertTrue(\"Topic \" + topic + \" not found\", topics.contains(topic));\n         List<TopicPartition> partitions = Collections.singletonList(new TopicPartition(topic, 0));\n         extension.getMockConsumer().rebalance(partitions);\n-        Map<TopicPartition, Long> partitionsBeginningMap = new HashMap<TopicPartition, Long>();\n-        Map<TopicPartition, Long> partitionsEndMap = new HashMap<TopicPartition, Long>();\n+        Map<TopicPartition, Long> partitionsBeginningMap = new HashMap<>();\n+        Map<TopicPartition, Long> partitionsEndMap = new HashMap<>();\n         long records = 10L;\n         for (TopicPartition partition : partitions) {\n-            partitionsBeginningMap.put(partition, 0l);\n+            partitionsBeginningMap.put(partition, 0L);\n             partitionsEndMap.put(partition, records);\n         }\n         extension.getMockConsumer().updateBeginningOffsets(partitionsBeginningMap);\n         extension.getMockConsumer().updateEndOffsets(partitionsEndMap);\n-        extension.getMockConsumer().addRecord(new ConsumerRecord<String, byte[]>(topic, 0, 0L, \"\",\n+        extension.getMockConsumer().addRecord(new ConsumerRecord<>(topic, 0, 0L, \"\",\n                 cloudEventText.getBytes()));\n     }\n \n", "next_change": {"commit": "02a8f2440ed9ecc0abc0702a1a04c97f91f348f9", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\nindex 3300b55d2..674143227 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\n", "chunk": "@@ -135,10 +135,9 @@ public class KakfaServerExtensionTest {\n         extension.getMockConsumer().rebalance(partitions);\n         Map<TopicPartition, Long> partitionsBeginningMap = new HashMap<>();\n         Map<TopicPartition, Long> partitionsEndMap = new HashMap<>();\n-        long records = 10L;\n         for (TopicPartition partition : partitions) {\n             partitionsBeginningMap.put(partition, 0L);\n-            partitionsEndMap.put(partition, records);\n+            partitionsEndMap.put(partition, 1L);\n         }\n         extension.getMockConsumer().updateBeginningOffsets(partitionsBeginningMap);\n         extension.getMockConsumer().updateEndOffsets(partitionsEndMap);\n", "next_change": {"commit": "1ab6958fe0bfbaf2245278de193e40219f168da9", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KafkaServerExtensionTest.java\nsimilarity index 63%\nrename from kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\nrename to kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KafkaServerExtensionTest.java\nindex 674143227..772892124 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KakfaServerExtensionTest.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KafkaServerExtensionTest.java\n", "chunk": "@@ -124,24 +143,45 @@ public class KakfaServerExtensionTest {\n         }\n     }\n \n+    @Test\n+    public void testWithDestroy() {\n+        when(processDefinition.getSignalsDesc()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+                new Signal(\"MySignal\", \"MySignal\", \"String\"))));\n+        Message msg = new Message(\"MyMessage\");\n+        msg.setName(\"Hello2\");\n+        msg.setType(\"String\");\n+        when(processDefinition.getMessagesDesc()).thenReturn(Collections.singletonList(MessageDescImpl.from(\n+                msg)));\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy1\", deployedUnit));\n+        publishEvent(\"MySignal\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"javierito\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy1\", \"MySignal\", \"javierito\");\n+        extension.destroy(server, registry);\n+        mockConsumer = new MockConsumer<String, byte[]>(OffsetResetStrategy.EARLIEST);\n+        extension.setKafkaConsumer(mockConsumer);\n+        extension.init(server, registry);\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy2\", deployedUnit));\n+        publishEvent(\"Hello2\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"pepe\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy2\", \"Message-Hello2\", \"pepe\");\n+    }\n+\n     private VerificationMode getTimeout() {\n         return timeout(Long.getLong(KafkaServerExtension.KAFKA_EXTENSION_PREFIX + \"poll.interval\", 1L) * 2000).times(1);\n     }\n \n     private void publishEvent(String topic, String cloudEventText) {\n-        Set<String> topics = extension.getMockConsumer().subscription();\n+        Set<String> topics = mockConsumer.subscription();\n         assertTrue(\"Topic \" + topic + \" not found\", topics.contains(topic));\n         List<TopicPartition> partitions = Collections.singletonList(new TopicPartition(topic, 0));\n-        extension.getMockConsumer().rebalance(partitions);\n+        mockConsumer.rebalance(partitions);\n         Map<TopicPartition, Long> partitionsBeginningMap = new HashMap<>();\n         Map<TopicPartition, Long> partitionsEndMap = new HashMap<>();\n         for (TopicPartition partition : partitions) {\n             partitionsBeginningMap.put(partition, 0L);\n             partitionsEndMap.put(partition, 1L);\n         }\n-        extension.getMockConsumer().updateBeginningOffsets(partitionsBeginningMap);\n-        extension.getMockConsumer().updateEndOffsets(partitionsEndMap);\n-        extension.getMockConsumer().addRecord(new ConsumerRecord<>(topic, 0, 0L, \"\",\n+        mockConsumer.updateBeginningOffsets(partitionsBeginningMap);\n+        mockConsumer.updateEndOffsets(partitionsEndMap);\n+        mockConsumer.addRecord(new ConsumerRecord<>(topic, 0, 0L, \"\",\n                 cloudEventText.getBytes()));\n     }\n \n", "next_change": null}]}}]}}]}}, {"oid": "5162c4b335dc9d4e66a42d45755478723f9ecd40", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/5162c4b335dc9d4e66a42d45755478723f9ecd40", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-10-30T15:15:43Z", "type": "forcePushed"}, {"oid": "02a8f2440ed9ecc0abc0702a1a04c97f91f348f9", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/02a8f2440ed9ecc0abc0702a1a04c97f91f348f9", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-10-30T15:17:23Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTkxNzk0Mg==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515917942", "body": "extract DeploymentEventListener (this is the topic manager) and Runnable (this is the event executor) from here.", "bodyText": "extract DeploymentEventListener (this is the topic manager) and Runnable (this is the event executor) from here.", "bodyHTML": "<p dir=\"auto\">extract DeploymentEventListener (this is the topic manager) and Runnable (this is the event executor) from here.</p>", "author": "elguardian", "createdAt": "2020-11-02T11:45:53Z", "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java", "diffHunk": "@@ -0,0 +1,307 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+*/\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.time.Duration;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.function.BiConsumer;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.serialization.ByteArrayDeserializer;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentEventListener;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedAsset;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.jbpm.services.api.model.SignalDesc;\n+import org.jbpm.services.api.model.SignalType;\n+import org.kie.server.api.KieServerConstants;\n+import org.kie.server.services.api.KieContainerInstance;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.api.SupportedTransports;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.kie.server.services.jbpm.JbpmKieServerExtension;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KafkaServerExtension implements KieServerExtension, DeploymentEventListener, Runnable {", "originalCommit": "02a8f2440ed9ecc0abc0702a1a04c97f91f348f9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjY1MTE4Mg==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r516651182", "bodyText": "I prefer to save object creation but making the extension implementing them", "author": "fjtirado", "createdAt": "2020-11-03T13:05:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTkxNzk0Mg=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTkyMTEwOA==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515921108", "body": "test signal first and then messages. there is no such thing as signal type message (in spite it is implemented that way)\r\nif (there is no signal  defined should log a warn message like there is no way I sent this to jbpm or signal not bounded to any process in kjar bla bla bal\r\nif there is a parse exception should ignore the error (dont't log at that level) as you are doing content based routing (log as warn message) -> ignoring event by jbpm (you have the structure ref (if that is defined then use it) -> getClassData\r\n\r\n", "bodyText": "test signal first and then messages. there is no such thing as signal type message (in spite it is implemented that way)\nif (there is no signal  defined should log a warn message like there is no way I sent this to jbpm or signal not bounded to any process in kjar bla bla bal\nif there is a parse exception should ignore the error (dont't log at that level) as you are doing content based routing (log as warn message) -> ignoring event by jbpm (you have the structure ref (if that is defined then use it) -> getClassData", "bodyHTML": "<p dir=\"auto\">test signal first and then messages. there is no such thing as signal type message (in spite it is implemented that way)<br>\nif (there is no signal  defined should log a warn message like there is no way I sent this to jbpm or signal not bounded to any process in kjar bla bla bal<br>\nif there is a parse exception should ignore the error (dont't log at that level) as you are doing content based routing (log as warn message) -&gt; ignoring event by jbpm (you have the structure ref (if that is defined then use it) -&gt; getClassData</p>", "author": "elguardian", "createdAt": "2020-11-02T11:52:19Z", "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java", "diffHunk": "@@ -0,0 +1,307 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+*/\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.time.Duration;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.function.BiConsumer;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.serialization.ByteArrayDeserializer;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentEventListener;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedAsset;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.jbpm.services.api.model.SignalDesc;\n+import org.jbpm.services.api.model.SignalType;\n+import org.kie.server.api.KieServerConstants;\n+import org.kie.server.services.api.KieContainerInstance;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.api.SupportedTransports;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.kie.server.services.jbpm.JbpmKieServerExtension;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KafkaServerExtension implements KieServerExtension, DeploymentEventListener, Runnable {\n+\n+    public static final String EXTENSION_NAME = \"Kafka\";\n+    static final String KAFKA_EXTENSION_PREFIX = \"org.kie.server.jbpm-kafka.ext.\";\n+    static final String TOPIC_PREFIX = KAFKA_EXTENSION_PREFIX + \"topics.\";\n+    private static final Logger logger = LoggerFactory.getLogger(KafkaServerExtension.class);\n+\n+    private AtomicBoolean initialized = new AtomicBoolean();\n+    private Consumer<String, byte[]> consumer;\n+    private ListenerSupport deploymentService;\n+    private ProcessService processService;\n+    private ScheduledExecutorService pollService;\n+    private ExecutorService notifyService;\n+\n+    private Map<String, SignalInfo> topic2Signal = new ConcurrentHashMap<>();\n+\n+    @Override\n+    public boolean isInitialized() {\n+        return initialized.get();\n+    }\n+\n+    @Override\n+    public boolean isActive() {\n+        return !Boolean.getBoolean(KieServerConstants.KIE_KAFKA_SERVER_EXT_DISABLED);\n+    }\n+\n+    @Override\n+    public void init(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (initialized.getAndSet(true)) {\n+            return;\n+        }\n+        pollService = Executors.newSingleThreadScheduledExecutor();\n+        notifyService = Executors.newCachedThreadPool();\n+        consumer = getKafkaConsumer();\n+        KieServerExtension jbpmExt = registry.getServerExtension(JbpmKieServerExtension.EXTENSION_NAME);\n+        if (jbpmExt == null) {\n+            throw new IllegalStateException(\"Cannot find extension \" + JbpmKieServerExtension.EXTENSION_NAME);\n+        }\n+\n+        for (Object service : jbpmExt.getServices()) {\n+            if (deploymentService == null && DeploymentService.class.isAssignableFrom(service.getClass())) {\n+                deploymentService = (ListenerSupport) service;\n+            } else if (processService == null && ProcessService.class.isAssignableFrom(service.getClass())) {\n+                processService = (ProcessService) service;\n+            }\n+            if (deploymentService != null && processService != null) {\n+                break;\n+            }\n+        }\n+        if (deploymentService == null) {\n+            throw new IllegalStateException(\"Cannot find deployment service\");\n+        }\n+        if (processService == null) {\n+            throw new IllegalStateException(\"Cannot find process service\");\n+        }\n+        deploymentService.addListener(this);\n+    }\n+\n+    @Override\n+    public void destroy(KieServerImpl kieServer, KieServerRegistry registry) {\n+        pollService.shutdownNow();\n+        pollService = null;\n+        notifyService.shutdownNow();\n+        notifyService = null;\n+        if (deploymentService != null) {\n+            deploymentService.removeListener(this);\n+            deploymentService = null;\n+        }\n+        if (consumer != null) {\n+            consumer.close();\n+            consumer = null;\n+        }\n+        initialized.set(false);\n+    }\n+\n+    protected Consumer<String, byte[]> getKafkaConsumer() {\n+        Map<String, Object> props = new HashMap<>();\n+        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, System.getProperty(\n+                KAFKA_EXTENSION_PREFIX + \"boopstrap.servers\", \"localhost:9092\"));\n+        // read only committed events\n+        props.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, IsolationLevel.READ_COMMITTED.toString().toLowerCase());\n+        // do not automatically create topics by default\n+        props.put(ConsumerConfig.ALLOW_AUTO_CREATE_TOPICS_CONFIG, Boolean.getBoolean(\n+                KAFKA_EXTENSION_PREFIX + \"auto.create.topics\"));\n+        props.put(ConsumerConfig.GROUP_ID_CONFIG, System.getProperty(KAFKA_EXTENSION_PREFIX + \"group.id\",\n+                \"jbpm-consumer\"));\n+        return new KafkaConsumer<>(props, new StringDeserializer(), new ByteArrayDeserializer());\n+    }\n+\n+    @Override\n+    public void onDeploy(DeploymentEvent event) {\n+        updateRegistration(event, this::updateTopics);\n+    }\n+\n+    @Override\n+    public void onUnDeploy(DeploymentEvent event) {\n+        updateRegistration(event, this::removeTopics);\n+    }\n+\n+    @Override\n+    public void onActivate(DeploymentEvent event) {\n+        updateRegistration(event, this::updateTopics);\n+    }\n+\n+    @Override\n+    public void onDeactivate(DeploymentEvent event) {\n+        updateRegistration(event, this::removeTopics);\n+    }\n+\n+    private void updateTopics(String deploymentId, ProcessDefinition processDefinition) {\n+        for (SignalDesc signal : processDefinition.getSignalsMetadata()) {\n+            topic2Signal.computeIfAbsent(topicFromSignal(signal), t -> new SignalInfo(deploymentId,\n+                    signal));\n+        }\n+    }\n+\n+    private void removeTopics(String deploymentId, ProcessDefinition processDefinition) {\n+        for (SignalDesc signal : processDefinition.getSignalsMetadata()) {\n+            topic2Signal.remove(topicFromSignal(signal));\n+        }\n+    }\n+\n+    private void updateRegistration(DeploymentEvent event, BiConsumer<String, ProcessDefinition> updater) {\n+        if (consumer != null) {\n+            for (DeployedAsset asset : event.getDeployedUnit().getDeployedAssets()) {\n+                updater.accept(event.getDeploymentId(), (ProcessDefinition) asset);\n+            }\n+            synchronized (consumer) {\n+                consumer.subscribe(topic2Signal.keySet());\n+            }\n+        }\n+    }\n+\n+    private String topicFromSignal(SignalDesc signal) {\n+        return System.getProperty(TOPIC_PREFIX + signal.getName(), signal.getName());\n+    }\n+\n+    @Override\n+    public void serverStarted() {\n+        if (pollService != null) {\n+            long delay = Long.getLong(KAFKA_EXTENSION_PREFIX + \"poll.interval\", 1L);\n+            pollService.scheduleWithFixedDelay(this, delay, delay, TimeUnit.SECONDS);\n+        }\n+    }\n+\n+    @Override\n+    public void createContainer(String id, KieContainerInstance kieContainerInstance, Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public boolean isUpdateContainerAllowed(String id,\n+                                            KieContainerInstance kieContainerInstance,\n+                                            Map<String, Object> parameters) {\n+        return false;\n+    }\n+\n+    @Override\n+    public void prepareContainerUpdate(String id,\n+                                       KieContainerInstance kieContainerInstance,\n+                                       Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public void updateContainer(String id, KieContainerInstance kieContainerInstance, Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public void disposeContainer(String id, KieContainerInstance kieContainerInstance, Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public List<Object> getAppComponents(SupportedTransports type) {\n+        return Collections.emptyList();\n+    }\n+\n+    @Override\n+    public <T> T getAppComponents(Class<T> serviceType) {\n+        return null;\n+    }\n+\n+    @Override\n+    public String getImplementedCapability() {\n+        return KieServerConstants.CAPABILITY_BPM_KAFKA;\n+    }\n+\n+    @Override\n+    public List<Object> getServices() {\n+        return Collections.emptyList();\n+    }\n+\n+    @Override\n+    public String getExtensionName() {\n+        return EXTENSION_NAME;\n+    }\n+\n+    @Override\n+    public Integer getStartOrder() {\n+        return 20;\n+    }\n+\n+    @Override\n+    public void run() {\n+        if (consumer != null && !topic2Signal.isEmpty()) {\n+            ConsumerRecords<String, byte[]> events;\n+            synchronized (consumer) {\n+                events = consumer.subscription().isEmpty() ? ConsumerRecords.empty() : consumer.poll(Duration.ZERO);\n+            }\n+            for (ConsumerRecord<String, byte[]> event : events) {\n+                notifyService.submit(() -> processEvent(event));\n+            }\n+        }\n+    }\n+\n+    private void processEvent(ConsumerRecord<String, byte[]> event) {\n+        SignalInfo signalInfo = topic2Signal.get(event.topic());", "originalCommit": "02a8f2440ed9ecc0abc0702a1a04c97f91f348f9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjY1MTg5NA==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r516651894", "bodyText": "Implementation changed to deal with two different methods: getSignalsDesc and getMessagesDesc. This certainly complicates implementation here, but allow message and signal diverge on future (right now, they have the same data, thats why the implementation was done assuming identity between them)", "author": "fjtirado", "createdAt": "2020-11-03T13:06:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTkyMTEwOA=="}], "type": "inlineReview", "revised_code": {"commit": "13c42b110a2fa2f9b6077c14c2094fea8dcc20b2", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\nindex 2911ced89..230145dbf 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n", "chunk": "@@ -262,34 +313,58 @@ public class KafkaServerExtension implements KieServerExtension, DeploymentEvent\n \n     @Override\n     public void run() {\n-        if (consumer != null && !topic2Signal.isEmpty()) {\n-            ConsumerRecords<String, byte[]> events;\n-            synchronized (consumer) {\n-                events = consumer.subscription().isEmpty() ? ConsumerRecords.empty() : consumer.poll(Duration.ZERO);\n-            }\n-            for (ConsumerRecord<String, byte[]> event : events) {\n-                notifyService.submit(() -> processEvent(event));\n+        changeRegistrationLock.lock();\n+        try {\n+            if (consumer != null && (!topic2Message.isEmpty() || !topic2Signal.isEmpty())) {\n+                ConsumerRecords<String, byte[]> events = consumer.subscription().isEmpty() ? ConsumerRecords.empty()\n+                        : consumer.poll(Duration.ZERO);\n+                for (ConsumerRecord<String, byte[]> event : events) {\n+                    notifyService.submit(() -> processEvent(event));\n+                }\n             }\n+        } finally {\n+            changeRegistrationLock.unlock();\n         }\n     }\n \n+    @FunctionalInterface\n+    private static interface Signaller {\n+\n+        void signalEvent(String deploymentId, String signalName, Object data);\n+    }\n+\n     private void processEvent(ConsumerRecord<String, byte[]> event) {\n-        SignalInfo signalInfo = topic2Signal.get(event.topic());\n+        changeRegistrationLock.lock();\n+        try {\n+            processEvent(topic2Signal, event, (deployment, signalName, data) -> processService.signalEvent(deployment,\n+                    signalName, data));\n+            processEvent(topic2Message, event, (deployment, signalName, data) -> processService.signalEvent(deployment,\n+                    \"Message-\" + signalName, data));\n+        } finally {\n+            changeRegistrationLock.unlock();\n+        }\n+    }\n+\n+    private <T extends SignalDescBase> void processEvent(Map<String, Map<T, Collection<String>>> topic2SignalBase,\n+                                                         ConsumerRecord<String, byte[]> event,\n+                                                         Signaller signaller) {\n+        Map<T, Collection<String>> signalInfo = topic2SignalBase.get(event.topic());\n         if (signalInfo != null) {\n-            try {\n-                String type = signalInfo.getSignalDesc().getName();\n-                if (signalInfo.getSignalDesc().getSignalType() == SignalType.MESSAGE) {\n-                    type = \"Message-\" + type;\n+            for (Map.Entry<T, Collection<String>> entry : signalInfo.entrySet())\n+                try {\n+                    String signalName = entry.getKey().getName();\n+                    CloudEvent<?> cloudEvent = CloudEvent.read(event.value(),\n+                            getDataClass(entry.getKey()));\n+                    for (String deploymentId : entry.getValue()) {\n+                        signaller.signalEvent(deploymentId, signalName, cloudEvent.getData());\n+                    }\n+                } catch (IOException | ParseException e) {\n+                    logger.error(\"Error deserializing event\", e);\n                 }\n-                processService.signalEvent(signalInfo.getDeploymentId(), type, CloudEvent.read(event.value(),\n-                        getDataClass(signalInfo.getSignalDesc())).getData());\n-            } catch (IOException | ParseException e) {\n-                logger.error(\"Error deserializing event\", e);\n-            }\n         }\n     }\n \n-    private Class<?> getDataClass(SignalDesc signalDesc) {\n+    private <T extends SignalDescBase> Class<?> getDataClass(T signalDesc) {\n         Class<?> dataClazz = Object.class;\n         if (signalDesc.getStructureRef() != null) {\n             try {\n", "next_change": {"commit": "89ec48820033dc591dbdd8172b8ed967bee3bb4e", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\nindex 230145dbf..2b635b5b9 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n", "chunk": "@@ -353,30 +385,34 @@ public class KafkaServerExtension implements KieServerExtension, DeploymentEvent\n             for (Map.Entry<T, Collection<String>> entry : signalInfo.entrySet())\n                 try {\n                     String signalName = entry.getKey().getName();\n-                    CloudEvent<?> cloudEvent = CloudEvent.read(event.value(),\n-                            getDataClass(entry.getKey()));\n                     for (String deploymentId : entry.getValue()) {\n+                        CloudEvent<?> cloudEvent = CloudEvent.read(event.value(), getDataClass(deploymentId, entry\n+                                .getKey()));\n+                        logger.debug(\"Sending event with name {} to deployment {} with data {}\", signalName,\n+                                deploymentId, cloudEvent.getData());\n                         signaller.signalEvent(deploymentId, signalName, cloudEvent.getData());\n                     }\n-                } catch (IOException | ParseException e) {\n+                } catch (IOException | ParseException | ClassNotFoundException e) {\n                     logger.error(\"Error deserializing event\", e);\n                 }\n         }\n     }\n \n-    private <T extends SignalDescBase> Class<?> getDataClass(T signalDesc) {\n-        Class<?> dataClazz = Object.class;\n-        if (signalDesc.getStructureRef() != null) {\n-            try {\n-                String className = signalDesc.getStructureRef();\n-                if (!className.contains(\".\")) {\n-                    className = \"java.lang.\" + className;\n-                }\n-                dataClazz = Class.forName(className);\n-            } catch (ClassNotFoundException ex) {\n-                logger.error(\"Invalid class in structure ref\", ex);\n+    private <T extends SignalDescBase> Class<?> getDataClass(String deploymentId,\n+                                                             T signalDesc) throws ClassNotFoundException {\n+        Optional<Class<?>> dataClazz = Optional.empty();\n+        String className = signalDesc.getStructureRef();\n+        if (className != null) {\n+            Collection<Class<?>> deployedClasses = classes.get(deploymentId);\n+            if (deployedClasses != null) {\n+                dataClazz = deployedClasses.stream().filter(c -> c.getCanonicalName().equals(className) || c\n+                        .getSimpleName().equals(className) || c.getTypeName().equals(className)).findAny();\n+            }\n+            if (!dataClazz.isPresent()) {\n+                logger.debug(\"Class {} is not find in deploymemt {}, trying from classloader\", className, deploymentId);\n+                dataClazz = Optional.of(Class.forName(className.contains(\".\") ? className : \"java.lang.\" + className));\n             }\n         }\n-        return dataClazz;\n+        return dataClazz.orElse(Object.class);\n     }\n }\n", "next_change": {"commit": "4b1cf7a3a0f88b8ed7f718439cec78f7b377aabf", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\nindex 2b635b5b9..02002da6f 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n", "chunk": "@@ -409,7 +431,8 @@ public class KafkaServerExtension implements KieServerExtension, DeploymentEvent\n                         .getSimpleName().equals(className) || c.getTypeName().equals(className)).findAny();\n             }\n             if (!dataClazz.isPresent()) {\n-                logger.debug(\"Class {} is not find in deploymemt {}, trying from classloader\", className, deploymentId);\n+                logger.debug(\"Class {} has not been found in deployment {}, trying from classloader\", className,\n+                        deploymentId);\n                 dataClazz = Optional.of(Class.forName(className.contains(\".\") ? className : \"java.lang.\" + className));\n             }\n         }\n", "next_change": {"commit": "9cbed4f8d3f2fbe44ae127c8c27c2dd0a917abaa", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\nindex 02002da6f..8974468be 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n", "chunk": "@@ -438,4 +436,9 @@ public class KafkaServerExtension implements KieServerExtension, DeploymentEvent\n         }\n         return dataClazz.orElse(Object.class);\n     }\n+\n+    @Override\n+    public String toString() {\n+        return EXTENSION_NAME + \" KIE Server extension\";\n+    }\n }\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTkyMjA5Mw==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515922093", "body": "the only thing missing here is the class loader. Maybe you can reuse the json marshaller (already has all this logic)\r\nAt least I cannot see how you can reach kjar class loader from here.", "bodyText": "the only thing missing here is the class loader. Maybe you can reuse the json marshaller (already has all this logic)\nAt least I cannot see how you can reach kjar class loader from here.", "bodyHTML": "<p dir=\"auto\">the only thing missing here is the class loader. Maybe you can reuse the json marshaller (already has all this logic)<br>\nAt least I cannot see how you can reach kjar class loader from here.</p>", "author": "elguardian", "createdAt": "2020-11-02T11:54:22Z", "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/CloudEvent.java", "diffHunk": "@@ -0,0 +1,96 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.text.SimpleDateFormat;\n+import java.util.Date;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n+class CloudEvent<T> {\n+\n+    private static ObjectMapper mapper = new ObjectMapper()\n+            .setDateFormat(new SimpleDateFormat(System.getProperty(\n+                    KafkaServerExtension.KAFKA_EXTENSION_PREFIX + \"json.date_format\", System.getProperty(\n+                            \"org.kie.server.json.date_format\",\n+                            \"yyyy-MM-dd'T'HH:mm:ss.SSSZ\"))));\n+\n+    private String specVersion;\n+    private Date time;\n+    private String id;\n+    private String type;\n+    private String source;\n+    private T data;\n+\n+    public static <T> CloudEvent<T> read(byte[] bytes, Class<T> type) throws IOException, ParseException {", "originalCommit": "02a8f2440ed9ecc0abc0702a1a04c97f91f348f9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjgxOTcxMw==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r516819713", "bodyText": "Good catch!. Using list of classes returned by DeployedEvent", "author": "fjtirado", "createdAt": "2020-11-03T17:00:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTkyMjA5Mw=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTkyMjY4MQ==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515922681", "body": "this is not going to find any class at project leve AFAIK.", "bodyText": "this is not going to find any class at project leve AFAIK.", "bodyHTML": "<p dir=\"auto\">this is not going to find any class at project leve AFAIK.</p>", "author": "elguardian", "createdAt": "2020-11-02T11:55:31Z", "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java", "diffHunk": "@@ -0,0 +1,307 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+*/\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.time.Duration;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.function.BiConsumer;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.serialization.ByteArrayDeserializer;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentEventListener;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedAsset;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.jbpm.services.api.model.SignalDesc;\n+import org.jbpm.services.api.model.SignalType;\n+import org.kie.server.api.KieServerConstants;\n+import org.kie.server.services.api.KieContainerInstance;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.api.SupportedTransports;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.kie.server.services.jbpm.JbpmKieServerExtension;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KafkaServerExtension implements KieServerExtension, DeploymentEventListener, Runnable {\n+\n+    public static final String EXTENSION_NAME = \"Kafka\";\n+    static final String KAFKA_EXTENSION_PREFIX = \"org.kie.server.jbpm-kafka.ext.\";\n+    static final String TOPIC_PREFIX = KAFKA_EXTENSION_PREFIX + \"topics.\";\n+    private static final Logger logger = LoggerFactory.getLogger(KafkaServerExtension.class);\n+\n+    private AtomicBoolean initialized = new AtomicBoolean();\n+    private Consumer<String, byte[]> consumer;\n+    private ListenerSupport deploymentService;\n+    private ProcessService processService;\n+    private ScheduledExecutorService pollService;\n+    private ExecutorService notifyService;\n+\n+    private Map<String, SignalInfo> topic2Signal = new ConcurrentHashMap<>();\n+\n+    @Override\n+    public boolean isInitialized() {\n+        return initialized.get();\n+    }\n+\n+    @Override\n+    public boolean isActive() {\n+        return !Boolean.getBoolean(KieServerConstants.KIE_KAFKA_SERVER_EXT_DISABLED);\n+    }\n+\n+    @Override\n+    public void init(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (initialized.getAndSet(true)) {\n+            return;\n+        }\n+        pollService = Executors.newSingleThreadScheduledExecutor();\n+        notifyService = Executors.newCachedThreadPool();\n+        consumer = getKafkaConsumer();\n+        KieServerExtension jbpmExt = registry.getServerExtension(JbpmKieServerExtension.EXTENSION_NAME);\n+        if (jbpmExt == null) {\n+            throw new IllegalStateException(\"Cannot find extension \" + JbpmKieServerExtension.EXTENSION_NAME);\n+        }\n+\n+        for (Object service : jbpmExt.getServices()) {\n+            if (deploymentService == null && DeploymentService.class.isAssignableFrom(service.getClass())) {\n+                deploymentService = (ListenerSupport) service;\n+            } else if (processService == null && ProcessService.class.isAssignableFrom(service.getClass())) {\n+                processService = (ProcessService) service;\n+            }\n+            if (deploymentService != null && processService != null) {\n+                break;\n+            }\n+        }\n+        if (deploymentService == null) {\n+            throw new IllegalStateException(\"Cannot find deployment service\");\n+        }\n+        if (processService == null) {\n+            throw new IllegalStateException(\"Cannot find process service\");\n+        }\n+        deploymentService.addListener(this);\n+    }\n+\n+    @Override\n+    public void destroy(KieServerImpl kieServer, KieServerRegistry registry) {\n+        pollService.shutdownNow();\n+        pollService = null;\n+        notifyService.shutdownNow();\n+        notifyService = null;\n+        if (deploymentService != null) {\n+            deploymentService.removeListener(this);\n+            deploymentService = null;\n+        }\n+        if (consumer != null) {\n+            consumer.close();\n+            consumer = null;\n+        }\n+        initialized.set(false);\n+    }\n+\n+    protected Consumer<String, byte[]> getKafkaConsumer() {\n+        Map<String, Object> props = new HashMap<>();\n+        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, System.getProperty(\n+                KAFKA_EXTENSION_PREFIX + \"boopstrap.servers\", \"localhost:9092\"));\n+        // read only committed events\n+        props.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, IsolationLevel.READ_COMMITTED.toString().toLowerCase());\n+        // do not automatically create topics by default\n+        props.put(ConsumerConfig.ALLOW_AUTO_CREATE_TOPICS_CONFIG, Boolean.getBoolean(\n+                KAFKA_EXTENSION_PREFIX + \"auto.create.topics\"));\n+        props.put(ConsumerConfig.GROUP_ID_CONFIG, System.getProperty(KAFKA_EXTENSION_PREFIX + \"group.id\",\n+                \"jbpm-consumer\"));\n+        return new KafkaConsumer<>(props, new StringDeserializer(), new ByteArrayDeserializer());\n+    }\n+\n+    @Override\n+    public void onDeploy(DeploymentEvent event) {\n+        updateRegistration(event, this::updateTopics);\n+    }\n+\n+    @Override\n+    public void onUnDeploy(DeploymentEvent event) {\n+        updateRegistration(event, this::removeTopics);\n+    }\n+\n+    @Override\n+    public void onActivate(DeploymentEvent event) {\n+        updateRegistration(event, this::updateTopics);\n+    }\n+\n+    @Override\n+    public void onDeactivate(DeploymentEvent event) {\n+        updateRegistration(event, this::removeTopics);\n+    }\n+\n+    private void updateTopics(String deploymentId, ProcessDefinition processDefinition) {\n+        for (SignalDesc signal : processDefinition.getSignalsMetadata()) {\n+            topic2Signal.computeIfAbsent(topicFromSignal(signal), t -> new SignalInfo(deploymentId,\n+                    signal));\n+        }\n+    }\n+\n+    private void removeTopics(String deploymentId, ProcessDefinition processDefinition) {\n+        for (SignalDesc signal : processDefinition.getSignalsMetadata()) {\n+            topic2Signal.remove(topicFromSignal(signal));\n+        }\n+    }\n+\n+    private void updateRegistration(DeploymentEvent event, BiConsumer<String, ProcessDefinition> updater) {\n+        if (consumer != null) {\n+            for (DeployedAsset asset : event.getDeployedUnit().getDeployedAssets()) {\n+                updater.accept(event.getDeploymentId(), (ProcessDefinition) asset);\n+            }\n+            synchronized (consumer) {\n+                consumer.subscribe(topic2Signal.keySet());\n+            }\n+        }\n+    }\n+\n+    private String topicFromSignal(SignalDesc signal) {\n+        return System.getProperty(TOPIC_PREFIX + signal.getName(), signal.getName());\n+    }\n+\n+    @Override\n+    public void serverStarted() {\n+        if (pollService != null) {\n+            long delay = Long.getLong(KAFKA_EXTENSION_PREFIX + \"poll.interval\", 1L);\n+            pollService.scheduleWithFixedDelay(this, delay, delay, TimeUnit.SECONDS);\n+        }\n+    }\n+\n+    @Override\n+    public void createContainer(String id, KieContainerInstance kieContainerInstance, Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public boolean isUpdateContainerAllowed(String id,\n+                                            KieContainerInstance kieContainerInstance,\n+                                            Map<String, Object> parameters) {\n+        return false;\n+    }\n+\n+    @Override\n+    public void prepareContainerUpdate(String id,\n+                                       KieContainerInstance kieContainerInstance,\n+                                       Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public void updateContainer(String id, KieContainerInstance kieContainerInstance, Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public void disposeContainer(String id, KieContainerInstance kieContainerInstance, Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public List<Object> getAppComponents(SupportedTransports type) {\n+        return Collections.emptyList();\n+    }\n+\n+    @Override\n+    public <T> T getAppComponents(Class<T> serviceType) {\n+        return null;\n+    }\n+\n+    @Override\n+    public String getImplementedCapability() {\n+        return KieServerConstants.CAPABILITY_BPM_KAFKA;\n+    }\n+\n+    @Override\n+    public List<Object> getServices() {\n+        return Collections.emptyList();\n+    }\n+\n+    @Override\n+    public String getExtensionName() {\n+        return EXTENSION_NAME;\n+    }\n+\n+    @Override\n+    public Integer getStartOrder() {\n+        return 20;\n+    }\n+\n+    @Override\n+    public void run() {\n+        if (consumer != null && !topic2Signal.isEmpty()) {\n+            ConsumerRecords<String, byte[]> events;\n+            synchronized (consumer) {\n+                events = consumer.subscription().isEmpty() ? ConsumerRecords.empty() : consumer.poll(Duration.ZERO);\n+            }\n+            for (ConsumerRecord<String, byte[]> event : events) {\n+                notifyService.submit(() -> processEvent(event));\n+            }\n+        }\n+    }\n+\n+    private void processEvent(ConsumerRecord<String, byte[]> event) {\n+        SignalInfo signalInfo = topic2Signal.get(event.topic());\n+        if (signalInfo != null) {\n+            try {\n+                String type = signalInfo.getSignalDesc().getName();\n+                if (signalInfo.getSignalDesc().getSignalType() == SignalType.MESSAGE) {\n+                    type = \"Message-\" + type;\n+                }\n+                processService.signalEvent(signalInfo.getDeploymentId(), type, CloudEvent.read(event.value(),\n+                        getDataClass(signalInfo.getSignalDesc())).getData());\n+            } catch (IOException | ParseException e) {\n+                logger.error(\"Error deserializing event\", e);\n+            }\n+        }\n+    }\n+\n+    private Class<?> getDataClass(SignalDesc signalDesc) {", "originalCommit": "02a8f2440ed9ecc0abc0702a1a04c97f91f348f9", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "13c42b110a2fa2f9b6077c14c2094fea8dcc20b2", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\nindex 2911ced89..230145dbf 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n", "chunk": "@@ -262,34 +313,58 @@ public class KafkaServerExtension implements KieServerExtension, DeploymentEvent\n \n     @Override\n     public void run() {\n-        if (consumer != null && !topic2Signal.isEmpty()) {\n-            ConsumerRecords<String, byte[]> events;\n-            synchronized (consumer) {\n-                events = consumer.subscription().isEmpty() ? ConsumerRecords.empty() : consumer.poll(Duration.ZERO);\n-            }\n-            for (ConsumerRecord<String, byte[]> event : events) {\n-                notifyService.submit(() -> processEvent(event));\n+        changeRegistrationLock.lock();\n+        try {\n+            if (consumer != null && (!topic2Message.isEmpty() || !topic2Signal.isEmpty())) {\n+                ConsumerRecords<String, byte[]> events = consumer.subscription().isEmpty() ? ConsumerRecords.empty()\n+                        : consumer.poll(Duration.ZERO);\n+                for (ConsumerRecord<String, byte[]> event : events) {\n+                    notifyService.submit(() -> processEvent(event));\n+                }\n             }\n+        } finally {\n+            changeRegistrationLock.unlock();\n         }\n     }\n \n+    @FunctionalInterface\n+    private static interface Signaller {\n+\n+        void signalEvent(String deploymentId, String signalName, Object data);\n+    }\n+\n     private void processEvent(ConsumerRecord<String, byte[]> event) {\n-        SignalInfo signalInfo = topic2Signal.get(event.topic());\n+        changeRegistrationLock.lock();\n+        try {\n+            processEvent(topic2Signal, event, (deployment, signalName, data) -> processService.signalEvent(deployment,\n+                    signalName, data));\n+            processEvent(topic2Message, event, (deployment, signalName, data) -> processService.signalEvent(deployment,\n+                    \"Message-\" + signalName, data));\n+        } finally {\n+            changeRegistrationLock.unlock();\n+        }\n+    }\n+\n+    private <T extends SignalDescBase> void processEvent(Map<String, Map<T, Collection<String>>> topic2SignalBase,\n+                                                         ConsumerRecord<String, byte[]> event,\n+                                                         Signaller signaller) {\n+        Map<T, Collection<String>> signalInfo = topic2SignalBase.get(event.topic());\n         if (signalInfo != null) {\n-            try {\n-                String type = signalInfo.getSignalDesc().getName();\n-                if (signalInfo.getSignalDesc().getSignalType() == SignalType.MESSAGE) {\n-                    type = \"Message-\" + type;\n+            for (Map.Entry<T, Collection<String>> entry : signalInfo.entrySet())\n+                try {\n+                    String signalName = entry.getKey().getName();\n+                    CloudEvent<?> cloudEvent = CloudEvent.read(event.value(),\n+                            getDataClass(entry.getKey()));\n+                    for (String deploymentId : entry.getValue()) {\n+                        signaller.signalEvent(deploymentId, signalName, cloudEvent.getData());\n+                    }\n+                } catch (IOException | ParseException e) {\n+                    logger.error(\"Error deserializing event\", e);\n                 }\n-                processService.signalEvent(signalInfo.getDeploymentId(), type, CloudEvent.read(event.value(),\n-                        getDataClass(signalInfo.getSignalDesc())).getData());\n-            } catch (IOException | ParseException e) {\n-                logger.error(\"Error deserializing event\", e);\n-            }\n         }\n     }\n \n-    private Class<?> getDataClass(SignalDesc signalDesc) {\n+    private <T extends SignalDescBase> Class<?> getDataClass(T signalDesc) {\n         Class<?> dataClazz = Object.class;\n         if (signalDesc.getStructureRef() != null) {\n             try {\n", "next_change": {"commit": "89ec48820033dc591dbdd8172b8ed967bee3bb4e", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\nindex 230145dbf..2b635b5b9 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n", "chunk": "@@ -353,30 +385,34 @@ public class KafkaServerExtension implements KieServerExtension, DeploymentEvent\n             for (Map.Entry<T, Collection<String>> entry : signalInfo.entrySet())\n                 try {\n                     String signalName = entry.getKey().getName();\n-                    CloudEvent<?> cloudEvent = CloudEvent.read(event.value(),\n-                            getDataClass(entry.getKey()));\n                     for (String deploymentId : entry.getValue()) {\n+                        CloudEvent<?> cloudEvent = CloudEvent.read(event.value(), getDataClass(deploymentId, entry\n+                                .getKey()));\n+                        logger.debug(\"Sending event with name {} to deployment {} with data {}\", signalName,\n+                                deploymentId, cloudEvent.getData());\n                         signaller.signalEvent(deploymentId, signalName, cloudEvent.getData());\n                     }\n-                } catch (IOException | ParseException e) {\n+                } catch (IOException | ParseException | ClassNotFoundException e) {\n                     logger.error(\"Error deserializing event\", e);\n                 }\n         }\n     }\n \n-    private <T extends SignalDescBase> Class<?> getDataClass(T signalDesc) {\n-        Class<?> dataClazz = Object.class;\n-        if (signalDesc.getStructureRef() != null) {\n-            try {\n-                String className = signalDesc.getStructureRef();\n-                if (!className.contains(\".\")) {\n-                    className = \"java.lang.\" + className;\n-                }\n-                dataClazz = Class.forName(className);\n-            } catch (ClassNotFoundException ex) {\n-                logger.error(\"Invalid class in structure ref\", ex);\n+    private <T extends SignalDescBase> Class<?> getDataClass(String deploymentId,\n+                                                             T signalDesc) throws ClassNotFoundException {\n+        Optional<Class<?>> dataClazz = Optional.empty();\n+        String className = signalDesc.getStructureRef();\n+        if (className != null) {\n+            Collection<Class<?>> deployedClasses = classes.get(deploymentId);\n+            if (deployedClasses != null) {\n+                dataClazz = deployedClasses.stream().filter(c -> c.getCanonicalName().equals(className) || c\n+                        .getSimpleName().equals(className) || c.getTypeName().equals(className)).findAny();\n+            }\n+            if (!dataClazz.isPresent()) {\n+                logger.debug(\"Class {} is not find in deploymemt {}, trying from classloader\", className, deploymentId);\n+                dataClazz = Optional.of(Class.forName(className.contains(\".\") ? className : \"java.lang.\" + className));\n             }\n         }\n-        return dataClazz;\n+        return dataClazz.orElse(Object.class);\n     }\n }\n", "next_change": {"commit": "4b1cf7a3a0f88b8ed7f718439cec78f7b377aabf", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\nindex 2b635b5b9..02002da6f 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n", "chunk": "@@ -409,7 +431,8 @@ public class KafkaServerExtension implements KieServerExtension, DeploymentEvent\n                         .getSimpleName().equals(className) || c.getTypeName().equals(className)).findAny();\n             }\n             if (!dataClazz.isPresent()) {\n-                logger.debug(\"Class {} is not find in deploymemt {}, trying from classloader\", className, deploymentId);\n+                logger.debug(\"Class {} has not been found in deployment {}, trying from classloader\", className,\n+                        deploymentId);\n                 dataClazz = Optional.of(Class.forName(className.contains(\".\") ? className : \"java.lang.\" + className));\n             }\n         }\n", "next_change": {"commit": "9cbed4f8d3f2fbe44ae127c8c27c2dd0a917abaa", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\nindex 02002da6f..8974468be 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n", "chunk": "@@ -438,4 +436,9 @@ public class KafkaServerExtension implements KieServerExtension, DeploymentEvent\n         }\n         return dataClazz.orElse(Object.class);\n     }\n+\n+    @Override\n+    public String toString() {\n+        return EXTENSION_NAME + \" KIE Server extension\";\n+    }\n }\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTkyNjA0Nw==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515926047", "body": "If you are setting by default this extension as true\r\nhttps://github.com/kiegroup/droolsjbpm-integration/pull/2288/files#diff-821631efbb543afdf97147bcc31174b3fa3f48fc3b97159a0536a484468d0c4cR82\r\n(disable false)\r\n\r\nthis is not necessaraly true as this can be active without any kafka server in the environment. Have you checked ?", "bodyText": "If you are setting by default this extension as true\nhttps://github.com/kiegroup/droolsjbpm-integration/pull/2288/files#diff-821631efbb543afdf97147bcc31174b3fa3f48fc3b97159a0536a484468d0c4cR82\n(disable false)\nthis is not necessaraly true as this can be active without any kafka server in the environment. Have you checked ?", "bodyHTML": "<p dir=\"auto\">If you are setting by default this extension as true<br>\n<a href=\"https://github.com/kiegroup/droolsjbpm-integration/pull/2288/files#diff-821631efbb543afdf97147bcc31174b3fa3f48fc3b97159a0536a484468d0c4cR82\">https://github.com/kiegroup/droolsjbpm-integration/pull/2288/files#diff-821631efbb543afdf97147bcc31174b3fa3f48fc3b97159a0536a484468d0c4cR82</a><br>\n(disable false)</p>\n<p dir=\"auto\">this is not necessaraly true as this can be active without any kafka server in the environment. Have you checked ?</p>", "author": "elguardian", "createdAt": "2020-11-02T12:02:45Z", "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java", "diffHunk": "@@ -0,0 +1,307 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+*/\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.time.Duration;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.function.BiConsumer;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.serialization.ByteArrayDeserializer;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentEventListener;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedAsset;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.jbpm.services.api.model.SignalDesc;\n+import org.jbpm.services.api.model.SignalType;\n+import org.kie.server.api.KieServerConstants;\n+import org.kie.server.services.api.KieContainerInstance;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.api.SupportedTransports;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.kie.server.services.jbpm.JbpmKieServerExtension;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KafkaServerExtension implements KieServerExtension, DeploymentEventListener, Runnable {\n+\n+    public static final String EXTENSION_NAME = \"Kafka\";\n+    static final String KAFKA_EXTENSION_PREFIX = \"org.kie.server.jbpm-kafka.ext.\";\n+    static final String TOPIC_PREFIX = KAFKA_EXTENSION_PREFIX + \"topics.\";\n+    private static final Logger logger = LoggerFactory.getLogger(KafkaServerExtension.class);\n+\n+    private AtomicBoolean initialized = new AtomicBoolean();\n+    private Consumer<String, byte[]> consumer;\n+    private ListenerSupport deploymentService;\n+    private ProcessService processService;\n+    private ScheduledExecutorService pollService;\n+    private ExecutorService notifyService;\n+\n+    private Map<String, SignalInfo> topic2Signal = new ConcurrentHashMap<>();\n+\n+    @Override\n+    public boolean isInitialized() {\n+        return initialized.get();\n+    }\n+\n+    @Override\n+    public boolean isActive() {\n+        return !Boolean.getBoolean(KieServerConstants.KIE_KAFKA_SERVER_EXT_DISABLED);\n+    }\n+\n+    @Override\n+    public void init(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (initialized.getAndSet(true)) {\n+            return;\n+        }\n+        pollService = Executors.newSingleThreadScheduledExecutor();\n+        notifyService = Executors.newCachedThreadPool();\n+        consumer = getKafkaConsumer();\n+        KieServerExtension jbpmExt = registry.getServerExtension(JbpmKieServerExtension.EXTENSION_NAME);\n+        if (jbpmExt == null) {\n+            throw new IllegalStateException(\"Cannot find extension \" + JbpmKieServerExtension.EXTENSION_NAME);\n+        }\n+\n+        for (Object service : jbpmExt.getServices()) {\n+            if (deploymentService == null && DeploymentService.class.isAssignableFrom(service.getClass())) {\n+                deploymentService = (ListenerSupport) service;\n+            } else if (processService == null && ProcessService.class.isAssignableFrom(service.getClass())) {\n+                processService = (ProcessService) service;\n+            }\n+            if (deploymentService != null && processService != null) {\n+                break;\n+            }\n+        }\n+        if (deploymentService == null) {\n+            throw new IllegalStateException(\"Cannot find deployment service\");\n+        }\n+        if (processService == null) {\n+            throw new IllegalStateException(\"Cannot find process service\");\n+        }\n+        deploymentService.addListener(this);\n+    }\n+\n+    @Override\n+    public void destroy(KieServerImpl kieServer, KieServerRegistry registry) {\n+        pollService.shutdownNow();\n+        pollService = null;\n+        notifyService.shutdownNow();\n+        notifyService = null;\n+        if (deploymentService != null) {\n+            deploymentService.removeListener(this);\n+            deploymentService = null;\n+        }\n+        if (consumer != null) {\n+            consumer.close();\n+            consumer = null;\n+        }\n+        initialized.set(false);\n+    }\n+\n+    protected Consumer<String, byte[]> getKafkaConsumer() {\n+        Map<String, Object> props = new HashMap<>();\n+        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, System.getProperty(\n+                KAFKA_EXTENSION_PREFIX + \"boopstrap.servers\", \"localhost:9092\"));", "originalCommit": "02a8f2440ed9ecc0abc0702a1a04c97f91f348f9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjY2NTk3Mg==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r516665972", "bodyText": "do we really need to check that? The kafka broker might be down when we start the server. I think this refers as if we want this extension to be active or not, regardless the status of the kafka broker", "author": "fjtirado", "createdAt": "2020-11-03T13:30:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTkyNjA0Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc3NTAxMw==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r516775013", "bodyText": "Problem was that kie server wont start when extension is enabled and kafka broker down. Consumer is now lazily initialized to preven that. Deployment with signals/messages will fail if attempted when kafka broker is down (so user might retry)", "author": "fjtirado", "createdAt": "2020-11-03T15:57:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTkyNjA0Nw=="}], "type": "inlineReview", "revised_code": {"commit": "13c42b110a2fa2f9b6077c14c2094fea8dcc20b2", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\nindex 2911ced89..230145dbf 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n", "chunk": "@@ -124,9 +133,17 @@ public class KafkaServerExtension implements KieServerExtension, DeploymentEvent\n             deploymentService.removeListener(this);\n             deploymentService = null;\n         }\n-        if (consumer != null) {\n-            consumer.close();\n-            consumer = null;\n+        changeRegistrationLock.lock();\n+        try {\n+            if (consumer != null) {\n+                consumer.close();\n+                consumer = null;\n+            }\n+            topic2Signal.clear();\n+            topic2Message.clear();\n+\n+        } finally {\n+            changeRegistrationLock.unlock();\n         }\n         initialized.set(false);\n     }\n", "next_change": {"commit": "1ab6958fe0bfbaf2245278de193e40219f168da9", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\nindex 230145dbf..5ee3548ac 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n", "chunk": "@@ -125,26 +127,38 @@ public class KafkaServerExtension implements KieServerExtension, DeploymentEvent\n \n     @Override\n     public void destroy(KieServerImpl kieServer, KieServerRegistry registry) {\n-        pollService.shutdownNow();\n-        pollService = null;\n-        notifyService.shutdownNow();\n-        notifyService = null;\n+\n+        if (notifyService != null) {\n+            notifyService.shutdownNow();\n+            notifyService = null;\n+        }\n         if (deploymentService != null) {\n             deploymentService.removeListener(this);\n             deploymentService = null;\n         }\n+\n         changeRegistrationLock.lock();\n         try {\n-            if (consumer != null) {\n-                consumer.close();\n-                consumer = null;\n-            }\n             topic2Signal.clear();\n             topic2Message.clear();\n \n         } finally {\n             changeRegistrationLock.unlock();\n         }\n+\n+        consumerLock.lock();\n+        try {\n+            if (consumer != null) {\n+                if (pollService != null) {\n+                    pollService.shutdownNow();\n+                    pollService = null;\n+                }\n+                consumer.close();\n+                consumer = null;\n+            }\n+        } finally {\n+            consumerLock.unlock();\n+        }\n         initialized.set(false);\n     }\n \n", "next_change": {"commit": "89ec48820033dc591dbdd8172b8ed967bee3bb4e", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\nindex 5ee3548ac..2b635b5b9 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n", "chunk": "@@ -159,6 +162,7 @@ public class KafkaServerExtension implements KieServerExtension, DeploymentEvent\n         } finally {\n             consumerLock.unlock();\n         }\n+        classes.clear();\n         initialized.set(false);\n     }\n \n", "next_change": {"commit": "4b1cf7a3a0f88b8ed7f718439cec78f7b377aabf", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\nindex 2b635b5b9..02002da6f 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n", "chunk": "@@ -162,8 +156,11 @@ public class KafkaServerExtension implements KieServerExtension, DeploymentEvent\n         } finally {\n             consumerLock.unlock();\n         }\n-        classes.clear();\n         initialized.set(false);\n+        notifyService = null;\n+        processService = null;\n+        deploymentService = null;\n+        logger.info(\"Extension \" + EXTENSION_NAME + \" destroyed\");\n     }\n \n     protected Consumer<String, byte[]> getKafkaConsumer() {\n", "next_change": {"commit": "9cbed4f8d3f2fbe44ae127c8c27c2dd0a917abaa", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\nindex 02002da6f..8974468be 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n", "chunk": "@@ -160,7 +159,6 @@ public class KafkaServerExtension implements KieServerExtension, DeploymentEvent\n         notifyService = null;\n         processService = null;\n         deploymentService = null;\n-        logger.info(\"Extension \" + EXTENSION_NAME + \" destroyed\");\n     }\n \n     protected Consumer<String, byte[]> getKafkaConsumer() {\n", "next_change": {"commit": "1a508f60083129fe949114e3c0b19f457c8587f9", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\nindex 8974468be..97185d39a 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n", "chunk": "@@ -142,23 +138,20 @@ public class KafkaServerExtension implements KieServerExtension, DeploymentEvent\n         } finally {\n             changeRegistrationLock.unlock();\n         }\n-        consumerLock.lock();\n-        try {\n-            if (consumer != null) {\n-                if (pollService != null) {\n-                    pollService.interrupt();\n-                    pollService = null;\n-                }\n+        if (consumerReady.compareAndSet(true, false)) {\n+            consumer.wakeup();\n+            consumerLock.lock();\n+            try {\n+                notifyService.shutdownNow();\n                 consumer.close();\n-                consumer = null;\n+                notifyService = null;\n+            } finally {\n+                consumerLock.unlock();\n             }\n-        } finally {\n-            consumerLock.unlock();\n         }\n-        initialized.set(false);\n-        notifyService = null;\n         processService = null;\n         deploymentService = null;\n+        initialized.set(false);\n     }\n \n     protected Consumer<String, byte[]> getKafkaConsumer() {\n", "next_change": {"commit": "a3f08ded394724d463262a6e934d9be600fab800", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\nindex 97185d39a..3132f474a 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n", "chunk": "@@ -127,28 +130,31 @@ public class KafkaServerExtension implements KieServerExtension, DeploymentEvent\n \n     @Override\n     public void destroy(KieServerImpl kieServer, KieServerRegistry registry) {\n-        classes.clear();\n         if (deploymentService != null) {\n             deploymentService.removeListener(this);\n         }\n-        changeRegistrationLock.lock();\n-        try {\n-            topic2Signal.clear();\n-            topic2Message.clear();\n-        } finally {\n-            changeRegistrationLock.unlock();\n-        }\n         if (consumerReady.compareAndSet(true, false)) {\n+            notifyService.shutdownNow();\n             consumer.wakeup();\n             consumerLock.lock();\n             try {\n-                notifyService.shutdownNow();\n                 consumer.close();\n-                notifyService = null;\n             } finally {\n                 consumerLock.unlock();\n             }\n+            notifyService = null;\n+            consumer = null;\n         }\n+\n+        changeRegistrationLock.lock();\n+        try {\n+            topic2Signal.clear();\n+            topic2Message.clear();\n+            isSubscribedCond.signal();\n+        } finally {\n+            changeRegistrationLock.unlock();\n+        }\n+        classes.clear();\n         processService = null;\n         deploymentService = null;\n         initialized.set(false);\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTkyOTExNA==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515929114", "body": "this is far to generic and it is not documented in the BAPL. \r\nsignal names within process does not necessarily mean the same among process I would argue this is a good idea in the general case. \r\nWhile I can see the benefit (and indeed you can leave it like this). You would need to search first for more particular signal definition\r\n\r\nThe most particular case (this should be mandatory at least)\r\nTOPIC_PREFIX.<deploymentId>.<processId>.signalName=signalName\r\n\r\nmore general (by deployment)\r\nTOPIC_PREFIX.<deploymentId>.signalName = signalName\r\n\r\nor your case (by entire server -> this is ok too)\r\nTOPIC_PREFIX.signalName = signalName\r\n\r\nAlso requires to say that some signal is bounded. For instance is there is a signal registed by a process there is need to set an info kjar - process id - signal has been bounded to topic (whatever topic is mapped) through system property whaever.\r\n\r\nThe spec how to define the mapping should be part of the documentation of your BAPL as well.\r\n\r\nThis would add a lot of info regarding the mapping and allow diagnostics.\r\n\r\n", "bodyText": "this is far to generic and it is not documented in the BAPL.\nsignal names within process does not necessarily mean the same among process I would argue this is a good idea in the general case.\nWhile I can see the benefit (and indeed you can leave it like this). You would need to search first for more particular signal definition\nThe most particular case (this should be mandatory at least)\nTOPIC_PREFIX...signalName=signalName\nmore general (by deployment)\nTOPIC_PREFIX..signalName = signalName\nor your case (by entire server -> this is ok too)\nTOPIC_PREFIX.signalName = signalName\nAlso requires to say that some signal is bounded. For instance is there is a signal registed by a process there is need to set an info kjar - process id - signal has been bounded to topic (whatever topic is mapped) through system property whaever.\nThe spec how to define the mapping should be part of the documentation of your BAPL as well.\nThis would add a lot of info regarding the mapping and allow diagnostics.", "bodyHTML": "<p dir=\"auto\">this is far to generic and it is not documented in the BAPL.<br>\nsignal names within process does not necessarily mean the same among process I would argue this is a good idea in the general case.<br>\nWhile I can see the benefit (and indeed you can leave it like this). You would need to search first for more particular signal definition</p>\n<p dir=\"auto\">The most particular case (this should be mandatory at least)<br>\nTOPIC_PREFIX...signalName=signalName</p>\n<p dir=\"auto\">more general (by deployment)<br>\nTOPIC_PREFIX..signalName = signalName</p>\n<p dir=\"auto\">or your case (by entire server -&gt; this is ok too)<br>\nTOPIC_PREFIX.signalName = signalName</p>\n<p dir=\"auto\">Also requires to say that some signal is bounded. For instance is there is a signal registed by a process there is need to set an info kjar - process id - signal has been bounded to topic (whatever topic is mapped) through system property whaever.</p>\n<p dir=\"auto\">The spec how to define the mapping should be part of the documentation of your BAPL as well.</p>\n<p dir=\"auto\">This would add a lot of info regarding the mapping and allow diagnostics.</p>", "author": "elguardian", "createdAt": "2020-11-02T12:09:27Z", "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java", "diffHunk": "@@ -0,0 +1,307 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+*/\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.time.Duration;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.function.BiConsumer;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.serialization.ByteArrayDeserializer;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentEventListener;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedAsset;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.jbpm.services.api.model.SignalDesc;\n+import org.jbpm.services.api.model.SignalType;\n+import org.kie.server.api.KieServerConstants;\n+import org.kie.server.services.api.KieContainerInstance;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.api.SupportedTransports;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.kie.server.services.jbpm.JbpmKieServerExtension;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KafkaServerExtension implements KieServerExtension, DeploymentEventListener, Runnable {\n+\n+    public static final String EXTENSION_NAME = \"Kafka\";\n+    static final String KAFKA_EXTENSION_PREFIX = \"org.kie.server.jbpm-kafka.ext.\";\n+    static final String TOPIC_PREFIX = KAFKA_EXTENSION_PREFIX + \"topics.\";\n+    private static final Logger logger = LoggerFactory.getLogger(KafkaServerExtension.class);\n+\n+    private AtomicBoolean initialized = new AtomicBoolean();\n+    private Consumer<String, byte[]> consumer;\n+    private ListenerSupport deploymentService;\n+    private ProcessService processService;\n+    private ScheduledExecutorService pollService;\n+    private ExecutorService notifyService;\n+\n+    private Map<String, SignalInfo> topic2Signal = new ConcurrentHashMap<>();\n+\n+    @Override\n+    public boolean isInitialized() {\n+        return initialized.get();\n+    }\n+\n+    @Override\n+    public boolean isActive() {\n+        return !Boolean.getBoolean(KieServerConstants.KIE_KAFKA_SERVER_EXT_DISABLED);\n+    }\n+\n+    @Override\n+    public void init(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (initialized.getAndSet(true)) {\n+            return;\n+        }\n+        pollService = Executors.newSingleThreadScheduledExecutor();\n+        notifyService = Executors.newCachedThreadPool();\n+        consumer = getKafkaConsumer();\n+        KieServerExtension jbpmExt = registry.getServerExtension(JbpmKieServerExtension.EXTENSION_NAME);\n+        if (jbpmExt == null) {\n+            throw new IllegalStateException(\"Cannot find extension \" + JbpmKieServerExtension.EXTENSION_NAME);\n+        }\n+\n+        for (Object service : jbpmExt.getServices()) {\n+            if (deploymentService == null && DeploymentService.class.isAssignableFrom(service.getClass())) {\n+                deploymentService = (ListenerSupport) service;\n+            } else if (processService == null && ProcessService.class.isAssignableFrom(service.getClass())) {\n+                processService = (ProcessService) service;\n+            }\n+            if (deploymentService != null && processService != null) {\n+                break;\n+            }\n+        }\n+        if (deploymentService == null) {\n+            throw new IllegalStateException(\"Cannot find deployment service\");\n+        }\n+        if (processService == null) {\n+            throw new IllegalStateException(\"Cannot find process service\");\n+        }\n+        deploymentService.addListener(this);\n+    }\n+\n+    @Override\n+    public void destroy(KieServerImpl kieServer, KieServerRegistry registry) {\n+        pollService.shutdownNow();\n+        pollService = null;\n+        notifyService.shutdownNow();\n+        notifyService = null;\n+        if (deploymentService != null) {\n+            deploymentService.removeListener(this);\n+            deploymentService = null;\n+        }\n+        if (consumer != null) {\n+            consumer.close();\n+            consumer = null;\n+        }\n+        initialized.set(false);\n+    }\n+\n+    protected Consumer<String, byte[]> getKafkaConsumer() {\n+        Map<String, Object> props = new HashMap<>();\n+        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, System.getProperty(\n+                KAFKA_EXTENSION_PREFIX + \"boopstrap.servers\", \"localhost:9092\"));\n+        // read only committed events\n+        props.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, IsolationLevel.READ_COMMITTED.toString().toLowerCase());\n+        // do not automatically create topics by default\n+        props.put(ConsumerConfig.ALLOW_AUTO_CREATE_TOPICS_CONFIG, Boolean.getBoolean(\n+                KAFKA_EXTENSION_PREFIX + \"auto.create.topics\"));\n+        props.put(ConsumerConfig.GROUP_ID_CONFIG, System.getProperty(KAFKA_EXTENSION_PREFIX + \"group.id\",\n+                \"jbpm-consumer\"));\n+        return new KafkaConsumer<>(props, new StringDeserializer(), new ByteArrayDeserializer());\n+    }\n+\n+    @Override\n+    public void onDeploy(DeploymentEvent event) {\n+        updateRegistration(event, this::updateTopics);\n+    }\n+\n+    @Override\n+    public void onUnDeploy(DeploymentEvent event) {\n+        updateRegistration(event, this::removeTopics);\n+    }\n+\n+    @Override\n+    public void onActivate(DeploymentEvent event) {\n+        updateRegistration(event, this::updateTopics);\n+    }\n+\n+    @Override\n+    public void onDeactivate(DeploymentEvent event) {\n+        updateRegistration(event, this::removeTopics);\n+    }\n+\n+    private void updateTopics(String deploymentId, ProcessDefinition processDefinition) {\n+        for (SignalDesc signal : processDefinition.getSignalsMetadata()) {\n+            topic2Signal.computeIfAbsent(topicFromSignal(signal), t -> new SignalInfo(deploymentId,\n+                    signal));\n+        }\n+    }\n+\n+    private void removeTopics(String deploymentId, ProcessDefinition processDefinition) {\n+        for (SignalDesc signal : processDefinition.getSignalsMetadata()) {\n+            topic2Signal.remove(topicFromSignal(signal));\n+        }\n+    }\n+\n+    private void updateRegistration(DeploymentEvent event, BiConsumer<String, ProcessDefinition> updater) {\n+        if (consumer != null) {\n+            for (DeployedAsset asset : event.getDeployedUnit().getDeployedAssets()) {\n+                updater.accept(event.getDeploymentId(), (ProcessDefinition) asset);\n+            }\n+            synchronized (consumer) {\n+                consumer.subscribe(topic2Signal.keySet());\n+            }\n+        }\n+    }\n+\n+    private String topicFromSignal(SignalDesc signal) {\n+        return System.getProperty(TOPIC_PREFIX + signal.getName(), signal.getName());", "originalCommit": "02a8f2440ed9ecc0abc0702a1a04c97f91f348f9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjg3NTY2Ng==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r516875666", "bodyText": "Leaving at it is for now. Opened https://issues.redhat.com/browse/JBPM-9455 to allow fine-grainer approach.", "author": "fjtirado", "createdAt": "2020-11-03T18:33:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTkyOTExNA=="}], "type": "inlineReview", "revised_code": {"commit": "13c42b110a2fa2f9b6077c14c2094fea8dcc20b2", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\nindex 2911ced89..230145dbf 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n", "chunk": "@@ -166,30 +183,64 @@ public class KafkaServerExtension implements KieServerExtension, DeploymentEvent\n     }\n \n     private void updateTopics(String deploymentId, ProcessDefinition processDefinition) {\n-        for (SignalDesc signal : processDefinition.getSignalsMetadata()) {\n-            topic2Signal.computeIfAbsent(topicFromSignal(signal), t -> new SignalInfo(deploymentId,\n-                    signal));\n-        }\n+        updateTopics(topic2Signal, deploymentId, processDefinition.getSignalsDesc());\n+        updateTopics(topic2Message, deploymentId, processDefinition.getMessagesDesc());\n     }\n \n     private void removeTopics(String deploymentId, ProcessDefinition processDefinition) {\n-        for (SignalDesc signal : processDefinition.getSignalsMetadata()) {\n-            topic2Signal.remove(topicFromSignal(signal));\n+        removeTopics(topic2Signal, deploymentId, processDefinition.getSignalsDesc());\n+        removeTopics(topic2Message, deploymentId, processDefinition.getMessagesDesc());\n+    }\n+\n+    private <T extends SignalDescBase> void updateTopics(Map<String, Map<T, Collection<String>>> topic2SignalBase,\n+                                                         String deploymentId,\n+                                                         Collection<T> signals) {\n+        for (T signal : signals) {\n+            topic2SignalBase.computeIfAbsent(topicFromSignal(signal), k -> new HashMap<>()).computeIfAbsent(\n+                    signal, k -> new ArrayList<>()).add(deploymentId);\n         }\n     }\n \n-    private void updateRegistration(DeploymentEvent event, BiConsumer<String, ProcessDefinition> updater) {\n-        if (consumer != null) {\n-            for (DeployedAsset asset : event.getDeployedUnit().getDeployedAssets()) {\n-                updater.accept(event.getDeploymentId(), (ProcessDefinition) asset);\n+    private <T extends SignalDescBase> void removeTopics(Map<String, Map<T, Collection<String>>> topic2SignalBase,\n+                                                         String deploymentId,\n+                                                         Collection<T> signalsDesc) {\n+        for (T signal : signalsDesc) {\n+            String topic = topicFromSignal(signal);\n+            Map<T, Collection<String>> signals = topic2SignalBase.get(topic);\n+            if (signals != null) {\n+                Collection<String> deploymentIds = signals.get(signal);\n+                if (deploymentIds != null) {\n+                    deploymentIds.remove(deploymentId);\n+                    if (deploymentIds.isEmpty()) {\n+                        signals.remove(signal);\n+                        if (signals.isEmpty()) {\n+                            topic2SignalBase.remove(topic);\n+                        }\n+                    }\n+                }\n+\n             }\n-            synchronized (consumer) {\n-                consumer.subscribe(topic2Signal.keySet());\n+        }\n+    }\n+\n+    private void updateRegistration(DeploymentEvent event, BiConsumer<String, ProcessDefinition> updater) {\n+        changeRegistrationLock.lock();\n+        try {\n+            if (consumer != null) {\n+                for (DeployedAsset asset : event.getDeployedUnit().getDeployedAssets()) {\n+                    updater.accept(event.getDeploymentId(), (ProcessDefinition) asset);\n+                }\n+                Set<String> topic2Register = new HashSet<>();\n+                topic2Register.addAll(topic2Signal.keySet());\n+                topic2Register.addAll(topic2Message.keySet());\n+                consumer.subscribe(topic2Register);\n             }\n+        } finally {\n+            changeRegistrationLock.unlock();\n         }\n     }\n \n-    private String topicFromSignal(SignalDesc signal) {\n+    private static <T extends SignalDescBase> String topicFromSignal(T signal) {\n         return System.getProperty(TOPIC_PREFIX + signal.getName(), signal.getName());\n     }\n \n", "next_change": {"commit": "1ab6958fe0bfbaf2245278de193e40219f168da9", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\nindex 230145dbf..5ee3548ac 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n", "chunk": "@@ -224,20 +238,29 @@ public class KafkaServerExtension implements KieServerExtension, DeploymentEvent\n     }\n \n     private void updateRegistration(DeploymentEvent event, BiConsumer<String, ProcessDefinition> updater) {\n+        Set<String> topic2Register = new HashSet<>();\n         changeRegistrationLock.lock();\n         try {\n-            if (consumer != null) {\n-                for (DeployedAsset asset : event.getDeployedUnit().getDeployedAssets()) {\n-                    updater.accept(event.getDeploymentId(), (ProcessDefinition) asset);\n-                }\n-                Set<String> topic2Register = new HashSet<>();\n-                topic2Register.addAll(topic2Signal.keySet());\n-                topic2Register.addAll(topic2Message.keySet());\n-                consumer.subscribe(topic2Register);\n+            for (DeployedAsset asset : event.getDeployedUnit().getDeployedAssets()) {\n+                updater.accept(event.getDeploymentId(), (ProcessDefinition) asset);\n             }\n+            topic2Register.addAll(topic2Signal.keySet());\n+            topic2Register.addAll(topic2Message.keySet());\n         } finally {\n             changeRegistrationLock.unlock();\n         }\n+        consumerLock.lock();\n+        try {\n+            if (consumer == null) {\n+                consumer = getKafkaConsumer();\n+                long delay = Long.getLong(KAFKA_EXTENSION_PREFIX + \"poll.interval\", 1L);\n+                pollService = Executors.newSingleThreadScheduledExecutor();\n+                pollService.scheduleWithFixedDelay(this, 0, delay, TimeUnit.SECONDS);\n+            }\n+            consumer.subscribe(topic2Register);\n+        } finally {\n+            consumerLock.unlock();\n+        }\n     }\n \n     private static <T extends SignalDescBase> String topicFromSignal(T signal) {\n", "next_change": {"commit": "4b1cf7a3a0f88b8ed7f718439cec78f7b377aabf", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\nindex 5ee3548ac..02002da6f 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n", "chunk": "@@ -252,15 +254,16 @@ public class KafkaServerExtension implements KieServerExtension, DeploymentEvent\n         consumerLock.lock();\n         try {\n             if (consumer == null) {\n+                logger.trace(\"Creating kafka consumer\");\n                 consumer = getKafkaConsumer();\n-                long delay = Long.getLong(KAFKA_EXTENSION_PREFIX + \"poll.interval\", 1L);\n-                pollService = Executors.newSingleThreadScheduledExecutor();\n-                pollService.scheduleWithFixedDelay(this, 0, delay, TimeUnit.SECONDS);\n+                pollService = new Thread(this);\n+                pollService.start();\n             }\n             consumer.subscribe(topic2Register);\n         } finally {\n             consumerLock.unlock();\n         }\n+        logger.debug(\"Updating kafka subscription list to these topics {}\", topic2Register);\n     }\n \n     private static <T extends SignalDescBase> String topicFromSignal(T signal) {\n", "next_change": {"commit": "a1cb9ea4402f589c17d2793fb7e8e1c24a53f4bb", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\nindex 02002da6f..739637a79 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n", "chunk": "@@ -272,7 +270,7 @@ public class KafkaServerExtension implements KieServerExtension, DeploymentEvent\n \n     @Override\n     public void serverStarted() {\n-        // todo will use lazy initialization for consumer\n+        // will use lazy initialization for consumer\n     }\n \n     @Override\n", "next_change": null}]}}]}}, {"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\nindex 230145dbf..5ee3548ac 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n", "chunk": "@@ -246,10 +269,7 @@ public class KafkaServerExtension implements KieServerExtension, DeploymentEvent\n \n     @Override\n     public void serverStarted() {\n-        if (pollService != null) {\n-            long delay = Long.getLong(KAFKA_EXTENSION_PREFIX + \"poll.interval\", 1L);\n-            pollService.scheduleWithFixedDelay(this, delay, delay, TimeUnit.SECONDS);\n-        }\n+        // todo will use lazy initialization for consumer\n     }\n \n     @Override\n", "next_change": {"commit": "a1cb9ea4402f589c17d2793fb7e8e1c24a53f4bb", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\nindex 5ee3548ac..739637a79 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n", "chunk": "@@ -269,7 +270,7 @@ public class KafkaServerExtension implements KieServerExtension, DeploymentEvent\n \n     @Override\n     public void serverStarted() {\n-        // todo will use lazy initialization for consumer\n+        // will use lazy initialization for consumer\n     }\n \n     @Override\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTkyOTc5OA==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515929798", "body": "debug levels regarding what signal you received and where are you sending it.\r\ntrace would be the message content.", "bodyText": "debug levels regarding what signal you received and where are you sending it.\ntrace would be the message content.", "bodyHTML": "<p dir=\"auto\">debug levels regarding what signal you received and where are you sending it.<br>\ntrace would be the message content.</p>", "author": "elguardian", "createdAt": "2020-11-02T12:10:55Z", "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java", "diffHunk": "@@ -0,0 +1,307 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+*/\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.time.Duration;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.function.BiConsumer;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.serialization.ByteArrayDeserializer;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentEventListener;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedAsset;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.jbpm.services.api.model.SignalDesc;\n+import org.jbpm.services.api.model.SignalType;\n+import org.kie.server.api.KieServerConstants;\n+import org.kie.server.services.api.KieContainerInstance;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.api.SupportedTransports;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.kie.server.services.jbpm.JbpmKieServerExtension;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KafkaServerExtension implements KieServerExtension, DeploymentEventListener, Runnable {\n+\n+    public static final String EXTENSION_NAME = \"Kafka\";\n+    static final String KAFKA_EXTENSION_PREFIX = \"org.kie.server.jbpm-kafka.ext.\";\n+    static final String TOPIC_PREFIX = KAFKA_EXTENSION_PREFIX + \"topics.\";\n+    private static final Logger logger = LoggerFactory.getLogger(KafkaServerExtension.class);\n+\n+    private AtomicBoolean initialized = new AtomicBoolean();\n+    private Consumer<String, byte[]> consumer;\n+    private ListenerSupport deploymentService;\n+    private ProcessService processService;\n+    private ScheduledExecutorService pollService;\n+    private ExecutorService notifyService;\n+\n+    private Map<String, SignalInfo> topic2Signal = new ConcurrentHashMap<>();\n+\n+    @Override\n+    public boolean isInitialized() {\n+        return initialized.get();\n+    }\n+\n+    @Override\n+    public boolean isActive() {\n+        return !Boolean.getBoolean(KieServerConstants.KIE_KAFKA_SERVER_EXT_DISABLED);\n+    }\n+\n+    @Override\n+    public void init(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (initialized.getAndSet(true)) {\n+            return;\n+        }\n+        pollService = Executors.newSingleThreadScheduledExecutor();\n+        notifyService = Executors.newCachedThreadPool();\n+        consumer = getKafkaConsumer();\n+        KieServerExtension jbpmExt = registry.getServerExtension(JbpmKieServerExtension.EXTENSION_NAME);\n+        if (jbpmExt == null) {\n+            throw new IllegalStateException(\"Cannot find extension \" + JbpmKieServerExtension.EXTENSION_NAME);\n+        }\n+\n+        for (Object service : jbpmExt.getServices()) {\n+            if (deploymentService == null && DeploymentService.class.isAssignableFrom(service.getClass())) {\n+                deploymentService = (ListenerSupport) service;\n+            } else if (processService == null && ProcessService.class.isAssignableFrom(service.getClass())) {\n+                processService = (ProcessService) service;\n+            }\n+            if (deploymentService != null && processService != null) {\n+                break;\n+            }\n+        }\n+        if (deploymentService == null) {\n+            throw new IllegalStateException(\"Cannot find deployment service\");\n+        }\n+        if (processService == null) {\n+            throw new IllegalStateException(\"Cannot find process service\");\n+        }\n+        deploymentService.addListener(this);\n+    }\n+\n+    @Override\n+    public void destroy(KieServerImpl kieServer, KieServerRegistry registry) {\n+        pollService.shutdownNow();\n+        pollService = null;\n+        notifyService.shutdownNow();\n+        notifyService = null;\n+        if (deploymentService != null) {\n+            deploymentService.removeListener(this);\n+            deploymentService = null;\n+        }\n+        if (consumer != null) {\n+            consumer.close();\n+            consumer = null;\n+        }\n+        initialized.set(false);\n+    }\n+\n+    protected Consumer<String, byte[]> getKafkaConsumer() {\n+        Map<String, Object> props = new HashMap<>();\n+        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, System.getProperty(\n+                KAFKA_EXTENSION_PREFIX + \"boopstrap.servers\", \"localhost:9092\"));\n+        // read only committed events\n+        props.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, IsolationLevel.READ_COMMITTED.toString().toLowerCase());\n+        // do not automatically create topics by default\n+        props.put(ConsumerConfig.ALLOW_AUTO_CREATE_TOPICS_CONFIG, Boolean.getBoolean(\n+                KAFKA_EXTENSION_PREFIX + \"auto.create.topics\"));\n+        props.put(ConsumerConfig.GROUP_ID_CONFIG, System.getProperty(KAFKA_EXTENSION_PREFIX + \"group.id\",\n+                \"jbpm-consumer\"));\n+        return new KafkaConsumer<>(props, new StringDeserializer(), new ByteArrayDeserializer());\n+    }\n+\n+    @Override\n+    public void onDeploy(DeploymentEvent event) {\n+        updateRegistration(event, this::updateTopics);\n+    }\n+\n+    @Override\n+    public void onUnDeploy(DeploymentEvent event) {\n+        updateRegistration(event, this::removeTopics);\n+    }\n+\n+    @Override\n+    public void onActivate(DeploymentEvent event) {\n+        updateRegistration(event, this::updateTopics);\n+    }\n+\n+    @Override\n+    public void onDeactivate(DeploymentEvent event) {\n+        updateRegistration(event, this::removeTopics);\n+    }\n+\n+    private void updateTopics(String deploymentId, ProcessDefinition processDefinition) {\n+        for (SignalDesc signal : processDefinition.getSignalsMetadata()) {\n+            topic2Signal.computeIfAbsent(topicFromSignal(signal), t -> new SignalInfo(deploymentId,\n+                    signal));\n+        }\n+    }\n+\n+    private void removeTopics(String deploymentId, ProcessDefinition processDefinition) {\n+        for (SignalDesc signal : processDefinition.getSignalsMetadata()) {\n+            topic2Signal.remove(topicFromSignal(signal));\n+        }\n+    }\n+\n+    private void updateRegistration(DeploymentEvent event, BiConsumer<String, ProcessDefinition> updater) {\n+        if (consumer != null) {\n+            for (DeployedAsset asset : event.getDeployedUnit().getDeployedAssets()) {\n+                updater.accept(event.getDeploymentId(), (ProcessDefinition) asset);\n+            }\n+            synchronized (consumer) {\n+                consumer.subscribe(topic2Signal.keySet());\n+            }\n+        }\n+    }\n+\n+    private String topicFromSignal(SignalDesc signal) {\n+        return System.getProperty(TOPIC_PREFIX + signal.getName(), signal.getName());\n+    }\n+\n+    @Override\n+    public void serverStarted() {\n+        if (pollService != null) {\n+            long delay = Long.getLong(KAFKA_EXTENSION_PREFIX + \"poll.interval\", 1L);\n+            pollService.scheduleWithFixedDelay(this, delay, delay, TimeUnit.SECONDS);\n+        }\n+    }\n+\n+    @Override\n+    public void createContainer(String id, KieContainerInstance kieContainerInstance, Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public boolean isUpdateContainerAllowed(String id,\n+                                            KieContainerInstance kieContainerInstance,\n+                                            Map<String, Object> parameters) {\n+        return false;\n+    }\n+\n+    @Override\n+    public void prepareContainerUpdate(String id,\n+                                       KieContainerInstance kieContainerInstance,\n+                                       Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public void updateContainer(String id, KieContainerInstance kieContainerInstance, Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public void disposeContainer(String id, KieContainerInstance kieContainerInstance, Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public List<Object> getAppComponents(SupportedTransports type) {\n+        return Collections.emptyList();\n+    }\n+\n+    @Override\n+    public <T> T getAppComponents(Class<T> serviceType) {\n+        return null;\n+    }\n+\n+    @Override\n+    public String getImplementedCapability() {\n+        return KieServerConstants.CAPABILITY_BPM_KAFKA;\n+    }\n+\n+    @Override\n+    public List<Object> getServices() {\n+        return Collections.emptyList();\n+    }\n+\n+    @Override\n+    public String getExtensionName() {\n+        return EXTENSION_NAME;\n+    }\n+\n+    @Override\n+    public Integer getStartOrder() {\n+        return 20;\n+    }\n+\n+    @Override\n+    public void run() {\n+        if (consumer != null && !topic2Signal.isEmpty()) {\n+            ConsumerRecords<String, byte[]> events;\n+            synchronized (consumer) {\n+                events = consumer.subscription().isEmpty() ? ConsumerRecords.empty() : consumer.poll(Duration.ZERO);\n+            }\n+            for (ConsumerRecord<String, byte[]> event : events) {\n+                notifyService.submit(() -> processEvent(event));\n+            }\n+        }\n+    }\n+\n+    private void processEvent(ConsumerRecord<String, byte[]> event) {\n+        SignalInfo signalInfo = topic2Signal.get(event.topic());\n+        if (signalInfo != null) {\n+            try {\n+                String type = signalInfo.getSignalDesc().getName();\n+                if (signalInfo.getSignalDesc().getSignalType() == SignalType.MESSAGE) {\n+                    type = \"Message-\" + type;\n+                }\n+                processService.signalEvent(signalInfo.getDeploymentId(), type, CloudEvent.read(event.value(),", "originalCommit": "02a8f2440ed9ecc0abc0702a1a04c97f91f348f9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc3NTE0Nw==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r516775147", "bodyText": "done", "author": "fjtirado", "createdAt": "2020-11-03T15:57:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTkyOTc5OA=="}], "type": "inlineReview", "revised_code": {"commit": "13c42b110a2fa2f9b6077c14c2094fea8dcc20b2", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\nindex 2911ced89..230145dbf 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n", "chunk": "@@ -262,34 +313,58 @@ public class KafkaServerExtension implements KieServerExtension, DeploymentEvent\n \n     @Override\n     public void run() {\n-        if (consumer != null && !topic2Signal.isEmpty()) {\n-            ConsumerRecords<String, byte[]> events;\n-            synchronized (consumer) {\n-                events = consumer.subscription().isEmpty() ? ConsumerRecords.empty() : consumer.poll(Duration.ZERO);\n-            }\n-            for (ConsumerRecord<String, byte[]> event : events) {\n-                notifyService.submit(() -> processEvent(event));\n+        changeRegistrationLock.lock();\n+        try {\n+            if (consumer != null && (!topic2Message.isEmpty() || !topic2Signal.isEmpty())) {\n+                ConsumerRecords<String, byte[]> events = consumer.subscription().isEmpty() ? ConsumerRecords.empty()\n+                        : consumer.poll(Duration.ZERO);\n+                for (ConsumerRecord<String, byte[]> event : events) {\n+                    notifyService.submit(() -> processEvent(event));\n+                }\n             }\n+        } finally {\n+            changeRegistrationLock.unlock();\n         }\n     }\n \n+    @FunctionalInterface\n+    private static interface Signaller {\n+\n+        void signalEvent(String deploymentId, String signalName, Object data);\n+    }\n+\n     private void processEvent(ConsumerRecord<String, byte[]> event) {\n-        SignalInfo signalInfo = topic2Signal.get(event.topic());\n+        changeRegistrationLock.lock();\n+        try {\n+            processEvent(topic2Signal, event, (deployment, signalName, data) -> processService.signalEvent(deployment,\n+                    signalName, data));\n+            processEvent(topic2Message, event, (deployment, signalName, data) -> processService.signalEvent(deployment,\n+                    \"Message-\" + signalName, data));\n+        } finally {\n+            changeRegistrationLock.unlock();\n+        }\n+    }\n+\n+    private <T extends SignalDescBase> void processEvent(Map<String, Map<T, Collection<String>>> topic2SignalBase,\n+                                                         ConsumerRecord<String, byte[]> event,\n+                                                         Signaller signaller) {\n+        Map<T, Collection<String>> signalInfo = topic2SignalBase.get(event.topic());\n         if (signalInfo != null) {\n-            try {\n-                String type = signalInfo.getSignalDesc().getName();\n-                if (signalInfo.getSignalDesc().getSignalType() == SignalType.MESSAGE) {\n-                    type = \"Message-\" + type;\n+            for (Map.Entry<T, Collection<String>> entry : signalInfo.entrySet())\n+                try {\n+                    String signalName = entry.getKey().getName();\n+                    CloudEvent<?> cloudEvent = CloudEvent.read(event.value(),\n+                            getDataClass(entry.getKey()));\n+                    for (String deploymentId : entry.getValue()) {\n+                        signaller.signalEvent(deploymentId, signalName, cloudEvent.getData());\n+                    }\n+                } catch (IOException | ParseException e) {\n+                    logger.error(\"Error deserializing event\", e);\n                 }\n-                processService.signalEvent(signalInfo.getDeploymentId(), type, CloudEvent.read(event.value(),\n-                        getDataClass(signalInfo.getSignalDesc())).getData());\n-            } catch (IOException | ParseException e) {\n-                logger.error(\"Error deserializing event\", e);\n-            }\n         }\n     }\n \n-    private Class<?> getDataClass(SignalDesc signalDesc) {\n+    private <T extends SignalDescBase> Class<?> getDataClass(T signalDesc) {\n         Class<?> dataClazz = Object.class;\n         if (signalDesc.getStructureRef() != null) {\n             try {\n", "next_change": {"commit": "89ec48820033dc591dbdd8172b8ed967bee3bb4e", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\nindex 230145dbf..2b635b5b9 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n", "chunk": "@@ -353,30 +385,34 @@ public class KafkaServerExtension implements KieServerExtension, DeploymentEvent\n             for (Map.Entry<T, Collection<String>> entry : signalInfo.entrySet())\n                 try {\n                     String signalName = entry.getKey().getName();\n-                    CloudEvent<?> cloudEvent = CloudEvent.read(event.value(),\n-                            getDataClass(entry.getKey()));\n                     for (String deploymentId : entry.getValue()) {\n+                        CloudEvent<?> cloudEvent = CloudEvent.read(event.value(), getDataClass(deploymentId, entry\n+                                .getKey()));\n+                        logger.debug(\"Sending event with name {} to deployment {} with data {}\", signalName,\n+                                deploymentId, cloudEvent.getData());\n                         signaller.signalEvent(deploymentId, signalName, cloudEvent.getData());\n                     }\n-                } catch (IOException | ParseException e) {\n+                } catch (IOException | ParseException | ClassNotFoundException e) {\n                     logger.error(\"Error deserializing event\", e);\n                 }\n         }\n     }\n \n-    private <T extends SignalDescBase> Class<?> getDataClass(T signalDesc) {\n-        Class<?> dataClazz = Object.class;\n-        if (signalDesc.getStructureRef() != null) {\n-            try {\n-                String className = signalDesc.getStructureRef();\n-                if (!className.contains(\".\")) {\n-                    className = \"java.lang.\" + className;\n-                }\n-                dataClazz = Class.forName(className);\n-            } catch (ClassNotFoundException ex) {\n-                logger.error(\"Invalid class in structure ref\", ex);\n+    private <T extends SignalDescBase> Class<?> getDataClass(String deploymentId,\n+                                                             T signalDesc) throws ClassNotFoundException {\n+        Optional<Class<?>> dataClazz = Optional.empty();\n+        String className = signalDesc.getStructureRef();\n+        if (className != null) {\n+            Collection<Class<?>> deployedClasses = classes.get(deploymentId);\n+            if (deployedClasses != null) {\n+                dataClazz = deployedClasses.stream().filter(c -> c.getCanonicalName().equals(className) || c\n+                        .getSimpleName().equals(className) || c.getTypeName().equals(className)).findAny();\n+            }\n+            if (!dataClazz.isPresent()) {\n+                logger.debug(\"Class {} is not find in deploymemt {}, trying from classloader\", className, deploymentId);\n+                dataClazz = Optional.of(Class.forName(className.contains(\".\") ? className : \"java.lang.\" + className));\n             }\n         }\n-        return dataClazz;\n+        return dataClazz.orElse(Object.class);\n     }\n }\n", "next_change": {"commit": "4b1cf7a3a0f88b8ed7f718439cec78f7b377aabf", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\nindex 2b635b5b9..02002da6f 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n", "chunk": "@@ -409,7 +431,8 @@ public class KafkaServerExtension implements KieServerExtension, DeploymentEvent\n                         .getSimpleName().equals(className) || c.getTypeName().equals(className)).findAny();\n             }\n             if (!dataClazz.isPresent()) {\n-                logger.debug(\"Class {} is not find in deploymemt {}, trying from classloader\", className, deploymentId);\n+                logger.debug(\"Class {} has not been found in deployment {}, trying from classloader\", className,\n+                        deploymentId);\n                 dataClazz = Optional.of(Class.forName(className.contains(\".\") ? className : \"java.lang.\" + className));\n             }\n         }\n", "next_change": {"commit": "9cbed4f8d3f2fbe44ae127c8c27c2dd0a917abaa", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\nindex 02002da6f..8974468be 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n", "chunk": "@@ -438,4 +436,9 @@ public class KafkaServerExtension implements KieServerExtension, DeploymentEvent\n         }\n         return dataClazz.orElse(Object.class);\n     }\n+\n+    @Override\n+    public String toString() {\n+        return EXTENSION_NAME + \" KIE Server extension\";\n+    }\n }\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTkyOTkzNw==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515929937", "body": "make this configurable (number of threads)", "bodyText": "make this configurable (number of threads)", "bodyHTML": "<p dir=\"auto\">make this configurable (number of threads)</p>", "author": "elguardian", "createdAt": "2020-11-02T12:11:13Z", "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java", "diffHunk": "@@ -0,0 +1,307 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+*/\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.time.Duration;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.function.BiConsumer;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.serialization.ByteArrayDeserializer;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentEventListener;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedAsset;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.jbpm.services.api.model.SignalDesc;\n+import org.jbpm.services.api.model.SignalType;\n+import org.kie.server.api.KieServerConstants;\n+import org.kie.server.services.api.KieContainerInstance;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.api.SupportedTransports;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.kie.server.services.jbpm.JbpmKieServerExtension;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KafkaServerExtension implements KieServerExtension, DeploymentEventListener, Runnable {\n+\n+    public static final String EXTENSION_NAME = \"Kafka\";\n+    static final String KAFKA_EXTENSION_PREFIX = \"org.kie.server.jbpm-kafka.ext.\";\n+    static final String TOPIC_PREFIX = KAFKA_EXTENSION_PREFIX + \"topics.\";\n+    private static final Logger logger = LoggerFactory.getLogger(KafkaServerExtension.class);\n+\n+    private AtomicBoolean initialized = new AtomicBoolean();\n+    private Consumer<String, byte[]> consumer;\n+    private ListenerSupport deploymentService;\n+    private ProcessService processService;\n+    private ScheduledExecutorService pollService;\n+    private ExecutorService notifyService;\n+\n+    private Map<String, SignalInfo> topic2Signal = new ConcurrentHashMap<>();\n+\n+    @Override\n+    public boolean isInitialized() {\n+        return initialized.get();\n+    }\n+\n+    @Override\n+    public boolean isActive() {\n+        return !Boolean.getBoolean(KieServerConstants.KIE_KAFKA_SERVER_EXT_DISABLED);\n+    }\n+\n+    @Override\n+    public void init(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (initialized.getAndSet(true)) {\n+            return;\n+        }\n+        pollService = Executors.newSingleThreadScheduledExecutor();\n+        notifyService = Executors.newCachedThreadPool();", "originalCommit": "02a8f2440ed9ecc0abc0702a1a04c97f91f348f9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjY2NDM0OQ==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r516664349", "bodyText": "I think the usage of newCachedThreadPool matches the use case, as per documentation (are you missing an upper limit?, me too ;), do we add it?)\n\nCreates a thread pool that creates new threads as needed, but\n\nwill reuse previously constructed threads when they are\navailable.  These pools will typically improve the performance\nof programs that execute many short-lived asynchronous tasks.\nCalls to {@code execute} will reuse previously constructed\nthreads if available. If no existing thread is available, a new\nthread will be created and added to the pool. Threads that have\nnot been used for sixty seconds are terminated and removed from\nthe cache. Thus, a pool that remains idle for long enough will\nnot consume any resources. Note that pools with similar\nproperties but different details (for example, timeout parameters)\nmay be created using {@link ThreadPoolExecutor} constructors.", "author": "fjtirado", "createdAt": "2020-11-03T13:27:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTkyOTkzNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc3NTg2OA==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r516775868", "bodyText": "Upper limit to avoid thread exhaustion set", "author": "fjtirado", "createdAt": "2020-11-03T15:58:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTkyOTkzNw=="}], "type": "inlineReview", "revised_code": {"commit": "1ab6958fe0bfbaf2245278de193e40219f168da9", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\nindex 2911ced89..5ee3548ac 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n", "chunk": "@@ -87,9 +99,8 @@ public class KafkaServerExtension implements KieServerExtension, DeploymentEvent\n         if (initialized.getAndSet(true)) {\n             return;\n         }\n-        pollService = Executors.newSingleThreadScheduledExecutor();\n-        notifyService = Executors.newCachedThreadPool();\n-        consumer = getKafkaConsumer();\n+        notifyService = new ThreadPoolExecutor(0, Integer.getInteger(KAFKA_EXTENSION_PREFIX + \"maxNotifyThreads\", 10),\n+                60L, TimeUnit.SECONDS, new LinkedBlockingQueue<>());\n         KieServerExtension jbpmExt = registry.getServerExtension(JbpmKieServerExtension.EXTENSION_NAME);\n         if (jbpmExt == null) {\n             throw new IllegalStateException(\"Cannot find extension \" + JbpmKieServerExtension.EXTENSION_NAME);\n", "next_change": {"commit": "1a508f60083129fe949114e3c0b19f457c8587f9", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\nindex 5ee3548ac..97185d39a 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n", "chunk": "@@ -99,8 +101,6 @@ public class KafkaServerExtension implements KieServerExtension, DeploymentEvent\n         if (initialized.getAndSet(true)) {\n             return;\n         }\n-        notifyService = new ThreadPoolExecutor(0, Integer.getInteger(KAFKA_EXTENSION_PREFIX + \"maxNotifyThreads\", 10),\n-                60L, TimeUnit.SECONDS, new LinkedBlockingQueue<>());\n         KieServerExtension jbpmExt = registry.getServerExtension(JbpmKieServerExtension.EXTENSION_NAME);\n         if (jbpmExt == null) {\n             throw new IllegalStateException(\"Cannot find extension \" + JbpmKieServerExtension.EXTENSION_NAME);\n", "next_change": {"commit": "66bd82c671d96ca07b334754c8cf6985ef7bb72e", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\nindex 97185d39a..0e236d8b7 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n", "chunk": "@@ -98,12 +104,14 @@ public class KafkaServerExtension implements KieServerExtension, DeploymentEvent\n \n     @Override\n     public void init(KieServerImpl kieServer, KieServerRegistry registry) {\n-        if (initialized.getAndSet(true)) {\n+        if (initialized.get()) {\n             return;\n         }\n+\n         KieServerExtension jbpmExt = registry.getServerExtension(JbpmKieServerExtension.EXTENSION_NAME);\n         if (jbpmExt == null) {\n-            throw new IllegalStateException(\"Cannot find extension \" + JbpmKieServerExtension.EXTENSION_NAME);\n+            logger.warn(\"Extension \" + JbpmKieServerExtension.EXTENSION_NAME + \" is required\");\n+            return;\n         }\n \n         for (Object service : jbpmExt.getServices()) {\n", "next_change": null}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTkzMDQ2MA==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r515930460", "body": "if we have several deployments with the same signal name, wouldn't be overriding the deployment Id ?", "bodyText": "if we have several deployments with the same signal name, wouldn't be overriding the deployment Id ?", "bodyHTML": "<p dir=\"auto\">if we have several deployments with the same signal name, wouldn't be overriding the deployment Id ?</p>", "author": "elguardian", "createdAt": "2020-11-02T12:12:23Z", "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java", "diffHunk": "@@ -0,0 +1,307 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+*/\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.time.Duration;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.function.BiConsumer;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.serialization.ByteArrayDeserializer;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentEventListener;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedAsset;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.jbpm.services.api.model.SignalDesc;\n+import org.jbpm.services.api.model.SignalType;\n+import org.kie.server.api.KieServerConstants;\n+import org.kie.server.services.api.KieContainerInstance;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.api.SupportedTransports;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.kie.server.services.jbpm.JbpmKieServerExtension;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KafkaServerExtension implements KieServerExtension, DeploymentEventListener, Runnable {\n+\n+    public static final String EXTENSION_NAME = \"Kafka\";\n+    static final String KAFKA_EXTENSION_PREFIX = \"org.kie.server.jbpm-kafka.ext.\";\n+    static final String TOPIC_PREFIX = KAFKA_EXTENSION_PREFIX + \"topics.\";\n+    private static final Logger logger = LoggerFactory.getLogger(KafkaServerExtension.class);\n+\n+    private AtomicBoolean initialized = new AtomicBoolean();\n+    private Consumer<String, byte[]> consumer;\n+    private ListenerSupport deploymentService;\n+    private ProcessService processService;\n+    private ScheduledExecutorService pollService;\n+    private ExecutorService notifyService;\n+\n+    private Map<String, SignalInfo> topic2Signal = new ConcurrentHashMap<>();\n+\n+    @Override\n+    public boolean isInitialized() {\n+        return initialized.get();\n+    }\n+\n+    @Override\n+    public boolean isActive() {\n+        return !Boolean.getBoolean(KieServerConstants.KIE_KAFKA_SERVER_EXT_DISABLED);\n+    }\n+\n+    @Override\n+    public void init(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (initialized.getAndSet(true)) {\n+            return;\n+        }\n+        pollService = Executors.newSingleThreadScheduledExecutor();\n+        notifyService = Executors.newCachedThreadPool();\n+        consumer = getKafkaConsumer();\n+        KieServerExtension jbpmExt = registry.getServerExtension(JbpmKieServerExtension.EXTENSION_NAME);\n+        if (jbpmExt == null) {\n+            throw new IllegalStateException(\"Cannot find extension \" + JbpmKieServerExtension.EXTENSION_NAME);\n+        }\n+\n+        for (Object service : jbpmExt.getServices()) {\n+            if (deploymentService == null && DeploymentService.class.isAssignableFrom(service.getClass())) {\n+                deploymentService = (ListenerSupport) service;\n+            } else if (processService == null && ProcessService.class.isAssignableFrom(service.getClass())) {\n+                processService = (ProcessService) service;\n+            }\n+            if (deploymentService != null && processService != null) {\n+                break;\n+            }\n+        }\n+        if (deploymentService == null) {\n+            throw new IllegalStateException(\"Cannot find deployment service\");\n+        }\n+        if (processService == null) {\n+            throw new IllegalStateException(\"Cannot find process service\");\n+        }\n+        deploymentService.addListener(this);\n+    }\n+\n+    @Override\n+    public void destroy(KieServerImpl kieServer, KieServerRegistry registry) {\n+        pollService.shutdownNow();\n+        pollService = null;\n+        notifyService.shutdownNow();\n+        notifyService = null;\n+        if (deploymentService != null) {\n+            deploymentService.removeListener(this);\n+            deploymentService = null;\n+        }\n+        if (consumer != null) {\n+            consumer.close();\n+            consumer = null;\n+        }\n+        initialized.set(false);\n+    }\n+\n+    protected Consumer<String, byte[]> getKafkaConsumer() {\n+        Map<String, Object> props = new HashMap<>();\n+        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, System.getProperty(\n+                KAFKA_EXTENSION_PREFIX + \"boopstrap.servers\", \"localhost:9092\"));\n+        // read only committed events\n+        props.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, IsolationLevel.READ_COMMITTED.toString().toLowerCase());\n+        // do not automatically create topics by default\n+        props.put(ConsumerConfig.ALLOW_AUTO_CREATE_TOPICS_CONFIG, Boolean.getBoolean(\n+                KAFKA_EXTENSION_PREFIX + \"auto.create.topics\"));\n+        props.put(ConsumerConfig.GROUP_ID_CONFIG, System.getProperty(KAFKA_EXTENSION_PREFIX + \"group.id\",\n+                \"jbpm-consumer\"));\n+        return new KafkaConsumer<>(props, new StringDeserializer(), new ByteArrayDeserializer());\n+    }\n+\n+    @Override\n+    public void onDeploy(DeploymentEvent event) {\n+        updateRegistration(event, this::updateTopics);\n+    }\n+\n+    @Override\n+    public void onUnDeploy(DeploymentEvent event) {\n+        updateRegistration(event, this::removeTopics);\n+    }\n+\n+    @Override\n+    public void onActivate(DeploymentEvent event) {\n+        updateRegistration(event, this::updateTopics);\n+    }\n+\n+    @Override\n+    public void onDeactivate(DeploymentEvent event) {\n+        updateRegistration(event, this::removeTopics);\n+    }\n+\n+    private void updateTopics(String deploymentId, ProcessDefinition processDefinition) {\n+        for (SignalDesc signal : processDefinition.getSignalsMetadata()) {\n+            topic2Signal.computeIfAbsent(topicFromSignal(signal), t -> new SignalInfo(deploymentId,", "originalCommit": "02a8f2440ed9ecc0abc0702a1a04c97f91f348f9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjY1MjUwOA==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r516652508", "bodyText": "Map structure changed to fix this", "author": "fjtirado", "createdAt": "2020-11-03T13:07:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTkzMDQ2MA=="}], "type": "inlineReview", "revised_code": {"commit": "13c42b110a2fa2f9b6077c14c2094fea8dcc20b2", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\nindex 2911ced89..230145dbf 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n", "chunk": "@@ -166,30 +183,64 @@ public class KafkaServerExtension implements KieServerExtension, DeploymentEvent\n     }\n \n     private void updateTopics(String deploymentId, ProcessDefinition processDefinition) {\n-        for (SignalDesc signal : processDefinition.getSignalsMetadata()) {\n-            topic2Signal.computeIfAbsent(topicFromSignal(signal), t -> new SignalInfo(deploymentId,\n-                    signal));\n-        }\n+        updateTopics(topic2Signal, deploymentId, processDefinition.getSignalsDesc());\n+        updateTopics(topic2Message, deploymentId, processDefinition.getMessagesDesc());\n     }\n \n     private void removeTopics(String deploymentId, ProcessDefinition processDefinition) {\n-        for (SignalDesc signal : processDefinition.getSignalsMetadata()) {\n-            topic2Signal.remove(topicFromSignal(signal));\n+        removeTopics(topic2Signal, deploymentId, processDefinition.getSignalsDesc());\n+        removeTopics(topic2Message, deploymentId, processDefinition.getMessagesDesc());\n+    }\n+\n+    private <T extends SignalDescBase> void updateTopics(Map<String, Map<T, Collection<String>>> topic2SignalBase,\n+                                                         String deploymentId,\n+                                                         Collection<T> signals) {\n+        for (T signal : signals) {\n+            topic2SignalBase.computeIfAbsent(topicFromSignal(signal), k -> new HashMap<>()).computeIfAbsent(\n+                    signal, k -> new ArrayList<>()).add(deploymentId);\n         }\n     }\n \n-    private void updateRegistration(DeploymentEvent event, BiConsumer<String, ProcessDefinition> updater) {\n-        if (consumer != null) {\n-            for (DeployedAsset asset : event.getDeployedUnit().getDeployedAssets()) {\n-                updater.accept(event.getDeploymentId(), (ProcessDefinition) asset);\n+    private <T extends SignalDescBase> void removeTopics(Map<String, Map<T, Collection<String>>> topic2SignalBase,\n+                                                         String deploymentId,\n+                                                         Collection<T> signalsDesc) {\n+        for (T signal : signalsDesc) {\n+            String topic = topicFromSignal(signal);\n+            Map<T, Collection<String>> signals = topic2SignalBase.get(topic);\n+            if (signals != null) {\n+                Collection<String> deploymentIds = signals.get(signal);\n+                if (deploymentIds != null) {\n+                    deploymentIds.remove(deploymentId);\n+                    if (deploymentIds.isEmpty()) {\n+                        signals.remove(signal);\n+                        if (signals.isEmpty()) {\n+                            topic2SignalBase.remove(topic);\n+                        }\n+                    }\n+                }\n+\n             }\n-            synchronized (consumer) {\n-                consumer.subscribe(topic2Signal.keySet());\n+        }\n+    }\n+\n+    private void updateRegistration(DeploymentEvent event, BiConsumer<String, ProcessDefinition> updater) {\n+        changeRegistrationLock.lock();\n+        try {\n+            if (consumer != null) {\n+                for (DeployedAsset asset : event.getDeployedUnit().getDeployedAssets()) {\n+                    updater.accept(event.getDeploymentId(), (ProcessDefinition) asset);\n+                }\n+                Set<String> topic2Register = new HashSet<>();\n+                topic2Register.addAll(topic2Signal.keySet());\n+                topic2Register.addAll(topic2Message.keySet());\n+                consumer.subscribe(topic2Register);\n             }\n+        } finally {\n+            changeRegistrationLock.unlock();\n         }\n     }\n \n-    private String topicFromSignal(SignalDesc signal) {\n+    private static <T extends SignalDescBase> String topicFromSignal(T signal) {\n         return System.getProperty(TOPIC_PREFIX + signal.getName(), signal.getName());\n     }\n \n", "next_change": {"commit": "1ab6958fe0bfbaf2245278de193e40219f168da9", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\nindex 230145dbf..5ee3548ac 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n", "chunk": "@@ -224,20 +238,29 @@ public class KafkaServerExtension implements KieServerExtension, DeploymentEvent\n     }\n \n     private void updateRegistration(DeploymentEvent event, BiConsumer<String, ProcessDefinition> updater) {\n+        Set<String> topic2Register = new HashSet<>();\n         changeRegistrationLock.lock();\n         try {\n-            if (consumer != null) {\n-                for (DeployedAsset asset : event.getDeployedUnit().getDeployedAssets()) {\n-                    updater.accept(event.getDeploymentId(), (ProcessDefinition) asset);\n-                }\n-                Set<String> topic2Register = new HashSet<>();\n-                topic2Register.addAll(topic2Signal.keySet());\n-                topic2Register.addAll(topic2Message.keySet());\n-                consumer.subscribe(topic2Register);\n+            for (DeployedAsset asset : event.getDeployedUnit().getDeployedAssets()) {\n+                updater.accept(event.getDeploymentId(), (ProcessDefinition) asset);\n             }\n+            topic2Register.addAll(topic2Signal.keySet());\n+            topic2Register.addAll(topic2Message.keySet());\n         } finally {\n             changeRegistrationLock.unlock();\n         }\n+        consumerLock.lock();\n+        try {\n+            if (consumer == null) {\n+                consumer = getKafkaConsumer();\n+                long delay = Long.getLong(KAFKA_EXTENSION_PREFIX + \"poll.interval\", 1L);\n+                pollService = Executors.newSingleThreadScheduledExecutor();\n+                pollService.scheduleWithFixedDelay(this, 0, delay, TimeUnit.SECONDS);\n+            }\n+            consumer.subscribe(topic2Register);\n+        } finally {\n+            consumerLock.unlock();\n+        }\n     }\n \n     private static <T extends SignalDescBase> String topicFromSignal(T signal) {\n", "next_change": {"commit": "4b1cf7a3a0f88b8ed7f718439cec78f7b377aabf", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\nindex 5ee3548ac..02002da6f 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n", "chunk": "@@ -252,15 +254,16 @@ public class KafkaServerExtension implements KieServerExtension, DeploymentEvent\n         consumerLock.lock();\n         try {\n             if (consumer == null) {\n+                logger.trace(\"Creating kafka consumer\");\n                 consumer = getKafkaConsumer();\n-                long delay = Long.getLong(KAFKA_EXTENSION_PREFIX + \"poll.interval\", 1L);\n-                pollService = Executors.newSingleThreadScheduledExecutor();\n-                pollService.scheduleWithFixedDelay(this, 0, delay, TimeUnit.SECONDS);\n+                pollService = new Thread(this);\n+                pollService.start();\n             }\n             consumer.subscribe(topic2Register);\n         } finally {\n             consumerLock.unlock();\n         }\n+        logger.debug(\"Updating kafka subscription list to these topics {}\", topic2Register);\n     }\n \n     private static <T extends SignalDescBase> String topicFromSignal(T signal) {\n", "next_change": {"commit": "a1cb9ea4402f589c17d2793fb7e8e1c24a53f4bb", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\nindex 02002da6f..739637a79 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n", "chunk": "@@ -272,7 +270,7 @@ public class KafkaServerExtension implements KieServerExtension, DeploymentEvent\n \n     @Override\n     public void serverStarted() {\n-        // todo will use lazy initialization for consumer\n+        // will use lazy initialization for consumer\n     }\n \n     @Override\n", "next_change": null}]}}]}}, {"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\nindex 230145dbf..5ee3548ac 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n", "chunk": "@@ -246,10 +269,7 @@ public class KafkaServerExtension implements KieServerExtension, DeploymentEvent\n \n     @Override\n     public void serverStarted() {\n-        if (pollService != null) {\n-            long delay = Long.getLong(KAFKA_EXTENSION_PREFIX + \"poll.interval\", 1L);\n-            pollService.scheduleWithFixedDelay(this, delay, delay, TimeUnit.SECONDS);\n-        }\n+        // todo will use lazy initialization for consumer\n     }\n \n     @Override\n", "next_change": {"commit": "a1cb9ea4402f589c17d2793fb7e8e1c24a53f4bb", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\nindex 5ee3548ac..739637a79 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n", "chunk": "@@ -269,7 +270,7 @@ public class KafkaServerExtension implements KieServerExtension, DeploymentEvent\n \n     @Override\n     public void serverStarted() {\n-        // todo will use lazy initialization for consumer\n+        // will use lazy initialization for consumer\n     }\n \n     @Override\n", "next_change": null}]}}]}}]}}, {"oid": "13c42b110a2fa2f9b6077c14c2094fea8dcc20b2", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/13c42b110a2fa2f9b6077c14c2094fea8dcc20b2", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-11-03T13:02:22Z", "type": "forcePushed"}, {"oid": "1ab6958fe0bfbaf2245278de193e40219f168da9", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/1ab6958fe0bfbaf2245278de193e40219f168da9", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-11-03T15:58:11Z", "type": "forcePushed"}, {"oid": "89ec48820033dc591dbdd8172b8ed967bee3bb4e", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/89ec48820033dc591dbdd8172b8ed967bee3bb4e", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-11-03T17:06:57Z", "type": "forcePushed"}, {"oid": "4b1cf7a3a0f88b8ed7f718439cec78f7b377aabf", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/4b1cf7a3a0f88b8ed7f718439cec78f7b377aabf", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-11-03T18:13:12Z", "type": "forcePushed"}, {"oid": "cd0ab2faf29f161a2e50e97ffaf74aaaefe2bbd2", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/cd0ab2faf29f161a2e50e97ffaf74aaaefe2bbd2", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-11-03T19:02:31Z", "type": "forcePushed"}, {"oid": "17d08ac91a960e2b2b0d0a0f4ede0dbacfa96398", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/17d08ac91a960e2b2b0d0a0f4ede0dbacfa96398", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-11-03T19:32:47Z", "type": "forcePushed"}, {"oid": "42f339a08f7d9eb123c506125fcf4aeb5a771dbe", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/42f339a08f7d9eb123c506125fcf4aeb5a771dbe", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-11-03T19:39:10Z", "type": "forcePushed"}, {"oid": "13cf2e3acbca0ecf0342470b14c72fcea677bcad", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/13cf2e3acbca0ecf0342470b14c72fcea677bcad", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-11-03T20:04:32Z", "type": "forcePushed"}, {"oid": "19edc3c68c6e445738877a4c3b0fa31aca0d6ae3", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/19edc3c68c6e445738877a4c3b0fa31aca0d6ae3", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-11-03T20:27:35Z", "type": "forcePushed"}, {"oid": "9cbed4f8d3f2fbe44ae127c8c27c2dd0a917abaa", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/9cbed4f8d3f2fbe44ae127c8c27c2dd0a917abaa", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-11-03T21:22:24Z", "type": "forcePushed"}, {"oid": "a1cb9ea4402f589c17d2793fb7e8e1c24a53f4bb", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/a1cb9ea4402f589c17d2793fb7e8e1c24a53f4bb", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-11-04T16:01:06Z", "type": "forcePushed"}, {"oid": "1a508f60083129fe949114e3c0b19f457c8587f9", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/1a508f60083129fe949114e3c0b19f457c8587f9", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-11-05T08:23:02Z", "type": "forcePushed"}, {"oid": "8b08b9dfe1cd5afb282fe684a2b9a5fa6a7ec7b0", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/8b08b9dfe1cd5afb282fe684a2b9a5fa6a7ec7b0", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-11-05T08:30:33Z", "type": "forcePushed"}, {"oid": "236d02e2b3dd570d51810a2d32af040e427aaa3f", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/236d02e2b3dd570d51810a2d32af040e427aaa3f", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-11-05T10:30:35Z", "type": "forcePushed"}, {"oid": "a95e2687e0fe78678090b8ee6dcb30f1a09dfdb6", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/a95e2687e0fe78678090b8ee6dcb30f1a09dfdb6", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-11-05T12:06:51Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA5MjcwMg==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r518092702", "body": "if we have consumer but not topics this loop does not sleep. we will eat CPU non stop without interruption.", "bodyText": "if we have consumer but not topics this loop does not sleep. we will eat CPU non stop without interruption.", "bodyHTML": "<p dir=\"auto\">if we have consumer but not topics this loop does not sleep. we will eat CPU non stop without interruption.</p>", "author": "elguardian", "createdAt": "2020-11-05T14:29:04Z", "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java", "diffHunk": "@@ -0,0 +1,453 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+*/\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.ThreadPoolExecutor;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.locks.Lock;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.function.BiConsumer;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.errors.WakeupException;\n+import org.apache.kafka.common.serialization.ByteArrayDeserializer;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentEventListener;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedAsset;\n+import org.jbpm.services.api.model.MessageDesc;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.jbpm.services.api.model.SignalDesc;\n+import org.jbpm.services.api.model.SignalDescBase;\n+import org.kie.server.api.KieServerConstants;\n+import org.kie.server.services.api.KieContainerInstance;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.api.SupportedTransports;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.kie.server.services.jbpm.JbpmKieServerExtension;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KafkaServerExtension implements KieServerExtension, DeploymentEventListener, Runnable {\n+\n+    public static final String EXTENSION_NAME = \"Kafka\";\n+    static final String KAFKA_EXTENSION_PREFIX = \"org.kie.server.jbpm-kafka.ext.\";\n+    static final String TOPIC_PREFIX = KAFKA_EXTENSION_PREFIX + \"topics.\";\n+    private static final Logger logger = LoggerFactory.getLogger(KafkaServerExtension.class);\n+\n+    private AtomicBoolean initialized = new AtomicBoolean();\n+    private AtomicBoolean consumerReady = new AtomicBoolean();\n+    private Consumer<String, byte[]> consumer;\n+    private ListenerSupport deploymentService;\n+    private ProcessService processService;\n+    private ExecutorService notifyService;\n+\n+    private Map<String, Map<SignalDesc, Collection<String>>> topic2Signal = new HashMap<>();\n+    private Map<String, Map<MessageDesc, Collection<String>>> topic2Message = new HashMap<>();\n+    private Map<String, Collection<Class<?>>> classes = new ConcurrentHashMap<>();\n+\n+    private Lock changeRegistrationLock = new ReentrantLock();\n+    private Lock consumerLock = new ReentrantLock();\n+\n+    @Override\n+    public boolean isInitialized() {\n+        return initialized.get();\n+    }\n+\n+    @Override\n+    public boolean isActive() {\n+        return !Boolean.getBoolean(KieServerConstants.KIE_KAFKA_SERVER_EXT_DISABLED);\n+    }\n+\n+    @Override\n+    public void init(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (initialized.getAndSet(true)) {\n+            return;\n+        }\n+        KieServerExtension jbpmExt = registry.getServerExtension(JbpmKieServerExtension.EXTENSION_NAME);\n+        if (jbpmExt == null) {\n+            throw new IllegalStateException(\"Cannot find extension \" + JbpmKieServerExtension.EXTENSION_NAME);\n+        }\n+\n+        for (Object service : jbpmExt.getServices()) {\n+            if (deploymentService == null && DeploymentService.class.isAssignableFrom(service.getClass())) {\n+                deploymentService = (ListenerSupport) service;\n+            } else if (processService == null && ProcessService.class.isAssignableFrom(service.getClass())) {\n+                processService = (ProcessService) service;\n+            }\n+            if (deploymentService != null && processService != null) {\n+                break;\n+            }\n+        }\n+        if (deploymentService == null) {\n+            throw new IllegalStateException(\"Cannot find deployment service\");\n+        }\n+        if (processService == null) {\n+            throw new IllegalStateException(\"Cannot find process service\");\n+        }\n+        deploymentService.addListener(this);\n+    }\n+\n+    @Override\n+    public void destroy(KieServerImpl kieServer, KieServerRegistry registry) {\n+        classes.clear();\n+        if (deploymentService != null) {\n+            deploymentService.removeListener(this);\n+        }\n+        changeRegistrationLock.lock();\n+        try {\n+            topic2Signal.clear();\n+            topic2Message.clear();\n+        } finally {\n+            changeRegistrationLock.unlock();\n+        }\n+        if (consumerReady.compareAndSet(true, false)) {\n+            consumer.wakeup();\n+            consumerLock.lock();\n+            try {\n+                notifyService.shutdownNow();\n+                consumer.close();\n+                notifyService = null;\n+                consumer = null;\n+            } finally {\n+                consumerLock.unlock();\n+            }\n+        }\n+        processService = null;\n+        deploymentService = null;\n+        initialized.set(false);\n+    }\n+\n+    protected Consumer<String, byte[]> getKafkaConsumer() {\n+        Map<String, Object> props = new HashMap<>();\n+        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, System.getProperty(\n+                KAFKA_EXTENSION_PREFIX + \"boopstrap.servers\", \"localhost:9092\"));\n+        // read only committed events\n+        props.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, IsolationLevel.READ_COMMITTED.toString().toLowerCase());\n+        // do not automatically create topics by default\n+        props.put(ConsumerConfig.ALLOW_AUTO_CREATE_TOPICS_CONFIG, Boolean.getBoolean(\n+                KAFKA_EXTENSION_PREFIX + \"auto.create.topics\"));\n+        props.put(ConsumerConfig.GROUP_ID_CONFIG, System.getProperty(KAFKA_EXTENSION_PREFIX + \"group.id\",\n+                \"jbpm-consumer\"));\n+        return new KafkaConsumer<>(props, new StringDeserializer(), new ByteArrayDeserializer());\n+    }\n+\n+    @Override\n+    public void onDeploy(DeploymentEvent event) {\n+        updateRegistration(event, this::updateTopics);\n+    }\n+\n+    @Override\n+    public void onUnDeploy(DeploymentEvent event) {\n+        updateRegistration(event, this::removeTopics);\n+    }\n+\n+    @Override\n+    public void onActivate(DeploymentEvent event) {\n+        updateRegistration(event, this::updateTopics);\n+    }\n+\n+    @Override\n+    public void onDeactivate(DeploymentEvent event) {\n+        updateRegistration(event, this::removeTopics);\n+    }\n+\n+    private void updateTopics(String deploymentId, ProcessDefinition processDefinition) {\n+        updateTopics(topic2Signal, deploymentId, processDefinition.getSignalsDesc());\n+        updateTopics(topic2Message, deploymentId, processDefinition.getMessagesDesc());\n+    }\n+\n+    private void removeTopics(String deploymentId, ProcessDefinition processDefinition) {\n+        removeTopics(topic2Signal, deploymentId, processDefinition.getSignalsDesc());\n+        removeTopics(topic2Message, deploymentId, processDefinition.getMessagesDesc());\n+    }\n+\n+    private <T extends SignalDescBase> void updateTopics(Map<String, Map<T, Collection<String>>> topic2SignalBase,\n+                                                         String deploymentId,\n+                                                         Collection<T> signals) {\n+        for (T signal : signals) {\n+            topic2SignalBase.computeIfAbsent(topicFromSignal(signal), k -> new HashMap<>()).computeIfAbsent(\n+                    signal, k -> new ArrayList<>()).add(deploymentId);\n+        }\n+    }\n+\n+    private <T extends SignalDescBase> void removeTopics(Map<String, Map<T, Collection<String>>> topic2SignalBase,\n+                                                         String deploymentId,\n+                                                         Collection<T> signalsDesc) {\n+        for (T signal : signalsDesc) {\n+            String topic = topicFromSignal(signal);\n+            Map<T, Collection<String>> signals = topic2SignalBase.get(topic);\n+            if (signals != null) {\n+                Collection<String> deploymentIds = signals.get(signal);\n+                if (deploymentIds != null) {\n+                    deploymentIds.remove(deploymentId);\n+                    if (deploymentIds.isEmpty()) {\n+                        signals.remove(signal);\n+                        if (signals.isEmpty()) {\n+                            topic2SignalBase.remove(topic);\n+                        }\n+                    }\n+                }\n+\n+            }\n+        }\n+    }\n+\n+    private void updateRegistration(DeploymentEvent event, BiConsumer<String, ProcessDefinition> updater) {\n+        classes.put(event.getDeploymentId(), event.getDeployedUnit().getDeployedClasses());\n+        Set<String> topic2Register = new HashSet<>();\n+        changeRegistrationLock.lock();\n+        try {\n+            for (DeployedAsset asset : event.getDeployedUnit().getDeployedAssets()) {\n+                updater.accept(event.getDeploymentId(), (ProcessDefinition) asset);\n+            }\n+            topic2Register.addAll(topic2Signal.keySet());\n+            topic2Register.addAll(topic2Message.keySet());\n+        } finally {\n+            changeRegistrationLock.unlock();\n+        }\n+\n+        if (consumerReady.compareAndSet(false, true)) {\n+            logger.trace(\"Creating kafka consumer\");\n+            consumer = getKafkaConsumer();\n+            subscribe(topic2Register);\n+            notifyService =\n+                    new ThreadPoolExecutor(1, Integer.getInteger(KAFKA_EXTENSION_PREFIX + \"maxNotifyThreads\", 10), 60L,\n+                            TimeUnit.SECONDS, new LinkedBlockingQueue<>());\n+            Thread pollService = new Thread(this);\n+            pollService.start();\n+        }\n+        else {\n+            consumer.wakeup();\n+            subscribe(topic2Register);\n+        }\n+\n+    }\n+\n+    private void subscribe(Set<String> topic2Register) {\n+        consumerLock.lock();\n+        try {\n+            consumer.subscribe(topic2Register);\n+        } finally {\n+            consumerLock.unlock();\n+        }\n+        logger.debug(\"Updated kafka subscription list to these topics {}\", topic2Register);\n+    }\n+\n+    private static <T extends SignalDescBase> String topicFromSignal(T signal) {\n+        return System.getProperty(TOPIC_PREFIX + signal.getName(), signal.getName());\n+    }\n+\n+    @Override\n+    public void serverStarted() {\n+        // will use lazy initialization for consumer\n+    }\n+\n+    @Override\n+    public void createContainer(String id, KieContainerInstance kieContainerInstance, Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public boolean isUpdateContainerAllowed(String id,\n+                                            KieContainerInstance kieContainerInstance,\n+                                            Map<String, Object> parameters) {\n+        return false;\n+    }\n+\n+    @Override\n+    public void prepareContainerUpdate(String id,\n+                                       KieContainerInstance kieContainerInstance,\n+                                       Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public void updateContainer(String id, KieContainerInstance kieContainerInstance, Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public void disposeContainer(String id, KieContainerInstance kieContainerInstance, Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public List<Object> getAppComponents(SupportedTransports type) {\n+        return Collections.emptyList();\n+    }\n+\n+    @Override\n+    public <T> T getAppComponents(Class<T> serviceType) {\n+        return null;\n+    }\n+\n+    @Override\n+    public String getImplementedCapability() {\n+        return KieServerConstants.CAPABILITY_BPM_KAFKA;\n+    }\n+\n+    @Override\n+    public List<Object> getServices() {\n+        return Collections.emptyList();\n+    }\n+\n+    @Override\n+    public String getExtensionName() {\n+        return EXTENSION_NAME;\n+    }\n+\n+    @Override\n+    public Integer getStartOrder() {\n+        return 20;\n+    }\n+\n+    @Override\n+    public void run() {\n+        Duration duration =\n+                Duration.ofSeconds(Long.getLong(KAFKA_EXTENSION_PREFIX + \"poll.interval\", 10L));\n+        logger.trace(\"Start polling kafka consumer every {} seconds\", duration.getSeconds());\n+        while (consumerReady.get()) {\n+            if (isSubscribed()) {\n+                ConsumerRecords<String, byte[]> events = ConsumerRecords.empty();\n+                consumerLock.lock();\n+                try {\n+                    try {\n+                        events = consumer.poll(duration);\n+                    } catch (WakeupException ex) {\n+                        logger.trace(\"Kafka wait interrupted\");\n+                    } catch (Exception ex) {\n+                        logger.error(\"Error polling kafka consumer\", ex);\n+                    }\n+                } finally {\n+                    consumerLock.unlock();\n+                }\n+                if (consumerReady.get() && !events.isEmpty()) {\n+                    if (logger.isDebugEnabled()) {\n+                        Map<String, Integer> eventsPerTopic = new HashMap<>();\n+                        for (ConsumerRecord<String, byte[]> event : events) {\n+                            eventsPerTopic.compute(event.topic(), (k, v) -> v == null ? 1 : v++);\n+                        }\n+                        logger.debug(\"Number of events received per topic {}\", eventsPerTopic);\n+                    }\n+                    for (ConsumerRecord<String, byte[]> event : events) {\n+                        notifyService.submit(() -> processEvent(event));\n+                    }\n+                }\n+            }\n+        }", "originalCommit": "a95e2687e0fe78678090b8ee6dcb30f1a09dfdb6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODE3NjQyMg==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r518176422", "bodyText": "good catch!! This bug was provoked by changing from ScheduledService to backgroung thread. Fixed used condition lock", "author": "fjtirado", "createdAt": "2020-11-05T16:16:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA5MjcwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODE4NDAzOA==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r518184038", "bodyText": "good catch, fixed with a condition object", "author": "fjtirado", "createdAt": "2020-11-05T16:26:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA5MjcwMg=="}], "type": "inlineReview", "revised_code": {"commit": "a3f08ded394724d463262a6e934d9be600fab800", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\nindex 88bc1cfaa..3132f474a 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n", "chunk": "@@ -344,50 +350,64 @@ public class KafkaServerExtension implements KieServerExtension, DeploymentEvent\n         Duration duration =\n                 Duration.ofSeconds(Long.getLong(KAFKA_EXTENSION_PREFIX + \"poll.interval\", 10L));\n         logger.trace(\"Start polling kafka consumer every {} seconds\", duration.getSeconds());\n-        while (consumerReady.get()) {\n-            if (isSubscribed()) {\n-                ConsumerRecords<String, byte[]> events = ConsumerRecords.empty();\n-                consumerLock.lock();\n-                try {\n-                    try {\n-                        events = consumer.poll(duration);\n-                    } catch (WakeupException ex) {\n-                        logger.trace(\"Kafka wait interrupted\");\n-                    } catch (Exception ex) {\n-                        logger.error(\"Error polling kafka consumer\", ex);\n-                    }\n-                } finally {\n-                    consumerLock.unlock();\n-                }\n-                if (consumerReady.get() && !events.isEmpty()) {\n-                    if (logger.isDebugEnabled()) {\n-                        Map<String, Integer> eventsPerTopic = new HashMap<>();\n-                        for (ConsumerRecord<String, byte[]> event : events) {\n-                            eventsPerTopic.compute(event.topic(), (k, v) -> v == null ? 1 : v++);\n-                        }\n-                        logger.debug(\"Number of events received per topic {}\", eventsPerTopic);\n-                    }\n-                    for (ConsumerRecord<String, byte[]> event : events) {\n-                        notifyService.submit(() -> processEvent(event));\n-                    }\n-                }\n+        try {\n+            while (consumerReady.get()) {\n+                checkSubscribed();\n+                dispatchEvents(pollEvents(duration));\n             }\n+        } catch (InterruptedException e) {\n+            logger.warn(\"Polling thread interrupted\", e);\n+            Thread.currentThread().interrupt();\n         }\n         logger.trace(\"Kafka polling stopped\");\n     }\n \n-    private boolean isSubscribed() {\n+    private void checkSubscribed() throws InterruptedException {\n         changeRegistrationLock.lock();\n         try {\n-            return !topic2Message.isEmpty() || !topic2Signal.isEmpty();\n+            while (consumerReady.get() && topic2Signal.isEmpty() && topic2Message.isEmpty()) {\n+                isSubscribedCond.await();\n+            }\n         } finally {\n             changeRegistrationLock.unlock();\n         }\n+    }\n+\n+    private ConsumerRecords<String, byte[]> pollEvents(Duration duration) {\n+        ConsumerRecords<String, byte[]> events = ConsumerRecords.empty();\n+        if (consumerReady.get()) {\n+            consumerLock.lock();\n+            try {\n+                events = consumer.poll(duration);\n+            } catch (WakeupException ex) {\n+                logger.trace(\"Kafka wait interrupted\");\n+            } catch (Exception ex) {\n+                logger.error(\"Error polling kafka consumer\", ex);\n+            } finally {\n+                consumerLock.unlock();\n+            }\n+        }\n+        return events;\n+    }\n \n+    private void dispatchEvents(ConsumerRecords<String, byte[]> events) {\n+        if (consumerReady.get() && !events.isEmpty()) {\n+            if (logger.isDebugEnabled()) {\n+                Map<String, Integer> eventsPerTopic = new HashMap<>();\n+                for (ConsumerRecord<String, byte[]> event : events) {\n+                    eventsPerTopic.compute(event.topic(), (k, v) -> v == null ? 1 : v++);\n+                }\n+                logger.debug(\"Number of events received per topic {}\", eventsPerTopic);\n+            }\n+            for (ConsumerRecord<String, byte[]> event : events) {\n+                notifyService.submit(() -> processEvent(event));\n+            }\n+        }\n     }\n \n     @FunctionalInterface\n     private static interface Signaller {\n+\n         void signalEvent(String deploymentId, String signalName, Object data);\n     }\n \n", "next_change": {"commit": "7dce599fbdcbb724217d646951918e2c2412074a", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\nindex 3132f474a..abff5dad2 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n", "chunk": "@@ -407,16 +406,17 @@ public class KafkaServerExtension implements KieServerExtension, DeploymentEvent\n \n     @FunctionalInterface\n     private static interface Signaller {\n-\n         void signalEvent(String deploymentId, String signalName, Object data);\n     }\n \n+    private Signaller messageSignaller = (deployment, signalName, data) -> signalEvent(deployment, \"Message-\" +\n+                                                                                                   signalName, data);\n+\n     private void processEvent(ConsumerRecord<String, byte[]> event) {\n         changeRegistrationLock.lock();\n         try {\n             processEvent(topic2Signal, event, this::signalEvent);\n-            processEvent(topic2Message, event,\n-                    (deployment, signalName, data) -> signalEvent(deployment, \"Message-\" + signalName, data));\n+            processEvent(topic2Message, event, messageSignaller);\n         } finally {\n             changeRegistrationLock.unlock();\n         }\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA5NDY3Mg==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r518094672", "body": "this is ok but has a limitation. we won't support in kafka events typed json unmarshaller. \r\n```\r\n{\r\n    map : {\r\n         \"key1\" : {\r\n               \"com.my.simple.type\" : {\r\n                       \"field\" : \"hello\"\r\n               }\r\n          }\r\n    }\r\n\r\n```\r\n(for instance when we have Map, List so the values are not clear and require types being in the json. \r\nThis limitation should be in the BAPL.", "bodyText": "this is ok but has a limitation. we won't support in kafka events typed json unmarshaller.\n{\n    map : {\n         \"key1\" : {\n               \"com.my.simple.type\" : {\n                       \"field\" : \"hello\"\n               }\n          }\n    }\n\n\n(for instance when we have Map, List so the values are not clear and require types being in the json.\nThis limitation should be in the BAPL.", "bodyHTML": "<p dir=\"auto\">this is ok but has a limitation. we won't support in kafka events typed json unmarshaller.</p>\n<div class=\"snippet-clipboard-content position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"{\n    map : {\n         &quot;key1&quot; : {\n               &quot;com.my.simple.type&quot; : {\n                       &quot;field&quot; : &quot;hello&quot;\n               }\n          }\n    }\n\"><pre><code>{\n    map : {\n         \"key1\" : {\n               \"com.my.simple.type\" : {\n                       \"field\" : \"hello\"\n               }\n          }\n    }\n\n</code></pre></div>\n<p dir=\"auto\">(for instance when we have Map, List so the values are not clear and require types being in the json.<br>\nThis limitation should be in the BAPL.</p>", "author": "elguardian", "createdAt": "2020-11-05T14:31:44Z", "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java", "diffHunk": "@@ -0,0 +1,453 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+*/\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.ThreadPoolExecutor;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.locks.Lock;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.function.BiConsumer;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.errors.WakeupException;\n+import org.apache.kafka.common.serialization.ByteArrayDeserializer;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentEventListener;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedAsset;\n+import org.jbpm.services.api.model.MessageDesc;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.jbpm.services.api.model.SignalDesc;\n+import org.jbpm.services.api.model.SignalDescBase;\n+import org.kie.server.api.KieServerConstants;\n+import org.kie.server.services.api.KieContainerInstance;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.api.SupportedTransports;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.kie.server.services.jbpm.JbpmKieServerExtension;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KafkaServerExtension implements KieServerExtension, DeploymentEventListener, Runnable {\n+\n+    public static final String EXTENSION_NAME = \"Kafka\";\n+    static final String KAFKA_EXTENSION_PREFIX = \"org.kie.server.jbpm-kafka.ext.\";\n+    static final String TOPIC_PREFIX = KAFKA_EXTENSION_PREFIX + \"topics.\";\n+    private static final Logger logger = LoggerFactory.getLogger(KafkaServerExtension.class);\n+\n+    private AtomicBoolean initialized = new AtomicBoolean();\n+    private AtomicBoolean consumerReady = new AtomicBoolean();\n+    private Consumer<String, byte[]> consumer;\n+    private ListenerSupport deploymentService;\n+    private ProcessService processService;\n+    private ExecutorService notifyService;\n+\n+    private Map<String, Map<SignalDesc, Collection<String>>> topic2Signal = new HashMap<>();\n+    private Map<String, Map<MessageDesc, Collection<String>>> topic2Message = new HashMap<>();\n+    private Map<String, Collection<Class<?>>> classes = new ConcurrentHashMap<>();\n+\n+    private Lock changeRegistrationLock = new ReentrantLock();\n+    private Lock consumerLock = new ReentrantLock();\n+\n+    @Override\n+    public boolean isInitialized() {\n+        return initialized.get();\n+    }\n+\n+    @Override\n+    public boolean isActive() {\n+        return !Boolean.getBoolean(KieServerConstants.KIE_KAFKA_SERVER_EXT_DISABLED);\n+    }\n+\n+    @Override\n+    public void init(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (initialized.getAndSet(true)) {\n+            return;\n+        }\n+        KieServerExtension jbpmExt = registry.getServerExtension(JbpmKieServerExtension.EXTENSION_NAME);\n+        if (jbpmExt == null) {\n+            throw new IllegalStateException(\"Cannot find extension \" + JbpmKieServerExtension.EXTENSION_NAME);\n+        }\n+\n+        for (Object service : jbpmExt.getServices()) {\n+            if (deploymentService == null && DeploymentService.class.isAssignableFrom(service.getClass())) {\n+                deploymentService = (ListenerSupport) service;\n+            } else if (processService == null && ProcessService.class.isAssignableFrom(service.getClass())) {\n+                processService = (ProcessService) service;\n+            }\n+            if (deploymentService != null && processService != null) {\n+                break;\n+            }\n+        }\n+        if (deploymentService == null) {\n+            throw new IllegalStateException(\"Cannot find deployment service\");\n+        }\n+        if (processService == null) {\n+            throw new IllegalStateException(\"Cannot find process service\");\n+        }\n+        deploymentService.addListener(this);\n+    }\n+\n+    @Override\n+    public void destroy(KieServerImpl kieServer, KieServerRegistry registry) {\n+        classes.clear();\n+        if (deploymentService != null) {\n+            deploymentService.removeListener(this);\n+        }\n+        changeRegistrationLock.lock();\n+        try {\n+            topic2Signal.clear();\n+            topic2Message.clear();\n+        } finally {\n+            changeRegistrationLock.unlock();\n+        }\n+        if (consumerReady.compareAndSet(true, false)) {\n+            consumer.wakeup();\n+            consumerLock.lock();\n+            try {\n+                notifyService.shutdownNow();\n+                consumer.close();\n+                notifyService = null;\n+                consumer = null;\n+            } finally {\n+                consumerLock.unlock();\n+            }\n+        }\n+        processService = null;\n+        deploymentService = null;\n+        initialized.set(false);\n+    }\n+\n+    protected Consumer<String, byte[]> getKafkaConsumer() {\n+        Map<String, Object> props = new HashMap<>();\n+        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, System.getProperty(\n+                KAFKA_EXTENSION_PREFIX + \"boopstrap.servers\", \"localhost:9092\"));\n+        // read only committed events\n+        props.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, IsolationLevel.READ_COMMITTED.toString().toLowerCase());\n+        // do not automatically create topics by default\n+        props.put(ConsumerConfig.ALLOW_AUTO_CREATE_TOPICS_CONFIG, Boolean.getBoolean(\n+                KAFKA_EXTENSION_PREFIX + \"auto.create.topics\"));\n+        props.put(ConsumerConfig.GROUP_ID_CONFIG, System.getProperty(KAFKA_EXTENSION_PREFIX + \"group.id\",\n+                \"jbpm-consumer\"));\n+        return new KafkaConsumer<>(props, new StringDeserializer(), new ByteArrayDeserializer());\n+    }\n+\n+    @Override\n+    public void onDeploy(DeploymentEvent event) {\n+        updateRegistration(event, this::updateTopics);\n+    }\n+\n+    @Override\n+    public void onUnDeploy(DeploymentEvent event) {\n+        updateRegistration(event, this::removeTopics);\n+    }\n+\n+    @Override\n+    public void onActivate(DeploymentEvent event) {\n+        updateRegistration(event, this::updateTopics);\n+    }\n+\n+    @Override\n+    public void onDeactivate(DeploymentEvent event) {\n+        updateRegistration(event, this::removeTopics);\n+    }\n+\n+    private void updateTopics(String deploymentId, ProcessDefinition processDefinition) {\n+        updateTopics(topic2Signal, deploymentId, processDefinition.getSignalsDesc());\n+        updateTopics(topic2Message, deploymentId, processDefinition.getMessagesDesc());\n+    }\n+\n+    private void removeTopics(String deploymentId, ProcessDefinition processDefinition) {\n+        removeTopics(topic2Signal, deploymentId, processDefinition.getSignalsDesc());\n+        removeTopics(topic2Message, deploymentId, processDefinition.getMessagesDesc());\n+    }\n+\n+    private <T extends SignalDescBase> void updateTopics(Map<String, Map<T, Collection<String>>> topic2SignalBase,\n+                                                         String deploymentId,\n+                                                         Collection<T> signals) {\n+        for (T signal : signals) {\n+            topic2SignalBase.computeIfAbsent(topicFromSignal(signal), k -> new HashMap<>()).computeIfAbsent(\n+                    signal, k -> new ArrayList<>()).add(deploymentId);\n+        }\n+    }\n+\n+    private <T extends SignalDescBase> void removeTopics(Map<String, Map<T, Collection<String>>> topic2SignalBase,\n+                                                         String deploymentId,\n+                                                         Collection<T> signalsDesc) {\n+        for (T signal : signalsDesc) {\n+            String topic = topicFromSignal(signal);\n+            Map<T, Collection<String>> signals = topic2SignalBase.get(topic);\n+            if (signals != null) {\n+                Collection<String> deploymentIds = signals.get(signal);\n+                if (deploymentIds != null) {\n+                    deploymentIds.remove(deploymentId);\n+                    if (deploymentIds.isEmpty()) {\n+                        signals.remove(signal);\n+                        if (signals.isEmpty()) {\n+                            topic2SignalBase.remove(topic);\n+                        }\n+                    }\n+                }\n+\n+            }\n+        }\n+    }\n+\n+    private void updateRegistration(DeploymentEvent event, BiConsumer<String, ProcessDefinition> updater) {\n+        classes.put(event.getDeploymentId(), event.getDeployedUnit().getDeployedClasses());\n+        Set<String> topic2Register = new HashSet<>();\n+        changeRegistrationLock.lock();\n+        try {\n+            for (DeployedAsset asset : event.getDeployedUnit().getDeployedAssets()) {\n+                updater.accept(event.getDeploymentId(), (ProcessDefinition) asset);\n+            }\n+            topic2Register.addAll(topic2Signal.keySet());\n+            topic2Register.addAll(topic2Message.keySet());\n+        } finally {\n+            changeRegistrationLock.unlock();\n+        }\n+\n+        if (consumerReady.compareAndSet(false, true)) {\n+            logger.trace(\"Creating kafka consumer\");\n+            consumer = getKafkaConsumer();\n+            subscribe(topic2Register);\n+            notifyService =\n+                    new ThreadPoolExecutor(1, Integer.getInteger(KAFKA_EXTENSION_PREFIX + \"maxNotifyThreads\", 10), 60L,\n+                            TimeUnit.SECONDS, new LinkedBlockingQueue<>());\n+            Thread pollService = new Thread(this);\n+            pollService.start();\n+        }\n+        else {\n+            consumer.wakeup();\n+            subscribe(topic2Register);\n+        }\n+\n+    }\n+\n+    private void subscribe(Set<String> topic2Register) {\n+        consumerLock.lock();\n+        try {\n+            consumer.subscribe(topic2Register);\n+        } finally {\n+            consumerLock.unlock();\n+        }\n+        logger.debug(\"Updated kafka subscription list to these topics {}\", topic2Register);\n+    }\n+\n+    private static <T extends SignalDescBase> String topicFromSignal(T signal) {\n+        return System.getProperty(TOPIC_PREFIX + signal.getName(), signal.getName());\n+    }\n+\n+    @Override\n+    public void serverStarted() {\n+        // will use lazy initialization for consumer\n+    }\n+\n+    @Override\n+    public void createContainer(String id, KieContainerInstance kieContainerInstance, Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public boolean isUpdateContainerAllowed(String id,\n+                                            KieContainerInstance kieContainerInstance,\n+                                            Map<String, Object> parameters) {\n+        return false;\n+    }\n+\n+    @Override\n+    public void prepareContainerUpdate(String id,\n+                                       KieContainerInstance kieContainerInstance,\n+                                       Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public void updateContainer(String id, KieContainerInstance kieContainerInstance, Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public void disposeContainer(String id, KieContainerInstance kieContainerInstance, Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public List<Object> getAppComponents(SupportedTransports type) {\n+        return Collections.emptyList();\n+    }\n+\n+    @Override\n+    public <T> T getAppComponents(Class<T> serviceType) {\n+        return null;\n+    }\n+\n+    @Override\n+    public String getImplementedCapability() {\n+        return KieServerConstants.CAPABILITY_BPM_KAFKA;\n+    }\n+\n+    @Override\n+    public List<Object> getServices() {\n+        return Collections.emptyList();\n+    }\n+\n+    @Override\n+    public String getExtensionName() {\n+        return EXTENSION_NAME;\n+    }\n+\n+    @Override\n+    public Integer getStartOrder() {\n+        return 20;\n+    }\n+\n+    @Override\n+    public void run() {\n+        Duration duration =\n+                Duration.ofSeconds(Long.getLong(KAFKA_EXTENSION_PREFIX + \"poll.interval\", 10L));\n+        logger.trace(\"Start polling kafka consumer every {} seconds\", duration.getSeconds());\n+        while (consumerReady.get()) {\n+            if (isSubscribed()) {\n+                ConsumerRecords<String, byte[]> events = ConsumerRecords.empty();\n+                consumerLock.lock();\n+                try {\n+                    try {\n+                        events = consumer.poll(duration);\n+                    } catch (WakeupException ex) {\n+                        logger.trace(\"Kafka wait interrupted\");\n+                    } catch (Exception ex) {\n+                        logger.error(\"Error polling kafka consumer\", ex);\n+                    }\n+                } finally {\n+                    consumerLock.unlock();\n+                }\n+                if (consumerReady.get() && !events.isEmpty()) {\n+                    if (logger.isDebugEnabled()) {\n+                        Map<String, Integer> eventsPerTopic = new HashMap<>();\n+                        for (ConsumerRecord<String, byte[]> event : events) {\n+                            eventsPerTopic.compute(event.topic(), (k, v) -> v == null ? 1 : v++);\n+                        }\n+                        logger.debug(\"Number of events received per topic {}\", eventsPerTopic);\n+                    }\n+                    for (ConsumerRecord<String, byte[]> event : events) {\n+                        notifyService.submit(() -> processEvent(event));\n+                    }\n+                }\n+            }\n+        }\n+        logger.trace(\"Kafka polling stopped\");\n+    }\n+\n+    private boolean isSubscribed() {\n+        changeRegistrationLock.lock();\n+        try {\n+            return !topic2Message.isEmpty() || !topic2Signal.isEmpty();\n+        } finally {\n+            changeRegistrationLock.unlock();\n+        }\n+\n+    }\n+\n+    @FunctionalInterface\n+    private static interface Signaller {\n+        void signalEvent(String deploymentId, String signalName, Object data);\n+    }\n+\n+    private void processEvent(ConsumerRecord<String, byte[]> event) {\n+        changeRegistrationLock.lock();\n+        try {\n+            processEvent(topic2Signal, event, this::signalEvent);\n+            processEvent(topic2Message, event,\n+                    (deployment, signalName, data) -> signalEvent(deployment, \"Message-\" + signalName, data));\n+        } finally {\n+            changeRegistrationLock.unlock();\n+        }\n+    }\n+    \n+    private void signalEvent  (String deployment, String signalName, Object data) {\n+        processService.signalEvent(deployment,signalName, data);\n+    }\n+\n+    private <T extends SignalDescBase> void processEvent(Map<String, Map<T, Collection<String>>> topic2SignalBase,\n+                                                         ConsumerRecord<String, byte[]> event,\n+                                                         Signaller signaller) {\n+        Map<T, Collection<String>> signalInfo = topic2SignalBase.get(event.topic());\n+        if (signalInfo != null) {\n+            for (Map.Entry<T, Collection<String>> entry : signalInfo.entrySet())\n+                try {\n+                    String signalName = entry.getKey().getName();\n+                    for (String deploymentId : entry.getValue()) {\n+                        CloudEvent<?> cloudEvent = CloudEvent.read(event.value(), getDataClass(deploymentId, entry\n+                                .getKey()));", "originalCommit": "a95e2687e0fe78678090b8ee6dcb30f1a09dfdb6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODE4MzYxNQ==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r518183615", "bodyText": "Limitation docummented in bapl", "author": "fjtirado", "createdAt": "2020-11-05T16:25:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODA5NDY3Mg=="}], "type": "inlineReview", "revised_code": null}, {"oid": "a3f08ded394724d463262a6e934d9be600fab800", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/a3f08ded394724d463262a6e934d9be600fab800", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-11-05T16:13:11Z", "type": "forcePushed"}, {"oid": "7dce599fbdcbb724217d646951918e2c2412074a", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/7dce599fbdcbb724217d646951918e2c2412074a", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-11-05T16:35:15Z", "type": "forcePushed"}, {"oid": "ad0cfb89fa112f2a98b9419495ae25c836094dba", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/ad0cfb89fa112f2a98b9419495ae25c836094dba", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-11-05T16:43:14Z", "type": "forcePushed"}, {"oid": "e9d0b7b6f2393d893b75e8f783e10163fd179c1b", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/e9d0b7b6f2393d893b75e8f783e10163fd179c1b", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-11-05T17:12:18Z", "type": "forcePushed"}, {"oid": "b3cdbcd530a752855d2657df035376a16d5b541c", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/b3cdbcd530a752855d2657df035376a16d5b541c", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-11-05T17:27:09Z", "type": "forcePushed"}, {"oid": "b383dc295882ea537dda989cb83658f1016326f8", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/b383dc295882ea537dda989cb83658f1016326f8", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-11-05T17:38:29Z", "type": "forcePushed"}, {"oid": "6b6c758a858eb67417179f99d9af440200aaeb14", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/6b6c758a858eb67417179f99d9af440200aaeb14", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-11-05T17:39:06Z", "type": "forcePushed"}, {"oid": "19526fb11d032f56e2c6a03171fe675b72b52056", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/19526fb11d032f56e2c6a03171fe675b72b52056", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-11-05T17:41:33Z", "type": "forcePushed"}, {"oid": "66bd82c671d96ca07b334754c8cf6985ef7bb72e", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/66bd82c671d96ca07b334754c8cf6985ef7bb72e", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-11-06T08:38:22Z", "type": "forcePushed"}, {"oid": "cac11f114b888e52e2f4f5bd0a3a9912f16ab332", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/cac11f114b888e52e2f4f5bd0a3a9912f16ab332", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-11-06T08:39:17Z", "type": "forcePushed"}, {"oid": "8be9b5aedcfd3fbc9ce840a9c3101598b5e22aa1", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/8be9b5aedcfd3fbc9ce840a9c3101598b5e22aa1", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-11-06T08:59:13Z", "type": "forcePushed"}, {"oid": "af43ecf49d1bad0773753abb586837ea7760d0dd", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/af43ecf49d1bad0773753abb586837ea7760d0dd", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-11-06T12:32:28Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODcxNjk0Mw==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r518716943", "body": "shouldn't we try to `unsubscribe` from topics before closing the consumer? wdyt?", "bodyText": "shouldn't we try to unsubscribe from topics before closing the consumer? wdyt?", "bodyHTML": "<p dir=\"auto\">shouldn't we try to <code>unsubscribe</code> from topics before closing the consumer? wdyt?</p>", "author": "afalhambra", "createdAt": "2020-11-06T12:21:15Z", "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java", "diffHunk": "@@ -0,0 +1,492 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+*/\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.ThreadPoolExecutor;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.concurrent.locks.Condition;\n+import java.util.concurrent.locks.Lock;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.function.BiConsumer;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.errors.WakeupException;\n+import org.apache.kafka.common.serialization.ByteArrayDeserializer;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentEventListener;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedAsset;\n+import org.jbpm.services.api.model.MessageDesc;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.jbpm.services.api.model.SignalDesc;\n+import org.jbpm.services.api.model.SignalDescBase;\n+import org.kie.server.api.KieServerConstants;\n+import org.kie.server.services.api.KieContainerInstance;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.api.SupportedTransports;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.kie.server.services.jbpm.JbpmKieServerExtension;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KafkaServerExtension implements KieServerExtension, DeploymentEventListener, Runnable {\n+\n+    public static final String EXTENSION_NAME = \"Kafka\";\n+    static final String KAFKA_EXTENSION_PREFIX = \"org.kie.server.jbpm-kafka.ext.\";\n+    static final String TOPIC_PREFIX = KAFKA_EXTENSION_PREFIX + \"topics.\";\n+    private static final Logger logger = LoggerFactory.getLogger(KafkaServerExtension.class);\n+\n+    private AtomicBoolean initialized = new AtomicBoolean();\n+    // Kafka consumer\n+    private Consumer<String, byte[]> consumer;\n+    // JBPM services\n+    private ListenerSupport deploymentService;\n+    private ProcessService processService;\n+    // Executor thread for dispatching signals to jbpm core\n+    private AtomicReference<ExecutorService> notifyService = new AtomicReference<>();\n+    // registration and classes information\n+    private Map<String, Map<SignalDesc, Collection<String>>> topic2Signal = new HashMap<>();\n+    private Map<String, Map<MessageDesc, Collection<String>>> topic2Message = new HashMap<>();\n+    private Map<String, Collection<Class<?>>> classes = new ConcurrentHashMap<>();\n+    // synchronization variables\n+    private AtomicBoolean consumerReady = new AtomicBoolean();\n+    private Lock changeRegistrationLock = new ReentrantLock();\n+    private Lock consumerLock = new ReentrantLock();\n+    private Condition isSubscribedCond = changeRegistrationLock.newCondition();\n+\n+    @Override\n+    public boolean isInitialized() {\n+        return initialized.get();\n+    }\n+\n+    @Override\n+    public boolean isActive() {\n+        return !Boolean.getBoolean(KieServerConstants.KIE_KAFKA_SERVER_EXT_DISABLED);\n+    }\n+\n+    @Override\n+    public void init(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (initialized.get()) {\n+            logger.warn(\"Kafka extension already initialized\");\n+            return;\n+        }\n+\n+        KieServerExtension jbpmExt = registry.getServerExtension(JbpmKieServerExtension.EXTENSION_NAME);\n+        if (jbpmExt == null) {\n+            logger.warn(\"Extension \" + JbpmKieServerExtension.EXTENSION_NAME + \" is required\");\n+            return;\n+        }\n+\n+        for (Object service : jbpmExt.getServices()) {\n+            if (deploymentService == null && DeploymentService.class.isAssignableFrom(service.getClass())) {\n+                deploymentService = (ListenerSupport) service;\n+            } else if (processService == null && ProcessService.class.isAssignableFrom(service.getClass())) {\n+                processService = (ProcessService) service;\n+            }\n+            if (deploymentService != null && processService != null) {\n+                break;\n+            }\n+        }\n+        if (deploymentService == null) {\n+            throw new IllegalStateException(\"Cannot find deployment service\");\n+        }\n+        if (processService == null) {\n+            throw new IllegalStateException(\"Cannot find process service\");\n+        }\n+        deploymentService.addListener(this);\n+        initialized.set(true);\n+    }\n+\n+    @Override\n+    public void destroy(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (deploymentService != null) {\n+            deploymentService.removeListener(this);\n+        }\n+        if (consumerReady.compareAndSet(true, false)) {\n+            notifyService.getAndSet(null).shutdownNow();\n+            consumer.wakeup();\n+            consumerLock.lock();\n+            try {\n+                consumer.close();", "originalCommit": "8be9b5aedcfd3fbc9ce840a9c3101598b5e22aa1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODg1MjQ1OA==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r518852458", "bodyText": "Im not sure is required, but probably does not harm, so adding", "author": "fjtirado", "createdAt": "2020-11-06T16:11:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODcxNjk0Mw=="}], "type": "inlineReview", "revised_code": {"commit": "d63411f76bc17e334fe358f8c70b90e4dd1ac424", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\nindex 900609366..13f7d0bcd 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n", "chunk": "@@ -145,7 +145,8 @@ public class KafkaServerExtension implements KieServerExtension, DeploymentEvent\n             consumer.wakeup();\n             consumerLock.lock();\n             try {\n-                consumer.close();\n+                consumer.unsubscribe();\n+                consumer.close(Duration.ofSeconds(Long.getLong(KAFKA_EXTENSION_PREFIX + \"close.timeout\", 30L)));\n             } finally {\n                 consumerLock.unlock();\n             }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODcxNzg1OQ==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r518717859", "body": "would be beneficial to parameterized a timeout when closing consumer? wdyt?", "bodyText": "would be beneficial to parameterized a timeout when closing consumer? wdyt?", "bodyHTML": "<p dir=\"auto\">would be beneficial to parameterized a timeout when closing consumer? wdyt?</p>", "author": "afalhambra", "createdAt": "2020-11-06T12:23:11Z", "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java", "diffHunk": "@@ -0,0 +1,492 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+*/\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.ThreadPoolExecutor;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.concurrent.locks.Condition;\n+import java.util.concurrent.locks.Lock;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.function.BiConsumer;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.errors.WakeupException;\n+import org.apache.kafka.common.serialization.ByteArrayDeserializer;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentEventListener;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedAsset;\n+import org.jbpm.services.api.model.MessageDesc;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.jbpm.services.api.model.SignalDesc;\n+import org.jbpm.services.api.model.SignalDescBase;\n+import org.kie.server.api.KieServerConstants;\n+import org.kie.server.services.api.KieContainerInstance;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.api.SupportedTransports;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.kie.server.services.jbpm.JbpmKieServerExtension;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KafkaServerExtension implements KieServerExtension, DeploymentEventListener, Runnable {\n+\n+    public static final String EXTENSION_NAME = \"Kafka\";\n+    static final String KAFKA_EXTENSION_PREFIX = \"org.kie.server.jbpm-kafka.ext.\";\n+    static final String TOPIC_PREFIX = KAFKA_EXTENSION_PREFIX + \"topics.\";\n+    private static final Logger logger = LoggerFactory.getLogger(KafkaServerExtension.class);\n+\n+    private AtomicBoolean initialized = new AtomicBoolean();\n+    // Kafka consumer\n+    private Consumer<String, byte[]> consumer;\n+    // JBPM services\n+    private ListenerSupport deploymentService;\n+    private ProcessService processService;\n+    // Executor thread for dispatching signals to jbpm core\n+    private AtomicReference<ExecutorService> notifyService = new AtomicReference<>();\n+    // registration and classes information\n+    private Map<String, Map<SignalDesc, Collection<String>>> topic2Signal = new HashMap<>();\n+    private Map<String, Map<MessageDesc, Collection<String>>> topic2Message = new HashMap<>();\n+    private Map<String, Collection<Class<?>>> classes = new ConcurrentHashMap<>();\n+    // synchronization variables\n+    private AtomicBoolean consumerReady = new AtomicBoolean();\n+    private Lock changeRegistrationLock = new ReentrantLock();\n+    private Lock consumerLock = new ReentrantLock();\n+    private Condition isSubscribedCond = changeRegistrationLock.newCondition();\n+\n+    @Override\n+    public boolean isInitialized() {\n+        return initialized.get();\n+    }\n+\n+    @Override\n+    public boolean isActive() {\n+        return !Boolean.getBoolean(KieServerConstants.KIE_KAFKA_SERVER_EXT_DISABLED);\n+    }\n+\n+    @Override\n+    public void init(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (initialized.get()) {\n+            logger.warn(\"Kafka extension already initialized\");\n+            return;\n+        }\n+\n+        KieServerExtension jbpmExt = registry.getServerExtension(JbpmKieServerExtension.EXTENSION_NAME);\n+        if (jbpmExt == null) {\n+            logger.warn(\"Extension \" + JbpmKieServerExtension.EXTENSION_NAME + \" is required\");\n+            return;\n+        }\n+\n+        for (Object service : jbpmExt.getServices()) {\n+            if (deploymentService == null && DeploymentService.class.isAssignableFrom(service.getClass())) {\n+                deploymentService = (ListenerSupport) service;\n+            } else if (processService == null && ProcessService.class.isAssignableFrom(service.getClass())) {\n+                processService = (ProcessService) service;\n+            }\n+            if (deploymentService != null && processService != null) {\n+                break;\n+            }\n+        }\n+        if (deploymentService == null) {\n+            throw new IllegalStateException(\"Cannot find deployment service\");\n+        }\n+        if (processService == null) {\n+            throw new IllegalStateException(\"Cannot find process service\");\n+        }\n+        deploymentService.addListener(this);\n+        initialized.set(true);\n+    }\n+\n+    @Override\n+    public void destroy(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (deploymentService != null) {\n+            deploymentService.removeListener(this);\n+        }\n+        if (consumerReady.compareAndSet(true, false)) {\n+            notifyService.getAndSet(null).shutdownNow();\n+            consumer.wakeup();\n+            consumerLock.lock();\n+            try {\n+                consumer.close();", "originalCommit": "8be9b5aedcfd3fbc9ce840a9c3101598b5e22aa1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODg2MDI4OQ==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r518860289", "bodyText": "Property added, default 30 seconds, like no parameter close", "author": "fjtirado", "createdAt": "2020-11-06T16:24:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODcxNzg1OQ=="}], "type": "inlineReview", "revised_code": {"commit": "d63411f76bc17e334fe358f8c70b90e4dd1ac424", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\nindex 900609366..13f7d0bcd 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n", "chunk": "@@ -145,7 +145,8 @@ public class KafkaServerExtension implements KieServerExtension, DeploymentEvent\n             consumer.wakeup();\n             consumerLock.lock();\n             try {\n-                consumer.close();\n+                consumer.unsubscribe();\n+                consumer.close(Duration.ofSeconds(Long.getLong(KAFKA_EXTENSION_PREFIX + \"close.timeout\", 30L)));\n             } finally {\n                 consumerLock.unlock();\n             }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODczMjA3OQ==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r518732079", "body": "is there any chance for this to be `null`, if so, shouldn't we at least log warn message informing about an error while dispatching events? wdyt?", "bodyText": "is there any chance for this to be null, if so, shouldn't we at least log warn message informing about an error while dispatching events? wdyt?", "bodyHTML": "<p dir=\"auto\">is there any chance for this to be <code>null</code>, if so, shouldn't we at least log warn message informing about an error while dispatching events? wdyt?</p>", "author": "afalhambra", "createdAt": "2020-11-06T12:52:56Z", "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java", "diffHunk": "@@ -0,0 +1,497 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+*/\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.ThreadPoolExecutor;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.concurrent.locks.Condition;\n+import java.util.concurrent.locks.Lock;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.function.BiConsumer;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.errors.WakeupException;\n+import org.apache.kafka.common.serialization.ByteArrayDeserializer;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentEventListener;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedAsset;\n+import org.jbpm.services.api.model.MessageDesc;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.jbpm.services.api.model.SignalDesc;\n+import org.jbpm.services.api.model.SignalDescBase;\n+import org.kie.server.api.KieServerConstants;\n+import org.kie.server.services.api.KieContainerInstance;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.api.SupportedTransports;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.kie.server.services.jbpm.JbpmKieServerExtension;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KafkaServerExtension implements KieServerExtension, DeploymentEventListener, Runnable {\n+\n+    public static final String EXTENSION_NAME = \"Kafka\";\n+    static final String KAFKA_EXTENSION_PREFIX = \"org.kie.server.jbpm-kafka.ext.\";\n+    static final String TOPIC_PREFIX = KAFKA_EXTENSION_PREFIX + \"topics.\";\n+    private static final Logger logger = LoggerFactory.getLogger(KafkaServerExtension.class);\n+\n+    private AtomicBoolean initialized = new AtomicBoolean();\n+    // Kafka consumer\n+    private Consumer<String, byte[]> consumer;\n+    // JBPM services\n+    private ListenerSupport deploymentService;\n+    private ProcessService processService;\n+    // Executor thread for dispatching signals to jbpm core\n+    private AtomicReference<ExecutorService> notifyService = new AtomicReference<>();\n+    // registration and classes information\n+    private Map<String, Map<SignalDesc, Collection<String>>> topic2Signal = new HashMap<>();\n+    private Map<String, Map<MessageDesc, Collection<String>>> topic2Message = new HashMap<>();\n+    private Map<String, Collection<Class<?>>> classes = new ConcurrentHashMap<>();\n+    // synchronization variables\n+    private AtomicBoolean consumerReady = new AtomicBoolean();\n+    private Lock changeRegistrationLock = new ReentrantLock();\n+    private Lock consumerLock = new ReentrantLock();\n+    private Condition isSubscribedCond = changeRegistrationLock.newCondition();\n+\n+    @Override\n+    public boolean isInitialized() {\n+        return initialized.get();\n+    }\n+\n+    @Override\n+    public boolean isActive() {\n+        return !Boolean.parseBoolean(System.getProperty(KieServerConstants.KIE_KAFKA_SERVER_EXT_DISABLED, \"true\"));\n+    }\n+\n+    @Override\n+    public void init(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (initialized.get()) {\n+            logger.warn(\"Kafka extension already initialized\");\n+            return;\n+        }\n+\n+        KieServerExtension jbpmExt = registry.getServerExtension(JbpmKieServerExtension.EXTENSION_NAME);\n+        if (jbpmExt == null) {\n+            logger.warn(\"Extension \" + JbpmKieServerExtension.EXTENSION_NAME + \" is required\");\n+            return;\n+        }\n+\n+        for (Object service : jbpmExt.getServices()) {\n+            if (deploymentService == null && DeploymentService.class.isAssignableFrom(service.getClass())) {\n+                deploymentService = (ListenerSupport) service;\n+            } else if (processService == null && ProcessService.class.isAssignableFrom(service.getClass())) {\n+                processService = (ProcessService) service;\n+            }\n+            if (deploymentService != null && processService != null) {\n+                break;\n+            }\n+        }\n+        if (deploymentService == null) {\n+            throw new IllegalStateException(\"Cannot find deployment service\");\n+        }\n+        if (processService == null) {\n+            throw new IllegalStateException(\"Cannot find process service\");\n+        }\n+        deploymentService.addListener(this);\n+        initialized.set(true);\n+    }\n+\n+    @Override\n+    public void destroy(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (deploymentService != null) {\n+            deploymentService.removeListener(this);\n+        }\n+        if (consumerReady.compareAndSet(true, false)) {\n+            notifyService.getAndSet(null).shutdownNow();\n+            consumer.wakeup();\n+            consumerLock.lock();\n+            try {\n+                consumer.close();\n+            } finally {\n+                consumerLock.unlock();\n+            }\n+            consumer = null;\n+        }\n+        changeRegistrationLock.lock();\n+        try {\n+            topic2Signal.clear();\n+            topic2Message.clear();\n+            isSubscribedCond.signal();\n+        } finally {\n+            changeRegistrationLock.unlock();\n+        }\n+        classes.clear();\n+        processService = null;\n+        deploymentService = null;\n+        initialized.set(false);\n+    }\n+\n+    protected Consumer<String, byte[]> getKafkaConsumer() {\n+        Map<String, Object> props = new HashMap<>();\n+        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, System.getProperty(\n+                KAFKA_EXTENSION_PREFIX + \"boopstrap.servers\", \"localhost:9092\"));\n+        // read only committed events\n+        props.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, IsolationLevel.READ_COMMITTED.toString().toLowerCase());\n+        // do not automatically create topics by default\n+        props.put(ConsumerConfig.ALLOW_AUTO_CREATE_TOPICS_CONFIG, Boolean.getBoolean(\n+                KAFKA_EXTENSION_PREFIX + \"auto.create.topics\"));\n+        props.put(ConsumerConfig.GROUP_ID_CONFIG, System.getProperty(KAFKA_EXTENSION_PREFIX + \"group.id\",\n+                \"jbpm-consumer\"));\n+        return new KafkaConsumer<>(props, new StringDeserializer(), new ByteArrayDeserializer());\n+    }\n+\n+    @Override\n+    public void onDeploy(DeploymentEvent event) {\n+        updateRegistration(event, this::updateTopics);\n+    }\n+\n+    @Override\n+    public void onUnDeploy(DeploymentEvent event) {\n+        updateRegistration(event, this::removeTopics);\n+    }\n+\n+    @Override\n+    public void onActivate(DeploymentEvent event) {\n+        updateRegistration(event, this::updateTopics);\n+    }\n+\n+    @Override\n+    public void onDeactivate(DeploymentEvent event) {\n+        updateRegistration(event, this::removeTopics);\n+    }\n+\n+    private void updateTopics(String deploymentId, ProcessDefinition processDefinition) {\n+        updateTopics(topic2Signal, deploymentId, processDefinition.getSignalsDesc());\n+        updateTopics(topic2Message, deploymentId, processDefinition.getMessagesDesc());\n+    }\n+\n+    private void removeTopics(String deploymentId, ProcessDefinition processDefinition) {\n+        removeTopics(topic2Signal, deploymentId, processDefinition.getSignalsDesc());\n+        removeTopics(topic2Message, deploymentId, processDefinition.getMessagesDesc());\n+    }\n+\n+    private <T extends SignalDescBase> void updateTopics(Map<String, Map<T, Collection<String>>> topic2SignalBase,\n+                                                         String deploymentId,\n+                                                         Collection<T> signals) {\n+        for (T signal : signals) {\n+            topic2SignalBase.computeIfAbsent(topicFromSignal(signal), k -> new HashMap<>()).computeIfAbsent(\n+                    signal, k -> new ArrayList<>()).add(deploymentId);\n+        }\n+    }\n+\n+    private <T extends SignalDescBase> void removeTopics(Map<String, Map<T, Collection<String>>> topic2SignalBase,\n+                                                         String deploymentId,\n+                                                         Collection<T> signalsDesc) {\n+        for (T signal : signalsDesc) {\n+            String topic = topicFromSignal(signal);\n+            Map<T, Collection<String>> signals = topic2SignalBase.get(topic);\n+            if (signals != null) {\n+                Collection<String> deploymentIds = signals.get(signal);\n+                if (deploymentIds != null) {\n+                    deploymentIds.remove(deploymentId);\n+                    if (deploymentIds.isEmpty()) {\n+                        signals.remove(signal);\n+                        if (signals.isEmpty()) {\n+                            topic2SignalBase.remove(topic);\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    private void updateRegistration(DeploymentEvent event, BiConsumer<String, ProcessDefinition> updater) {\n+        classes.put(event.getDeploymentId(), event.getDeployedUnit().getDeployedClasses());\n+        Set<String> topic2Register = new HashSet<>();\n+        changeRegistrationLock.lock();\n+        try {\n+            for (DeployedAsset asset : event.getDeployedUnit().getDeployedAssets()) {\n+                updater.accept(event.getDeploymentId(), (ProcessDefinition) asset);\n+            }\n+            topic2Register.addAll(topic2Signal.keySet());\n+            topic2Register.addAll(topic2Message.keySet());\n+        } finally {\n+            changeRegistrationLock.unlock();\n+        }\n+\n+        if (!consumerReady.get() && topic2Register.isEmpty()) {\n+            logger.debug(\"There are no topics to subscribe and consumer is not active yet, so skipping\");\n+            return;\n+        }\n+\n+        if (consumerReady.compareAndSet(false, true)) {\n+            logger.trace(\"Creating kafka consumer\");\n+            consumer = getKafkaConsumer();\n+            subscribe(topic2Register);\n+            notifyService.set(\n+                    new ThreadPoolExecutor(1, Integer.getInteger(KAFKA_EXTENSION_PREFIX + \"maxNotifyThreads\", 10), 60L,\n+                            TimeUnit.SECONDS, new LinkedBlockingQueue<>()));\n+            new Thread(this).start();\n+        } else {\n+            consumer.wakeup();\n+            subscribe(topic2Register);\n+            if (!topic2Register.isEmpty()) {\n+                changeRegistrationLock.lock();\n+                try {\n+                    isSubscribedCond.signal();\n+                } finally {\n+                    changeRegistrationLock.unlock();\n+                }\n+            }\n+        }\n+\n+    }\n+\n+    private void subscribe(Set<String> topic2Register) {\n+        consumerLock.lock();\n+        try {\n+            consumer.subscribe(topic2Register);\n+        } finally {\n+            consumerLock.unlock();\n+        }\n+        logger.debug(\"Updated kafka subscription list to these topics {}\", topic2Register);\n+    }\n+\n+    private static <T extends SignalDescBase> String topicFromSignal(T signal) {\n+        return System.getProperty(TOPIC_PREFIX + signal.getName(), signal.getName());\n+    }\n+\n+    @Override\n+    public void serverStarted() {\n+        // will use lazy initialization for consumer\n+    }\n+\n+    @Override\n+    public void createContainer(String id, KieContainerInstance kieContainerInstance, Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public boolean isUpdateContainerAllowed(String id,\n+                                            KieContainerInstance kieContainerInstance,\n+                                            Map<String, Object> parameters) {\n+        return true;\n+    }\n+\n+    @Override\n+    public void prepareContainerUpdate(String id,\n+                                       KieContainerInstance kieContainerInstance,\n+                                       Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public void updateContainer(String id, KieContainerInstance kieContainerInstance, Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public void disposeContainer(String id, KieContainerInstance kieContainerInstance, Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public List<Object> getAppComponents(SupportedTransports type) {\n+        return Collections.emptyList();\n+    }\n+\n+    @Override\n+    public <T> T getAppComponents(Class<T> serviceType) {\n+        return null;\n+    }\n+\n+    @Override\n+    public String getImplementedCapability() {\n+        return KieServerConstants.CAPABILITY_BPM_KAFKA;\n+    }\n+\n+    @Override\n+    public List<Object> getServices() {\n+        return Collections.emptyList();\n+    }\n+\n+    @Override\n+    public String getExtensionName() {\n+        return EXTENSION_NAME;\n+    }\n+\n+    @Override\n+    public Integer getStartOrder() {\n+        return 20;\n+    }\n+\n+    @Override\n+    public void run() {\n+        Duration duration =\n+                Duration.ofSeconds(Long.getLong(KAFKA_EXTENSION_PREFIX + \"poll.interval\", 10L));\n+        logger.trace(\"Start polling kafka consumer every {} seconds\", duration.getSeconds());\n+        try {\n+            while (consumerReady.get()) {\n+                checkSubscribed();\n+                dispatchEvents(pollEvents(duration));\n+            }\n+        } catch (InterruptedException e) {\n+            logger.warn(\"Polling thread interrupted\", e);\n+            Thread.currentThread().interrupt();\n+        } catch (Exception e) {\n+            logger.error(\"Polling thread unexpectedly finished\", e);\n+        }\n+        logger.trace(\"Kafka polling stopped\");\n+    }\n+\n+    private void checkSubscribed() throws InterruptedException {\n+        changeRegistrationLock.lock();\n+        try {\n+            while (consumerReady.get() && topic2Signal.isEmpty() && topic2Message.isEmpty()) {\n+                isSubscribedCond.await();\n+            }\n+        } finally {\n+            changeRegistrationLock.unlock();\n+        }\n+    }\n+\n+    private ConsumerRecords<String, byte[]> pollEvents(Duration duration) {\n+        ConsumerRecords<String, byte[]> events = ConsumerRecords.empty();\n+        if (consumerReady.get()) {\n+            consumerLock.lock();\n+            try {\n+                events = consumer.poll(duration);\n+            } catch (WakeupException ex) {\n+                logger.trace(\"Kafka wait interrupted\");\n+            } catch (Exception ex) {\n+                logger.error(\"Error polling Kafka consumer\", ex);\n+            } finally {\n+                consumerLock.unlock();\n+            }\n+        }\n+        return events;\n+    }\n+\n+    private void dispatchEvents(ConsumerRecords<String, byte[]> events) {\n+        if (consumerReady.get() && !events.isEmpty()) {\n+            if (logger.isDebugEnabled()) {\n+                printEventsLog(events);\n+            }\n+            for (ConsumerRecord<String, byte[]> event : events) {\n+                if (notifyService.get() != null) {", "originalCommit": "af43ecf49d1bad0773753abb586837ea7760d0dd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODg2MDAwNw==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r518860007", "bodyText": "this will be null only when destroying the extension. so Im removing the check and if the exception ever happen, it will catched and printed", "author": "fjtirado", "createdAt": "2020-11-06T16:24:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODczMjA3OQ=="}], "type": "inlineReview", "revised_code": {"commit": "d63411f76bc17e334fe358f8c70b90e4dd1ac424", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\nindex 1f19e17f5..13f7d0bcd 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n", "chunk": "@@ -412,9 +421,7 @@ public class KafkaServerExtension implements KieServerExtension, DeploymentEvent\n                 printEventsLog(events);\n             }\n             for (ConsumerRecord<String, byte[]> event : events) {\n-                if (notifyService.get() != null) {\n-                    notifyService.get().submit(() -> processEvent(event));\n-                }\n+                notifyService.get().submit(() -> processEvent(event));\n             }\n         }\n     }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODczMjUzMg==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r518732532", "body": "`static` is redundant for inner interfaces\r\n```suggestion\r\n    private interface Signaller {\r\n```", "bodyText": "static is redundant for inner interfaces\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                private static interface Signaller {\n          \n          \n            \n                private interface Signaller {", "bodyHTML": "<p dir=\"auto\"><code>static</code> is redundant for inner interfaces</p>\n  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">    <span class=\"pl-k\">private</span> <span class=\"pl-k x x-first\">static</span><span class=\"x x-last\"> </span><span class=\"pl-k\">interface</span> <span class=\"pl-en\">Signaller</span> {</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">    <span class=\"pl-k\">private</span> <span class=\"pl-k\">interface</span> <span class=\"pl-en\">Signaller</span> {</td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "afalhambra", "createdAt": "2020-11-06T12:53:56Z", "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java", "diffHunk": "@@ -0,0 +1,497 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+*/\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.ThreadPoolExecutor;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.concurrent.locks.Condition;\n+import java.util.concurrent.locks.Lock;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.function.BiConsumer;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.errors.WakeupException;\n+import org.apache.kafka.common.serialization.ByteArrayDeserializer;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentEventListener;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedAsset;\n+import org.jbpm.services.api.model.MessageDesc;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.jbpm.services.api.model.SignalDesc;\n+import org.jbpm.services.api.model.SignalDescBase;\n+import org.kie.server.api.KieServerConstants;\n+import org.kie.server.services.api.KieContainerInstance;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.api.SupportedTransports;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.kie.server.services.jbpm.JbpmKieServerExtension;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KafkaServerExtension implements KieServerExtension, DeploymentEventListener, Runnable {\n+\n+    public static final String EXTENSION_NAME = \"Kafka\";\n+    static final String KAFKA_EXTENSION_PREFIX = \"org.kie.server.jbpm-kafka.ext.\";\n+    static final String TOPIC_PREFIX = KAFKA_EXTENSION_PREFIX + \"topics.\";\n+    private static final Logger logger = LoggerFactory.getLogger(KafkaServerExtension.class);\n+\n+    private AtomicBoolean initialized = new AtomicBoolean();\n+    // Kafka consumer\n+    private Consumer<String, byte[]> consumer;\n+    // JBPM services\n+    private ListenerSupport deploymentService;\n+    private ProcessService processService;\n+    // Executor thread for dispatching signals to jbpm core\n+    private AtomicReference<ExecutorService> notifyService = new AtomicReference<>();\n+    // registration and classes information\n+    private Map<String, Map<SignalDesc, Collection<String>>> topic2Signal = new HashMap<>();\n+    private Map<String, Map<MessageDesc, Collection<String>>> topic2Message = new HashMap<>();\n+    private Map<String, Collection<Class<?>>> classes = new ConcurrentHashMap<>();\n+    // synchronization variables\n+    private AtomicBoolean consumerReady = new AtomicBoolean();\n+    private Lock changeRegistrationLock = new ReentrantLock();\n+    private Lock consumerLock = new ReentrantLock();\n+    private Condition isSubscribedCond = changeRegistrationLock.newCondition();\n+\n+    @Override\n+    public boolean isInitialized() {\n+        return initialized.get();\n+    }\n+\n+    @Override\n+    public boolean isActive() {\n+        return !Boolean.parseBoolean(System.getProperty(KieServerConstants.KIE_KAFKA_SERVER_EXT_DISABLED, \"true\"));\n+    }\n+\n+    @Override\n+    public void init(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (initialized.get()) {\n+            logger.warn(\"Kafka extension already initialized\");\n+            return;\n+        }\n+\n+        KieServerExtension jbpmExt = registry.getServerExtension(JbpmKieServerExtension.EXTENSION_NAME);\n+        if (jbpmExt == null) {\n+            logger.warn(\"Extension \" + JbpmKieServerExtension.EXTENSION_NAME + \" is required\");\n+            return;\n+        }\n+\n+        for (Object service : jbpmExt.getServices()) {\n+            if (deploymentService == null && DeploymentService.class.isAssignableFrom(service.getClass())) {\n+                deploymentService = (ListenerSupport) service;\n+            } else if (processService == null && ProcessService.class.isAssignableFrom(service.getClass())) {\n+                processService = (ProcessService) service;\n+            }\n+            if (deploymentService != null && processService != null) {\n+                break;\n+            }\n+        }\n+        if (deploymentService == null) {\n+            throw new IllegalStateException(\"Cannot find deployment service\");\n+        }\n+        if (processService == null) {\n+            throw new IllegalStateException(\"Cannot find process service\");\n+        }\n+        deploymentService.addListener(this);\n+        initialized.set(true);\n+    }\n+\n+    @Override\n+    public void destroy(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (deploymentService != null) {\n+            deploymentService.removeListener(this);\n+        }\n+        if (consumerReady.compareAndSet(true, false)) {\n+            notifyService.getAndSet(null).shutdownNow();\n+            consumer.wakeup();\n+            consumerLock.lock();\n+            try {\n+                consumer.close();\n+            } finally {\n+                consumerLock.unlock();\n+            }\n+            consumer = null;\n+        }\n+        changeRegistrationLock.lock();\n+        try {\n+            topic2Signal.clear();\n+            topic2Message.clear();\n+            isSubscribedCond.signal();\n+        } finally {\n+            changeRegistrationLock.unlock();\n+        }\n+        classes.clear();\n+        processService = null;\n+        deploymentService = null;\n+        initialized.set(false);\n+    }\n+\n+    protected Consumer<String, byte[]> getKafkaConsumer() {\n+        Map<String, Object> props = new HashMap<>();\n+        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, System.getProperty(\n+                KAFKA_EXTENSION_PREFIX + \"boopstrap.servers\", \"localhost:9092\"));\n+        // read only committed events\n+        props.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, IsolationLevel.READ_COMMITTED.toString().toLowerCase());\n+        // do not automatically create topics by default\n+        props.put(ConsumerConfig.ALLOW_AUTO_CREATE_TOPICS_CONFIG, Boolean.getBoolean(\n+                KAFKA_EXTENSION_PREFIX + \"auto.create.topics\"));\n+        props.put(ConsumerConfig.GROUP_ID_CONFIG, System.getProperty(KAFKA_EXTENSION_PREFIX + \"group.id\",\n+                \"jbpm-consumer\"));\n+        return new KafkaConsumer<>(props, new StringDeserializer(), new ByteArrayDeserializer());\n+    }\n+\n+    @Override\n+    public void onDeploy(DeploymentEvent event) {\n+        updateRegistration(event, this::updateTopics);\n+    }\n+\n+    @Override\n+    public void onUnDeploy(DeploymentEvent event) {\n+        updateRegistration(event, this::removeTopics);\n+    }\n+\n+    @Override\n+    public void onActivate(DeploymentEvent event) {\n+        updateRegistration(event, this::updateTopics);\n+    }\n+\n+    @Override\n+    public void onDeactivate(DeploymentEvent event) {\n+        updateRegistration(event, this::removeTopics);\n+    }\n+\n+    private void updateTopics(String deploymentId, ProcessDefinition processDefinition) {\n+        updateTopics(topic2Signal, deploymentId, processDefinition.getSignalsDesc());\n+        updateTopics(topic2Message, deploymentId, processDefinition.getMessagesDesc());\n+    }\n+\n+    private void removeTopics(String deploymentId, ProcessDefinition processDefinition) {\n+        removeTopics(topic2Signal, deploymentId, processDefinition.getSignalsDesc());\n+        removeTopics(topic2Message, deploymentId, processDefinition.getMessagesDesc());\n+    }\n+\n+    private <T extends SignalDescBase> void updateTopics(Map<String, Map<T, Collection<String>>> topic2SignalBase,\n+                                                         String deploymentId,\n+                                                         Collection<T> signals) {\n+        for (T signal : signals) {\n+            topic2SignalBase.computeIfAbsent(topicFromSignal(signal), k -> new HashMap<>()).computeIfAbsent(\n+                    signal, k -> new ArrayList<>()).add(deploymentId);\n+        }\n+    }\n+\n+    private <T extends SignalDescBase> void removeTopics(Map<String, Map<T, Collection<String>>> topic2SignalBase,\n+                                                         String deploymentId,\n+                                                         Collection<T> signalsDesc) {\n+        for (T signal : signalsDesc) {\n+            String topic = topicFromSignal(signal);\n+            Map<T, Collection<String>> signals = topic2SignalBase.get(topic);\n+            if (signals != null) {\n+                Collection<String> deploymentIds = signals.get(signal);\n+                if (deploymentIds != null) {\n+                    deploymentIds.remove(deploymentId);\n+                    if (deploymentIds.isEmpty()) {\n+                        signals.remove(signal);\n+                        if (signals.isEmpty()) {\n+                            topic2SignalBase.remove(topic);\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    private void updateRegistration(DeploymentEvent event, BiConsumer<String, ProcessDefinition> updater) {\n+        classes.put(event.getDeploymentId(), event.getDeployedUnit().getDeployedClasses());\n+        Set<String> topic2Register = new HashSet<>();\n+        changeRegistrationLock.lock();\n+        try {\n+            for (DeployedAsset asset : event.getDeployedUnit().getDeployedAssets()) {\n+                updater.accept(event.getDeploymentId(), (ProcessDefinition) asset);\n+            }\n+            topic2Register.addAll(topic2Signal.keySet());\n+            topic2Register.addAll(topic2Message.keySet());\n+        } finally {\n+            changeRegistrationLock.unlock();\n+        }\n+\n+        if (!consumerReady.get() && topic2Register.isEmpty()) {\n+            logger.debug(\"There are no topics to subscribe and consumer is not active yet, so skipping\");\n+            return;\n+        }\n+\n+        if (consumerReady.compareAndSet(false, true)) {\n+            logger.trace(\"Creating kafka consumer\");\n+            consumer = getKafkaConsumer();\n+            subscribe(topic2Register);\n+            notifyService.set(\n+                    new ThreadPoolExecutor(1, Integer.getInteger(KAFKA_EXTENSION_PREFIX + \"maxNotifyThreads\", 10), 60L,\n+                            TimeUnit.SECONDS, new LinkedBlockingQueue<>()));\n+            new Thread(this).start();\n+        } else {\n+            consumer.wakeup();\n+            subscribe(topic2Register);\n+            if (!topic2Register.isEmpty()) {\n+                changeRegistrationLock.lock();\n+                try {\n+                    isSubscribedCond.signal();\n+                } finally {\n+                    changeRegistrationLock.unlock();\n+                }\n+            }\n+        }\n+\n+    }\n+\n+    private void subscribe(Set<String> topic2Register) {\n+        consumerLock.lock();\n+        try {\n+            consumer.subscribe(topic2Register);\n+        } finally {\n+            consumerLock.unlock();\n+        }\n+        logger.debug(\"Updated kafka subscription list to these topics {}\", topic2Register);\n+    }\n+\n+    private static <T extends SignalDescBase> String topicFromSignal(T signal) {\n+        return System.getProperty(TOPIC_PREFIX + signal.getName(), signal.getName());\n+    }\n+\n+    @Override\n+    public void serverStarted() {\n+        // will use lazy initialization for consumer\n+    }\n+\n+    @Override\n+    public void createContainer(String id, KieContainerInstance kieContainerInstance, Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public boolean isUpdateContainerAllowed(String id,\n+                                            KieContainerInstance kieContainerInstance,\n+                                            Map<String, Object> parameters) {\n+        return true;\n+    }\n+\n+    @Override\n+    public void prepareContainerUpdate(String id,\n+                                       KieContainerInstance kieContainerInstance,\n+                                       Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public void updateContainer(String id, KieContainerInstance kieContainerInstance, Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public void disposeContainer(String id, KieContainerInstance kieContainerInstance, Map<String, Object> parameters) {\n+        // will be done by listener\n+    }\n+\n+    @Override\n+    public List<Object> getAppComponents(SupportedTransports type) {\n+        return Collections.emptyList();\n+    }\n+\n+    @Override\n+    public <T> T getAppComponents(Class<T> serviceType) {\n+        return null;\n+    }\n+\n+    @Override\n+    public String getImplementedCapability() {\n+        return KieServerConstants.CAPABILITY_BPM_KAFKA;\n+    }\n+\n+    @Override\n+    public List<Object> getServices() {\n+        return Collections.emptyList();\n+    }\n+\n+    @Override\n+    public String getExtensionName() {\n+        return EXTENSION_NAME;\n+    }\n+\n+    @Override\n+    public Integer getStartOrder() {\n+        return 20;\n+    }\n+\n+    @Override\n+    public void run() {\n+        Duration duration =\n+                Duration.ofSeconds(Long.getLong(KAFKA_EXTENSION_PREFIX + \"poll.interval\", 10L));\n+        logger.trace(\"Start polling kafka consumer every {} seconds\", duration.getSeconds());\n+        try {\n+            while (consumerReady.get()) {\n+                checkSubscribed();\n+                dispatchEvents(pollEvents(duration));\n+            }\n+        } catch (InterruptedException e) {\n+            logger.warn(\"Polling thread interrupted\", e);\n+            Thread.currentThread().interrupt();\n+        } catch (Exception e) {\n+            logger.error(\"Polling thread unexpectedly finished\", e);\n+        }\n+        logger.trace(\"Kafka polling stopped\");\n+    }\n+\n+    private void checkSubscribed() throws InterruptedException {\n+        changeRegistrationLock.lock();\n+        try {\n+            while (consumerReady.get() && topic2Signal.isEmpty() && topic2Message.isEmpty()) {\n+                isSubscribedCond.await();\n+            }\n+        } finally {\n+            changeRegistrationLock.unlock();\n+        }\n+    }\n+\n+    private ConsumerRecords<String, byte[]> pollEvents(Duration duration) {\n+        ConsumerRecords<String, byte[]> events = ConsumerRecords.empty();\n+        if (consumerReady.get()) {\n+            consumerLock.lock();\n+            try {\n+                events = consumer.poll(duration);\n+            } catch (WakeupException ex) {\n+                logger.trace(\"Kafka wait interrupted\");\n+            } catch (Exception ex) {\n+                logger.error(\"Error polling Kafka consumer\", ex);\n+            } finally {\n+                consumerLock.unlock();\n+            }\n+        }\n+        return events;\n+    }\n+\n+    private void dispatchEvents(ConsumerRecords<String, byte[]> events) {\n+        if (consumerReady.get() && !events.isEmpty()) {\n+            if (logger.isDebugEnabled()) {\n+                printEventsLog(events);\n+            }\n+            for (ConsumerRecord<String, byte[]> event : events) {\n+                if (notifyService.get() != null) {\n+                    notifyService.get().submit(() -> processEvent(event));\n+                }\n+            }\n+        }\n+    }\n+\n+    private void printEventsLog(ConsumerRecords<String, byte[]> events) {\n+        Map<String, Integer> eventsPerTopic = new HashMap<>();\n+        for (ConsumerRecord<String, byte[]> event : events) {\n+            eventsPerTopic.compute(event.topic(), (k, v) -> v == null ? 1 : v++);\n+        }\n+        logger.debug(\"Number of events received per topic {}\", eventsPerTopic);\n+    }\n+\n+    @FunctionalInterface\n+    private static interface Signaller {", "originalCommit": "af43ecf49d1bad0773753abb586837ea7760d0dd", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "d63411f76bc17e334fe358f8c70b90e4dd1ac424", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\nindex 1f19e17f5..13f7d0bcd 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java\n", "chunk": "@@ -428,7 +435,7 @@ public class KafkaServerExtension implements KieServerExtension, DeploymentEvent\n     }\n \n     @FunctionalInterface\n-    private static interface Signaller {\n+    private interface Signaller {\n \n         void signalEvent(String deploymentId, String signalName, Object data);\n     }\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODc0NzE1NA==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r518747154", "body": "Shouldn't we also stop consumer when undeploying? just wondering, wdyt?", "bodyText": "Shouldn't we also stop consumer when undeploying? just wondering, wdyt?", "bodyHTML": "<p dir=\"auto\">Shouldn't we also stop consumer when undeploying? just wondering, wdyt?</p>", "author": "afalhambra", "createdAt": "2020-11-06T13:22:35Z", "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java", "diffHunk": "@@ -0,0 +1,497 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+*/\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.ThreadPoolExecutor;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.concurrent.locks.Condition;\n+import java.util.concurrent.locks.Lock;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.function.BiConsumer;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.errors.WakeupException;\n+import org.apache.kafka.common.serialization.ByteArrayDeserializer;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentEventListener;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedAsset;\n+import org.jbpm.services.api.model.MessageDesc;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.jbpm.services.api.model.SignalDesc;\n+import org.jbpm.services.api.model.SignalDescBase;\n+import org.kie.server.api.KieServerConstants;\n+import org.kie.server.services.api.KieContainerInstance;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.api.SupportedTransports;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.kie.server.services.jbpm.JbpmKieServerExtension;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KafkaServerExtension implements KieServerExtension, DeploymentEventListener, Runnable {\n+\n+    public static final String EXTENSION_NAME = \"Kafka\";\n+    static final String KAFKA_EXTENSION_PREFIX = \"org.kie.server.jbpm-kafka.ext.\";\n+    static final String TOPIC_PREFIX = KAFKA_EXTENSION_PREFIX + \"topics.\";\n+    private static final Logger logger = LoggerFactory.getLogger(KafkaServerExtension.class);\n+\n+    private AtomicBoolean initialized = new AtomicBoolean();\n+    // Kafka consumer\n+    private Consumer<String, byte[]> consumer;\n+    // JBPM services\n+    private ListenerSupport deploymentService;\n+    private ProcessService processService;\n+    // Executor thread for dispatching signals to jbpm core\n+    private AtomicReference<ExecutorService> notifyService = new AtomicReference<>();\n+    // registration and classes information\n+    private Map<String, Map<SignalDesc, Collection<String>>> topic2Signal = new HashMap<>();\n+    private Map<String, Map<MessageDesc, Collection<String>>> topic2Message = new HashMap<>();\n+    private Map<String, Collection<Class<?>>> classes = new ConcurrentHashMap<>();\n+    // synchronization variables\n+    private AtomicBoolean consumerReady = new AtomicBoolean();\n+    private Lock changeRegistrationLock = new ReentrantLock();\n+    private Lock consumerLock = new ReentrantLock();\n+    private Condition isSubscribedCond = changeRegistrationLock.newCondition();\n+\n+    @Override\n+    public boolean isInitialized() {\n+        return initialized.get();\n+    }\n+\n+    @Override\n+    public boolean isActive() {\n+        return !Boolean.parseBoolean(System.getProperty(KieServerConstants.KIE_KAFKA_SERVER_EXT_DISABLED, \"true\"));\n+    }\n+\n+    @Override\n+    public void init(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (initialized.get()) {\n+            logger.warn(\"Kafka extension already initialized\");\n+            return;\n+        }\n+\n+        KieServerExtension jbpmExt = registry.getServerExtension(JbpmKieServerExtension.EXTENSION_NAME);\n+        if (jbpmExt == null) {\n+            logger.warn(\"Extension \" + JbpmKieServerExtension.EXTENSION_NAME + \" is required\");\n+            return;\n+        }\n+\n+        for (Object service : jbpmExt.getServices()) {\n+            if (deploymentService == null && DeploymentService.class.isAssignableFrom(service.getClass())) {\n+                deploymentService = (ListenerSupport) service;\n+            } else if (processService == null && ProcessService.class.isAssignableFrom(service.getClass())) {\n+                processService = (ProcessService) service;\n+            }\n+            if (deploymentService != null && processService != null) {\n+                break;\n+            }\n+        }\n+        if (deploymentService == null) {\n+            throw new IllegalStateException(\"Cannot find deployment service\");\n+        }\n+        if (processService == null) {\n+            throw new IllegalStateException(\"Cannot find process service\");\n+        }\n+        deploymentService.addListener(this);\n+        initialized.set(true);\n+    }\n+\n+    @Override\n+    public void destroy(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (deploymentService != null) {\n+            deploymentService.removeListener(this);\n+        }\n+        if (consumerReady.compareAndSet(true, false)) {\n+            notifyService.getAndSet(null).shutdownNow();\n+            consumer.wakeup();\n+            consumerLock.lock();\n+            try {\n+                consumer.close();\n+            } finally {\n+                consumerLock.unlock();\n+            }\n+            consumer = null;\n+        }\n+        changeRegistrationLock.lock();\n+        try {\n+            topic2Signal.clear();\n+            topic2Message.clear();\n+            isSubscribedCond.signal();\n+        } finally {\n+            changeRegistrationLock.unlock();\n+        }\n+        classes.clear();\n+        processService = null;\n+        deploymentService = null;\n+        initialized.set(false);\n+    }\n+\n+    protected Consumer<String, byte[]> getKafkaConsumer() {\n+        Map<String, Object> props = new HashMap<>();\n+        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, System.getProperty(\n+                KAFKA_EXTENSION_PREFIX + \"boopstrap.servers\", \"localhost:9092\"));\n+        // read only committed events\n+        props.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, IsolationLevel.READ_COMMITTED.toString().toLowerCase());\n+        // do not automatically create topics by default\n+        props.put(ConsumerConfig.ALLOW_AUTO_CREATE_TOPICS_CONFIG, Boolean.getBoolean(\n+                KAFKA_EXTENSION_PREFIX + \"auto.create.topics\"));\n+        props.put(ConsumerConfig.GROUP_ID_CONFIG, System.getProperty(KAFKA_EXTENSION_PREFIX + \"group.id\",\n+                \"jbpm-consumer\"));\n+        return new KafkaConsumer<>(props, new StringDeserializer(), new ByteArrayDeserializer());\n+    }\n+\n+    @Override\n+    public void onDeploy(DeploymentEvent event) {\n+        updateRegistration(event, this::updateTopics);\n+    }\n+\n+    @Override\n+    public void onUnDeploy(DeploymentEvent event) {", "originalCommit": "af43ecf49d1bad0773753abb586837ea7760d0dd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODg1NTQ1Nw==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r518855457", "bodyText": "No, we are undeploying one container, there might be other containers listening for events", "author": "fjtirado", "createdAt": "2020-11-06T16:16:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODc0NzE1NA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODc0NzMyNg==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r518747326", "body": "same as above", "bodyText": "same as above", "bodyHTML": "<p dir=\"auto\">same as above</p>", "author": "afalhambra", "createdAt": "2020-11-06T13:22:57Z", "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/main/java/org/kie/server/services/jbpm/kafka/KafkaServerExtension.java", "diffHunk": "@@ -0,0 +1,497 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+*/\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.io.IOException;\n+import java.text.ParseException;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.ThreadPoolExecutor;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.concurrent.locks.Condition;\n+import java.util.concurrent.locks.Lock;\n+import java.util.concurrent.locks.ReentrantLock;\n+import java.util.function.BiConsumer;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.ConsumerRecords;\n+import org.apache.kafka.clients.consumer.KafkaConsumer;\n+import org.apache.kafka.common.IsolationLevel;\n+import org.apache.kafka.common.errors.WakeupException;\n+import org.apache.kafka.common.serialization.ByteArrayDeserializer;\n+import org.apache.kafka.common.serialization.StringDeserializer;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentEventListener;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedAsset;\n+import org.jbpm.services.api.model.MessageDesc;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.jbpm.services.api.model.SignalDesc;\n+import org.jbpm.services.api.model.SignalDescBase;\n+import org.kie.server.api.KieServerConstants;\n+import org.kie.server.services.api.KieContainerInstance;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.api.SupportedTransports;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.kie.server.services.jbpm.JbpmKieServerExtension;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KafkaServerExtension implements KieServerExtension, DeploymentEventListener, Runnable {\n+\n+    public static final String EXTENSION_NAME = \"Kafka\";\n+    static final String KAFKA_EXTENSION_PREFIX = \"org.kie.server.jbpm-kafka.ext.\";\n+    static final String TOPIC_PREFIX = KAFKA_EXTENSION_PREFIX + \"topics.\";\n+    private static final Logger logger = LoggerFactory.getLogger(KafkaServerExtension.class);\n+\n+    private AtomicBoolean initialized = new AtomicBoolean();\n+    // Kafka consumer\n+    private Consumer<String, byte[]> consumer;\n+    // JBPM services\n+    private ListenerSupport deploymentService;\n+    private ProcessService processService;\n+    // Executor thread for dispatching signals to jbpm core\n+    private AtomicReference<ExecutorService> notifyService = new AtomicReference<>();\n+    // registration and classes information\n+    private Map<String, Map<SignalDesc, Collection<String>>> topic2Signal = new HashMap<>();\n+    private Map<String, Map<MessageDesc, Collection<String>>> topic2Message = new HashMap<>();\n+    private Map<String, Collection<Class<?>>> classes = new ConcurrentHashMap<>();\n+    // synchronization variables\n+    private AtomicBoolean consumerReady = new AtomicBoolean();\n+    private Lock changeRegistrationLock = new ReentrantLock();\n+    private Lock consumerLock = new ReentrantLock();\n+    private Condition isSubscribedCond = changeRegistrationLock.newCondition();\n+\n+    @Override\n+    public boolean isInitialized() {\n+        return initialized.get();\n+    }\n+\n+    @Override\n+    public boolean isActive() {\n+        return !Boolean.parseBoolean(System.getProperty(KieServerConstants.KIE_KAFKA_SERVER_EXT_DISABLED, \"true\"));\n+    }\n+\n+    @Override\n+    public void init(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (initialized.get()) {\n+            logger.warn(\"Kafka extension already initialized\");\n+            return;\n+        }\n+\n+        KieServerExtension jbpmExt = registry.getServerExtension(JbpmKieServerExtension.EXTENSION_NAME);\n+        if (jbpmExt == null) {\n+            logger.warn(\"Extension \" + JbpmKieServerExtension.EXTENSION_NAME + \" is required\");\n+            return;\n+        }\n+\n+        for (Object service : jbpmExt.getServices()) {\n+            if (deploymentService == null && DeploymentService.class.isAssignableFrom(service.getClass())) {\n+                deploymentService = (ListenerSupport) service;\n+            } else if (processService == null && ProcessService.class.isAssignableFrom(service.getClass())) {\n+                processService = (ProcessService) service;\n+            }\n+            if (deploymentService != null && processService != null) {\n+                break;\n+            }\n+        }\n+        if (deploymentService == null) {\n+            throw new IllegalStateException(\"Cannot find deployment service\");\n+        }\n+        if (processService == null) {\n+            throw new IllegalStateException(\"Cannot find process service\");\n+        }\n+        deploymentService.addListener(this);\n+        initialized.set(true);\n+    }\n+\n+    @Override\n+    public void destroy(KieServerImpl kieServer, KieServerRegistry registry) {\n+        if (deploymentService != null) {\n+            deploymentService.removeListener(this);\n+        }\n+        if (consumerReady.compareAndSet(true, false)) {\n+            notifyService.getAndSet(null).shutdownNow();\n+            consumer.wakeup();\n+            consumerLock.lock();\n+            try {\n+                consumer.close();\n+            } finally {\n+                consumerLock.unlock();\n+            }\n+            consumer = null;\n+        }\n+        changeRegistrationLock.lock();\n+        try {\n+            topic2Signal.clear();\n+            topic2Message.clear();\n+            isSubscribedCond.signal();\n+        } finally {\n+            changeRegistrationLock.unlock();\n+        }\n+        classes.clear();\n+        processService = null;\n+        deploymentService = null;\n+        initialized.set(false);\n+    }\n+\n+    protected Consumer<String, byte[]> getKafkaConsumer() {\n+        Map<String, Object> props = new HashMap<>();\n+        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, System.getProperty(\n+                KAFKA_EXTENSION_PREFIX + \"boopstrap.servers\", \"localhost:9092\"));\n+        // read only committed events\n+        props.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, IsolationLevel.READ_COMMITTED.toString().toLowerCase());\n+        // do not automatically create topics by default\n+        props.put(ConsumerConfig.ALLOW_AUTO_CREATE_TOPICS_CONFIG, Boolean.getBoolean(\n+                KAFKA_EXTENSION_PREFIX + \"auto.create.topics\"));\n+        props.put(ConsumerConfig.GROUP_ID_CONFIG, System.getProperty(KAFKA_EXTENSION_PREFIX + \"group.id\",\n+                \"jbpm-consumer\"));\n+        return new KafkaConsumer<>(props, new StringDeserializer(), new ByteArrayDeserializer());\n+    }\n+\n+    @Override\n+    public void onDeploy(DeploymentEvent event) {\n+        updateRegistration(event, this::updateTopics);\n+    }\n+\n+    @Override\n+    public void onUnDeploy(DeploymentEvent event) {\n+        updateRegistration(event, this::removeTopics);\n+    }\n+\n+    @Override\n+    public void onActivate(DeploymentEvent event) {\n+        updateRegistration(event, this::updateTopics);\n+    }\n+\n+    @Override\n+    public void onDeactivate(DeploymentEvent event) {\n+        updateRegistration(event, this::removeTopics);", "originalCommit": "af43ecf49d1bad0773753abb586837ea7760d0dd", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODgwNDIzNg==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r518804236", "body": "`Long.getLong(KafkaServerExtension.KAFKA_EXTENSION_PREFIX + \"poll.interval\", 1L) * 2000` will always return `2` seconds as the property `org.kie.server.jbpm-kafka.ext.poll.interval` is not defined anywhere in the test. \r\n\r\nNot an issue, but I was thinking about testing all these different sets of properties and make sure it behaves properly", "bodyText": "Long.getLong(KafkaServerExtension.KAFKA_EXTENSION_PREFIX + \"poll.interval\", 1L) * 2000 will always return 2 seconds as the property org.kie.server.jbpm-kafka.ext.poll.interval is not defined anywhere in the test.\nNot an issue, but I was thinking about testing all these different sets of properties and make sure it behaves properly", "bodyHTML": "<p dir=\"auto\"><code>Long.getLong(KafkaServerExtension.KAFKA_EXTENSION_PREFIX + \"poll.interval\", 1L) * 2000</code> will always return <code>2</code> seconds as the property <code>org.kie.server.jbpm-kafka.ext.poll.interval</code> is not defined anywhere in the test.</p>\n<p dir=\"auto\">Not an issue, but I was thinking about testing all these different sets of properties and make sure it behaves properly</p>", "author": "afalhambra", "createdAt": "2020-11-06T14:57:10Z", "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KafkaServerExtensionTest.java", "diffHunk": "@@ -0,0 +1,237 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.MockConsumer;\n+import org.apache.kafka.clients.consumer.OffsetResetStrategy;\n+import org.apache.kafka.common.TopicPartition;\n+import org.jbpm.bpmn2.core.Message;\n+import org.jbpm.bpmn2.core.Signal;\n+import org.jbpm.kie.services.impl.model.MessageDescImpl;\n+import org.jbpm.kie.services.impl.model.SignalDescImpl;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedUnit;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.mockito.Mockito;\n+import org.mockito.verification.VerificationMode;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.junit.Assert.assertTrue;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.timeout;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+import static org.mockito.Mockito.withSettings;\n+\n+public class KafkaServerExtensionTest {\n+\n+    private static class MockKafkaServerExtension extends KafkaServerExtension {\n+\n+        private MockConsumer<String, byte[]> consumer;\n+\n+        public MockKafkaServerExtension(MockConsumer<String, byte[]> consumer) {\n+            this.consumer = consumer;\n+        }\n+\n+        protected Consumer<String, byte[]> getKafkaConsumer() {\n+            return consumer;\n+        }\n+\n+        public void setKafkaConsumer(MockConsumer<String, byte[]> consumer) {\n+            this.consumer = consumer;\n+        }\n+    }\n+\n+    private ProcessService processService;\n+    private MockKafkaServerExtension extension;\n+    private KieServerImpl server;\n+    private KieServerRegistry registry;\n+    private DeployedUnit deployedUnit;\n+    private ProcessDefinition processDefinition;\n+    private MockConsumer<String, byte[]> mockConsumer;\n+    private static Logger logger = LoggerFactory.getLogger(KafkaServerExtensionTest.class);\n+\n+\n+    @Before\n+    public void setup() {\n+        mockConsumer = new MockConsumer<>(OffsetResetStrategy.EARLIEST);\n+        extension = new MockKafkaServerExtension(mockConsumer);\n+        server = mock(KieServerImpl.class);\n+        registry = mock(KieServerRegistry.class);\n+        KieServerExtension serverExtension = mock(KieServerExtension.class);\n+        when(registry.getServerExtension(Mockito.anyString())).thenReturn(serverExtension);\n+        ListenerSupport deployService = mock(ListenerSupport.class, withSettings().extraInterfaces(\n+                DeploymentService.class));\n+        processService = mock(ProcessService.class);\n+        when(serverExtension.getServices()).thenReturn(Arrays.asList(deployService, processService));\n+        deployedUnit = mock(DeployedUnit.class);\n+        processDefinition = mock(ProcessDefinition.class);\n+        when(deployedUnit.getDeployedAssets()).thenReturn(Collections.singletonList(processDefinition));\n+        extension.init(server, registry);\n+        extension.serverStarted();\n+    }\n+\n+    @After\n+    public void close() {\n+        extension.destroy(server, registry);\n+    }\n+\n+    @Test\n+    public void testKafkaServerExecutorSignal() {\n+        when(processDefinition.getSignalsDesc()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+                new Signal(\"MySignal\", \"MySignal\", \"String\"))));\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy1\", deployedUnit));\n+        publishEvent(\"MySignal\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"javierito\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy1\", \"MySignal\", \"javierito\");\n+    }\n+\n+    @Test\n+    public void testKafkaSubscriptionChange() {\n+        when(processDefinition.getSignalsDesc()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+                new Signal(\"MySignal\", \"MySignal\", \"String\"))));\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy1\", deployedUnit));\n+        publishEvent(\"MySignal\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"javierito\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy1\", \"MySignal\", \"javierito\");\n+        when(processDefinition.getSignalsDesc()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+                new Signal(\"ChangedSignal\", \"ChangedSignal\", \"String\"))));\n+        extension.onActivate(new DeploymentEvent(\"MyDeploy1\", deployedUnit));\n+        publishEvent(\"ChangedSignal\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"javierito\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy1\", \"ChangedSignal\", \"javierito\");\n+    }\n+\n+    @Test\n+    public void testKafkaSubscriptionEmpty() {\n+        when(processDefinition.getSignalsDesc()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+                new Signal(\"MySignal\", \"MySignal\", \"String\"))));\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy1\", deployedUnit));\n+        publishEvent(\"MySignal\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"javierito\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy1\", \"MySignal\", \"javierito\");\n+        extension.onUnDeploy(new DeploymentEvent(\"MyDeploy1\", deployedUnit));\n+        when(processDefinition.getSignalsDesc()).thenReturn(Collections.emptyList());\n+        extension.onActivate(new DeploymentEvent(\"MyDeploy1\", deployedUnit));\n+        publishEventWithoutTopicCheck(\"ChangedSignal\",\n+                \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"javierito\\\"}\");\n+        verify(processService, getTimeout(0)).signalEvent(\"MyDeploy1\", \"ChangedSignal\", \"javierito\");\n+        when(processDefinition.getSignalsDesc()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+                new Signal(\"MySignal\", \"NewSignal\", \"String\"))));\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy1\", deployedUnit));\n+        publishEvent(\"NewSignal\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"javierito\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy1\", \"NewSignal\", \"javierito\");\n+    }\n+\n+    @Test\n+    public void testKafkaServerExecutorMessage() {\n+        Message msg = new Message(\"MyMessage\");\n+        msg.setName(\"Hello\");\n+        msg.setType(\"String\");\n+        when(processDefinition.getMessagesDesc()).thenReturn(Collections.singletonList(MessageDescImpl.from(msg)));\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy2\", deployedUnit));\n+        publishEvent(\"Hello\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"pepe\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy2\", \"Message-Hello\", \"pepe\");\n+    }\n+\n+    @Test\n+    public void testKafkaServerExecutorMessageTopic() {\n+        final String topicProperty = KafkaServerExtension.TOPIC_PREFIX + \"Hello\";\n+        System.setProperty(topicProperty, \"MyTopic\");\n+        try {\n+            Message msg = new Message(\"MyMessage\");\n+            msg.setName(\"Hello\");\n+            msg.setType(\"String\");\n+            when(processDefinition.getMessagesDesc()).thenReturn(Collections.singletonList(MessageDescImpl.from(\n+                    msg)));\n+            extension.onDeploy(new DeploymentEvent(\"MyDeploy3\", deployedUnit));\n+            publishEvent(\"MyTopic\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"pepe\\\"}\");\n+            verify(processService, getTimeout()).signalEvent(\"MyDeploy3\", \"Message-Hello\", \"pepe\");\n+        } finally {\n+            System.clearProperty(topicProperty);\n+        }\n+    }\n+\n+    @Test\n+    public void testWithDestroy() {\n+        when(processDefinition.getSignalsDesc()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+                new Signal(\"MySignal\", \"MySignal2\", \"String\"))));\n+        Message msg = new Message(\"MyMessage\");\n+        msg.setName(\"Hello2\");\n+        msg.setType(\"String\");\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy4\", deployedUnit));\n+        publishEvent(\"MySignal2\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"javierito\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy4\", \"MySignal2\", \"javierito\");\n+        extension.destroy(server, registry);\n+        mockConsumer = new MockConsumer<String, byte[]>(OffsetResetStrategy.EARLIEST);\n+        when(processDefinition.getSignalsDesc()).thenReturn(Collections.emptyList());\n+        when(processDefinition.getMessagesDesc()).thenReturn(Collections.singletonList(MessageDescImpl.from(\n+                msg)));\n+        extension.setKafkaConsumer(mockConsumer);\n+        extension.init(server, registry);\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy5\", deployedUnit));\n+        publishEvent(\"Hello2\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"pepe\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy5\", \"Message-Hello2\", \"pepe\");\n+    }\n+\n+\n+    private VerificationMode getTimeout() {\n+        return getTimeout(1);\n+    }\n+\n+    private VerificationMode getTimeout(int times) {\n+        return timeout(Long.getLong(KafkaServerExtension.KAFKA_EXTENSION_PREFIX + \"poll.interval\", 1L) * 2000).times(", "originalCommit": "af43ecf49d1bad0773753abb586837ea7760d0dd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODg2MDU1MQ==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r518860551", "bodyText": "Ill test that one, other I think should be tested by integration test", "author": "fjtirado", "createdAt": "2020-11-06T16:24:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODgwNDIzNg=="}], "type": "inlineReview", "revised_code": {"commit": "d63411f76bc17e334fe358f8c70b90e4dd1ac424", "changed_code": [{"header": "diff --git a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KafkaServerExtensionTest.java b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KafkaServerExtensionTest.java\nindex 2c1da5943..08b3169d0 100644\n--- a/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KafkaServerExtensionTest.java\n+++ b/kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KafkaServerExtensionTest.java\n", "chunk": "@@ -208,17 +286,12 @@ public class KafkaServerExtensionTest {\n     }\n \n     private VerificationMode getTimeout(int times) {\n-        return timeout(Long.getLong(KafkaServerExtension.KAFKA_EXTENSION_PREFIX + \"poll.interval\", 1L) * 2000).times(\n-                times);\n+        return timeout(TIMEOUT * 1000).times(times);\n     }\n \n     private void publishEvent(String topic, String cloudEventText) {\n         Set<String> topics = mockConsumer.subscription();\n         assertTrue(\"Topic \" + topic + \" not found\", topics.contains(topic));\n-        publishEventWithoutTopicCheck(topic, cloudEventText);\n-    }\n-\n-    private void publishEventWithoutTopicCheck(String topic, String cloudEventText) {\n         List<TopicPartition> partitions = Collections.singletonList(new TopicPartition(topic, 0));\n         Map<TopicPartition, Long> partitionsBeginningMap = new HashMap<>();\n         Map<TopicPartition, Long> partitionsEndMap = new HashMap<>();\n", "next_change": null}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODgyOTQ4Mw==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r518829483", "body": "It would be nice to check some other data structure for the cloudEvent rather than always a String.", "bodyText": "It would be nice to check some other data structure for the cloudEvent rather than always a String.", "bodyHTML": "<p dir=\"auto\">It would be nice to check some other data structure for the cloudEvent rather than always a String.</p>", "author": "afalhambra", "createdAt": "2020-11-06T15:34:42Z", "path": "kie-server-parent/kie-server-services/kie-server-services-kafka/src/test/java/org/kie/server/services/jbpm/kafka/KafkaServerExtensionTest.java", "diffHunk": "@@ -0,0 +1,237 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.kie.server.services.jbpm.kafka;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+\n+import org.apache.kafka.clients.consumer.Consumer;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.apache.kafka.clients.consumer.MockConsumer;\n+import org.apache.kafka.clients.consumer.OffsetResetStrategy;\n+import org.apache.kafka.common.TopicPartition;\n+import org.jbpm.bpmn2.core.Message;\n+import org.jbpm.bpmn2.core.Signal;\n+import org.jbpm.kie.services.impl.model.MessageDescImpl;\n+import org.jbpm.kie.services.impl.model.SignalDescImpl;\n+import org.jbpm.services.api.DeploymentEvent;\n+import org.jbpm.services.api.DeploymentService;\n+import org.jbpm.services.api.ListenerSupport;\n+import org.jbpm.services.api.ProcessService;\n+import org.jbpm.services.api.model.DeployedUnit;\n+import org.jbpm.services.api.model.ProcessDefinition;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.kie.server.services.api.KieServerExtension;\n+import org.kie.server.services.api.KieServerRegistry;\n+import org.kie.server.services.impl.KieServerImpl;\n+import org.mockito.Mockito;\n+import org.mockito.verification.VerificationMode;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.junit.Assert.assertTrue;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.timeout;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+import static org.mockito.Mockito.withSettings;\n+\n+public class KafkaServerExtensionTest {\n+\n+    private static class MockKafkaServerExtension extends KafkaServerExtension {\n+\n+        private MockConsumer<String, byte[]> consumer;\n+\n+        public MockKafkaServerExtension(MockConsumer<String, byte[]> consumer) {\n+            this.consumer = consumer;\n+        }\n+\n+        protected Consumer<String, byte[]> getKafkaConsumer() {\n+            return consumer;\n+        }\n+\n+        public void setKafkaConsumer(MockConsumer<String, byte[]> consumer) {\n+            this.consumer = consumer;\n+        }\n+    }\n+\n+    private ProcessService processService;\n+    private MockKafkaServerExtension extension;\n+    private KieServerImpl server;\n+    private KieServerRegistry registry;\n+    private DeployedUnit deployedUnit;\n+    private ProcessDefinition processDefinition;\n+    private MockConsumer<String, byte[]> mockConsumer;\n+    private static Logger logger = LoggerFactory.getLogger(KafkaServerExtensionTest.class);\n+\n+\n+    @Before\n+    public void setup() {\n+        mockConsumer = new MockConsumer<>(OffsetResetStrategy.EARLIEST);\n+        extension = new MockKafkaServerExtension(mockConsumer);\n+        server = mock(KieServerImpl.class);\n+        registry = mock(KieServerRegistry.class);\n+        KieServerExtension serverExtension = mock(KieServerExtension.class);\n+        when(registry.getServerExtension(Mockito.anyString())).thenReturn(serverExtension);\n+        ListenerSupport deployService = mock(ListenerSupport.class, withSettings().extraInterfaces(\n+                DeploymentService.class));\n+        processService = mock(ProcessService.class);\n+        when(serverExtension.getServices()).thenReturn(Arrays.asList(deployService, processService));\n+        deployedUnit = mock(DeployedUnit.class);\n+        processDefinition = mock(ProcessDefinition.class);\n+        when(deployedUnit.getDeployedAssets()).thenReturn(Collections.singletonList(processDefinition));\n+        extension.init(server, registry);\n+        extension.serverStarted();\n+    }\n+\n+    @After\n+    public void close() {\n+        extension.destroy(server, registry);\n+    }\n+\n+    @Test\n+    public void testKafkaServerExecutorSignal() {\n+        when(processDefinition.getSignalsDesc()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+                new Signal(\"MySignal\", \"MySignal\", \"String\"))));\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy1\", deployedUnit));\n+        publishEvent(\"MySignal\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"javierito\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy1\", \"MySignal\", \"javierito\");\n+    }\n+\n+    @Test\n+    public void testKafkaSubscriptionChange() {\n+        when(processDefinition.getSignalsDesc()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+                new Signal(\"MySignal\", \"MySignal\", \"String\"))));\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy1\", deployedUnit));\n+        publishEvent(\"MySignal\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"javierito\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy1\", \"MySignal\", \"javierito\");\n+        when(processDefinition.getSignalsDesc()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+                new Signal(\"ChangedSignal\", \"ChangedSignal\", \"String\"))));\n+        extension.onActivate(new DeploymentEvent(\"MyDeploy1\", deployedUnit));\n+        publishEvent(\"ChangedSignal\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"javierito\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy1\", \"ChangedSignal\", \"javierito\");\n+    }\n+\n+    @Test\n+    public void testKafkaSubscriptionEmpty() {\n+        when(processDefinition.getSignalsDesc()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+                new Signal(\"MySignal\", \"MySignal\", \"String\"))));\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy1\", deployedUnit));\n+        publishEvent(\"MySignal\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"javierito\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy1\", \"MySignal\", \"javierito\");\n+        extension.onUnDeploy(new DeploymentEvent(\"MyDeploy1\", deployedUnit));\n+        when(processDefinition.getSignalsDesc()).thenReturn(Collections.emptyList());\n+        extension.onActivate(new DeploymentEvent(\"MyDeploy1\", deployedUnit));\n+        publishEventWithoutTopicCheck(\"ChangedSignal\",\n+                \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"javierito\\\"}\");\n+        verify(processService, getTimeout(0)).signalEvent(\"MyDeploy1\", \"ChangedSignal\", \"javierito\");\n+        when(processDefinition.getSignalsDesc()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+                new Signal(\"MySignal\", \"NewSignal\", \"String\"))));\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy1\", deployedUnit));\n+        publishEvent(\"NewSignal\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"javierito\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy1\", \"NewSignal\", \"javierito\");\n+    }\n+\n+    @Test\n+    public void testKafkaServerExecutorMessage() {\n+        Message msg = new Message(\"MyMessage\");\n+        msg.setName(\"Hello\");\n+        msg.setType(\"String\");\n+        when(processDefinition.getMessagesDesc()).thenReturn(Collections.singletonList(MessageDescImpl.from(msg)));\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy2\", deployedUnit));\n+        publishEvent(\"Hello\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"pepe\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy2\", \"Message-Hello\", \"pepe\");\n+    }\n+\n+    @Test\n+    public void testKafkaServerExecutorMessageTopic() {\n+        final String topicProperty = KafkaServerExtension.TOPIC_PREFIX + \"Hello\";\n+        System.setProperty(topicProperty, \"MyTopic\");\n+        try {\n+            Message msg = new Message(\"MyMessage\");\n+            msg.setName(\"Hello\");\n+            msg.setType(\"String\");\n+            when(processDefinition.getMessagesDesc()).thenReturn(Collections.singletonList(MessageDescImpl.from(\n+                    msg)));\n+            extension.onDeploy(new DeploymentEvent(\"MyDeploy3\", deployedUnit));\n+            publishEvent(\"MyTopic\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"pepe\\\"}\");\n+            verify(processService, getTimeout()).signalEvent(\"MyDeploy3\", \"Message-Hello\", \"pepe\");\n+        } finally {\n+            System.clearProperty(topicProperty);\n+        }\n+    }\n+\n+    @Test\n+    public void testWithDestroy() {\n+        when(processDefinition.getSignalsDesc()).thenReturn(Collections.singletonList(SignalDescImpl.from(\n+                new Signal(\"MySignal\", \"MySignal2\", \"String\"))));\n+        Message msg = new Message(\"MyMessage\");\n+        msg.setName(\"Hello2\");\n+        msg.setType(\"String\");\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy4\", deployedUnit));\n+        publishEvent(\"MySignal2\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"javierito\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy4\", \"MySignal2\", \"javierito\");\n+        extension.destroy(server, registry);\n+        mockConsumer = new MockConsumer<String, byte[]>(OffsetResetStrategy.EARLIEST);\n+        when(processDefinition.getSignalsDesc()).thenReturn(Collections.emptyList());\n+        when(processDefinition.getMessagesDesc()).thenReturn(Collections.singletonList(MessageDescImpl.from(\n+                msg)));\n+        extension.setKafkaConsumer(mockConsumer);\n+        extension.init(server, registry);\n+        extension.onDeploy(new DeploymentEvent(\"MyDeploy5\", deployedUnit));\n+        publishEvent(\"Hello2\", \"{\\\"id\\\":\\\"javi\\\",\\\"type\\\":\\\"one\\\",\\\"source\\\":\\\"pepe\\\",\\\"data\\\":\\\"pepe\\\"}\");\n+        verify(processService, getTimeout()).signalEvent(\"MyDeploy5\", \"Message-Hello2\", \"pepe\");", "originalCommit": "af43ecf49d1bad0773753abb586837ea7760d0dd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODg1NTg0MA==", "url": "https://github.com/kiegroup/droolsjbpm-integration/pull/2288#discussion_r518855840", "bodyText": "Sure, test added", "author": "fjtirado", "createdAt": "2020-11-06T16:17:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODgyOTQ4Mw=="}], "type": "inlineReview", "revised_code": null}, {"oid": "d63411f76bc17e334fe358f8c70b90e4dd1ac424", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/d63411f76bc17e334fe358f8c70b90e4dd1ac424", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-11-06T16:50:53Z", "type": "forcePushed"}, {"oid": "4efcbabbeadb197f6e8fb1a651bb1db181cf0079", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/4efcbabbeadb197f6e8fb1a651bb1db181cf0079", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-11-10T10:14:14Z", "type": "forcePushed"}, {"oid": "95e21534d050bff56d13074948950be9df939956", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/95e21534d050bff56d13074948950be9df939956", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-11-12T10:22:47Z", "type": "forcePushed"}, {"oid": "95b49e57d4cffeeb11e2932450b8e238634c0922", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/95b49e57d4cffeeb11e2932450b8e238634c0922", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-11-12T10:24:52Z", "type": "forcePushed"}, {"oid": "945d353841d850912e6eefcc695cd7d4d91389cc", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/945d353841d850912e6eefcc695cd7d4d91389cc", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-11-12T10:28:49Z", "type": "forcePushed"}, {"oid": "3f70db10544811cf5d8d5efcd041deec80f2b89b", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/3f70db10544811cf5d8d5efcd041deec80f2b89b", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-11-12T15:41:58Z", "type": "forcePushed"}, {"oid": "8979388bc0e800adb102dfb3c4a9fbae2a868590", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/8979388bc0e800adb102dfb3c4a9fbae2a868590", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-11-12T17:38:02Z", "type": "commit"}, {"oid": "8979388bc0e800adb102dfb3c4a9fbae2a868590", "url": "https://github.com/kiegroup/droolsjbpm-integration/commit/8979388bc0e800adb102dfb3c4a9fbae2a868590", "message": "[JBPM-9436] AMQ Streams (Kafka) listener functionality / consumer\n\nAdding Kafka extension", "committedDate": "2020-11-12T17:38:02Z", "type": "forcePushed"}]}