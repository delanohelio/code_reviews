{"pr_number": 3653, "pr_title": "Schema", "pr_createdAt": "2020-09-15T16:05:13Z", "pr_url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3653", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODg2ODE3Mw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3653#discussion_r488868173", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        v1beta2Create(name, mapListener(), null);\n          \n          \n            \n                        Exception e = assertThrows(() -> v1beta2Create(name, mapListener(), null))", "author": "samuel-hawker", "createdAt": "2020-09-15T18:12:29Z", "path": "api/src/test/java/io/strimzi/api/kafka/model/ApiEvolutionCrdIT.java", "diffHunk": "@@ -0,0 +1,232 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.api.kafka.model;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.stream.Collectors;\n+\n+import com.fasterxml.jackson.dataformat.yaml.YAMLMapper;\n+import io.fabric8.kubernetes.api.model.apiextensions.CustomResourceDefinition;\n+import io.fabric8.kubernetes.client.dsl.NonNamespaceOperation;\n+import io.fabric8.kubernetes.client.dsl.Resource;\n+import io.strimzi.api.kafka.Crds;\n+import io.strimzi.api.kafka.KafkaList;\n+import io.strimzi.api.kafka.model.listener.KafkaListeners;\n+import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;\n+import io.strimzi.api.kafka.model.listener.arraylistener.ArrayOrObjectKafkaListeners;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListenerBuilder;\n+import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;\n+import io.strimzi.test.TestUtils;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.AfterAll;\n+import org.junit.jupiter.api.Assertions;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Test;\n+\n+import static java.util.Collections.singletonList;\n+\n+public class ApiEvolutionCrdIT extends AbstractCrdIT {\n+    private static final Logger LOGGER = LogManager.getLogger(ApiEvolutionCrdIT.class);\n+\n+    public static final String NAMESPACE = \"api-evolution-it\";\n+\n+    @Test\n+    public void kafkaApiEvolution() throws IOException {\n+        assumeKube1_16Plus();\n+        // Create CRD with v1beta1 having map-or-list listeners (and no v1beta2)\n+        LOGGER.info(\"Create CRD\");\n+        long crdGeneration = createOrReplaceCrd(\"src/test/resources/io/strimzi/api/kafka/model/040-Crd-kafka-v1alpha1-v1beta1-store-v1beta1.yaml\");\n+        waitForCrd(\"crd\", \"kafkas.kafka.strimzi.io\");\n+\n+        // Create one CR instance with a list listener and one with a map listeners\n+        LOGGER.info(\"Create instances\");\n+        v1beta1Create(\"v1beta1.map.v1beta1.stored.via.v1beta1.endpoint\", mapListener(), null);\n+        v1beta1Create(\"v1beta1.list.v1beta1.stored.via.v1beta1.endpoint\", null, listListener());\n+\n+        // Check we can consume these via v1beta1 endpoint\n+        LOGGER.info(\"Assert instances via v1beta1\");\n+        assertIsMapListener(v1beta1Get(\"v1beta1.map.v1beta1.stored.via.v1beta1.endpoint\"));\n+        assertIsListListener(v1beta1Get(\"v1beta1.list.v1beta1.stored.via.v1beta1.endpoint\"));\n+\n+        // Replace CRD with one having v1beta2 which is served but not stored (v1beta1 is stored)\n+        LOGGER.info(\"Replace CRD\");\n+        long crdGeneration2 = createOrReplaceCrd(\"src/test/resources/io/strimzi/api/kafka/model/040-Crd-kafka-v1beta1-v1beta2-store-v1beta1.yaml\");\n+        waitForCrdUpdate(crdGeneration2);\n+\n+        // Check we can't create a v1beta2 with a map\n+        assertV1beta2CreateFailure(\"v1beta2.map.v1beta1.stored.via.v1beta2.endpoint\");\n+\n+        // Create a v1beta2 with list\n+        LOGGER.info(\"Create 3rd instance via v1beta2 endpoint\");\n+        v1beta2Create(\"v1beta2.list.v1beta1.stored.via.v1beta1.endpoint\", null, listListener());\n+\n+        // Check we can still consume all CRs via both endpoints\n+        LOGGER.info(\"Assert instances via both endpoints\");\n+        assertIsMapListener(v1beta1Get(\"v1beta1.map.v1beta1.stored.via.v1beta1.endpoint\"));\n+        assertIsListListener(v1beta1Get(\"v1beta1.list.v1beta1.stored.via.v1beta1.endpoint\"));\n+        assertIsListListener(v1beta1Get(\"v1beta2.list.v1beta1.stored.via.v1beta1.endpoint\"));\n+        assertIsMapListener(v1beta2Get(\"v1beta1.map.v1beta1.stored.via.v1beta1.endpoint\"));\n+        assertIsListListener(v1beta2Get(\"v1beta1.list.v1beta1.stored.via.v1beta1.endpoint\"));\n+        assertIsListListener(v1beta2Get(\"v1beta2.list.v1beta1.stored.via.v1beta1.endpoint\"));\n+\n+        // Upgrade CRD so v1beta2 is stored\n+        LOGGER.info(\"Update CRD so v1beta2 is stored\");\n+        long crdGeneration3 = createOrReplaceCrd(\"src/test/resources/io/strimzi/api/kafka/model/040-Crd-kafka-v1beta1-v1beta2-store-v1beta2.yaml\");\n+        waitForCrdUpdate(crdGeneration3);\n+\n+        // Check we can still consume all CRs via both endpoints\n+        LOGGER.info(\"Assert instances via both endpoints\");\n+        assertIsMapListener(v1beta1Get(\"v1beta1.map.v1beta1.stored.via.v1beta1.endpoint\"));\n+        assertIsListListener(v1beta1Get(\"v1beta1.list.v1beta1.stored.via.v1beta1.endpoint\"));\n+        assertIsListListener(v1beta1Get(\"v1beta1.list.v1beta1.stored.via.v1beta1.endpoint\"));\n+        assertIsMapListener(v1beta2Get(\"v1beta1.map.v1beta1.stored.via.v1beta1.endpoint\"));\n+        assertIsListListener(v1beta2Get(\"v1beta1.list.v1beta1.stored.via.v1beta1.endpoint\"));\n+        assertIsListListener(v1beta2Get(\"v1beta1.list.v1beta1.stored.via.v1beta1.endpoint\"));\n+\n+        // Check we can still create/update v1beta1 endpoint with a map listeners\n+        v1beta1Create(\"v1beta1.map.v1beta2.stored.via.v1beta1.endpoint\", mapListener(), null);\n+        // But we can't via the v1beta2 endpoint\n+        assertV1beta2CreateFailure(\"v1beta2.map.v1beta2.stored.via.v1beta2.endpoint\");\n+        // But lists are still OK\n+        v1beta1Create(\"v1beta1.list.v1beta2.stored.via.v1beta1.endpoint\", null, listListener());\n+        v1beta2Create(\"v1beta2.list.v1beta2.stored.via.v1beta2.endpoint\", null, listListener());\n+    }\n+\n+    private void assertV1beta2CreateFailure(String name) {\n+        try {\n+            LOGGER.info(\"Check can't create map-listener via v1beta2\");\n+            v1beta2Create(name, mapListener(), null);", "originalCommit": "6f44863ce8054e309240493821527e26a0034ed7", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e0f92c6fc18b6dd3638f33950c4fc16da6f3d7c5", "changed_code": [{"header": "diff --git a/api/src/test/java/io/strimzi/api/kafka/model/ApiEvolutionCrdIT.java b/api/src/test/java/io/strimzi/api/kafka/model/ApiEvolutionCrdIT.java\nindex 0de1fe08a..e29752566 100644\n--- a/api/src/test/java/io/strimzi/api/kafka/model/ApiEvolutionCrdIT.java\n+++ b/api/src/test/java/io/strimzi/api/kafka/model/ApiEvolutionCrdIT.java\n", "chunk": "@@ -28,95 +34,172 @@ import org.junit.jupiter.api.Assertions;\n import org.junit.jupiter.api.BeforeAll;\n import org.junit.jupiter.api.Test;\n \n+import static io.strimzi.api.annotations.ApiVersion.V1;\n+import static io.strimzi.api.annotations.ApiVersion.V1ALPHA1;\n+import static io.strimzi.api.annotations.ApiVersion.V1BETA1;\n+import static io.strimzi.api.annotations.ApiVersion.V1BETA1_PLUS;\n+import static io.strimzi.api.annotations.ApiVersion.V1BETA2;\n+import static java.util.Arrays.asList;\n+import static java.util.Collections.emptyMap;\n import static java.util.Collections.singletonList;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+import static org.junit.jupiter.api.Assertions.assertNull;\n \n public class ApiEvolutionCrdIT extends AbstractCrdIT {\n     private static final Logger LOGGER = LogManager.getLogger(ApiEvolutionCrdIT.class);\n \n     public static final String NAMESPACE = \"api-evolution-it\";\n+    //public static final YAMLMapper YAML_MAPPER = new YAMLMapper();\n \n     @Test\n-    public void kafkaApiEvolution() throws IOException {\n+    public void kafkaApiEvolution() throws IOException, InterruptedException {\n         assumeKube1_16Plus();\n-        // Create CRD with v1beta1 having map-or-list listeners (and no v1beta2)\n-        LOGGER.info(\"Create CRD\");\n-        long crdGeneration = createOrReplaceCrd(\"src/test/resources/io/strimzi/api/kafka/model/040-Crd-kafka-v1alpha1-v1beta1-store-v1beta1.yaml\");\n-        waitForCrd(\"crd\", \"kafkas.kafka.strimzi.io\");\n-\n-        // Create one CR instance with a list listener and one with a map listeners\n-        LOGGER.info(\"Create instances\");\n-        v1beta1Create(\"v1beta1.map.v1beta1.stored.via.v1beta1.endpoint\", mapListener(), null);\n-        v1beta1Create(\"v1beta1.list.v1beta1.stored.via.v1beta1.endpoint\", null, listListener());\n-\n-        // Check we can consume these via v1beta1 endpoint\n-        LOGGER.info(\"Assert instances via v1beta1\");\n-        assertIsMapListener(v1beta1Get(\"v1beta1.map.v1beta1.stored.via.v1beta1.endpoint\"));\n-        assertIsListListener(v1beta1Get(\"v1beta1.list.v1beta1.stored.via.v1beta1.endpoint\"));\n-\n-        // Replace CRD with one having v1beta2 which is served but not stored (v1beta1 is stored)\n-        LOGGER.info(\"Replace CRD\");\n-        long crdGeneration2 = createOrReplaceCrd(\"src/test/resources/io/strimzi/api/kafka/model/040-Crd-kafka-v1beta1-v1beta2-store-v1beta1.yaml\");\n-        waitForCrdUpdate(crdGeneration2);\n-\n-        // Check we can't create a v1beta2 with a map\n-        assertV1beta2CreateFailure(\"v1beta2.map.v1beta1.stored.via.v1beta2.endpoint\");\n-\n-        // Create a v1beta2 with list\n-        LOGGER.info(\"Create 3rd instance via v1beta2 endpoint\");\n-        v1beta2Create(\"v1beta2.list.v1beta1.stored.via.v1beta1.endpoint\", null, listListener());\n-\n-        // Check we can still consume all CRs via both endpoints\n-        LOGGER.info(\"Assert instances via both endpoints\");\n-        assertIsMapListener(v1beta1Get(\"v1beta1.map.v1beta1.stored.via.v1beta1.endpoint\"));\n-        assertIsListListener(v1beta1Get(\"v1beta1.list.v1beta1.stored.via.v1beta1.endpoint\"));\n-        assertIsListListener(v1beta1Get(\"v1beta2.list.v1beta1.stored.via.v1beta1.endpoint\"));\n-        assertIsMapListener(v1beta2Get(\"v1beta1.map.v1beta1.stored.via.v1beta1.endpoint\"));\n-        assertIsListListener(v1beta2Get(\"v1beta1.list.v1beta1.stored.via.v1beta1.endpoint\"));\n-        assertIsListListener(v1beta2Get(\"v1beta2.list.v1beta1.stored.via.v1beta1.endpoint\"));\n-\n-        // Upgrade CRD so v1beta2 is stored\n-        LOGGER.info(\"Update CRD so v1beta2 is stored\");\n-        long crdGeneration3 = createOrReplaceCrd(\"src/test/resources/io/strimzi/api/kafka/model/040-Crd-kafka-v1beta1-v1beta2-store-v1beta2.yaml\");\n-        waitForCrdUpdate(crdGeneration3);\n-\n-        // Check we can still consume all CRs via both endpoints\n-        LOGGER.info(\"Assert instances via both endpoints\");\n-        assertIsMapListener(v1beta1Get(\"v1beta1.map.v1beta1.stored.via.v1beta1.endpoint\"));\n-        assertIsListListener(v1beta1Get(\"v1beta1.list.v1beta1.stored.via.v1beta1.endpoint\"));\n-        assertIsListListener(v1beta1Get(\"v1beta1.list.v1beta1.stored.via.v1beta1.endpoint\"));\n-        assertIsMapListener(v1beta2Get(\"v1beta1.map.v1beta1.stored.via.v1beta1.endpoint\"));\n-        assertIsListListener(v1beta2Get(\"v1beta1.list.v1beta1.stored.via.v1beta1.endpoint\"));\n-        assertIsListListener(v1beta2Get(\"v1beta1.list.v1beta1.stored.via.v1beta1.endpoint\"));\n-\n-        // Check we can still create/update v1beta1 endpoint with a map listeners\n-        v1beta1Create(\"v1beta1.map.v1beta2.stored.via.v1beta1.endpoint\", mapListener(), null);\n-        // But we can't via the v1beta2 endpoint\n-        assertV1beta2CreateFailure(\"v1beta2.map.v1beta2.stored.via.v1beta2.endpoint\");\n-        // But lists are still OK\n-        v1beta1Create(\"v1beta1.list.v1beta2.stored.via.v1beta1.endpoint\", null, listListener());\n-        v1beta2Create(\"v1beta2.list.v1beta2.stored.via.v1beta2.endpoint\", null, listListener());\n+        try {\n+            /* Strimzi 0.20\n+             * v1alpha1 exists but is no longer served, there is no v1beta2\n+             * users upgrade their instances\n+             */\n+\n+            // Create CRD with v1beta1 having map-or-list listeners (and no v1beta2)\n+            LOGGER.info(\"Phase 1 : Create CRD\");\n+            CustomResourceDefinition crdPhase1 = new CrdV1Beta1Builder()\n+                    .withVersions(V1ALPHA1, V1BETA1)\n+                    .withServedVersions(V1BETA1_PLUS)\n+                    .withStorageVersion(V1BETA1)\n+                    .createOrReplace();\n+            Thread.sleep(5_000);\n+            waitForCrdUpdate(crdPhase1.getMetadata().getGeneration());\n+\n+            // Create one CR instance with a list listener and one with a map listeners\n+            LOGGER.info(\"Phase 1 : Create instances\");\n+            final String nameA = \"instance.a\";\n+            final String nameB = \"instance.b\";\n+            Kafka instanceA = v1beta1Create(nameA, mapListener(), null);\n+            Kafka instanceB = v1beta1Create(nameB, null, listListener());\n+\n+            // Check we can consume these via v1beta1 endpoint\n+            LOGGER.info(\"Phase 1 : Assert instances via v1beta1\");\n+            assertIsMapListener(v1beta1Get(nameA));\n+            assertIsListListener(v1beta1Get(nameB));\n+\n+            // Upgrade instance A to use a list listener\n+            v1beta1Op().withName(nameA).replace(new KafkaBuilder(instanceA).editSpec().editKafka().withListeners(\n+                    new ArrayOrObjectKafkaListeners(instanceA.getSpec().getKafka().getListeners().newOrConverted()))\n+                    .endKafka().endSpec().build());\n+\n+            /* Strimzi 0.21\n+             * v1beta2 gets added, and v1beta2 is stored\n+             * users touch all instances, so there's nothing stored at v1beta1\n+             */\n+\n+            // Replace CRD with one having v1beta2 which is served but not stored (v1beta1 is stored)\n+            LOGGER.info(\"Phase 2 : Replace CRD, removing v1alpha1, adding v1beta2\");\n+            CustomResourceDefinition crdPhase2 = new CrdV1Beta1Builder()\n+                    .withVersions(V1BETA1, V1BETA2)\n+                    .withServedVersions(V1BETA1_PLUS)\n+                    .withStorageVersion(V1BETA2)\n+                    .createOrReplace();\n+            waitForCrdUpdate(crdPhase2.getMetadata().getGeneration());\n+            assertEquals(\"v1beta2\", crdPhase2.getSpec().getVersions().stream()\n+                    .filter(v -> v.getStorage()).map(v -> v.getName()).findFirst().get());\n+\n+            // Check we can't create a v1beta2 with a map via the v1beta2 endpoint\n+            assertV1beta2CreateFailure(\"not.valid\");\n+\n+            // Check we can still create a v1beta1 with list via the v1beta1 endpoint\n+            final String nameC = \"instance.c\";\n+            Kafka instanceC = v1beta2Create(nameC, null, listListener());\n+\n+            LOGGER.info(\"Phase 2 : Upgrading all instances to new stored version\");\n+            instanceA = touchV1Beta2(nameA);\n+            instanceB = touchV1Beta2(nameB);\n+            instanceC = touchV1Beta2(nameC);\n+\n+            Thread.sleep(5_000);\n+            LOGGER.info(\"Phase 2 : Assert instances via both endpoints\");\n+            assertIsListListener(v1beta1Get(nameA));\n+            assertIsListListener(v1beta1Get(nameB));\n+            assertIsListListener(v1beta1Get(nameC));\n+            assertIsListListener(v1beta2Get(nameA));\n+            assertIsListListener(v1beta2Get(nameB));\n+            assertIsListListener(v1beta2Get(nameC));\n+\n+            LOGGER.info(\"Phase 2 : Updating CRD so v1beta1 has served=false\");\n+            CustomResourceDefinition crdPhase2Part2 = cluster.client().getClient().customResourceDefinitions()\n+                    .createOrReplace(new CustomResourceDefinitionBuilder(crdPhase2).editSpec()\n+                            .editLastVersion().withServed(false).endVersion().endSpec().build());\n+\n+            CustomResourceDefinition crdPhase2Part3 = waitForCrdUpdate(crdPhase2Part2.getMetadata().getGeneration());\n+\n+            LOGGER.info(\"Phase 2 : Updating CRD status.stored versions = v1beta2\");\n+            CustomResourceDefinition crdPhase2Part4 = cluster.client().getClient().customResourceDefinitions()\n+                    .updateStatus(new CustomResourceDefinitionBuilder(crdPhase2Part3).editStatus().withStoredVersions(asList(\"v1beta2\")).endStatus().build());\n+\n+            assertEquals(asList(\"v1beta2\"), crdPhase2Part4.getStatus().getStoredVersions());\n+            Thread.sleep(5_000);\n+            assertIsListListener(v1beta2Get(nameA));\n+            assertIsListListener(v1beta2Get(nameB));\n+            assertIsListListener(v1beta2Get(nameC));\n+\n+            // Strimzi 0.22\n+\n+            // Upgrade CRD so v1beta2 is stored, and v1beta1 is not served\n+            LOGGER.info(\"Phase 3 : Update CRD so v1beta2 is stored\");\n+            io.fabric8.kubernetes.api.model.apiextensions.v1.CustomResourceDefinition crdPhase3 = new CrdV1Builder()\n+                    .withVersions(V1BETA2)\n+                    .withServedVersions(ApiVersion.V1BETA2_PLUS)\n+                    .withStorageVersion(V1BETA2)\n+                    .createOrReplace();\n+            waitForCrdUpdate(crdPhase3.getMetadata().getGeneration());\n+            assertEquals(\"v1beta2\", crdPhase3.getSpec().getVersions().stream()\n+                    .filter(v -> v.getStorage()).map(v -> v.getName()).findFirst().get());\n+            assertEquals(asList(\"v1beta2\"), crdPhase3.getStatus().getStoredVersions());\n+\n+            // Check we can still consume all CRs via v1beta2 endpoint\n+            LOGGER.info(\"Assert instances via v1beta2 endpoint\");\n+            assertIsListListener(v1beta2Get(nameA));\n+            assertIsListListener(v1beta2Get(nameB));\n+            assertIsListListener(v1beta2Get(nameC));\n+        } finally {\n+            deleteCrd();\n+        }\n+\n+    }\n+\n+    public Kafka touchV1Beta2(String name) {\n+        Kafka build = new KafkaBuilder(v1beta2Get(name))\n+                .withApiVersion(\"kafka.strimzi.io/v1beta2\")\n+                .editMetadata().addToAnnotations(\"bother\", \"yes\").endMetadata()\n+                .build();\n+        build = v1beta2Op().withName(name).replace(build);\n+        build = new KafkaBuilder(build)\n+                .editMetadata().removeFromAnnotations(\"bother\").endMetadata()\n+                .build();\n+        build = v1beta2Op().withName(name).replace(build);\n+        return build;\n     }\n \n     private void assertV1beta2CreateFailure(String name) {\n-        try {\n-            LOGGER.info(\"Check can't create map-listener via v1beta2\");\n-            v1beta2Create(name, mapListener(), null);\n-            Assertions.fail();\n-        } catch (RuntimeException e) {\n-            LOGGER.info(\"Exception, good\", e);\n-            Assertions.assertTrue(e.getMessage().contains(\n-                    \"Kafka.kafka.strimzi.io \\\"\" + name + \"\\\" is invalid: \" +\n-                    \"spec.kafka.listeners: Invalid value: \\\"object\\\": \" +\n-                    \"spec.kafka.listeners in body must be of type array:\"));\n-        }\n+        LOGGER.info(\"Check can't create map-listener via v1beta2\");\n+        KubernetesClientException e = Assertions.assertThrows(KubernetesClientException.class, () -> v1beta2Create(name, mapListener(), null));\n+        LOGGER.info(\"Exception, good\", e);\n+        Assertions.assertTrue(e.getMessage().contains(\n+                \"Kafka.kafka.strimzi.io \\\"\" + name + \"\\\" is invalid: \" +\n+                \"spec.kafka.listeners: Invalid value: \\\"object\\\": \" +\n+                \"spec.kafka.listeners in body must be of type array:\"));\n+    }\n+\n+    private Kafka v1beta1Create(String name, KafkaListeners kafkaListeners, GenericKafkaListener o) {\n+        return v1beta1Op().create(buildKafkaCr(Kafka.V1BETA1, name, kafkaListeners, o));\n     }\n \n-    private void v1beta1Create(String name, KafkaListeners kafkaListeners, GenericKafkaListener o) {\n-        v1beta1Op().create(buildKafkaCr(Kafka.V1BETA1, name, kafkaListeners, o));\n+    private Kafka v1beta2Create(String name, KafkaListeners kafkaListeners, GenericKafkaListener o) {\n+        return v1beta2Op().create(buildKafkaCr(Kafka.V1BETA2, name, kafkaListeners, o));\n     }\n \n-    private void v1beta2Create(String name, KafkaListeners kafkaListeners, GenericKafkaListener o) {\n-        v1beta2Op().create(buildKafkaCr(Kafka.V1BETA2, name, kafkaListeners, o));\n+    private void v1Create(String name, KafkaListeners kafkaListeners, GenericKafkaListener o) {\n+        v1Op().create(buildKafkaCr(Kafka.V1BETA2, name, kafkaListeners, o));\n     }\n \n     private Kafka v1beta1Get(String s) {\n", "next_change": {"commit": "a2aeb50ef0497a39e49106539b6d506b86cfbf91", "changed_code": [{"header": "diff --git a/api/src/test/java/io/strimzi/api/kafka/model/ApiEvolutionCrdIT.java b/api/src/test/java/io/strimzi/api/kafka/model/ApiEvolutionCrdIT.java\ndeleted file mode 100644\nindex e29752566..000000000\n--- a/api/src/test/java/io/strimzi/api/kafka/model/ApiEvolutionCrdIT.java\n+++ /dev/null\n", "chunk": "@@ -1,402 +0,0 @@\n-/*\n- * Copyright Strimzi authors.\n- * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n- */\n-package io.strimzi.api.kafka.model;\n-\n-import java.io.IOException;\n-import java.io.StringWriter;\n-\n-import io.fabric8.kubernetes.api.model.HasMetadata;\n-import io.fabric8.kubernetes.api.model.apiextensions.v1beta1.CustomResourceDefinition;\n-import io.fabric8.kubernetes.api.model.apiextensions.v1beta1.CustomResourceDefinitionBuilder;\n-import io.fabric8.kubernetes.client.KubernetesClientException;\n-import io.fabric8.kubernetes.client.V1ApiextensionsAPIGroupClient;\n-import io.fabric8.kubernetes.client.dsl.NonNamespaceOperation;\n-import io.fabric8.kubernetes.client.dsl.Resource;\n-import io.strimzi.api.kafka.Crds;\n-import io.strimzi.api.kafka.KafkaList;\n-import io.strimzi.api.kafka.model.listener.KafkaListeners;\n-import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;\n-import io.strimzi.api.kafka.model.listener.arraylistener.ArrayOrObjectKafkaListeners;\n-import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener;\n-import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListenerBuilder;\n-import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;\n-import io.strimzi.api.annotations.ApiVersion;\n-import io.strimzi.crdgenerator.CrdGenerator;\n-import io.strimzi.api.annotations.KubeVersion;\n-import io.strimzi.api.annotations.VersionRange;\n-import io.strimzi.test.TestUtils;\n-import org.apache.logging.log4j.LogManager;\n-import org.apache.logging.log4j.Logger;\n-import org.junit.jupiter.api.AfterAll;\n-import org.junit.jupiter.api.Assertions;\n-import org.junit.jupiter.api.BeforeAll;\n-import org.junit.jupiter.api.Test;\n-\n-import static io.strimzi.api.annotations.ApiVersion.V1;\n-import static io.strimzi.api.annotations.ApiVersion.V1ALPHA1;\n-import static io.strimzi.api.annotations.ApiVersion.V1BETA1;\n-import static io.strimzi.api.annotations.ApiVersion.V1BETA1_PLUS;\n-import static io.strimzi.api.annotations.ApiVersion.V1BETA2;\n-import static java.util.Arrays.asList;\n-import static java.util.Collections.emptyMap;\n-import static java.util.Collections.singletonList;\n-import static org.junit.jupiter.api.Assertions.assertEquals;\n-import static org.junit.jupiter.api.Assertions.assertNotNull;\n-import static org.junit.jupiter.api.Assertions.assertNull;\n-\n-public class ApiEvolutionCrdIT extends AbstractCrdIT {\n-    private static final Logger LOGGER = LogManager.getLogger(ApiEvolutionCrdIT.class);\n-\n-    public static final String NAMESPACE = \"api-evolution-it\";\n-    //public static final YAMLMapper YAML_MAPPER = new YAMLMapper();\n-\n-    @Test\n-    public void kafkaApiEvolution() throws IOException, InterruptedException {\n-        assumeKube1_16Plus();\n-        try {\n-            /* Strimzi 0.20\n-             * v1alpha1 exists but is no longer served, there is no v1beta2\n-             * users upgrade their instances\n-             */\n-\n-            // Create CRD with v1beta1 having map-or-list listeners (and no v1beta2)\n-            LOGGER.info(\"Phase 1 : Create CRD\");\n-            CustomResourceDefinition crdPhase1 = new CrdV1Beta1Builder()\n-                    .withVersions(V1ALPHA1, V1BETA1)\n-                    .withServedVersions(V1BETA1_PLUS)\n-                    .withStorageVersion(V1BETA1)\n-                    .createOrReplace();\n-            Thread.sleep(5_000);\n-            waitForCrdUpdate(crdPhase1.getMetadata().getGeneration());\n-\n-            // Create one CR instance with a list listener and one with a map listeners\n-            LOGGER.info(\"Phase 1 : Create instances\");\n-            final String nameA = \"instance.a\";\n-            final String nameB = \"instance.b\";\n-            Kafka instanceA = v1beta1Create(nameA, mapListener(), null);\n-            Kafka instanceB = v1beta1Create(nameB, null, listListener());\n-\n-            // Check we can consume these via v1beta1 endpoint\n-            LOGGER.info(\"Phase 1 : Assert instances via v1beta1\");\n-            assertIsMapListener(v1beta1Get(nameA));\n-            assertIsListListener(v1beta1Get(nameB));\n-\n-            // Upgrade instance A to use a list listener\n-            v1beta1Op().withName(nameA).replace(new KafkaBuilder(instanceA).editSpec().editKafka().withListeners(\n-                    new ArrayOrObjectKafkaListeners(instanceA.getSpec().getKafka().getListeners().newOrConverted()))\n-                    .endKafka().endSpec().build());\n-\n-            /* Strimzi 0.21\n-             * v1beta2 gets added, and v1beta2 is stored\n-             * users touch all instances, so there's nothing stored at v1beta1\n-             */\n-\n-            // Replace CRD with one having v1beta2 which is served but not stored (v1beta1 is stored)\n-            LOGGER.info(\"Phase 2 : Replace CRD, removing v1alpha1, adding v1beta2\");\n-            CustomResourceDefinition crdPhase2 = new CrdV1Beta1Builder()\n-                    .withVersions(V1BETA1, V1BETA2)\n-                    .withServedVersions(V1BETA1_PLUS)\n-                    .withStorageVersion(V1BETA2)\n-                    .createOrReplace();\n-            waitForCrdUpdate(crdPhase2.getMetadata().getGeneration());\n-            assertEquals(\"v1beta2\", crdPhase2.getSpec().getVersions().stream()\n-                    .filter(v -> v.getStorage()).map(v -> v.getName()).findFirst().get());\n-\n-            // Check we can't create a v1beta2 with a map via the v1beta2 endpoint\n-            assertV1beta2CreateFailure(\"not.valid\");\n-\n-            // Check we can still create a v1beta1 with list via the v1beta1 endpoint\n-            final String nameC = \"instance.c\";\n-            Kafka instanceC = v1beta2Create(nameC, null, listListener());\n-\n-            LOGGER.info(\"Phase 2 : Upgrading all instances to new stored version\");\n-            instanceA = touchV1Beta2(nameA);\n-            instanceB = touchV1Beta2(nameB);\n-            instanceC = touchV1Beta2(nameC);\n-\n-            Thread.sleep(5_000);\n-            LOGGER.info(\"Phase 2 : Assert instances via both endpoints\");\n-            assertIsListListener(v1beta1Get(nameA));\n-            assertIsListListener(v1beta1Get(nameB));\n-            assertIsListListener(v1beta1Get(nameC));\n-            assertIsListListener(v1beta2Get(nameA));\n-            assertIsListListener(v1beta2Get(nameB));\n-            assertIsListListener(v1beta2Get(nameC));\n-\n-            LOGGER.info(\"Phase 2 : Updating CRD so v1beta1 has served=false\");\n-            CustomResourceDefinition crdPhase2Part2 = cluster.client().getClient().customResourceDefinitions()\n-                    .createOrReplace(new CustomResourceDefinitionBuilder(crdPhase2).editSpec()\n-                            .editLastVersion().withServed(false).endVersion().endSpec().build());\n-\n-            CustomResourceDefinition crdPhase2Part3 = waitForCrdUpdate(crdPhase2Part2.getMetadata().getGeneration());\n-\n-            LOGGER.info(\"Phase 2 : Updating CRD status.stored versions = v1beta2\");\n-            CustomResourceDefinition crdPhase2Part4 = cluster.client().getClient().customResourceDefinitions()\n-                    .updateStatus(new CustomResourceDefinitionBuilder(crdPhase2Part3).editStatus().withStoredVersions(asList(\"v1beta2\")).endStatus().build());\n-\n-            assertEquals(asList(\"v1beta2\"), crdPhase2Part4.getStatus().getStoredVersions());\n-            Thread.sleep(5_000);\n-            assertIsListListener(v1beta2Get(nameA));\n-            assertIsListListener(v1beta2Get(nameB));\n-            assertIsListListener(v1beta2Get(nameC));\n-\n-            // Strimzi 0.22\n-\n-            // Upgrade CRD so v1beta2 is stored, and v1beta1 is not served\n-            LOGGER.info(\"Phase 3 : Update CRD so v1beta2 is stored\");\n-            io.fabric8.kubernetes.api.model.apiextensions.v1.CustomResourceDefinition crdPhase3 = new CrdV1Builder()\n-                    .withVersions(V1BETA2)\n-                    .withServedVersions(ApiVersion.V1BETA2_PLUS)\n-                    .withStorageVersion(V1BETA2)\n-                    .createOrReplace();\n-            waitForCrdUpdate(crdPhase3.getMetadata().getGeneration());\n-            assertEquals(\"v1beta2\", crdPhase3.getSpec().getVersions().stream()\n-                    .filter(v -> v.getStorage()).map(v -> v.getName()).findFirst().get());\n-            assertEquals(asList(\"v1beta2\"), crdPhase3.getStatus().getStoredVersions());\n-\n-            // Check we can still consume all CRs via v1beta2 endpoint\n-            LOGGER.info(\"Assert instances via v1beta2 endpoint\");\n-            assertIsListListener(v1beta2Get(nameA));\n-            assertIsListListener(v1beta2Get(nameB));\n-            assertIsListListener(v1beta2Get(nameC));\n-        } finally {\n-            deleteCrd();\n-        }\n-\n-    }\n-\n-    public Kafka touchV1Beta2(String name) {\n-        Kafka build = new KafkaBuilder(v1beta2Get(name))\n-                .withApiVersion(\"kafka.strimzi.io/v1beta2\")\n-                .editMetadata().addToAnnotations(\"bother\", \"yes\").endMetadata()\n-                .build();\n-        build = v1beta2Op().withName(name).replace(build);\n-        build = new KafkaBuilder(build)\n-                .editMetadata().removeFromAnnotations(\"bother\").endMetadata()\n-                .build();\n-        build = v1beta2Op().withName(name).replace(build);\n-        return build;\n-    }\n-\n-    private void assertV1beta2CreateFailure(String name) {\n-        LOGGER.info(\"Check can't create map-listener via v1beta2\");\n-        KubernetesClientException e = Assertions.assertThrows(KubernetesClientException.class, () -> v1beta2Create(name, mapListener(), null));\n-        LOGGER.info(\"Exception, good\", e);\n-        Assertions.assertTrue(e.getMessage().contains(\n-                \"Kafka.kafka.strimzi.io \\\"\" + name + \"\\\" is invalid: \" +\n-                \"spec.kafka.listeners: Invalid value: \\\"object\\\": \" +\n-                \"spec.kafka.listeners in body must be of type array:\"));\n-    }\n-\n-    private Kafka v1beta1Create(String name, KafkaListeners kafkaListeners, GenericKafkaListener o) {\n-        return v1beta1Op().create(buildKafkaCr(Kafka.V1BETA1, name, kafkaListeners, o));\n-    }\n-\n-    private Kafka v1beta2Create(String name, KafkaListeners kafkaListeners, GenericKafkaListener o) {\n-        return v1beta2Op().create(buildKafkaCr(Kafka.V1BETA2, name, kafkaListeners, o));\n-    }\n-\n-    private void v1Create(String name, KafkaListeners kafkaListeners, GenericKafkaListener o) {\n-        v1Op().create(buildKafkaCr(Kafka.V1BETA2, name, kafkaListeners, o));\n-    }\n-\n-    private Kafka v1beta1Get(String s) {\n-        return v1beta1Op().withName(s).get();\n-    }\n-\n-    private Kafka v1beta2Get(String s) {\n-        return v1beta2Op().withName(s).get();\n-    }\n-\n-    private Kafka v1Get(String s) {\n-        return v1Op().withName(s).get();\n-    }\n-\n-    private CustomResourceDefinition waitForCrdUpdate(long crdGeneration2) {\n-        TestUtils.waitFor(\"CRD update\", 1000, 30000, () ->\n-                crdGeneration2 == cluster.client().getClient().customResourceDefinitions()\n-                        .withName(\"kafkas.kafka.strimzi.io\").get()\n-                        .getMetadata().getGeneration());\n-        return cluster.client().getClient().customResourceDefinitions()\n-                .withName(\"kafkas.kafka.strimzi.io\").get();\n-    }\n-\n-    abstract class Builder<Crd extends HasMetadata, Self extends Builder<Crd, Self>> {\n-        protected VersionRange<ApiVersion> servedVersions;\n-        protected ApiVersion storageVersion;\n-        protected ApiVersion[] versions;\n-\n-        public Self withServedVersions(VersionRange<ApiVersion> apiVersions) {\n-            this.servedVersions = apiVersions;\n-            return self();\n-        }\n-\n-        public Self withStorageVersion(ApiVersion apiVersion) {\n-            this.storageVersion = apiVersion;\n-            return self();\n-        }\n-\n-        public Self withVersions(ApiVersion... apiVersions) {\n-            this.versions = apiVersions;\n-            return self();\n-        }\n-\n-        protected abstract Self self();\n-\n-        abstract Crd createOrReplace() throws IOException;\n-    }\n-\n-    class CrdV1Beta1Builder extends Builder<CustomResourceDefinition, CrdV1Beta1Builder> {\n-\n-        private CustomResourceDefinition build() throws IOException {\n-            StringWriter sw = new StringWriter();\n-            new CrdGenerator(KubeVersion.V1_16_PLUS, V1BETA1, CrdGenerator.YAML_MAPPER, emptyMap(),\n-                    new CrdGenerator.DefaultReporter(), asList(versions), storageVersion,\n-                    servedVersions,\n-                    new CrdGenerator.NoneConversionStrategy()).generate(Kafka.class, sw);\n-            return CrdGenerator.YAML_MAPPER.readValue(sw.toString(), CustomResourceDefinition.class);\n-        }\n-\n-        @Override\n-        protected CrdV1Beta1Builder self() {\n-            return this;\n-        }\n-\n-        @Override\n-        public CustomResourceDefinition createOrReplace() throws IOException {\n-            CustomResourceDefinition build = build();\n-            return cluster.client().getClient().customResourceDefinitions()\n-                    .createOrReplace(build);\n-        }\n-\n-    }\n-\n-    class CrdV1Builder extends Builder<io.fabric8.kubernetes.api.model.apiextensions.v1.CustomResourceDefinition, CrdV1Builder> {\n-\n-        private io.fabric8.kubernetes.api.model.apiextensions.v1.CustomResourceDefinition build() throws IOException {\n-            StringWriter sw = new StringWriter();\n-            new CrdGenerator(KubeVersion.V1_16_PLUS, V1, CrdGenerator.YAML_MAPPER, emptyMap(),\n-                    new CrdGenerator.DefaultReporter(), asList(versions), storageVersion, servedVersions,\n-                    new CrdGenerator.NoneConversionStrategy()).generate(Kafka.class, sw);\n-            return CrdGenerator.YAML_MAPPER.readValue(sw.toString(), io.fabric8.kubernetes.api.model.apiextensions.v1.CustomResourceDefinition.class);\n-        }\n-\n-        @Override\n-        protected CrdV1Builder self() {\n-            return this;\n-        }\n-\n-        @Override\n-        public io.fabric8.kubernetes.api.model.apiextensions.v1.CustomResourceDefinition createOrReplace() throws IOException {\n-            return cluster.client().getClient().adapt(V1ApiextensionsAPIGroupClient.class).customResourceDefinitions()\n-                    .createOrReplace(build());\n-        }\n-    }\n-\n-    private void deleteCrd() {\n-        KubernetesClientException ex = null;\n-        try {\n-            cluster.client().getClient().customResourceDefinitions()\n-                    .withName(\"kafkas.kafka.strimzi.io\")\n-                    .delete();\n-        } catch (KubernetesClientException e) {\n-            ex = e;\n-            try {\n-                cluster.client().getClient().adapt(V1ApiextensionsAPIGroupClient.class).customResourceDefinitions()\n-                        .withName(\"kafkas.kafka.strimzi.io\")\n-                        .delete();\n-            } catch (KubernetesClientException e2) {\n-                if (ex == null) {\n-                    ex = e2;\n-                }\n-            }\n-        }\n-        if (ex != null) {\n-            throw ex;\n-        }\n-    }\n-\n-    private void assertIsMapListener(Kafka kafka) {\n-        assertNotNull(kafka);\n-        assertNotNull(kafka.getSpec());\n-        KafkaClusterSpec kafkaSpec = kafka.getSpec().getKafka();\n-        assertNotNull(kafkaSpec);\n-        ArrayOrObjectKafkaListeners listeners = kafkaSpec.getListeners();\n-        assertNotNull(listeners);\n-        assertNotNull(listeners.getKafkaListeners());\n-        assertNull(listeners.getGenericKafkaListeners());\n-        assertNotNull(kafkaSpec.getConfig());\n-        assertEquals(\"someValue\", kafkaSpec.getConfig().get(\"some.kafka.config\"));\n-    }\n-\n-    private void assertIsListListener(Kafka kafka) {\n-        assertNotNull(kafka);\n-        assertNotNull(kafka.getSpec());\n-        KafkaClusterSpec kafkaSpec = kafka.getSpec().getKafka();\n-        assertNotNull(kafkaSpec);\n-        ArrayOrObjectKafkaListeners listeners = kafkaSpec.getListeners();\n-        assertNotNull(listeners);\n-        assertNull(listeners.getKafkaListeners());\n-        assertNotNull(listeners.getGenericKafkaListeners());\n-        assertNotNull(kafkaSpec.getConfig());\n-        assertEquals(\"someValue\", kafkaSpec.getConfig().get(\"some.kafka.config\"));\n-    }\n-\n-    private NonNamespaceOperation<Kafka, KafkaList, DoneableKafka, Resource<Kafka, DoneableKafka>> v1beta1Op() {\n-        return Crds.kafkaV1Beta1Operation(cluster.client().getClient()).inNamespace(NAMESPACE);\n-    }\n-\n-    private NonNamespaceOperation<Kafka, KafkaList, DoneableKafka, Resource<Kafka, DoneableKafka>> v1beta2Op() {\n-        return Crds.kafkaV1Beta2Operation(cluster.client().getClient()).inNamespace(NAMESPACE);\n-    }\n-\n-    private NonNamespaceOperation<Kafka, KafkaList, DoneableKafka, Resource<Kafka, DoneableKafka>> v1Op() {\n-        return Crds.kafkaV1Operation(cluster.client().getClient()).inNamespace(NAMESPACE);\n-    }\n-\n-    private GenericKafkaListener listListener() {\n-        return new GenericKafkaListenerBuilder().withType(KafkaListenerType.INTERNAL).withName(\"plain\").withPort(9092).withTls(false).build();\n-    }\n-\n-    private KafkaListeners mapListener() {\n-        return new KafkaListenersBuilder().withNewPlain().endPlain().build();\n-    }\n-\n-    private Kafka buildKafkaCr(String apiVersion, String name, KafkaListeners mapListeners, GenericKafkaListener listListeners) {\n-        if ((mapListeners == null) == (listListeners == null)) {\n-            throw new IllegalArgumentException(\"Exactly one of mapListeners or listListeners must be non-null\");\n-        }\n-        return new KafkaBuilder().withApiVersion(apiVersion)\n-                .withNewMetadata()\n-                    .withName(name)\n-                    .withNamespace(NAMESPACE)\n-                .endMetadata()\n-                .withNewSpec()\n-                    .withNewKafka()\n-                        .withReplicas(1)\n-                        .withNewEphemeralStorage().endEphemeralStorage()\n-                        .withListeners(listListeners != null ? new ArrayOrObjectKafkaListeners(singletonList(listListeners)) : new ArrayOrObjectKafkaListeners(mapListeners))\n-                        .addToConfig(\"some.kafka.config\", \"someValue\")\n-                    .endKafka()\n-                    .withNewZookeeper()\n-                        .withReplicas(1)\n-                        .withNewEphemeralStorage().endEphemeralStorage()\n-                    .endZookeeper()\n-                .endSpec()\n-                        .build();\n-    }\n-\n-\n-    @BeforeAll\n-    void setupEnvironment() {\n-        cluster.createNamespace(NAMESPACE);\n-        //waitForCrd(\"crd\", \"kafkas.kafka.strimzi.io\");\n-    }\n-\n-    @AfterAll\n-    void teardownEnvironment() {\n-        cluster.deleteNamespaces();\n-    }\n-}\n", "next_change": {"commit": "3577b7170a381cfc97d3e058c1c41d93e672ac3d", "changed_code": [{"header": "diff --git a/api/src/test/java/io/strimzi/api/kafka/model/ApiEvolutionCrdIT.java b/api/src/test/java/io/strimzi/api/kafka/model/ApiEvolutionCrdIT.java\nnew file mode 100644\nindex 000000000..0de1fe08a\n--- /dev/null\n+++ b/api/src/test/java/io/strimzi/api/kafka/model/ApiEvolutionCrdIT.java\n", "chunk": "@@ -0,0 +1,232 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.api.kafka.model;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.stream.Collectors;\n+\n+import com.fasterxml.jackson.dataformat.yaml.YAMLMapper;\n+import io.fabric8.kubernetes.api.model.apiextensions.CustomResourceDefinition;\n+import io.fabric8.kubernetes.client.dsl.NonNamespaceOperation;\n+import io.fabric8.kubernetes.client.dsl.Resource;\n+import io.strimzi.api.kafka.Crds;\n+import io.strimzi.api.kafka.KafkaList;\n+import io.strimzi.api.kafka.model.listener.KafkaListeners;\n+import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;\n+import io.strimzi.api.kafka.model.listener.arraylistener.ArrayOrObjectKafkaListeners;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListenerBuilder;\n+import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;\n+import io.strimzi.test.TestUtils;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.AfterAll;\n+import org.junit.jupiter.api.Assertions;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Test;\n+\n+import static java.util.Collections.singletonList;\n+\n+public class ApiEvolutionCrdIT extends AbstractCrdIT {\n+    private static final Logger LOGGER = LogManager.getLogger(ApiEvolutionCrdIT.class);\n+\n+    public static final String NAMESPACE = \"api-evolution-it\";\n+\n+    @Test\n+    public void kafkaApiEvolution() throws IOException {\n+        assumeKube1_16Plus();\n+        // Create CRD with v1beta1 having map-or-list listeners (and no v1beta2)\n+        LOGGER.info(\"Create CRD\");\n+        long crdGeneration = createOrReplaceCrd(\"src/test/resources/io/strimzi/api/kafka/model/040-Crd-kafka-v1alpha1-v1beta1-store-v1beta1.yaml\");\n+        waitForCrd(\"crd\", \"kafkas.kafka.strimzi.io\");\n+\n+        // Create one CR instance with a list listener and one with a map listeners\n+        LOGGER.info(\"Create instances\");\n+        v1beta1Create(\"v1beta1.map.v1beta1.stored.via.v1beta1.endpoint\", mapListener(), null);\n+        v1beta1Create(\"v1beta1.list.v1beta1.stored.via.v1beta1.endpoint\", null, listListener());\n+\n+        // Check we can consume these via v1beta1 endpoint\n+        LOGGER.info(\"Assert instances via v1beta1\");\n+        assertIsMapListener(v1beta1Get(\"v1beta1.map.v1beta1.stored.via.v1beta1.endpoint\"));\n+        assertIsListListener(v1beta1Get(\"v1beta1.list.v1beta1.stored.via.v1beta1.endpoint\"));\n+\n+        // Replace CRD with one having v1beta2 which is served but not stored (v1beta1 is stored)\n+        LOGGER.info(\"Replace CRD\");\n+        long crdGeneration2 = createOrReplaceCrd(\"src/test/resources/io/strimzi/api/kafka/model/040-Crd-kafka-v1beta1-v1beta2-store-v1beta1.yaml\");\n+        waitForCrdUpdate(crdGeneration2);\n+\n+        // Check we can't create a v1beta2 with a map\n+        assertV1beta2CreateFailure(\"v1beta2.map.v1beta1.stored.via.v1beta2.endpoint\");\n+\n+        // Create a v1beta2 with list\n+        LOGGER.info(\"Create 3rd instance via v1beta2 endpoint\");\n+        v1beta2Create(\"v1beta2.list.v1beta1.stored.via.v1beta1.endpoint\", null, listListener());\n+\n+        // Check we can still consume all CRs via both endpoints\n+        LOGGER.info(\"Assert instances via both endpoints\");\n+        assertIsMapListener(v1beta1Get(\"v1beta1.map.v1beta1.stored.via.v1beta1.endpoint\"));\n+        assertIsListListener(v1beta1Get(\"v1beta1.list.v1beta1.stored.via.v1beta1.endpoint\"));\n+        assertIsListListener(v1beta1Get(\"v1beta2.list.v1beta1.stored.via.v1beta1.endpoint\"));\n+        assertIsMapListener(v1beta2Get(\"v1beta1.map.v1beta1.stored.via.v1beta1.endpoint\"));\n+        assertIsListListener(v1beta2Get(\"v1beta1.list.v1beta1.stored.via.v1beta1.endpoint\"));\n+        assertIsListListener(v1beta2Get(\"v1beta2.list.v1beta1.stored.via.v1beta1.endpoint\"));\n+\n+        // Upgrade CRD so v1beta2 is stored\n+        LOGGER.info(\"Update CRD so v1beta2 is stored\");\n+        long crdGeneration3 = createOrReplaceCrd(\"src/test/resources/io/strimzi/api/kafka/model/040-Crd-kafka-v1beta1-v1beta2-store-v1beta2.yaml\");\n+        waitForCrdUpdate(crdGeneration3);\n+\n+        // Check we can still consume all CRs via both endpoints\n+        LOGGER.info(\"Assert instances via both endpoints\");\n+        assertIsMapListener(v1beta1Get(\"v1beta1.map.v1beta1.stored.via.v1beta1.endpoint\"));\n+        assertIsListListener(v1beta1Get(\"v1beta1.list.v1beta1.stored.via.v1beta1.endpoint\"));\n+        assertIsListListener(v1beta1Get(\"v1beta1.list.v1beta1.stored.via.v1beta1.endpoint\"));\n+        assertIsMapListener(v1beta2Get(\"v1beta1.map.v1beta1.stored.via.v1beta1.endpoint\"));\n+        assertIsListListener(v1beta2Get(\"v1beta1.list.v1beta1.stored.via.v1beta1.endpoint\"));\n+        assertIsListListener(v1beta2Get(\"v1beta1.list.v1beta1.stored.via.v1beta1.endpoint\"));\n+\n+        // Check we can still create/update v1beta1 endpoint with a map listeners\n+        v1beta1Create(\"v1beta1.map.v1beta2.stored.via.v1beta1.endpoint\", mapListener(), null);\n+        // But we can't via the v1beta2 endpoint\n+        assertV1beta2CreateFailure(\"v1beta2.map.v1beta2.stored.via.v1beta2.endpoint\");\n+        // But lists are still OK\n+        v1beta1Create(\"v1beta1.list.v1beta2.stored.via.v1beta1.endpoint\", null, listListener());\n+        v1beta2Create(\"v1beta2.list.v1beta2.stored.via.v1beta2.endpoint\", null, listListener());\n+    }\n+\n+    private void assertV1beta2CreateFailure(String name) {\n+        try {\n+            LOGGER.info(\"Check can't create map-listener via v1beta2\");\n+            v1beta2Create(name, mapListener(), null);\n+            Assertions.fail();\n+        } catch (RuntimeException e) {\n+            LOGGER.info(\"Exception, good\", e);\n+            Assertions.assertTrue(e.getMessage().contains(\n+                    \"Kafka.kafka.strimzi.io \\\"\" + name + \"\\\" is invalid: \" +\n+                    \"spec.kafka.listeners: Invalid value: \\\"object\\\": \" +\n+                    \"spec.kafka.listeners in body must be of type array:\"));\n+        }\n+    }\n+\n+    private void v1beta1Create(String name, KafkaListeners kafkaListeners, GenericKafkaListener o) {\n+        v1beta1Op().create(buildKafkaCr(Kafka.V1BETA1, name, kafkaListeners, o));\n+    }\n+\n+    private void v1beta2Create(String name, KafkaListeners kafkaListeners, GenericKafkaListener o) {\n+        v1beta2Op().create(buildKafkaCr(Kafka.V1BETA2, name, kafkaListeners, o));\n+    }\n+\n+    private Kafka v1beta1Get(String s) {\n+        return v1beta1Op().withName(s).get();\n+    }\n+\n+    private Kafka v1beta2Get(String s) {\n+        return v1beta2Op().withName(s).get();\n+    }\n+\n+    private void waitForCrdUpdate(long crdGeneration2) {\n+        TestUtils.waitFor(\"CRD update\", 1000, 30000, () ->\n+                crdGeneration2 == cluster.client().getClient().customResourceDefinitions()\n+                        .withName(\"kafkas.kafka.strimzi.io\").get()\n+                        .getMetadata().getGeneration());\n+    }\n+\n+    private Long createOrReplaceCrd(String s) throws IOException {\n+        File src = new File(s);\n+        if (!src.exists()) {\n+            throw new RuntimeException(src.getAbsolutePath() + \" does not exist\");\n+        }\n+        CustomResourceDefinition crd = new YAMLMapper().readValue(src, CustomResourceDefinition.class);\n+        LOGGER.info(\"Create or replacing {} with versions {}\", crd.getMetadata().getName(),\n+                crd.getSpec().getVersions().stream()\n+                        .map(v -> v.getName() + \"{stored=\" + v.getStorage() + \"}\")\n+                        .collect(Collectors.joining(\", \")));\n+        return cluster.client().getClient().customResourceDefinitions().createOrReplace(crd).getMetadata().getGeneration();\n+    }\n+\n+    private void deleteCrd(String s) throws IOException {\n+        File src = new File(s);\n+        if (!src.exists()) {\n+            throw new RuntimeException(src.getAbsolutePath() + \" does not exist\");\n+        }\n+        CustomResourceDefinition crd = new YAMLMapper().readValue(src, CustomResourceDefinition.class);\n+        LOGGER.info(\"Create or replacing {} with versions {}\", crd.getMetadata().getName(),\n+                crd.getSpec().getVersions().stream()\n+                        .map(v -> v.getName() + \"{stored=\" + v.getStorage() + \"}\")\n+                        .collect(Collectors.joining(\", \")));\n+        cluster.client().getClient().customResourceDefinitions().delete(crd);\n+    }\n+\n+    private void assertIsMapListener(Kafka kafka) {\n+        Assertions.assertNotNull(kafka);\n+        Assertions.assertNotNull(kafka.getSpec());\n+        Assertions.assertNotNull(kafka.getSpec().getKafka());\n+        Assertions.assertNotNull(kafka.getSpec().getKafka().getListeners());\n+        Assertions.assertNotNull(kafka.getSpec().getKafka().getListeners().getKafkaListeners());\n+        Assertions.assertNull(kafka.getSpec().getKafka().getListeners().getGenericKafkaListeners());\n+    }\n+\n+    private void assertIsListListener(Kafka kafka) {\n+        Assertions.assertNotNull(kafka);\n+        Assertions.assertNotNull(kafka.getSpec());\n+        Assertions.assertNotNull(kafka.getSpec().getKafka());\n+        Assertions.assertNotNull(kafka.getSpec().getKafka().getListeners());\n+        Assertions.assertNull(kafka.getSpec().getKafka().getListeners().getKafkaListeners());\n+        Assertions.assertNotNull(kafka.getSpec().getKafka().getListeners().getGenericKafkaListeners());\n+    }\n+\n+    private NonNamespaceOperation<Kafka, KafkaList, DoneableKafka, Resource<Kafka, DoneableKafka>> v1beta1Op() {\n+        return Crds.kafkaV1Beta1Operation(cluster.client().getClient()).inNamespace(NAMESPACE);\n+    }\n+\n+    private NonNamespaceOperation<Kafka, KafkaList, DoneableKafka, Resource<Kafka, DoneableKafka>> v1beta2Op() {\n+        return Crds.kafkaV1Beta2Operation(cluster.client().getClient()).inNamespace(NAMESPACE);\n+    }\n+\n+    private GenericKafkaListener listListener() {\n+        return new GenericKafkaListenerBuilder().withType(KafkaListenerType.INTERNAL).withName(\"plain\").withPort(9092).withTls(false).build();\n+    }\n+\n+    private KafkaListeners mapListener() {\n+        return new KafkaListenersBuilder().withNewPlain().endPlain().build();\n+    }\n+\n+    private Kafka buildKafkaCr(String apiVersion, String name, KafkaListeners mapListeners, GenericKafkaListener listListeners) {\n+        if ((mapListeners == null) == (listListeners == null)) {\n+            throw new IllegalArgumentException(\"Exactly one of mapListeners or listListeners must be non-null\");\n+        }\n+        return new KafkaBuilder().withApiVersion(apiVersion)\n+                .withNewMetadata()\n+                    .withName(name)\n+                    .withNamespace(NAMESPACE)\n+                .endMetadata()\n+                .withNewSpec()\n+                    .withNewKafka()\n+                        .withReplicas(1)\n+                        .withNewEphemeralStorage().endEphemeralStorage()\n+                        .withListeners(new ArrayOrObjectKafkaListeners(listListeners == null ? null : singletonList(listListeners), mapListeners))\n+                    .endKafka()\n+                    .withNewZookeeper()\n+                        .withReplicas(1)\n+                        .withNewEphemeralStorage().endEphemeralStorage()\n+                    .endZookeeper()\n+                .endSpec()\n+                        .build();\n+    }\n+\n+\n+    @BeforeAll\n+    void setupEnvironment() {\n+        cluster.createNamespace(NAMESPACE);\n+        //waitForCrd(\"crd\", \"kafkas.kafka.strimzi.io\");\n+    }\n+\n+    @AfterAll\n+    void teardownEnvironment() throws IOException {\n+        deleteCrd(\"src/test/resources/io/strimzi/api/kafka/model//040-Crd-kafka-v1alpha1-v1beta1-store-v1beta1.yaml\");\n+        cluster.deleteNamespaces();\n+    }\n+}\n", "next_change": {"commit": "d35a149d84d2fb0267853c7fea9db5d99f5e85b4", "changed_code": [{"header": "diff --git a/api/src/test/java/io/strimzi/api/kafka/model/ApiEvolutionCrdIT.java b/api/src/test/java/io/strimzi/api/kafka/model/ApiEvolutionCrdIT.java\nindex 0de1fe08a..72a63fe18 100644\n--- a/api/src/test/java/io/strimzi/api/kafka/model/ApiEvolutionCrdIT.java\n+++ b/api/src/test/java/io/strimzi/api/kafka/model/ApiEvolutionCrdIT.java\n", "chunk": "@@ -225,8 +385,7 @@ public class ApiEvolutionCrdIT extends AbstractCrdIT {\n     }\n \n     @AfterAll\n-    void teardownEnvironment() throws IOException {\n-        deleteCrd(\"src/test/resources/io/strimzi/api/kafka/model//040-Crd-kafka-v1alpha1-v1beta1-store-v1beta1.yaml\");\n+    void teardownEnvironment() {\n         cluster.deleteNamespaces();\n     }\n }\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODg3NTUxNg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3653#discussion_r488875516", "bodyText": "Wouldn't be better to name it createInternalPlainListener or am I missing something?", "author": "see-quick", "createdAt": "2020-09-15T18:26:02Z", "path": "api/src/test/java/io/strimzi/api/kafka/model/ApiEvolutionCrdIT.java", "diffHunk": "@@ -0,0 +1,232 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.api.kafka.model;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.stream.Collectors;\n+\n+import com.fasterxml.jackson.dataformat.yaml.YAMLMapper;\n+import io.fabric8.kubernetes.api.model.apiextensions.CustomResourceDefinition;\n+import io.fabric8.kubernetes.client.dsl.NonNamespaceOperation;\n+import io.fabric8.kubernetes.client.dsl.Resource;\n+import io.strimzi.api.kafka.Crds;\n+import io.strimzi.api.kafka.KafkaList;\n+import io.strimzi.api.kafka.model.listener.KafkaListeners;\n+import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;\n+import io.strimzi.api.kafka.model.listener.arraylistener.ArrayOrObjectKafkaListeners;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListenerBuilder;\n+import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;\n+import io.strimzi.test.TestUtils;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.AfterAll;\n+import org.junit.jupiter.api.Assertions;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Test;\n+\n+import static java.util.Collections.singletonList;\n+\n+public class ApiEvolutionCrdIT extends AbstractCrdIT {\n+    private static final Logger LOGGER = LogManager.getLogger(ApiEvolutionCrdIT.class);\n+\n+    public static final String NAMESPACE = \"api-evolution-it\";\n+\n+    @Test\n+    public void kafkaApiEvolution() throws IOException {\n+        assumeKube1_16Plus();\n+        // Create CRD with v1beta1 having map-or-list listeners (and no v1beta2)\n+        LOGGER.info(\"Create CRD\");\n+        long crdGeneration = createOrReplaceCrd(\"src/test/resources/io/strimzi/api/kafka/model/040-Crd-kafka-v1alpha1-v1beta1-store-v1beta1.yaml\");\n+        waitForCrd(\"crd\", \"kafkas.kafka.strimzi.io\");\n+\n+        // Create one CR instance with a list listener and one with a map listeners\n+        LOGGER.info(\"Create instances\");\n+        v1beta1Create(\"v1beta1.map.v1beta1.stored.via.v1beta1.endpoint\", mapListener(), null);\n+        v1beta1Create(\"v1beta1.list.v1beta1.stored.via.v1beta1.endpoint\", null, listListener());\n+\n+        // Check we can consume these via v1beta1 endpoint\n+        LOGGER.info(\"Assert instances via v1beta1\");\n+        assertIsMapListener(v1beta1Get(\"v1beta1.map.v1beta1.stored.via.v1beta1.endpoint\"));\n+        assertIsListListener(v1beta1Get(\"v1beta1.list.v1beta1.stored.via.v1beta1.endpoint\"));\n+\n+        // Replace CRD with one having v1beta2 which is served but not stored (v1beta1 is stored)\n+        LOGGER.info(\"Replace CRD\");\n+        long crdGeneration2 = createOrReplaceCrd(\"src/test/resources/io/strimzi/api/kafka/model/040-Crd-kafka-v1beta1-v1beta2-store-v1beta1.yaml\");\n+        waitForCrdUpdate(crdGeneration2);\n+\n+        // Check we can't create a v1beta2 with a map\n+        assertV1beta2CreateFailure(\"v1beta2.map.v1beta1.stored.via.v1beta2.endpoint\");\n+\n+        // Create a v1beta2 with list\n+        LOGGER.info(\"Create 3rd instance via v1beta2 endpoint\");\n+        v1beta2Create(\"v1beta2.list.v1beta1.stored.via.v1beta1.endpoint\", null, listListener());\n+\n+        // Check we can still consume all CRs via both endpoints\n+        LOGGER.info(\"Assert instances via both endpoints\");\n+        assertIsMapListener(v1beta1Get(\"v1beta1.map.v1beta1.stored.via.v1beta1.endpoint\"));\n+        assertIsListListener(v1beta1Get(\"v1beta1.list.v1beta1.stored.via.v1beta1.endpoint\"));\n+        assertIsListListener(v1beta1Get(\"v1beta2.list.v1beta1.stored.via.v1beta1.endpoint\"));\n+        assertIsMapListener(v1beta2Get(\"v1beta1.map.v1beta1.stored.via.v1beta1.endpoint\"));\n+        assertIsListListener(v1beta2Get(\"v1beta1.list.v1beta1.stored.via.v1beta1.endpoint\"));\n+        assertIsListListener(v1beta2Get(\"v1beta2.list.v1beta1.stored.via.v1beta1.endpoint\"));\n+\n+        // Upgrade CRD so v1beta2 is stored\n+        LOGGER.info(\"Update CRD so v1beta2 is stored\");\n+        long crdGeneration3 = createOrReplaceCrd(\"src/test/resources/io/strimzi/api/kafka/model/040-Crd-kafka-v1beta1-v1beta2-store-v1beta2.yaml\");\n+        waitForCrdUpdate(crdGeneration3);\n+\n+        // Check we can still consume all CRs via both endpoints\n+        LOGGER.info(\"Assert instances via both endpoints\");\n+        assertIsMapListener(v1beta1Get(\"v1beta1.map.v1beta1.stored.via.v1beta1.endpoint\"));\n+        assertIsListListener(v1beta1Get(\"v1beta1.list.v1beta1.stored.via.v1beta1.endpoint\"));\n+        assertIsListListener(v1beta1Get(\"v1beta1.list.v1beta1.stored.via.v1beta1.endpoint\"));\n+        assertIsMapListener(v1beta2Get(\"v1beta1.map.v1beta1.stored.via.v1beta1.endpoint\"));\n+        assertIsListListener(v1beta2Get(\"v1beta1.list.v1beta1.stored.via.v1beta1.endpoint\"));\n+        assertIsListListener(v1beta2Get(\"v1beta1.list.v1beta1.stored.via.v1beta1.endpoint\"));\n+\n+        // Check we can still create/update v1beta1 endpoint with a map listeners\n+        v1beta1Create(\"v1beta1.map.v1beta2.stored.via.v1beta1.endpoint\", mapListener(), null);\n+        // But we can't via the v1beta2 endpoint\n+        assertV1beta2CreateFailure(\"v1beta2.map.v1beta2.stored.via.v1beta2.endpoint\");\n+        // But lists are still OK\n+        v1beta1Create(\"v1beta1.list.v1beta2.stored.via.v1beta1.endpoint\", null, listListener());\n+        v1beta2Create(\"v1beta2.list.v1beta2.stored.via.v1beta2.endpoint\", null, listListener());\n+    }\n+\n+    private void assertV1beta2CreateFailure(String name) {\n+        try {\n+            LOGGER.info(\"Check can't create map-listener via v1beta2\");\n+            v1beta2Create(name, mapListener(), null);\n+            Assertions.fail();\n+        } catch (RuntimeException e) {\n+            LOGGER.info(\"Exception, good\", e);\n+            Assertions.assertTrue(e.getMessage().contains(\n+                    \"Kafka.kafka.strimzi.io \\\"\" + name + \"\\\" is invalid: \" +\n+                    \"spec.kafka.listeners: Invalid value: \\\"object\\\": \" +\n+                    \"spec.kafka.listeners in body must be of type array:\"));\n+        }\n+    }\n+\n+    private void v1beta1Create(String name, KafkaListeners kafkaListeners, GenericKafkaListener o) {\n+        v1beta1Op().create(buildKafkaCr(Kafka.V1BETA1, name, kafkaListeners, o));\n+    }\n+\n+    private void v1beta2Create(String name, KafkaListeners kafkaListeners, GenericKafkaListener o) {\n+        v1beta2Op().create(buildKafkaCr(Kafka.V1BETA2, name, kafkaListeners, o));\n+    }\n+\n+    private Kafka v1beta1Get(String s) {\n+        return v1beta1Op().withName(s).get();\n+    }\n+\n+    private Kafka v1beta2Get(String s) {\n+        return v1beta2Op().withName(s).get();\n+    }\n+\n+    private void waitForCrdUpdate(long crdGeneration2) {\n+        TestUtils.waitFor(\"CRD update\", 1000, 30000, () ->\n+                crdGeneration2 == cluster.client().getClient().customResourceDefinitions()\n+                        .withName(\"kafkas.kafka.strimzi.io\").get()\n+                        .getMetadata().getGeneration());\n+    }\n+\n+    private Long createOrReplaceCrd(String s) throws IOException {\n+        File src = new File(s);\n+        if (!src.exists()) {\n+            throw new RuntimeException(src.getAbsolutePath() + \" does not exist\");\n+        }\n+        CustomResourceDefinition crd = new YAMLMapper().readValue(src, CustomResourceDefinition.class);\n+        LOGGER.info(\"Create or replacing {} with versions {}\", crd.getMetadata().getName(),\n+                crd.getSpec().getVersions().stream()\n+                        .map(v -> v.getName() + \"{stored=\" + v.getStorage() + \"}\")\n+                        .collect(Collectors.joining(\", \")));\n+        return cluster.client().getClient().customResourceDefinitions().createOrReplace(crd).getMetadata().getGeneration();\n+    }\n+\n+    private void deleteCrd(String s) throws IOException {\n+        File src = new File(s);\n+        if (!src.exists()) {\n+            throw new RuntimeException(src.getAbsolutePath() + \" does not exist\");\n+        }\n+        CustomResourceDefinition crd = new YAMLMapper().readValue(src, CustomResourceDefinition.class);\n+        LOGGER.info(\"Create or replacing {} with versions {}\", crd.getMetadata().getName(),\n+                crd.getSpec().getVersions().stream()\n+                        .map(v -> v.getName() + \"{stored=\" + v.getStorage() + \"}\")\n+                        .collect(Collectors.joining(\", \")));\n+        cluster.client().getClient().customResourceDefinitions().delete(crd);\n+    }\n+\n+    private void assertIsMapListener(Kafka kafka) {\n+        Assertions.assertNotNull(kafka);\n+        Assertions.assertNotNull(kafka.getSpec());\n+        Assertions.assertNotNull(kafka.getSpec().getKafka());\n+        Assertions.assertNotNull(kafka.getSpec().getKafka().getListeners());\n+        Assertions.assertNotNull(kafka.getSpec().getKafka().getListeners().getKafkaListeners());\n+        Assertions.assertNull(kafka.getSpec().getKafka().getListeners().getGenericKafkaListeners());\n+    }\n+\n+    private void assertIsListListener(Kafka kafka) {\n+        Assertions.assertNotNull(kafka);\n+        Assertions.assertNotNull(kafka.getSpec());\n+        Assertions.assertNotNull(kafka.getSpec().getKafka());\n+        Assertions.assertNotNull(kafka.getSpec().getKafka().getListeners());\n+        Assertions.assertNull(kafka.getSpec().getKafka().getListeners().getKafkaListeners());\n+        Assertions.assertNotNull(kafka.getSpec().getKafka().getListeners().getGenericKafkaListeners());\n+    }\n+\n+    private NonNamespaceOperation<Kafka, KafkaList, DoneableKafka, Resource<Kafka, DoneableKafka>> v1beta1Op() {\n+        return Crds.kafkaV1Beta1Operation(cluster.client().getClient()).inNamespace(NAMESPACE);\n+    }\n+\n+    private NonNamespaceOperation<Kafka, KafkaList, DoneableKafka, Resource<Kafka, DoneableKafka>> v1beta2Op() {\n+        return Crds.kafkaV1Beta2Operation(cluster.client().getClient()).inNamespace(NAMESPACE);\n+    }\n+\n+    private GenericKafkaListener listListener() {", "originalCommit": "6f44863ce8054e309240493821527e26a0034ed7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTI0OTk0MA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3653#discussion_r489249940", "bodyText": "The precise details of the listener don't matter (the CR is never actually consumed by the operator), instead what we're testing here is that we API server lets us create a Kafka CR with listeners as a list rather than a map.", "author": "tombentley", "createdAt": "2020-09-16T08:16:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODg3NTUxNg=="}], "type": "inlineReview", "revised_code": {"commit": "e0f92c6fc18b6dd3638f33950c4fc16da6f3d7c5", "changed_code": [{"header": "diff --git a/api/src/test/java/io/strimzi/api/kafka/model/ApiEvolutionCrdIT.java b/api/src/test/java/io/strimzi/api/kafka/model/ApiEvolutionCrdIT.java\nindex 0de1fe08a..e29752566 100644\n--- a/api/src/test/java/io/strimzi/api/kafka/model/ApiEvolutionCrdIT.java\n+++ b/api/src/test/java/io/strimzi/api/kafka/model/ApiEvolutionCrdIT.java\n", "chunk": "@@ -186,6 +352,10 @@ public class ApiEvolutionCrdIT extends AbstractCrdIT {\n         return Crds.kafkaV1Beta2Operation(cluster.client().getClient()).inNamespace(NAMESPACE);\n     }\n \n+    private NonNamespaceOperation<Kafka, KafkaList, DoneableKafka, Resource<Kafka, DoneableKafka>> v1Op() {\n+        return Crds.kafkaV1Operation(cluster.client().getClient()).inNamespace(NAMESPACE);\n+    }\n+\n     private GenericKafkaListener listListener() {\n         return new GenericKafkaListenerBuilder().withType(KafkaListenerType.INTERNAL).withName(\"plain\").withPort(9092).withTls(false).build();\n     }\n", "next_change": {"commit": "a2aeb50ef0497a39e49106539b6d506b86cfbf91", "changed_code": [{"header": "diff --git a/api/src/test/java/io/strimzi/api/kafka/model/ApiEvolutionCrdIT.java b/api/src/test/java/io/strimzi/api/kafka/model/ApiEvolutionCrdIT.java\ndeleted file mode 100644\nindex e29752566..000000000\n--- a/api/src/test/java/io/strimzi/api/kafka/model/ApiEvolutionCrdIT.java\n+++ /dev/null\n", "chunk": "@@ -1,402 +0,0 @@\n-/*\n- * Copyright Strimzi authors.\n- * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n- */\n-package io.strimzi.api.kafka.model;\n-\n-import java.io.IOException;\n-import java.io.StringWriter;\n-\n-import io.fabric8.kubernetes.api.model.HasMetadata;\n-import io.fabric8.kubernetes.api.model.apiextensions.v1beta1.CustomResourceDefinition;\n-import io.fabric8.kubernetes.api.model.apiextensions.v1beta1.CustomResourceDefinitionBuilder;\n-import io.fabric8.kubernetes.client.KubernetesClientException;\n-import io.fabric8.kubernetes.client.V1ApiextensionsAPIGroupClient;\n-import io.fabric8.kubernetes.client.dsl.NonNamespaceOperation;\n-import io.fabric8.kubernetes.client.dsl.Resource;\n-import io.strimzi.api.kafka.Crds;\n-import io.strimzi.api.kafka.KafkaList;\n-import io.strimzi.api.kafka.model.listener.KafkaListeners;\n-import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;\n-import io.strimzi.api.kafka.model.listener.arraylistener.ArrayOrObjectKafkaListeners;\n-import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener;\n-import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListenerBuilder;\n-import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;\n-import io.strimzi.api.annotations.ApiVersion;\n-import io.strimzi.crdgenerator.CrdGenerator;\n-import io.strimzi.api.annotations.KubeVersion;\n-import io.strimzi.api.annotations.VersionRange;\n-import io.strimzi.test.TestUtils;\n-import org.apache.logging.log4j.LogManager;\n-import org.apache.logging.log4j.Logger;\n-import org.junit.jupiter.api.AfterAll;\n-import org.junit.jupiter.api.Assertions;\n-import org.junit.jupiter.api.BeforeAll;\n-import org.junit.jupiter.api.Test;\n-\n-import static io.strimzi.api.annotations.ApiVersion.V1;\n-import static io.strimzi.api.annotations.ApiVersion.V1ALPHA1;\n-import static io.strimzi.api.annotations.ApiVersion.V1BETA1;\n-import static io.strimzi.api.annotations.ApiVersion.V1BETA1_PLUS;\n-import static io.strimzi.api.annotations.ApiVersion.V1BETA2;\n-import static java.util.Arrays.asList;\n-import static java.util.Collections.emptyMap;\n-import static java.util.Collections.singletonList;\n-import static org.junit.jupiter.api.Assertions.assertEquals;\n-import static org.junit.jupiter.api.Assertions.assertNotNull;\n-import static org.junit.jupiter.api.Assertions.assertNull;\n-\n-public class ApiEvolutionCrdIT extends AbstractCrdIT {\n-    private static final Logger LOGGER = LogManager.getLogger(ApiEvolutionCrdIT.class);\n-\n-    public static final String NAMESPACE = \"api-evolution-it\";\n-    //public static final YAMLMapper YAML_MAPPER = new YAMLMapper();\n-\n-    @Test\n-    public void kafkaApiEvolution() throws IOException, InterruptedException {\n-        assumeKube1_16Plus();\n-        try {\n-            /* Strimzi 0.20\n-             * v1alpha1 exists but is no longer served, there is no v1beta2\n-             * users upgrade their instances\n-             */\n-\n-            // Create CRD with v1beta1 having map-or-list listeners (and no v1beta2)\n-            LOGGER.info(\"Phase 1 : Create CRD\");\n-            CustomResourceDefinition crdPhase1 = new CrdV1Beta1Builder()\n-                    .withVersions(V1ALPHA1, V1BETA1)\n-                    .withServedVersions(V1BETA1_PLUS)\n-                    .withStorageVersion(V1BETA1)\n-                    .createOrReplace();\n-            Thread.sleep(5_000);\n-            waitForCrdUpdate(crdPhase1.getMetadata().getGeneration());\n-\n-            // Create one CR instance with a list listener and one with a map listeners\n-            LOGGER.info(\"Phase 1 : Create instances\");\n-            final String nameA = \"instance.a\";\n-            final String nameB = \"instance.b\";\n-            Kafka instanceA = v1beta1Create(nameA, mapListener(), null);\n-            Kafka instanceB = v1beta1Create(nameB, null, listListener());\n-\n-            // Check we can consume these via v1beta1 endpoint\n-            LOGGER.info(\"Phase 1 : Assert instances via v1beta1\");\n-            assertIsMapListener(v1beta1Get(nameA));\n-            assertIsListListener(v1beta1Get(nameB));\n-\n-            // Upgrade instance A to use a list listener\n-            v1beta1Op().withName(nameA).replace(new KafkaBuilder(instanceA).editSpec().editKafka().withListeners(\n-                    new ArrayOrObjectKafkaListeners(instanceA.getSpec().getKafka().getListeners().newOrConverted()))\n-                    .endKafka().endSpec().build());\n-\n-            /* Strimzi 0.21\n-             * v1beta2 gets added, and v1beta2 is stored\n-             * users touch all instances, so there's nothing stored at v1beta1\n-             */\n-\n-            // Replace CRD with one having v1beta2 which is served but not stored (v1beta1 is stored)\n-            LOGGER.info(\"Phase 2 : Replace CRD, removing v1alpha1, adding v1beta2\");\n-            CustomResourceDefinition crdPhase2 = new CrdV1Beta1Builder()\n-                    .withVersions(V1BETA1, V1BETA2)\n-                    .withServedVersions(V1BETA1_PLUS)\n-                    .withStorageVersion(V1BETA2)\n-                    .createOrReplace();\n-            waitForCrdUpdate(crdPhase2.getMetadata().getGeneration());\n-            assertEquals(\"v1beta2\", crdPhase2.getSpec().getVersions().stream()\n-                    .filter(v -> v.getStorage()).map(v -> v.getName()).findFirst().get());\n-\n-            // Check we can't create a v1beta2 with a map via the v1beta2 endpoint\n-            assertV1beta2CreateFailure(\"not.valid\");\n-\n-            // Check we can still create a v1beta1 with list via the v1beta1 endpoint\n-            final String nameC = \"instance.c\";\n-            Kafka instanceC = v1beta2Create(nameC, null, listListener());\n-\n-            LOGGER.info(\"Phase 2 : Upgrading all instances to new stored version\");\n-            instanceA = touchV1Beta2(nameA);\n-            instanceB = touchV1Beta2(nameB);\n-            instanceC = touchV1Beta2(nameC);\n-\n-            Thread.sleep(5_000);\n-            LOGGER.info(\"Phase 2 : Assert instances via both endpoints\");\n-            assertIsListListener(v1beta1Get(nameA));\n-            assertIsListListener(v1beta1Get(nameB));\n-            assertIsListListener(v1beta1Get(nameC));\n-            assertIsListListener(v1beta2Get(nameA));\n-            assertIsListListener(v1beta2Get(nameB));\n-            assertIsListListener(v1beta2Get(nameC));\n-\n-            LOGGER.info(\"Phase 2 : Updating CRD so v1beta1 has served=false\");\n-            CustomResourceDefinition crdPhase2Part2 = cluster.client().getClient().customResourceDefinitions()\n-                    .createOrReplace(new CustomResourceDefinitionBuilder(crdPhase2).editSpec()\n-                            .editLastVersion().withServed(false).endVersion().endSpec().build());\n-\n-            CustomResourceDefinition crdPhase2Part3 = waitForCrdUpdate(crdPhase2Part2.getMetadata().getGeneration());\n-\n-            LOGGER.info(\"Phase 2 : Updating CRD status.stored versions = v1beta2\");\n-            CustomResourceDefinition crdPhase2Part4 = cluster.client().getClient().customResourceDefinitions()\n-                    .updateStatus(new CustomResourceDefinitionBuilder(crdPhase2Part3).editStatus().withStoredVersions(asList(\"v1beta2\")).endStatus().build());\n-\n-            assertEquals(asList(\"v1beta2\"), crdPhase2Part4.getStatus().getStoredVersions());\n-            Thread.sleep(5_000);\n-            assertIsListListener(v1beta2Get(nameA));\n-            assertIsListListener(v1beta2Get(nameB));\n-            assertIsListListener(v1beta2Get(nameC));\n-\n-            // Strimzi 0.22\n-\n-            // Upgrade CRD so v1beta2 is stored, and v1beta1 is not served\n-            LOGGER.info(\"Phase 3 : Update CRD so v1beta2 is stored\");\n-            io.fabric8.kubernetes.api.model.apiextensions.v1.CustomResourceDefinition crdPhase3 = new CrdV1Builder()\n-                    .withVersions(V1BETA2)\n-                    .withServedVersions(ApiVersion.V1BETA2_PLUS)\n-                    .withStorageVersion(V1BETA2)\n-                    .createOrReplace();\n-            waitForCrdUpdate(crdPhase3.getMetadata().getGeneration());\n-            assertEquals(\"v1beta2\", crdPhase3.getSpec().getVersions().stream()\n-                    .filter(v -> v.getStorage()).map(v -> v.getName()).findFirst().get());\n-            assertEquals(asList(\"v1beta2\"), crdPhase3.getStatus().getStoredVersions());\n-\n-            // Check we can still consume all CRs via v1beta2 endpoint\n-            LOGGER.info(\"Assert instances via v1beta2 endpoint\");\n-            assertIsListListener(v1beta2Get(nameA));\n-            assertIsListListener(v1beta2Get(nameB));\n-            assertIsListListener(v1beta2Get(nameC));\n-        } finally {\n-            deleteCrd();\n-        }\n-\n-    }\n-\n-    public Kafka touchV1Beta2(String name) {\n-        Kafka build = new KafkaBuilder(v1beta2Get(name))\n-                .withApiVersion(\"kafka.strimzi.io/v1beta2\")\n-                .editMetadata().addToAnnotations(\"bother\", \"yes\").endMetadata()\n-                .build();\n-        build = v1beta2Op().withName(name).replace(build);\n-        build = new KafkaBuilder(build)\n-                .editMetadata().removeFromAnnotations(\"bother\").endMetadata()\n-                .build();\n-        build = v1beta2Op().withName(name).replace(build);\n-        return build;\n-    }\n-\n-    private void assertV1beta2CreateFailure(String name) {\n-        LOGGER.info(\"Check can't create map-listener via v1beta2\");\n-        KubernetesClientException e = Assertions.assertThrows(KubernetesClientException.class, () -> v1beta2Create(name, mapListener(), null));\n-        LOGGER.info(\"Exception, good\", e);\n-        Assertions.assertTrue(e.getMessage().contains(\n-                \"Kafka.kafka.strimzi.io \\\"\" + name + \"\\\" is invalid: \" +\n-                \"spec.kafka.listeners: Invalid value: \\\"object\\\": \" +\n-                \"spec.kafka.listeners in body must be of type array:\"));\n-    }\n-\n-    private Kafka v1beta1Create(String name, KafkaListeners kafkaListeners, GenericKafkaListener o) {\n-        return v1beta1Op().create(buildKafkaCr(Kafka.V1BETA1, name, kafkaListeners, o));\n-    }\n-\n-    private Kafka v1beta2Create(String name, KafkaListeners kafkaListeners, GenericKafkaListener o) {\n-        return v1beta2Op().create(buildKafkaCr(Kafka.V1BETA2, name, kafkaListeners, o));\n-    }\n-\n-    private void v1Create(String name, KafkaListeners kafkaListeners, GenericKafkaListener o) {\n-        v1Op().create(buildKafkaCr(Kafka.V1BETA2, name, kafkaListeners, o));\n-    }\n-\n-    private Kafka v1beta1Get(String s) {\n-        return v1beta1Op().withName(s).get();\n-    }\n-\n-    private Kafka v1beta2Get(String s) {\n-        return v1beta2Op().withName(s).get();\n-    }\n-\n-    private Kafka v1Get(String s) {\n-        return v1Op().withName(s).get();\n-    }\n-\n-    private CustomResourceDefinition waitForCrdUpdate(long crdGeneration2) {\n-        TestUtils.waitFor(\"CRD update\", 1000, 30000, () ->\n-                crdGeneration2 == cluster.client().getClient().customResourceDefinitions()\n-                        .withName(\"kafkas.kafka.strimzi.io\").get()\n-                        .getMetadata().getGeneration());\n-        return cluster.client().getClient().customResourceDefinitions()\n-                .withName(\"kafkas.kafka.strimzi.io\").get();\n-    }\n-\n-    abstract class Builder<Crd extends HasMetadata, Self extends Builder<Crd, Self>> {\n-        protected VersionRange<ApiVersion> servedVersions;\n-        protected ApiVersion storageVersion;\n-        protected ApiVersion[] versions;\n-\n-        public Self withServedVersions(VersionRange<ApiVersion> apiVersions) {\n-            this.servedVersions = apiVersions;\n-            return self();\n-        }\n-\n-        public Self withStorageVersion(ApiVersion apiVersion) {\n-            this.storageVersion = apiVersion;\n-            return self();\n-        }\n-\n-        public Self withVersions(ApiVersion... apiVersions) {\n-            this.versions = apiVersions;\n-            return self();\n-        }\n-\n-        protected abstract Self self();\n-\n-        abstract Crd createOrReplace() throws IOException;\n-    }\n-\n-    class CrdV1Beta1Builder extends Builder<CustomResourceDefinition, CrdV1Beta1Builder> {\n-\n-        private CustomResourceDefinition build() throws IOException {\n-            StringWriter sw = new StringWriter();\n-            new CrdGenerator(KubeVersion.V1_16_PLUS, V1BETA1, CrdGenerator.YAML_MAPPER, emptyMap(),\n-                    new CrdGenerator.DefaultReporter(), asList(versions), storageVersion,\n-                    servedVersions,\n-                    new CrdGenerator.NoneConversionStrategy()).generate(Kafka.class, sw);\n-            return CrdGenerator.YAML_MAPPER.readValue(sw.toString(), CustomResourceDefinition.class);\n-        }\n-\n-        @Override\n-        protected CrdV1Beta1Builder self() {\n-            return this;\n-        }\n-\n-        @Override\n-        public CustomResourceDefinition createOrReplace() throws IOException {\n-            CustomResourceDefinition build = build();\n-            return cluster.client().getClient().customResourceDefinitions()\n-                    .createOrReplace(build);\n-        }\n-\n-    }\n-\n-    class CrdV1Builder extends Builder<io.fabric8.kubernetes.api.model.apiextensions.v1.CustomResourceDefinition, CrdV1Builder> {\n-\n-        private io.fabric8.kubernetes.api.model.apiextensions.v1.CustomResourceDefinition build() throws IOException {\n-            StringWriter sw = new StringWriter();\n-            new CrdGenerator(KubeVersion.V1_16_PLUS, V1, CrdGenerator.YAML_MAPPER, emptyMap(),\n-                    new CrdGenerator.DefaultReporter(), asList(versions), storageVersion, servedVersions,\n-                    new CrdGenerator.NoneConversionStrategy()).generate(Kafka.class, sw);\n-            return CrdGenerator.YAML_MAPPER.readValue(sw.toString(), io.fabric8.kubernetes.api.model.apiextensions.v1.CustomResourceDefinition.class);\n-        }\n-\n-        @Override\n-        protected CrdV1Builder self() {\n-            return this;\n-        }\n-\n-        @Override\n-        public io.fabric8.kubernetes.api.model.apiextensions.v1.CustomResourceDefinition createOrReplace() throws IOException {\n-            return cluster.client().getClient().adapt(V1ApiextensionsAPIGroupClient.class).customResourceDefinitions()\n-                    .createOrReplace(build());\n-        }\n-    }\n-\n-    private void deleteCrd() {\n-        KubernetesClientException ex = null;\n-        try {\n-            cluster.client().getClient().customResourceDefinitions()\n-                    .withName(\"kafkas.kafka.strimzi.io\")\n-                    .delete();\n-        } catch (KubernetesClientException e) {\n-            ex = e;\n-            try {\n-                cluster.client().getClient().adapt(V1ApiextensionsAPIGroupClient.class).customResourceDefinitions()\n-                        .withName(\"kafkas.kafka.strimzi.io\")\n-                        .delete();\n-            } catch (KubernetesClientException e2) {\n-                if (ex == null) {\n-                    ex = e2;\n-                }\n-            }\n-        }\n-        if (ex != null) {\n-            throw ex;\n-        }\n-    }\n-\n-    private void assertIsMapListener(Kafka kafka) {\n-        assertNotNull(kafka);\n-        assertNotNull(kafka.getSpec());\n-        KafkaClusterSpec kafkaSpec = kafka.getSpec().getKafka();\n-        assertNotNull(kafkaSpec);\n-        ArrayOrObjectKafkaListeners listeners = kafkaSpec.getListeners();\n-        assertNotNull(listeners);\n-        assertNotNull(listeners.getKafkaListeners());\n-        assertNull(listeners.getGenericKafkaListeners());\n-        assertNotNull(kafkaSpec.getConfig());\n-        assertEquals(\"someValue\", kafkaSpec.getConfig().get(\"some.kafka.config\"));\n-    }\n-\n-    private void assertIsListListener(Kafka kafka) {\n-        assertNotNull(kafka);\n-        assertNotNull(kafka.getSpec());\n-        KafkaClusterSpec kafkaSpec = kafka.getSpec().getKafka();\n-        assertNotNull(kafkaSpec);\n-        ArrayOrObjectKafkaListeners listeners = kafkaSpec.getListeners();\n-        assertNotNull(listeners);\n-        assertNull(listeners.getKafkaListeners());\n-        assertNotNull(listeners.getGenericKafkaListeners());\n-        assertNotNull(kafkaSpec.getConfig());\n-        assertEquals(\"someValue\", kafkaSpec.getConfig().get(\"some.kafka.config\"));\n-    }\n-\n-    private NonNamespaceOperation<Kafka, KafkaList, DoneableKafka, Resource<Kafka, DoneableKafka>> v1beta1Op() {\n-        return Crds.kafkaV1Beta1Operation(cluster.client().getClient()).inNamespace(NAMESPACE);\n-    }\n-\n-    private NonNamespaceOperation<Kafka, KafkaList, DoneableKafka, Resource<Kafka, DoneableKafka>> v1beta2Op() {\n-        return Crds.kafkaV1Beta2Operation(cluster.client().getClient()).inNamespace(NAMESPACE);\n-    }\n-\n-    private NonNamespaceOperation<Kafka, KafkaList, DoneableKafka, Resource<Kafka, DoneableKafka>> v1Op() {\n-        return Crds.kafkaV1Operation(cluster.client().getClient()).inNamespace(NAMESPACE);\n-    }\n-\n-    private GenericKafkaListener listListener() {\n-        return new GenericKafkaListenerBuilder().withType(KafkaListenerType.INTERNAL).withName(\"plain\").withPort(9092).withTls(false).build();\n-    }\n-\n-    private KafkaListeners mapListener() {\n-        return new KafkaListenersBuilder().withNewPlain().endPlain().build();\n-    }\n-\n-    private Kafka buildKafkaCr(String apiVersion, String name, KafkaListeners mapListeners, GenericKafkaListener listListeners) {\n-        if ((mapListeners == null) == (listListeners == null)) {\n-            throw new IllegalArgumentException(\"Exactly one of mapListeners or listListeners must be non-null\");\n-        }\n-        return new KafkaBuilder().withApiVersion(apiVersion)\n-                .withNewMetadata()\n-                    .withName(name)\n-                    .withNamespace(NAMESPACE)\n-                .endMetadata()\n-                .withNewSpec()\n-                    .withNewKafka()\n-                        .withReplicas(1)\n-                        .withNewEphemeralStorage().endEphemeralStorage()\n-                        .withListeners(listListeners != null ? new ArrayOrObjectKafkaListeners(singletonList(listListeners)) : new ArrayOrObjectKafkaListeners(mapListeners))\n-                        .addToConfig(\"some.kafka.config\", \"someValue\")\n-                    .endKafka()\n-                    .withNewZookeeper()\n-                        .withReplicas(1)\n-                        .withNewEphemeralStorage().endEphemeralStorage()\n-                    .endZookeeper()\n-                .endSpec()\n-                        .build();\n-    }\n-\n-\n-    @BeforeAll\n-    void setupEnvironment() {\n-        cluster.createNamespace(NAMESPACE);\n-        //waitForCrd(\"crd\", \"kafkas.kafka.strimzi.io\");\n-    }\n-\n-    @AfterAll\n-    void teardownEnvironment() {\n-        cluster.deleteNamespaces();\n-    }\n-}\n", "next_change": {"commit": "3577b7170a381cfc97d3e058c1c41d93e672ac3d", "changed_code": [{"header": "diff --git a/api/src/test/java/io/strimzi/api/kafka/model/ApiEvolutionCrdIT.java b/api/src/test/java/io/strimzi/api/kafka/model/ApiEvolutionCrdIT.java\nnew file mode 100644\nindex 000000000..0de1fe08a\n--- /dev/null\n+++ b/api/src/test/java/io/strimzi/api/kafka/model/ApiEvolutionCrdIT.java\n", "chunk": "@@ -0,0 +1,232 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.api.kafka.model;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.stream.Collectors;\n+\n+import com.fasterxml.jackson.dataformat.yaml.YAMLMapper;\n+import io.fabric8.kubernetes.api.model.apiextensions.CustomResourceDefinition;\n+import io.fabric8.kubernetes.client.dsl.NonNamespaceOperation;\n+import io.fabric8.kubernetes.client.dsl.Resource;\n+import io.strimzi.api.kafka.Crds;\n+import io.strimzi.api.kafka.KafkaList;\n+import io.strimzi.api.kafka.model.listener.KafkaListeners;\n+import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;\n+import io.strimzi.api.kafka.model.listener.arraylistener.ArrayOrObjectKafkaListeners;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener;\n+import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListenerBuilder;\n+import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;\n+import io.strimzi.test.TestUtils;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.AfterAll;\n+import org.junit.jupiter.api.Assertions;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.api.Test;\n+\n+import static java.util.Collections.singletonList;\n+\n+public class ApiEvolutionCrdIT extends AbstractCrdIT {\n+    private static final Logger LOGGER = LogManager.getLogger(ApiEvolutionCrdIT.class);\n+\n+    public static final String NAMESPACE = \"api-evolution-it\";\n+\n+    @Test\n+    public void kafkaApiEvolution() throws IOException {\n+        assumeKube1_16Plus();\n+        // Create CRD with v1beta1 having map-or-list listeners (and no v1beta2)\n+        LOGGER.info(\"Create CRD\");\n+        long crdGeneration = createOrReplaceCrd(\"src/test/resources/io/strimzi/api/kafka/model/040-Crd-kafka-v1alpha1-v1beta1-store-v1beta1.yaml\");\n+        waitForCrd(\"crd\", \"kafkas.kafka.strimzi.io\");\n+\n+        // Create one CR instance with a list listener and one with a map listeners\n+        LOGGER.info(\"Create instances\");\n+        v1beta1Create(\"v1beta1.map.v1beta1.stored.via.v1beta1.endpoint\", mapListener(), null);\n+        v1beta1Create(\"v1beta1.list.v1beta1.stored.via.v1beta1.endpoint\", null, listListener());\n+\n+        // Check we can consume these via v1beta1 endpoint\n+        LOGGER.info(\"Assert instances via v1beta1\");\n+        assertIsMapListener(v1beta1Get(\"v1beta1.map.v1beta1.stored.via.v1beta1.endpoint\"));\n+        assertIsListListener(v1beta1Get(\"v1beta1.list.v1beta1.stored.via.v1beta1.endpoint\"));\n+\n+        // Replace CRD with one having v1beta2 which is served but not stored (v1beta1 is stored)\n+        LOGGER.info(\"Replace CRD\");\n+        long crdGeneration2 = createOrReplaceCrd(\"src/test/resources/io/strimzi/api/kafka/model/040-Crd-kafka-v1beta1-v1beta2-store-v1beta1.yaml\");\n+        waitForCrdUpdate(crdGeneration2);\n+\n+        // Check we can't create a v1beta2 with a map\n+        assertV1beta2CreateFailure(\"v1beta2.map.v1beta1.stored.via.v1beta2.endpoint\");\n+\n+        // Create a v1beta2 with list\n+        LOGGER.info(\"Create 3rd instance via v1beta2 endpoint\");\n+        v1beta2Create(\"v1beta2.list.v1beta1.stored.via.v1beta1.endpoint\", null, listListener());\n+\n+        // Check we can still consume all CRs via both endpoints\n+        LOGGER.info(\"Assert instances via both endpoints\");\n+        assertIsMapListener(v1beta1Get(\"v1beta1.map.v1beta1.stored.via.v1beta1.endpoint\"));\n+        assertIsListListener(v1beta1Get(\"v1beta1.list.v1beta1.stored.via.v1beta1.endpoint\"));\n+        assertIsListListener(v1beta1Get(\"v1beta2.list.v1beta1.stored.via.v1beta1.endpoint\"));\n+        assertIsMapListener(v1beta2Get(\"v1beta1.map.v1beta1.stored.via.v1beta1.endpoint\"));\n+        assertIsListListener(v1beta2Get(\"v1beta1.list.v1beta1.stored.via.v1beta1.endpoint\"));\n+        assertIsListListener(v1beta2Get(\"v1beta2.list.v1beta1.stored.via.v1beta1.endpoint\"));\n+\n+        // Upgrade CRD so v1beta2 is stored\n+        LOGGER.info(\"Update CRD so v1beta2 is stored\");\n+        long crdGeneration3 = createOrReplaceCrd(\"src/test/resources/io/strimzi/api/kafka/model/040-Crd-kafka-v1beta1-v1beta2-store-v1beta2.yaml\");\n+        waitForCrdUpdate(crdGeneration3);\n+\n+        // Check we can still consume all CRs via both endpoints\n+        LOGGER.info(\"Assert instances via both endpoints\");\n+        assertIsMapListener(v1beta1Get(\"v1beta1.map.v1beta1.stored.via.v1beta1.endpoint\"));\n+        assertIsListListener(v1beta1Get(\"v1beta1.list.v1beta1.stored.via.v1beta1.endpoint\"));\n+        assertIsListListener(v1beta1Get(\"v1beta1.list.v1beta1.stored.via.v1beta1.endpoint\"));\n+        assertIsMapListener(v1beta2Get(\"v1beta1.map.v1beta1.stored.via.v1beta1.endpoint\"));\n+        assertIsListListener(v1beta2Get(\"v1beta1.list.v1beta1.stored.via.v1beta1.endpoint\"));\n+        assertIsListListener(v1beta2Get(\"v1beta1.list.v1beta1.stored.via.v1beta1.endpoint\"));\n+\n+        // Check we can still create/update v1beta1 endpoint with a map listeners\n+        v1beta1Create(\"v1beta1.map.v1beta2.stored.via.v1beta1.endpoint\", mapListener(), null);\n+        // But we can't via the v1beta2 endpoint\n+        assertV1beta2CreateFailure(\"v1beta2.map.v1beta2.stored.via.v1beta2.endpoint\");\n+        // But lists are still OK\n+        v1beta1Create(\"v1beta1.list.v1beta2.stored.via.v1beta1.endpoint\", null, listListener());\n+        v1beta2Create(\"v1beta2.list.v1beta2.stored.via.v1beta2.endpoint\", null, listListener());\n+    }\n+\n+    private void assertV1beta2CreateFailure(String name) {\n+        try {\n+            LOGGER.info(\"Check can't create map-listener via v1beta2\");\n+            v1beta2Create(name, mapListener(), null);\n+            Assertions.fail();\n+        } catch (RuntimeException e) {\n+            LOGGER.info(\"Exception, good\", e);\n+            Assertions.assertTrue(e.getMessage().contains(\n+                    \"Kafka.kafka.strimzi.io \\\"\" + name + \"\\\" is invalid: \" +\n+                    \"spec.kafka.listeners: Invalid value: \\\"object\\\": \" +\n+                    \"spec.kafka.listeners in body must be of type array:\"));\n+        }\n+    }\n+\n+    private void v1beta1Create(String name, KafkaListeners kafkaListeners, GenericKafkaListener o) {\n+        v1beta1Op().create(buildKafkaCr(Kafka.V1BETA1, name, kafkaListeners, o));\n+    }\n+\n+    private void v1beta2Create(String name, KafkaListeners kafkaListeners, GenericKafkaListener o) {\n+        v1beta2Op().create(buildKafkaCr(Kafka.V1BETA2, name, kafkaListeners, o));\n+    }\n+\n+    private Kafka v1beta1Get(String s) {\n+        return v1beta1Op().withName(s).get();\n+    }\n+\n+    private Kafka v1beta2Get(String s) {\n+        return v1beta2Op().withName(s).get();\n+    }\n+\n+    private void waitForCrdUpdate(long crdGeneration2) {\n+        TestUtils.waitFor(\"CRD update\", 1000, 30000, () ->\n+                crdGeneration2 == cluster.client().getClient().customResourceDefinitions()\n+                        .withName(\"kafkas.kafka.strimzi.io\").get()\n+                        .getMetadata().getGeneration());\n+    }\n+\n+    private Long createOrReplaceCrd(String s) throws IOException {\n+        File src = new File(s);\n+        if (!src.exists()) {\n+            throw new RuntimeException(src.getAbsolutePath() + \" does not exist\");\n+        }\n+        CustomResourceDefinition crd = new YAMLMapper().readValue(src, CustomResourceDefinition.class);\n+        LOGGER.info(\"Create or replacing {} with versions {}\", crd.getMetadata().getName(),\n+                crd.getSpec().getVersions().stream()\n+                        .map(v -> v.getName() + \"{stored=\" + v.getStorage() + \"}\")\n+                        .collect(Collectors.joining(\", \")));\n+        return cluster.client().getClient().customResourceDefinitions().createOrReplace(crd).getMetadata().getGeneration();\n+    }\n+\n+    private void deleteCrd(String s) throws IOException {\n+        File src = new File(s);\n+        if (!src.exists()) {\n+            throw new RuntimeException(src.getAbsolutePath() + \" does not exist\");\n+        }\n+        CustomResourceDefinition crd = new YAMLMapper().readValue(src, CustomResourceDefinition.class);\n+        LOGGER.info(\"Create or replacing {} with versions {}\", crd.getMetadata().getName(),\n+                crd.getSpec().getVersions().stream()\n+                        .map(v -> v.getName() + \"{stored=\" + v.getStorage() + \"}\")\n+                        .collect(Collectors.joining(\", \")));\n+        cluster.client().getClient().customResourceDefinitions().delete(crd);\n+    }\n+\n+    private void assertIsMapListener(Kafka kafka) {\n+        Assertions.assertNotNull(kafka);\n+        Assertions.assertNotNull(kafka.getSpec());\n+        Assertions.assertNotNull(kafka.getSpec().getKafka());\n+        Assertions.assertNotNull(kafka.getSpec().getKafka().getListeners());\n+        Assertions.assertNotNull(kafka.getSpec().getKafka().getListeners().getKafkaListeners());\n+        Assertions.assertNull(kafka.getSpec().getKafka().getListeners().getGenericKafkaListeners());\n+    }\n+\n+    private void assertIsListListener(Kafka kafka) {\n+        Assertions.assertNotNull(kafka);\n+        Assertions.assertNotNull(kafka.getSpec());\n+        Assertions.assertNotNull(kafka.getSpec().getKafka());\n+        Assertions.assertNotNull(kafka.getSpec().getKafka().getListeners());\n+        Assertions.assertNull(kafka.getSpec().getKafka().getListeners().getKafkaListeners());\n+        Assertions.assertNotNull(kafka.getSpec().getKafka().getListeners().getGenericKafkaListeners());\n+    }\n+\n+    private NonNamespaceOperation<Kafka, KafkaList, DoneableKafka, Resource<Kafka, DoneableKafka>> v1beta1Op() {\n+        return Crds.kafkaV1Beta1Operation(cluster.client().getClient()).inNamespace(NAMESPACE);\n+    }\n+\n+    private NonNamespaceOperation<Kafka, KafkaList, DoneableKafka, Resource<Kafka, DoneableKafka>> v1beta2Op() {\n+        return Crds.kafkaV1Beta2Operation(cluster.client().getClient()).inNamespace(NAMESPACE);\n+    }\n+\n+    private GenericKafkaListener listListener() {\n+        return new GenericKafkaListenerBuilder().withType(KafkaListenerType.INTERNAL).withName(\"plain\").withPort(9092).withTls(false).build();\n+    }\n+\n+    private KafkaListeners mapListener() {\n+        return new KafkaListenersBuilder().withNewPlain().endPlain().build();\n+    }\n+\n+    private Kafka buildKafkaCr(String apiVersion, String name, KafkaListeners mapListeners, GenericKafkaListener listListeners) {\n+        if ((mapListeners == null) == (listListeners == null)) {\n+            throw new IllegalArgumentException(\"Exactly one of mapListeners or listListeners must be non-null\");\n+        }\n+        return new KafkaBuilder().withApiVersion(apiVersion)\n+                .withNewMetadata()\n+                    .withName(name)\n+                    .withNamespace(NAMESPACE)\n+                .endMetadata()\n+                .withNewSpec()\n+                    .withNewKafka()\n+                        .withReplicas(1)\n+                        .withNewEphemeralStorage().endEphemeralStorage()\n+                        .withListeners(new ArrayOrObjectKafkaListeners(listListeners == null ? null : singletonList(listListeners), mapListeners))\n+                    .endKafka()\n+                    .withNewZookeeper()\n+                        .withReplicas(1)\n+                        .withNewEphemeralStorage().endEphemeralStorage()\n+                    .endZookeeper()\n+                .endSpec()\n+                        .build();\n+    }\n+\n+\n+    @BeforeAll\n+    void setupEnvironment() {\n+        cluster.createNamespace(NAMESPACE);\n+        //waitForCrd(\"crd\", \"kafkas.kafka.strimzi.io\");\n+    }\n+\n+    @AfterAll\n+    void teardownEnvironment() throws IOException {\n+        deleteCrd(\"src/test/resources/io/strimzi/api/kafka/model//040-Crd-kafka-v1alpha1-v1beta1-store-v1beta1.yaml\");\n+        cluster.deleteNamespaces();\n+    }\n+}\n", "next_change": {"commit": "d35a149d84d2fb0267853c7fea9db5d99f5e85b4", "changed_code": [{"header": "diff --git a/api/src/test/java/io/strimzi/api/kafka/model/ApiEvolutionCrdIT.java b/api/src/test/java/io/strimzi/api/kafka/model/ApiEvolutionCrdIT.java\nindex 0de1fe08a..72a63fe18 100644\n--- a/api/src/test/java/io/strimzi/api/kafka/model/ApiEvolutionCrdIT.java\n+++ b/api/src/test/java/io/strimzi/api/kafka/model/ApiEvolutionCrdIT.java\n", "chunk": "@@ -225,8 +385,7 @@ public class ApiEvolutionCrdIT extends AbstractCrdIT {\n     }\n \n     @AfterAll\n-    void teardownEnvironment() throws IOException {\n-        deleteCrd(\"src/test/resources/io/strimzi/api/kafka/model//040-Crd-kafka-v1alpha1-v1beta1-store-v1beta1.yaml\");\n+    void teardownEnvironment() {\n         cluster.deleteNamespaces();\n     }\n }\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODg3OTA1OQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3653#discussion_r488879059", "bodyText": "Just curious, but wouldn't be better to use switch construction for the else if?", "author": "see-quick", "createdAt": "2020-09-15T18:32:25Z", "path": "crd-generator/src/main/java/io/strimzi/crdgenerator/CrdGenerator.java", "diffHunk": "@@ -652,44 +898,91 @@ ArrayNode stringArray(Iterable<String> list) {\n         return arrayNode;\n     }\n \n-    @SuppressWarnings(\"unchecked\")\n-    public static void main(String[] args) throws IOException, ClassNotFoundException {\n-        boolean yaml = false;\n-        Map<String, String> labels = new LinkedHashMap<>();\n+    static class CommandOptions {\n+        private boolean yaml = false;\n+        private LinkedHashMap<String, String> labels = new LinkedHashMap<>();\n+        VersionRange<KubeVersion> targetKubeVersions = null;\n+        ApiVersion crdApiVersion = null;\n+        List<ApiVersion> apiVersions = null;\n+        ApiVersion storageVersion = null;\n         Map<String, Class<? extends CustomResource>> classes = new HashMap<>();\n-        for (int i = 0; i < args.length; i++) {\n-            String arg = args[i];\n-            if (arg.startsWith(\"--\")) {\n-                if (arg.equals(\"--yaml\")) {\n-                    yaml = true;\n-                } else if (arg.equals(\"--label\")) {\n-                    i++;\n-                    int index = args[i].indexOf(\":\");\n-                    if (index == -1) {\n-                        argParseErr(\"Invalid --label \" + args[i]);\n-                    }\n-                    labels.put(args[i].substring(0, index), args[i].substring(index + 1));\n \n+        @SuppressWarnings({\"unchecked\", \"CyclomaticComplexity\"})\n+        public CommandOptions(String[] args) throws ClassNotFoundException {\n+            for (int i = 0; i < args.length; i++) {\n+                String arg = args[i];\n+                if (arg.startsWith(\"--\")) {\n+                    if (arg.equals(\"--yaml\")) {\n+                        yaml = true;\n+                    } else if (arg.equals(\"--label\")) {", "originalCommit": "6f44863ce8054e309240493821527e26a0034ed7", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e0f92c6fc18b6dd3638f33950c4fc16da6f3d7c5", "changed_code": [{"header": "diff --git a/crd-generator/src/main/java/io/strimzi/crdgenerator/CrdGenerator.java b/crd-generator/src/main/java/io/strimzi/crdgenerator/CrdGenerator.java\nindex 18032b7df..c1c53c7b9 100644\n--- a/crd-generator/src/main/java/io/strimzi/crdgenerator/CrdGenerator.java\n+++ b/crd-generator/src/main/java/io/strimzi/crdgenerator/CrdGenerator.java\n", "chunk": "@@ -906,51 +1021,130 @@ public class CrdGenerator {\n         List<ApiVersion> apiVersions = null;\n         ApiVersion storageVersion = null;\n         Map<String, Class<? extends CustomResource>> classes = new HashMap<>();\n-\n-        @SuppressWarnings({\"unchecked\", \"CyclomaticComplexity\"})\n-        public CommandOptions(String[] args) throws ClassNotFoundException {\n+        private final ConversionStrategy conversionStrategy;\n+\n+        @SuppressWarnings({\"unchecked\", \"CyclomaticComplexity\", \"JavaNCSS\"})\n+        public CommandOptions(String[] args) throws ClassNotFoundException, IOException {\n+            String conversionServiceUrl = null;\n+            String conversionServiceName = null;\n+            String conversionServiceNamespace = null;\n+            String conversionServicePath = null;\n+            int conversionServicePort = -1;\n+            String conversionServiceCaBundle = null;\n             for (int i = 0; i < args.length; i++) {\n                 String arg = args[i];\n                 if (arg.startsWith(\"--\")) {\n-                    if (arg.equals(\"--yaml\")) {\n-                        yaml = true;\n-                    } else if (arg.equals(\"--label\")) {\n-                        i++;\n-                        int index = args[i].indexOf(\":\");\n-                        if (index == -1) {\n-                            argParseErr(\"Invalid --label \" + args[i]);\n-                        }\n-                        labels.put(args[i].substring(0, index), args[i].substring(index + 1));\n-                    } else if (arg.equals(\"--target-kube\")) {\n-                        if (targetKubeVersions != null) {\n-                            argParseErr(\"--target-kube can only be specified once\");\n-                        } else if (i >= arg.length() - 1) {\n-                            argParseErr(\"--target-kube needs an argument\");\n-                        }\n-                        targetKubeVersions = KubeVersion.parseRange(args[++i]);\n-                    } else if (arg.equals(\"--crd-api-version\")) {\n-                        if (crdApiVersion != null) {\n-                            argParseErr(\"--crd-api-version can only be specified once\");\n-                        } else if (i >= arg.length() - 1) {\n-                            argParseErr(\"--crd-api-version needs an argument\");\n-                        }\n-                        crdApiVersion = ApiVersion.parse(args[++i]);\n-                    } else if (arg.equals(\"--api-versions\")) {\n-                        if (apiVersions != null) {\n-                            argParseErr(\"--api-versions can only be specified once\");\n-                        } else if (i >= arg.length() - 1) {\n-                            argParseErr(\"--api-versions needs an argument\");\n-                        }\n-                        apiVersions = Arrays.stream(args[++i].split(\",\")).map(v -> ApiVersion.parse(v)).collect(Collectors.toList());\n-                    } else if (arg.equals(\"--storage-version\")) {\n-                        if (storageVersion != null) {\n-                            argParseErr(\"--storage-version can only be specified once\");\n-                        } else if (i >= arg.length() - 1) {\n-                            argParseErr(\"--storage-version needs an argument\");\n-                        }\n-                        storageVersion = ApiVersion.parse(args[++i]);\n-                    } else {\n-                        throw new RuntimeException(\"Unsupported command line option \" + arg);\n+                    switch (arg) {\n+                        case \"--yaml\":\n+                            yaml = true;\n+                            break;\n+                        case \"--label\":\n+                            i++;\n+                            int index = args[i].indexOf(\":\");\n+                            if (index == -1) {\n+                                argParseErr(\"Invalid --label \" + args[i]);\n+                            }\n+                            labels.put(args[i].substring(0, index), args[i].substring(index + 1));\n+                            break;\n+                        case \"--target-kube\":\n+                            if (targetKubeVersions != null) {\n+                                argParseErr(\"--target-kube can only be specified once\");\n+                            } else if (i >= arg.length() - 1) {\n+                                argParseErr(\"--target-kube needs an argument\");\n+                            } else {\n+                                targetKubeVersions = KubeVersion.parseRange(args[++i]);\n+                            }\n+                            break;\n+                        case \"--crd-api-version\":\n+                            if (crdApiVersion != null) {\n+                                argParseErr(\"--crd-api-version can only be specified once\");\n+                            } else if (i >= arg.length() - 1) {\n+                                argParseErr(\"--crd-api-version needs an argument\");\n+                            } else {\n+                                crdApiVersion = ApiVersion.parse(args[++i]);\n+                            }\n+                            break;\n+                        case \"--api-versions\":\n+                            if (apiVersions != null) {\n+                                argParseErr(\"--api-versions can only be specified once\");\n+                            } else if (i >= arg.length() - 1) {\n+                                argParseErr(\"--api-versions needs an argument\");\n+                            } else {\n+                                apiVersions = Arrays.stream(args[++i].split(\",\")).map(v -> ApiVersion.parse(v)).collect(Collectors.toList());\n+                            }\n+                            break;\n+                        case \"--storage-version\":\n+                            if (storageVersion != null) {\n+                                argParseErr(\"--storage-version can only be specified once\");\n+                            } else if (i >= arg.length() - 1) {\n+                                argParseErr(\"--storage-version needs an argument\");\n+                            } else {\n+                                storageVersion = ApiVersion.parse(args[++i]);\n+                            }\n+                            break;\n+                        case \"--conversion-service-url\":\n+                            if (conversionServiceUrl != null) {\n+                                argParseErr(\"--conversion-service-url can only be specified once\");\n+                            } else if (i >= arg.length() - 1) {\n+                                argParseErr(\"--conversion-service-url needs an argument\");\n+                            } else {\n+                                conversionServiceUrl = args[++i];\n+                            }\n+                            break;\n+                        case \"--conversion-service-name\":\n+                            if (conversionServiceName != null) {\n+                                argParseErr(\"--conversion-service-name can only be specified once\");\n+                            } else if (i >= arg.length() - 1) {\n+                                argParseErr(\"--conversion-service-name needs an argument\");\n+                            } else {\n+                                conversionServiceName = args[++i];\n+                            }\n+                            break;\n+                        case \"--conversion-service-namespace\":\n+                            if (conversionServiceNamespace != null) {\n+                                argParseErr(\"--conversion-service-namespace can only be specified once\");\n+                            } else if (i >= arg.length() - 1) {\n+                                argParseErr(\"--conversion-service-namespace needs an argument\");\n+                            } else {\n+                                conversionServiceNamespace = args[++i];\n+                            }\n+                            break;\n+                        case \"--conversion-service-path\":\n+                            if (conversionServicePath != null) {\n+                                argParseErr(\"--conversion-service-path can only be specified once\");\n+                            } else if (i >= arg.length() - 1) {\n+                                argParseErr(\"--conversion-service-path needs an argument\");\n+                            } else {\n+                                conversionServicePath = args[++i];\n+                            }\n+                            break;\n+                        case \"--conversion-service-port\":\n+                            if (conversionServicePort > 0) {\n+                                argParseErr(\"--conversion-service-port can only be specified once\");\n+                            } else if (i >= arg.length() - 1) {\n+                                argParseErr(\"--conversion-service-port needs an argument\");\n+                            } else {\n+                                conversionServicePort = parseInt(args[++i]);\n+                            }\n+                            break;\n+                        case \"--conversion-service-ca-bundle\":\n+                            if (conversionServiceCaBundle != null) {\n+                                argParseErr(\"--conversion-service-ca-bundle can only be specified once\");\n+                            } else if (i >= arg.length() - 1) {\n+                                argParseErr(\"--conversion-service-ca-bundle needs an argument\");\n+                            } else {\n+                                // TODO read file and base64\n+                                File file = new File(args[++i]);\n+                                byte[] bundleBytes = Files.readAllBytes(file.toPath());\n+                                conversionServiceCaBundle = new String(bundleBytes, StandardCharsets.UTF_8);\n+                                if (!conversionServiceCaBundle.contains(\"-----BEGIN CERTIFICATE-----\")) {\n+                                    throw new IllegalStateException(\"File \" + file + \" given by --conversion-service-ca-bundle should be PEM encoded\");\n+                                }\n+                                conversionServiceCaBundle = Base64.getEncoder().encodeToString(bundleBytes);\n+                            }\n+                            break;\n+                        default:\n+                            throw new RuntimeException(\"Unsupported command line option \" + arg);\n                     }\n                 } else {\n                     String className = arg.substring(0, arg.indexOf('='));\n", "next_change": {"commit": "a2aeb50ef0497a39e49106539b6d506b86cfbf91", "changed_code": [{"header": "diff --git a/crd-generator/src/main/java/io/strimzi/crdgenerator/CrdGenerator.java b/crd-generator/src/main/java/io/strimzi/crdgenerator/CrdGenerator.java\nindex c1c53c7b9..6b6778fa0 100644\n--- a/crd-generator/src/main/java/io/strimzi/crdgenerator/CrdGenerator.java\n+++ b/crd-generator/src/main/java/io/strimzi/crdgenerator/CrdGenerator.java\n", "chunk": "@@ -1013,175 +657,44 @@ public class CrdGenerator {\n         return arrayNode;\n     }\n \n-    static class CommandOptions {\n-        private boolean yaml = false;\n-        private LinkedHashMap<String, String> labels = new LinkedHashMap<>();\n-        VersionRange<KubeVersion> targetKubeVersions = null;\n-        ApiVersion crdApiVersion = null;\n-        List<ApiVersion> apiVersions = null;\n-        ApiVersion storageVersion = null;\n+    @SuppressWarnings(\"unchecked\")\n+    public static void main(String[] args) throws IOException, ClassNotFoundException {\n+        boolean yaml = false;\n+        Map<String, String> labels = new LinkedHashMap<>();\n         Map<String, Class<? extends CustomResource>> classes = new HashMap<>();\n-        private final ConversionStrategy conversionStrategy;\n-\n-        @SuppressWarnings({\"unchecked\", \"CyclomaticComplexity\", \"JavaNCSS\"})\n-        public CommandOptions(String[] args) throws ClassNotFoundException, IOException {\n-            String conversionServiceUrl = null;\n-            String conversionServiceName = null;\n-            String conversionServiceNamespace = null;\n-            String conversionServicePath = null;\n-            int conversionServicePort = -1;\n-            String conversionServiceCaBundle = null;\n-            for (int i = 0; i < args.length; i++) {\n-                String arg = args[i];\n-                if (arg.startsWith(\"--\")) {\n-                    switch (arg) {\n-                        case \"--yaml\":\n-                            yaml = true;\n-                            break;\n-                        case \"--label\":\n-                            i++;\n-                            int index = args[i].indexOf(\":\");\n-                            if (index == -1) {\n-                                argParseErr(\"Invalid --label \" + args[i]);\n-                            }\n-                            labels.put(args[i].substring(0, index), args[i].substring(index + 1));\n-                            break;\n-                        case \"--target-kube\":\n-                            if (targetKubeVersions != null) {\n-                                argParseErr(\"--target-kube can only be specified once\");\n-                            } else if (i >= arg.length() - 1) {\n-                                argParseErr(\"--target-kube needs an argument\");\n-                            } else {\n-                                targetKubeVersions = KubeVersion.parseRange(args[++i]);\n-                            }\n-                            break;\n-                        case \"--crd-api-version\":\n-                            if (crdApiVersion != null) {\n-                                argParseErr(\"--crd-api-version can only be specified once\");\n-                            } else if (i >= arg.length() - 1) {\n-                                argParseErr(\"--crd-api-version needs an argument\");\n-                            } else {\n-                                crdApiVersion = ApiVersion.parse(args[++i]);\n-                            }\n-                            break;\n-                        case \"--api-versions\":\n-                            if (apiVersions != null) {\n-                                argParseErr(\"--api-versions can only be specified once\");\n-                            } else if (i >= arg.length() - 1) {\n-                                argParseErr(\"--api-versions needs an argument\");\n-                            } else {\n-                                apiVersions = Arrays.stream(args[++i].split(\",\")).map(v -> ApiVersion.parse(v)).collect(Collectors.toList());\n-                            }\n-                            break;\n-                        case \"--storage-version\":\n-                            if (storageVersion != null) {\n-                                argParseErr(\"--storage-version can only be specified once\");\n-                            } else if (i >= arg.length() - 1) {\n-                                argParseErr(\"--storage-version needs an argument\");\n-                            } else {\n-                                storageVersion = ApiVersion.parse(args[++i]);\n-                            }\n-                            break;\n-                        case \"--conversion-service-url\":\n-                            if (conversionServiceUrl != null) {\n-                                argParseErr(\"--conversion-service-url can only be specified once\");\n-                            } else if (i >= arg.length() - 1) {\n-                                argParseErr(\"--conversion-service-url needs an argument\");\n-                            } else {\n-                                conversionServiceUrl = args[++i];\n-                            }\n-                            break;\n-                        case \"--conversion-service-name\":\n-                            if (conversionServiceName != null) {\n-                                argParseErr(\"--conversion-service-name can only be specified once\");\n-                            } else if (i >= arg.length() - 1) {\n-                                argParseErr(\"--conversion-service-name needs an argument\");\n-                            } else {\n-                                conversionServiceName = args[++i];\n-                            }\n-                            break;\n-                        case \"--conversion-service-namespace\":\n-                            if (conversionServiceNamespace != null) {\n-                                argParseErr(\"--conversion-service-namespace can only be specified once\");\n-                            } else if (i >= arg.length() - 1) {\n-                                argParseErr(\"--conversion-service-namespace needs an argument\");\n-                            } else {\n-                                conversionServiceNamespace = args[++i];\n-                            }\n-                            break;\n-                        case \"--conversion-service-path\":\n-                            if (conversionServicePath != null) {\n-                                argParseErr(\"--conversion-service-path can only be specified once\");\n-                            } else if (i >= arg.length() - 1) {\n-                                argParseErr(\"--conversion-service-path needs an argument\");\n-                            } else {\n-                                conversionServicePath = args[++i];\n-                            }\n-                            break;\n-                        case \"--conversion-service-port\":\n-                            if (conversionServicePort > 0) {\n-                                argParseErr(\"--conversion-service-port can only be specified once\");\n-                            } else if (i >= arg.length() - 1) {\n-                                argParseErr(\"--conversion-service-port needs an argument\");\n-                            } else {\n-                                conversionServicePort = parseInt(args[++i]);\n-                            }\n-                            break;\n-                        case \"--conversion-service-ca-bundle\":\n-                            if (conversionServiceCaBundle != null) {\n-                                argParseErr(\"--conversion-service-ca-bundle can only be specified once\");\n-                            } else if (i >= arg.length() - 1) {\n-                                argParseErr(\"--conversion-service-ca-bundle needs an argument\");\n-                            } else {\n-                                // TODO read file and base64\n-                                File file = new File(args[++i]);\n-                                byte[] bundleBytes = Files.readAllBytes(file.toPath());\n-                                conversionServiceCaBundle = new String(bundleBytes, StandardCharsets.UTF_8);\n-                                if (!conversionServiceCaBundle.contains(\"-----BEGIN CERTIFICATE-----\")) {\n-                                    throw new IllegalStateException(\"File \" + file + \" given by --conversion-service-ca-bundle should be PEM encoded\");\n-                                }\n-                                conversionServiceCaBundle = Base64.getEncoder().encodeToString(bundleBytes);\n-                            }\n-                            break;\n-                        default:\n-                            throw new RuntimeException(\"Unsupported command line option \" + arg);\n+        for (int i = 0; i < args.length; i++) {\n+            String arg = args[i];\n+            if (arg.startsWith(\"--\")) {\n+                if (arg.equals(\"--yaml\")) {\n+                    yaml = true;\n+                } else if (arg.equals(\"--label\")) {\n+                    i++;\n+                    int index = args[i].indexOf(\":\");\n+                    if (index == -1) {\n+                        argParseErr(\"Invalid --label \" + args[i]);\n                     }\n+                    labels.put(args[i].substring(0, index), args[i].substring(index + 1));\n+\n                 } else {\n-                    String className = arg.substring(0, arg.indexOf('='));\n-                    String fileName = arg.substring(arg.indexOf('=') + 1).replace(\"/\", File.separator);\n-                    Class<?> cls = Class.forName(className);\n-                    if (!CustomResource.class.equals(cls)\n-                            && CustomResource.class.isAssignableFrom(cls)) {\n-                        classes.put(fileName, (Class<? extends CustomResource>) cls);\n-                    } else {\n-                        argParseErr(cls + \" is not a subclass of \" + CustomResource.class.getName());\n-                    }\n+                    throw new RuntimeException(\"Unsupported command line option \" + arg);\n                 }\n-            }\n-            if (targetKubeVersions == null) {\n-                targetKubeVersions = KubeVersion.parseRange(\"1.11+\");\n-            }\n-            if (crdApiVersion == null) {\n-                crdApiVersion = ApiVersion.V1BETA1;\n-            }\n-            if (conversionServiceName != null) {\n-                conversionStrategy = new WebhookConversionStrategy(conversionServiceName, conversionServiceNamespace, conversionServicePath, conversionServicePort, conversionServiceCaBundle);\n-            } else if (conversionServiceUrl != null) {\n-                conversionStrategy = new WebhookConversionStrategy(conversionServiceName, conversionServiceCaBundle);\n             } else {\n-                conversionStrategy = new NoneConversionStrategy();\n+                String className = arg.substring(0, arg.indexOf('='));\n+                String fileName = arg.substring(arg.indexOf('=') + 1).replace(\"/\", File.separator);\n+                Class<?> cls = Class.forName(className);\n+                if (!CustomResource.class.equals(cls)\n+                        && CustomResource.class.isAssignableFrom(cls)) {\n+                    classes.put(fileName, (Class<? extends CustomResource>) cls);\n+                } else {\n+                    argParseErr(cls + \" is not a subclass of \" + CustomResource.class.getName());\n+                }\n             }\n         }\n-    }\n-\n-    public static void main(String[] args) throws IOException, ClassNotFoundException {\n-        CommandOptions opts = new CommandOptions(args);\n \n-        CrdGenerator generator = new CrdGenerator(opts.targetKubeVersions, opts.crdApiVersion,\n-                opts.yaml ? YAML_MAPPER.configure(YAMLGenerator.Feature.MINIMIZE_QUOTES, true) : JSON_MATTER,\n-                opts.labels, new DefaultReporter(),\n-                opts.apiVersions, opts.storageVersion, null, opts.conversionStrategy);\n-        for (Map.Entry<String, Class<? extends CustomResource>> entry : opts.classes.entrySet()) {\n+        CrdGenerator generator = new CrdGenerator(yaml ?\n+                new YAMLMapper().configure(YAMLGenerator.Feature.MINIMIZE_QUOTES, true).configure(YAMLGenerator.Feature.WRITE_DOC_START_MARKER, false) :\n+                new ObjectMapper(), labels);\n+        for (Map.Entry<String, Class<? extends CustomResource>> entry : classes.entrySet()) {\n             File file = new File(entry.getKey());\n             if (file.getParentFile().exists()) {\n                 if (!file.getParentFile().isDirectory()) {\n", "next_change": {"commit": "4815308c7d19fc21416c9c75eb60c1c88518330c", "changed_code": [{"header": "diff --git a/crd-generator/src/main/java/io/strimzi/crdgenerator/CrdGenerator.java b/crd-generator/src/main/java/io/strimzi/crdgenerator/CrdGenerator.java\nindex 6b6778fa0..2070f2747 100644\n--- a/crd-generator/src/main/java/io/strimzi/crdgenerator/CrdGenerator.java\n+++ b/crd-generator/src/main/java/io/strimzi/crdgenerator/CrdGenerator.java\n", "chunk": "@@ -690,8 +830,11 @@ public class CrdGenerator {\n                 }\n             }\n         }\n+        if (targetKubeVersion == null) {\n+            targetKubeVersion = KubeVersion.v1_11;\n+        }\n \n-        CrdGenerator generator = new CrdGenerator(yaml ?\n+        CrdGenerator generator = new CrdGenerator(targetKubeVersion, yaml ?\n                 new YAMLMapper().configure(YAMLGenerator.Feature.MINIMIZE_QUOTES, true).configure(YAMLGenerator.Feature.WRITE_DOC_START_MARKER, false) :\n                 new ObjectMapper(), labels);\n         for (Map.Entry<String, Class<? extends CustomResource>> entry : classes.entrySet()) {\n", "next_change": {"commit": "0e5c41b5ecf1aa3e3ac264a547f8044485a43624", "changed_code": [{"header": "diff --git a/crd-generator/src/main/java/io/strimzi/crdgenerator/CrdGenerator.java b/crd-generator/src/main/java/io/strimzi/crdgenerator/CrdGenerator.java\nindex 2070f2747..3ffe226fb 100644\n--- a/crd-generator/src/main/java/io/strimzi/crdgenerator/CrdGenerator.java\n+++ b/crd-generator/src/main/java/io/strimzi/crdgenerator/CrdGenerator.java\n", "chunk": "@@ -831,7 +833,7 @@ public class CrdGenerator {\n             }\n         }\n         if (targetKubeVersion == null) {\n-            targetKubeVersion = KubeVersion.v1_11;\n+            targetKubeVersion = KubeVersion.V1_11;\n         }\n \n         CrdGenerator generator = new CrdGenerator(targetKubeVersion, yaml ?\n", "next_change": {"commit": "3577b7170a381cfc97d3e058c1c41d93e672ac3d", "changed_code": [{"header": "diff --git a/crd-generator/src/main/java/io/strimzi/crdgenerator/CrdGenerator.java b/crd-generator/src/main/java/io/strimzi/crdgenerator/CrdGenerator.java\nindex 3ffe226fb..c6360d1e9 100644\n--- a/crd-generator/src/main/java/io/strimzi/crdgenerator/CrdGenerator.java\n+++ b/crd-generator/src/main/java/io/strimzi/crdgenerator/CrdGenerator.java\n", "chunk": "@@ -792,54 +907,91 @@ public class CrdGenerator {\n         return arrayNode;\n     }\n \n-    @SuppressWarnings(\"unchecked\")\n-    public static void main(String[] args) throws IOException, ClassNotFoundException {\n-        boolean yaml = false;\n-        Map<String, String> labels = new LinkedHashMap<>();\n+    static class CommandOptions {\n+        private boolean yaml = false;\n+        private LinkedHashMap<String, String> labels = new LinkedHashMap<>();\n+        VersionRange<KubeVersion> targetKubeVersions = null;\n+        ApiVersion crdApiVersion = null;\n+        List<ApiVersion> apiVersions = null;\n+        ApiVersion storageVersion = null;\n         Map<String, Class<? extends CustomResource>> classes = new HashMap<>();\n-        KubeVersion targetKubeVersion = null;\n-        for (int i = 0; i < args.length; i++) {\n-            String arg = args[i];\n-            if (arg.startsWith(\"--\")) {\n-                if (arg.equals(\"--yaml\")) {\n-                    yaml = true;\n-                } else if (arg.equals(\"--label\")) {\n-                    i++;\n-                    int index = args[i].indexOf(\":\");\n-                    if (index == -1) {\n-                        argParseErr(\"Invalid --label \" + args[i]);\n-                    }\n-                    labels.put(args[i].substring(0, index), args[i].substring(index + 1));\n-                } else if (arg.equals(\"--target-kube\")) {\n-                    if (targetKubeVersion != null) {\n-                        argParseErr(\"--target-kube can only be specified once\");\n-                    } else if (i >= arg.length() - 1) {\n-                        argParseErr(\"--target-kube needs an argument\");\n+\n+        @SuppressWarnings({\"unchecked\", \"CyclomaticComplexity\"})\n+        public CommandOptions(String[] args) throws ClassNotFoundException {\n+            for (int i = 0; i < args.length; i++) {\n+                String arg = args[i];\n+                if (arg.startsWith(\"--\")) {\n+                    if (arg.equals(\"--yaml\")) {\n+                        yaml = true;\n+                    } else if (arg.equals(\"--label\")) {\n+                        i++;\n+                        int index = args[i].indexOf(\":\");\n+                        if (index == -1) {\n+                            argParseErr(\"Invalid --label \" + args[i]);\n+                        }\n+                        labels.put(args[i].substring(0, index), args[i].substring(index + 1));\n+                    } else if (arg.equals(\"--target-kube\")) {\n+                        if (targetKubeVersions != null) {\n+                            argParseErr(\"--target-kube can only be specified once\");\n+                        } else if (i >= arg.length() - 1) {\n+                            argParseErr(\"--target-kube needs an argument\");\n+                        }\n+                        targetKubeVersions = KubeVersion.parseRange(args[++i]);\n+                    } else if (arg.equals(\"--crd-api-version\")) {\n+                        if (crdApiVersion != null) {\n+                            argParseErr(\"--crd-api-version can only be specified once\");\n+                        } else if (i >= arg.length() - 1) {\n+                            argParseErr(\"--crd-api-version needs an argument\");\n+                        }\n+                        crdApiVersion = ApiVersion.parse(args[++i]);\n+                    } else if (arg.equals(\"--api-versions\")) {\n+                        if (apiVersions != null) {\n+                            argParseErr(\"--api-versions can only be specified once\");\n+                        } else if (i >= arg.length() - 1) {\n+                            argParseErr(\"--api-versions needs an argument\");\n+                        }\n+                        apiVersions = Arrays.stream(args[++i].split(\",\")).map(v -> ApiVersion.parse(v)).collect(Collectors.toList());\n+                    } else if (arg.equals(\"--storage-version\")) {\n+                        if (storageVersion != null) {\n+                            argParseErr(\"--storage-version can only be specified once\");\n+                        } else if (i >= arg.length() - 1) {\n+                            argParseErr(\"--storage-version needs an argument\");\n+                        }\n+                        storageVersion = ApiVersion.parse(args[++i]);\n+                    } else {\n+                        throw new RuntimeException(\"Unsupported command line option \" + arg);\n                     }\n-                    targetKubeVersion = KubeVersion.parse(args[++i]);\n-                } else {\n-                    throw new RuntimeException(\"Unsupported command line option \" + arg);\n-                }\n-            } else {\n-                String className = arg.substring(0, arg.indexOf('='));\n-                String fileName = arg.substring(arg.indexOf('=') + 1).replace(\"/\", File.separator);\n-                Class<?> cls = Class.forName(className);\n-                if (!CustomResource.class.equals(cls)\n-                        && CustomResource.class.isAssignableFrom(cls)) {\n-                    classes.put(fileName, (Class<? extends CustomResource>) cls);\n                 } else {\n-                    argParseErr(cls + \" is not a subclass of \" + CustomResource.class.getName());\n+                    String className = arg.substring(0, arg.indexOf('='));\n+                    String fileName = arg.substring(arg.indexOf('=') + 1).replace(\"/\", File.separator);\n+                    Class<?> cls = Class.forName(className);\n+                    if (!CustomResource.class.equals(cls)\n+                            && CustomResource.class.isAssignableFrom(cls)) {\n+                        classes.put(fileName, (Class<? extends CustomResource>) cls);\n+                    } else {\n+                        argParseErr(cls + \" is not a subclass of \" + CustomResource.class.getName());\n+                    }\n                 }\n             }\n+            if (targetKubeVersions == null) {\n+                targetKubeVersions = KubeVersion.parseRange(\"1.11+\");\n+            }\n+            if (crdApiVersion == null) {\n+                crdApiVersion = ApiVersion.V1BETA1;\n+            }\n         }\n-        if (targetKubeVersion == null) {\n-            targetKubeVersion = KubeVersion.V1_11;\n-        }\n+    }\n \n-        CrdGenerator generator = new CrdGenerator(targetKubeVersion, yaml ?\n-                new YAMLMapper().configure(YAMLGenerator.Feature.MINIMIZE_QUOTES, true).configure(YAMLGenerator.Feature.WRITE_DOC_START_MARKER, false) :\n-                new ObjectMapper(), labels);\n-        for (Map.Entry<String, Class<? extends CustomResource>> entry : classes.entrySet()) {\n+    public static void main(String[] args) throws IOException, ClassNotFoundException {\n+        CommandOptions opts = new CommandOptions(args);\n+\n+        CrdGenerator generator = new CrdGenerator(opts.targetKubeVersions, opts.crdApiVersion,\n+                new DefaultReporter(),\n+                opts.yaml ?\n+                new YAMLMapper().configure(YAMLGenerator.Feature.MINIMIZE_QUOTES, true)\n+                        .configure(YAMLGenerator.Feature.WRITE_DOC_START_MARKER, false) :\n+                new ObjectMapper(), opts.labels, opts.apiVersions, opts.storageVersion);\n+        for (Map.Entry<String, Class<? extends CustomResource>> entry : opts.classes.entrySet()) {\n             File file = new File(entry.getKey());\n             if (file.getParentFile().exists()) {\n                 if (!file.getParentFile().isDirectory()) {\n", "next_change": {"commit": "d35a149d84d2fb0267853c7fea9db5d99f5e85b4", "changed_code": [{"header": "diff --git a/crd-generator/src/main/java/io/strimzi/crdgenerator/CrdGenerator.java b/crd-generator/src/main/java/io/strimzi/crdgenerator/CrdGenerator.java\nindex c6360d1e9..63e13dec3 100644\n--- a/crd-generator/src/main/java/io/strimzi/crdgenerator/CrdGenerator.java\n+++ b/crd-generator/src/main/java/io/strimzi/crdgenerator/CrdGenerator.java\n", "chunk": "@@ -986,11 +1178,9 @@ public class CrdGenerator {\n         CommandOptions opts = new CommandOptions(args);\n \n         CrdGenerator generator = new CrdGenerator(opts.targetKubeVersions, opts.crdApiVersion,\n-                new DefaultReporter(),\n-                opts.yaml ?\n-                new YAMLMapper().configure(YAMLGenerator.Feature.MINIMIZE_QUOTES, true)\n-                        .configure(YAMLGenerator.Feature.WRITE_DOC_START_MARKER, false) :\n-                new ObjectMapper(), opts.labels, opts.apiVersions, opts.storageVersion);\n+                opts.yaml ? YAML_MAPPER : JSON_MATTER,\n+                opts.labels, new DefaultReporter(),\n+                opts.apiVersions, opts.storageVersion, null, opts.conversionStrategy);\n         for (Map.Entry<String, Class<? extends CustomResource>> entry : opts.classes.entrySet()) {\n             File file = new File(entry.getKey());\n             if (file.getParentFile().exists()) {\n", "next_change": {"commit": "651a6a425367cc52e97c95fd6bf8a5368100eb04", "changed_code": [{"header": "diff --git a/crd-generator/src/main/java/io/strimzi/crdgenerator/CrdGenerator.java b/crd-generator/src/main/java/io/strimzi/crdgenerator/CrdGenerator.java\nindex 63e13dec3..985b9ba30 100644\n--- a/crd-generator/src/main/java/io/strimzi/crdgenerator/CrdGenerator.java\n+++ b/crd-generator/src/main/java/io/strimzi/crdgenerator/CrdGenerator.java\n", "chunk": "@@ -1178,7 +1183,7 @@ public class CrdGenerator {\n         CommandOptions opts = new CommandOptions(args);\n \n         CrdGenerator generator = new CrdGenerator(opts.targetKubeVersions, opts.crdApiVersion,\n-                opts.yaml ? YAML_MAPPER : JSON_MATTER,\n+                opts.yaml ? YAML_MAPPER.configure(YAMLGenerator.Feature.MINIMIZE_QUOTES, true) : JSON_MATTER,\n                 opts.labels, new DefaultReporter(),\n                 opts.apiVersions, opts.storageVersion, null, opts.conversionStrategy);\n         for (Map.Entry<String, Class<? extends CustomResource>> entry : opts.classes.entrySet()) {\n", "next_change": null}]}}]}}]}}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODk0NzAzOA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3653#discussion_r488947038", "bodyText": "What is the difference for these two? Will each of these watch for another version resource? Will we need to do everything twice in the operators?", "author": "scholzj", "createdAt": "2020-09-15T20:16:13Z", "path": "api/src/main/java/io/strimzi/api/kafka/Crds.java", "diffHunk": "@@ -269,6 +269,14 @@ public static CustomResourceDefinition kafka() {\n         return client.customResources(CustomResourceDefinitionContext.fromCrd(crd(Kafka.class, Constants.V1ALPHA1)), Kafka.class, KafkaList.class, DoneableKafka.class);\n     }\n \n+    public static MixedOperation<Kafka, KafkaList, DoneableKafka, Resource<Kafka, DoneableKafka>> kafkaV1Beta1Operation(KubernetesClient client) {\n+        return client.customResources(CustomResourceDefinitionContext.fromCrd(crd(Kafka.class, Constants.V1BETA1)), Kafka.class, KafkaList.class, DoneableKafka.class);\n+    }\n+\n+    public static MixedOperation<Kafka, KafkaList, DoneableKafka, Resource<Kafka, DoneableKafka>> kafkaV1Beta2Operation(KubernetesClient client) {\n+        return client.customResources(CustomResourceDefinitionContext.fromCrd(crd(Kafka.class, Constants.V1BETA2)), Kafka.class, KafkaList.class, DoneableKafka.class);\n+    }", "originalCommit": "6f44863ce8054e309240493821527e26a0034ed7", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e0f92c6fc18b6dd3638f33950c4fc16da6f3d7c5", "changed_code": [{"header": "diff --git a/api/src/main/java/io/strimzi/api/kafka/Crds.java b/api/src/main/java/io/strimzi/api/kafka/Crds.java\nindex 9f1698f9b..1b430432e 100644\n--- a/api/src/main/java/io/strimzi/api/kafka/Crds.java\n+++ b/api/src/main/java/io/strimzi/api/kafka/Crds.java\n", "chunk": "@@ -277,6 +277,10 @@ public class Crds {\n         return client.customResources(CustomResourceDefinitionContext.fromCrd(crd(Kafka.class, Constants.V1BETA2)), Kafka.class, KafkaList.class, DoneableKafka.class);\n     }\n \n+    public static MixedOperation<Kafka, KafkaList, DoneableKafka, Resource<Kafka, DoneableKafka>> kafkaV1Operation(KubernetesClient client) {\n+        return client.customResources(CustomResourceDefinitionContext.fromCrd(crd(Kafka.class, Constants.V1)), Kafka.class, KafkaList.class, DoneableKafka.class);\n+    }\n+\n     public static CustomResourceDefinition kafkaConnect() {\n         return crd(KafkaConnect.class);\n     }\n", "next_change": {"commit": "a2aeb50ef0497a39e49106539b6d506b86cfbf91", "changed_code": [{"header": "diff --git a/api/src/main/java/io/strimzi/api/kafka/Crds.java b/api/src/main/java/io/strimzi/api/kafka/Crds.java\nindex 1b430432e..5d063f853 100644\n--- a/api/src/main/java/io/strimzi/api/kafka/Crds.java\n+++ b/api/src/main/java/io/strimzi/api/kafka/Crds.java\n", "chunk": "@@ -269,18 +269,6 @@ public class Crds {\n         return client.customResources(CustomResourceDefinitionContext.fromCrd(crd(Kafka.class, Constants.V1ALPHA1)), Kafka.class, KafkaList.class, DoneableKafka.class);\n     }\n \n-    public static MixedOperation<Kafka, KafkaList, DoneableKafka, Resource<Kafka, DoneableKafka>> kafkaV1Beta1Operation(KubernetesClient client) {\n-        return client.customResources(CustomResourceDefinitionContext.fromCrd(crd(Kafka.class, Constants.V1BETA1)), Kafka.class, KafkaList.class, DoneableKafka.class);\n-    }\n-\n-    public static MixedOperation<Kafka, KafkaList, DoneableKafka, Resource<Kafka, DoneableKafka>> kafkaV1Beta2Operation(KubernetesClient client) {\n-        return client.customResources(CustomResourceDefinitionContext.fromCrd(crd(Kafka.class, Constants.V1BETA2)), Kafka.class, KafkaList.class, DoneableKafka.class);\n-    }\n-\n-    public static MixedOperation<Kafka, KafkaList, DoneableKafka, Resource<Kafka, DoneableKafka>> kafkaV1Operation(KubernetesClient client) {\n-        return client.customResources(CustomResourceDefinitionContext.fromCrd(crd(Kafka.class, Constants.V1)), Kafka.class, KafkaList.class, DoneableKafka.class);\n-    }\n-\n     public static CustomResourceDefinition kafkaConnect() {\n         return crd(KafkaConnect.class);\n     }\n", "next_change": {"commit": "3577b7170a381cfc97d3e058c1c41d93e672ac3d", "changed_code": [{"header": "diff --git a/api/src/main/java/io/strimzi/api/kafka/Crds.java b/api/src/main/java/io/strimzi/api/kafka/Crds.java\nindex 5d063f853..a050f82cb 100644\n--- a/api/src/main/java/io/strimzi/api/kafka/Crds.java\n+++ b/api/src/main/java/io/strimzi/api/kafka/Crds.java\n", "chunk": "@@ -269,6 +269,14 @@ public class Crds {\n         return client.customResources(CustomResourceDefinitionContext.fromCrd(crd(Kafka.class, Constants.V1ALPHA1)), Kafka.class, KafkaList.class, DoneableKafka.class);\n     }\n \n+    public static MixedOperation<Kafka, KafkaList, DoneableKafka, Resource<Kafka, DoneableKafka>> kafkaV1Beta1Operation(KubernetesClient client) {\n+        return client.customResources(CustomResourceDefinitionContext.fromCrd(crd(Kafka.class, Constants.V1BETA1)), Kafka.class, KafkaList.class, DoneableKafka.class);\n+    }\n+\n+    public static MixedOperation<Kafka, KafkaList, DoneableKafka, Resource<Kafka, DoneableKafka>> kafkaV1Beta2Operation(KubernetesClient client) {\n+        return client.customResources(CustomResourceDefinitionContext.fromCrd(crd(Kafka.class, Constants.V1BETA2)), Kafka.class, KafkaList.class, DoneableKafka.class);\n+    }\n+\n     public static CustomResourceDefinition kafkaConnect() {\n         return crd(KafkaConnect.class);\n     }\n", "next_change": {"commit": "d35a149d84d2fb0267853c7fea9db5d99f5e85b4", "changed_code": [{"header": "diff --git a/api/src/main/java/io/strimzi/api/kafka/Crds.java b/api/src/main/java/io/strimzi/api/kafka/Crds.java\nindex a050f82cb..1b430432e 100644\n--- a/api/src/main/java/io/strimzi/api/kafka/Crds.java\n+++ b/api/src/main/java/io/strimzi/api/kafka/Crds.java\n", "chunk": "@@ -277,6 +277,10 @@ public class Crds {\n         return client.customResources(CustomResourceDefinitionContext.fromCrd(crd(Kafka.class, Constants.V1BETA2)), Kafka.class, KafkaList.class, DoneableKafka.class);\n     }\n \n+    public static MixedOperation<Kafka, KafkaList, DoneableKafka, Resource<Kafka, DoneableKafka>> kafkaV1Operation(KubernetesClient client) {\n+        return client.customResources(CustomResourceDefinitionContext.fromCrd(crd(Kafka.class, Constants.V1)), Kafka.class, KafkaList.class, DoneableKafka.class);\n+    }\n+\n     public static CustomResourceDefinition kafkaConnect() {\n         return crd(KafkaConnect.class);\n     }\n", "next_change": null}]}}]}}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIyMDU3MA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3653#discussion_r489220570", "bodyText": "What's the syntax for the value of this annotation? It's an interval or a list? or something different?", "author": "ppatierno", "createdAt": "2020-09-16T07:26:10Z", "path": "api/src/main/java/io/strimzi/api/kafka/model/KafkaClusterSpec.java", "diffHunk": "@@ -146,6 +147,7 @@ public void setLogging(Logging logging) {\n         this.logging = logging;\n     }\n \n+    @PresentInVersions(\"v1alpha1-v1beta1\")", "originalCommit": "6f44863ce8054e309240493821527e26a0034ed7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTI1NjE3NA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3653#discussion_r489256174", "bodyText": "It's described here: https://github.com/strimzi/strimzi-kafka-operator/pull/3653/files#diff-762d04edf28bcda2d851e559e33f5ea4R93. In this case it's an interval with inclusive ends (we don't actually know whether there is a v1alpha2, we just compute inclusion based on the endpoints). It can also be an open-ended interval (e.g. v1beta2+), or a single version (v1beta1).", "author": "tombentley", "createdAt": "2020-09-16T08:26:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIyMDU3MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTI2MDAwNA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3653#discussion_r489260004", "bodyText": "Thanks, got it!", "author": "ppatierno", "createdAt": "2020-09-16T08:32:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIyMDU3MA=="}], "type": "inlineReview", "revised_code": {"commit": "a2aeb50ef0497a39e49106539b6d506b86cfbf91", "changed_code": [{"header": "diff --git a/api/src/main/java/io/strimzi/api/kafka/model/KafkaClusterSpec.java b/api/src/main/java/io/strimzi/api/kafka/model/KafkaClusterSpec.java\nindex a99e48c85..db7808dab 100644\n--- a/api/src/main/java/io/strimzi/api/kafka/model/KafkaClusterSpec.java\n+++ b/api/src/main/java/io/strimzi/api/kafka/model/KafkaClusterSpec.java\n", "chunk": "@@ -147,7 +146,6 @@ public class KafkaClusterSpec implements UnknownPropertyPreserving, Serializable\n         this.logging = logging;\n     }\n \n-    @PresentInVersions(\"v1alpha1-v1beta1\")\n     @DeprecatedProperty\n     @Deprecated\n     @Description(\"TLS sidecar configuration\")\n", "next_change": {"commit": "3577b7170a381cfc97d3e058c1c41d93e672ac3d", "changed_code": [{"header": "diff --git a/api/src/main/java/io/strimzi/api/kafka/model/KafkaClusterSpec.java b/api/src/main/java/io/strimzi/api/kafka/model/KafkaClusterSpec.java\nindex db7808dab..a99e48c85 100644\n--- a/api/src/main/java/io/strimzi/api/kafka/model/KafkaClusterSpec.java\n+++ b/api/src/main/java/io/strimzi/api/kafka/model/KafkaClusterSpec.java\n", "chunk": "@@ -146,6 +147,7 @@ public class KafkaClusterSpec implements UnknownPropertyPreserving, Serializable\n         this.logging = logging;\n     }\n \n+    @PresentInVersions(\"v1alpha1-v1beta1\")\n     @DeprecatedProperty\n     @Deprecated\n     @Description(\"TLS sidecar configuration\")\n", "next_change": null}]}}]}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIyNDA4OA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3653#discussion_r489224088", "bodyText": "can we think more about using an enum as Alpha, Beta and Stable instead of short values 0, 1 and 2 (that anyway could be the corresponding underlying values of the enum)", "author": "ppatierno", "createdAt": "2020-09-16T07:32:15Z", "path": "crd-generator/src/main/java/io/strimzi/crdgenerator/ApiVersion.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.crdgenerator;\n+\n+\n+import java.util.Objects;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+import static java.lang.Short.parseShort;\n+\n+/**\n+ * Represents the version of a Kubernetes API, for example {@code v1alpha1} or {@code v2}.\n+ * These version numbers are comparable, so {@code v1alpha1 < v1beta1 < v1 < v2alpha1} etc.\n+ */\n+public class ApiVersion implements Comparable<ApiVersion> {\n+\n+    public static final Pattern PATTERN = Pattern.compile(\"v([0-9]+)((alpha|beta)([0-9]+))?\");\n+    public static final ApiVersion V1ALPHA1 = parse(\"v1alpha1\");\n+    public static final ApiVersion V1BETA1 = parse(\"v1beta1\");\n+    public static final ApiVersion V1 = parse(\"v1\");\n+\n+    private final short major;\n+    private final short ab;\n+    private final short minor;\n+\n+    public ApiVersion(short major, short ab, short minor) {\n+        if (major < 0 || ab < 0 || ab > 2 || minor < 0) {\n+            throw new RuntimeException();\n+        }\n+        this.major = major;\n+        this.ab = ab;\n+        this.minor = minor;\n+    }\n+\n+    private static Matcher matcher(String apiVersion) {\n+        return PATTERN.matcher(apiVersion);\n+    }\n+\n+    public static boolean isVersion(String apiVersion) {\n+        return matcher(apiVersion).matches();\n+    }\n+\n+    public static ApiVersion parse(String apiVersion) {\n+        Matcher matcher = matcher(apiVersion);\n+        if (!matcher.matches()) {\n+            throw new IllegalArgumentException(\"Invalid version \" + apiVersion);\n+        }\n+        short major = parseShort(matcher.group(1));\n+        short ab;\n+        short minor;\n+        String alphaBeta = matcher.group(3);\n+        if (matcher.groupCount() > 1 && alphaBeta != null) {\n+            if (\"alpha\".equals(alphaBeta)) {\n+                ab = 0;\n+            } else if (\"beta\".equals(alphaBeta)) {\n+                ab = 1;\n+            } else {\n+                throw new IllegalStateException(alphaBeta);\n+            }\n+            minor = parseShort(matcher.group(4));\n+        } else {\n+            ab = 2;", "originalCommit": "6f44863ce8054e309240493821527e26a0034ed7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTI1Nzk0NA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3653#discussion_r489257944", "bodyText": "There's no benefit to using an enum because these things are entirely internal to ApiVersion. The intention is that people use the String form (v1alpha1) rather than using a constructor which takes actual values. Using constants would actually make the compareTo code harder to read imho, but I'll do it anyway.", "author": "tombentley", "createdAt": "2020-09-16T08:28:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIyNDA4OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTI1OTQ1NA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/3653#discussion_r489259454", "bodyText": "Well, I don't think that the benefit has to be for people using it only but even for developers maintaining it. I got the values now or at least you could document them so no need to update but I think that using enums don't hurt.", "author": "ppatierno", "createdAt": "2020-09-16T08:31:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIyNDA4OA=="}], "type": "inlineReview", "revised_code": {"commit": "e0f92c6fc18b6dd3638f33950c4fc16da6f3d7c5", "changed_code": [{"header": "diff --git a/crd-generator/src/main/java/io/strimzi/crdgenerator/ApiVersion.java b/crd-annotations/src/main/java/io/strimzi/api/annotations/ApiVersion.java\nsimilarity index 73%\nrename from crd-generator/src/main/java/io/strimzi/crdgenerator/ApiVersion.java\nrename to crd-annotations/src/main/java/io/strimzi/api/annotations/ApiVersion.java\nindex e15b0d3bd..60dc580b8 100644\n--- a/crd-generator/src/main/java/io/strimzi/crdgenerator/ApiVersion.java\n+++ b/crd-annotations/src/main/java/io/strimzi/api/annotations/ApiVersion.java\n", "chunk": "@@ -49,23 +59,23 @@ public class ApiVersion implements Comparable<ApiVersion> {\n             throw new IllegalArgumentException(\"Invalid version \" + apiVersion);\n         }\n         short major = parseShort(matcher.group(1));\n-        short ab;\n+        Stability stability;\n         short minor;\n         String alphaBeta = matcher.group(3);\n         if (matcher.groupCount() > 1 && alphaBeta != null) {\n             if (\"alpha\".equals(alphaBeta)) {\n-                ab = 0;\n+                stability = Stability.ALPHA;\n             } else if (\"beta\".equals(alphaBeta)) {\n-                ab = 1;\n+                stability = Stability.BETA;\n             } else {\n                 throw new IllegalStateException(alphaBeta);\n             }\n             minor = parseShort(matcher.group(4));\n         } else {\n-            ab = 2;\n+            stability = Stability.STABLE;\n             minor = 0;\n         }\n-        return new ApiVersion(major, ab, minor);\n+        return new ApiVersion(major, stability, minor);\n     }\n \n     public static VersionRange<ApiVersion> parseRange(String s) {\n", "next_change": null}]}}, {"oid": "e0f92c6fc18b6dd3638f33950c4fc16da6f3d7c5", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/e0f92c6fc18b6dd3638f33950c4fc16da6f3d7c5", "message": "fix\n\nSigned-off-by: Tom Bentley <tbentley@redhat.com>", "committedDate": "2020-09-22T17:17:40Z", "type": "forcePushed"}, {"oid": "d6c128f5ad0763ee832b255088a1fe936ac001d1", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/d6c128f5ad0763ee832b255088a1fe936ac001d1", "message": "Rebase fix\n\nSigned-off-by: Tom Bentley <tbentley@redhat.com>", "committedDate": "2020-10-05T08:47:03Z", "type": "forcePushed"}, {"oid": "a2aeb50ef0497a39e49106539b6d506b86cfbf91", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/a2aeb50ef0497a39e49106539b6d506b86cfbf91", "message": "Add ApiVersion and range. Allow @Pattern, @Description and @Alternative to declare a version\n\nSigned-off-by: Tom Bentley <tbentley@redhat.com>", "committedDate": "2020-10-05T09:00:11Z", "type": "commit"}, {"oid": "4815308c7d19fc21416c9c75eb60c1c88518330c", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/4815308c7d19fc21416c9c75eb60c1c88518330c", "message": "Support for versiond schemas\n\nSigned-off-by: Tom Bentley <tbentley@redhat.com>", "committedDate": "2020-10-05T09:00:11Z", "type": "commit"}, {"oid": "fe93c86b32d7c3fc719e9098cddb484fae8ff439", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/fe93c86b32d7c3fc719e9098cddb484fae8ff439", "message": "Generify version ranges and versions\n\nSigned-off-by: Tom Bentley <tbentley@redhat.com>", "committedDate": "2020-10-05T09:00:11Z", "type": "commit"}, {"oid": "46f2298df9981a7d9b2dcf34fbc579f9628f7a36", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/46f2298df9981a7d9b2dcf34fbc579f9628f7a36", "message": "Fix tests\n\nSigned-off-by: Tom Bentley <tbentley@redhat.com>", "committedDate": "2020-10-05T09:00:11Z", "type": "commit"}, {"oid": "6cb598b884d57bad7dc898ebc3f7354b53e87948", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/6cb598b884d57bad7dc898ebc3f7354b53e87948", "message": "Nasty compromise for dealing with properties\n\nProbably need to assert that either annotations have no `apiVersion`, or that the `apiVersions` cover the versions in the CR in which they're embedded.\n\nSigned-off-by: Tom Bentley <tbentley@redhat.com>", "committedDate": "2020-10-05T09:00:11Z", "type": "commit"}, {"oid": "0e5c41b5ecf1aa3e3ac264a547f8044485a43624", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/0e5c41b5ecf1aa3e3ac264a547f8044485a43624", "message": "fixes\n\nSigned-off-by: Tom Bentley <tbentley@redhat.com>", "committedDate": "2020-10-05T09:00:11Z", "type": "commit"}, {"oid": "1fd1c47d430f252006d43af89c99ea552b3c1267", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/1fd1c47d430f252006d43af89c99ea552b3c1267", "message": "fix\n\nSigned-off-by: Tom Bentley <tbentley@redhat.com>", "committedDate": "2020-10-05T09:00:11Z", "type": "commit"}, {"oid": "1193cce2281dc1805fc2ca04981f027de50bc8f3", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/1193cce2281dc1805fc2ca04981f027de50bc8f3", "message": "Make prerequisites-check.sh respect DOCKER_CMD\n\nSigned-off-by: Tom Bentley <tbentley@redhat.com>", "committedDate": "2020-10-05T09:00:11Z", "type": "commit"}, {"oid": "3577b7170a381cfc97d3e058c1c41d93e672ac3d", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/3577b7170a381cfc97d3e058c1c41d93e672ac3d", "message": "wip\n\nSigned-off-by: Tom Bentley <tbentley@redhat.com>", "committedDate": "2020-10-05T09:00:11Z", "type": "commit"}, {"oid": "fa69907115f821c055c58da967ee7462bd75ce98", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/fa69907115f821c055c58da967ee7462bd75ce98", "message": "Fix test\n\nSigned-off-by: Tom Bentley <tbentley@redhat.com>", "committedDate": "2020-10-05T09:00:11Z", "type": "commit"}, {"oid": "4cae94f4d0ff23bb4fbc7c40c2444a84ba81410e", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/4cae94f4d0ff23bb4fbc7c40c2444a84ba81410e", "message": "fixup\n\nSigned-off-by: Tom Bentley <tbentley@redhat.com>", "committedDate": "2020-10-05T09:00:11Z", "type": "commit"}, {"oid": "d2e0014450b0c36f7b1502db547a79c33b3b6176", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/d2e0014450b0c36f7b1502db547a79c33b3b6176", "message": "java11ism\n\nSigned-off-by: Tom Bentley <tbentley@redhat.com>", "committedDate": "2020-10-05T09:00:11Z", "type": "commit"}, {"oid": "9c9dd4387efbd69fdb1e510077db9a157b965454", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/9c9dd4387efbd69fdb1e510077db9a157b965454", "message": "spotbuts\n\nSigned-off-by: Tom Bentley <tbentley@redhat.com>", "committedDate": "2020-10-05T09:00:11Z", "type": "commit"}, {"oid": "40dda7cafd9817fc98cff9bc3c0adc1dd96db354", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/40dda7cafd9817fc98cff9bc3c0adc1dd96db354", "message": "default\n\nSigned-off-by: Tom Bentley <tbentley@redhat.com>", "committedDate": "2020-10-05T09:00:11Z", "type": "commit"}, {"oid": "428b522fbc1f92cb0ccc8477643382475e99409e", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/428b522fbc1f92cb0ccc8477643382475e99409e", "message": "Some code review comments\n\nSigned-off-by: Tom Bentley <tbentley@redhat.com>", "committedDate": "2020-10-05T09:00:11Z", "type": "commit"}, {"oid": "c0c0ca15a9ec252fcb1c5f5816bef20b2ce8064c", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/c0c0ca15a9ec252fcb1c5f5816bef20b2ce8064c", "message": "More review comments and fixes for CRD v1\n\nSigned-off-by: Tom Bentley <tbentley@redhat.com>", "committedDate": "2020-10-05T09:00:11Z", "type": "commit"}, {"oid": "d35a149d84d2fb0267853c7fea9db5d99f5e85b4", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/d35a149d84d2fb0267853c7fea9db5d99f5e85b4", "message": "wip\n\nSigned-off-by: Tom Bentley <tbentley@redhat.com>", "committedDate": "2020-10-05T09:00:11Z", "type": "commit"}, {"oid": "f550da68e8756ea25dd2847d9c75d08246421d19", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/f550da68e8756ea25dd2847d9c75d08246421d19", "message": "to revert\n\nSigned-off-by: Tom Bentley <tbentley@redhat.com>", "committedDate": "2020-10-05T09:00:11Z", "type": "commit"}, {"oid": "74c23bbb3050105bf424594cfc876f2c1cd9018d", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/74c23bbb3050105bf424594cfc876f2c1cd9018d", "message": "Revert \"to revert\"\n\nThis reverts commit 54ad402d6f080b3eba1b5f012518d58ca014c924.\n\nSigned-off-by: Tom Bentley <tbentley@redhat.com>", "committedDate": "2020-10-05T09:00:11Z", "type": "commit"}, {"oid": "651a6a425367cc52e97c95fd6bf8a5368100eb04", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/651a6a425367cc52e97c95fd6bf8a5368100eb04", "message": "fix\n\nSigned-off-by: Tom Bentley <tbentley@redhat.com>", "committedDate": "2020-10-05T09:00:11Z", "type": "commit"}, {"oid": "371ee692cea6ac9109455567d48f6bf12fe8427d", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/371ee692cea6ac9109455567d48f6bf12fe8427d", "message": "fix\n\nSigned-off-by: Tom Bentley <tbentley@redhat.com>", "committedDate": "2020-10-05T09:00:11Z", "type": "commit"}, {"oid": "ce181dbe29bad4cb06d087c3a9762d24ac644741", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/ce181dbe29bad4cb06d087c3a9762d24ac644741", "message": "Fix problem with map types with CRD v1\n\nSigned-off-by: Tom Bentley <tbentley@redhat.com>", "committedDate": "2020-10-05T09:00:11Z", "type": "commit"}, {"oid": "6df319248f3401a618e9866dc199c2926371878b", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/6df319248f3401a618e9866dc199c2926371878b", "message": "Update derived resources\n\nSigned-off-by: Tom Bentley <tbentley@redhat.com>", "committedDate": "2020-10-05T09:00:11Z", "type": "commit"}, {"oid": "a09baad32000aded2cf76d6673cab116c4dc369f", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/a09baad32000aded2cf76d6673cab116c4dc369f", "message": "Test\n\nSigned-off-by: Tom Bentley <tbentley@redhat.com>", "committedDate": "2020-10-05T09:00:12Z", "type": "commit"}, {"oid": "c053bb54b6e72f35a5bbdf9b0f285077cbb2f6a0", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/c053bb54b6e72f35a5bbdf9b0f285077cbb2f6a0", "message": "Test\n\nSigned-off-by: Tom Bentley <tbentley@redhat.com>", "committedDate": "2020-10-05T09:00:12Z", "type": "commit"}, {"oid": "d2db69873eb92218c1ee290746c423ae82fd6619", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/d2db69873eb92218c1ee290746c423ae82fd6619", "message": "Rebase fix\n\nSigned-off-by: Tom Bentley <tbentley@redhat.com>", "committedDate": "2020-10-05T09:00:12Z", "type": "commit"}, {"oid": "735307cf158ccff0882fab3c9e14997d8fc7307e", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/735307cf158ccff0882fab3c9e14997d8fc7307e", "message": "derived\n\nSigned-off-by: Tom Bentley <tbentley@redhat.com>", "committedDate": "2020-10-05T09:00:12Z", "type": "commit"}, {"oid": "735307cf158ccff0882fab3c9e14997d8fc7307e", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/735307cf158ccff0882fab3c9e14997d8fc7307e", "message": "derived\n\nSigned-off-by: Tom Bentley <tbentley@redhat.com>", "committedDate": "2020-10-05T09:00:12Z", "type": "forcePushed"}]}