{"pr_number": 2830, "pr_title": "[MO] - [system test] -> additional properties of `SSL`", "pr_author": "see-quick", "pr_createdAt": "2020-04-14T14:45:08Z", "pr_url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODIwNjA3OA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r408206078", "body": "If I read the test correctly ... the `configWithLowestVersionOfTls` is not compatible with `configWithNewestVersionOfTls` ... so this should fail and you need to test that it fails IMHO?", "bodyText": "If I read the test correctly ... the configWithLowestVersionOfTls is not compatible with configWithNewestVersionOfTls ... so this should fail and you need to test that it fails IMHO?", "bodyHTML": "<p dir=\"auto\">If I read the test correctly ... the <code>configWithLowestVersionOfTls</code> is not compatible with <code>configWithNewestVersionOfTls</code> ... so this should fail and you need to test that it fails IMHO?</p>", "author": "scholzj", "createdAt": "2020-04-14T14:59:30Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/SslConfigurationST.java", "diffHunk": "@@ -0,0 +1,92 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest;\n+\n+import io.strimzi.api.kafka.model.KafkaConnectResources;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaConnectResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+\n+public class SslConfigurationST extends SecurityST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(SslConfigurationST.class);\n+\n+    @Test\n+    void testKafkaAndKafkaConnectTlsVersion() {\n+\n+        Map<String, Object> configWithNewestVersionOfTls = new HashMap<>();\n+\n+        final String tlsVersion12 = \"TLSv1.2\";\n+        final String tlsVersion1 = \"TLSv1\";\n+\n+        configWithNewestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12);\n+        configWithNewestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL);\n+\n+        LOGGER.info(\"Deploying Kafka cluster with the support {} TLS\",  tlsVersion12);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withConfig(configWithNewestVersionOfTls)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        Map<String, Object> configsFromKafkaCustomResource = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getConfig();\n+\n+        LOGGER.info(\"Verifying that Kafka cluster has the excepted configuration:\\n\" +\n+                \"\" + SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" +\n+                \"\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n+            configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG),\n+            configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG));\n+\n+        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG), is(tlsVersion12));\n+        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG), is(SslConfigs.DEFAULT_SSL_PROTOCOL));\n+\n+        Map<String, Object> configWithLowestVersionOfTls = new HashMap<>();\n+\n+        configWithLowestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion1);\n+        configWithLowestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, tlsVersion1);\n+\n+        KafkaClientsResource.deployKafkaClients(KAFKA_CLIENTS_NAME).done();\n+\n+        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n+            .editSpec()\n+                .withConfig(configWithLowestVersionOfTls)\n+            .endSpec()\n+            .build());\n+\n+        PodUtils.waitUntilPodIsPresent(KafkaConnectResources.deploymentName(CLUSTER_NAME)); // pod is not ready...", "originalCommit": "4496a4c4310559fc9cabbdcd210f1766e658ba40", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ1NTU0Mw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r408455543", "bodyText": "So, I do not want to verify it via logs in the Kafka connect pod, which is not a reliable option and can cost us flakiness. Actually, if the test will not work we will be able to find the bug\nPodUtils.waitUntilPodsByNameStability(KafkaConnectResources.deploymentName(CLUSTER_NAME));  -> if the bug will be present this method will failed because Kafka Connect pod will not be ready.\nDo you have some though? How to specifically verify it without using logs?", "author": "see-quick", "createdAt": "2020-04-14T21:46:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODIwNjA3OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ1NTczMA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r408455730", "bodyText": "So, I do not want to verify it via logs in the Kafka connect pod, which is not a reliable option and can cost us flakiness. Actually, if the test will not work we will be able to find the bug\nPodUtils.waitUntilPodsByNameStability(KafkaConnectResources.deploymentName(CLUSTER_NAME)); ->\nIf the bug will be present this method will fail because Kafka Connect pod will not be ready.\nDo you have some though? How to specifically verify it without using logs?", "author": "see-quick", "createdAt": "2020-04-14T21:47:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODIwNjA3OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ2NzEwNg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r408467106", "bodyText": "Well, when you deploy it with wrong configuration, the pod will not get ready. So you should at least check whether that is in the status before fixing the configuration and checking that it gets fixed. That was what I was thinking about.", "author": "scholzj", "createdAt": "2020-04-14T22:13:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODIwNjA3OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODc4NzcxNA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r408787714", "bodyText": "Yeah... I have done it.", "author": "see-quick", "createdAt": "2020-04-15T12:00:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODIwNjA3OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODIwNjYxNA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r408206614", "body": "Connect with capital C? Just a detail ...", "bodyText": "Connect with capital C? Just a detail ...", "bodyHTML": "<p dir=\"auto\">Connect with capital C? Just a detail ...</p>", "author": "scholzj", "createdAt": "2020-04-14T15:00:04Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/SslConfigurationST.java", "diffHunk": "@@ -0,0 +1,92 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest;\n+\n+import io.strimzi.api.kafka.model.KafkaConnectResources;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaConnectResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+\n+public class SslConfigurationST extends SecurityST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(SslConfigurationST.class);\n+\n+    @Test\n+    void testKafkaAndKafkaConnectTlsVersion() {\n+\n+        Map<String, Object> configWithNewestVersionOfTls = new HashMap<>();\n+\n+        final String tlsVersion12 = \"TLSv1.2\";\n+        final String tlsVersion1 = \"TLSv1\";\n+\n+        configWithNewestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12);\n+        configWithNewestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL);\n+\n+        LOGGER.info(\"Deploying Kafka cluster with the support {} TLS\",  tlsVersion12);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withConfig(configWithNewestVersionOfTls)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        Map<String, Object> configsFromKafkaCustomResource = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getConfig();\n+\n+        LOGGER.info(\"Verifying that Kafka cluster has the excepted configuration:\\n\" +\n+                \"\" + SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" +\n+                \"\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n+            configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG),\n+            configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG));\n+\n+        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG), is(tlsVersion12));\n+        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG), is(SslConfigs.DEFAULT_SSL_PROTOCOL));\n+\n+        Map<String, Object> configWithLowestVersionOfTls = new HashMap<>();\n+\n+        configWithLowestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion1);\n+        configWithLowestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, tlsVersion1);\n+\n+        KafkaClientsResource.deployKafkaClients(KAFKA_CLIENTS_NAME).done();\n+\n+        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n+            .editSpec()\n+                .withConfig(configWithLowestVersionOfTls)\n+            .endSpec()\n+            .build());\n+\n+        PodUtils.waitUntilPodIsPresent(KafkaConnectResources.deploymentName(CLUSTER_NAME)); // pod is not ready...\n+\n+        LOGGER.info(\"Replacing Kafka connect config to the newest(TLSv1.2) one same as the Kafka broker has.\");\n+        KafkaConnectResource.replaceKafkaConnectResource(CLUSTER_NAME, kafkaConnect -> kafkaConnect.getSpec().setConfig(configWithNewestVersionOfTls));\n+\n+        Map<String, Object> configsFromKafkaConnectCustomResource = KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getConfig();\n+\n+        LOGGER.info(\"Verifying that Kafka connect has the excepted configuration:\\n\" +\n+                \"\" + SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" +\n+                \"\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n+            configsFromKafkaConnectCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG),\n+            configsFromKafkaConnectCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG));\n+\n+        assertThat(configsFromKafkaConnectCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG), is(tlsVersion12));\n+        assertThat(configsFromKafkaConnectCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG), is(SslConfigs.DEFAULT_SSL_PROTOCOL));\n+\n+        LOGGER.info(\"Verifying that Kafka connect is stable\");", "originalCommit": "4496a4c4310559fc9cabbdcd210f1766e658ba40", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTM5OTg2Ng==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r409399866", "body": "Shouldn't we reset the counter here?", "bodyText": "Shouldn't we reset the counter here?", "bodyHTML": "<p dir=\"auto\">Shouldn't we reset the counter here?</p>", "author": "Frawless", "createdAt": "2020-04-16T09:06:26Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/objects/PodUtils.java", "diffHunk": "@@ -233,25 +250,27 @@ public static void waitUntilPodsStability(List<Pod> pods) {\n         int[] stabilityCounter = {0};\n \n         TestUtils.waitFor(\"Waiting for pods stability\", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,\n-            () -> {\n-                for (Pod pod : pods) {\n-                    if (pod.getStatus().getPhase().equals(\"Running\")) {\n-                        LOGGER.info(\"Pod {} is in the {} state. Remaining seconds pod to be stable {}\",\n-                            pod.getMetadata().getName(), pod.getStatus().getPhase(),\n-                            Constants.GLOBAL_RECONCILIATION_COUNT - stabilityCounter[0]);\n-                    } else {\n-                        LOGGER.info(\"Pod {} is not stable in phase following phase {}\", pod.getMetadata().getName(), pod.getStatus().getPhase());\n-                        return false;\n-                    }\n-                }\n-                stabilityCounter[0]++;\n+            () -> verifyThatPodsAreStable(pods, stabilityCounter));\n+    }\n \n-                if (stabilityCounter[0] == Constants.GLOBAL_RECONCILIATION_COUNT) {\n-                    LOGGER.info(\"All pods are stable {}\", pods.toString());\n-                    return true;\n-                }\n+    private static boolean verifyThatPodsAreStable(List<Pod> pods, int[] stabilityCounter) {\n+        for (Pod pod : pods) {\n+            if (pod.getStatus().getPhase().equals(\"Running\")) {\n+                LOGGER.info(\"Pod {} is in the {} state. Remaining seconds pod to be stable {}\",\n+                    pod.getMetadata().getName(), pod.getStatus().getPhase(),\n+                    Constants.GLOBAL_RECONCILIATION_COUNT - stabilityCounter[0]);\n+            } else {\n+                LOGGER.info(\"Pod {} is not stable in phase following phase {}\", pod.getMetadata().getName(), pod.getStatus().getPhase());", "originalCommit": "c73a91da86ec30fe7ec8b6369ea566ce2b8eb1c1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTUxMjY4OQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r409512689", "bodyText": "Good catch!!!", "author": "see-quick", "createdAt": "2020-04-16T12:23:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTM5OTg2Ng=="}], "type": "inlineReview"}, {"oid": "6950efa8d467f4019340d4ee3495ecf8a9db64be", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/6950efa8d467f4019340d4ee3495ecf8a9db64be", "message": "[MO] - [commend] -> Jakub\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-04-16T12:21:59Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTY0NjQ5MQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r409646491", "body": "I think we should add also a check that the condition is Ready now.", "bodyText": "I think we should add also a check that the condition is Ready now.", "bodyHTML": "<p dir=\"auto\">I think we should add also a check that the condition is Ready now.</p>", "author": "scholzj", "createdAt": "2020-04-16T15:26:23Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/security/SslConfigurationST.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.security;\n+\n+import io.strimzi.api.kafka.model.KafkaConnectResources;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaConnectResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+\n+@Tag(REGRESSION)\n+public class SslConfigurationST extends SecurityST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(SslConfigurationST.class);\n+\n+    @Test\n+    void testKafkaAndKafkaConnectTlsVersion() {\n+\n+        Map<String, Object> configWithNewestVersionOfTls = new HashMap<>();\n+\n+        final String tlsVersion12 = \"TLSv1.2\";\n+        final String tlsVersion1 = \"TLSv1\";\n+\n+        configWithNewestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12);\n+        configWithNewestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL);\n+\n+        LOGGER.info(\"Deploying Kafka cluster with the support {} TLS\",  tlsVersion12);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withConfig(configWithNewestVersionOfTls)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        Map<String, Object> configsFromKafkaCustomResource = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getConfig();\n+\n+        LOGGER.info(\"Verifying that Kafka cluster has the excepted configuration:\\n\" +\n+                \"\" + SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" +\n+                \"\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n+            configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG),\n+            configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG));\n+\n+        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG), is(tlsVersion12));\n+        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG), is(SslConfigs.DEFAULT_SSL_PROTOCOL));\n+\n+        Map<String, Object> configWithLowestVersionOfTls = new HashMap<>();\n+\n+        configWithLowestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion1);\n+        configWithLowestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, tlsVersion1);\n+\n+        KafkaClientsResource.deployKafkaClients(KAFKA_CLIENTS_NAME).done();\n+\n+        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n+            .editSpec()\n+                .withConfig(configWithLowestVersionOfTls)\n+            .endSpec()\n+            .build());\n+\n+        LOGGER.info(\"Verifying that Kafka Connect status is NotReady because of different TLS version\");\n+\n+        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"NotReady\");\n+\n+        LOGGER.info(\"Replacing Kafka Connect config to the newest(TLSv1.2) one same as the Kafka broker has.\");\n+\n+        KafkaConnectResource.replaceKafkaConnectResource(CLUSTER_NAME, kafkaConnect -> kafkaConnect.getSpec().setConfig(configWithNewestVersionOfTls));\n+\n+        LOGGER.info(\"Verifying that Kafka Connect has the excepted configuration:\\n\" +\n+            SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n+            tlsVersion12, SslConfigs.DEFAULT_SSL_PROTOCOL);\n+\n+        KafkaConnectUtils.waitForKafkaConnectConfigChange(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12, NAMESPACE, CLUSTER_NAME);\n+        KafkaConnectUtils.waitForKafkaConnectConfigChange(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL, NAMESPACE, CLUSTER_NAME);\n+\n+        LOGGER.info(\"Verifying that Kafka Connect is stable\");\n+\n+        PodUtils.waitUntilPodsByNameStability(KafkaConnectResources.deploymentName(CLUSTER_NAME));", "originalCommit": "6950efa8d467f4019340d4ee3495ecf8a9db64be", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTE2NDk5NA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r411164994", "bodyText": "make sense )))", "author": "see-quick", "createdAt": "2020-04-20T07:46:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTY0NjQ5MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTY0Njc2NA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r409646764", "body": "Same as above - you should also check that the KafkaConnect is now ready.", "bodyText": "Same as above - you should also check that the KafkaConnect is now ready.", "bodyHTML": "<p dir=\"auto\">Same as above - you should also check that the KafkaConnect is now ready.</p>", "author": "scholzj", "createdAt": "2020-04-16T15:26:41Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/security/SslConfigurationST.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.security;\n+\n+import io.strimzi.api.kafka.model.KafkaConnectResources;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaConnectResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+\n+@Tag(REGRESSION)\n+public class SslConfigurationST extends SecurityST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(SslConfigurationST.class);\n+\n+    @Test\n+    void testKafkaAndKafkaConnectTlsVersion() {\n+\n+        Map<String, Object> configWithNewestVersionOfTls = new HashMap<>();\n+\n+        final String tlsVersion12 = \"TLSv1.2\";\n+        final String tlsVersion1 = \"TLSv1\";\n+\n+        configWithNewestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12);\n+        configWithNewestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL);\n+\n+        LOGGER.info(\"Deploying Kafka cluster with the support {} TLS\",  tlsVersion12);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withConfig(configWithNewestVersionOfTls)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        Map<String, Object> configsFromKafkaCustomResource = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getConfig();\n+\n+        LOGGER.info(\"Verifying that Kafka cluster has the excepted configuration:\\n\" +\n+                \"\" + SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" +\n+                \"\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n+            configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG),\n+            configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG));\n+\n+        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG), is(tlsVersion12));\n+        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG), is(SslConfigs.DEFAULT_SSL_PROTOCOL));\n+\n+        Map<String, Object> configWithLowestVersionOfTls = new HashMap<>();\n+\n+        configWithLowestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion1);\n+        configWithLowestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, tlsVersion1);\n+\n+        KafkaClientsResource.deployKafkaClients(KAFKA_CLIENTS_NAME).done();\n+\n+        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n+            .editSpec()\n+                .withConfig(configWithLowestVersionOfTls)\n+            .endSpec()\n+            .build());\n+\n+        LOGGER.info(\"Verifying that Kafka Connect status is NotReady because of different TLS version\");\n+\n+        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"NotReady\");\n+\n+        LOGGER.info(\"Replacing Kafka Connect config to the newest(TLSv1.2) one same as the Kafka broker has.\");\n+\n+        KafkaConnectResource.replaceKafkaConnectResource(CLUSTER_NAME, kafkaConnect -> kafkaConnect.getSpec().setConfig(configWithNewestVersionOfTls));\n+\n+        LOGGER.info(\"Verifying that Kafka Connect has the excepted configuration:\\n\" +\n+            SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n+            tlsVersion12, SslConfigs.DEFAULT_SSL_PROTOCOL);\n+\n+        KafkaConnectUtils.waitForKafkaConnectConfigChange(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12, NAMESPACE, CLUSTER_NAME);\n+        KafkaConnectUtils.waitForKafkaConnectConfigChange(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL, NAMESPACE, CLUSTER_NAME);\n+\n+        LOGGER.info(\"Verifying that Kafka Connect is stable\");\n+\n+        PodUtils.waitUntilPodsByNameStability(KafkaConnectResources.deploymentName(CLUSTER_NAME));\n+    }\n+\n+    @Test\n+    void testKafkaAndKafkaConnectCipherSuites() {\n+        Map<String, Object> configWithCipherSuitesSha384 = new HashMap<>();\n+\n+        final String cipherSuitesSha384 = \"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\";\n+        final String cipherSuitesSha256 = \"TLS_DHE_RSA_WITH_AES_128_GCM_SHA256\";\n+\n+        configWithCipherSuitesSha384.put(SslConfigs.SSL_CIPHER_SUITES_CONFIG, cipherSuitesSha384);\n+\n+        LOGGER.info(\"Deploying Kafka cluster with the support {} cipher algorithms\",  cipherSuitesSha384);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withConfig(configWithCipherSuitesSha384)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        Map<String, Object> configsFromKafkaCustomResource = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getConfig();\n+\n+        LOGGER.info(\"Verifying that Kafka cluster has the excepted configuration:\\n\" + SslConfigs.SSL_CIPHER_SUITES_CONFIG + \" -> {}\",\n+            configsFromKafkaCustomResource.get(SslConfigs.SSL_CIPHER_SUITES_CONFIG));\n+\n+        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_CIPHER_SUITES_CONFIG), is(cipherSuitesSha384));\n+\n+        Map<String, Object> configWithCipherSuitesSha256 = new HashMap<>();\n+\n+        configWithCipherSuitesSha256.put(SslConfigs.SSL_CIPHER_SUITES_CONFIG, cipherSuitesSha256);\n+\n+        KafkaClientsResource.deployKafkaClients(KAFKA_CLIENTS_NAME).done();\n+\n+        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n+            .editSpec()\n+                .withConfig(configWithCipherSuitesSha256)\n+            .endSpec()\n+            .build());\n+\n+        LOGGER.info(\"Verifying that Kafka Connect status is NotReady because of different cipher suites complexity of algorithm\");\n+\n+        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"NotReady\");\n+\n+        LOGGER.info(\"Replacing Kafka Connect config to the cipher suites same as the Kafka broker has.\");\n+\n+        KafkaConnectResource.replaceKafkaConnectResource(CLUSTER_NAME, kafkaConnect -> kafkaConnect.getSpec().setConfig(configWithCipherSuitesSha384));\n+\n+        LOGGER.info(\"Verifying that Kafka Connect has the excepted configuration:\\n\" +\n+            SslConfigs.SSL_CIPHER_SUITES_CONFIG + \" -> {}\", configsFromKafkaCustomResource.get(SslConfigs.SSL_CIPHER_SUITES_CONFIG));\n+\n+        KafkaConnectUtils.waitForKafkaConnectConfigChange(SslConfigs.SSL_CIPHER_SUITES_CONFIG, cipherSuitesSha384, NAMESPACE, CLUSTER_NAME);\n+\n+        LOGGER.info(\"Verifying that Kafka Connect is stable\");\n+\n+        PodUtils.waitUntilPodsByNameStability(KafkaConnectResources.deploymentName(CLUSTER_NAME));", "originalCommit": "6950efa8d467f4019340d4ee3495ecf8a9db64be", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjM5ODkyMw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r416398923", "body": "I always try to start my method Javadocs with a verb (gets, waits, calculates etc), that tends to ensure that the first sentence is concise and to the point.\r\n\r\n```suggestion\r\n     * Waits until the kafka connect CR config has changed.\r\n```", "bodyText": "I always try to start my method Javadocs with a verb (gets, waits, calculates etc), that tends to ensure that the first sentence is concise and to the point.\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                 *  Method waitForKafkaConnectConfigChange, which will wait until the kafka connect CR config will be changed\n          \n          \n            \n                 * Waits until the kafka connect CR config has changed.", "bodyHTML": "<p dir=\"auto\">I always try to start my method Javadocs with a verb (gets, waits, calculates etc), that tends to ensure that the first sentence is concise and to the point.</p>\n  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">     <span class=\"pl-k\">*</span> <span class=\"x x-first\"> </span><span class=\"pl-smi x\">Method</span><span class=\"x x-last\"> waitForKafkaConnectConfigChange, which will wait </span>until the kafka connect <span class=\"pl-c1\">CR</span> config <span class=\"x x-first x-last\">will be </span>changed</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">     <span class=\"pl-k\">*</span> <span class=\"pl-smi x x-first\">Waits</span><span class=\"x x-last\"> </span>until the kafka connect <span class=\"pl-c1\">CR</span> config <span class=\"x x-first x-last\">has </span>changed<span class=\"x x-first x-last\">.</span></td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "tombentley", "createdAt": "2020-04-28T07:42:14Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaConnectUtils.java", "diffHunk": "@@ -53,4 +53,22 @@ public static void waitForMessagesInKafkaConnectFileSink(String kafkaConnectPodN\n         waitForMessagesInKafkaConnectFileSink(kafkaConnectPodName, sinkFileName,\n                 \"\\\"Sending messages\\\": \\\"Hello-world - 99\\\"\");\n     }\n+\n+    /**\n+     *  Method waitForKafkaConnectConfigChange, which will wait until the kafka connect CR config will be changed", "originalCommit": "49c9062fe88b80e57ab6de4db52bb6dad6861760", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjQwMDgxOQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r416400819", "body": "```suggestion\r\n     * Waits until all matching pods are {@linkplain #verifyThatPodsAreStable(List, int) stable} in the \"Running\" phase. \r\n```", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                 * Method waitUntilPodsByNameStability ensuring for every pod listed for kafka or zookeeper statefulSet will be controlling\n          \n          \n            \n                 * their status in Running phase. If the pod will be running for selected time #Constants.GLOBAL_RECONCILIATION_COUNT\n          \n          \n            \n                 * pod is considered as a stable. Otherwise this procedure will be repeat.\n          \n          \n            \n                 * Waits until all matching pods are {@linkplain #verifyThatPodsAreStable(List, int) stable} in the \"Running\" phase.", "bodyHTML": "  <div class=\"my-2 border rounded-1 js-suggested-changes-blob diff-view js-check-bidi\" id=\"\">\n    <div class=\"f6 p-2 lh-condensed border-bottom d-flex\">\n      <div class=\"flex-auto flex-items-center color-fg-muted\">\n        Suggested change\n        <span class=\"tooltipped tooltipped-multiline tooltipped-s\" aria-label=\"This code change can be committed by users with write permissions.\">\n          <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-info hide-sm\">\n    <path fill-rule=\"evenodd\" d=\"M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z\"></path>\n</svg>\n        </span>\n      </div>\n    </div>\n    <div itemprop=\"text\" class=\"blob-wrapper data file\" style=\"margin: 0; border: none; overflow-y: visible; overflow-x: auto;\">\n      <table class=\"d-table tab-size mb-0 width-full\" data-paste-markdown-skip=\"\">\n          <tbody><tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"240\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">     <span class=\"pl-k\">*</span> <span class=\"pl-smi\">Method</span> waitUntilPodsByNameStability ensuring <span class=\"pl-k\">for</span> every pod listed <span class=\"pl-k\">for</span> kafka or zookeeper statefulSet will be controlling</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"241\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">     <span class=\"pl-k\">*</span> their status in <span class=\"pl-smi\">Running</span> phase. <span class=\"pl-smi\">If</span> the pod will be running <span class=\"pl-k\">for</span> selected time #<span class=\"pl-smi\">Constants</span><span class=\"pl-c1\"><span class=\"pl-k\">.</span>GLOBAL_RECONCILIATION_COUNT</span></td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-deletion text-right border-0 px-2 py-1 lh-default\" data-line-number=\"242\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-deletion js-blob-code-deletion blob-code-marker-deletion\">     <span class=\"pl-k\">*</span> pod is considered as a stable. <span class=\"pl-smi\">Otherwise</span> <span class=\"pl-c1\">this</span> procedure will be repeat.</td>\n          </tr>\n          <tr class=\"border-0\">\n            <td class=\"blob-num blob-num-addition text-right border-0 px-2 py-1 lh-default\" data-line-number=\"240\"></td>\n            <td class=\"border-0 px-2 py-1 blob-code-inner blob-code-addition js-blob-code-addition blob-code-marker-addition\">     <span class=\"pl-k\">*</span> <span class=\"pl-smi\">Waits</span> until all matching pods are {<span class=\"pl-k\">@linkplain</span> #verifyThatPodsAreStable(<span class=\"pl-smi\">List</span>, <span class=\"pl-k\">int</span>) stable} in the <span class=\"pl-s\"><span class=\"pl-pds\">\"</span>Running<span class=\"pl-pds\">\"</span></span> phase. </td>\n          </tr>\n      </tbody></table>\n    </div>\n    <div class=\"js-apply-changes\"></div>\n  </div>\n", "author": "tombentley", "createdAt": "2020-04-28T07:45:16Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/objects/PodUtils.java", "diffHunk": "@@ -223,6 +224,22 @@ public static void waitUntilPodLabelsDeletion(String podName, String... labelKey\n         }\n     }\n \n+    /**\n+     * Method waitUntilPodsByNameStability ensuring for every pod listed for kafka or zookeeper statefulSet will be controlling\n+     * their status in Running phase. If the pod will be running for selected time #Constants.GLOBAL_RECONCILIATION_COUNT\n+     * pod is considered as a stable. Otherwise this procedure will be repeat.", "originalCommit": "49c9062fe88b80e57ab6de4db52bb6dad6861760", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjQwMTkyNw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r416401927", "body": "It's a bit confusing that this `Constants.GLOBAL_RECONCILIATION_COUNT` is called a count when according to that logging it's actually a number of seconds. I think you're relying on the caller invoking this from a `waitFor()` which is polling once per second. I guess that's OK since this is a private method, but I wonder if this contract could be improved.\r\n\r\nI guess the two callers are basically the same except for how they supply the `List<Pod>`, right? So why not:\r\n\r\n* Change the `List<Pod> pods` to `Supplier<List<Pod>> pods`\r\n* Move the `waitFor` and the `int[] stabilityCounter = {0};` from the callers into this method.\r\n* Call the `Supplier` each time in the `waitFor`\r\n\r\nThat way the poll interval is defined in the same method as how you're using the stabilityCounter. ", "bodyText": "It's a bit confusing that this Constants.GLOBAL_RECONCILIATION_COUNT is called a count when according to that logging it's actually a number of seconds. I think you're relying on the caller invoking this from a waitFor() which is polling once per second. I guess that's OK since this is a private method, but I wonder if this contract could be improved.\nI guess the two callers are basically the same except for how they supply the List<Pod>, right? So why not:\n\nChange the List<Pod> pods to Supplier<List<Pod>> pods\nMove the waitFor and the int[] stabilityCounter = {0}; from the callers into this method.\nCall the Supplier each time in the waitFor\n\nThat way the poll interval is defined in the same method as how you're using the stabilityCounter.", "bodyHTML": "<p dir=\"auto\">It's a bit confusing that this <code>Constants.GLOBAL_RECONCILIATION_COUNT</code> is called a count when according to that logging it's actually a number of seconds. I think you're relying on the caller invoking this from a <code>waitFor()</code> which is polling once per second. I guess that's OK since this is a private method, but I wonder if this contract could be improved.</p>\n<p dir=\"auto\">I guess the two callers are basically the same except for how they supply the <code>List&lt;Pod&gt;</code>, right? So why not:</p>\n<ul dir=\"auto\">\n<li>Change the <code>List&lt;Pod&gt; pods</code> to <code>Supplier&lt;List&lt;Pod&gt;&gt; pods</code></li>\n<li>Move the <code>waitFor</code> and the <code>int[] stabilityCounter = {0};</code> from the callers into this method.</li>\n<li>Call the <code>Supplier</code> each time in the <code>waitFor</code></li>\n</ul>\n<p dir=\"auto\">That way the poll interval is defined in the same method as how you're using the stabilityCounter.</p>", "author": "tombentley", "createdAt": "2020-04-28T07:46:54Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/objects/PodUtils.java", "diffHunk": "@@ -233,25 +250,29 @@ public static void waitUntilPodsStability(List<Pod> pods) {\n         int[] stabilityCounter = {0};\n \n         TestUtils.waitFor(\"Waiting for pods stability\", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,\n-            () -> {\n-                for (Pod pod : pods) {\n-                    if (pod.getStatus().getPhase().equals(\"Running\")) {\n-                        LOGGER.info(\"Pod {} is in the {} state. Remaining seconds pod to be stable {}\",\n-                            pod.getMetadata().getName(), pod.getStatus().getPhase(),\n-                            Constants.GLOBAL_RECONCILIATION_COUNT - stabilityCounter[0]);\n-                    } else {\n-                        LOGGER.info(\"Pod {} is not stable in phase following phase {}\", pod.getMetadata().getName(), pod.getStatus().getPhase());\n-                        return false;\n-                    }\n-                }\n-                stabilityCounter[0]++;\n+            () -> verifyThatPodsAreStable(pods, stabilityCounter));\n+    }\n \n-                if (stabilityCounter[0] == Constants.GLOBAL_RECONCILIATION_COUNT) {\n-                    LOGGER.info(\"All pods are stable {}\", pods.toString());\n-                    return true;\n-                }\n+    private static boolean verifyThatPodsAreStable(List<Pod> pods, int[] stabilityCounter) {\n+        for (Pod pod : pods) {\n+            if (pod.getStatus().getPhase().equals(\"Running\")) {\n+                LOGGER.info(\"Pod {} is in the {} state. Remaining seconds pod to be stable {}\",\n+                    pod.getMetadata().getName(), pod.getStatus().getPhase(),\n+                    Constants.GLOBAL_RECONCILIATION_COUNT - stabilityCounter[0]);", "originalCommit": "49c9062fe88b80e57ab6de4db52bb6dad6861760", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjQ5MjA0Mg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r416492042", "bodyText": "Thanks )", "author": "see-quick", "createdAt": "2020-04-28T10:07:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjQwMTkyNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjQwNjA5OA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r416406098", "body": "Do you mean accepted rather than excepted?", "bodyText": "Do you mean accepted rather than excepted?", "bodyHTML": "<p dir=\"auto\">Do you mean accepted rather than excepted?</p>", "author": "tombentley", "createdAt": "2020-04-28T07:53:44Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/security/SslConfigurationST.java", "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.security;\n+\n+import io.strimzi.api.kafka.model.KafkaConnectResources;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaConnectResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+\n+@Tag(REGRESSION)\n+public class SslConfigurationST extends SecurityST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(SslConfigurationST.class);\n+\n+    @Test\n+    void testKafkaAndKafkaConnectTlsVersion() {\n+\n+        Map<String, Object> configWithNewestVersionOfTls = new HashMap<>();\n+\n+        final String tlsVersion12 = \"TLSv1.2\";\n+        final String tlsVersion1 = \"TLSv1\";\n+\n+        configWithNewestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12);\n+        configWithNewestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL);\n+\n+        LOGGER.info(\"Deploying Kafka cluster with the support {} TLS\",  tlsVersion12);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withConfig(configWithNewestVersionOfTls)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        Map<String, Object> configsFromKafkaCustomResource = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getConfig();\n+\n+        LOGGER.info(\"Verifying that Kafka cluster has the excepted configuration:\\n\" +", "originalCommit": "49c9062fe88b80e57ab6de4db52bb6dad6861760", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjQwNjUzNg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r416406536", "body": "Why using `+` when you could interpolate with `{}`?", "bodyText": "Why using + when you could interpolate with {}?", "bodyHTML": "<p dir=\"auto\">Why using <code>+</code> when you could interpolate with <code>{}</code>?</p>", "author": "tombentley", "createdAt": "2020-04-28T07:54:25Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/security/SslConfigurationST.java", "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.security;\n+\n+import io.strimzi.api.kafka.model.KafkaConnectResources;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaConnectResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+\n+@Tag(REGRESSION)\n+public class SslConfigurationST extends SecurityST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(SslConfigurationST.class);\n+\n+    @Test\n+    void testKafkaAndKafkaConnectTlsVersion() {\n+\n+        Map<String, Object> configWithNewestVersionOfTls = new HashMap<>();\n+\n+        final String tlsVersion12 = \"TLSv1.2\";\n+        final String tlsVersion1 = \"TLSv1\";\n+\n+        configWithNewestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12);\n+        configWithNewestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL);\n+\n+        LOGGER.info(\"Deploying Kafka cluster with the support {} TLS\",  tlsVersion12);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withConfig(configWithNewestVersionOfTls)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        Map<String, Object> configsFromKafkaCustomResource = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getConfig();\n+\n+        LOGGER.info(\"Verifying that Kafka cluster has the excepted configuration:\\n\" +\n+                \"\" + SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" +\n+                \"\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n+            configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG),\n+            configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG));", "originalCommit": "49c9062fe88b80e57ab6de4db52bb6dad6861760", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjQwNzEzMw==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r416407133", "body": "Should we also assert on the NotReady reason?", "bodyText": "Should we also assert on the NotReady reason?", "bodyHTML": "<p dir=\"auto\">Should we also assert on the NotReady reason?</p>", "author": "tombentley", "createdAt": "2020-04-28T07:55:25Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/security/SslConfigurationST.java", "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.security;\n+\n+import io.strimzi.api.kafka.model.KafkaConnectResources;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaConnectResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+\n+@Tag(REGRESSION)\n+public class SslConfigurationST extends SecurityST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(SslConfigurationST.class);\n+\n+    @Test\n+    void testKafkaAndKafkaConnectTlsVersion() {\n+\n+        Map<String, Object> configWithNewestVersionOfTls = new HashMap<>();\n+\n+        final String tlsVersion12 = \"TLSv1.2\";\n+        final String tlsVersion1 = \"TLSv1\";\n+\n+        configWithNewestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12);\n+        configWithNewestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL);\n+\n+        LOGGER.info(\"Deploying Kafka cluster with the support {} TLS\",  tlsVersion12);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withConfig(configWithNewestVersionOfTls)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        Map<String, Object> configsFromKafkaCustomResource = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getConfig();\n+\n+        LOGGER.info(\"Verifying that Kafka cluster has the excepted configuration:\\n\" +\n+                \"\" + SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" +\n+                \"\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n+            configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG),\n+            configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG));\n+\n+        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG), is(tlsVersion12));\n+        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG), is(SslConfigs.DEFAULT_SSL_PROTOCOL));\n+\n+        Map<String, Object> configWithLowestVersionOfTls = new HashMap<>();\n+\n+        configWithLowestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion1);\n+        configWithLowestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, tlsVersion1);\n+\n+        KafkaClientsResource.deployKafkaClients(KAFKA_CLIENTS_NAME).done();\n+\n+        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n+            .editSpec()\n+                .withConfig(configWithLowestVersionOfTls)\n+            .endSpec()\n+            .build());\n+\n+        LOGGER.info(\"Verifying that Kafka Connect status is NotReady because of different TLS version\");\n+\n+        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"NotReady\");", "originalCommit": "49c9062fe88b80e57ab6de4db52bb6dad6861760", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjQzNzUxNg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r416437516", "bodyText": "I think, there is no need to assert value. This dynamic wait just ensures the CR of Kafka Connect will be in the desired state.", "author": "see-quick", "createdAt": "2020-04-28T08:42:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjQwNzEzMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjQwNzYxMA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r416407610", "body": "Similar comments", "bodyText": "Similar comments", "bodyHTML": "<p dir=\"auto\">Similar comments</p>", "author": "tombentley", "createdAt": "2020-04-28T07:56:05Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/security/SslConfigurationST.java", "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.security;\n+\n+import io.strimzi.api.kafka.model.KafkaConnectResources;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaConnectResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+\n+@Tag(REGRESSION)\n+public class SslConfigurationST extends SecurityST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(SslConfigurationST.class);\n+\n+    @Test\n+    void testKafkaAndKafkaConnectTlsVersion() {\n+\n+        Map<String, Object> configWithNewestVersionOfTls = new HashMap<>();\n+\n+        final String tlsVersion12 = \"TLSv1.2\";\n+        final String tlsVersion1 = \"TLSv1\";\n+\n+        configWithNewestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12);\n+        configWithNewestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL);\n+\n+        LOGGER.info(\"Deploying Kafka cluster with the support {} TLS\",  tlsVersion12);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withConfig(configWithNewestVersionOfTls)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        Map<String, Object> configsFromKafkaCustomResource = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getConfig();\n+\n+        LOGGER.info(\"Verifying that Kafka cluster has the excepted configuration:\\n\" +\n+                \"\" + SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" +\n+                \"\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n+            configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG),\n+            configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG));\n+\n+        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG), is(tlsVersion12));\n+        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG), is(SslConfigs.DEFAULT_SSL_PROTOCOL));\n+\n+        Map<String, Object> configWithLowestVersionOfTls = new HashMap<>();\n+\n+        configWithLowestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion1);\n+        configWithLowestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, tlsVersion1);\n+\n+        KafkaClientsResource.deployKafkaClients(KAFKA_CLIENTS_NAME).done();\n+\n+        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n+            .editSpec()\n+                .withConfig(configWithLowestVersionOfTls)\n+            .endSpec()\n+            .build());\n+\n+        LOGGER.info(\"Verifying that Kafka Connect status is NotReady because of different TLS version\");\n+\n+        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"NotReady\");\n+\n+        LOGGER.info(\"Replacing Kafka Connect config to the newest(TLSv1.2) one same as the Kafka broker has.\");\n+\n+        KafkaConnectResource.replaceKafkaConnectResource(CLUSTER_NAME, kafkaConnect -> kafkaConnect.getSpec().setConfig(configWithNewestVersionOfTls));\n+\n+        LOGGER.info(\"Verifying that Kafka Connect has the excepted configuration:\\n\" +\n+            SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n+            tlsVersion12, SslConfigs.DEFAULT_SSL_PROTOCOL);\n+\n+        KafkaConnectUtils.waitForKafkaConnectConfigChange(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12, NAMESPACE, CLUSTER_NAME);\n+        KafkaConnectUtils.waitForKafkaConnectConfigChange(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL, NAMESPACE, CLUSTER_NAME);\n+\n+        LOGGER.info(\"Verifying that Kafka Connect is stable\");\n+\n+        PodUtils.waitUntilPodsByNameStability(KafkaConnectResources.deploymentName(CLUSTER_NAME));\n+\n+        LOGGER.info(\"Verifying that Kafka Connect status is Ready because of same TLS version\");\n+\n+        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"Ready\");\n+    }\n+\n+    @Test\n+    void testKafkaAndKafkaConnectCipherSuites() {\n+        Map<String, Object> configWithCipherSuitesSha384 = new HashMap<>();\n+\n+        final String cipherSuitesSha384 = \"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\";\n+        final String cipherSuitesSha256 = \"TLS_DHE_RSA_WITH_AES_128_GCM_SHA256\";\n+\n+        configWithCipherSuitesSha384.put(SslConfigs.SSL_CIPHER_SUITES_CONFIG, cipherSuitesSha384);\n+\n+        LOGGER.info(\"Deploying Kafka cluster with the support {} cipher algorithms\",  cipherSuitesSha384);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withConfig(configWithCipherSuitesSha384)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        Map<String, Object> configsFromKafkaCustomResource = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getConfig();\n+\n+        LOGGER.info(\"Verifying that Kafka cluster has the excepted configuration:\\n\" + SslConfigs.SSL_CIPHER_SUITES_CONFIG + \" -> {}\",\n+            configsFromKafkaCustomResource.get(SslConfigs.SSL_CIPHER_SUITES_CONFIG));", "originalCommit": "49c9062fe88b80e57ab6de4db52bb6dad6861760", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjQwNzg0Mg==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r416407842", "body": "Again why `+`", "bodyText": "Again why +", "bodyHTML": "<p dir=\"auto\">Again why <code>+</code></p>", "author": "tombentley", "createdAt": "2020-04-28T07:56:23Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/security/SslConfigurationST.java", "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.security;\n+\n+import io.strimzi.api.kafka.model.KafkaConnectResources;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaConnectResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+\n+@Tag(REGRESSION)\n+public class SslConfigurationST extends SecurityST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(SslConfigurationST.class);\n+\n+    @Test\n+    void testKafkaAndKafkaConnectTlsVersion() {\n+\n+        Map<String, Object> configWithNewestVersionOfTls = new HashMap<>();\n+\n+        final String tlsVersion12 = \"TLSv1.2\";\n+        final String tlsVersion1 = \"TLSv1\";\n+\n+        configWithNewestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12);\n+        configWithNewestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL);\n+\n+        LOGGER.info(\"Deploying Kafka cluster with the support {} TLS\",  tlsVersion12);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withConfig(configWithNewestVersionOfTls)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        Map<String, Object> configsFromKafkaCustomResource = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getConfig();\n+\n+        LOGGER.info(\"Verifying that Kafka cluster has the excepted configuration:\\n\" +\n+                \"\" + SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" +\n+                \"\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n+            configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG),\n+            configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG));\n+\n+        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG), is(tlsVersion12));\n+        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG), is(SslConfigs.DEFAULT_SSL_PROTOCOL));\n+\n+        Map<String, Object> configWithLowestVersionOfTls = new HashMap<>();\n+\n+        configWithLowestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion1);\n+        configWithLowestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, tlsVersion1);\n+\n+        KafkaClientsResource.deployKafkaClients(KAFKA_CLIENTS_NAME).done();\n+\n+        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n+            .editSpec()\n+                .withConfig(configWithLowestVersionOfTls)\n+            .endSpec()\n+            .build());\n+\n+        LOGGER.info(\"Verifying that Kafka Connect status is NotReady because of different TLS version\");\n+\n+        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"NotReady\");\n+\n+        LOGGER.info(\"Replacing Kafka Connect config to the newest(TLSv1.2) one same as the Kafka broker has.\");\n+\n+        KafkaConnectResource.replaceKafkaConnectResource(CLUSTER_NAME, kafkaConnect -> kafkaConnect.getSpec().setConfig(configWithNewestVersionOfTls));\n+\n+        LOGGER.info(\"Verifying that Kafka Connect has the excepted configuration:\\n\" +\n+            SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n+            tlsVersion12, SslConfigs.DEFAULT_SSL_PROTOCOL);\n+\n+        KafkaConnectUtils.waitForKafkaConnectConfigChange(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12, NAMESPACE, CLUSTER_NAME);\n+        KafkaConnectUtils.waitForKafkaConnectConfigChange(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL, NAMESPACE, CLUSTER_NAME);\n+\n+        LOGGER.info(\"Verifying that Kafka Connect is stable\");\n+\n+        PodUtils.waitUntilPodsByNameStability(KafkaConnectResources.deploymentName(CLUSTER_NAME));\n+\n+        LOGGER.info(\"Verifying that Kafka Connect status is Ready because of same TLS version\");\n+\n+        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"Ready\");\n+    }\n+\n+    @Test\n+    void testKafkaAndKafkaConnectCipherSuites() {\n+        Map<String, Object> configWithCipherSuitesSha384 = new HashMap<>();\n+\n+        final String cipherSuitesSha384 = \"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\";\n+        final String cipherSuitesSha256 = \"TLS_DHE_RSA_WITH_AES_128_GCM_SHA256\";\n+\n+        configWithCipherSuitesSha384.put(SslConfigs.SSL_CIPHER_SUITES_CONFIG, cipherSuitesSha384);\n+\n+        LOGGER.info(\"Deploying Kafka cluster with the support {} cipher algorithms\",  cipherSuitesSha384);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withConfig(configWithCipherSuitesSha384)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        Map<String, Object> configsFromKafkaCustomResource = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getConfig();\n+\n+        LOGGER.info(\"Verifying that Kafka cluster has the excepted configuration:\\n\" + SslConfigs.SSL_CIPHER_SUITES_CONFIG + \" -> {}\",\n+            configsFromKafkaCustomResource.get(SslConfigs.SSL_CIPHER_SUITES_CONFIG));\n+\n+        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_CIPHER_SUITES_CONFIG), is(cipherSuitesSha384));\n+\n+        Map<String, Object> configWithCipherSuitesSha256 = new HashMap<>();\n+\n+        configWithCipherSuitesSha256.put(SslConfigs.SSL_CIPHER_SUITES_CONFIG, cipherSuitesSha256);\n+\n+        KafkaClientsResource.deployKafkaClients(KAFKA_CLIENTS_NAME).done();\n+\n+        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n+            .editSpec()\n+                .withConfig(configWithCipherSuitesSha256)\n+            .endSpec()\n+            .build());\n+\n+        LOGGER.info(\"Verifying that Kafka Connect status is NotReady because of different cipher suites complexity of algorithm\");\n+\n+        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"NotReady\");\n+\n+        LOGGER.info(\"Replacing Kafka Connect config to the cipher suites same as the Kafka broker has.\");\n+\n+        KafkaConnectResource.replaceKafkaConnectResource(CLUSTER_NAME, kafkaConnect -> kafkaConnect.getSpec().setConfig(configWithCipherSuitesSha384));\n+\n+        LOGGER.info(\"Verifying that Kafka Connect has the excepted configuration:\\n\" +\n+            SslConfigs.SSL_CIPHER_SUITES_CONFIG + \" -> {}\", configsFromKafkaCustomResource.get(SslConfigs.SSL_CIPHER_SUITES_CONFIG));", "originalCommit": "49c9062fe88b80e57ab6de4db52bb6dad6861760", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjQwODAxNQ==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r416408015", "body": "Again, why `+`?", "bodyText": "Again, why +?", "bodyHTML": "<p dir=\"auto\">Again, why <code>+</code>?</p>", "author": "tombentley", "createdAt": "2020-04-28T07:56:42Z", "path": "systemtest/src/test/java/io/strimzi/systemtest/security/SslConfigurationST.java", "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Copyright Strimzi authors.\n+ * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).\n+ */\n+package io.strimzi.systemtest.security;\n+\n+import io.strimzi.api.kafka.model.KafkaConnectResources;\n+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;\n+import io.strimzi.systemtest.resources.crd.KafkaConnectResource;\n+import io.strimzi.systemtest.resources.crd.KafkaResource;\n+import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;\n+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;\n+import org.apache.kafka.common.config.SslConfigs;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+import static io.strimzi.systemtest.Constants.REGRESSION;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.CoreMatchers.is;\n+\n+@Tag(REGRESSION)\n+public class SslConfigurationST extends SecurityST {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(SslConfigurationST.class);\n+\n+    @Test\n+    void testKafkaAndKafkaConnectTlsVersion() {\n+\n+        Map<String, Object> configWithNewestVersionOfTls = new HashMap<>();\n+\n+        final String tlsVersion12 = \"TLSv1.2\";\n+        final String tlsVersion1 = \"TLSv1\";\n+\n+        configWithNewestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion12);\n+        configWithNewestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, SslConfigs.DEFAULT_SSL_PROTOCOL);\n+\n+        LOGGER.info(\"Deploying Kafka cluster with the support {} TLS\",  tlsVersion12);\n+\n+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)\n+            .editSpec()\n+                .editKafka()\n+                    .withConfig(configWithNewestVersionOfTls)\n+                .endKafka()\n+            .endSpec()\n+            .done();\n+\n+        Map<String, Object> configsFromKafkaCustomResource = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getKafka().getConfig();\n+\n+        LOGGER.info(\"Verifying that Kafka cluster has the excepted configuration:\\n\" +\n+                \"\" + SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" +\n+                \"\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n+            configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG),\n+            configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG));\n+\n+        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG), is(tlsVersion12));\n+        assertThat(configsFromKafkaCustomResource.get(SslConfigs.SSL_PROTOCOL_CONFIG), is(SslConfigs.DEFAULT_SSL_PROTOCOL));\n+\n+        Map<String, Object> configWithLowestVersionOfTls = new HashMap<>();\n+\n+        configWithLowestVersionOfTls.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, tlsVersion1);\n+        configWithLowestVersionOfTls.put(SslConfigs.SSL_PROTOCOL_CONFIG, tlsVersion1);\n+\n+        KafkaClientsResource.deployKafkaClients(KAFKA_CLIENTS_NAME).done();\n+\n+        KafkaConnectResource.kafkaConnectWithoutWait(KafkaConnectResource.defaultKafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)\n+            .editSpec()\n+                .withConfig(configWithLowestVersionOfTls)\n+            .endSpec()\n+            .build());\n+\n+        LOGGER.info(\"Verifying that Kafka Connect status is NotReady because of different TLS version\");\n+\n+        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, \"NotReady\");\n+\n+        LOGGER.info(\"Replacing Kafka Connect config to the newest(TLSv1.2) one same as the Kafka broker has.\");\n+\n+        KafkaConnectResource.replaceKafkaConnectResource(CLUSTER_NAME, kafkaConnect -> kafkaConnect.getSpec().setConfig(configWithNewestVersionOfTls));\n+\n+        LOGGER.info(\"Verifying that Kafka Connect has the excepted configuration:\\n\" +\n+            SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG + \" -> {}\\n\" + SslConfigs.SSL_PROTOCOL_CONFIG + \" -> {}\",\n+            tlsVersion12, SslConfigs.DEFAULT_SSL_PROTOCOL);", "originalCommit": "49c9062fe88b80e57ab6de4db52bb6dad6861760", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjQxMTQ5NA==", "url": "https://github.com/strimzi/strimzi-kafka-operator/pull/2830#discussion_r416411494", "body": "You should factor out a local variable for `KafkaConnectResource.kafkaConnectClient().inNamespace(namespace).withName(clusterName).get().getSpec().getConfig().get(propertyKey)`", "bodyText": "You should factor out a local variable for KafkaConnectResource.kafkaConnectClient().inNamespace(namespace).withName(clusterName).get().getSpec().getConfig().get(propertyKey)", "bodyHTML": "<p dir=\"auto\">You should factor out a local variable for <code>KafkaConnectResource.kafkaConnectClient().inNamespace(namespace).withName(clusterName).get().getSpec().getConfig().get(propertyKey)</code></p>", "author": "tombentley", "createdAt": "2020-04-28T08:02:09Z", "path": "systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaConnectUtils.java", "diffHunk": "@@ -53,4 +53,22 @@ public static void waitForMessagesInKafkaConnectFileSink(String kafkaConnectPodN\n         waitForMessagesInKafkaConnectFileSink(kafkaConnectPodName, sinkFileName,\n                 \"\\\"Sending messages\\\": \\\"Hello-world - 99\\\"\");\n     }\n+\n+    /**\n+     *  Method waitForKafkaConnectConfigChange, which will wait until the kafka connect CR config will be changed\n+     * @param propertyKey property key in the Kafka Connect CR config\n+     * @param propertyValue property value in the Kafka Connect CR config\n+     * @param namespace namespace name\n+     * @param clusterName cluster name\n+     */\n+    public static void waitForKafkaConnectConfigChange(String propertyKey, String propertyValue, String namespace, String clusterName) {\n+        LOGGER.info(\"Waiting for Kafka Connect property {} -> {} change\", propertyKey, propertyValue);\n+        TestUtils.waitFor(\"Waiting for Kafka Connect config \" + propertyKey + \" -> \" + propertyValue, Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,\n+            () -> {\n+                LOGGER.debug(\"Property key -> {}, Current property value -> {}\", propertyKey, KafkaConnectResource.kafkaConnectClient().inNamespace(namespace).withName(clusterName).get().getSpec().getConfig().get(propertyKey));\n+                LOGGER.debug(KafkaConnectResource.kafkaConnectClient().inNamespace(namespace).withName(clusterName).get().getSpec().getConfig().get(propertyKey) + \" == \" + propertyValue);\n+                return KafkaConnectResource.kafkaConnectClient().inNamespace(namespace).withName(clusterName).get().getSpec().getConfig().get(propertyKey).equals(propertyValue);", "originalCommit": "49c9062fe88b80e57ab6de4db52bb6dad6861760", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "9c45e7871e04b1bf9f83368b4c54d28c5be6172b", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/9c45e7871e04b1bf9f83368b4c54d28c5be6172b", "message": "[MO] - [system test] -> ssl\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-04-28T10:11:51Z", "type": "commit"}, {"oid": "89410e3705ccd09839157945c01aaeef8e189c77", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/89410e3705ccd09839157945c01aaeef8e189c77", "message": "[MO] - [commends] -> Jakub\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-04-28T10:11:51Z", "type": "commit"}, {"oid": "66e7c730a0c534f3449eedc99dc47be288de7add", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/66e7c730a0c534f3449eedc99dc47be288de7add", "message": "[MO] -s\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-04-28T10:11:51Z", "type": "commit"}, {"oid": "12b270dc334950ce97e7593bd5f671662047e207", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/12b270dc334950ce97e7593bd5f671662047e207", "message": "[MO] - [cipher] -> adding test case for cipher version\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-04-28T10:11:51Z", "type": "commit"}, {"oid": "6235d85c88e4216f22737f97cbcb59d45e3654c4", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/6235d85c88e4216f22737f97cbcb59d45e3654c4", "message": "[MO] - [tag] -> regression\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-04-28T10:11:51Z", "type": "commit"}, {"oid": "c2ad735bbf54ae2e78730189a1c4851c255b23cc", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/c2ad735bbf54ae2e78730189a1c4851c255b23cc", "message": "s\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-04-28T10:11:51Z", "type": "commit"}, {"oid": "5c8994c8fb6cef1d4397245ffee97ced47a43f1e", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/5c8994c8fb6cef1d4397245ffee97ced47a43f1e", "message": "[MO] - [commend] -> Jakub\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-04-28T10:11:51Z", "type": "commit"}, {"oid": "9ee3a8d1cbb12d6ebab8995a88d823dd919d62d2", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/9ee3a8d1cbb12d6ebab8995a88d823dd919d62d2", "message": "[MO] - [jakub] -> commends\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-04-28T10:11:51Z", "type": "commit"}, {"oid": "070db9a6f21e1d9d421abe6d55558f105c1c1113", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/070db9a6f21e1d9d421abe6d55558f105c1c1113", "message": "Tom's suggestion\n\nSigned-off-by: Tom Bentley <tbentley@redhat.com>", "committedDate": "2020-04-28T10:16:21Z", "type": "commit"}, {"oid": "4704d55f276d075067c38801fe0aba940dd73ffa", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/4704d55f276d075067c38801fe0aba940dd73ffa", "message": "[MO] -[ ss\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-04-28T10:16:21Z", "type": "commit"}, {"oid": "b2e626d126485b8c1ddccc53539c66b6701d0b35", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/b2e626d126485b8c1ddccc53539c66b6701d0b35", "message": "ss\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-04-28T10:16:58Z", "type": "commit"}, {"oid": "b2e626d126485b8c1ddccc53539c66b6701d0b35", "url": "https://github.com/strimzi/strimzi-kafka-operator/commit/b2e626d126485b8c1ddccc53539c66b6701d0b35", "message": "ss\n\nSigned-off-by: morsak <xorsak02@stud.fit.vutbr.cz>", "committedDate": "2020-04-28T10:16:58Z", "type": "forcePushed"}]}